{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install squaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "from ascento_gym import Ascento\n",
    "# from balance_pend import InvertedPendulumEnv as Ascento\n",
    "from stable_baselines3 import PPO, DDPG, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# env = Ascento()\n",
    "# env.reset_model()\n",
    "# for i_episode in range(150):\n",
    "#     observation = env.reset()\n",
    "#     done = None\n",
    "#     while not done:\n",
    "#         env.render()\n",
    "#         print(env.yaw)\n",
    "#         action = env.action_space.sample()\n",
    "# #         action[2] = 1\n",
    "# #         action[3] = 1\n",
    "\n",
    "#         observation, reward, done, info = env.step(action)\n",
    "        \n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "env = Ascento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.50653708e+00,  5.54769695e-03,  7.91810233e-01, -8.99110199e-03,\n",
       "        1.31662288e-02, -6.27203297e+00, -5.54978574e-03,  2.01209707e-03,\n",
       "       -6.42936714e-03, -2.30647056e-03,  7.39075246e-04,  3.43360622e-04])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1. -1. -1. -1.], [1. 1. 1. 1.], (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1865658 , -0.05869308, -0.47286385, -0.3740179 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.77887636, -0.62552128, -0.31807912, -1.00353629, -1.53367033,\n",
       "       -2.09505598, -0.15921661,  1.46301218, -2.05553094, -1.21583457,\n",
       "        1.20236824, -0.24364779])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = make_vec_env(Ascento, n_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Ascento()\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'models_ascento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold = 20*1e5, verbose = 1)\n",
    "\n",
    "eval_callback = EvalCallback(env, callback_on_new_best = stop_callback,\n",
    "                            eval_freq = 5000, best_model_save_path = save_path, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "logs_dir = os.path.join('Training', 'logs_dir_ascento')\n",
    "model = PPO('MlpPolicy', vec_env, verbose = 1, tensorboard_log = logs_dir, create_eval_env = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load('/home/bmsit/Ascento/jointed_limited/Training/models_ascento/best_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"/home/bmsit/Ascento/jointed_limited/Training/models_ascento/ppo_jl_ramp_top_v3.zip\", env = vec_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/logs_dir_ascento/PPO_63\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 253      |\n",
      "|    ep_rew_mean     | -7.9e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 1637     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 283         |\n",
      "|    ep_rew_mean          | -4.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1265        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003135209 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02e+06    |\n",
      "|    n_updates            | 50870       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 4.14e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5000, episode_reward=-10246.17 +/- 12116.71\n",
      "Episode length: 400.60 +/- 331.09\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 401           |\n",
      "|    mean_reward          | -1.02e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 5000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9025377e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.15          |\n",
      "|    explained_variance   | 0.35          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.24e+07      |\n",
      "|    n_updates            | 50880         |\n",
      "|    policy_gradient_loss | -3.66e-05     |\n",
      "|    std                  | 0.244         |\n",
      "|    value_loss           | 9.46e+07      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 342       |\n",
      "|    ep_rew_mean     | -6.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 996       |\n",
      "|    iterations      | 3         |\n",
      "|    time_elapsed    | 6         |\n",
      "|    total_timesteps | 6144      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 357         |\n",
      "|    ep_rew_mean          | -4.92e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 1018        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001221868 |\n",
      "|    clip_fraction        | 0.000732    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.74e+07    |\n",
      "|    n_updates            | 50890       |\n",
      "|    policy_gradient_loss | -0.00062    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 7.81e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=-2162.80 +/- 6596.65\n",
      "Episode length: 427.20 +/- 332.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 427         |\n",
      "|    mean_reward          | -2.16e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009055714 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.682       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+04    |\n",
      "|    n_updates            | 50900       |\n",
      "|    policy_gradient_loss | -0.00195    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.84e+05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 342       |\n",
      "|    ep_rew_mean     | -4.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 932       |\n",
      "|    iterations      | 5         |\n",
      "|    time_elapsed    | 10        |\n",
      "|    total_timesteps | 10240     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 307          |\n",
      "|    ep_rew_mean          | -3.69e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 956          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 12           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031196293 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.15         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.03e+06     |\n",
      "|    n_updates            | 50910        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 2.05e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 297          |\n",
      "|    ep_rew_mean          | -4.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 973          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046004998 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.15         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+07     |\n",
      "|    n_updates            | 50920        |\n",
      "|    policy_gradient_loss | -0.00726     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 6.71e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-8706.18 +/- 10674.38\n",
      "Episode length: 950.20 +/- 1367.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 950          |\n",
      "|    mean_reward          | -8.71e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 15000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024380514 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.15         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.73e+07     |\n",
      "|    n_updates            | 50930        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 2.6e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 339       |\n",
      "|    ep_rew_mean     | -4.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 865       |\n",
      "|    iterations      | 8         |\n",
      "|    time_elapsed    | 18        |\n",
      "|    total_timesteps | 16384     |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 360           |\n",
      "|    ep_rew_mean          | -4.25e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 887           |\n",
      "|    iterations           | 9             |\n",
      "|    time_elapsed         | 20            |\n",
      "|    total_timesteps      | 18432         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046189287 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.15          |\n",
      "|    explained_variance   | 0.475         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.56e+07      |\n",
      "|    n_updates            | 50940         |\n",
      "|    policy_gradient_loss | -0.000345     |\n",
      "|    std                  | 0.244         |\n",
      "|    value_loss           | 4.34e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-22140.57 +/- 30152.30\n",
      "Episode length: 561.00 +/- 603.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 561         |\n",
      "|    mean_reward          | -2.21e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005755626 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.65e+04    |\n",
      "|    n_updates            | 50950       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 3.48e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 364      |\n",
      "|    ep_rew_mean     | -4.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 853      |\n",
      "|    iterations      | 10       |\n",
      "|    time_elapsed    | 23       |\n",
      "|    total_timesteps | 20480    |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 384          |\n",
      "|    ep_rew_mean          | -3.89e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 871          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 25           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037019649 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.15         |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.82e+05     |\n",
      "|    n_updates            | 50960        |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 2.3e+06      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 384         |\n",
      "|    ep_rew_mean          | -3.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 887         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010198131 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.89e+04    |\n",
      "|    n_updates            | 50970       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.81e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=25000, episode_reward=-7622.91 +/- 11189.12\n",
      "Episode length: 449.20 +/- 338.84\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 449        |\n",
      "|    mean_reward          | -7.62e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 25000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00717491 |\n",
      "|    clip_fraction        | 0.0386     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.14       |\n",
      "|    explained_variance   | 0.837      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.99e+05   |\n",
      "|    n_updates            | 50980      |\n",
      "|    policy_gradient_loss | -0.00535   |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 1.21e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 384       |\n",
      "|    ep_rew_mean     | -3.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 868       |\n",
      "|    iterations      | 13        |\n",
      "|    time_elapsed    | 30        |\n",
      "|    total_timesteps | 26624     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 469         |\n",
      "|    ep_rew_mean          | -3.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 882         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007130116 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.14        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.49e+03    |\n",
      "|    n_updates            | 50990       |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 3.51e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-45037.13 +/- 69302.95\n",
      "Episode length: 761.00 +/- 830.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 761          |\n",
      "|    mean_reward          | -4.5e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060897693 |\n",
      "|    clip_fraction        | 0.0414       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.14         |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.29e+03     |\n",
      "|    n_updates            | 51000        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    std                  | 0.245        |\n",
      "|    value_loss           | 8.31e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 464       |\n",
      "|    ep_rew_mean     | -3.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 849       |\n",
      "|    iterations      | 15        |\n",
      "|    time_elapsed    | 36        |\n",
      "|    total_timesteps | 30720     |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 448           |\n",
      "|    ep_rew_mean          | -3.42e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 861           |\n",
      "|    iterations           | 16            |\n",
      "|    time_elapsed         | 38            |\n",
      "|    total_timesteps      | 32768         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047217077 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.14          |\n",
      "|    explained_variance   | 0.292         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.27e+07      |\n",
      "|    n_updates            | 51010         |\n",
      "|    policy_gradient_loss | -0.000732     |\n",
      "|    std                  | 0.245         |\n",
      "|    value_loss           | 1.35e+07      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 459         |\n",
      "|    ep_rew_mean          | -3.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 872         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004200431 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.14        |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+05    |\n",
      "|    n_updates            | 51020       |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 2.04e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-7358.69 +/- 6343.93\n",
      "Episode length: 125.80 +/- 151.99\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 126          |\n",
      "|    mean_reward          | -7.36e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 35000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022303513 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.14         |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.29e+06     |\n",
      "|    n_updates            | 51030        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    std                  | 0.245        |\n",
      "|    value_loss           | 3.78e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 448      |\n",
      "|    ep_rew_mean     | -3.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 875      |\n",
      "|    iterations      | 18       |\n",
      "|    time_elapsed    | 42       |\n",
      "|    total_timesteps | 36864    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 426         |\n",
      "|    ep_rew_mean          | -2.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 884         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004502484 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.14        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+05     |\n",
      "|    n_updates            | 51040       |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 5.83e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=3015.75 +/- 19481.81\n",
      "Episode length: 1608.60 +/- 1721.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.61e+03    |\n",
      "|    mean_reward          | 3.02e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014937952 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.0404      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.68e+03    |\n",
      "|    n_updates            | 51050       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 9.48e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 441       |\n",
      "|    ep_rew_mean     | -2.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 822       |\n",
      "|    iterations      | 20        |\n",
      "|    time_elapsed    | 49        |\n",
      "|    total_timesteps | 40960     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 446         |\n",
      "|    ep_rew_mean          | -2.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 832         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005132852 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.49e+07    |\n",
      "|    n_updates            | 51060       |\n",
      "|    policy_gradient_loss | -0.000843   |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.35e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-7342.75 +/- 15717.26\n",
      "Episode length: 1991.40 +/- 2058.33\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.99e+03   |\n",
      "|    mean_reward          | -7.34e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 45000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00675751 |\n",
      "|    clip_fraction        | 0.0508     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.15       |\n",
      "|    explained_variance   | 0.367      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.55e+05   |\n",
      "|    n_updates            | 51070      |\n",
      "|    policy_gradient_loss | -0.00529   |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 3.14e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 446       |\n",
      "|    ep_rew_mean     | -2.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 771       |\n",
      "|    iterations      | 22        |\n",
      "|    time_elapsed    | 58        |\n",
      "|    total_timesteps | 45056     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 473        |\n",
      "|    ep_rew_mean          | -2.79e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 780        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 60         |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00871185 |\n",
      "|    clip_fraction        | 0.089      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.15       |\n",
      "|    explained_variance   | 0.857      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.32e+03   |\n",
      "|    n_updates            | 51080      |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 1.22e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 491         |\n",
      "|    ep_rew_mean          | -2.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 790         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007778314 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.07e+03    |\n",
      "|    n_updates            | 51090       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 6.25e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-14379.23 +/- 20469.26\n",
      "Episode length: 805.00 +/- 673.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 805         |\n",
      "|    mean_reward          | -1.44e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010838669 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+04    |\n",
      "|    n_updates            | 51100       |\n",
      "|    policy_gradient_loss | -0.00713    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 8.11e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 493       |\n",
      "|    ep_rew_mean     | -2.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 775       |\n",
      "|    iterations      | 25        |\n",
      "|    time_elapsed    | 66        |\n",
      "|    total_timesteps | 51200     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 506          |\n",
      "|    ep_rew_mean          | -2.87e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 784          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 67           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068804463 |\n",
      "|    clip_fraction        | 0.0575       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+04     |\n",
      "|    n_updates            | 51110        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 1.44e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-32572.45 +/- 34312.88\n",
      "Episode length: 2148.60 +/- 2337.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.15e+03    |\n",
      "|    mean_reward          | -3.26e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 55000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001531461 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.17        |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.38e+06    |\n",
      "|    n_updates            | 51120       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 3.31e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 511       |\n",
      "|    ep_rew_mean     | -2.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 737       |\n",
      "|    iterations      | 27        |\n",
      "|    time_elapsed    | 74        |\n",
      "|    total_timesteps | 55296     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 505         |\n",
      "|    ep_rew_mean          | -2.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 745         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 76          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003559975 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.17        |\n",
      "|    explained_variance   | 0.497       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.91e+06    |\n",
      "|    n_updates            | 51130       |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 2.01e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 499         |\n",
      "|    ep_rew_mean          | -2.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 754         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 78          |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008278912 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+07    |\n",
      "|    n_updates            | 51140       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 4.19e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-455.62 +/- 6777.12\n",
      "Episode length: 618.40 +/- 506.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 618          |\n",
      "|    mean_reward          | -456         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076135304 |\n",
      "|    clip_fraction        | 0.0849       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.59e+04     |\n",
      "|    n_updates            | 51150        |\n",
      "|    policy_gradient_loss | -0.0047      |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 3.47e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 516       |\n",
      "|    ep_rew_mean     | -2.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 748       |\n",
      "|    iterations      | 30        |\n",
      "|    time_elapsed    | 82        |\n",
      "|    total_timesteps | 61440     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 531          |\n",
      "|    ep_rew_mean          | -1.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 756          |\n",
      "|    iterations           | 31           |\n",
      "|    time_elapsed         | 83           |\n",
      "|    total_timesteps      | 63488        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060332417 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.661        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+06     |\n",
      "|    n_updates            | 51160        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 1.02e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-32028.11 +/- 43603.80\n",
      "Episode length: 2167.60 +/- 2321.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.17e+03     |\n",
      "|    mean_reward          | -3.2e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 65000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052786907 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.78e+04     |\n",
      "|    n_updates            | 51170        |\n",
      "|    policy_gradient_loss | -0.00854     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 4.1e+05      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 532       |\n",
      "|    ep_rew_mean     | -2.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 32        |\n",
      "|    time_elapsed    | 91        |\n",
      "|    total_timesteps | 65536     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 558         |\n",
      "|    ep_rew_mean          | -2.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 726         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 93          |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008058259 |\n",
      "|    clip_fraction        | 0.0192      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+07    |\n",
      "|    n_updates            | 51180       |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.42e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 569         |\n",
      "|    ep_rew_mean          | -1.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 733         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 94          |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005351471 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2e+06     |\n",
      "|    n_updates            | 51190       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 6.97e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-18866.15 +/- 26067.11\n",
      "Episode length: 197.00 +/- 231.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 197          |\n",
      "|    mean_reward          | -1.89e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041516377 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.137        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+05     |\n",
      "|    n_updates            | 51200        |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 2.22e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -1.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 736       |\n",
      "|    iterations      | 35        |\n",
      "|    time_elapsed    | 97        |\n",
      "|    total_timesteps | 71680     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 606        |\n",
      "|    ep_rew_mean          | -1.46e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 743        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 99         |\n",
      "|    total_timesteps      | 73728      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01943928 |\n",
      "|    clip_fraction        | 0.107      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.16       |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.42e+03   |\n",
      "|    n_updates            | 51210      |\n",
      "|    policy_gradient_loss | -0.00579   |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 6.21e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=75000, episode_reward=1133.64 +/- 9264.59\n",
      "Episode length: 1536.00 +/- 1759.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.54e+03    |\n",
      "|    mean_reward          | 1.13e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 75000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008933416 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 51220       |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 6.46e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 611       |\n",
      "|    ep_rew_mean     | -1.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 722       |\n",
      "|    iterations      | 37        |\n",
      "|    time_elapsed    | 104       |\n",
      "|    total_timesteps | 75776     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 640         |\n",
      "|    ep_rew_mean          | -1.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 106         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011676023 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.63e+03    |\n",
      "|    n_updates            | 51230       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 7.99e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 626       |\n",
      "|    ep_rew_mean          | -1.31e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 735       |\n",
      "|    iterations           | 39        |\n",
      "|    time_elapsed         | 108       |\n",
      "|    total_timesteps      | 79872     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0134936 |\n",
      "|    clip_fraction        | 0.124     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.16      |\n",
      "|    explained_variance   | 0.979     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.39e+03  |\n",
      "|    n_updates            | 51240     |\n",
      "|    policy_gradient_loss | -0.0022   |\n",
      "|    std                  | 0.244     |\n",
      "|    value_loss           | 1.59e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=1529.61 +/- 3314.91\n",
      "Episode length: 2448.40 +/- 2123.97\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.45e+03     |\n",
      "|    mean_reward          | 1.53e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076851347 |\n",
      "|    clip_fraction        | 0.117        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.16         |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+06     |\n",
      "|    n_updates            | 51250        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 1.82e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 628       |\n",
      "|    ep_rew_mean     | -1.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 40        |\n",
      "|    time_elapsed    | 116       |\n",
      "|    total_timesteps | 81920     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 628         |\n",
      "|    ep_rew_mean          | -1.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 118         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012197287 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.5e+03     |\n",
      "|    n_updates            | 51260       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 2.96e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-59.91 +/- 6776.11\n",
      "Episode length: 907.80 +/- 429.30\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 908           |\n",
      "|    mean_reward          | -59.9         |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 85000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092811143 |\n",
      "|    clip_fraction        | 0.00547       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.16          |\n",
      "|    explained_variance   | 0.471         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.26e+04      |\n",
      "|    n_updates            | 51270         |\n",
      "|    policy_gradient_loss | -0.00199      |\n",
      "|    std                  | 0.244         |\n",
      "|    value_loss           | 2.56e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 633       |\n",
      "|    ep_rew_mean     | -1.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 42        |\n",
      "|    time_elapsed    | 122       |\n",
      "|    total_timesteps | 86016     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 663         |\n",
      "|    ep_rew_mean          | -1.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008403529 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+04    |\n",
      "|    n_updates            | 51280       |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 3.15e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-135474.06 +/- 198699.78\n",
      "Episode length: 564.60 +/- 524.32\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 565        |\n",
      "|    mean_reward          | -1.35e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 90000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00734827 |\n",
      "|    clip_fraction        | 0.034      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.17       |\n",
      "|    explained_variance   | 0.504      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.6e+06    |\n",
      "|    n_updates            | 51290      |\n",
      "|    policy_gradient_loss | -0.00286   |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 1.49e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 599       |\n",
      "|    ep_rew_mean     | -1.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 707       |\n",
      "|    iterations      | 44        |\n",
      "|    time_elapsed    | 127       |\n",
      "|    total_timesteps | 90112     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 589          |\n",
      "|    ep_rew_mean          | -1.21e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 713          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 129          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074208635 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.17         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.15e+04     |\n",
      "|    n_updates            | 51300        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    std                  | 0.244        |\n",
      "|    value_loss           | 1.31e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 589         |\n",
      "|    ep_rew_mean          | -1.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 131         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013485271 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 900         |\n",
      "|    n_updates            | 51310       |\n",
      "|    policy_gradient_loss | -2.81e-07   |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 2.65e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-862.14 +/- 3282.81\n",
      "Episode length: 509.20 +/- 359.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 509         |\n",
      "|    mean_reward          | -862        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 95000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014510302 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.17        |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 726         |\n",
      "|    n_updates            | 51320       |\n",
      "|    policy_gradient_loss | 0.00254     |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 2.62e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 631       |\n",
      "|    ep_rew_mean     | -1.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 717       |\n",
      "|    iterations      | 47        |\n",
      "|    time_elapsed    | 134       |\n",
      "|    total_timesteps | 96256     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 631         |\n",
      "|    ep_rew_mean          | -1.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008432241 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.17        |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.61e+04    |\n",
      "|    n_updates            | 51330       |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 6.63e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-14484.52 +/- 22721.16\n",
      "Episode length: 1415.00 +/- 1872.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.42e+03    |\n",
      "|    mean_reward          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009385053 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.17        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 753         |\n",
      "|    n_updates            | 51340       |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 1.97e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 680      |\n",
      "|    ep_rew_mean     | -1.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 695      |\n",
      "|    iterations      | 49       |\n",
      "|    time_elapsed    | 144      |\n",
      "|    total_timesteps | 100352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 677         |\n",
      "|    ep_rew_mean          | -1.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 698         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 146         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013032092 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.18        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 347         |\n",
      "|    n_updates            | 51350       |\n",
      "|    policy_gradient_loss | -0.00171    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 7.6e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 679          |\n",
      "|    ep_rew_mean          | -1.33e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 148          |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070191007 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.2          |\n",
      "|    explained_variance   | 0.688        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.93e+03     |\n",
      "|    n_updates            | 51360        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    std                  | 0.242        |\n",
      "|    value_loss           | 6.74e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-24633.16 +/- 36355.86\n",
      "Episode length: 133.60 +/- 152.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 134         |\n",
      "|    mean_reward          | -2.46e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 105000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009757649 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.28e+06    |\n",
      "|    n_updates            | 51370       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.43e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 679       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 705       |\n",
      "|    iterations      | 52        |\n",
      "|    time_elapsed    | 150       |\n",
      "|    total_timesteps | 106496    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 661          |\n",
      "|    ep_rew_mean          | -1.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 710          |\n",
      "|    iterations           | 53           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 108544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042057517 |\n",
      "|    clip_fraction        | 0.0686       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.2          |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.65e+05     |\n",
      "|    n_updates            | 51380        |\n",
      "|    policy_gradient_loss | 0.00306      |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 3.68e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-28268.47 +/- 29021.67\n",
      "Episode length: 2040.20 +/- 2416.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.04e+03    |\n",
      "|    mean_reward          | -2.83e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009933776 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.62e+07    |\n",
      "|    n_updates            | 51390       |\n",
      "|    policy_gradient_loss | 0.000777    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 4.16e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 606       |\n",
      "|    ep_rew_mean     | -1.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 54        |\n",
      "|    time_elapsed    | 159       |\n",
      "|    total_timesteps | 110592    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 608         |\n",
      "|    ep_rew_mean          | -1.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009375423 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+07    |\n",
      "|    n_updates            | 51400       |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 4.6e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 600        |\n",
      "|    ep_rew_mean          | -1.57e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 702        |\n",
      "|    iterations           | 56         |\n",
      "|    time_elapsed         | 163        |\n",
      "|    total_timesteps      | 114688     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01747341 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.19       |\n",
      "|    explained_variance   | 0.0541     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 920        |\n",
      "|    n_updates            | 51410      |\n",
      "|    policy_gradient_loss | -0.00137   |\n",
      "|    std                  | 0.242      |\n",
      "|    value_loss           | 6.4e+04    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-31853.65 +/- 45251.24\n",
      "Episode length: 1142.00 +/- 1938.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.14e+03    |\n",
      "|    mean_reward          | -3.19e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 115000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019660264 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.19        |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.62e+03    |\n",
      "|    n_updates            | 51420       |\n",
      "|    policy_gradient_loss | 0.00223     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.49e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 596       |\n",
      "|    ep_rew_mean     | -1.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 695       |\n",
      "|    iterations      | 57        |\n",
      "|    time_elapsed    | 167       |\n",
      "|    total_timesteps | 116736    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 579          |\n",
      "|    ep_rew_mean          | -1.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 699          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 169          |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030138458 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.19         |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+07     |\n",
      "|    n_updates            | 51430        |\n",
      "|    policy_gradient_loss | 0.000794     |\n",
      "|    std                  | 0.242        |\n",
      "|    value_loss           | 3.77e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-720.51 +/- 3221.54\n",
      "Episode length: 248.00 +/- 195.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 248         |\n",
      "|    mean_reward          | -721        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008596027 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.19        |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.21e+03    |\n",
      "|    n_updates            | 51440       |\n",
      "|    policy_gradient_loss | -0.00869    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 2.08e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 568       |\n",
      "|    ep_rew_mean     | -1.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 59        |\n",
      "|    time_elapsed    | 172       |\n",
      "|    total_timesteps | 120832    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 555         |\n",
      "|    ep_rew_mean          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 705         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 174         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026820822 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.661       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+06    |\n",
      "|    n_updates            | 51450       |\n",
      "|    policy_gradient_loss | 0.00519     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.19e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 557         |\n",
      "|    ep_rew_mean          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 709         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 175         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007971609 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.19        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+04    |\n",
      "|    n_updates            | 51460       |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 6.29e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-1545.11 +/- 4266.72\n",
      "Episode length: 308.40 +/- 266.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 308         |\n",
      "|    mean_reward          | -1.55e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 125000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013230184 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 874         |\n",
      "|    n_updates            | 51470       |\n",
      "|    policy_gradient_loss | 0.00179     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.48e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 530       |\n",
      "|    ep_rew_mean     | -1.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 711       |\n",
      "|    iterations      | 62        |\n",
      "|    time_elapsed    | 178       |\n",
      "|    total_timesteps | 126976    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 485        |\n",
      "|    ep_rew_mean          | -1.32e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 715        |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 180        |\n",
      "|    total_timesteps      | 129024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01750844 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.21       |\n",
      "|    explained_variance   | 0.87       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.4e+04    |\n",
      "|    n_updates            | 51480      |\n",
      "|    policy_gradient_loss | -0.00358   |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 6.59e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-9440.94 +/- 21190.48\n",
      "Episode length: 1362.00 +/- 1841.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.36e+03    |\n",
      "|    mean_reward          | -9.44e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010297495 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.21        |\n",
      "|    explained_variance   | -0.248      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.11e+05    |\n",
      "|    n_updates            | 51490       |\n",
      "|    policy_gradient_loss | 0.000943    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.1e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 479       |\n",
      "|    ep_rew_mean     | -1.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 706       |\n",
      "|    iterations      | 64        |\n",
      "|    time_elapsed    | 185       |\n",
      "|    total_timesteps | 131072    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 479         |\n",
      "|    ep_rew_mean          | -1.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 710         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 187         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026481712 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.21        |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 318         |\n",
      "|    n_updates            | 51500       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-6563.64 +/- 4064.70\n",
      "Episode length: 142.00 +/- 122.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 142         |\n",
      "|    mean_reward          | -6.56e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 135000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017620688 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.21        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 566         |\n",
      "|    n_updates            | 51510       |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 524       |\n",
      "|    ep_rew_mean     | -1.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 712       |\n",
      "|    iterations      | 66        |\n",
      "|    time_elapsed    | 189       |\n",
      "|    total_timesteps | 135168    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 484         |\n",
      "|    ep_rew_mean          | -1.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 716         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 191         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009554199 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 678         |\n",
      "|    n_updates            | 51520       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 1.14e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 490          |\n",
      "|    ep_rew_mean          | -1.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 193          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066590663 |\n",
      "|    clip_fraction        | 0.0739       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.2          |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.07e+05     |\n",
      "|    n_updates            | 51530        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    std                  | 0.243        |\n",
      "|    value_loss           | 1.93e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=140000, episode_reward=-4049.14 +/- 11871.18\n",
      "Episode length: 458.60 +/- 572.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 459         |\n",
      "|    mean_reward          | -4.05e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021435494 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.06e+05    |\n",
      "|    n_updates            | 51540       |\n",
      "|    policy_gradient_loss | 0.00474     |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 1.4e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 403       |\n",
      "|    ep_rew_mean     | -1.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 720       |\n",
      "|    iterations      | 69        |\n",
      "|    time_elapsed    | 196       |\n",
      "|    total_timesteps | 141312    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 404          |\n",
      "|    ep_rew_mean          | -1.23e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 723          |\n",
      "|    iterations           | 70           |\n",
      "|    time_elapsed         | 198          |\n",
      "|    total_timesteps      | 143360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030972725 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.2          |\n",
      "|    explained_variance   | 0.703        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.11e+05     |\n",
      "|    n_updates            | 51550        |\n",
      "|    policy_gradient_loss | 0.00331      |\n",
      "|    std                  | 0.243        |\n",
      "|    value_loss           | 2.65e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-34695.46 +/- 39779.41\n",
      "Episode length: 2242.80 +/- 2272.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.24e+03    |\n",
      "|    mean_reward          | -3.47e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 145000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008948126 |\n",
      "|    clip_fraction        | 0.0846      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 906         |\n",
      "|    n_updates            | 51560       |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 3.17e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 405       |\n",
      "|    ep_rew_mean     | -1.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 708       |\n",
      "|    iterations      | 71        |\n",
      "|    time_elapsed    | 205       |\n",
      "|    total_timesteps | 145408    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 416         |\n",
      "|    ep_rew_mean          | -1.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 711         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 207         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004200824 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.21        |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+05    |\n",
      "|    n_updates            | 51570       |\n",
      "|    policy_gradient_loss | -0.000939   |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.93e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 422         |\n",
      "|    ep_rew_mean          | -1.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 209         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008386472 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.21        |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 865         |\n",
      "|    n_updates            | 51580       |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.19e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-24261.23 +/- 58511.31\n",
      "Episode length: 509.80 +/- 216.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 510         |\n",
      "|    mean_reward          | -2.43e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011498766 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.41e+03    |\n",
      "|    n_updates            | 51590       |\n",
      "|    policy_gradient_loss | 0.000261    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 4.38e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 434       |\n",
      "|    ep_rew_mean     | -9.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 714       |\n",
      "|    iterations      | 74        |\n",
      "|    time_elapsed    | 212       |\n",
      "|    total_timesteps | 151552    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 443         |\n",
      "|    ep_rew_mean          | -9.68e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 213         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008010402 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.09e+03    |\n",
      "|    n_updates            | 51600       |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 6.76e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-53328.79 +/- 64699.30\n",
      "Episode length: 306.20 +/- 243.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 306         |\n",
      "|    mean_reward          | -5.33e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 155000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005144427 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.91e+04    |\n",
      "|    n_updates            | 51610       |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.21e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 456      |\n",
      "|    ep_rew_mean     | -1e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 718      |\n",
      "|    iterations      | 76       |\n",
      "|    time_elapsed    | 216      |\n",
      "|    total_timesteps | 155648   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 446          |\n",
      "|    ep_rew_mean          | -1.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 721          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024101543 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.7e+07      |\n",
      "|    n_updates            | 51620        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 3.56e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 466       |\n",
      "|    ep_rew_mean          | -1.33e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 724       |\n",
      "|    iterations           | 78        |\n",
      "|    time_elapsed         | 220       |\n",
      "|    total_timesteps      | 159744    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0041451 |\n",
      "|    clip_fraction        | 0.0253    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.22      |\n",
      "|    explained_variance   | 0.604     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.44e+05  |\n",
      "|    n_updates            | 51630     |\n",
      "|    policy_gradient_loss | -0.00266  |\n",
      "|    std                  | 0.241     |\n",
      "|    value_loss           | 6.14e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=5423.60 +/- 12476.05\n",
      "Episode length: 1352.20 +/- 1832.72\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.35e+03      |\n",
      "|    mean_reward          | 5.42e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 160000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050687016 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.22          |\n",
      "|    explained_variance   | 0.435         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.7e+06       |\n",
      "|    n_updates            | 51640         |\n",
      "|    policy_gradient_loss | -0.000526     |\n",
      "|    std                  | 0.241         |\n",
      "|    value_loss           | 6.37e+07      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 470       |\n",
      "|    ep_rew_mean     | -1.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 717       |\n",
      "|    iterations      | 79        |\n",
      "|    time_elapsed    | 225       |\n",
      "|    total_timesteps | 161792    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 473          |\n",
      "|    ep_rew_mean          | -1.74e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013137355 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.98e+07     |\n",
      "|    n_updates            | 51650        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 7.65e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-414.33 +/- 9807.53\n",
      "Episode length: 421.80 +/- 344.34\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 422          |\n",
      "|    mean_reward          | -414         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 165000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035425844 |\n",
      "|    clip_fraction        | 0.0415       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.48e+03     |\n",
      "|    n_updates            | 51660        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 3.71e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 479       |\n",
      "|    ep_rew_mean     | -1.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 720       |\n",
      "|    iterations      | 81        |\n",
      "|    time_elapsed    | 230       |\n",
      "|    total_timesteps | 165888    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 491         |\n",
      "|    ep_rew_mean          | -1.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 232         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013506123 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+03    |\n",
      "|    n_updates            | 51670       |\n",
      "|    policy_gradient_loss | 0.00408     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 5.93e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 481         |\n",
      "|    ep_rew_mean          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 726         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 233         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006474639 |\n",
      "|    clip_fraction        | 0.0857      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.205       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.32e+04    |\n",
      "|    n_updates            | 51680       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 9.24e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=3784.98 +/- 14011.48\n",
      "Episode length: 1470.40 +/- 1766.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.47e+03     |\n",
      "|    mean_reward          | 3.78e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 170000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023851474 |\n",
      "|    clip_fraction        | 0.00825      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.11e+07     |\n",
      "|    n_updates            | 51690        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 6.45e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 466       |\n",
      "|    ep_rew_mean     | -1.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 84        |\n",
      "|    time_elapsed    | 239       |\n",
      "|    total_timesteps | 172032    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 470         |\n",
      "|    ep_rew_mean          | -2.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007356544 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8e+06     |\n",
      "|    n_updates            | 51700       |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.65e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=6428.24 +/- 12686.90\n",
      "Episode length: 1177.00 +/- 1923.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.18e+03    |\n",
      "|    mean_reward          | 6.43e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 175000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005130642 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.26e+07    |\n",
      "|    n_updates            | 51710       |\n",
      "|    policy_gradient_loss | 4.47e-05    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 4.15e+07    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 472       |\n",
      "|    ep_rew_mean     | -2.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 716       |\n",
      "|    iterations      | 86        |\n",
      "|    time_elapsed    | 245       |\n",
      "|    total_timesteps | 176128    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 482         |\n",
      "|    ep_rew_mean          | -2.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 718         |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 247         |\n",
      "|    total_timesteps      | 178176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004187262 |\n",
      "|    clip_fraction        | 0.00635     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.82e+06    |\n",
      "|    n_updates            | 51720       |\n",
      "|    policy_gradient_loss | -0.000258   |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 1.46e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=1339.37 +/- 4276.09\n",
      "Episode length: 503.80 +/- 288.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 504         |\n",
      "|    mean_reward          | 1.34e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006165909 |\n",
      "|    clip_fraction        | 0.03        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.7e+03     |\n",
      "|    n_updates            | 51730       |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 6.82e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 507       |\n",
      "|    ep_rew_mean     | -3.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 88        |\n",
      "|    time_elapsed    | 250       |\n",
      "|    total_timesteps | 180224    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 457          |\n",
      "|    ep_rew_mean          | -3.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 721          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 252          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032170406 |\n",
      "|    clip_fraction        | 0.00283      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.24e+07     |\n",
      "|    n_updates            | 51740        |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    std                  | 0.242        |\n",
      "|    value_loss           | 1.76e+08     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 473         |\n",
      "|    ep_rew_mean          | -3.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 254         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005422717 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 51750       |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 2.26e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-3101.79 +/- 11202.13\n",
      "Episode length: 1265.00 +/- 1888.92\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.26e+03  |\n",
      "|    mean_reward          | -3.1e+03  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 185000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0154611 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.22      |\n",
      "|    explained_variance   | 0.869     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.67e+04  |\n",
      "|    n_updates            | 51760     |\n",
      "|    policy_gradient_loss | 0.002     |\n",
      "|    std                  | 0.242     |\n",
      "|    value_loss           | 2.19e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 475       |\n",
      "|    ep_rew_mean     | -3.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 91        |\n",
      "|    time_elapsed    | 259       |\n",
      "|    total_timesteps | 186368    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 462         |\n",
      "|    ep_rew_mean          | -3.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003149767 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.593       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13e+06    |\n",
      "|    n_updates            | 51770       |\n",
      "|    policy_gradient_loss | 0.00204     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 5.07e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=190000, episode_reward=-268.84 +/- 10994.34\n",
      "Episode length: 1383.60 +/- 1857.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.38e+03    |\n",
      "|    mean_reward          | -269        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008993267 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6e+03     |\n",
      "|    n_updates            | 51780       |\n",
      "|    policy_gradient_loss | 0.000638    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.36e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 457       |\n",
      "|    ep_rew_mean     | -3.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 714       |\n",
      "|    iterations      | 93        |\n",
      "|    time_elapsed    | 266       |\n",
      "|    total_timesteps | 190464    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 436         |\n",
      "|    ep_rew_mean          | -3.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 268         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010764606 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55e+07    |\n",
      "|    n_updates            | 51790       |\n",
      "|    policy_gradient_loss | 0.00573     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.74e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 417         |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 270         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008847908 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.6e+03     |\n",
      "|    n_updates            | 51800       |\n",
      "|    policy_gradient_loss | 0.00155     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 5.74e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=595.25 +/- 1413.61\n",
      "Episode length: 528.00 +/- 115.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 528          |\n",
      "|    mean_reward          | 595          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 195000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041284394 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.23         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.7e+05      |\n",
      "|    n_updates            | 51810        |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 5.16e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 410       |\n",
      "|    ep_rew_mean     | -3.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 719       |\n",
      "|    iterations      | 96        |\n",
      "|    time_elapsed    | 273       |\n",
      "|    total_timesteps | 196608    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 374         |\n",
      "|    ep_rew_mean          | -2.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 275         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008247204 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.6e+06     |\n",
      "|    n_updates            | 51820       |\n",
      "|    policy_gradient_loss | -0.000966   |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.08e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-12764.51 +/- 16029.83\n",
      "Episode length: 1015.80 +/- 1233.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | -1.28e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003161013 |\n",
      "|    clip_fraction        | 0.00972     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.51        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+05    |\n",
      "|    n_updates            | 51830       |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.45e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 357       |\n",
      "|    ep_rew_mean     | -2.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 98        |\n",
      "|    time_elapsed    | 279       |\n",
      "|    total_timesteps | 200704    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | -2.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006002509 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.108       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.76e+03    |\n",
      "|    n_updates            | 51840       |\n",
      "|    policy_gradient_loss | -0.00154    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 7.09e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 362         |\n",
      "|    ep_rew_mean          | -2.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 723         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 283         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016678609 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+03    |\n",
      "|    n_updates            | 51850       |\n",
      "|    policy_gradient_loss | -0.000602   |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.1e+05     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=205000, episode_reward=-7209.21 +/- 9088.39\n",
      "Episode length: 1298.20 +/- 1873.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.3e+03     |\n",
      "|    mean_reward          | -7.21e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 205000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005842621 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.25e+04    |\n",
      "|    n_updates            | 51860       |\n",
      "|    policy_gradient_loss | 0.000708    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.6e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 374       |\n",
      "|    ep_rew_mean     | -2.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 718       |\n",
      "|    iterations      | 101       |\n",
      "|    time_elapsed    | 288       |\n",
      "|    total_timesteps | 206848    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 348         |\n",
      "|    ep_rew_mean          | -2.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 720         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 289         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010370729 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+07    |\n",
      "|    n_updates            | 51870       |\n",
      "|    policy_gradient_loss | 0.000603    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 4.62e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-24414.89 +/- 40207.86\n",
      "Episode length: 254.40 +/- 300.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 254          |\n",
      "|    mean_reward          | -2.44e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 210000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022779368 |\n",
      "|    clip_fraction        | 0.0315       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.23         |\n",
      "|    explained_variance   | 0.473        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.97e+07     |\n",
      "|    n_updates            | 51880        |\n",
      "|    policy_gradient_loss | 0.002        |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 5.1e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 299       |\n",
      "|    ep_rew_mean     | -1.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 721       |\n",
      "|    iterations      | 103       |\n",
      "|    time_elapsed    | 292       |\n",
      "|    total_timesteps | 210944    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 297          |\n",
      "|    ep_rew_mean          | -1.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 723          |\n",
      "|    iterations           | 104          |\n",
      "|    time_elapsed         | 294          |\n",
      "|    total_timesteps      | 212992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037109423 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.23         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.71e+06     |\n",
      "|    n_updates            | 51890        |\n",
      "|    policy_gradient_loss | -0.00235     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 1.8e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=-1295.45 +/- 1595.57\n",
      "Episode length: 501.00 +/- 208.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 501         |\n",
      "|    mean_reward          | -1.3e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 215000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011908701 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 51900       |\n",
      "|    policy_gradient_loss | 5.05e-05    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.93e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 286       |\n",
      "|    ep_rew_mean     | -1.61e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 723       |\n",
      "|    iterations      | 105       |\n",
      "|    time_elapsed    | 297       |\n",
      "|    total_timesteps | 215040    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 301         |\n",
      "|    ep_rew_mean          | -1.61e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 299         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017070675 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.33e+04    |\n",
      "|    n_updates            | 51910       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 7.15e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 308         |\n",
      "|    ep_rew_mean          | -1.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 301         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011692988 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 51920       |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.99e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-1033.93 +/- 3594.14\n",
      "Episode length: 308.20 +/- 173.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 308         |\n",
      "|    mean_reward          | -1.03e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 220000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017540697 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 51930       |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 9.38e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 306       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 728       |\n",
      "|    iterations      | 108       |\n",
      "|    time_elapsed    | 303       |\n",
      "|    total_timesteps | 221184    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 316         |\n",
      "|    ep_rew_mean          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010437475 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.75e+05    |\n",
      "|    n_updates            | 51940       |\n",
      "|    policy_gradient_loss | 0.00102     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 7.27e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=1801.41 +/- 3837.75\n",
      "Episode length: 494.40 +/- 203.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 494         |\n",
      "|    mean_reward          | 1.8e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 225000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009758802 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.23        |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34e+03    |\n",
      "|    n_updates            | 51950       |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 3.57e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 322       |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 730       |\n",
      "|    iterations      | 110       |\n",
      "|    time_elapsed    | 308       |\n",
      "|    total_timesteps | 225280    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 319         |\n",
      "|    ep_rew_mean          | -1.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 732         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016558269 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.46e+05    |\n",
      "|    n_updates            | 51960       |\n",
      "|    policy_gradient_loss | 0.00676     |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 1.92e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 325        |\n",
      "|    ep_rew_mean          | -1.29e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 734        |\n",
      "|    iterations           | 112        |\n",
      "|    time_elapsed         | 312        |\n",
      "|    total_timesteps      | 229376     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01036343 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.24       |\n",
      "|    explained_variance   | 0.87       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.42e+03   |\n",
      "|    n_updates            | 51970      |\n",
      "|    policy_gradient_loss | -0.00511   |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 1.47e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-23655.36 +/- 48127.84\n",
      "Episode length: 280.00 +/- 189.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 280         |\n",
      "|    mean_reward          | -2.37e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004227139 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.37e+03    |\n",
      "|    n_updates            | 51980       |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 1.4e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 337       |\n",
      "|    ep_rew_mean     | -1.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 735       |\n",
      "|    iterations      | 113       |\n",
      "|    time_elapsed    | 314       |\n",
      "|    total_timesteps | 231424    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | -1.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 737         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005773442 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.52e+03    |\n",
      "|    n_updates            | 51990       |\n",
      "|    policy_gradient_loss | -0.000664   |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 2.4e+05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=-14709.30 +/- 5682.33\n",
      "Episode length: 105.20 +/- 181.97\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 105          |\n",
      "|    mean_reward          | -1.47e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 235000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076386635 |\n",
      "|    clip_fraction        | 0.0939       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 52000        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 6.92e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 359       |\n",
      "|    ep_rew_mean     | -1.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 738       |\n",
      "|    iterations      | 115       |\n",
      "|    time_elapsed    | 318       |\n",
      "|    total_timesteps | 235520    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 364          |\n",
      "|    ep_rew_mean          | -1.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 741          |\n",
      "|    iterations           | 116          |\n",
      "|    time_elapsed         | 320          |\n",
      "|    total_timesteps      | 237568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016268613 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.98e+06     |\n",
      "|    n_updates            | 52010        |\n",
      "|    policy_gradient_loss | 0.000335     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 8.37e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 371          |\n",
      "|    ep_rew_mean          | -1.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 743          |\n",
      "|    iterations           | 117          |\n",
      "|    time_elapsed         | 322          |\n",
      "|    total_timesteps      | 239616       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072961543 |\n",
      "|    clip_fraction        | 0.0611       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.53e+03     |\n",
      "|    n_updates            | 52020        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 6.26e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-29685.84 +/- 79154.17\n",
      "Episode length: 1413.60 +/- 1822.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.41e+03     |\n",
      "|    mean_reward          | -2.97e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 240000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058097374 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+07     |\n",
      "|    n_updates            | 52030        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 3.65e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 360       |\n",
      "|    ep_rew_mean     | -1.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 737       |\n",
      "|    iterations      | 118       |\n",
      "|    time_elapsed    | 327       |\n",
      "|    total_timesteps | 241664    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | -1.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 739         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 329         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011913693 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.512       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.67e+03    |\n",
      "|    n_updates            | 52040       |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 2.49e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=-5931.00 +/- 15557.35\n",
      "Episode length: 349.20 +/- 387.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 349         |\n",
      "|    mean_reward          | -5.93e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 245000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008613452 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.9e+06     |\n",
      "|    n_updates            | 52050       |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 4.12e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 378       |\n",
      "|    ep_rew_mean     | -1.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 739       |\n",
      "|    iterations      | 120       |\n",
      "|    time_elapsed    | 332       |\n",
      "|    total_timesteps | 245760    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 400          |\n",
      "|    ep_rew_mean          | -1.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 741          |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 334          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035152435 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05e+07     |\n",
      "|    n_updates            | 52060        |\n",
      "|    policy_gradient_loss | -0.00204     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 4.18e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 404         |\n",
      "|    ep_rew_mean          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 743         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 336         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005241379 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.06e+07    |\n",
      "|    n_updates            | 52070       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 7.37e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-3192.21 +/- 6484.42\n",
      "Episode length: 537.80 +/- 285.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 538          |\n",
      "|    mean_reward          | -3.19e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 250000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038701757 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.717        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.44e+06     |\n",
      "|    n_updates            | 52080        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.24         |\n",
      "|    value_loss           | 9.66e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 423       |\n",
      "|    ep_rew_mean     | -1.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 742       |\n",
      "|    iterations      | 123       |\n",
      "|    time_elapsed    | 339       |\n",
      "|    total_timesteps | 251904    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 432         |\n",
      "|    ep_rew_mean          | -1.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 744         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012411429 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.461       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.07e+07    |\n",
      "|    n_updates            | 52090       |\n",
      "|    policy_gradient_loss | -0.000546   |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 8.48e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=255000, episode_reward=3625.43 +/- 5400.42\n",
      "Episode length: 478.40 +/- 431.13\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 478        |\n",
      "|    mean_reward          | 3.63e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 255000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01096973 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.25       |\n",
      "|    explained_variance   | 0.704      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.94e+03   |\n",
      "|    n_updates            | 52100      |\n",
      "|    policy_gradient_loss | -0.000153  |\n",
      "|    std                  | 0.239      |\n",
      "|    value_loss           | 2.31e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 444       |\n",
      "|    ep_rew_mean     | -1.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 743       |\n",
      "|    iterations      | 125       |\n",
      "|    time_elapsed    | 344       |\n",
      "|    total_timesteps | 256000    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 443         |\n",
      "|    ep_rew_mean          | -1.84e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 745         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 345         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022885697 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69e+03    |\n",
      "|    n_updates            | 52110       |\n",
      "|    policy_gradient_loss | 0.000565    |\n",
      "|    std                  | 0.239       |\n",
      "|    value_loss           | 1.25e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=2036.11 +/- 8591.44\n",
      "Episode length: 829.80 +/- 871.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 830         |\n",
      "|    mean_reward          | 2.04e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015493988 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 52120       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 4.68e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 452       |\n",
      "|    ep_rew_mean     | -1.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 743       |\n",
      "|    iterations      | 127       |\n",
      "|    time_elapsed    | 349       |\n",
      "|    total_timesteps | 260096    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 444         |\n",
      "|    ep_rew_mean          | -1.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 745         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 351         |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007226811 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+04    |\n",
      "|    n_updates            | 52130       |\n",
      "|    policy_gradient_loss | 0.000791    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 6.96e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 447        |\n",
      "|    ep_rew_mean          | -2e+04     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 747        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 353        |\n",
      "|    total_timesteps      | 264192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01082121 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.24       |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.34e+03   |\n",
      "|    n_updates            | 52140      |\n",
      "|    policy_gradient_loss | 0.01       |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 1.54e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=-10767.15 +/- 23642.69\n",
      "Episode length: 520.40 +/- 293.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 520         |\n",
      "|    mean_reward          | -1.08e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 265000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003816389 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+06    |\n",
      "|    n_updates            | 52150       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 2.74e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 439       |\n",
      "|    ep_rew_mean     | -1.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 746       |\n",
      "|    iterations      | 130       |\n",
      "|    time_elapsed    | 356       |\n",
      "|    total_timesteps | 266240    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 445         |\n",
      "|    ep_rew_mean          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 748         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012370937 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 52160       |\n",
      "|    policy_gradient_loss | 0.000384    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.65e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-22322.72 +/- 59539.31\n",
      "Episode length: 902.20 +/- 566.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 902         |\n",
      "|    mean_reward          | -2.23e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011347504 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.26e+03    |\n",
      "|    n_updates            | 52170       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.66e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 450       |\n",
      "|    ep_rew_mean     | -1.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 745       |\n",
      "|    iterations      | 132       |\n",
      "|    time_elapsed    | 362       |\n",
      "|    total_timesteps | 270336    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 472          |\n",
      "|    ep_rew_mean          | -2.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 747          |\n",
      "|    iterations           | 133          |\n",
      "|    time_elapsed         | 364          |\n",
      "|    total_timesteps      | 272384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067868503 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.24         |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.56e+03     |\n",
      "|    n_updates            | 52180        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 1.85e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 482          |\n",
      "|    ep_rew_mean          | -2.4e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 749          |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 366          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014026609 |\n",
      "|    clip_fraction        | 0.00171      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.24         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.93e+06     |\n",
      "|    n_updates            | 52190        |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 2.14e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=-58812.89 +/- 44501.64\n",
      "Episode length: 437.60 +/- 501.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 438          |\n",
      "|    mean_reward          | -5.88e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 275000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059156255 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.24         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.19e+07     |\n",
      "|    n_updates            | 52200        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 6.05e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 482      |\n",
      "|    ep_rew_mean     | -2.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 748      |\n",
      "|    iterations      | 135      |\n",
      "|    time_elapsed    | 369      |\n",
      "|    total_timesteps | 276480   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 482         |\n",
      "|    ep_rew_mean          | -2.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 750         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 370         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014493738 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 879         |\n",
      "|    n_updates            | 52210       |\n",
      "|    policy_gradient_loss | 0.000591    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.82e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-91148.99 +/- 158583.12\n",
      "Episode length: 998.60 +/- 1520.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 999         |\n",
      "|    mean_reward          | -9.11e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014317092 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.9e+03     |\n",
      "|    n_updates            | 52220       |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 5.61e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 534       |\n",
      "|    ep_rew_mean     | -2.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 747       |\n",
      "|    iterations      | 137       |\n",
      "|    time_elapsed    | 375       |\n",
      "|    total_timesteps | 280576    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 535          |\n",
      "|    ep_rew_mean          | -2.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 749          |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 377          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043228446 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.72e+07     |\n",
      "|    n_updates            | 52230        |\n",
      "|    policy_gradient_loss | -0.00147     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 1.88e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 541          |\n",
      "|    ep_rew_mean          | -2.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 751          |\n",
      "|    iterations           | 139          |\n",
      "|    time_elapsed         | 378          |\n",
      "|    total_timesteps      | 284672       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015965865 |\n",
      "|    clip_fraction        | 0.00371      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21e+06     |\n",
      "|    n_updates            | 52240        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 5.09e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=-19111.85 +/- 22511.85\n",
      "Episode length: 494.40 +/- 380.15\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 494        |\n",
      "|    mean_reward          | -1.91e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 285000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00637603 |\n",
      "|    clip_fraction        | 0.0331     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.25       |\n",
      "|    explained_variance   | 0.915      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.22e+03   |\n",
      "|    n_updates            | 52250      |\n",
      "|    policy_gradient_loss | -0.00167   |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 8.52e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 537       |\n",
      "|    ep_rew_mean     | -2.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 750       |\n",
      "|    iterations      | 140       |\n",
      "|    time_elapsed    | 381       |\n",
      "|    total_timesteps | 286720    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 515         |\n",
      "|    ep_rew_mean          | -2.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 752         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 383         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004668073 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.721       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.82e+03    |\n",
      "|    n_updates            | 52260       |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.3e+06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=13134.58 +/- 17177.07\n",
      "Episode length: 1399.20 +/- 1820.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4e+03      |\n",
      "|    mean_reward          | 1.31e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 290000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058302423 |\n",
      "|    clip_fraction        | 0.0386       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.85e+06     |\n",
      "|    n_updates            | 52270        |\n",
      "|    policy_gradient_loss | -0.00574     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 5.77e+06     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 501       |\n",
      "|    ep_rew_mean     | -2.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 747       |\n",
      "|    iterations      | 142       |\n",
      "|    time_elapsed    | 389       |\n",
      "|    total_timesteps | 290816    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 513         |\n",
      "|    ep_rew_mean          | -2.6e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 749         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 390         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009150239 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.46e+03    |\n",
      "|    n_updates            | 52280       |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.96e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 509          |\n",
      "|    ep_rew_mean          | -2.68e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 750          |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 392          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047942875 |\n",
      "|    clip_fraction        | 0.0534       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+07     |\n",
      "|    n_updates            | 52290        |\n",
      "|    policy_gradient_loss | -0.00342     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 4.36e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=6364.08 +/- 5852.45\n",
      "Episode length: 824.20 +/- 368.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 824          |\n",
      "|    mean_reward          | 6.36e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 295000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025213165 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.46e+06     |\n",
      "|    n_updates            | 52300        |\n",
      "|    policy_gradient_loss | -0.000638    |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 9.63e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 509       |\n",
      "|    ep_rew_mean     | -2.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 748       |\n",
      "|    iterations      | 145       |\n",
      "|    time_elapsed    | 396       |\n",
      "|    total_timesteps | 296960    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 557         |\n",
      "|    ep_rew_mean          | -3.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 750         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 398         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009203045 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 52310       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 5.35e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=10383.56 +/- 17542.90\n",
      "Episode length: 2009.40 +/- 1774.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.01e+03     |\n",
      "|    mean_reward          | 1.04e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016136845 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.02e+07     |\n",
      "|    n_updates            | 52320        |\n",
      "|    policy_gradient_loss | 0.000588     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 9.02e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 557       |\n",
      "|    ep_rew_mean     | -3.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 742       |\n",
      "|    iterations      | 147       |\n",
      "|    time_elapsed    | 405       |\n",
      "|    total_timesteps | 301056    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 557        |\n",
      "|    ep_rew_mean          | -3.06e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 743        |\n",
      "|    iterations           | 148        |\n",
      "|    time_elapsed         | 407        |\n",
      "|    total_timesteps      | 303104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01336276 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.27       |\n",
      "|    explained_variance   | 0.913      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 642        |\n",
      "|    n_updates            | 52330      |\n",
      "|    policy_gradient_loss | -0.00163   |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 3.21e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=305000, episode_reward=-105973.37 +/- 174703.49\n",
      "Episode length: 417.60 +/- 360.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 418         |\n",
      "|    mean_reward          | -1.06e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 305000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012193739 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.27        |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 551         |\n",
      "|    n_updates            | 52340       |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 583       |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 742       |\n",
      "|    iterations      | 149       |\n",
      "|    time_elapsed    | 410       |\n",
      "|    total_timesteps | 305152    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 585         |\n",
      "|    ep_rew_mean          | -2.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 744         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 412         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007237705 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.5e+07     |\n",
      "|    n_updates            | 52350       |\n",
      "|    policy_gradient_loss | 0.00206     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 6.71e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 583          |\n",
      "|    ep_rew_mean          | -2.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 745          |\n",
      "|    iterations           | 151          |\n",
      "|    time_elapsed         | 414          |\n",
      "|    total_timesteps      | 309248       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026251674 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.56e+05     |\n",
      "|    n_updates            | 52360        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 8.1e+05      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-78392.38 +/- 153544.48\n",
      "Episode length: 564.60 +/- 279.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 565         |\n",
      "|    mean_reward          | -7.84e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004026226 |\n",
      "|    clip_fraction        | 0.012       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+06    |\n",
      "|    n_updates            | 52370       |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 9.22e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 574       |\n",
      "|    ep_rew_mean     | -2.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 742       |\n",
      "|    iterations      | 152       |\n",
      "|    time_elapsed    | 419       |\n",
      "|    total_timesteps | 311296    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 567         |\n",
      "|    ep_rew_mean          | -2.61e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 744         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002710522 |\n",
      "|    clip_fraction        | 0.0063      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+07    |\n",
      "|    n_updates            | 52380       |\n",
      "|    policy_gradient_loss | -0.00357    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.43e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=-79049.63 +/- 159452.40\n",
      "Episode length: 1601.20 +/- 1712.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6e+03      |\n",
      "|    mean_reward          | -7.9e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 315000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010435916 |\n",
      "|    clip_fraction        | 0.00083      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.1e+06      |\n",
      "|    n_updates            | 52390        |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 6.1e+06      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 569       |\n",
      "|    ep_rew_mean     | -2.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 738       |\n",
      "|    iterations      | 154       |\n",
      "|    time_elapsed    | 427       |\n",
      "|    total_timesteps | 315392    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 563        |\n",
      "|    ep_rew_mean          | -2.82e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 740        |\n",
      "|    iterations           | 155        |\n",
      "|    time_elapsed         | 428        |\n",
      "|    total_timesteps      | 317440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00553888 |\n",
      "|    clip_fraction        | 0.0201     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.26       |\n",
      "|    explained_variance   | 0.861      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.78e+05   |\n",
      "|    n_updates            | 52400      |\n",
      "|    policy_gradient_loss | -0.0047    |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 1.3e+06    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 572          |\n",
      "|    ep_rew_mean          | -2.83e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 741          |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 430          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017966958 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.77e+07     |\n",
      "|    n_updates            | 52410        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 2.73e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=320000, episode_reward=-61621.53 +/- 95344.16\n",
      "Episode length: 1649.00 +/- 1887.63\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.65e+03     |\n",
      "|    mean_reward          | -6.16e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028975792 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.69e+07     |\n",
      "|    n_updates            | 52420        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 8.47e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -3.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 736       |\n",
      "|    iterations      | 157       |\n",
      "|    time_elapsed    | 436       |\n",
      "|    total_timesteps | 321536    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 591         |\n",
      "|    ep_rew_mean          | -3.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 737         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 438         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002881608 |\n",
      "|    clip_fraction        | 0.00547     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.26        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.23e+04    |\n",
      "|    n_updates            | 52430       |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 4.06e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=23312.69 +/- 22924.87\n",
      "Episode length: 2689.60 +/- 1987.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.69e+03     |\n",
      "|    mean_reward          | 2.33e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 325000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026006126 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.26         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.47e+05     |\n",
      "|    n_updates            | 52440        |\n",
      "|    policy_gradient_loss | -0.00111     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 7.1e+05      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 591       |\n",
      "|    ep_rew_mean     | -3.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 728       |\n",
      "|    iterations      | 159       |\n",
      "|    time_elapsed    | 446       |\n",
      "|    total_timesteps | 325632    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 633         |\n",
      "|    ep_rew_mean          | -3.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 448         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016688006 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 346         |\n",
      "|    n_updates            | 52450       |\n",
      "|    policy_gradient_loss | 0.000958    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 640        |\n",
      "|    ep_rew_mean          | -3.56e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 731        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 450        |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00485071 |\n",
      "|    clip_fraction        | 0.0466     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.24       |\n",
      "|    explained_variance   | 0.453      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.78e+07   |\n",
      "|    n_updates            | 52460      |\n",
      "|    policy_gradient_loss | -0.000206  |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 8.21e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-73942.56 +/- 183643.78\n",
      "Episode length: 2614.20 +/- 1877.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.61e+03     |\n",
      "|    mean_reward          | -7.39e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 330000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069864755 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.25         |\n",
      "|    explained_variance   | 0.77         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.1e+04      |\n",
      "|    n_updates            | 52470        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 4.69e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 640       |\n",
      "|    ep_rew_mean     | -3.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 723       |\n",
      "|    iterations      | 162       |\n",
      "|    time_elapsed    | 458       |\n",
      "|    total_timesteps | 331776    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 640         |\n",
      "|    ep_rew_mean          | -3.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 460         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010607265 |\n",
      "|    clip_fraction        | 0.0756      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.77e+03    |\n",
      "|    n_updates            | 52480       |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.71e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=-86596.70 +/- 161470.65\n",
      "Episode length: 1074.40 +/- 1394.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.07e+03    |\n",
      "|    mean_reward          | -8.66e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 335000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022996316 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 323         |\n",
      "|    n_updates            | 52490       |\n",
      "|    policy_gradient_loss | 0.0078      |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 741         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 685       |\n",
      "|    ep_rew_mean     | -3.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 722       |\n",
      "|    iterations      | 164       |\n",
      "|    time_elapsed    | 465       |\n",
      "|    total_timesteps | 335872    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 684        |\n",
      "|    ep_rew_mean          | -3.54e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 723        |\n",
      "|    iterations           | 165        |\n",
      "|    time_elapsed         | 466        |\n",
      "|    total_timesteps      | 337920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01099241 |\n",
      "|    clip_fraction        | 0.0924     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.25       |\n",
      "|    explained_variance   | 0.8        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.68e+03   |\n",
      "|    n_updates            | 52500      |\n",
      "|    policy_gradient_loss | -0.00446   |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 1.37e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 684         |\n",
      "|    ep_rew_mean          | -3.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 468         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005808899 |\n",
      "|    clip_fraction        | 0.0835      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 52510       |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.42e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-10412.78 +/- 59599.51\n",
      "Episode length: 1580.20 +/- 1822.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.58e+03    |\n",
      "|    mean_reward          | -1.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005520586 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+03    |\n",
      "|    n_updates            | 52520       |\n",
      "|    policy_gradient_loss | -0.00337    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.27e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 706       |\n",
      "|    ep_rew_mean     | -3.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 720       |\n",
      "|    iterations      | 167       |\n",
      "|    time_elapsed    | 474       |\n",
      "|    total_timesteps | 342016    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 723         |\n",
      "|    ep_rew_mean          | -3.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 722         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004078266 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.32e+07    |\n",
      "|    n_updates            | 52530       |\n",
      "|    policy_gradient_loss | -0.000406   |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 8.78e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=21400.33 +/- 64219.52\n",
      "Episode length: 3046.60 +/- 2392.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.05e+03    |\n",
      "|    mean_reward          | 2.14e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 345000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046246104 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.34e+04    |\n",
      "|    n_updates            | 52540       |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 5.07e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 729       |\n",
      "|    ep_rew_mean     | -3.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 712       |\n",
      "|    iterations      | 169       |\n",
      "|    time_elapsed    | 485       |\n",
      "|    total_timesteps | 346112    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 729         |\n",
      "|    ep_rew_mean          | -3.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 487         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007022646 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.21e+03    |\n",
      "|    n_updates            | 52550       |\n",
      "|    policy_gradient_loss | -0.00197    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.31e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-41489.25 +/- 175909.37\n",
      "Episode length: 4105.20 +/- 1789.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.11e+03    |\n",
      "|    mean_reward          | -4.15e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050412625 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 52560       |\n",
      "|    policy_gradient_loss | 0.0177      |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 415         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 729       |\n",
      "|    ep_rew_mean     | -3.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 171       |\n",
      "|    time_elapsed    | 499       |\n",
      "|    total_timesteps | 350208    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 774         |\n",
      "|    ep_rew_mean          | -3.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 501         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009442058 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 52570       |\n",
      "|    policy_gradient_loss | 0.00298     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 451         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 774         |\n",
      "|    ep_rew_mean          | -3.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 503         |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008836072 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.27        |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 272         |\n",
      "|    n_updates            | 52580       |\n",
      "|    policy_gradient_loss | 0.00144     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=-158374.23 +/- 172875.00\n",
      "Episode length: 1948.20 +/- 2292.81\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.95e+03   |\n",
      "|    mean_reward          | -1.58e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 355000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06329886 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.27       |\n",
      "|    explained_variance   | 0.911      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 37.5       |\n",
      "|    n_updates            | 52590      |\n",
      "|    policy_gradient_loss | 0.00899    |\n",
      "|    std                  | 0.243      |\n",
      "|    value_loss           | 147        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 823       |\n",
      "|    ep_rew_mean     | -3.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 699       |\n",
      "|    iterations      | 174       |\n",
      "|    time_elapsed    | 509       |\n",
      "|    total_timesteps | 356352    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 823         |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 511         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004122153 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.25        |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 270         |\n",
      "|    n_updates            | 52600       |\n",
      "|    policy_gradient_loss | 0.00273     |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 3.63e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-149573.18 +/- 232339.39\n",
      "Episode length: 2859.60 +/- 2202.16\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.86e+03   |\n",
      "|    mean_reward          | -1.5e+05   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 360000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03757227 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.27       |\n",
      "|    explained_variance   | -0.05      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 57.2       |\n",
      "|    n_updates            | 52610      |\n",
      "|    policy_gradient_loss | 0.00341    |\n",
      "|    std                  | 0.241      |\n",
      "|    value_loss           | 286        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 823       |\n",
      "|    ep_rew_mean     | -3.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 692       |\n",
      "|    iterations      | 176       |\n",
      "|    time_elapsed    | 520       |\n",
      "|    total_timesteps | 360448    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 814         |\n",
      "|    ep_rew_mean          | -3.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 521         |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014979018 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.3         |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 52620       |\n",
      "|    policy_gradient_loss | 0.002       |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 814          |\n",
      "|    ep_rew_mean          | -3.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 178          |\n",
      "|    time_elapsed         | 523          |\n",
      "|    total_timesteps      | 364544       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037895227 |\n",
      "|    clip_fraction        | 0.126        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.31         |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.84e+05     |\n",
      "|    n_updates            | 52630        |\n",
      "|    policy_gradient_loss | 0.00244      |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 3.01e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=-46149.06 +/- 197022.67\n",
      "Episode length: 3647.60 +/- 1913.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.65e+03    |\n",
      "|    mean_reward          | -4.61e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 365000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060773373 |\n",
      "|    clip_fraction        | 0.479       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.32        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 52640       |\n",
      "|    policy_gradient_loss | 0.0649      |\n",
      "|    std                  | 0.239       |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 847       |\n",
      "|    ep_rew_mean     | -3.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 179       |\n",
      "|    time_elapsed    | 534       |\n",
      "|    total_timesteps | 366592    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 847          |\n",
      "|    ep_rew_mean          | -3.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 537          |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044608233 |\n",
      "|    clip_fraction        | 0.134        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.34         |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 511          |\n",
      "|    n_updates            | 52650        |\n",
      "|    policy_gradient_loss | 0.00317      |\n",
      "|    std                  | 0.239        |\n",
      "|    value_loss           | 1.45e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=370000, episode_reward=-91386.15 +/- 179152.00\n",
      "Episode length: 3214.60 +/- 1825.05\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.21e+03   |\n",
      "|    mean_reward          | -9.14e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 370000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01131259 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.34       |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 102        |\n",
      "|    n_updates            | 52660      |\n",
      "|    policy_gradient_loss | -0.0039    |\n",
      "|    std                  | 0.239      |\n",
      "|    value_loss           | 257        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 847       |\n",
      "|    ep_rew_mean     | -3.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 675       |\n",
      "|    iterations      | 181       |\n",
      "|    time_elapsed    | 548       |\n",
      "|    total_timesteps | 370688    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 897          |\n",
      "|    ep_rew_mean          | -3.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 677          |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 550          |\n",
      "|    total_timesteps      | 372736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084025655 |\n",
      "|    clip_fraction        | 0.138        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.35         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 127          |\n",
      "|    n_updates            | 52670        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    std                  | 0.239        |\n",
      "|    value_loss           | 535          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 897          |\n",
      "|    ep_rew_mean          | -3.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 678          |\n",
      "|    iterations           | 183          |\n",
      "|    time_elapsed         | 552          |\n",
      "|    total_timesteps      | 374784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041569527 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.35         |\n",
      "|    explained_variance   | 0.823        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+04     |\n",
      "|    n_updates            | 52680        |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    std                  | 0.239        |\n",
      "|    value_loss           | 1.39e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=-160699.92 +/- 167595.02\n",
      "Episode length: 3223.60 +/- 1534.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.22e+03    |\n",
      "|    mean_reward          | -1.61e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 375000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016284328 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.36        |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 52690       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    std                  | 0.238       |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 916       |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 670       |\n",
      "|    iterations      | 184       |\n",
      "|    time_elapsed    | 561       |\n",
      "|    total_timesteps | 376832    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 916          |\n",
      "|    ep_rew_mean          | -3.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 672          |\n",
      "|    iterations           | 185          |\n",
      "|    time_elapsed         | 563          |\n",
      "|    total_timesteps      | 378880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040662372 |\n",
      "|    clip_fraction        | 0.0809       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.37         |\n",
      "|    explained_variance   | 0.652        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.71e+05     |\n",
      "|    n_updates            | 52700        |\n",
      "|    policy_gradient_loss | -0.000149    |\n",
      "|    std                  | 0.238        |\n",
      "|    value_loss           | 6.39e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=-125440.53 +/- 186473.62\n",
      "Episode length: 2350.40 +/- 2050.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.35e+03    |\n",
      "|    mean_reward          | -1.25e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 380000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009203436 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.37        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.4        |\n",
      "|    n_updates            | 52710       |\n",
      "|    policy_gradient_loss | -0.00718    |\n",
      "|    std                  | 0.237       |\n",
      "|    value_loss           | 329         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 916       |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 666       |\n",
      "|    iterations      | 186       |\n",
      "|    time_elapsed    | 571       |\n",
      "|    total_timesteps | 380928    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 958         |\n",
      "|    ep_rew_mean          | -3.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 573         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040040217 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.41        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 52720       |\n",
      "|    policy_gradient_loss | 0.00576     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=-74276.65 +/- 147562.62\n",
      "Episode length: 835.00 +/- 1243.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 835         |\n",
      "|    mean_reward          | -7.43e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 385000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047907844 |\n",
      "|    clip_fraction        | 0.509       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.44        |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.18e+07    |\n",
      "|    n_updates            | 52730       |\n",
      "|    policy_gradient_loss | 0.0198      |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 3.91e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 958       |\n",
      "|    ep_rew_mean     | -3.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 667       |\n",
      "|    iterations      | 188       |\n",
      "|    time_elapsed    | 577       |\n",
      "|    total_timesteps | 385024    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 994          |\n",
      "|    ep_rew_mean          | -3.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 668          |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 578          |\n",
      "|    total_timesteps      | 387072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071885316 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.44         |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 604          |\n",
      "|    n_updates            | 52740        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.95e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -3.66e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 669          |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 580          |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029738354 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.44         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.31e+07     |\n",
      "|    n_updates            | 52750        |\n",
      "|    policy_gradient_loss | 0.00144      |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.07e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=-62030.42 +/- 159173.79\n",
      "Episode length: 1644.00 +/- 1999.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.64e+03    |\n",
      "|    mean_reward          | -6.2e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008496564 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.45        |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 276         |\n",
      "|    n_updates            | 52760       |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 3.39e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -3.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 666       |\n",
      "|    iterations      | 191       |\n",
      "|    time_elapsed    | 586       |\n",
      "|    total_timesteps | 391168    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -3.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 588         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014659626 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.45        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49          |\n",
      "|    n_updates            | 52770       |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=-242471.05 +/- 201615.74\n",
      "Episode length: 1742.00 +/- 972.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.74e+03    |\n",
      "|    mean_reward          | -2.42e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 395000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003983759 |\n",
      "|    clip_fraction        | 0.0464      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.46        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.44e+07    |\n",
      "|    n_updates            | 52780       |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 5.48e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.05e+03  |\n",
      "|    ep_rew_mean     | -3.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 664       |\n",
      "|    iterations      | 193       |\n",
      "|    time_elapsed    | 594       |\n",
      "|    total_timesteps | 395264    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -4.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 666         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 596         |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013063227 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.46        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02e+04    |\n",
      "|    n_updates            | 52790       |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 6.69e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -5.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 667          |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 598          |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031095145 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.46         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+07     |\n",
      "|    n_updates            | 52800        |\n",
      "|    policy_gradient_loss | -0.000272    |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 6.34e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-320853.62 +/- 161702.57\n",
      "Episode length: 1734.80 +/- 863.21\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.73e+03      |\n",
      "|    mean_reward          | -3.21e+05     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 400000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094028236 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.46          |\n",
      "|    explained_variance   | 0.462         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.82e+07      |\n",
      "|    n_updates            | 52810         |\n",
      "|    policy_gradient_loss | -5.33e-05     |\n",
      "|    std                  | 0.234         |\n",
      "|    value_loss           | 2.11e+08      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.1e+03   |\n",
      "|    ep_rew_mean     | -5.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 664       |\n",
      "|    iterations      | 196       |\n",
      "|    time_elapsed    | 604       |\n",
      "|    total_timesteps | 401408    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -5.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 665          |\n",
      "|    iterations           | 197          |\n",
      "|    time_elapsed         | 606          |\n",
      "|    total_timesteps      | 403456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009334283 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.46         |\n",
      "|    explained_variance   | 0.563        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.8e+06      |\n",
      "|    n_updates            | 52820        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.42e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=-301076.62 +/- 133415.59\n",
      "Episode length: 1722.80 +/- 1272.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.72e+03    |\n",
      "|    mean_reward          | -3.01e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 405000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011694258 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.45        |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79e+07    |\n",
      "|    n_updates            | 52830       |\n",
      "|    policy_gradient_loss | 0.00226     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 4.42e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.14e+03  |\n",
      "|    ep_rew_mean     | -5.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 662       |\n",
      "|    iterations      | 198       |\n",
      "|    time_elapsed    | 612       |\n",
      "|    total_timesteps | 405504    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -5.89e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 614          |\n",
      "|    total_timesteps      | 407552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016114071 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.45         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.84e+07     |\n",
      "|    n_updates            | 52840        |\n",
      "|    policy_gradient_loss | -0.000981    |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 9.79e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.17e+03     |\n",
      "|    ep_rew_mean          | -6.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 616          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062609906 |\n",
      "|    clip_fraction        | 0.0564       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.46         |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 906          |\n",
      "|    n_updates            | 52850        |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 4.04e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=-228562.85 +/- 191293.29\n",
      "Episode length: 1422.80 +/- 938.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.42e+03    |\n",
      "|    mean_reward          | -2.29e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 410000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003562103 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09e+07    |\n",
      "|    n_updates            | 52860       |\n",
      "|    policy_gradient_loss | -0.000442   |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 7.55e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.17e+03  |\n",
      "|    ep_rew_mean     | -6.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 662       |\n",
      "|    iterations      | 201       |\n",
      "|    time_elapsed    | 621       |\n",
      "|    total_timesteps | 411648    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -6.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 202          |\n",
      "|    time_elapsed         | 623          |\n",
      "|    total_timesteps      | 413696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021678791 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.916        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47e+05     |\n",
      "|    n_updates            | 52870        |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 4.18e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=-269616.30 +/- 133833.20\n",
      "Episode length: 1342.80 +/- 1267.68\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.34e+03     |\n",
      "|    mean_reward          | -2.7e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 415000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010472366 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.61e+07     |\n",
      "|    n_updates            | 52880        |\n",
      "|    policy_gradient_loss | -0.000474    |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 6.88e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.21e+03 |\n",
      "|    ep_rew_mean     | -7e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 661      |\n",
      "|    iterations      | 203      |\n",
      "|    time_elapsed    | 628      |\n",
      "|    total_timesteps | 415744   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | -7.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 662          |\n",
      "|    iterations           | 204          |\n",
      "|    time_elapsed         | 630          |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030648152 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.25e+07     |\n",
      "|    n_updates            | 52890        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 8.94e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -7.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 205          |\n",
      "|    time_elapsed         | 632          |\n",
      "|    total_timesteps      | 419840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017869014 |\n",
      "|    clip_fraction        | 0.0111       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.76e+07     |\n",
      "|    n_updates            | 52900        |\n",
      "|    policy_gradient_loss | -0.00208     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 1.25e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=-135048.50 +/- 176830.45\n",
      "Episode length: 1036.20 +/- 1396.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.04e+03     |\n",
      "|    mean_reward          | -1.35e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 420000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068782927 |\n",
      "|    clip_fraction        | 0.0884       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.752        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+04     |\n",
      "|    n_updates            | 52910        |\n",
      "|    policy_gradient_loss | 0.00164      |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 4.77e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.2e+03   |\n",
      "|    ep_rew_mean     | -7.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 662       |\n",
      "|    iterations      | 206       |\n",
      "|    time_elapsed    | 636       |\n",
      "|    total_timesteps | 421888    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | -7.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 664         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004844399 |\n",
      "|    clip_fraction        | 0.0128      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.22e+05    |\n",
      "|    n_updates            | 52920       |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 7.1e+05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=-70877.71 +/- 151236.50\n",
      "Episode length: 1457.80 +/- 1767.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.46e+03     |\n",
      "|    mean_reward          | -7.09e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 425000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069429204 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.65e+07     |\n",
      "|    n_updates            | 52930        |\n",
      "|    policy_gradient_loss | -0.0044      |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 7.03e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -8.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 661       |\n",
      "|    iterations      | 208       |\n",
      "|    time_elapsed    | 643       |\n",
      "|    total_timesteps | 425984    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.22e+03     |\n",
      "|    ep_rew_mean          | -8.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 209          |\n",
      "|    time_elapsed         | 645          |\n",
      "|    total_timesteps      | 428032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027783741 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95e+07     |\n",
      "|    n_updates            | 52940        |\n",
      "|    policy_gradient_loss | 0.00033      |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 9.79e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-146055.40 +/- 165139.46\n",
      "Episode length: 1160.20 +/- 1141.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.16e+03    |\n",
      "|    mean_reward          | -1.46e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 430000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004215734 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.22e+07    |\n",
      "|    n_updates            | 52950       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 1.52e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.22e+03  |\n",
      "|    ep_rew_mean     | -8.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 661       |\n",
      "|    iterations      | 210       |\n",
      "|    time_elapsed    | 650       |\n",
      "|    total_timesteps | 430080    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | -8.87e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 662          |\n",
      "|    iterations           | 211          |\n",
      "|    time_elapsed         | 652          |\n",
      "|    total_timesteps      | 432128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061446265 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.896        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 52960        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.23e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | -9.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004733326 |\n",
      "|    clip_fraction        | 0.0267      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.59e+07    |\n",
      "|    n_updates            | 52970       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 8.27e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=435000, episode_reward=21209.72 +/- 91373.64\n",
      "Episode length: 3469.80 +/- 2014.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.47e+03     |\n",
      "|    mean_reward          | 2.12e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 435000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036413847 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.21e+07     |\n",
      "|    n_updates            | 52980        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 6.28e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.27e+03  |\n",
      "|    ep_rew_mean     | -9.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 655       |\n",
      "|    iterations      | 213       |\n",
      "|    time_elapsed    | 665       |\n",
      "|    total_timesteps | 436224    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.27e+03   |\n",
      "|    ep_rew_mean          | -9.11e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 656        |\n",
      "|    iterations           | 214        |\n",
      "|    time_elapsed         | 667        |\n",
      "|    total_timesteps      | 438272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01612724 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.47       |\n",
      "|    explained_variance   | 0.862      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 159        |\n",
      "|    n_updates            | 52990      |\n",
      "|    policy_gradient_loss | 0.000893   |\n",
      "|    std                  | 0.234      |\n",
      "|    value_loss           | 896        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-290486.54 +/- 176064.70\n",
      "Episode length: 2388.60 +/- 1314.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.39e+03    |\n",
      "|    mean_reward          | -2.9e+05    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005734534 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.12e+07    |\n",
      "|    n_updates            | 53000       |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 5.38e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.31e+03  |\n",
      "|    ep_rew_mean     | -9.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 652       |\n",
      "|    iterations      | 215       |\n",
      "|    time_elapsed    | 675       |\n",
      "|    total_timesteps | 440320    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.31e+03     |\n",
      "|    ep_rew_mean          | -9.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 653          |\n",
      "|    iterations           | 216          |\n",
      "|    time_elapsed         | 676          |\n",
      "|    total_timesteps      | 442368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012636468 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.47         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.25e+04     |\n",
      "|    n_updates            | 53010        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 2.93e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | -9.91e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 678         |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014054898 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.28e+03    |\n",
      "|    n_updates            | 53020       |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 4.11e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=-299027.78 +/- 177569.94\n",
      "Episode length: 3285.80 +/- 1823.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.29e+03     |\n",
      "|    mean_reward          | -2.99e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 445000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009115766 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.48         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.45e+07     |\n",
      "|    n_updates            | 53030        |\n",
      "|    policy_gradient_loss | -0.000829    |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 9.3e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -9.91e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 648       |\n",
      "|    iterations      | 218       |\n",
      "|    time_elapsed    | 688       |\n",
      "|    total_timesteps | 446464    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.39e+03     |\n",
      "|    ep_rew_mean          | -9.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 649          |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 690          |\n",
      "|    total_timesteps      | 448512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071191937 |\n",
      "|    clip_fraction        | 0.0772       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.48         |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 976          |\n",
      "|    n_updates            | 53040        |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 7.41e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-42832.49 +/- 81279.03\n",
      "Episode length: 1171.20 +/- 1344.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.17e+03     |\n",
      "|    mean_reward          | -4.28e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 450000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020738598 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.49         |\n",
      "|    explained_variance   | 0.859        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.65e+05     |\n",
      "|    n_updates            | 53050        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 4.62e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | -1e+05   |\n",
      "| time/              |          |\n",
      "|    fps             | 648      |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 695      |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | -1e+05      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 697         |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009159516 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.49        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+07    |\n",
      "|    n_updates            | 53060       |\n",
      "|    policy_gradient_loss | 0.00105     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 3.42e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | -1e+05      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 698         |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016341124 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.51        |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90.3        |\n",
      "|    n_updates            | 53070       |\n",
      "|    policy_gradient_loss | 0.00634     |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 362         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=-112269.32 +/- 144799.71\n",
      "Episode length: 889.00 +/- 974.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 889         |\n",
      "|    mean_reward          | -1.12e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 455000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007934272 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 322         |\n",
      "|    n_updates            | 53080       |\n",
      "|    policy_gradient_loss | -0.00517    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -9.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 649       |\n",
      "|    iterations      | 223       |\n",
      "|    time_elapsed    | 702       |\n",
      "|    total_timesteps | 456704    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | -1e+05       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 704          |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020484084 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.54         |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.09e+04     |\n",
      "|    n_updates            | 53090        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 3.23e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=35584.81 +/- 77803.18\n",
      "Episode length: 4311.20 +/- 1377.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.31e+03     |\n",
      "|    mean_reward          | 3.56e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 460000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015523684 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.54         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6e+06        |\n",
      "|    n_updates            | 53100        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 3.99e+07     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.47e+03 |\n",
      "|    ep_rew_mean     | -1e+05   |\n",
      "| time/              |          |\n",
      "|    fps             | 642      |\n",
      "|    iterations      | 225      |\n",
      "|    time_elapsed    | 716      |\n",
      "|    total_timesteps | 460800   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | -1.02e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 226          |\n",
      "|    time_elapsed         | 718          |\n",
      "|    total_timesteps      | 462848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032074763 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.54         |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.43e+04     |\n",
      "|    n_updates            | 53110        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 1.14e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | -1.02e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 645          |\n",
      "|    iterations           | 227          |\n",
      "|    time_elapsed         | 720          |\n",
      "|    total_timesteps      | 464896       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007944091 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.54         |\n",
      "|    explained_variance   | 0.468        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.09e+07     |\n",
      "|    n_updates            | 53120        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 5.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=14909.60 +/- 35446.84\n",
      "Episode length: 1129.60 +/- 1939.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.13e+03    |\n",
      "|    mean_reward          | 1.49e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 465000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008327263 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 221         |\n",
      "|    n_updates            | 53130       |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -1.02e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 643       |\n",
      "|    iterations      | 228       |\n",
      "|    time_elapsed    | 725       |\n",
      "|    total_timesteps | 466944    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -1.01e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 645         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 727         |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006927468 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 303         |\n",
      "|    n_updates            | 53140       |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 2.32e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=26191.32 +/- 37441.25\n",
      "Episode length: 2155.40 +/- 2332.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.16e+03     |\n",
      "|    mean_reward          | 2.62e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 470000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048539764 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.54         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+04     |\n",
      "|    n_updates            | 53150        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 6.69e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -1.01e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 640       |\n",
      "|    iterations      | 230       |\n",
      "|    time_elapsed    | 735       |\n",
      "|    total_timesteps | 471040    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.58e+03  |\n",
      "|    ep_rew_mean          | -1.01e+05 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 640       |\n",
      "|    iterations           | 231       |\n",
      "|    time_elapsed         | 738       |\n",
      "|    total_timesteps      | 473088    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0094601 |\n",
      "|    clip_fraction        | 0.0936    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.54      |\n",
      "|    explained_variance   | 0.824     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 803       |\n",
      "|    n_updates            | 53160     |\n",
      "|    policy_gradient_loss | -0.00427  |\n",
      "|    std                  | 0.232     |\n",
      "|    value_loss           | 2.08e+03  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=27548.75 +/- 34880.79\n",
      "Episode length: 3012.00 +/- 2434.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.01e+03     |\n",
      "|    mean_reward          | 2.75e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 475000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005011412 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.53         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3e+05        |\n",
      "|    n_updates            | 53170        |\n",
      "|    policy_gradient_loss | -0.000843    |\n",
      "|    std                  | 0.232        |\n",
      "|    value_loss           | 6.6e+05      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -1.01e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 232       |\n",
      "|    time_elapsed    | 750       |\n",
      "|    total_timesteps | 475136    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | -1.01e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 752          |\n",
      "|    total_timesteps      | 477184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047934754 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.53         |\n",
      "|    explained_variance   | 0.849        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.94e+03     |\n",
      "|    n_updates            | 53180        |\n",
      "|    policy_gradient_loss | -0.00037     |\n",
      "|    std                  | 0.232        |\n",
      "|    value_loss           | 1.43e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -1.03e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 754         |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009659631 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 460         |\n",
      "|    n_updates            | 53190       |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 2.92e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-30031.23 +/- 54113.35\n",
      "Episode length: 286.80 +/- 383.19\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 287          |\n",
      "|    mean_reward          | -3e+04       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037178006 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.53         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66e+07     |\n",
      "|    n_updates            | 53200        |\n",
      "|    policy_gradient_loss | 1.39e-05     |\n",
      "|    std                  | 0.232        |\n",
      "|    value_loss           | 7.93e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.61e+03  |\n",
      "|    ep_rew_mean     | -1.04e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 235       |\n",
      "|    time_elapsed    | 756       |\n",
      "|    total_timesteps | 481280    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | -1.04e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 759          |\n",
      "|    total_timesteps      | 483328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053977957 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.53         |\n",
      "|    explained_variance   | 0.488        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47e+07     |\n",
      "|    n_updates            | 53210        |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    std                  | 0.232        |\n",
      "|    value_loss           | 5.36e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=485000, episode_reward=-8392.79 +/- 15011.28\n",
      "Episode length: 1401.00 +/- 1880.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4e+03     |\n",
      "|    mean_reward          | -8.39e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 485000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019878749 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.54        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 286         |\n",
      "|    n_updates            | 53220       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 882         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -9.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 237       |\n",
      "|    time_elapsed    | 764       |\n",
      "|    total_timesteps | 485376    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -9.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 766         |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006948444 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.56        |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 621         |\n",
      "|    n_updates            | 53230       |\n",
      "|    policy_gradient_loss | -0.00787    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.08e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -1.03e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 768          |\n",
      "|    total_timesteps      | 489472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041706385 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.56         |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.52e+04     |\n",
      "|    n_updates            | 53240        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 6.54e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=-67785.96 +/- 144755.25\n",
      "Episode length: 2078.20 +/- 2385.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.08e+03     |\n",
      "|    mean_reward          | -6.78e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 490000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015221762 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.56         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.16e+07     |\n",
      "|    n_updates            | 53250        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 7.35e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.03e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 240       |\n",
      "|    time_elapsed    | 775       |\n",
      "|    total_timesteps | 491520    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.03e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 777         |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004078995 |\n",
      "|    clip_fraction        | 0.00991     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.56        |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.34e+04    |\n",
      "|    n_updates            | 53260       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 3.13e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=1621.45 +/- 3424.06\n",
      "Episode length: 1312.80 +/- 1862.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.31e+03    |\n",
      "|    mean_reward          | 1.62e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 495000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008937204 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.56        |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 981         |\n",
      "|    n_updates            | 53270       |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 4.19e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.03e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 242       |\n",
      "|    time_elapsed    | 782       |\n",
      "|    total_timesteps | 495616    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -9.88e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 784         |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010967189 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.57        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 232         |\n",
      "|    n_updates            | 53280       |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.09e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.67e+03     |\n",
      "|    ep_rew_mean          | -9.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 244          |\n",
      "|    time_elapsed         | 786          |\n",
      "|    total_timesteps      | 499712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046791187 |\n",
      "|    clip_fraction        | 0.0299       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.58         |\n",
      "|    explained_variance   | 0.748        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.4e+03      |\n",
      "|    n_updates            | 53290        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 5.23e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500000, episode_reward=-32703.56 +/- 131749.85\n",
      "Episode length: 3051.60 +/- 2386.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.05e+03    |\n",
      "|    mean_reward          | -3.27e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016790252 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.57        |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 303         |\n",
      "|    n_updates            | 53300       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.67e+03  |\n",
      "|    ep_rew_mean     | -9.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 245       |\n",
      "|    time_elapsed    | 795       |\n",
      "|    total_timesteps | 501760    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | -9.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018095398 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.59        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 53310       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 357         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=505000, episode_reward=-38023.67 +/- 70936.54\n",
      "Episode length: 1794.20 +/- 2151.94\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.79e+03  |\n",
      "|    mean_reward          | -3.8e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 505000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0101393 |\n",
      "|    clip_fraction        | 0.0469    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.6       |\n",
      "|    explained_variance   | 0.498     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.81e+07  |\n",
      "|    n_updates            | 53320     |\n",
      "|    policy_gradient_loss | -0.00101  |\n",
      "|    std                  | 0.229     |\n",
      "|    value_loss           | 3.76e+07  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.55e+03 |\n",
      "|    ep_rew_mean     | -1e+05   |\n",
      "| time/              |          |\n",
      "|    fps             | 629      |\n",
      "|    iterations      | 247      |\n",
      "|    time_elapsed    | 803      |\n",
      "|    total_timesteps | 505856   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | -1.01e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 805          |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006137506 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.6          |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.93e+06     |\n",
      "|    n_updates            | 53330        |\n",
      "|    policy_gradient_loss | -9.79e-05    |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 2.81e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.38e+03     |\n",
      "|    ep_rew_mean          | -1.06e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 807          |\n",
      "|    total_timesteps      | 509952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046169967 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.6          |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+05     |\n",
      "|    n_updates            | 53340        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 4.89e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=17075.33 +/- 28547.19\n",
      "Episode length: 2041.40 +/- 2415.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.04e+03     |\n",
      "|    mean_reward          | 1.71e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 510000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035373478 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.6          |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.38e+07     |\n",
      "|    n_updates            | 53350        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 6.22e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.35e+03  |\n",
      "|    ep_rew_mean     | -1.07e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 250       |\n",
      "|    time_elapsed    | 814       |\n",
      "|    total_timesteps | 512000    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -1.03e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 816         |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011307418 |\n",
      "|    clip_fraction        | 0.0942      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.6         |\n",
      "|    explained_variance   | 0.135       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+03    |\n",
      "|    n_updates            | 53360       |\n",
      "|    policy_gradient_loss | -0.00425    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 6.46e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=515000, episode_reward=-145403.82 +/- 123219.74\n",
      "Episode length: 1308.80 +/- 1497.36\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.31e+03     |\n",
      "|    mean_reward          | -1.45e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 515000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029506811 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.6          |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.24e+06     |\n",
      "|    n_updates            | 53370        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 4.27e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -1.03e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 252       |\n",
      "|    time_elapsed    | 821       |\n",
      "|    total_timesteps | 516096    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -1.01e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 823         |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009138817 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.6         |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 53380       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    std                  | 0.23        |\n",
      "|    value_loss           | 6.07e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-54968.69 +/- 62033.61\n",
      "Episode length: 93.60 +/- 65.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 93.6         |\n",
      "|    mean_reward          | -5.5e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 520000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027212894 |\n",
      "|    clip_fraction        | 0.0207       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.59         |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.52e+07     |\n",
      "|    n_updates            | 53390        |\n",
      "|    policy_gradient_loss | -0.000289    |\n",
      "|    std                  | 0.23         |\n",
      "|    value_loss           | 6.22e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -1.01e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 254       |\n",
      "|    time_elapsed    | 825       |\n",
      "|    total_timesteps | 520192    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | -9.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 255          |\n",
      "|    time_elapsed         | 827          |\n",
      "|    total_timesteps      | 522240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089551015 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.6          |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 377          |\n",
      "|    n_updates            | 53400        |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -9.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 828         |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010997051 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.62        |\n",
      "|    explained_variance   | 0.63        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.96e+06    |\n",
      "|    n_updates            | 53410       |\n",
      "|    policy_gradient_loss | 0.00181     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 4.08e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=8413.67 +/- 24430.37\n",
      "Episode length: 1142.00 +/- 1936.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.14e+03     |\n",
      "|    mean_reward          | 8.41e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 525000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064593814 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.62         |\n",
      "|    explained_variance   | 0.845        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.1e+04      |\n",
      "|    n_updates            | 53420        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 2.38e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.27e+03  |\n",
      "|    ep_rew_mean     | -8.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 257       |\n",
      "|    time_elapsed    | 833       |\n",
      "|    total_timesteps | 526336    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -8.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 835         |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004857988 |\n",
      "|    clip_fraction        | 0.0159      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.62        |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.66e+06    |\n",
      "|    n_updates            | 53430       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 2.82e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=-2944.46 +/- 11597.37\n",
      "Episode length: 2466.20 +/- 2192.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.47e+03     |\n",
      "|    mean_reward          | -2.94e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 530000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067023686 |\n",
      "|    clip_fraction        | 0.0483       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.61         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.67e+04     |\n",
      "|    n_updates            | 53440        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 1.32e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -7.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 259       |\n",
      "|    time_elapsed    | 843       |\n",
      "|    total_timesteps | 530432    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -7.77e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 628          |\n",
      "|    iterations           | 260          |\n",
      "|    time_elapsed         | 846          |\n",
      "|    total_timesteps      | 532480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021074591 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.61         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.1e+06      |\n",
      "|    n_updates            | 53450        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 6.17e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -7.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 849         |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013963266 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.62        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 459         |\n",
      "|    n_updates            | 53460       |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.8e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=535000, episode_reward=-118839.09 +/- 98529.73\n",
      "Episode length: 250.40 +/- 243.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 250         |\n",
      "|    mean_reward          | -1.19e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 535000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010349455 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 53470       |\n",
      "|    policy_gradient_loss | 0.000907    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 958         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.23e+03 |\n",
      "|    ep_rew_mean     | -7.7e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 630      |\n",
      "|    iterations      | 262      |\n",
      "|    time_elapsed    | 851      |\n",
      "|    total_timesteps | 536576   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | -7.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 263         |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 538624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014512103 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.553       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 410         |\n",
      "|    n_updates            | 53480       |\n",
      "|    policy_gradient_loss | -0.00753    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.75e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=-98403.38 +/- 117166.90\n",
      "Episode length: 1279.40 +/- 1860.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.28e+03     |\n",
      "|    mean_reward          | -9.84e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 540000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070532956 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.858        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 53490        |\n",
      "|    policy_gradient_loss | -0.00227     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 1.55e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.22e+03  |\n",
      "|    ep_rew_mean     | -6.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 627       |\n",
      "|    iterations      | 264       |\n",
      "|    time_elapsed    | 860       |\n",
      "|    total_timesteps | 540672    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.22e+03     |\n",
      "|    ep_rew_mean          | -6.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 628          |\n",
      "|    iterations           | 265          |\n",
      "|    time_elapsed         | 863          |\n",
      "|    total_timesteps      | 542720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050028847 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+04     |\n",
      "|    n_updates            | 53500        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 5.69e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | -6.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 865         |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015112879 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 354         |\n",
      "|    n_updates            | 53510       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=545000, episode_reward=-70953.72 +/- 95933.33\n",
      "Episode length: 483.00 +/- 568.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 483         |\n",
      "|    mean_reward          | -7.1e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 545000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004990269 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.76e+06    |\n",
      "|    n_updates            | 53520       |\n",
      "|    policy_gradient_loss | 0.00106     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 3.08e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.22e+03  |\n",
      "|    ep_rew_mean     | -5.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 267       |\n",
      "|    time_elapsed    | 868       |\n",
      "|    total_timesteps | 546816    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -4.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 268          |\n",
      "|    time_elapsed         | 869          |\n",
      "|    total_timesteps      | 548864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010224399 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.63         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.94e+04     |\n",
      "|    n_updates            | 53530        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 4.46e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=550000, episode_reward=-6852.56 +/- 5561.56\n",
      "Episode length: 178.40 +/- 94.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 178          |\n",
      "|    mean_reward          | -6.85e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 550000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018665087 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.63         |\n",
      "|    explained_variance   | 0.626        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.36e+05     |\n",
      "|    n_updates            | 53540        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 5.95e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -3.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 269       |\n",
      "|    time_elapsed    | 872       |\n",
      "|    total_timesteps | 550912    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 973          |\n",
      "|    ep_rew_mean          | -3.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 632          |\n",
      "|    iterations           | 270          |\n",
      "|    time_elapsed         | 874          |\n",
      "|    total_timesteps      | 552960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019401663 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.63         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79e+06     |\n",
      "|    n_updates            | 53550        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 2.91e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=555000, episode_reward=-57277.47 +/- 94777.05\n",
      "Episode length: 2485.20 +/- 2157.52\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.49e+03     |\n",
      "|    mean_reward          | -5.73e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 555000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039776843 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.63         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+07     |\n",
      "|    n_updates            | 53560        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 3.21e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 931       |\n",
      "|    ep_rew_mean     | -3.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 271       |\n",
      "|    time_elapsed    | 882       |\n",
      "|    total_timesteps | 555008    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 836         |\n",
      "|    ep_rew_mean          | -3.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 884         |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005796188 |\n",
      "|    clip_fraction        | 0.0227      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.44e+04    |\n",
      "|    n_updates            | 53570       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 6.07e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 790           |\n",
      "|    ep_rew_mean          | -3.68e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 631           |\n",
      "|    iterations           | 273           |\n",
      "|    time_elapsed         | 885           |\n",
      "|    total_timesteps      | 559104        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037664676 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.63          |\n",
      "|    explained_variance   | 0.609         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.05e+07      |\n",
      "|    n_updates            | 53580         |\n",
      "|    policy_gradient_loss | -0.00132      |\n",
      "|    std                  | 0.227         |\n",
      "|    value_loss           | 1.67e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-51534.35 +/- 103175.37\n",
      "Episode length: 140.20 +/- 130.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 140         |\n",
      "|    mean_reward          | -5.15e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004046224 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+07    |\n",
      "|    n_updates            | 53590       |\n",
      "|    policy_gradient_loss | -0.000919   |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 2.01e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 703       |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 274       |\n",
      "|    time_elapsed    | 888       |\n",
      "|    total_timesteps | 561152    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 661         |\n",
      "|    ep_rew_mean          | -3.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 890         |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001995525 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.49e+07    |\n",
      "|    n_updates            | 53600       |\n",
      "|    policy_gradient_loss | 0.000784    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 9.98e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=565000, episode_reward=-10450.89 +/- 15544.31\n",
      "Episode length: 1128.00 +/- 1936.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.13e+03    |\n",
      "|    mean_reward          | -1.05e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 565000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003989574 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+07    |\n",
      "|    n_updates            | 53610       |\n",
      "|    policy_gradient_loss | 0.00032     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.8e+07     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 658       |\n",
      "|    ep_rew_mean     | -3.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 276       |\n",
      "|    time_elapsed    | 897       |\n",
      "|    total_timesteps | 565248    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 658         |\n",
      "|    ep_rew_mean          | -3.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 277         |\n",
      "|    time_elapsed         | 898         |\n",
      "|    total_timesteps      | 567296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009744631 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 53620       |\n",
      "|    policy_gradient_loss | -0.000661   |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 6.57e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 705         |\n",
      "|    ep_rew_mean          | -3.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 900         |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010911692 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 497         |\n",
      "|    n_updates            | 53630       |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 2.25e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=-94825.41 +/- 114439.13\n",
      "Episode length: 359.60 +/- 188.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 360          |\n",
      "|    mean_reward          | -9.48e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 570000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062180078 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.48e+03     |\n",
      "|    n_updates            | 53640        |\n",
      "|    policy_gradient_loss | -0.00295     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 3.11e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 676       |\n",
      "|    ep_rew_mean     | -3.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 632       |\n",
      "|    iterations      | 279       |\n",
      "|    time_elapsed    | 903       |\n",
      "|    total_timesteps | 571392    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 668          |\n",
      "|    ep_rew_mean          | -3.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 633          |\n",
      "|    iterations           | 280          |\n",
      "|    time_elapsed         | 905          |\n",
      "|    total_timesteps      | 573440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013357124 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.38e+07     |\n",
      "|    n_updates            | 53650        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    std                  | 0.227        |\n",
      "|    value_loss           | 3.88e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=-52949.39 +/- 96606.88\n",
      "Episode length: 411.20 +/- 326.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 411         |\n",
      "|    mean_reward          | -5.29e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 575000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008218362 |\n",
      "|    clip_fraction        | 0.0242      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69e+04    |\n",
      "|    n_updates            | 53660       |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.24e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 669       |\n",
      "|    ep_rew_mean     | -3.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 281       |\n",
      "|    time_elapsed    | 908       |\n",
      "|    total_timesteps | 575488    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 683       |\n",
      "|    ep_rew_mean          | -2.92e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 634       |\n",
      "|    iterations           | 282       |\n",
      "|    time_elapsed         | 909       |\n",
      "|    total_timesteps      | 577536    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.004854  |\n",
      "|    clip_fraction        | 0.0285    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.64      |\n",
      "|    explained_variance   | 0.706     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.23e+05  |\n",
      "|    n_updates            | 53670     |\n",
      "|    policy_gradient_loss | -0.00185  |\n",
      "|    std                  | 0.226     |\n",
      "|    value_loss           | 3.32e+05  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 668          |\n",
      "|    ep_rew_mean          | -3.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 911          |\n",
      "|    total_timesteps      | 579584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055129435 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.64         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.02e+03     |\n",
      "|    n_updates            | 53680        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    std                  | 0.226        |\n",
      "|    value_loss           | 1.17e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=-41979.47 +/- 92025.95\n",
      "Episode length: 353.20 +/- 117.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 353         |\n",
      "|    mean_reward          | -4.2e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001467413 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.64        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.88e+07    |\n",
      "|    n_updates            | 53690       |\n",
      "|    policy_gradient_loss | -0.000932   |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 1.55e+08    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 668      |\n",
      "|    ep_rew_mean     | -3.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 635      |\n",
      "|    iterations      | 284      |\n",
      "|    time_elapsed    | 914      |\n",
      "|    total_timesteps | 581632   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 711         |\n",
      "|    ep_rew_mean          | -3.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 916         |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014968387 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.65        |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.8        |\n",
      "|    n_updates            | 53700       |\n",
      "|    policy_gradient_loss | 0.0153      |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=585000, episode_reward=-79621.18 +/- 100076.35\n",
      "Episode length: 254.00 +/- 128.65\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 254        |\n",
      "|    mean_reward          | -7.96e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 585000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02562721 |\n",
      "|    clip_fraction        | 0.558      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.67       |\n",
      "|    explained_variance   | 0.709      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.01e+03   |\n",
      "|    n_updates            | 53710      |\n",
      "|    policy_gradient_loss | 0.0492     |\n",
      "|    std                  | 0.225      |\n",
      "|    value_loss           | 2.6e+04    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 726       |\n",
      "|    ep_rew_mean     | -3.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 637       |\n",
      "|    iterations      | 286       |\n",
      "|    time_elapsed    | 919       |\n",
      "|    total_timesteps | 585728    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 658          |\n",
      "|    ep_rew_mean          | -4.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 638          |\n",
      "|    iterations           | 287          |\n",
      "|    time_elapsed         | 920          |\n",
      "|    total_timesteps      | 587776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010019758 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.67         |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.7e+04      |\n",
      "|    n_updates            | 53720        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    std                  | 0.225        |\n",
      "|    value_loss           | 1.47e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 543          |\n",
      "|    ep_rew_mean          | -4.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 639          |\n",
      "|    iterations           | 288          |\n",
      "|    time_elapsed         | 922          |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.380075e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.67         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.21e+07     |\n",
      "|    n_updates            | 53730        |\n",
      "|    policy_gradient_loss | -0.000329    |\n",
      "|    std                  | 0.225        |\n",
      "|    value_loss           | 1.96e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=9370.66 +/- 19941.82\n",
      "Episode length: 1195.40 +/- 1909.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2e+03      |\n",
      "|    mean_reward          | 9.37e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 590000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.901598e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.67         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.78e+07     |\n",
      "|    n_updates            | 53740        |\n",
      "|    policy_gradient_loss | -0.000327    |\n",
      "|    std                  | 0.225        |\n",
      "|    value_loss           | 1.37e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 517       |\n",
      "|    ep_rew_mean     | -5.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 289       |\n",
      "|    time_elapsed    | 927       |\n",
      "|    total_timesteps | 591872    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 517          |\n",
      "|    ep_rew_mean          | -5.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 638          |\n",
      "|    iterations           | 290          |\n",
      "|    time_elapsed         | 929          |\n",
      "|    total_timesteps      | 593920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039134505 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.67         |\n",
      "|    explained_variance   | 0.594        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 642          |\n",
      "|    n_updates            | 53750        |\n",
      "|    policy_gradient_loss | -0.00293     |\n",
      "|    std                  | 0.225        |\n",
      "|    value_loss           | 4.06e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=595000, episode_reward=-52456.28 +/- 51324.48\n",
      "Episode length: 697.20 +/- 918.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 697         |\n",
      "|    mean_reward          | -5.25e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 595000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010413269 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.67        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 612         |\n",
      "|    n_updates            | 53760       |\n",
      "|    policy_gradient_loss | -0.00523    |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 3.08e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 506       |\n",
      "|    ep_rew_mean     | -5.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 637       |\n",
      "|    iterations      | 291       |\n",
      "|    time_elapsed    | 934       |\n",
      "|    total_timesteps | 595968    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 506          |\n",
      "|    ep_rew_mean          | -5.34e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 638          |\n",
      "|    iterations           | 292          |\n",
      "|    time_elapsed         | 937          |\n",
      "|    total_timesteps      | 598016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031905612 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.68         |\n",
      "|    explained_variance   | 0.459        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+07     |\n",
      "|    n_updates            | 53770        |\n",
      "|    policy_gradient_loss | 0.00143      |\n",
      "|    std                  | 0.225        |\n",
      "|    value_loss           | 4.59e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=600000, episode_reward=-197350.35 +/- 98225.19\n",
      "Episode length: 222.20 +/- 103.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 222         |\n",
      "|    mean_reward          | -1.97e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016349196 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.68        |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 501         |\n",
      "|    n_updates            | 53780       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 531       |\n",
      "|    ep_rew_mean     | -5.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 293       |\n",
      "|    time_elapsed    | 939       |\n",
      "|    total_timesteps | 600064    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 521         |\n",
      "|    ep_rew_mean          | -5.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 941         |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010522123 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.68        |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34e+07    |\n",
      "|    n_updates            | 53790       |\n",
      "|    policy_gradient_loss | 0.0013      |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 5.38e+07    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 521           |\n",
      "|    ep_rew_mean          | -5.76e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 640           |\n",
      "|    iterations           | 295           |\n",
      "|    time_elapsed         | 943           |\n",
      "|    total_timesteps      | 604160        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00029234376 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.68          |\n",
      "|    explained_variance   | 0.423         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.37e+07      |\n",
      "|    n_updates            | 53800         |\n",
      "|    policy_gradient_loss | -0.00129      |\n",
      "|    std                  | 0.225         |\n",
      "|    value_loss           | 3.5e+07       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=605000, episode_reward=315.74 +/- 8053.52\n",
      "Episode length: 529.60 +/- 790.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 530         |\n",
      "|    mean_reward          | 316         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 605000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008450501 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.68        |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 53810       |\n",
      "|    policy_gradient_loss | -0.000574   |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 3.69e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 523       |\n",
      "|    ep_rew_mean     | -5.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 640       |\n",
      "|    iterations      | 296       |\n",
      "|    time_elapsed    | 946       |\n",
      "|    total_timesteps | 606208    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 532          |\n",
      "|    ep_rew_mean          | -6.15e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 641          |\n",
      "|    iterations           | 297          |\n",
      "|    time_elapsed         | 948          |\n",
      "|    total_timesteps      | 608256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039157905 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.69         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+07     |\n",
      "|    n_updates            | 53820        |\n",
      "|    policy_gradient_loss | -0.000342    |\n",
      "|    std                  | 0.224        |\n",
      "|    value_loss           | 4.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=-2013.57 +/- 15997.81\n",
      "Episode length: 1598.40 +/- 1868.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -2.01e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 610000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000455593 |\n",
      "|    clip_fraction        | 0.000146    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.69        |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.73e+07    |\n",
      "|    n_updates            | 53830       |\n",
      "|    policy_gradient_loss | -8.17e-05   |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 5.33e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 508       |\n",
      "|    ep_rew_mean     | -6.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 639       |\n",
      "|    iterations      | 298       |\n",
      "|    time_elapsed    | 954       |\n",
      "|    total_timesteps | 610304    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 501          |\n",
      "|    ep_rew_mean          | -6.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 640          |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 956          |\n",
      "|    total_timesteps      | 612352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001956923 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.69         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.54e+07     |\n",
      "|    n_updates            | 53840        |\n",
      "|    policy_gradient_loss | -0.000756    |\n",
      "|    std                  | 0.224        |\n",
      "|    value_loss           | 9.42e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | -6.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 641          |\n",
      "|    iterations           | 300          |\n",
      "|    time_elapsed         | 957          |\n",
      "|    total_timesteps      | 614400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011391831 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.69         |\n",
      "|    explained_variance   | 0.489        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.86e+07     |\n",
      "|    n_updates            | 53850        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    std                  | 0.224        |\n",
      "|    value_loss           | 4.37e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=615000, episode_reward=-50832.43 +/- 97246.94\n",
      "Episode length: 587.80 +/- 773.25\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 588        |\n",
      "|    mean_reward          | -5.08e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 615000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00401276 |\n",
      "|    clip_fraction        | 0.0152     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.69       |\n",
      "|    explained_variance   | 0.843      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.91e+05   |\n",
      "|    n_updates            | 53860      |\n",
      "|    policy_gradient_loss | -0.0062    |\n",
      "|    std                  | 0.224      |\n",
      "|    value_loss           | 2.6e+06    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 500       |\n",
      "|    ep_rew_mean     | -6.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 641       |\n",
      "|    iterations      | 301       |\n",
      "|    time_elapsed    | 961       |\n",
      "|    total_timesteps | 616448    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 550         |\n",
      "|    ep_rew_mean          | -6.01e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 963         |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029542351 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.71        |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 217         |\n",
      "|    n_updates            | 53870       |\n",
      "|    policy_gradient_loss | 0.00195     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 536         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=-5759.20 +/- 11416.63\n",
      "Episode length: 186.80 +/- 140.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 187         |\n",
      "|    mean_reward          | -5.76e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 620000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007957363 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 53880       |\n",
      "|    policy_gradient_loss | 0.00619     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 7.34e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 500       |\n",
      "|    ep_rew_mean     | -6.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 642       |\n",
      "|    iterations      | 303       |\n",
      "|    time_elapsed    | 965       |\n",
      "|    total_timesteps | 620544    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | -6.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 304          |\n",
      "|    time_elapsed         | 967          |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010096309 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.18e+07     |\n",
      "|    n_updates            | 53890        |\n",
      "|    policy_gradient_loss | -0.000654    |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 8.07e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | -6.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 644          |\n",
      "|    iterations           | 305          |\n",
      "|    time_elapsed         | 969          |\n",
      "|    total_timesteps      | 624640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069297804 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 53900        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 7.15e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=-2670.85 +/- 24947.39\n",
      "Episode length: 756.80 +/- 1229.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 757         |\n",
      "|    mean_reward          | -2.67e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 625000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018521303 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.638       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.6        |\n",
      "|    n_updates            | 53910       |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 496       |\n",
      "|    ep_rew_mean     | -6.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 306       |\n",
      "|    time_elapsed    | 972       |\n",
      "|    total_timesteps | 626688    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 536        |\n",
      "|    ep_rew_mean          | -6.33e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 644        |\n",
      "|    iterations           | 307        |\n",
      "|    time_elapsed         | 975        |\n",
      "|    total_timesteps      | 628736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01613023 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.73       |\n",
      "|    explained_variance   | 0.905      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 65.7       |\n",
      "|    n_updates            | 53920      |\n",
      "|    policy_gradient_loss | 0.00141    |\n",
      "|    std                  | 0.222      |\n",
      "|    value_loss           | 517        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=-64426.66 +/- 74851.76\n",
      "Episode length: 158.40 +/- 154.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 158         |\n",
      "|    mean_reward          | -6.44e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 630000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010122383 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.59e+06    |\n",
      "|    n_updates            | 53930       |\n",
      "|    policy_gradient_loss | 0.00414     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.95e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 556       |\n",
      "|    ep_rew_mean     | -6.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 308       |\n",
      "|    time_elapsed    | 978       |\n",
      "|    total_timesteps | 630784    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 566          |\n",
      "|    ep_rew_mean          | -6.4e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 645          |\n",
      "|    iterations           | 309          |\n",
      "|    time_elapsed         | 980          |\n",
      "|    total_timesteps      | 632832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131467115 |\n",
      "|    clip_fraction        | 0.0682       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.74         |\n",
      "|    explained_variance   | 0.597        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.35e+06     |\n",
      "|    n_updates            | 53940        |\n",
      "|    policy_gradient_loss | -0.00789     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 3.71e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 565         |\n",
      "|    ep_rew_mean          | -6.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 982         |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004229361 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.31e+05    |\n",
      "|    n_updates            | 53950       |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 6.52e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=635000, episode_reward=-24578.66 +/- 41711.16\n",
      "Episode length: 626.60 +/- 1093.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 627         |\n",
      "|    mean_reward          | -2.46e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 635000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004949145 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.67e+03    |\n",
      "|    n_updates            | 53960       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.27e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 521      |\n",
      "|    ep_rew_mean     | -5.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 645      |\n",
      "|    iterations      | 311      |\n",
      "|    time_elapsed    | 986      |\n",
      "|    total_timesteps | 636928   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 518         |\n",
      "|    ep_rew_mean          | -5.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 987         |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001922351 |\n",
      "|    clip_fraction        | 0.00278     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+05    |\n",
      "|    n_updates            | 53970       |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.01e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-9204.27 +/- 45459.40\n",
      "Episode length: 1623.40 +/- 2001.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.62e+03    |\n",
      "|    mean_reward          | -9.2e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 640000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008823989 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 53980       |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 2.31e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 518       |\n",
      "|    ep_rew_mean     | -5.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 313       |\n",
      "|    time_elapsed    | 993       |\n",
      "|    total_timesteps | 641024    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 559         |\n",
      "|    ep_rew_mean          | -5.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 645         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 995         |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009022603 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.75        |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 53990       |\n",
      "|    policy_gradient_loss | -0.000455   |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 1.24e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=645000, episode_reward=-87362.54 +/- 92201.25\n",
      "Episode length: 149.00 +/- 102.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 149         |\n",
      "|    mean_reward          | -8.74e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 645000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012780096 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.76        |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.92e+06    |\n",
      "|    n_updates            | 54000       |\n",
      "|    policy_gradient_loss | 0.00319     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 4.46e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 560       |\n",
      "|    ep_rew_mean     | -5.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 645       |\n",
      "|    iterations      | 315       |\n",
      "|    time_elapsed    | 999       |\n",
      "|    total_timesteps | 645120    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 580          |\n",
      "|    ep_rew_mean          | -4.79e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 646          |\n",
      "|    iterations           | 316          |\n",
      "|    time_elapsed         | 1001         |\n",
      "|    total_timesteps      | 647168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048246556 |\n",
      "|    clip_fraction        | 0.053        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.0029       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.51e+05     |\n",
      "|    n_updates            | 54010        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 7.47e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 603         |\n",
      "|    ep_rew_mean          | -5.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 647         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 1003        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008563176 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.76        |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.49e+04    |\n",
      "|    n_updates            | 54020       |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 2.65e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=-7802.93 +/- 21744.27\n",
      "Episode length: 570.40 +/- 664.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 570         |\n",
      "|    mean_reward          | -7.8e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 650000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002544441 |\n",
      "|    clip_fraction        | 0.0137      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.76        |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.33e+07    |\n",
      "|    n_updates            | 54030       |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 9.01e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 610       |\n",
      "|    ep_rew_mean     | -4.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 646       |\n",
      "|    iterations      | 318       |\n",
      "|    time_elapsed    | 1006      |\n",
      "|    total_timesteps | 651264    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 630           |\n",
      "|    ep_rew_mean          | -4.65e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 647           |\n",
      "|    iterations           | 319           |\n",
      "|    time_elapsed         | 1008          |\n",
      "|    total_timesteps      | 653312        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00092834723 |\n",
      "|    clip_fraction        | 0.00537       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.76          |\n",
      "|    explained_variance   | 0.516         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.76e+07      |\n",
      "|    n_updates            | 54040         |\n",
      "|    policy_gradient_loss | -0.00296      |\n",
      "|    std                  | 0.221         |\n",
      "|    value_loss           | 3.36e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=655000, episode_reward=-17009.32 +/- 25509.07\n",
      "Episode length: 425.20 +/- 425.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 425        |\n",
      "|    mean_reward          | -1.7e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 655000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00325482 |\n",
      "|    clip_fraction        | 0.0164     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.76       |\n",
      "|    explained_variance   | 0.636      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.6e+04    |\n",
      "|    n_updates            | 54050      |\n",
      "|    policy_gradient_loss | -0.00261   |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 7.85e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 630       |\n",
      "|    ep_rew_mean     | -4.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 647       |\n",
      "|    iterations      | 320       |\n",
      "|    time_elapsed    | 1011      |\n",
      "|    total_timesteps | 655360    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 587        |\n",
      "|    ep_rew_mean          | -4.5e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 648        |\n",
      "|    iterations           | 321        |\n",
      "|    time_elapsed         | 1013       |\n",
      "|    total_timesteps      | 657408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01106739 |\n",
      "|    clip_fraction        | 0.0675     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.76       |\n",
      "|    explained_variance   | 0.867      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 719        |\n",
      "|    n_updates            | 54060      |\n",
      "|    policy_gradient_loss | 0.000545   |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 4.8e+03    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 580          |\n",
      "|    ep_rew_mean          | -4.76e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 649          |\n",
      "|    iterations           | 322          |\n",
      "|    time_elapsed         | 1015         |\n",
      "|    total_timesteps      | 659456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033436213 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.77         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33e+07     |\n",
      "|    n_updates            | 54070        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 6.69e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=-1622.43 +/- 13934.88\n",
      "Episode length: 630.40 +/- 649.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 630          |\n",
      "|    mean_reward          | -1.62e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 660000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007399898 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.77         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.6e+07      |\n",
      "|    n_updates            | 54080        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 8.76e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 597       |\n",
      "|    ep_rew_mean     | -5.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 648       |\n",
      "|    iterations      | 323       |\n",
      "|    time_elapsed    | 1019      |\n",
      "|    total_timesteps | 661504    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 558         |\n",
      "|    ep_rew_mean          | -5.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 1021        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001956008 |\n",
      "|    clip_fraction        | 0.00488     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.39e+07    |\n",
      "|    n_updates            | 54090       |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 1.17e+08    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=665000, episode_reward=-110312.65 +/- 92448.29\n",
      "Episode length: 189.20 +/- 213.82\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 189           |\n",
      "|    mean_reward          | -1.1e+05      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 665000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00031739913 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.77          |\n",
      "|    explained_variance   | 0.521         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.03e+07      |\n",
      "|    n_updates            | 54100         |\n",
      "|    policy_gradient_loss | -0.00154      |\n",
      "|    std                  | 0.221         |\n",
      "|    value_loss           | 3.68e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 573       |\n",
      "|    ep_rew_mean     | -5.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 325       |\n",
      "|    time_elapsed    | 1023      |\n",
      "|    total_timesteps | 665600    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 573          |\n",
      "|    ep_rew_mean          | -5.09e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 1025         |\n",
      "|    total_timesteps      | 667648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066807154 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.77         |\n",
      "|    explained_variance   | -0.0124      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59e+04     |\n",
      "|    n_updates            | 54110        |\n",
      "|    policy_gradient_loss | -0.00391     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 1.05e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 620         |\n",
      "|    ep_rew_mean          | -4.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 651         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 1027        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015844854 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 478         |\n",
      "|    n_updates            | 54120       |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=-68239.56 +/- 105510.41\n",
      "Episode length: 677.40 +/- 1074.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 677          |\n",
      "|    mean_reward          | -6.82e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 670000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073871193 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.78         |\n",
      "|    explained_variance   | 0.734        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.16e+03     |\n",
      "|    n_updates            | 54130        |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 1.84e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 634       |\n",
      "|    ep_rew_mean     | -4.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 651       |\n",
      "|    iterations      | 328       |\n",
      "|    time_elapsed    | 1031      |\n",
      "|    total_timesteps | 671744    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 629          |\n",
      "|    ep_rew_mean          | -4.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 652          |\n",
      "|    iterations           | 329          |\n",
      "|    time_elapsed         | 1033         |\n",
      "|    total_timesteps      | 673792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016579998 |\n",
      "|    clip_fraction        | 0.00605      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.78         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.91e+06     |\n",
      "|    n_updates            | 54140        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 1.77e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=-38052.42 +/- 72112.94\n",
      "Episode length: 834.00 +/- 1233.92\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 834           |\n",
      "|    mean_reward          | -3.81e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 675000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086417526 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.78          |\n",
      "|    explained_variance   | 0.533         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.37e+07      |\n",
      "|    n_updates            | 54150         |\n",
      "|    policy_gradient_loss | -0.000686     |\n",
      "|    std                  | 0.222         |\n",
      "|    value_loss           | 4.32e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 650       |\n",
      "|    ep_rew_mean     | -4.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 330       |\n",
      "|    time_elapsed    | 1038      |\n",
      "|    total_timesteps | 675840    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 661        |\n",
      "|    ep_rew_mean          | -4.62e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 651        |\n",
      "|    iterations           | 331        |\n",
      "|    time_elapsed         | 1040       |\n",
      "|    total_timesteps      | 677888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00580153 |\n",
      "|    clip_fraction        | 0.024      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.78       |\n",
      "|    explained_variance   | 0.869      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.2e+06    |\n",
      "|    n_updates            | 54160      |\n",
      "|    policy_gradient_loss | -0.00231   |\n",
      "|    std                  | 0.222      |\n",
      "|    value_loss           | 6.65e+05   |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 671           |\n",
      "|    ep_rew_mean          | -4.98e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 651           |\n",
      "|    iterations           | 332           |\n",
      "|    time_elapsed         | 1043          |\n",
      "|    total_timesteps      | 679936        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018804835 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.78          |\n",
      "|    explained_variance   | 0.715         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.36e+06      |\n",
      "|    n_updates            | 54170         |\n",
      "|    policy_gradient_loss | -9.92e-05     |\n",
      "|    std                  | 0.222         |\n",
      "|    value_loss           | 3.97e+06      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=680000, episode_reward=-73121.36 +/- 53528.60\n",
      "Episode length: 62.60 +/- 37.47\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 62.6         |\n",
      "|    mean_reward          | -7.31e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 680000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026133973 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.78         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.74e+07     |\n",
      "|    n_updates            | 54180        |\n",
      "|    policy_gradient_loss | -0.000885    |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 6.45e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 682       |\n",
      "|    ep_rew_mean     | -4.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 652       |\n",
      "|    iterations      | 333       |\n",
      "|    time_elapsed    | 1045      |\n",
      "|    total_timesteps | 681984    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 682          |\n",
      "|    ep_rew_mean          | -4.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 653          |\n",
      "|    iterations           | 334          |\n",
      "|    time_elapsed         | 1047         |\n",
      "|    total_timesteps      | 684032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019441075 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.78         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.96e+06     |\n",
      "|    n_updates            | 54190        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 2.22e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=685000, episode_reward=-86714.22 +/- 95047.66\n",
      "Episode length: 319.80 +/- 416.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 320         |\n",
      "|    mean_reward          | -8.67e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 685000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016156774 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 54200       |\n",
      "|    policy_gradient_loss | 0.00333     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 762         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 649       |\n",
      "|    ep_rew_mean     | -5.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 653       |\n",
      "|    iterations      | 335       |\n",
      "|    time_elapsed    | 1049      |\n",
      "|    total_timesteps | 686080    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 649          |\n",
      "|    ep_rew_mean          | -5.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 654          |\n",
      "|    iterations           | 336          |\n",
      "|    time_elapsed         | 1051         |\n",
      "|    total_timesteps      | 688128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036031427 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.79         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59e+07     |\n",
      "|    n_updates            | 54210        |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 7.08e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=-70016.29 +/- 96325.75\n",
      "Episode length: 1765.20 +/- 2097.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.77e+03    |\n",
      "|    mean_reward          | -7e+04      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 690000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036539182 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90.9        |\n",
      "|    n_updates            | 54220       |\n",
      "|    policy_gradient_loss | 0.00285     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 410         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 697       |\n",
      "|    ep_rew_mean     | -4.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 652       |\n",
      "|    iterations      | 337       |\n",
      "|    time_elapsed    | 1058      |\n",
      "|    total_timesteps | 690176    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 645         |\n",
      "|    ep_rew_mean          | -5.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 1060        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013815509 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.8         |\n",
      "|    explained_variance   | -0.136      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 230         |\n",
      "|    n_updates            | 54230       |\n",
      "|    policy_gradient_loss | 0.000878    |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 4.27e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 629       |\n",
      "|    ep_rew_mean          | -5.7e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 653       |\n",
      "|    iterations           | 339       |\n",
      "|    time_elapsed         | 1062      |\n",
      "|    total_timesteps      | 694272    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0201461 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.8       |\n",
      "|    explained_variance   | 0.451     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.1e+07   |\n",
      "|    n_updates            | 54240     |\n",
      "|    policy_gradient_loss | 0.0183    |\n",
      "|    std                  | 0.22      |\n",
      "|    value_loss           | 1.44e+08  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=695000, episode_reward=-51231.61 +/- 66869.51\n",
      "Episode length: 344.00 +/- 414.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 344          |\n",
      "|    mean_reward          | -5.12e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 695000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010238942 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.8          |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+07     |\n",
      "|    n_updates            | 54250        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 4.18e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 629      |\n",
      "|    ep_rew_mean     | -5.7e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 653      |\n",
      "|    iterations      | 340      |\n",
      "|    time_elapsed    | 1065     |\n",
      "|    total_timesteps | 696320   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 661         |\n",
      "|    ep_rew_mean          | -6.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 1067        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011356702 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.81        |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 364         |\n",
      "|    n_updates            | 54260       |\n",
      "|    policy_gradient_loss | -0.000756   |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1e+03       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=-85980.87 +/- 107230.69\n",
      "Episode length: 187.80 +/- 126.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 188         |\n",
      "|    mean_reward          | -8.6e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005184341 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.82        |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.17e+07    |\n",
      "|    n_updates            | 54270       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 7.03e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 636       |\n",
      "|    ep_rew_mean     | -6.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 654       |\n",
      "|    iterations      | 342       |\n",
      "|    time_elapsed    | 1069      |\n",
      "|    total_timesteps | 700416    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 636           |\n",
      "|    ep_rew_mean          | -6.03e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 655           |\n",
      "|    iterations           | 343           |\n",
      "|    time_elapsed         | 1071          |\n",
      "|    total_timesteps      | 702464        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00020572536 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.81          |\n",
      "|    explained_variance   | 0.558         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.4e+05       |\n",
      "|    n_updates            | 54280         |\n",
      "|    policy_gradient_loss | -0.000756     |\n",
      "|    std                  | 0.22          |\n",
      "|    value_loss           | 1.24e+06      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -6.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 1073        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028318044 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 54290       |\n",
      "|    policy_gradient_loss | 0.00996     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=705000, episode_reward=-77712.95 +/- 97327.85\n",
      "Episode length: 111.60 +/- 36.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 112         |\n",
      "|    mean_reward          | -7.77e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 705000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010386074 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.3e+06     |\n",
      "|    n_updates            | 54300       |\n",
      "|    policy_gradient_loss | 0.00139     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 1.34e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 670       |\n",
      "|    ep_rew_mean     | -6.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 656       |\n",
      "|    iterations      | 345       |\n",
      "|    time_elapsed    | 1075      |\n",
      "|    total_timesteps | 706560    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 702          |\n",
      "|    ep_rew_mean          | -6.65e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 657          |\n",
      "|    iterations           | 346          |\n",
      "|    time_elapsed         | 1077         |\n",
      "|    total_timesteps      | 708608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011121004 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.48e+07     |\n",
      "|    n_updates            | 54310        |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    std                  | 0.219        |\n",
      "|    value_loss           | 7.8e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=-13867.19 +/- 14059.73\n",
      "Episode length: 652.80 +/- 1073.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 653          |\n",
      "|    mean_reward          | -1.39e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 710000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020037508 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.699        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+06     |\n",
      "|    n_updates            | 54320        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    std                  | 0.219        |\n",
      "|    value_loss           | 3.51e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 736      |\n",
      "|    ep_rew_mean     | -6.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 657      |\n",
      "|    iterations      | 347      |\n",
      "|    time_elapsed    | 1081     |\n",
      "|    total_timesteps | 710656   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 736          |\n",
      "|    ep_rew_mean          | -6.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 657          |\n",
      "|    iterations           | 348          |\n",
      "|    time_elapsed         | 1083         |\n",
      "|    total_timesteps      | 712704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033922927 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.31e+03     |\n",
      "|    n_updates            | 54330        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    std                  | 0.219        |\n",
      "|    value_loss           | 1.05e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 724         |\n",
      "|    ep_rew_mean          | -7.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 658         |\n",
      "|    iterations           | 349         |\n",
      "|    time_elapsed         | 1085        |\n",
      "|    total_timesteps      | 714752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009953931 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 54340       |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 537         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=715000, episode_reward=-94933.65 +/- 84185.72\n",
      "Episode length: 221.00 +/- 231.86\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 221          |\n",
      "|    mean_reward          | -9.49e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 715000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046526096 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.519        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.61e+07     |\n",
      "|    n_updates            | 54350        |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    std                  | 0.218        |\n",
      "|    value_loss           | 1.28e+08     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 666      |\n",
      "|    ep_rew_mean     | -6.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 659      |\n",
      "|    iterations      | 350      |\n",
      "|    time_elapsed    | 1087     |\n",
      "|    total_timesteps | 716800   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 622          |\n",
      "|    ep_rew_mean          | -7.16e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 659          |\n",
      "|    iterations           | 351          |\n",
      "|    time_elapsed         | 1089         |\n",
      "|    total_timesteps      | 718848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.480315e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.57e+07     |\n",
      "|    n_updates            | 54360        |\n",
      "|    policy_gradient_loss | -0.000406    |\n",
      "|    std                  | 0.218        |\n",
      "|    value_loss           | 5.8e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=-56893.14 +/- 85291.67\n",
      "Episode length: 195.80 +/- 90.95\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 196           |\n",
      "|    mean_reward          | -5.69e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 720000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035263866 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.85          |\n",
      "|    explained_variance   | 0.495         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.01e+07      |\n",
      "|    n_updates            | 54370         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    std                  | 0.218         |\n",
      "|    value_loss           | 7.42e+07      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 621      |\n",
      "|    ep_rew_mean     | -7.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 660      |\n",
      "|    iterations      | 352      |\n",
      "|    time_elapsed    | 1092     |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 657         |\n",
      "|    ep_rew_mean          | -7.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 660         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 1094        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005319656 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05e+07    |\n",
      "|    n_updates            | 54380       |\n",
      "|    policy_gradient_loss | 0.00137     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 4.18e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 658          |\n",
      "|    ep_rew_mean          | -7.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 661          |\n",
      "|    iterations           | 354          |\n",
      "|    time_elapsed         | 1095         |\n",
      "|    total_timesteps      | 724992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020681217 |\n",
      "|    clip_fraction        | 0.00791      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.537        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.92e+07     |\n",
      "|    n_updates            | 54390        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    std                  | 0.218        |\n",
      "|    value_loss           | 8.92e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=-27811.07 +/- 52828.86\n",
      "Episode length: 252.80 +/- 157.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 253         |\n",
      "|    mean_reward          | -2.78e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 725000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010173837 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13e+07    |\n",
      "|    n_updates            | 54400       |\n",
      "|    policy_gradient_loss | 0.00258     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 4.69e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 658       |\n",
      "|    ep_rew_mean     | -7.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 661       |\n",
      "|    iterations      | 355       |\n",
      "|    time_elapsed    | 1098      |\n",
      "|    total_timesteps | 727040    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 696         |\n",
      "|    ep_rew_mean          | -7.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 1100        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006142175 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+03    |\n",
      "|    n_updates            | 54410       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 3.78e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=730000, episode_reward=-10753.71 +/- 10394.18\n",
      "Episode length: 222.00 +/- 128.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 222          |\n",
      "|    mean_reward          | -1.08e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 730000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017057378 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.87         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+07     |\n",
      "|    n_updates            | 54420        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 6.81e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 695       |\n",
      "|    ep_rew_mean     | -7.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 662       |\n",
      "|    iterations      | 357       |\n",
      "|    time_elapsed    | 1102      |\n",
      "|    total_timesteps | 731136    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 695         |\n",
      "|    ep_rew_mean          | -7.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 1104        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011224893 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.87        |\n",
      "|    explained_variance   | 0.313       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 579         |\n",
      "|    n_updates            | 54430       |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 4.63e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=735000, episode_reward=-25183.84 +/- 16148.04\n",
      "Episode length: 100.00 +/- 88.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 100         |\n",
      "|    mean_reward          | -2.52e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 735000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013349973 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.88        |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 651         |\n",
      "|    n_updates            | 54440       |\n",
      "|    policy_gradient_loss | -0.00859    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 734       |\n",
      "|    ep_rew_mean     | -7.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 664       |\n",
      "|    iterations      | 359       |\n",
      "|    time_elapsed    | 1107      |\n",
      "|    total_timesteps | 735232    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 753         |\n",
      "|    ep_rew_mean          | -6.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 664         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 1109        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009280791 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.38e+03    |\n",
      "|    n_updates            | 54450       |\n",
      "|    policy_gradient_loss | -0.0053     |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 1.2e+05     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 753          |\n",
      "|    ep_rew_mean          | -6.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 665          |\n",
      "|    iterations           | 361          |\n",
      "|    time_elapsed         | 1110         |\n",
      "|    total_timesteps      | 739328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004910899 |\n",
      "|    clip_fraction        | 0.00161      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.446        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.15e+07     |\n",
      "|    n_updates            | 54460        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 3.97e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=-95478.48 +/- 80256.01\n",
      "Episode length: 1327.20 +/- 1859.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.33e+03    |\n",
      "|    mean_reward          | -9.55e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 740000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006780946 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 54470       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 706       |\n",
      "|    ep_rew_mean     | -7.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 664       |\n",
      "|    iterations      | 362       |\n",
      "|    time_elapsed    | 1116      |\n",
      "|    total_timesteps | 741376    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 716          |\n",
      "|    ep_rew_mean          | -7.58e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 363          |\n",
      "|    time_elapsed         | 1118         |\n",
      "|    total_timesteps      | 743424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018587017 |\n",
      "|    clip_fraction        | 0.00571      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.506        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.97e+07     |\n",
      "|    n_updates            | 54480        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 1.09e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=745000, episode_reward=-7011.99 +/- 15472.12\n",
      "Episode length: 1201.40 +/- 1904.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.2e+03     |\n",
      "|    mean_reward          | -7.01e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 745000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006099852 |\n",
      "|    clip_fraction        | 0.0318      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34e+06    |\n",
      "|    n_updates            | 54490       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 8.15e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 728       |\n",
      "|    ep_rew_mean     | -7.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 663       |\n",
      "|    iterations      | 364       |\n",
      "|    time_elapsed    | 1123      |\n",
      "|    total_timesteps | 745472    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | -7.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 662          |\n",
      "|    iterations           | 365          |\n",
      "|    time_elapsed         | 1128         |\n",
      "|    total_timesteps      | 747520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049549844 |\n",
      "|    clip_fraction        | 0.0366       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.37e+07     |\n",
      "|    n_updates            | 54500        |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 2.88e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 721         |\n",
      "|    ep_rew_mean          | -7.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 662         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 1130        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001293203 |\n",
      "|    clip_fraction        | 0.00205     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.55e+06    |\n",
      "|    n_updates            | 54510       |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 3.34e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=-56525.58 +/- 62409.36\n",
      "Episode length: 74.20 +/- 73.01\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 74.2         |\n",
      "|    mean_reward          | -5.65e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 750000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074467966 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.29e+07     |\n",
      "|    n_updates            | 54520        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 2.96e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 722       |\n",
      "|    ep_rew_mean     | -7.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 663       |\n",
      "|    iterations      | 367       |\n",
      "|    time_elapsed    | 1133      |\n",
      "|    total_timesteps | 751616    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 740          |\n",
      "|    ep_rew_mean          | -7.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 368          |\n",
      "|    time_elapsed         | 1135         |\n",
      "|    total_timesteps      | 753664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035364479 |\n",
      "|    clip_fraction        | 0.0161       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.19e+06     |\n",
      "|    n_updates            | 54530        |\n",
      "|    policy_gradient_loss | -0.00124     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 1.23e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=755000, episode_reward=-40750.22 +/- 56713.99\n",
      "Episode length: 163.00 +/- 57.27\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 163          |\n",
      "|    mean_reward          | -4.08e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 755000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049988152 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.725        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17e+04     |\n",
      "|    n_updates            | 54540        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 7.84e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 748       |\n",
      "|    ep_rew_mean     | -7.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 664       |\n",
      "|    iterations      | 369       |\n",
      "|    time_elapsed    | 1137      |\n",
      "|    total_timesteps | 755712    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 722          |\n",
      "|    ep_rew_mean          | -7.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 370          |\n",
      "|    time_elapsed         | 1139         |\n",
      "|    total_timesteps      | 757760       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047350265 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59e+05     |\n",
      "|    n_updates            | 54550        |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 2.68e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 682          |\n",
      "|    ep_rew_mean          | -6.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 665          |\n",
      "|    iterations           | 371          |\n",
      "|    time_elapsed         | 1141         |\n",
      "|    total_timesteps      | 759808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026767068 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86e+06     |\n",
      "|    n_updates            | 54560        |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 1.58e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=-74595.84 +/- 82706.92\n",
      "Episode length: 476.20 +/- 376.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 476         |\n",
      "|    mean_reward          | -7.46e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003435159 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.82e+04    |\n",
      "|    n_updates            | 54570       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 3.08e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 690       |\n",
      "|    ep_rew_mean     | -6.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 665       |\n",
      "|    iterations      | 372       |\n",
      "|    time_elapsed    | 1144      |\n",
      "|    total_timesteps | 761856    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 599          |\n",
      "|    ep_rew_mean          | -5.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 666          |\n",
      "|    iterations           | 373          |\n",
      "|    time_elapsed         | 1146         |\n",
      "|    total_timesteps      | 763904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044584014 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.58e+06     |\n",
      "|    n_updates            | 54580        |\n",
      "|    policy_gradient_loss | -0.00231     |\n",
      "|    std                  | 0.217        |\n",
      "|    value_loss           | 2.58e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=765000, episode_reward=-91137.89 +/- 108709.32\n",
      "Episode length: 392.60 +/- 347.79\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 393           |\n",
      "|    mean_reward          | -9.11e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 765000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034775963 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.89          |\n",
      "|    explained_variance   | 0.578         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.02e+06      |\n",
      "|    n_updates            | 54590         |\n",
      "|    policy_gradient_loss | -0.000655     |\n",
      "|    std                  | 0.217         |\n",
      "|    value_loss           | 8.67e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 515       |\n",
      "|    ep_rew_mean     | -5.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 666       |\n",
      "|    iterations      | 374       |\n",
      "|    time_elapsed    | 1149      |\n",
      "|    total_timesteps | 765952    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 526          |\n",
      "|    ep_rew_mean          | -4.81e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 667          |\n",
      "|    iterations           | 375          |\n",
      "|    time_elapsed         | 1151         |\n",
      "|    total_timesteps      | 768000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016535737 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.89         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+07     |\n",
      "|    n_updates            | 54600        |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 2.45e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=-39526.44 +/- 49324.79\n",
      "Episode length: 326.40 +/- 224.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 326         |\n",
      "|    mean_reward          | -3.95e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 770000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004684993 |\n",
      "|    clip_fraction        | 0.0233      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.79e+04    |\n",
      "|    n_updates            | 54610       |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 3.78e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 547       |\n",
      "|    ep_rew_mean     | -4.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 667       |\n",
      "|    iterations      | 376       |\n",
      "|    time_elapsed    | 1154      |\n",
      "|    total_timesteps | 770048    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 543         |\n",
      "|    ep_rew_mean          | -4.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 667         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 1155        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002972906 |\n",
      "|    clip_fraction        | 0.0342      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.84e+06    |\n",
      "|    n_updates            | 54620       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 1.75e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 578         |\n",
      "|    ep_rew_mean          | -4.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 1157        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014699761 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.15e+03    |\n",
      "|    n_updates            | 54630       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 5.84e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=-77666.41 +/- 79640.03\n",
      "Episode length: 288.20 +/- 112.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 288          |\n",
      "|    mean_reward          | -7.77e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 775000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0100193955 |\n",
      "|    clip_fraction        | 0.0937       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.56e+03     |\n",
      "|    n_updates            | 54640        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 1.64e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 596       |\n",
      "|    ep_rew_mean     | -4.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 668       |\n",
      "|    iterations      | 379       |\n",
      "|    time_elapsed    | 1160      |\n",
      "|    total_timesteps | 776192    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 614         |\n",
      "|    ep_rew_mean          | -4.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 669         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 1162        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012171373 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.9         |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.01e+03    |\n",
      "|    n_updates            | 54650       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 2.24e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=780000, episode_reward=-54551.81 +/- 73936.34\n",
      "Episode length: 199.60 +/- 249.19\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 200          |\n",
      "|    mean_reward          | -5.46e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 780000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026646089 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.23e+06     |\n",
      "|    n_updates            | 54660        |\n",
      "|    policy_gradient_loss | -0.000454    |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 2.04e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 564       |\n",
      "|    ep_rew_mean     | -3.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 669       |\n",
      "|    iterations      | 381       |\n",
      "|    time_elapsed    | 1165      |\n",
      "|    total_timesteps | 780288    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 586          |\n",
      "|    ep_rew_mean          | -3.65e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 670          |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 1166         |\n",
      "|    total_timesteps      | 782336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010042317 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.467        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.8e+07      |\n",
      "|    n_updates            | 54670        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 9.64e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 558          |\n",
      "|    ep_rew_mean          | -3.59e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 671          |\n",
      "|    iterations           | 383          |\n",
      "|    time_elapsed         | 1168         |\n",
      "|    total_timesteps      | 784384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024529565 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+05     |\n",
      "|    n_updates            | 54680        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 5.04e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=785000, episode_reward=-77695.11 +/- 57822.82\n",
      "Episode length: 466.40 +/- 341.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 466         |\n",
      "|    mean_reward          | -7.77e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 785000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011220113 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.9         |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.69e+03    |\n",
      "|    n_updates            | 54690       |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 8.98e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 520       |\n",
      "|    ep_rew_mean     | -3.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 670       |\n",
      "|    iterations      | 384       |\n",
      "|    time_elapsed    | 1172      |\n",
      "|    total_timesteps | 786432    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 476          |\n",
      "|    ep_rew_mean          | -3.36e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 671          |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 1173         |\n",
      "|    total_timesteps      | 788480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022048478 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.536        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+07     |\n",
      "|    n_updates            | 54700        |\n",
      "|    policy_gradient_loss | 0.000158     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 1.84e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=-10746.57 +/- 7995.59\n",
      "Episode length: 83.40 +/- 72.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 83.4         |\n",
      "|    mean_reward          | -1.07e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 790000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011495913 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.485        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.79e+07     |\n",
      "|    n_updates            | 54710        |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 6.65e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 471       |\n",
      "|    ep_rew_mean     | -3.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 672       |\n",
      "|    iterations      | 386       |\n",
      "|    time_elapsed    | 1176      |\n",
      "|    total_timesteps | 790528    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 489          |\n",
      "|    ep_rew_mean          | -2.87e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 672          |\n",
      "|    iterations           | 387          |\n",
      "|    time_elapsed         | 1178         |\n",
      "|    total_timesteps      | 792576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042707575 |\n",
      "|    clip_fraction        | 0.0227       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+04     |\n",
      "|    n_updates            | 54720        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 1.84e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 470         |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 673         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 1180        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012660803 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.9         |\n",
      "|    explained_variance   | 0.712       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.47e+04    |\n",
      "|    n_updates            | 54730       |\n",
      "|    policy_gradient_loss | -0.00103    |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 4.1e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=795000, episode_reward=-51251.03 +/- 81899.95\n",
      "Episode length: 85.20 +/- 68.10\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 85.2         |\n",
      "|    mean_reward          | -5.13e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 795000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064244457 |\n",
      "|    clip_fraction        | 0.0518       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.9          |\n",
      "|    explained_variance   | 0.49         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+05     |\n",
      "|    n_updates            | 54740        |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    std                  | 0.215        |\n",
      "|    value_loss           | 3.04e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 470       |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 389       |\n",
      "|    time_elapsed    | 1182      |\n",
      "|    total_timesteps | 796672    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 516        |\n",
      "|    ep_rew_mean          | -2.79e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 674        |\n",
      "|    iterations           | 390        |\n",
      "|    time_elapsed         | 1184       |\n",
      "|    total_timesteps      | 798720     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00723736 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.91       |\n",
      "|    explained_variance   | 0.952      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 884        |\n",
      "|    n_updates            | 54750      |\n",
      "|    policy_gradient_loss | -0.00289   |\n",
      "|    std                  | 0.214      |\n",
      "|    value_loss           | 3.02e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=-17130.91 +/- 27998.24\n",
      "Episode length: 1080.80 +/- 1920.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.08e+03     |\n",
      "|    mean_reward          | -1.71e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 800000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071622143 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.868        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.11e+03     |\n",
      "|    n_updates            | 54760        |\n",
      "|    policy_gradient_loss | 2.93e-05     |\n",
      "|    std                  | 0.214        |\n",
      "|    value_loss           | 3.16e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 495       |\n",
      "|    ep_rew_mean     | -2.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 391       |\n",
      "|    time_elapsed    | 1189      |\n",
      "|    total_timesteps | 800768    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 505         |\n",
      "|    ep_rew_mean          | -2.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 1191        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004886276 |\n",
      "|    clip_fraction        | 0.0394      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | 0.649       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.65e+03    |\n",
      "|    n_updates            | 54770       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    std                  | 0.215       |\n",
      "|    value_loss           | 2.36e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 505         |\n",
      "|    ep_rew_mean          | -2.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 1193        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008287445 |\n",
      "|    clip_fraction        | 0.0586      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | 0.191       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.33e+03    |\n",
      "|    n_updates            | 54780       |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    std                  | 0.215       |\n",
      "|    value_loss           | 1.22e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=805000, episode_reward=-19257.87 +/- 67514.65\n",
      "Episode length: 1372.20 +/- 1845.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.37e+03    |\n",
      "|    mean_reward          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 805000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009424116 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.93        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 509         |\n",
      "|    n_updates            | 54790       |\n",
      "|    policy_gradient_loss | 0.00447     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 537       |\n",
      "|    ep_rew_mean     | -2.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 394       |\n",
      "|    time_elapsed    | 1198      |\n",
      "|    total_timesteps | 806912    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 537          |\n",
      "|    ep_rew_mean          | -2.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 673          |\n",
      "|    iterations           | 395          |\n",
      "|    time_elapsed         | 1200         |\n",
      "|    total_timesteps      | 808960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049211057 |\n",
      "|    clip_fraction        | 0.0287       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.94         |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+04     |\n",
      "|    n_updates            | 54800        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 6.32e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=-6571.12 +/- 19408.97\n",
      "Episode length: 427.60 +/- 344.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 428         |\n",
      "|    mean_reward          | -6.57e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 810000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009951867 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 54810       |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 2.13e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 537       |\n",
      "|    ep_rew_mean     | -2.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 396       |\n",
      "|    time_elapsed    | 1203      |\n",
      "|    total_timesteps | 811008    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 562         |\n",
      "|    ep_rew_mean          | -2.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 674         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 1205        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014009013 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 302         |\n",
      "|    n_updates            | 54820       |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=815000, episode_reward=3421.22 +/- 28449.95\n",
      "Episode length: 1497.40 +/- 1780.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.5e+03     |\n",
      "|    mean_reward          | 3.42e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 815000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012632687 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.53e+06    |\n",
      "|    n_updates            | 54830       |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 3.34e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 557      |\n",
      "|    ep_rew_mean     | -3.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 672      |\n",
      "|    iterations      | 398      |\n",
      "|    time_elapsed    | 1211     |\n",
      "|    total_timesteps | 815104   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 539          |\n",
      "|    ep_rew_mean          | -3.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 673          |\n",
      "|    iterations           | 399          |\n",
      "|    time_elapsed         | 1213         |\n",
      "|    total_timesteps      | 817152       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015789237 |\n",
      "|    clip_fraction        | 0.00586      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.466        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.99e+07     |\n",
      "|    n_updates            | 54840        |\n",
      "|    policy_gradient_loss | -0.00386     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 1.13e+08     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 539           |\n",
      "|    ep_rew_mean          | -3.53e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 674           |\n",
      "|    iterations           | 400           |\n",
      "|    time_elapsed         | 1215          |\n",
      "|    total_timesteps      | 819200        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063769356 |\n",
      "|    clip_fraction        | 0.000586      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.92          |\n",
      "|    explained_variance   | 0.517         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.96e+07      |\n",
      "|    n_updates            | 54850         |\n",
      "|    policy_gradient_loss | -0.00141      |\n",
      "|    std                  | 0.213         |\n",
      "|    value_loss           | 6.58e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=-42469.03 +/- 64162.44\n",
      "Episode length: 214.20 +/- 142.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 214         |\n",
      "|    mean_reward          | -4.25e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010336818 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 774         |\n",
      "|    n_updates            | 54860       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 2.34e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 589       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 674       |\n",
      "|    iterations      | 401       |\n",
      "|    time_elapsed    | 1217      |\n",
      "|    total_timesteps | 821248    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 589         |\n",
      "|    ep_rew_mean          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 1219        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020614065 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.7e+03     |\n",
      "|    n_updates            | 54870       |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 1.29e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=825000, episode_reward=-36436.29 +/- 59304.09\n",
      "Episode length: 212.00 +/- 177.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 212          |\n",
      "|    mean_reward          | -3.64e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 825000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101290215 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 54880        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 2.06e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 589       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 675       |\n",
      "|    iterations      | 403       |\n",
      "|    time_elapsed    | 1222      |\n",
      "|    total_timesteps | 825344    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 636          |\n",
      "|    ep_rew_mean          | -3.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 675          |\n",
      "|    iterations           | 404          |\n",
      "|    time_elapsed         | 1224         |\n",
      "|    total_timesteps      | 827392       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094954325 |\n",
      "|    clip_fraction        | 0.0662       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.787        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.87e+03     |\n",
      "|    n_updates            | 54890        |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 4.13e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 636          |\n",
      "|    ep_rew_mean          | -3.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 676          |\n",
      "|    iterations           | 405          |\n",
      "|    time_elapsed         | 1226         |\n",
      "|    total_timesteps      | 829440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014241261 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.559        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.6e+06      |\n",
      "|    n_updates            | 54900        |\n",
      "|    policy_gradient_loss | -0.000308    |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 1.32e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=-75286.80 +/- 96110.52\n",
      "Episode length: 219.40 +/- 135.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 219          |\n",
      "|    mean_reward          | -7.53e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 830000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075976187 |\n",
      "|    clip_fraction        | 0.091        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.92         |\n",
      "|    explained_variance   | 0.834        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 894          |\n",
      "|    n_updates            | 54910        |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 4.13e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 686       |\n",
      "|    ep_rew_mean     | -3.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 676       |\n",
      "|    iterations      | 406       |\n",
      "|    time_elapsed    | 1228      |\n",
      "|    total_timesteps | 831488    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 681         |\n",
      "|    ep_rew_mean          | -3.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 677         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 1230        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006639648 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.93        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.59e+06    |\n",
      "|    n_updates            | 54920       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 1.73e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=835000, episode_reward=-16170.70 +/- 13200.91\n",
      "Episode length: 476.20 +/- 407.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 476          |\n",
      "|    mean_reward          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 835000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018767264 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.93         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+07      |\n",
      "|    n_updates            | 54930        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 2.15e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 681       |\n",
      "|    ep_rew_mean     | -3.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 677       |\n",
      "|    iterations      | 408       |\n",
      "|    time_elapsed    | 1233      |\n",
      "|    total_timesteps | 835584    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 710        |\n",
      "|    ep_rew_mean          | -3.66e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 677        |\n",
      "|    iterations           | 409        |\n",
      "|    time_elapsed         | 1235       |\n",
      "|    total_timesteps      | 837632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01391153 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.93       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 300        |\n",
      "|    n_updates            | 54940      |\n",
      "|    policy_gradient_loss | -0.00314   |\n",
      "|    std                  | 0.213      |\n",
      "|    value_loss           | 1.69e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 714         |\n",
      "|    ep_rew_mean          | -3.66e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 678         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 1237        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008935408 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.33e+05    |\n",
      "|    n_updates            | 54950       |\n",
      "|    policy_gradient_loss | 0.00783     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 2.34e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=-88097.59 +/- 85254.69\n",
      "Episode length: 1196.00 +/- 1493.24\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.2e+03      |\n",
      "|    mean_reward          | -8.81e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 840000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026488993 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.94         |\n",
      "|    explained_variance   | 0.838        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.36e+03     |\n",
      "|    n_updates            | 54960        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    std                  | 0.213        |\n",
      "|    value_loss           | 3.51e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 714       |\n",
      "|    ep_rew_mean     | -3.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 677       |\n",
      "|    iterations      | 411       |\n",
      "|    time_elapsed    | 1242      |\n",
      "|    total_timesteps | 841728    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 733         |\n",
      "|    ep_rew_mean          | -3.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 677         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 1244        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018949378 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 353         |\n",
      "|    n_updates            | 54970       |\n",
      "|    policy_gradient_loss | -0.00094    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.73e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=845000, episode_reward=47.21 +/- 8008.89\n",
      "Episode length: 476.60 +/- 358.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 477          |\n",
      "|    mean_reward          | 47.2         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 845000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070271953 |\n",
      "|    clip_fraction        | 0.133        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.19e+06     |\n",
      "|    n_updates            | 54980        |\n",
      "|    policy_gradient_loss | -0.000834    |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.44e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 677       |\n",
      "|    ep_rew_mean     | -3.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 677       |\n",
      "|    iterations      | 413       |\n",
      "|    time_elapsed    | 1247      |\n",
      "|    total_timesteps | 845824    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 679          |\n",
      "|    ep_rew_mean          | -3.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 678          |\n",
      "|    iterations           | 414          |\n",
      "|    time_elapsed         | 1249         |\n",
      "|    total_timesteps      | 847872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011324476 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.44e+06     |\n",
      "|    n_updates            | 54990        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.27e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 677          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 679          |\n",
      "|    iterations           | 415          |\n",
      "|    time_elapsed         | 1251         |\n",
      "|    total_timesteps      | 849920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006531159 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.78e+07     |\n",
      "|    n_updates            | 55000        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.1e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=-44795.11 +/- 56224.99\n",
      "Episode length: 1155.20 +/- 1459.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.16e+03     |\n",
      "|    mean_reward          | -4.48e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 850000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009786575 |\n",
      "|    clip_fraction        | 0.00352      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.518        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.57e+07     |\n",
      "|    n_updates            | 55010        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.63e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 653       |\n",
      "|    ep_rew_mean     | -3.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 678       |\n",
      "|    iterations      | 416       |\n",
      "|    time_elapsed    | 1256      |\n",
      "|    total_timesteps | 851968    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 664          |\n",
      "|    ep_rew_mean          | -3.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 678          |\n",
      "|    iterations           | 417          |\n",
      "|    time_elapsed         | 1258         |\n",
      "|    total_timesteps      | 854016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013027206 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.08e+07     |\n",
      "|    n_updates            | 55020        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.63e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=855000, episode_reward=-45565.00 +/- 49079.00\n",
      "Episode length: 747.20 +/- 495.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 747          |\n",
      "|    mean_reward          | -4.56e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 855000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018708906 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+07     |\n",
      "|    n_updates            | 55030        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.49e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 683       |\n",
      "|    ep_rew_mean     | -3.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 678       |\n",
      "|    iterations      | 418       |\n",
      "|    time_elapsed    | 1262      |\n",
      "|    total_timesteps | 856064    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 700        |\n",
      "|    ep_rew_mean          | -3.47e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 678        |\n",
      "|    iterations           | 419        |\n",
      "|    time_elapsed         | 1264       |\n",
      "|    total_timesteps      | 858112     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00761073 |\n",
      "|    clip_fraction        | 0.0586     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.95       |\n",
      "|    explained_variance   | 0.671      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.03e+03   |\n",
      "|    n_updates            | 55040      |\n",
      "|    policy_gradient_loss | -0.0059    |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 1.13e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=-82440.88 +/- 51490.48\n",
      "Episode length: 166.40 +/- 187.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 166          |\n",
      "|    mean_reward          | -8.24e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 860000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006053442 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+07     |\n",
      "|    n_updates            | 55050        |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.87e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 700       |\n",
      "|    ep_rew_mean     | -3.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 679       |\n",
      "|    iterations      | 420       |\n",
      "|    time_elapsed    | 1266      |\n",
      "|    total_timesteps | 860160    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 696          |\n",
      "|    ep_rew_mean          | -3.51e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 679          |\n",
      "|    iterations           | 421          |\n",
      "|    time_elapsed         | 1268         |\n",
      "|    total_timesteps      | 862208       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034942504 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.582        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+05     |\n",
      "|    n_updates            | 55060        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.17e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 699          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 680          |\n",
      "|    iterations           | 422          |\n",
      "|    time_elapsed         | 1270         |\n",
      "|    total_timesteps      | 864256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076560695 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.71e+04     |\n",
      "|    n_updates            | 55070        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.36e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=865000, episode_reward=-34212.98 +/- 52552.68\n",
      "Episode length: 481.60 +/- 473.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 482         |\n",
      "|    mean_reward          | -3.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 865000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016955333 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 616         |\n",
      "|    n_updates            | 55080       |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 4.25e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 671       |\n",
      "|    ep_rew_mean     | -3.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 423       |\n",
      "|    time_elapsed    | 1273      |\n",
      "|    total_timesteps | 866304    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 664          |\n",
      "|    ep_rew_mean          | -3.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 680          |\n",
      "|    iterations           | 424          |\n",
      "|    time_elapsed         | 1275         |\n",
      "|    total_timesteps      | 868352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054288986 |\n",
      "|    clip_fraction        | 0.0667       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.686        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.5e+05      |\n",
      "|    n_updates            | 55090        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.8e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=-114857.87 +/- 93322.72\n",
      "Episode length: 205.20 +/- 122.99\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 205           |\n",
      "|    mean_reward          | -1.15e+05     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 870000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073169265 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.95          |\n",
      "|    explained_variance   | 0.582         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.73e+06      |\n",
      "|    n_updates            | 55100         |\n",
      "|    policy_gradient_loss | -0.00176      |\n",
      "|    std                  | 0.211         |\n",
      "|    value_loss           | 2.03e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 636       |\n",
      "|    ep_rew_mean     | -3.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 425       |\n",
      "|    time_elapsed    | 1278      |\n",
      "|    total_timesteps | 870400    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 579          |\n",
      "|    ep_rew_mean          | -3.64e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 681          |\n",
      "|    iterations           | 426          |\n",
      "|    time_elapsed         | 1279         |\n",
      "|    total_timesteps      | 872448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006252886 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.54e+06     |\n",
      "|    n_updates            | 55110        |\n",
      "|    policy_gradient_loss | -0.00087     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 6.98e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 586          |\n",
      "|    ep_rew_mean          | -2.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 427          |\n",
      "|    time_elapsed         | 1281         |\n",
      "|    total_timesteps      | 874496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013221533 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.87e+06     |\n",
      "|    n_updates            | 55120        |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.98e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=875000, episode_reward=-99055.44 +/- 138440.69\n",
      "Episode length: 233.60 +/- 307.36\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 234          |\n",
      "|    mean_reward          | -9.91e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 875000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043230485 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.15e+05     |\n",
      "|    n_updates            | 55130        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.02e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 507       |\n",
      "|    ep_rew_mean     | -2.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 428       |\n",
      "|    time_elapsed    | 1284      |\n",
      "|    total_timesteps | 876544    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 453          |\n",
      "|    ep_rew_mean          | -3.27e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 429          |\n",
      "|    time_elapsed         | 1286         |\n",
      "|    total_timesteps      | 878592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011703009 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.18e+07     |\n",
      "|    n_updates            | 55140        |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.88e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=-148041.42 +/- 145763.06\n",
      "Episode length: 518.20 +/- 269.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 518         |\n",
      "|    mean_reward          | -1.48e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 880000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003495092 |\n",
      "|    clip_fraction        | 0.0212      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.48e+07    |\n",
      "|    n_updates            | 55150       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.07e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 426       |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 430       |\n",
      "|    time_elapsed    | 1289      |\n",
      "|    total_timesteps | 880640    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 380          |\n",
      "|    ep_rew_mean          | -3.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 431          |\n",
      "|    time_elapsed         | 1291         |\n",
      "|    total_timesteps      | 882688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020666942 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.48e+06     |\n",
      "|    n_updates            | 55160        |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.1e+07      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 375         |\n",
      "|    ep_rew_mean          | -3.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 1293        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001880385 |\n",
      "|    clip_fraction        | 0.0149      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+07    |\n",
      "|    n_updates            | 55170       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 4.11e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=885000, episode_reward=-40321.40 +/- 52888.13\n",
      "Episode length: 242.60 +/- 189.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 243          |\n",
      "|    mean_reward          | -4.03e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 885000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008294933 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.565        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.56e+06     |\n",
      "|    n_updates            | 55180        |\n",
      "|    policy_gradient_loss | -0.00297     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 9.08e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 387       |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 433       |\n",
      "|    time_elapsed    | 1296      |\n",
      "|    total_timesteps | 886784    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 382          |\n",
      "|    ep_rew_mean          | -3.42e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 434          |\n",
      "|    time_elapsed         | 1298         |\n",
      "|    total_timesteps      | 888832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014034929 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.27e+07     |\n",
      "|    n_updates            | 55190        |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.47e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=-30533.68 +/- 54061.31\n",
      "Episode length: 118.60 +/- 72.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 119         |\n",
      "|    mean_reward          | -3.05e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 890000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002581934 |\n",
      "|    clip_fraction        | 0.00479     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.58e+07    |\n",
      "|    n_updates            | 55200       |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 7.13e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 390       |\n",
      "|    ep_rew_mean     | -3.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 435       |\n",
      "|    time_elapsed    | 1300      |\n",
      "|    total_timesteps | 890880    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 392         |\n",
      "|    ep_rew_mean          | -3.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 1302        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004406333 |\n",
      "|    clip_fraction        | 0.0241      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.21e+04    |\n",
      "|    n_updates            | 55210       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.58e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 359          |\n",
      "|    ep_rew_mean          | -3.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 686          |\n",
      "|    iterations           | 437          |\n",
      "|    time_elapsed         | 1304         |\n",
      "|    total_timesteps      | 894976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013198364 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58e+07     |\n",
      "|    n_updates            | 55220        |\n",
      "|    policy_gradient_loss | -0.000548    |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.16e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=895000, episode_reward=-67783.29 +/- 128460.44\n",
      "Episode length: 439.40 +/- 470.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 439          |\n",
      "|    mean_reward          | -6.78e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 895000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016471581 |\n",
      "|    clip_fraction        | 0.00327      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.92e+06     |\n",
      "|    n_updates            | 55230        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.66e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 364       |\n",
      "|    ep_rew_mean     | -3.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 438       |\n",
      "|    time_elapsed    | 1307      |\n",
      "|    total_timesteps | 897024    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | -4.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 1309        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001893191 |\n",
      "|    clip_fraction        | 0.00605     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+07    |\n",
      "|    n_updates            | 55240       |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.74e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=-81099.53 +/- 69759.29\n",
      "Episode length: 385.80 +/- 297.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 386          |\n",
      "|    mean_reward          | -8.11e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 900000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007215962 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.51e+07     |\n",
      "|    n_updates            | 55250        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.95e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 316       |\n",
      "|    ep_rew_mean     | -3.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 440       |\n",
      "|    time_elapsed    | 1312      |\n",
      "|    total_timesteps | 901120    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 319          |\n",
      "|    ep_rew_mean          | -3.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 441          |\n",
      "|    time_elapsed         | 1314         |\n",
      "|    total_timesteps      | 903168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027754642 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.684        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51e+06     |\n",
      "|    n_updates            | 55260        |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 5.4e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=905000, episode_reward=-106637.88 +/- 119409.85\n",
      "Episode length: 406.40 +/- 298.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 406          |\n",
      "|    mean_reward          | -1.07e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 905000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026269981 |\n",
      "|    clip_fraction        | 0.00356      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.663        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.4e+05      |\n",
      "|    n_updates            | 55270        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 6.02e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 322       |\n",
      "|    ep_rew_mean     | -4.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 687       |\n",
      "|    iterations      | 442       |\n",
      "|    time_elapsed    | 1317      |\n",
      "|    total_timesteps | 905216    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 332          |\n",
      "|    ep_rew_mean          | -4.56e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 443          |\n",
      "|    time_elapsed         | 1319         |\n",
      "|    total_timesteps      | 907264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010132449 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.03e+07     |\n",
      "|    n_updates            | 55280        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.6e+07      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 320         |\n",
      "|    ep_rew_mean          | -4.34e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 688         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 1321        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005292215 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.91e+07    |\n",
      "|    n_updates            | 55290       |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 8.07e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=910000, episode_reward=-36363.13 +/- 58509.00\n",
      "Episode length: 237.20 +/- 102.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 237          |\n",
      "|    mean_reward          | -3.64e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 910000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020047927 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.515        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+07     |\n",
      "|    n_updates            | 55300        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.92e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 336       |\n",
      "|    ep_rew_mean     | -4.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 688       |\n",
      "|    iterations      | 445       |\n",
      "|    time_elapsed    | 1323      |\n",
      "|    total_timesteps | 911360    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 337          |\n",
      "|    ep_rew_mean          | -3.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 689          |\n",
      "|    iterations           | 446          |\n",
      "|    time_elapsed         | 1325         |\n",
      "|    total_timesteps      | 913408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041399584 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.791        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.58e+04     |\n",
      "|    n_updates            | 55310        |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.71e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=915000, episode_reward=-37543.19 +/- 66546.46\n",
      "Episode length: 425.80 +/- 415.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 426         |\n",
      "|    mean_reward          | -3.75e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 915000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005428077 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.66e+06    |\n",
      "|    n_updates            | 55320       |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.22e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 351       |\n",
      "|    ep_rew_mean     | -3.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 689       |\n",
      "|    iterations      | 447       |\n",
      "|    time_elapsed    | 1328      |\n",
      "|    total_timesteps | 915456    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 355         |\n",
      "|    ep_rew_mean          | -3.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 1330        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007240559 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.67e+05    |\n",
      "|    n_updates            | 55330       |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.38e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 374          |\n",
      "|    ep_rew_mean          | -3.69e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 449          |\n",
      "|    time_elapsed         | 1332         |\n",
      "|    total_timesteps      | 919552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037572728 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02e+04     |\n",
      "|    n_updates            | 55340        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.02e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=-27799.32 +/- 34825.42\n",
      "Episode length: 748.20 +/- 1230.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 748         |\n",
      "|    mean_reward          | -2.78e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 920000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008601338 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.72e+03    |\n",
      "|    n_updates            | 55350       |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 8.82e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 374       |\n",
      "|    ep_rew_mean     | -3.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 689       |\n",
      "|    iterations      | 450       |\n",
      "|    time_elapsed    | 1336      |\n",
      "|    total_timesteps | 921600    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 407         |\n",
      "|    ep_rew_mean          | -3.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 1340        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018346671 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 863         |\n",
      "|    n_updates            | 55360       |\n",
      "|    policy_gradient_loss | 0.00302     |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=925000, episode_reward=-18892.28 +/- 23129.94\n",
      "Episode length: 507.40 +/- 448.24\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 507        |\n",
      "|    mean_reward          | -1.89e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 925000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00816167 |\n",
      "|    clip_fraction        | 0.0603     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.93       |\n",
      "|    explained_variance   | 0.576      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.64e+07   |\n",
      "|    n_updates            | 55370      |\n",
      "|    policy_gradient_loss | 0.00103    |\n",
      "|    std                  | 0.212      |\n",
      "|    value_loss           | 1.12e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 426       |\n",
      "|    ep_rew_mean     | -3.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 688       |\n",
      "|    iterations      | 452       |\n",
      "|    time_elapsed    | 1344      |\n",
      "|    total_timesteps | 925696    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 413          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 689          |\n",
      "|    iterations           | 453          |\n",
      "|    time_elapsed         | 1346         |\n",
      "|    total_timesteps      | 927744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031907423 |\n",
      "|    clip_fraction        | 0.00874      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.93         |\n",
      "|    explained_variance   | 0.599        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.97e+03     |\n",
      "|    n_updates            | 55380        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 3.95e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 413          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 689          |\n",
      "|    iterations           | 454          |\n",
      "|    time_elapsed         | 1348         |\n",
      "|    total_timesteps      | 929792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024826159 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.93         |\n",
      "|    explained_variance   | 0.697        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.8e+05      |\n",
      "|    n_updates            | 55390        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 1.55e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=-9628.04 +/- 6611.78\n",
      "Episode length: 183.00 +/- 205.75\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 183        |\n",
      "|    mean_reward          | -9.63e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 930000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01616993 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.94       |\n",
      "|    explained_variance   | 0.882      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 751        |\n",
      "|    n_updates            | 55400      |\n",
      "|    policy_gradient_loss | -0.00112   |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 2.81e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 435       |\n",
      "|    ep_rew_mean     | -2.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 689       |\n",
      "|    iterations      | 455       |\n",
      "|    time_elapsed    | 1351      |\n",
      "|    total_timesteps | 931840    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 425         |\n",
      "|    ep_rew_mean          | -3.43e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 690         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 1353        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004587495 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.25e+07    |\n",
      "|    n_updates            | 55410       |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.23e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=935000, episode_reward=-7743.72 +/- 16970.73\n",
      "Episode length: 220.40 +/- 146.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 220          |\n",
      "|    mean_reward          | -7.74e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 935000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007653007 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51e+07     |\n",
      "|    n_updates            | 55420        |\n",
      "|    policy_gradient_loss | -1.69e-05    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 7.44e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 434       |\n",
      "|    ep_rew_mean     | -3.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 690       |\n",
      "|    iterations      | 457       |\n",
      "|    time_elapsed    | 1355      |\n",
      "|    total_timesteps | 935936    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 429          |\n",
      "|    ep_rew_mean          | -3.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 458          |\n",
      "|    time_elapsed         | 1357         |\n",
      "|    total_timesteps      | 937984       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031412018 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.86e+05     |\n",
      "|    n_updates            | 55430        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.14e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=-16199.95 +/- 35388.77\n",
      "Episode length: 1269.00 +/- 1653.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.27e+03     |\n",
      "|    mean_reward          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 940000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0001406704 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.07e+07     |\n",
      "|    n_updates            | 55440        |\n",
      "|    policy_gradient_loss | -0.00037     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 6.38e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 416       |\n",
      "|    ep_rew_mean     | -3.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 689       |\n",
      "|    iterations      | 459       |\n",
      "|    time_elapsed    | 1362      |\n",
      "|    total_timesteps | 940032    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 421          |\n",
      "|    ep_rew_mean          | -3.05e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 690          |\n",
      "|    iterations           | 460          |\n",
      "|    time_elapsed         | 1364         |\n",
      "|    total_timesteps      | 942080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046558566 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.797        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+04     |\n",
      "|    n_updates            | 55450        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.88e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 421         |\n",
      "|    ep_rew_mean          | -3.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 1366        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017733723 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 432         |\n",
      "|    n_updates            | 55460       |\n",
      "|    policy_gradient_loss | -0.000354   |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=945000, episode_reward=-99425.65 +/- 99848.46\n",
      "Episode length: 261.20 +/- 184.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 261         |\n",
      "|    mean_reward          | -9.94e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 945000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009031856 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 55470       |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.22e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 466      |\n",
      "|    ep_rew_mean     | -2.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 691      |\n",
      "|    iterations      | 462      |\n",
      "|    time_elapsed    | 1368     |\n",
      "|    total_timesteps | 946176   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 477          |\n",
      "|    ep_rew_mean          | -2.95e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 691          |\n",
      "|    iterations           | 463          |\n",
      "|    time_elapsed         | 1370         |\n",
      "|    total_timesteps      | 948224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073442645 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.8e+05      |\n",
      "|    n_updates            | 55480        |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 7.05e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=-42090.86 +/- 64011.53\n",
      "Episode length: 264.80 +/- 89.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 265         |\n",
      "|    mean_reward          | -4.21e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 950000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002936211 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.602       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.1e+07     |\n",
      "|    n_updates            | 55490       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.09e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 484       |\n",
      "|    ep_rew_mean     | -2.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 691       |\n",
      "|    iterations      | 464       |\n",
      "|    time_elapsed    | 1373      |\n",
      "|    total_timesteps | 950272    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 488         |\n",
      "|    ep_rew_mean          | -2.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 1375        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010472017 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+07    |\n",
      "|    n_updates            | 55500       |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 6.86e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 466          |\n",
      "|    ep_rew_mean          | -2.35e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 692          |\n",
      "|    iterations           | 466          |\n",
      "|    time_elapsed         | 1377         |\n",
      "|    total_timesteps      | 954368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043301964 |\n",
      "|    clip_fraction        | 0.039        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.96e+04     |\n",
      "|    n_updates            | 55510        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.72e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=955000, episode_reward=-116658.46 +/- 78072.48\n",
      "Episode length: 338.20 +/- 179.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 338          |\n",
      "|    mean_reward          | -1.17e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 955000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027690628 |\n",
      "|    clip_fraction        | 0.00815      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.44e+06     |\n",
      "|    n_updates            | 55520        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.25e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 453       |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 692       |\n",
      "|    iterations      | 467       |\n",
      "|    time_elapsed    | 1380      |\n",
      "|    total_timesteps | 956416    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 445          |\n",
      "|    ep_rew_mean          | -3e+04       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 468          |\n",
      "|    time_elapsed         | 1382         |\n",
      "|    total_timesteps      | 958464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012459334 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.567        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.1e+07      |\n",
      "|    n_updates            | 55530        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.86e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=960000, episode_reward=-34354.46 +/- 55659.35\n",
      "Episode length: 136.60 +/- 85.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 137          |\n",
      "|    mean_reward          | -3.44e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 960000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007019745 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.94e+07     |\n",
      "|    n_updates            | 55540        |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 5.21e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 432       |\n",
      "|    ep_rew_mean     | -3.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 469       |\n",
      "|    time_elapsed    | 1384      |\n",
      "|    total_timesteps | 960512    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 394          |\n",
      "|    ep_rew_mean          | -3.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 1386         |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019243554 |\n",
      "|    clip_fraction        | 0.0043       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.29e+07     |\n",
      "|    n_updates            | 55550        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 6.13e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 401         |\n",
      "|    ep_rew_mean          | -3.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 1388        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006438368 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.0561      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.08e+03    |\n",
      "|    n_updates            | 55560       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 9.4e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=965000, episode_reward=-51253.29 +/- 74564.39\n",
      "Episode length: 264.60 +/- 196.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 265          |\n",
      "|    mean_reward          | -5.13e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 965000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017090328 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+07      |\n",
      "|    n_updates            | 55570        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.67e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 407       |\n",
      "|    ep_rew_mean     | -3.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 695       |\n",
      "|    iterations      | 472       |\n",
      "|    time_elapsed    | 1390      |\n",
      "|    total_timesteps | 966656    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 367          |\n",
      "|    ep_rew_mean          | -3.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 473          |\n",
      "|    time_elapsed         | 1392         |\n",
      "|    total_timesteps      | 968704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040520984 |\n",
      "|    clip_fraction        | 0.0192       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.64e+06     |\n",
      "|    n_updates            | 55580        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.48e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=-17488.26 +/- 23404.07\n",
      "Episode length: 168.20 +/- 43.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 168          |\n",
      "|    mean_reward          | -1.75e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 970000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031152018 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88e+07     |\n",
      "|    n_updates            | 55590        |\n",
      "|    policy_gradient_loss | -0.0041      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.62e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 368       |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 695       |\n",
      "|    iterations      | 474       |\n",
      "|    time_elapsed    | 1394      |\n",
      "|    total_timesteps | 970752    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 372         |\n",
      "|    ep_rew_mean          | -3.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 1396        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001474736 |\n",
      "|    clip_fraction        | 0.00371     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+07    |\n",
      "|    n_updates            | 55600       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.85e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 369         |\n",
      "|    ep_rew_mean          | -3.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 1398        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002726337 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.06e+07    |\n",
      "|    n_updates            | 55610       |\n",
      "|    policy_gradient_loss | -0.000323   |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.42e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=975000, episode_reward=-44130.48 +/- 64308.01\n",
      "Episode length: 177.20 +/- 62.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 177          |\n",
      "|    mean_reward          | -4.41e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 975000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021951133 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.525        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.57e+07     |\n",
      "|    n_updates            | 55620        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.31e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 379       |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 697       |\n",
      "|    iterations      | 477       |\n",
      "|    time_elapsed    | 1401      |\n",
      "|    total_timesteps | 976896    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 383        |\n",
      "|    ep_rew_mean          | -3.24e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 697        |\n",
      "|    iterations           | 478        |\n",
      "|    time_elapsed         | 1403       |\n",
      "|    total_timesteps      | 978944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00523379 |\n",
      "|    clip_fraction        | 0.031      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.95       |\n",
      "|    explained_variance   | 0.645      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.62e+03   |\n",
      "|    n_updates            | 55630      |\n",
      "|    policy_gradient_loss | -0.00303   |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 1.03e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=-40560.88 +/- 80689.38\n",
      "Episode length: 256.80 +/- 165.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 257          |\n",
      "|    mean_reward          | -4.06e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 980000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021594162 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.38e+07     |\n",
      "|    n_updates            | 55640        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 4.75e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 345       |\n",
      "|    ep_rew_mean     | -3.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 697       |\n",
      "|    iterations      | 479       |\n",
      "|    time_elapsed    | 1406      |\n",
      "|    total_timesteps | 980992    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 372         |\n",
      "|    ep_rew_mean          | -3.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 1408        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062231578 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.21e+03    |\n",
      "|    n_updates            | 55650       |\n",
      "|    policy_gradient_loss | 0.00715     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 6.9e+06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=985000, episode_reward=-5545.41 +/- 6634.68\n",
      "Episode length: 222.20 +/- 197.80\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 222        |\n",
      "|    mean_reward          | -5.55e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 985000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01267455 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.95       |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.73e+03   |\n",
      "|    n_updates            | 55660      |\n",
      "|    policy_gradient_loss | -0.00291   |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 8.07e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 367       |\n",
      "|    ep_rew_mean     | -3.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 698       |\n",
      "|    iterations      | 481       |\n",
      "|    time_elapsed    | 1410      |\n",
      "|    total_timesteps | 985088    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 349          |\n",
      "|    ep_rew_mean          | -3.68e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 482          |\n",
      "|    time_elapsed         | 1412         |\n",
      "|    total_timesteps      | 987136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043737586 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.29e+06     |\n",
      "|    n_updates            | 55670        |\n",
      "|    policy_gradient_loss | 0.00204      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 8.52e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 360          |\n",
      "|    ep_rew_mean          | -3.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 699          |\n",
      "|    iterations           | 483          |\n",
      "|    time_elapsed         | 1414         |\n",
      "|    total_timesteps      | 989184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028759968 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.69e+07     |\n",
      "|    n_updates            | 55680        |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 6.62e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=-36240.25 +/- 67474.01\n",
      "Episode length: 171.80 +/- 135.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 172         |\n",
      "|    mean_reward          | -3.62e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 990000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001357327 |\n",
      "|    clip_fraction        | 0.000781    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.73e+04    |\n",
      "|    n_updates            | 55690       |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 5.85e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 352       |\n",
      "|    ep_rew_mean     | -3.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 699       |\n",
      "|    iterations      | 484       |\n",
      "|    time_elapsed    | 1416      |\n",
      "|    total_timesteps | 991232    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 360          |\n",
      "|    ep_rew_mean          | -3.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 485          |\n",
      "|    time_elapsed         | 1418         |\n",
      "|    total_timesteps      | 993280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027395175 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.4e+07      |\n",
      "|    n_updates            | 55700        |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 8.93e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=995000, episode_reward=-6913.16 +/- 5576.21\n",
      "Episode length: 331.00 +/- 458.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 331          |\n",
      "|    mean_reward          | -6.91e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 995000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017882668 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.29e+07     |\n",
      "|    n_updates            | 55710        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.17e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 377       |\n",
      "|    ep_rew_mean     | -3.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 700       |\n",
      "|    iterations      | 486       |\n",
      "|    time_elapsed    | 1421      |\n",
      "|    total_timesteps | 995328    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 376         |\n",
      "|    ep_rew_mean          | -3.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 1423        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013277749 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.5e+03     |\n",
      "|    n_updates            | 55720       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.6e+04     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 385          |\n",
      "|    ep_rew_mean          | -3.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 488          |\n",
      "|    time_elapsed         | 1427         |\n",
      "|    total_timesteps      | 999424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065867878 |\n",
      "|    clip_fraction        | 0.0618       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.549        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02e+07     |\n",
      "|    n_updates            | 55730        |\n",
      "|    policy_gradient_loss | -0.00625     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.37e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=-6997.51 +/- 11404.47\n",
      "Episode length: 440.80 +/- 435.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 441          |\n",
      "|    mean_reward          | -7e+03       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050680926 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.34e+07     |\n",
      "|    n_updates            | 55740        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 3.71e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 341       |\n",
      "|    ep_rew_mean     | -3.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 699       |\n",
      "|    iterations      | 489       |\n",
      "|    time_elapsed    | 1431      |\n",
      "|    total_timesteps | 1001472   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 357         |\n",
      "|    ep_rew_mean          | -3.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 1432        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005320745 |\n",
      "|    clip_fraction        | 0.0336      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27e+07    |\n",
      "|    n_updates            | 55750       |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.58e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1005000, episode_reward=-53005.31 +/- 50076.84\n",
      "Episode length: 78.80 +/- 86.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 78.8        |\n",
      "|    mean_reward          | -5.3e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1005000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009754993 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.17e+05    |\n",
      "|    n_updates            | 55760       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.99e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 366       |\n",
      "|    ep_rew_mean     | -3.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 700       |\n",
      "|    iterations      | 491       |\n",
      "|    time_elapsed    | 1435      |\n",
      "|    total_timesteps | 1005568   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 366          |\n",
      "|    ep_rew_mean          | -3.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 701          |\n",
      "|    iterations           | 492          |\n",
      "|    time_elapsed         | 1436         |\n",
      "|    total_timesteps      | 1007616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044287723 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.01e+07     |\n",
      "|    n_updates            | 55770        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 7.78e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | -3.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 493         |\n",
      "|    time_elapsed         | 1438        |\n",
      "|    total_timesteps      | 1009664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006063072 |\n",
      "|    clip_fraction        | 0.0435      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.315       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.66e+03    |\n",
      "|    n_updates            | 55780       |\n",
      "|    policy_gradient_loss | -0.00086    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.17e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=-14176.35 +/- 32217.77\n",
      "Episode length: 355.40 +/- 318.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 355          |\n",
      "|    mean_reward          | -1.42e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1010000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059342184 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+07     |\n",
      "|    n_updates            | 55790        |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.68e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 369       |\n",
      "|    ep_rew_mean     | -3.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 494       |\n",
      "|    time_elapsed    | 1441      |\n",
      "|    total_timesteps | 1011712   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 385          |\n",
      "|    ep_rew_mean          | -3.23e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 495          |\n",
      "|    time_elapsed         | 1443         |\n",
      "|    total_timesteps      | 1013760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077021667 |\n",
      "|    clip_fraction        | 0.0823       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.796        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.69e+04     |\n",
      "|    n_updates            | 55800        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 5.7e+05      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1015000, episode_reward=-34421.90 +/- 62727.21\n",
      "Episode length: 475.20 +/- 469.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 475         |\n",
      "|    mean_reward          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1015000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009786254 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.5e+03     |\n",
      "|    n_updates            | 55810       |\n",
      "|    policy_gradient_loss | -0.000264   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.39e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 375       |\n",
      "|    ep_rew_mean     | -3.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 496       |\n",
      "|    time_elapsed    | 1446      |\n",
      "|    total_timesteps | 1015808   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 393          |\n",
      "|    ep_rew_mean          | -3.11e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 497          |\n",
      "|    time_elapsed         | 1448         |\n",
      "|    total_timesteps      | 1017856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044150683 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.509        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86e+07     |\n",
      "|    n_updates            | 55820        |\n",
      "|    policy_gradient_loss | 0.00107      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.95e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | -2.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 1449        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007900742 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2e+03       |\n",
      "|    n_updates            | 55830       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.04e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=-53758.05 +/- 106891.27\n",
      "Episode length: 871.20 +/- 1033.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 871          |\n",
      "|    mean_reward          | -5.38e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1020000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063450327 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.12e+05     |\n",
      "|    n_updates            | 55840        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.42e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 377       |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 499       |\n",
      "|    time_elapsed    | 1453      |\n",
      "|    total_timesteps | 1021952   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 377          |\n",
      "|    ep_rew_mean          | -3.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 500          |\n",
      "|    time_elapsed         | 1455         |\n",
      "|    total_timesteps      | 1024000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045791273 |\n",
      "|    clip_fraction        | 0.0308       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.34e+07     |\n",
      "|    n_updates            | 55850        |\n",
      "|    policy_gradient_loss | -0.000887    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 6.58e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1025000, episode_reward=-46707.09 +/- 57126.40\n",
      "Episode length: 1005.60 +/- 1250.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | -4.67e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1025000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039689485 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+07     |\n",
      "|    n_updates            | 55860        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.98e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 397       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 501       |\n",
      "|    time_elapsed    | 1460      |\n",
      "|    total_timesteps | 1026048   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 405         |\n",
      "|    ep_rew_mean          | -3.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 1461        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010236473 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 55870       |\n",
      "|    policy_gradient_loss | -0.00098    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.47e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1030000, episode_reward=-12382.94 +/- 21565.06\n",
      "Episode length: 584.20 +/- 475.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 584         |\n",
      "|    mean_reward          | -1.24e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004083563 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.548       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+04    |\n",
      "|    n_updates            | 55880       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 6.87e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 425       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 503       |\n",
      "|    time_elapsed    | 1465      |\n",
      "|    total_timesteps | 1030144   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 438          |\n",
      "|    ep_rew_mean          | -3.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 504          |\n",
      "|    time_elapsed         | 1467         |\n",
      "|    total_timesteps      | 1032192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041568438 |\n",
      "|    clip_fraction        | 0.0112       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.73e+07     |\n",
      "|    n_updates            | 55890        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 7.12e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 439          |\n",
      "|    ep_rew_mean          | -3.2e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 704          |\n",
      "|    iterations           | 505          |\n",
      "|    time_elapsed         | 1468         |\n",
      "|    total_timesteps      | 1034240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084609315 |\n",
      "|    clip_fraction        | 0.088        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | -0.165       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.41e+03     |\n",
      "|    n_updates            | 55900        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 9.16e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1035000, episode_reward=1498.62 +/- 11521.71\n",
      "Episode length: 717.00 +/- 435.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 717         |\n",
      "|    mean_reward          | 1.5e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1035000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014339038 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | -0.00704    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.34e+04    |\n",
      "|    n_updates            | 55910       |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 6.88e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 447       |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 506       |\n",
      "|    time_elapsed    | 1472      |\n",
      "|    total_timesteps | 1036288   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 450          |\n",
      "|    ep_rew_mean          | -3.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 704          |\n",
      "|    iterations           | 507          |\n",
      "|    time_elapsed         | 1474         |\n",
      "|    total_timesteps      | 1038336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081555545 |\n",
      "|    clip_fraction        | 0.0905       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.65e+07     |\n",
      "|    n_updates            | 55920        |\n",
      "|    policy_gradient_loss | 0.00327      |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 2.88e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=-21542.05 +/- 39005.44\n",
      "Episode length: 961.00 +/- 1317.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 961         |\n",
      "|    mean_reward          | -2.15e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006740451 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02e+04    |\n",
      "|    n_updates            | 55930       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.75e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 462       |\n",
      "|    ep_rew_mean     | -2.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 508       |\n",
      "|    time_elapsed    | 1479      |\n",
      "|    total_timesteps | 1040384   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 462         |\n",
      "|    ep_rew_mean          | -2.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 1481        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006667736 |\n",
      "|    clip_fraction        | 0.0416      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.92e+03    |\n",
      "|    n_updates            | 55940       |\n",
      "|    policy_gradient_loss | -0.00551    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 5.99e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 509         |\n",
      "|    ep_rew_mean          | -2.92e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 510         |\n",
      "|    time_elapsed         | 1483        |\n",
      "|    total_timesteps      | 1044480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014524324 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 319         |\n",
      "|    n_updates            | 55950       |\n",
      "|    policy_gradient_loss | 0.00409     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.22e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1045000, episode_reward=-16289.34 +/- 30395.54\n",
      "Episode length: 1364.80 +/- 1356.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.36e+03    |\n",
      "|    mean_reward          | -1.63e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1045000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009647084 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.558       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.81e+07    |\n",
      "|    n_updates            | 55960       |\n",
      "|    policy_gradient_loss | 0.000576    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.83e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 500       |\n",
      "|    ep_rew_mean     | -2.91e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 511       |\n",
      "|    time_elapsed    | 1488      |\n",
      "|    total_timesteps | 1046528   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 515         |\n",
      "|    ep_rew_mean          | -2.91e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 1490        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009051585 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.12e+03    |\n",
      "|    n_updates            | 55970       |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.55e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=-40928.60 +/- 52421.74\n",
      "Episode length: 937.00 +/- 891.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 937         |\n",
      "|    mean_reward          | -4.09e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007677711 |\n",
      "|    clip_fraction        | 0.0346      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+04    |\n",
      "|    n_updates            | 55980       |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.5e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 516       |\n",
      "|    ep_rew_mean     | -2.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 513       |\n",
      "|    time_elapsed    | 1494      |\n",
      "|    total_timesteps | 1050624   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 521          |\n",
      "|    ep_rew_mean          | -2.85e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 514          |\n",
      "|    time_elapsed         | 1496         |\n",
      "|    total_timesteps      | 1052672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047638104 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.7e+07      |\n",
      "|    n_updates            | 55990        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 6.17e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 543          |\n",
      "|    ep_rew_mean          | -2.94e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 515          |\n",
      "|    time_elapsed         | 1498         |\n",
      "|    total_timesteps      | 1054720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026748672 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.9e+06      |\n",
      "|    n_updates            | 56000        |\n",
      "|    policy_gradient_loss | -0.00461     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.01e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1055000, episode_reward=-17547.23 +/- 46104.30\n",
      "Episode length: 1598.80 +/- 1013.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -1.75e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1055000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024932204 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.85e+06    |\n",
      "|    n_updates            | 56010       |\n",
      "|    policy_gradient_loss | 0.00333     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.39e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 543       |\n",
      "|    ep_rew_mean     | -2.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 516       |\n",
      "|    time_elapsed    | 1503      |\n",
      "|    total_timesteps | 1056768   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 569         |\n",
      "|    ep_rew_mean          | -2.96e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 1507        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013049165 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 899         |\n",
      "|    n_updates            | 56020       |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.54e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=119.93 +/- 11583.05\n",
      "Episode length: 1334.80 +/- 999.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.33e+03    |\n",
      "|    mean_reward          | 120         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008688288 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.72e+06    |\n",
      "|    n_updates            | 56030       |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.6e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 600       |\n",
      "|    ep_rew_mean     | -2.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 518       |\n",
      "|    time_elapsed    | 1512      |\n",
      "|    total_timesteps | 1060864   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 600         |\n",
      "|    ep_rew_mean          | -2.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 1514        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013970007 |\n",
      "|    clip_fraction        | 0.0804      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.67e+06    |\n",
      "|    n_updates            | 56040       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.89e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 618         |\n",
      "|    ep_rew_mean          | -2.94e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 1515        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014056737 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.33e+05    |\n",
      "|    n_updates            | 56050       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.76e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1065000, episode_reward=-23352.05 +/- 51483.99\n",
      "Episode length: 643.20 +/- 767.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 643         |\n",
      "|    mean_reward          | -2.34e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1065000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028281204 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 56060       |\n",
      "|    policy_gradient_loss | 0.00681     |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 5.71e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 618       |\n",
      "|    ep_rew_mean     | -2.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 521       |\n",
      "|    time_elapsed    | 1519      |\n",
      "|    total_timesteps | 1067008   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 643         |\n",
      "|    ep_rew_mean          | -2.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 1521        |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012741146 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 796         |\n",
      "|    n_updates            | 56070       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 3.98e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1070000, episode_reward=510.37 +/- 8484.94\n",
      "Episode length: 1453.60 +/- 812.39\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.45e+03     |\n",
      "|    mean_reward          | 510          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1070000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064291083 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.94         |\n",
      "|    explained_variance   | 0.494        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.33e+06     |\n",
      "|    n_updates            | 56080        |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 2.48e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 653       |\n",
      "|    ep_rew_mean     | -2.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 523       |\n",
      "|    time_elapsed    | 1526      |\n",
      "|    total_timesteps | 1071104   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 666          |\n",
      "|    ep_rew_mean          | -2.79e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 524          |\n",
      "|    time_elapsed         | 1528         |\n",
      "|    total_timesteps      | 1073152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011321154 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.94         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.52e+06     |\n",
      "|    n_updates            | 56090        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 3.32e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1075000, episode_reward=-36036.33 +/- 57701.00\n",
      "Episode length: 1016.80 +/- 798.52\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.02e+03   |\n",
      "|    mean_reward          | -3.6e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1075000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18767625 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.94       |\n",
      "|    explained_variance   | 0.519      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.28e+06   |\n",
      "|    n_updates            | 56100      |\n",
      "|    policy_gradient_loss | 0.00936    |\n",
      "|    std                  | 0.212      |\n",
      "|    value_loss           | 2.15e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 666       |\n",
      "|    ep_rew_mean     | -2.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 525       |\n",
      "|    time_elapsed    | 1532      |\n",
      "|    total_timesteps | 1075200   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 688        |\n",
      "|    ep_rew_mean          | -2.76e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 701        |\n",
      "|    iterations           | 526        |\n",
      "|    time_elapsed         | 1534       |\n",
      "|    total_timesteps      | 1077248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01792892 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.95       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 419        |\n",
      "|    n_updates            | 56110      |\n",
      "|    policy_gradient_loss | 0.00857    |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 1.72e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 702         |\n",
      "|    ep_rew_mean          | -2.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 1536        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009302237 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.843       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.89e+05    |\n",
      "|    n_updates            | 56120       |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 8.47e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=-70914.33 +/- 86417.98\n",
      "Episode length: 827.20 +/- 769.84\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 827        |\n",
      "|    mean_reward          | -7.09e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1080000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01301824 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.97       |\n",
      "|    explained_variance   | 0.875      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 363        |\n",
      "|    n_updates            | 56130      |\n",
      "|    policy_gradient_loss | 0.00043    |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 3.36e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 719       |\n",
      "|    ep_rew_mean     | -2.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 528       |\n",
      "|    time_elapsed    | 1540      |\n",
      "|    total_timesteps | 1081344   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 731          |\n",
      "|    ep_rew_mean          | -2.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 529          |\n",
      "|    time_elapsed         | 1542         |\n",
      "|    total_timesteps      | 1083392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039515486 |\n",
      "|    clip_fraction        | 0.0779       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.66e+06     |\n",
      "|    n_updates            | 56140        |\n",
      "|    policy_gradient_loss | 0.00129      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.33e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1085000, episode_reward=-38669.24 +/- 93257.15\n",
      "Episode length: 1154.00 +/- 853.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.15e+03     |\n",
      "|    mean_reward          | -3.87e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1085000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011137633 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.591        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.89e+05     |\n",
      "|    n_updates            | 56150        |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.5e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 751       |\n",
      "|    ep_rew_mean     | -2.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 530       |\n",
      "|    time_elapsed    | 1546      |\n",
      "|    total_timesteps | 1085440   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 776         |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 1548        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012123177 |\n",
      "|    clip_fraction        | 0.097       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 56160       |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.13e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 776         |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 1550        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006473097 |\n",
      "|    clip_fraction        | 0.0396      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02e+06    |\n",
      "|    n_updates            | 56170       |\n",
      "|    policy_gradient_loss | 0.000364    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.27e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1090000, episode_reward=-4578.29 +/- 12987.47\n",
      "Episode length: 409.80 +/- 713.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 410         |\n",
      "|    mean_reward          | -4.58e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012412484 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 624         |\n",
      "|    n_updates            | 56180       |\n",
      "|    policy_gradient_loss | 0.00219     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.59e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 804       |\n",
      "|    ep_rew_mean     | -3.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 533       |\n",
      "|    time_elapsed    | 1553      |\n",
      "|    total_timesteps | 1091584   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 786          |\n",
      "|    ep_rew_mean          | -3.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 534          |\n",
      "|    time_elapsed         | 1555         |\n",
      "|    total_timesteps      | 1093632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045627854 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.93e+07     |\n",
      "|    n_updates            | 56190        |\n",
      "|    policy_gradient_loss | -0.000722    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.73e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1095000, episode_reward=-37486.12 +/- 53484.60\n",
      "Episode length: 286.80 +/- 506.18\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 287          |\n",
      "|    mean_reward          | -3.75e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1095000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013742929 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66e+06     |\n",
      "|    n_updates            | 56200        |\n",
      "|    policy_gradient_loss | -0.000773    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.35e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 781       |\n",
      "|    ep_rew_mean     | -3.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 535       |\n",
      "|    time_elapsed    | 1557      |\n",
      "|    total_timesteps | 1095680   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 795        |\n",
      "|    ep_rew_mean          | -3.24e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 703        |\n",
      "|    iterations           | 536        |\n",
      "|    time_elapsed         | 1559       |\n",
      "|    total_timesteps      | 1097728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01695916 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.98       |\n",
      "|    explained_variance   | 0.849      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 876        |\n",
      "|    n_updates            | 56210      |\n",
      "|    policy_gradient_loss | -0.00165   |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.42e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 794         |\n",
      "|    ep_rew_mean          | -3.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 1561        |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014247401 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 486         |\n",
      "|    n_updates            | 56220       |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4e+03       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=-8116.10 +/- 24695.74\n",
      "Episode length: 871.60 +/- 1007.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 872         |\n",
      "|    mean_reward          | -8.12e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012632706 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.49e+03    |\n",
      "|    n_updates            | 56230       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.34e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 817       |\n",
      "|    ep_rew_mean     | -3.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 538       |\n",
      "|    time_elapsed    | 1567      |\n",
      "|    total_timesteps | 1101824   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 832        |\n",
      "|    ep_rew_mean          | -3.32e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 703        |\n",
      "|    iterations           | 539        |\n",
      "|    time_elapsed         | 1569       |\n",
      "|    total_timesteps      | 1103872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01209381 |\n",
      "|    clip_fraction        | 0.0891     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.98       |\n",
      "|    explained_variance   | 0.866      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.09e+03   |\n",
      "|    n_updates            | 56240      |\n",
      "|    policy_gradient_loss | -7.58e-05  |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 3.4e+04    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1105000, episode_reward=1471.50 +/- 4788.52\n",
      "Episode length: 520.60 +/- 847.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 521          |\n",
      "|    mean_reward          | 1.47e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1105000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040449603 |\n",
      "|    clip_fraction        | 0.047        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33e+07     |\n",
      "|    n_updates            | 56250        |\n",
      "|    policy_gradient_loss | 0.00214      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.16e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 846      |\n",
      "|    ep_rew_mean     | -3.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 703      |\n",
      "|    iterations      | 540      |\n",
      "|    time_elapsed    | 1572     |\n",
      "|    total_timesteps | 1105920  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 861        |\n",
      "|    ep_rew_mean          | -3.15e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 703        |\n",
      "|    iterations           | 541        |\n",
      "|    time_elapsed         | 1574       |\n",
      "|    total_timesteps      | 1107968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02487038 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.97       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 472        |\n",
      "|    n_updates            | 56260      |\n",
      "|    policy_gradient_loss | 0.00605    |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 2.15e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=-46307.28 +/- 90182.93\n",
      "Episode length: 540.40 +/- 877.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 540        |\n",
      "|    mean_reward          | -4.63e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1110000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13630846 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.97       |\n",
      "|    explained_variance   | 0.567      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1e+07      |\n",
      "|    n_updates            | 56270      |\n",
      "|    policy_gradient_loss | -0.00154   |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 1.14e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 835       |\n",
      "|    ep_rew_mean     | -2.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 542       |\n",
      "|    time_elapsed    | 1578      |\n",
      "|    total_timesteps | 1110016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 833         |\n",
      "|    ep_rew_mean          | -2.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 1579        |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006186582 |\n",
      "|    clip_fraction        | 0.0512      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.624       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.86e+05    |\n",
      "|    n_updates            | 56280       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.17e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 834         |\n",
      "|    ep_rew_mean          | -2.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 1581        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018905375 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 452         |\n",
      "|    n_updates            | 56290       |\n",
      "|    policy_gradient_loss | 0.000144    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.66e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1115000, episode_reward=-90057.47 +/- 69208.72\n",
      "Episode length: 1345.20 +/- 1148.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.35e+03    |\n",
      "|    mean_reward          | -9.01e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1115000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006197034 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.1e+03     |\n",
      "|    n_updates            | 56300       |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.92e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 842       |\n",
      "|    ep_rew_mean     | -2.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 545       |\n",
      "|    time_elapsed    | 1587      |\n",
      "|    total_timesteps | 1116160   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 850         |\n",
      "|    ep_rew_mean          | -2.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 1589        |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063047305 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.592       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+06    |\n",
      "|    n_updates            | 56310       |\n",
      "|    policy_gradient_loss | 0.00187     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 5.85e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=-60671.56 +/- 86044.53\n",
      "Episode length: 1649.20 +/- 1267.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.65e+03     |\n",
      "|    mean_reward          | -6.07e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062962403 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.547        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.89e+06     |\n",
      "|    n_updates            | 56320        |\n",
      "|    policy_gradient_loss | 0.00337      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.08e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 861       |\n",
      "|    ep_rew_mean     | -2.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 547       |\n",
      "|    time_elapsed    | 1595      |\n",
      "|    total_timesteps | 1120256   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 878          |\n",
      "|    ep_rew_mean          | -2.76e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 548          |\n",
      "|    time_elapsed         | 1597         |\n",
      "|    total_timesteps      | 1122304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154872555 |\n",
      "|    clip_fraction        | 0.177        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 56330        |\n",
      "|    policy_gradient_loss | 0.00198      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 7.41e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 888         |\n",
      "|    ep_rew_mean          | -2.72e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 1599        |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009578971 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+07       |\n",
      "|    n_updates            | 56340       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.91e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1125000, episode_reward=-95696.59 +/- 48565.39\n",
      "Episode length: 1334.00 +/- 636.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.33e+03     |\n",
      "|    mean_reward          | -9.57e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1125000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028683464 |\n",
      "|    clip_fraction        | 0.0169       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.57         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+04     |\n",
      "|    n_updates            | 56350        |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.85e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 905       |\n",
      "|    ep_rew_mean     | -2.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 550       |\n",
      "|    time_elapsed    | 1604      |\n",
      "|    total_timesteps | 1126400   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 918        |\n",
      "|    ep_rew_mean          | -2.95e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 702        |\n",
      "|    iterations           | 551        |\n",
      "|    time_elapsed         | 1605       |\n",
      "|    total_timesteps      | 1128448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04365673 |\n",
      "|    clip_fraction        | 0.0774     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.96       |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.83e+07   |\n",
      "|    n_updates            | 56360      |\n",
      "|    policy_gradient_loss | 0.0179     |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 2.03e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1130000, episode_reward=-83272.57 +/- 38248.67\n",
      "Episode length: 965.40 +/- 753.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 965         |\n",
      "|    mean_reward          | -8.33e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013769226 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.69e+06    |\n",
      "|    n_updates            | 56370       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.63e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 938       |\n",
      "|    ep_rew_mean     | -3.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 552       |\n",
      "|    time_elapsed    | 1610      |\n",
      "|    total_timesteps | 1130496   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 951         |\n",
      "|    ep_rew_mean          | -3.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 1611        |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006935332 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+07    |\n",
      "|    n_updates            | 56380       |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.21e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 960          |\n",
      "|    ep_rew_mean          | -3.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 554          |\n",
      "|    time_elapsed         | 1613         |\n",
      "|    total_timesteps      | 1134592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056308676 |\n",
      "|    clip_fraction        | 0.0561       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.562        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+07     |\n",
      "|    n_updates            | 56390        |\n",
      "|    policy_gradient_loss | 0.00224      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.4e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1135000, episode_reward=-74614.59 +/- 70720.29\n",
      "Episode length: 942.20 +/- 707.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 942          |\n",
      "|    mean_reward          | -7.46e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1135000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010086935 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.569        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.58e+04     |\n",
      "|    n_updates            | 56400        |\n",
      "|    policy_gradient_loss | 0.000298     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.54e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 964       |\n",
      "|    ep_rew_mean     | -3.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 555       |\n",
      "|    time_elapsed    | 1617      |\n",
      "|    total_timesteps | 1136640   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 922         |\n",
      "|    ep_rew_mean          | -3.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 703         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 1619        |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014729232 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 893         |\n",
      "|    n_updates            | 56410       |\n",
      "|    policy_gradient_loss | 0.000745    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.22e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1140000, episode_reward=-55111.62 +/- 35362.47\n",
      "Episode length: 1317.40 +/- 760.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.32e+03    |\n",
      "|    mean_reward          | -5.51e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010669215 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.643       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 56420       |\n",
      "|    policy_gradient_loss | -0.000756   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.18e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 914       |\n",
      "|    ep_rew_mean     | -3.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 557       |\n",
      "|    time_elapsed    | 1626      |\n",
      "|    total_timesteps | 1140736   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 922         |\n",
      "|    ep_rew_mean          | -3.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 1628        |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010843392 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+05    |\n",
      "|    n_updates            | 56430       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.15e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 926         |\n",
      "|    ep_rew_mean          | -3.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 702         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 1630        |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012567291 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.86e+06    |\n",
      "|    n_updates            | 56440       |\n",
      "|    policy_gradient_loss | 0.00918     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.39e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1145000, episode_reward=-30993.66 +/- 45582.27\n",
      "Episode length: 1264.80 +/- 1091.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.26e+03    |\n",
      "|    mean_reward          | -3.1e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1145000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007555652 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.41e+06    |\n",
      "|    n_updates            | 56450       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.1e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 924       |\n",
      "|    ep_rew_mean     | -3.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 560       |\n",
      "|    time_elapsed    | 1635      |\n",
      "|    total_timesteps | 1146880   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 917       |\n",
      "|    ep_rew_mean          | -3.33e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 701       |\n",
      "|    iterations           | 561       |\n",
      "|    time_elapsed         | 1636      |\n",
      "|    total_timesteps      | 1148928   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0058821 |\n",
      "|    clip_fraction        | 0.0355    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.97      |\n",
      "|    explained_variance   | 0.619     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.46e+07  |\n",
      "|    n_updates            | 56460     |\n",
      "|    policy_gradient_loss | -0.00474  |\n",
      "|    std                  | 0.21      |\n",
      "|    value_loss           | 1.32e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=-82800.65 +/- 14359.82\n",
      "Episode length: 1840.80 +/- 1470.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.84e+03    |\n",
      "|    mean_reward          | -8.28e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013911464 |\n",
      "|    clip_fraction        | 0.0974      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.16e+07    |\n",
      "|    n_updates            | 56470       |\n",
      "|    policy_gradient_loss | -0.000369   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.66e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 913       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 700       |\n",
      "|    iterations      | 562       |\n",
      "|    time_elapsed    | 1643      |\n",
      "|    total_timesteps | 1150976   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 913         |\n",
      "|    ep_rew_mean          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 1644        |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010401363 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.05e+06    |\n",
      "|    n_updates            | 56480       |\n",
      "|    policy_gradient_loss | 0.000152    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.06e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1155000, episode_reward=-6634.19 +/- 7821.31\n",
      "Episode length: 106.20 +/- 14.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 106         |\n",
      "|    mean_reward          | -6.63e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1155000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009355681 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+03    |\n",
      "|    n_updates            | 56490       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.93e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 942       |\n",
      "|    ep_rew_mean     | -3.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 564       |\n",
      "|    time_elapsed    | 1646      |\n",
      "|    total_timesteps | 1155072   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 954          |\n",
      "|    ep_rew_mean          | -3.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 701          |\n",
      "|    iterations           | 565          |\n",
      "|    time_elapsed         | 1648         |\n",
      "|    total_timesteps      | 1157120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056360653 |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.26e+06     |\n",
      "|    n_updates            | 56500        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.57e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 954          |\n",
      "|    ep_rew_mean          | -3.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 702          |\n",
      "|    iterations           | 566          |\n",
      "|    time_elapsed         | 1650         |\n",
      "|    total_timesteps      | 1159168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075988923 |\n",
      "|    clip_fraction        | 0.0589       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.416        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.62e+05     |\n",
      "|    n_updates            | 56510        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 5.65e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=-18315.05 +/- 20373.17\n",
      "Episode length: 1652.60 +/- 1947.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.65e+03    |\n",
      "|    mean_reward          | -1.83e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011390546 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 685         |\n",
      "|    n_updates            | 56520       |\n",
      "|    policy_gradient_loss | 0.00205     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 7.68e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 980       |\n",
      "|    ep_rew_mean     | -3.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 567       |\n",
      "|    time_elapsed    | 1656      |\n",
      "|    total_timesteps | 1161216   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 988         |\n",
      "|    ep_rew_mean          | -3.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 1658        |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023815991 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 685         |\n",
      "|    n_updates            | 56530       |\n",
      "|    policy_gradient_loss | 0.0062      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.44e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1165000, episode_reward=28155.66 +/- 27597.97\n",
      "Episode length: 3031.00 +/- 2030.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.03e+03    |\n",
      "|    mean_reward          | 2.82e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1165000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006310149 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+04    |\n",
      "|    n_updates            | 56540       |\n",
      "|    policy_gradient_loss | -0.000479   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.31e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 961       |\n",
      "|    ep_rew_mean     | -3.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 698       |\n",
      "|    iterations      | 569       |\n",
      "|    time_elapsed    | 1667      |\n",
      "|    total_timesteps | 1165312   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 963          |\n",
      "|    ep_rew_mean          | -3.28e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 699          |\n",
      "|    iterations           | 570          |\n",
      "|    time_elapsed         | 1669         |\n",
      "|    total_timesteps      | 1167360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055144206 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.92e+04     |\n",
      "|    n_updates            | 56550        |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.56e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 968         |\n",
      "|    ep_rew_mean          | -3.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 699         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 1670        |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030103968 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 540         |\n",
      "|    n_updates            | 56560       |\n",
      "|    policy_gradient_loss | 0.00928     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.6e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1170000, episode_reward=-63087.06 +/- 65473.53\n",
      "Episode length: 1742.20 +/- 1449.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.74e+03    |\n",
      "|    mean_reward          | -6.31e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028590623 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+07    |\n",
      "|    n_updates            | 56570       |\n",
      "|    policy_gradient_loss | 0.0144      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.3e+07     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 978       |\n",
      "|    ep_rew_mean     | -3.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 698       |\n",
      "|    iterations      | 572       |\n",
      "|    time_elapsed    | 1676      |\n",
      "|    total_timesteps | 1171456   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 940         |\n",
      "|    ep_rew_mean          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 699         |\n",
      "|    iterations           | 573         |\n",
      "|    time_elapsed         | 1678        |\n",
      "|    total_timesteps      | 1173504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016439069 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 493         |\n",
      "|    n_updates            | 56580       |\n",
      "|    policy_gradient_loss | 0.00388     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 8.41e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1175000, episode_reward=3061.96 +/- 30322.18\n",
      "Episode length: 2486.80 +/- 1977.34\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.49e+03     |\n",
      "|    mean_reward          | 3.06e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1175000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075915717 |\n",
      "|    clip_fraction        | 0.0793       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.28e+05     |\n",
      "|    n_updates            | 56590        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 9.9e+06      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 936       |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 697       |\n",
      "|    iterations      | 574       |\n",
      "|    time_elapsed    | 1686      |\n",
      "|    total_timesteps | 1175552   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 936         |\n",
      "|    ep_rew_mean          | -3.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 1688        |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023581598 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.23e+03    |\n",
      "|    n_updates            | 56600       |\n",
      "|    policy_gradient_loss | 0.00255     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.4e+04     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 936          |\n",
      "|    ep_rew_mean          | -3.21e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 697          |\n",
      "|    iterations           | 576          |\n",
      "|    time_elapsed         | 1690         |\n",
      "|    total_timesteps      | 1179648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049287155 |\n",
      "|    clip_fraction        | 0.0525       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+04      |\n",
      "|    n_updates            | 56610        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.2e+04      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=-5731.27 +/- 10578.57\n",
      "Episode length: 878.60 +/- 1572.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 879         |\n",
      "|    mean_reward          | -5.73e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010418166 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 661         |\n",
      "|    n_updates            | 56620       |\n",
      "|    policy_gradient_loss | -0.002      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.1e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 951       |\n",
      "|    ep_rew_mean     | -3.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 697       |\n",
      "|    iterations      | 577       |\n",
      "|    time_elapsed    | 1694      |\n",
      "|    total_timesteps | 1181696   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 951         |\n",
      "|    ep_rew_mean          | -3.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 1695        |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007840467 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.55e+03    |\n",
      "|    n_updates            | 56630       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 9.72e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1185000, episode_reward=-3375.85 +/- 37529.27\n",
      "Episode length: 1756.60 +/- 2080.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.76e+03    |\n",
      "|    mean_reward          | -3.38e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1185000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012036909 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.549       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+06    |\n",
      "|    n_updates            | 56640       |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.17e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 954       |\n",
      "|    ep_rew_mean     | -3.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 696       |\n",
      "|    iterations      | 579       |\n",
      "|    time_elapsed    | 1702      |\n",
      "|    total_timesteps | 1185792   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 954         |\n",
      "|    ep_rew_mean          | -3.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 697         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 1704        |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016927488 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.92e+04    |\n",
      "|    n_updates            | 56650       |\n",
      "|    policy_gradient_loss | 0.0048      |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.75e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 987         |\n",
      "|    ep_rew_mean          | -2.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 696         |\n",
      "|    iterations           | 581         |\n",
      "|    time_elapsed         | 1708        |\n",
      "|    total_timesteps      | 1189888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025369333 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 56660       |\n",
      "|    policy_gradient_loss | 0.00716     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 769         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1190000, episode_reward=-11667.28 +/- 45639.05\n",
      "Episode length: 1762.40 +/- 2139.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.76e+03    |\n",
      "|    mean_reward          | -1.17e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009231659 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 650         |\n",
      "|    n_updates            | 56670       |\n",
      "|    policy_gradient_loss | 0.00204     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.55e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 981       |\n",
      "|    ep_rew_mean     | -2.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 695       |\n",
      "|    iterations      | 582       |\n",
      "|    time_elapsed    | 1714      |\n",
      "|    total_timesteps | 1191936   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.87e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 695         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 1716        |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009099964 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.57e+06    |\n",
      "|    n_updates            | 56680       |\n",
      "|    policy_gradient_loss | 0.00022     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.38e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1195000, episode_reward=2854.00 +/- 18266.81\n",
      "Episode length: 1075.60 +/- 1809.82\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.08e+03     |\n",
      "|    mean_reward          | 2.85e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1195000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036450138 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.658        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05e+06     |\n",
      "|    n_updates            | 56690        |\n",
      "|    policy_gradient_loss | 0.00179      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 9.11e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 694       |\n",
      "|    iterations      | 584       |\n",
      "|    time_elapsed    | 1720      |\n",
      "|    total_timesteps | 1196032   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -3.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 585          |\n",
      "|    time_elapsed         | 1722         |\n",
      "|    total_timesteps      | 1198080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070115677 |\n",
      "|    clip_fraction        | 0.0433       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.527        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.94e+06     |\n",
      "|    n_updates            | 56700        |\n",
      "|    policy_gradient_loss | 0.000919     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.18e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=23885.52 +/- 22253.49\n",
      "Episode length: 2649.00 +/- 2202.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.65e+03    |\n",
      "|    mean_reward          | 2.39e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018767694 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 56710       |\n",
      "|    policy_gradient_loss | 0.00713     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.39e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.03e+03  |\n",
      "|    ep_rew_mean     | -2.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 586       |\n",
      "|    time_elapsed    | 1730      |\n",
      "|    total_timesteps | 1200128   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -2.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 693         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 1732        |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022959167 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 418         |\n",
      "|    n_updates            | 56720       |\n",
      "|    policy_gradient_loss | 0.00074     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 4.26e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -2.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 1734        |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007234295 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 484         |\n",
      "|    n_updates            | 56730       |\n",
      "|    policy_gradient_loss | 0.00069     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 6.62e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1205000, episode_reward=-4016.12 +/- 55815.43\n",
      "Episode length: 1937.20 +/- 2313.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.94e+03    |\n",
      "|    mean_reward          | -4.02e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1205000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020091735 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 432         |\n",
      "|    n_updates            | 56740       |\n",
      "|    policy_gradient_loss | 0.00511     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.79e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -2.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 692       |\n",
      "|    iterations      | 589       |\n",
      "|    time_elapsed    | 1741      |\n",
      "|    total_timesteps | 1206272   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.07e+03     |\n",
      "|    ep_rew_mean          | -2.96e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 590          |\n",
      "|    time_elapsed         | 1742         |\n",
      "|    total_timesteps      | 1208320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051507894 |\n",
      "|    clip_fraction        | 0.0957       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.93         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.42e+03     |\n",
      "|    n_updates            | 56750        |\n",
      "|    policy_gradient_loss | 0.00125      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.03e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1210000, episode_reward=-71938.53 +/- 95274.03\n",
      "Episode length: 2796.60 +/- 1599.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.8e+03     |\n",
      "|    mean_reward          | -7.19e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011788978 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 292         |\n",
      "|    n_updates            | 56760       |\n",
      "|    policy_gradient_loss | -0.00094    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.62e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -3.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 691       |\n",
      "|    iterations      | 591       |\n",
      "|    time_elapsed    | 1751      |\n",
      "|    total_timesteps | 1210368   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -3.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 1753        |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021724638 |\n",
      "|    clip_fraction        | 0.464       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.81e+07    |\n",
      "|    n_updates            | 56770       |\n",
      "|    policy_gradient_loss | 0.0313      |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.89e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -3.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 1755        |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009933357 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 418         |\n",
      "|    n_updates            | 56780       |\n",
      "|    policy_gradient_loss | -0.000518   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.47e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1215000, episode_reward=-84173.58 +/- 107091.85\n",
      "Episode length: 780.20 +/- 1335.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 780         |\n",
      "|    mean_reward          | -8.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1215000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006341353 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.65e+04    |\n",
      "|    n_updates            | 56790       |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.02e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -2.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 691       |\n",
      "|    iterations      | 594       |\n",
      "|    time_elapsed    | 1758      |\n",
      "|    total_timesteps | 1216512   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -2.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 692         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 1760        |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005169631 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.65e+03    |\n",
      "|    n_updates            | 56800       |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.34e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=-76738.52 +/- 70395.20\n",
      "Episode length: 1716.60 +/- 1750.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.72e+03    |\n",
      "|    mean_reward          | -7.67e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011572853 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 551         |\n",
      "|    n_updates            | 56810       |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.39e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.16e+03  |\n",
      "|    ep_rew_mean     | -3.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 690       |\n",
      "|    iterations      | 596       |\n",
      "|    time_elapsed    | 1766      |\n",
      "|    total_timesteps | 1220608   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | -3.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 1768        |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002672559 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.502       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.72e+06    |\n",
      "|    n_updates            | 56820       |\n",
      "|    policy_gradient_loss | 0.000205    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.56e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | -3.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 1770        |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007998097 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.93e+04    |\n",
      "|    n_updates            | 56830       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.53e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1225000, episode_reward=-50162.71 +/- 103189.47\n",
      "Episode length: 1169.80 +/- 1924.32\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.17e+03     |\n",
      "|    mean_reward          | -5.02e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1225000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009289847 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.95         |\n",
      "|    explained_variance   | 0.511        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.09e+07     |\n",
      "|    n_updates            | 56840        |\n",
      "|    policy_gradient_loss | -0.000603    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 7.7e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.16e+03  |\n",
      "|    ep_rew_mean     | -3.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 690       |\n",
      "|    iterations      | 599       |\n",
      "|    time_elapsed    | 1775      |\n",
      "|    total_timesteps | 1226752   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | -3.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 1777        |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013939395 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 454         |\n",
      "|    n_updates            | 56850       |\n",
      "|    policy_gradient_loss | 0.00254     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=-26827.69 +/- 73237.26\n",
      "Episode length: 1655.00 +/- 2037.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.66e+03    |\n",
      "|    mean_reward          | -2.68e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013089528 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.95        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 686         |\n",
      "|    n_updates            | 56860       |\n",
      "|    policy_gradient_loss | -0.000765   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.44e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.2e+03  |\n",
      "|    ep_rew_mean     | -3.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 690      |\n",
      "|    iterations      | 601      |\n",
      "|    time_elapsed    | 1783     |\n",
      "|    total_timesteps | 1230848  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -3.6e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 690         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 1785        |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012869036 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2e+07     |\n",
      "|    n_updates            | 56870       |\n",
      "|    policy_gradient_loss | 0.00731     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.42e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -3.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 691         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 1786        |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012019384 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 546         |\n",
      "|    n_updates            | 56880       |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1235000, episode_reward=36812.55 +/- 29805.02\n",
      "Episode length: 3038.60 +/- 2402.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.04e+03    |\n",
      "|    mean_reward          | 3.68e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1235000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017088037 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.573       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7e+06       |\n",
      "|    n_updates            | 56890       |\n",
      "|    policy_gradient_loss | 0.00347     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 9.1e+06     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -3.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 688       |\n",
      "|    iterations      | 604       |\n",
      "|    time_elapsed    | 1796      |\n",
      "|    total_timesteps | 1236992   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -3.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 1798        |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019056937 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 56900       |\n",
      "|    policy_gradient_loss | 0.00449     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 700         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=883.27 +/- 29396.07\n",
      "Episode length: 1178.40 +/- 1925.75\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.18e+03   |\n",
      "|    mean_reward          | 883        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1240000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02155669 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.98       |\n",
      "|    explained_variance   | 0.907      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 534        |\n",
      "|    n_updates            | 56910      |\n",
      "|    policy_gradient_loss | 0.0118     |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 2.8e+03    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.28e+03  |\n",
      "|    ep_rew_mean     | -3.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 688       |\n",
      "|    iterations      | 606       |\n",
      "|    time_elapsed    | 1802      |\n",
      "|    total_timesteps | 1241088   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | -3.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 688         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 1804        |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008609043 |\n",
      "|    clip_fraction        | 0.0758      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 787         |\n",
      "|    n_updates            | 56920       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 5.22e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1245000, episode_reward=25622.38 +/- 27828.06\n",
      "Episode length: 2733.00 +/- 2265.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.73e+03     |\n",
      "|    mean_reward          | 2.56e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1245000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0113815665 |\n",
      "|    clip_fraction        | 0.0671       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.28e+06     |\n",
      "|    n_updates            | 56930        |\n",
      "|    policy_gradient_loss | -0.0034      |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.84e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.3e+03   |\n",
      "|    ep_rew_mean     | -3.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 608       |\n",
      "|    time_elapsed    | 1812      |\n",
      "|    total_timesteps | 1245184   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.3e+03      |\n",
      "|    ep_rew_mean          | -3.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 609          |\n",
      "|    time_elapsed         | 1814         |\n",
      "|    total_timesteps      | 1247232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038229427 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.508        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+07      |\n",
      "|    n_updates            | 56940        |\n",
      "|    policy_gradient_loss | 0.000466     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.12e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.3e+03      |\n",
      "|    ep_rew_mean          | -3.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 1816         |\n",
      "|    total_timesteps      | 1249280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062645865 |\n",
      "|    clip_fraction        | 0.0355       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.718        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66e+04     |\n",
      "|    n_updates            | 56950        |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.24e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=15273.14 +/- 63550.52\n",
      "Episode length: 3011.80 +/- 2435.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.01e+03    |\n",
      "|    mean_reward          | 1.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010868644 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 242         |\n",
      "|    n_updates            | 56960       |\n",
      "|    policy_gradient_loss | -4.13e-05   |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 3.69e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.3e+03   |\n",
      "|    ep_rew_mean     | -3.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 611       |\n",
      "|    time_elapsed    | 1825      |\n",
      "|    total_timesteps | 1251328   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | -3.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 1827        |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010753894 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.7e+04     |\n",
      "|    n_updates            | 56970       |\n",
      "|    policy_gradient_loss | 0.00174     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 9.03e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1255000, episode_reward=-13825.95 +/- 89187.97\n",
      "Episode length: 3591.00 +/- 1912.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.59e+03    |\n",
      "|    mean_reward          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1255000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011232588 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.537       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 56980       |\n",
      "|    policy_gradient_loss | 0.0044      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 4.63e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.3e+03   |\n",
      "|    ep_rew_mean     | -3.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 613       |\n",
      "|    time_elapsed    | 1837      |\n",
      "|    total_timesteps | 1255424   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | -3.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 1839        |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013381032 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 56990       |\n",
      "|    policy_gradient_loss | 0.00681     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 838         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | -3.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 1841        |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010078328 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 333         |\n",
      "|    n_updates            | 57000       |\n",
      "|    policy_gradient_loss | 0.00286     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=-58517.55 +/- 84222.28\n",
      "Episode length: 2045.60 +/- 1859.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.05e+03    |\n",
      "|    mean_reward          | -5.85e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006228311 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+06    |\n",
      "|    n_updates            | 57010       |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.24e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.3e+03   |\n",
      "|    ep_rew_mean     | -3.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 616       |\n",
      "|    time_elapsed    | 1848      |\n",
      "|    total_timesteps | 1261568   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | -3.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 1850        |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026307724 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 57020       |\n",
      "|    policy_gradient_loss | 0.00619     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 614         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1265000, episode_reward=-149055.08 +/- 149332.76\n",
      "Episode length: 728.40 +/- 830.77\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 728        |\n",
      "|    mean_reward          | -1.49e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1265000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09161258 |\n",
      "|    clip_fraction        | 0.536      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.463      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.08e+07   |\n",
      "|    n_updates            | 57030      |\n",
      "|    policy_gradient_loss | 0.0433     |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 4.47e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.26e+03  |\n",
      "|    ep_rew_mean     | -3.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 618       |\n",
      "|    time_elapsed    | 1853      |\n",
      "|    total_timesteps | 1265664   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | -3.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 619          |\n",
      "|    time_elapsed         | 1855         |\n",
      "|    total_timesteps      | 1267712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016296844 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.502        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.93e+07     |\n",
      "|    n_updates            | 57040        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 7.58e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | -3.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 1857        |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007324255 |\n",
      "|    clip_fraction        | 0.044       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.87e+07    |\n",
      "|    n_updates            | 57050       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.25e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1270000, episode_reward=-135663.82 +/- 162104.98\n",
      "Episode length: 789.60 +/- 851.96\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 790          |\n",
      "|    mean_reward          | -1.36e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1270000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071312115 |\n",
      "|    clip_fraction        | 0.0519       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.848        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.32e+03     |\n",
      "|    n_updates            | 57060        |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 5.57e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.24e+03  |\n",
      "|    ep_rew_mean     | -3.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 621       |\n",
      "|    time_elapsed    | 1861      |\n",
      "|    total_timesteps | 1271808   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.24e+03  |\n",
      "|    ep_rew_mean          | -3.31e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 683       |\n",
      "|    iterations           | 622       |\n",
      "|    time_elapsed         | 1863      |\n",
      "|    total_timesteps      | 1273856   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1976769 |\n",
      "|    clip_fraction        | 0.521     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.03      |\n",
      "|    explained_variance   | 0.951     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 161       |\n",
      "|    n_updates            | 57070     |\n",
      "|    policy_gradient_loss | 0.0101    |\n",
      "|    std                  | 0.207     |\n",
      "|    value_loss           | 1.36e+03  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1275000, episode_reward=-61322.20 +/- 108010.20\n",
      "Episode length: 74.60 +/- 56.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 74.6        |\n",
      "|    mean_reward          | -6.13e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1275000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017016381 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 581         |\n",
      "|    n_updates            | 57080       |\n",
      "|    policy_gradient_loss | 0.00168     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.29e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.29e+03  |\n",
      "|    ep_rew_mean     | -3.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 623       |\n",
      "|    time_elapsed    | 1865      |\n",
      "|    total_timesteps | 1275904   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.29e+03   |\n",
      "|    ep_rew_mean          | -3.23e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 684        |\n",
      "|    iterations           | 624        |\n",
      "|    time_elapsed         | 1866       |\n",
      "|    total_timesteps      | 1277952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01684277 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 267        |\n",
      "|    n_updates            | 57090      |\n",
      "|    policy_gradient_loss | 4.86e-05   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 4.35e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=15814.88 +/- 27651.21\n",
      "Episode length: 2040.60 +/- 2416.55\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.04e+03     |\n",
      "|    mean_reward          | 1.58e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068403054 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 230          |\n",
      "|    n_updates            | 57100        |\n",
      "|    policy_gradient_loss | 0.000612     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.62e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 625       |\n",
      "|    time_elapsed    | 1873      |\n",
      "|    total_timesteps | 1280000   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | -3.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 626          |\n",
      "|    time_elapsed         | 1875         |\n",
      "|    total_timesteps      | 1282048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061319964 |\n",
      "|    clip_fraction        | 0.0509       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.639        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.25e+03     |\n",
      "|    n_updates            | 57110        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.32e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | -3.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 627          |\n",
      "|    time_elapsed         | 1877         |\n",
      "|    total_timesteps      | 1284096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0151393395 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 316          |\n",
      "|    n_updates            | 57120        |\n",
      "|    policy_gradient_loss | 0.000374     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 853          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1285000, episode_reward=35436.62 +/- 28383.93\n",
      "Episode length: 3046.00 +/- 2393.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.05e+03    |\n",
      "|    mean_reward          | 3.54e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1285000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009403083 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.36e+03    |\n",
      "|    n_updates            | 57130       |\n",
      "|    policy_gradient_loss | 0.0214      |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.31e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -2.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 628       |\n",
      "|    time_elapsed    | 1886      |\n",
      "|    total_timesteps | 1286144   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | -2.95e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 629          |\n",
      "|    time_elapsed         | 1888         |\n",
      "|    total_timesteps      | 1288192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042532473 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | 0.775        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+04     |\n",
      "|    n_updates            | 57140        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.3e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1290000, episode_reward=8944.99 +/- 24038.77\n",
      "Episode length: 1216.40 +/- 1911.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.22e+03    |\n",
      "|    mean_reward          | 8.94e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007358309 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 57150       |\n",
      "|    policy_gradient_loss | -0.00513    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.39e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -2.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 630       |\n",
      "|    time_elapsed    | 1892      |\n",
      "|    total_timesteps | 1290240   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | -2.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 1894        |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010960296 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.72e+03    |\n",
      "|    n_updates            | 57160       |\n",
      "|    policy_gradient_loss | -0.00931    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.74e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | -2.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 1896        |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005800897 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54e+04    |\n",
      "|    n_updates            | 57170       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.18e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1295000, episode_reward=-181.64 +/- 1485.57\n",
      "Episode length: 154.60 +/- 165.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 155         |\n",
      "|    mean_reward          | -182        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1295000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028960353 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 385         |\n",
      "|    n_updates            | 57180       |\n",
      "|    policy_gradient_loss | 0.00269     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.26e+03  |\n",
      "|    ep_rew_mean     | -2.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 633       |\n",
      "|    time_elapsed    | 1898      |\n",
      "|    total_timesteps | 1296384   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | -2.56e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 634          |\n",
      "|    time_elapsed         | 1900         |\n",
      "|    total_timesteps      | 1298432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0148016885 |\n",
      "|    clip_fraction        | 0.247        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 112          |\n",
      "|    n_updates            | 57190        |\n",
      "|    policy_gradient_loss | 0.0102       |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 811          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=-8647.04 +/- 9055.74\n",
      "Episode length: 331.00 +/- 462.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 331         |\n",
      "|    mean_reward          | -8.65e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011976128 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 57200       |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.9e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.27e+03  |\n",
      "|    ep_rew_mean     | -2.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 635       |\n",
      "|    time_elapsed    | 1903      |\n",
      "|    total_timesteps | 1300480   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.27e+03     |\n",
      "|    ep_rew_mean          | -2.7e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 636          |\n",
      "|    time_elapsed         | 1905         |\n",
      "|    total_timesteps      | 1302528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097066015 |\n",
      "|    clip_fraction        | 0.0693       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+05     |\n",
      "|    n_updates            | 57210        |\n",
      "|    policy_gradient_loss | 0.00363      |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.14e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -2.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 637          |\n",
      "|    time_elapsed         | 1906         |\n",
      "|    total_timesteps      | 1304576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052353917 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.76e+06     |\n",
      "|    n_updates            | 57220        |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.11e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1305000, episode_reward=-56415.87 +/- 109620.70\n",
      "Episode length: 363.80 +/- 552.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 364          |\n",
      "|    mean_reward          | -5.64e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1305000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028731003 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.529        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.63e+05     |\n",
      "|    n_updates            | 57230        |\n",
      "|    policy_gradient_loss | -0.000785    |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 4.65e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -3.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 638       |\n",
      "|    time_elapsed    | 1909      |\n",
      "|    total_timesteps | 1306624   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -2.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 639          |\n",
      "|    time_elapsed         | 1911         |\n",
      "|    total_timesteps      | 1308672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028435504 |\n",
      "|    clip_fraction        | 0.0041       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.528        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.46e+07     |\n",
      "|    n_updates            | 57240        |\n",
      "|    policy_gradient_loss | -0.000638    |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 4.82e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1310000, episode_reward=-19888.10 +/- 20411.12\n",
      "Episode length: 443.60 +/- 468.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 444         |\n",
      "|    mean_reward          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003850261 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.59e+07    |\n",
      "|    n_updates            | 57250       |\n",
      "|    policy_gradient_loss | 0.000792    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 3.33e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 870       |\n",
      "|    ep_rew_mean     | -2.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 640       |\n",
      "|    time_elapsed    | 1914      |\n",
      "|    total_timesteps | 1310720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 782         |\n",
      "|    ep_rew_mean          | -2.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 1916        |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005728727 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13e+06    |\n",
      "|    n_updates            | 57260       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 3.6e+06     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 739          |\n",
      "|    ep_rew_mean          | -2.3e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 642          |\n",
      "|    time_elapsed         | 1918         |\n",
      "|    total_timesteps      | 1314816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028841174 |\n",
      "|    clip_fraction        | 0.0228       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+05     |\n",
      "|    n_updates            | 57270        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 5.22e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1315000, episode_reward=-14731.26 +/- 4886.14\n",
      "Episode length: 750.20 +/- 428.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 750         |\n",
      "|    mean_reward          | -1.47e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1315000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027592978 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.581       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.9e+05     |\n",
      "|    n_updates            | 57280       |\n",
      "|    policy_gradient_loss | 0.00401     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 5.25e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 733       |\n",
      "|    ep_rew_mean     | -2.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 643       |\n",
      "|    time_elapsed    | 1921      |\n",
      "|    total_timesteps | 1316864   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 714         |\n",
      "|    ep_rew_mean          | -2.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 1923        |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011125155 |\n",
      "|    clip_fraction        | 0.0996      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+04    |\n",
      "|    n_updates            | 57290       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.58e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1320000, episode_reward=-18100.58 +/- 15109.86\n",
      "Episode length: 462.20 +/- 811.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 462         |\n",
      "|    mean_reward          | -1.81e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012595214 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.86e+04    |\n",
      "|    n_updates            | 57300       |\n",
      "|    policy_gradient_loss | -0.000527   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 4.07e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 695       |\n",
      "|    ep_rew_mean     | -2.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 645       |\n",
      "|    time_elapsed    | 1926      |\n",
      "|    total_timesteps | 1320960   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 697         |\n",
      "|    ep_rew_mean          | -2.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 1928        |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009292852 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.39e+06    |\n",
      "|    n_updates            | 57310       |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.61e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1325000, episode_reward=-7817.14 +/- 21287.89\n",
      "Episode length: 1516.60 +/- 1968.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.52e+03    |\n",
      "|    mean_reward          | -7.82e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1325000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007764572 |\n",
      "|    clip_fraction        | 0.0732      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.67e+05    |\n",
      "|    n_updates            | 57320       |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.23e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 662       |\n",
      "|    ep_rew_mean     | -2.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 647       |\n",
      "|    time_elapsed    | 1934      |\n",
      "|    total_timesteps | 1325056   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -2.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 1936        |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024513185 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+04    |\n",
      "|    n_updates            | 57330       |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 5.72e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -2.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 1937        |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025499212 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 57340       |\n",
      "|    policy_gradient_loss | 0.00799     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.42e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=-53887.23 +/- 129494.51\n",
      "Episode length: 1258.60 +/- 1896.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.26e+03    |\n",
      "|    mean_reward          | -5.39e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007954387 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 57350       |\n",
      "|    policy_gradient_loss | 0.000358    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.1e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 658       |\n",
      "|    ep_rew_mean     | -1.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 650       |\n",
      "|    time_elapsed    | 1942      |\n",
      "|    total_timesteps | 1331200   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 683         |\n",
      "|    ep_rew_mean          | -1.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 685         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 1944        |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006258919 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.88e+06    |\n",
      "|    n_updates            | 57360       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.03e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1335000, episode_reward=25120.05 +/- 27060.79\n",
      "Episode length: 3020.80 +/- 2424.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.02e+03    |\n",
      "|    mean_reward          | 2.51e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1335000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006806619 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 974         |\n",
      "|    n_updates            | 57370       |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.8e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 699       |\n",
      "|    ep_rew_mean     | -1.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 652       |\n",
      "|    time_elapsed    | 1953      |\n",
      "|    total_timesteps | 1335296   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 699         |\n",
      "|    ep_rew_mean          | -1.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 1955        |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025816865 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 380         |\n",
      "|    n_updates            | 57380       |\n",
      "|    policy_gradient_loss | 0.00248     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1e+05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 699         |\n",
      "|    ep_rew_mean          | -1.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 1957        |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008152951 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 57390       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 9.25e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=10015.33 +/- 20837.51\n",
      "Episode length: 1603.40 +/- 1975.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6e+03      |\n",
      "|    mean_reward          | 1e+04        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1340000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055457796 |\n",
      "|    clip_fraction        | 0.0707       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 57400        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.84e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 761       |\n",
      "|    ep_rew_mean     | -1.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 655       |\n",
      "|    time_elapsed    | 1963      |\n",
      "|    total_timesteps | 1341440   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 775        |\n",
      "|    ep_rew_mean          | -1.51e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 683        |\n",
      "|    iterations           | 656        |\n",
      "|    time_elapsed         | 1964       |\n",
      "|    total_timesteps      | 1343488    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00267379 |\n",
      "|    clip_fraction        | 0.00791    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.522      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.76e+05   |\n",
      "|    n_updates            | 57410      |\n",
      "|    policy_gradient_loss | -0.00213   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 3.2e+06    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1345000, episode_reward=-94628.08 +/- 76372.71\n",
      "Episode length: 1982.60 +/- 2367.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.98e+03    |\n",
      "|    mean_reward          | -9.46e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1345000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019899037 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 362         |\n",
      "|    n_updates            | 57420       |\n",
      "|    policy_gradient_loss | 5.99e-05    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 2.62e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 754       |\n",
      "|    ep_rew_mean     | -1.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 657       |\n",
      "|    time_elapsed    | 1971      |\n",
      "|    total_timesteps | 1345536   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 754          |\n",
      "|    ep_rew_mean          | -1.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 658          |\n",
      "|    time_elapsed         | 1973         |\n",
      "|    total_timesteps      | 1347584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044146795 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.71e+06     |\n",
      "|    n_updates            | 57430        |\n",
      "|    policy_gradient_loss | -9.45e-05    |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 8.16e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 699        |\n",
      "|    ep_rew_mean          | -1.64e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 683        |\n",
      "|    iterations           | 659        |\n",
      "|    time_elapsed         | 1975       |\n",
      "|    total_timesteps      | 1349632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01055845 |\n",
      "|    clip_fraction        | 0.0655     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.01       |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 794        |\n",
      "|    n_updates            | 57440      |\n",
      "|    policy_gradient_loss | -0.000725  |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 7.92e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=-90121.11 +/- 118303.01\n",
      "Episode length: 246.20 +/- 283.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 246          |\n",
      "|    mean_reward          | -9.01e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1350000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017478033 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.61e+07     |\n",
      "|    n_updates            | 57450        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 5.14e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 712       |\n",
      "|    ep_rew_mean     | -1.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 660       |\n",
      "|    time_elapsed    | 1977      |\n",
      "|    total_timesteps | 1351680   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 712          |\n",
      "|    ep_rew_mean          | -1.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 683          |\n",
      "|    iterations           | 661          |\n",
      "|    time_elapsed         | 1979         |\n",
      "|    total_timesteps      | 1353728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046678185 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.18e+04     |\n",
      "|    n_updates            | 57460        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.55e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1355000, episode_reward=-89103.70 +/- 67276.00\n",
      "Episode length: 989.40 +/- 1153.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 989         |\n",
      "|    mean_reward          | -8.91e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1355000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011410978 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 57470       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 8.74e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 744       |\n",
      "|    ep_rew_mean     | -1.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 662       |\n",
      "|    time_elapsed    | 1983      |\n",
      "|    total_timesteps | 1355776   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 744         |\n",
      "|    ep_rew_mean          | -1.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 1985        |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009522829 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.814       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.87e+05    |\n",
      "|    n_updates            | 57480       |\n",
      "|    policy_gradient_loss | 0.00443     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 3.35e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 750         |\n",
      "|    ep_rew_mean          | -1.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 1987        |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007158313 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 917         |\n",
      "|    n_updates            | 57490       |\n",
      "|    policy_gradient_loss | -0.000515   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 7.4e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=3727.25 +/- 88819.03\n",
      "Episode length: 3627.20 +/- 1838.24\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.63e+03     |\n",
      "|    mean_reward          | 3.73e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010036284 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.79e+06     |\n",
      "|    n_updates            | 57500        |\n",
      "|    policy_gradient_loss | -0.000377    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.04e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 758       |\n",
      "|    ep_rew_mean     | -2.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 665       |\n",
      "|    time_elapsed    | 1997      |\n",
      "|    total_timesteps | 1361920   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 759        |\n",
      "|    ep_rew_mean          | -2.11e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 682        |\n",
      "|    iterations           | 666        |\n",
      "|    time_elapsed         | 1999       |\n",
      "|    total_timesteps      | 1363968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00311486 |\n",
      "|    clip_fraction        | 0.00615    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.512      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.4e+07    |\n",
      "|    n_updates            | 57510      |\n",
      "|    policy_gradient_loss | -0.004     |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 7.08e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1365000, episode_reward=27372.62 +/- 42823.91\n",
      "Episode length: 3030.60 +/- 2412.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.03e+03     |\n",
      "|    mean_reward          | 2.74e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1365000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059814984 |\n",
      "|    clip_fraction        | 0.0695       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.01e+04     |\n",
      "|    n_updates            | 57520        |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.83e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 759       |\n",
      "|    ep_rew_mean     | -2.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 667       |\n",
      "|    time_elapsed    | 2008      |\n",
      "|    total_timesteps | 1366016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 757         |\n",
      "|    ep_rew_mean          | -2.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 680         |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 2010        |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014900365 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 353         |\n",
      "|    n_updates            | 57530       |\n",
      "|    policy_gradient_loss | 0.0244      |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1370000, episode_reward=-101188.56 +/- 159405.29\n",
      "Episode length: 491.80 +/- 516.92\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 492        |\n",
      "|    mean_reward          | -1.01e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1370000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24847949 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.604      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 232        |\n",
      "|    n_updates            | 57540      |\n",
      "|    policy_gradient_loss | 0.0358     |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 7.34e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 757       |\n",
      "|    ep_rew_mean     | -2.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 669       |\n",
      "|    time_elapsed    | 2013      |\n",
      "|    total_timesteps | 1370112   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 757        |\n",
      "|    ep_rew_mean          | -2.19e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 680        |\n",
      "|    iterations           | 670        |\n",
      "|    time_elapsed         | 2015       |\n",
      "|    total_timesteps      | 1372160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00885131 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 286        |\n",
      "|    n_updates            | 57550      |\n",
      "|    policy_gradient_loss | 0.00337    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.59e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 774        |\n",
      "|    ep_rew_mean          | -2.28e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 681        |\n",
      "|    iterations           | 671        |\n",
      "|    time_elapsed         | 2017       |\n",
      "|    total_timesteps      | 1374208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01916358 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.521      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.78e+04   |\n",
      "|    n_updates            | 57560      |\n",
      "|    policy_gradient_loss | -5.62e-05  |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 5.54e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1375000, episode_reward=-86195.98 +/- 184011.83\n",
      "Episode length: 1071.80 +/- 858.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.07e+03     |\n",
      "|    mean_reward          | -8.62e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1375000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050775874 |\n",
      "|    clip_fraction        | 0.074        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.97e+05     |\n",
      "|    n_updates            | 57570        |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.09e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 774       |\n",
      "|    ep_rew_mean     | -2.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 672       |\n",
      "|    time_elapsed    | 2021      |\n",
      "|    total_timesteps | 1376256   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 774         |\n",
      "|    ep_rew_mean          | -2.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 2023        |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014023382 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 294         |\n",
      "|    n_updates            | 57580       |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.51e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=-39410.70 +/- 32058.50\n",
      "Episode length: 757.40 +/- 516.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 757         |\n",
      "|    mean_reward          | -3.94e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034128096 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 279         |\n",
      "|    n_updates            | 57590       |\n",
      "|    policy_gradient_loss | 0.00394     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.32e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 803       |\n",
      "|    ep_rew_mean     | -2.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 674       |\n",
      "|    time_elapsed    | 2027      |\n",
      "|    total_timesteps | 1380352   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 791         |\n",
      "|    ep_rew_mean          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 675         |\n",
      "|    time_elapsed         | 2029        |\n",
      "|    total_timesteps      | 1382400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005423677 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.19e+06    |\n",
      "|    n_updates            | 57600       |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.75e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 788          |\n",
      "|    ep_rew_mean          | -2.46e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 681          |\n",
      "|    iterations           | 676          |\n",
      "|    time_elapsed         | 2031         |\n",
      "|    total_timesteps      | 1384448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053198095 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+07     |\n",
      "|    n_updates            | 57610        |\n",
      "|    policy_gradient_loss | 0.000606     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 5.31e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1385000, episode_reward=-124690.63 +/- 177900.23\n",
      "Episode length: 513.60 +/- 475.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 514         |\n",
      "|    mean_reward          | -1.25e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1385000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008947574 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.27e+05    |\n",
      "|    n_updates            | 57620       |\n",
      "|    policy_gradient_loss | -0.0038     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.22e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 791       |\n",
      "|    ep_rew_mean     | -2.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 677       |\n",
      "|    time_elapsed    | 2034      |\n",
      "|    total_timesteps | 1386496   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 806          |\n",
      "|    ep_rew_mean          | -2.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 681          |\n",
      "|    iterations           | 678          |\n",
      "|    time_elapsed         | 2036         |\n",
      "|    total_timesteps      | 1388544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041976185 |\n",
      "|    clip_fraction        | 0.0503       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.18e+06     |\n",
      "|    n_updates            | 57630        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 6.19e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=-143270.36 +/- 122076.73\n",
      "Episode length: 551.40 +/- 466.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 551         |\n",
      "|    mean_reward          | -1.43e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004473648 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.29e+07    |\n",
      "|    n_updates            | 57640       |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.13e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 808       |\n",
      "|    ep_rew_mean     | -2.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 679       |\n",
      "|    time_elapsed    | 2039      |\n",
      "|    total_timesteps | 1390592   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 833          |\n",
      "|    ep_rew_mean          | -2.83e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 680          |\n",
      "|    time_elapsed         | 2041         |\n",
      "|    total_timesteps      | 1392640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036500741 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.94e+06     |\n",
      "|    n_updates            | 57650        |\n",
      "|    policy_gradient_loss | -0.000797    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.47e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 833        |\n",
      "|    ep_rew_mean          | -3.11e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 682        |\n",
      "|    iterations           | 681        |\n",
      "|    time_elapsed         | 2042       |\n",
      "|    total_timesteps      | 1394688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00526675 |\n",
      "|    clip_fraction        | 0.0459     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.901      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.02e+04   |\n",
      "|    n_updates            | 57660      |\n",
      "|    policy_gradient_loss | -0.00715   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 4.33e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1395000, episode_reward=-134833.51 +/- 187002.91\n",
      "Episode length: 1099.20 +/- 1579.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.1e+03      |\n",
      "|    mean_reward          | -1.35e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1395000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031219306 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.487        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.23e+06     |\n",
      "|    n_updates            | 57670        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.59e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 836       |\n",
      "|    ep_rew_mean     | -3.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 682       |\n",
      "|    time_elapsed    | 2047      |\n",
      "|    total_timesteps | 1396736   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 863          |\n",
      "|    ep_rew_mean          | -3.39e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 683          |\n",
      "|    time_elapsed         | 2049         |\n",
      "|    total_timesteps      | 1398784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029610163 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.645        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.03e+05     |\n",
      "|    n_updates            | 57680        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.28e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=-65112.61 +/- 98171.70\n",
      "Episode length: 202.80 +/- 178.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 203         |\n",
      "|    mean_reward          | -6.51e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003501397 |\n",
      "|    clip_fraction        | 0.0218      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+07    |\n",
      "|    n_updates            | 57690       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.12e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 876       |\n",
      "|    ep_rew_mean     | -4.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 684       |\n",
      "|    time_elapsed    | 2051      |\n",
      "|    total_timesteps | 1400832   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 861         |\n",
      "|    ep_rew_mean          | -4.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 2053        |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008240599 |\n",
      "|    clip_fraction        | 0.0693      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.46e+07    |\n",
      "|    n_updates            | 57700       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.47e+08    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 847         |\n",
      "|    ep_rew_mean          | -5.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 2055        |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007848222 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.47e+07    |\n",
      "|    n_updates            | 57710       |\n",
      "|    policy_gradient_loss | 0.00607     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.33e+08    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1405000, episode_reward=-97199.45 +/- 133945.80\n",
      "Episode length: 2628.00 +/- 1999.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.63e+03    |\n",
      "|    mean_reward          | -9.72e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1405000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007737805 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.48        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.34e+07    |\n",
      "|    n_updates            | 57720       |\n",
      "|    policy_gradient_loss | 0.00159     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.13e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 854       |\n",
      "|    ep_rew_mean     | -5.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 687       |\n",
      "|    time_elapsed    | 2063      |\n",
      "|    total_timesteps | 1406976   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 866        |\n",
      "|    ep_rew_mean          | -5.57e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 682        |\n",
      "|    iterations           | 688        |\n",
      "|    time_elapsed         | 2065       |\n",
      "|    total_timesteps      | 1409024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01362989 |\n",
      "|    clip_fraction        | 0.0874     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.709      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.76e+03   |\n",
      "|    n_updates            | 57730      |\n",
      "|    policy_gradient_loss | -0.00152   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.47e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1410000, episode_reward=2732.97 +/- 24001.79\n",
      "Episode length: 1416.80 +/- 1819.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.42e+03    |\n",
      "|    mean_reward          | 2.73e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002236811 |\n",
      "|    clip_fraction        | 0.0177      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.515       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.37e+06    |\n",
      "|    n_updates            | 57740       |\n",
      "|    policy_gradient_loss | -0.00376    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.61e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 866       |\n",
      "|    ep_rew_mean     | -5.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 681       |\n",
      "|    iterations      | 689       |\n",
      "|    time_elapsed    | 2070      |\n",
      "|    total_timesteps | 1411072   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 915         |\n",
      "|    ep_rew_mean          | -5.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 681         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 2072        |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020582061 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 57750       |\n",
      "|    policy_gradient_loss | 0.00229     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.21e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1415000, episode_reward=-102779.53 +/- 189288.94\n",
      "Episode length: 170.00 +/- 132.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 170         |\n",
      "|    mean_reward          | -1.03e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1415000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010397487 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 387         |\n",
      "|    n_updates            | 57760       |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.86e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 926       |\n",
      "|    ep_rew_mean     | -5.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 682       |\n",
      "|    iterations      | 691       |\n",
      "|    time_elapsed    | 2074      |\n",
      "|    total_timesteps | 1415168   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 910          |\n",
      "|    ep_rew_mean          | -5.64e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 682          |\n",
      "|    iterations           | 692          |\n",
      "|    time_elapsed         | 2076         |\n",
      "|    total_timesteps      | 1417216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061271437 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.05         |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.48e+05     |\n",
      "|    n_updates            | 57770        |\n",
      "|    policy_gradient_loss | -0.000318    |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 7.72e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 930         |\n",
      "|    ep_rew_mean          | -5.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 682         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 2078        |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019303277 |\n",
      "|    clip_fraction        | 0.0688      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.563       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.44e+06    |\n",
      "|    n_updates            | 57780       |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 7.25e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=-19188.56 +/- 28904.05\n",
      "Episode length: 223.80 +/- 305.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 224         |\n",
      "|    mean_reward          | -1.92e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008361815 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.97e+06    |\n",
      "|    n_updates            | 57790       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 3.98e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 882       |\n",
      "|    ep_rew_mean     | -5.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 694       |\n",
      "|    time_elapsed    | 2080      |\n",
      "|    total_timesteps | 1421312   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 884         |\n",
      "|    ep_rew_mean          | -6.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 2082        |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014546277 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.29e+04    |\n",
      "|    n_updates            | 57800       |\n",
      "|    policy_gradient_loss | 0.00097     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 4.51e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1425000, episode_reward=-20464.09 +/- 13918.94\n",
      "Episode length: 206.00 +/- 164.95\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 206       |\n",
      "|    mean_reward          | -2.05e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1425000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0110384 |\n",
      "|    clip_fraction        | 0.116     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.05      |\n",
      "|    explained_variance   | 0.505     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 5.47e+07  |\n",
      "|    n_updates            | 57810     |\n",
      "|    policy_gradient_loss | 0.00425   |\n",
      "|    std                  | 0.206     |\n",
      "|    value_loss           | 8.25e+07  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 838       |\n",
      "|    ep_rew_mean     | -6.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 696       |\n",
      "|    time_elapsed    | 2084      |\n",
      "|    total_timesteps | 1425408   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 791         |\n",
      "|    ep_rew_mean          | -5.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 2086        |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013599893 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 759         |\n",
      "|    n_updates            | 57820       |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 8.47e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 802         |\n",
      "|    ep_rew_mean          | -5.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 2088        |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005949182 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.538       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.96e+06    |\n",
      "|    n_updates            | 57830       |\n",
      "|    policy_gradient_loss | -0.00335    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.59e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1430000, episode_reward=-6960.09 +/- 9441.72\n",
      "Episode length: 311.60 +/- 394.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 312         |\n",
      "|    mean_reward          | -6.96e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007987187 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.57e+03    |\n",
      "|    n_updates            | 57840       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.3e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 801       |\n",
      "|    ep_rew_mean     | -5.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 699       |\n",
      "|    time_elapsed    | 2091      |\n",
      "|    total_timesteps | 1431552   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 801         |\n",
      "|    ep_rew_mean          | -5.92e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 2093        |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012541655 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.9e+03     |\n",
      "|    n_updates            | 57850       |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.48e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1435000, episode_reward=-50218.81 +/- 91115.60\n",
      "Episode length: 462.20 +/- 460.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 462         |\n",
      "|    mean_reward          | -5.02e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1435000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012377303 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 664         |\n",
      "|    n_updates            | 57860       |\n",
      "|    policy_gradient_loss | -0.000897   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.47e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 801       |\n",
      "|    ep_rew_mean     | -5.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 701       |\n",
      "|    time_elapsed    | 2096      |\n",
      "|    total_timesteps | 1435648   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 831        |\n",
      "|    ep_rew_mean          | -5.95e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 685        |\n",
      "|    iterations           | 702        |\n",
      "|    time_elapsed         | 2097       |\n",
      "|    total_timesteps      | 1437696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02418044 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 477        |\n",
      "|    n_updates            | 57870      |\n",
      "|    policy_gradient_loss | -0.00121   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 4.42e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 795          |\n",
      "|    ep_rew_mean          | -6.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 703          |\n",
      "|    time_elapsed         | 2099         |\n",
      "|    total_timesteps      | 1439744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057191644 |\n",
      "|    clip_fraction        | 0.114        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.676        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.87e+06     |\n",
      "|    n_updates            | 57880        |\n",
      "|    policy_gradient_loss | 0.00159      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.38e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=-9182.31 +/- 10840.06\n",
      "Episode length: 160.20 +/- 167.93\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 160        |\n",
      "|    mean_reward          | -9.18e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1440000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00847703 |\n",
      "|    clip_fraction        | 0.0543     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.675      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.64e+06   |\n",
      "|    n_updates            | 57890      |\n",
      "|    policy_gradient_loss | -0.0049    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 7.88e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 799       |\n",
      "|    ep_rew_mean     | -5.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 704       |\n",
      "|    time_elapsed    | 2102      |\n",
      "|    total_timesteps | 1441792   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 712          |\n",
      "|    ep_rew_mean          | -5.73e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 686          |\n",
      "|    iterations           | 705          |\n",
      "|    time_elapsed         | 2103         |\n",
      "|    total_timesteps      | 1443840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076622902 |\n",
      "|    clip_fraction        | 0.0453       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.713        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.29e+06     |\n",
      "|    n_updates            | 57900        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.05e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1445000, episode_reward=-92740.03 +/- 195218.49\n",
      "Episode length: 1376.20 +/- 1840.26\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.38e+03   |\n",
      "|    mean_reward          | -9.27e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1445000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00437847 |\n",
      "|    clip_fraction        | 0.0183     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.638      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.04e+06   |\n",
      "|    n_updates            | 57910      |\n",
      "|    policy_gradient_loss | -0.00322   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.25e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 665       |\n",
      "|    ep_rew_mean     | -5.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 706       |\n",
      "|    time_elapsed    | 2109      |\n",
      "|    total_timesteps | 1445888   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 670          |\n",
      "|    ep_rew_mean          | -5.8e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 707          |\n",
      "|    time_elapsed         | 2110         |\n",
      "|    total_timesteps      | 1447936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037669628 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+06     |\n",
      "|    n_updates            | 57920        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.15e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 687         |\n",
      "|    ep_rew_mean          | -5.43e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 708         |\n",
      "|    time_elapsed         | 2112        |\n",
      "|    total_timesteps      | 1449984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017152961 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 761         |\n",
      "|    n_updates            | 57930       |\n",
      "|    policy_gradient_loss | 0.00318     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 9.5e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1450000, episode_reward=-7968.45 +/- 13218.51\n",
      "Episode length: 326.20 +/- 502.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 326         |\n",
      "|    mean_reward          | -7.97e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007557896 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.53e+06    |\n",
      "|    n_updates            | 57940       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.2e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 697       |\n",
      "|    ep_rew_mean     | -5.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 709       |\n",
      "|    time_elapsed    | 2115      |\n",
      "|    total_timesteps | 1452032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 708         |\n",
      "|    ep_rew_mean          | -5.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 2117        |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010775724 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.01e+04    |\n",
      "|    n_updates            | 57950       |\n",
      "|    policy_gradient_loss | 0.000387    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.72e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1455000, episode_reward=-12913.27 +/- 12522.60\n",
      "Episode length: 457.40 +/- 374.55\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 457       |\n",
      "|    mean_reward          | -1.29e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1455000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0083698 |\n",
      "|    clip_fraction        | 0.069     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.03      |\n",
      "|    explained_variance   | 0.707     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.23e+03  |\n",
      "|    n_updates            | 57960     |\n",
      "|    policy_gradient_loss | -0.000418 |\n",
      "|    std                  | 0.207     |\n",
      "|    value_loss           | 5.79e+06  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 712       |\n",
      "|    ep_rew_mean     | -5.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 711       |\n",
      "|    time_elapsed    | 2120      |\n",
      "|    total_timesteps | 1456128   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 707          |\n",
      "|    ep_rew_mean          | -5.34e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 2121         |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087351035 |\n",
      "|    clip_fraction        | 0.0682       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.61e+03     |\n",
      "|    n_updates            | 57970        |\n",
      "|    policy_gradient_loss | -0.000337    |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.53e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=-3519.21 +/- 6047.84\n",
      "Episode length: 621.00 +/- 571.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 621         |\n",
      "|    mean_reward          | -3.52e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005363078 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.5e+07     |\n",
      "|    n_updates            | 57980       |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 8.24e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 703       |\n",
      "|    ep_rew_mean     | -5.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 687       |\n",
      "|    iterations      | 713       |\n",
      "|    time_elapsed    | 2125      |\n",
      "|    total_timesteps | 1460224   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 710         |\n",
      "|    ep_rew_mean          | -5.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 2127        |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032857746 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+03       |\n",
      "|    n_updates            | 57990       |\n",
      "|    policy_gradient_loss | 0.00224     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.37e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 710          |\n",
      "|    ep_rew_mean          | -5.15e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 2128         |\n",
      "|    total_timesteps      | 1464320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025737395 |\n",
      "|    clip_fraction        | 0.0794       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | 0.756        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.92e+06     |\n",
      "|    n_updates            | 58000        |\n",
      "|    policy_gradient_loss | 0.00176      |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.44e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1465000, episode_reward=311.68 +/- 7655.29\n",
      "Episode length: 1496.60 +/- 1817.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.5e+03     |\n",
      "|    mean_reward          | 312         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1465000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014528122 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 978         |\n",
      "|    n_updates            | 58010       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 4.4e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 710       |\n",
      "|    ep_rew_mean     | -5.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 687       |\n",
      "|    iterations      | 716       |\n",
      "|    time_elapsed    | 2134      |\n",
      "|    total_timesteps | 1466368   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 754         |\n",
      "|    ep_rew_mean          | -5.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 2136        |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011240633 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 952         |\n",
      "|    n_updates            | 58020       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.42e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=932.33 +/- 7299.39\n",
      "Episode length: 1306.00 +/- 1355.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.31e+03    |\n",
      "|    mean_reward          | 932         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019159988 |\n",
      "|    clip_fraction        | 0.0868      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.55e+05    |\n",
      "|    n_updates            | 58030       |\n",
      "|    policy_gradient_loss | -0.000453   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 7.72e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 770       |\n",
      "|    ep_rew_mean     | -4.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 718       |\n",
      "|    time_elapsed    | 2141      |\n",
      "|    total_timesteps | 1470464   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 772        |\n",
      "|    ep_rew_mean          | -4.95e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 687        |\n",
      "|    iterations           | 719        |\n",
      "|    time_elapsed         | 2142       |\n",
      "|    total_timesteps      | 1472512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03782237 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.583      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 593        |\n",
      "|    n_updates            | 58040      |\n",
      "|    policy_gradient_loss | 0.00934    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 8.91e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 738         |\n",
      "|    ep_rew_mean          | -3.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 2144        |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016788162 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 531         |\n",
      "|    n_updates            | 58050       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1475000, episode_reward=-15257.47 +/- 12153.30\n",
      "Episode length: 666.80 +/- 582.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 667         |\n",
      "|    mean_reward          | -1.53e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1475000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023668528 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.622       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.82e+06    |\n",
      "|    n_updates            | 58060       |\n",
      "|    policy_gradient_loss | 0.0182      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.88e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 741      |\n",
      "|    ep_rew_mean     | -3.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 687      |\n",
      "|    iterations      | 721      |\n",
      "|    time_elapsed    | 2148     |\n",
      "|    total_timesteps | 1476608  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 741         |\n",
      "|    ep_rew_mean          | -3.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 687         |\n",
      "|    iterations           | 722         |\n",
      "|    time_elapsed         | 2150        |\n",
      "|    total_timesteps      | 1478656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013965745 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 751         |\n",
      "|    n_updates            | 58070       |\n",
      "|    policy_gradient_loss | 0.00591     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.77e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=4760.75 +/- 25424.52\n",
      "Episode length: 1415.00 +/- 1863.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.42e+03    |\n",
      "|    mean_reward          | 4.76e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024390034 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 406         |\n",
      "|    n_updates            | 58080       |\n",
      "|    policy_gradient_loss | 0.00588     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.63e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 788       |\n",
      "|    ep_rew_mean     | -3.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 723       |\n",
      "|    time_elapsed    | 2155      |\n",
      "|    total_timesteps | 1480704   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 788        |\n",
      "|    ep_rew_mean          | -3.42e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 687        |\n",
      "|    iterations           | 724        |\n",
      "|    time_elapsed         | 2157       |\n",
      "|    total_timesteps      | 1482752    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01842523 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2          |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 431        |\n",
      "|    n_updates            | 58090      |\n",
      "|    policy_gradient_loss | 0.00233    |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 3.86e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 806          |\n",
      "|    ep_rew_mean          | -3.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 687          |\n",
      "|    iterations           | 725          |\n",
      "|    time_elapsed         | 2158         |\n",
      "|    total_timesteps      | 1484800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094747795 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2            |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 480          |\n",
      "|    n_updates            | 58100        |\n",
      "|    policy_gradient_loss | 0.00183      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1485000, episode_reward=-31217.82 +/- 75340.69\n",
      "Episode length: 2459.80 +/- 2216.13\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.46e+03   |\n",
      "|    mean_reward          | -3.12e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1485000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19551304 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2          |\n",
      "|    explained_variance   | 0.587      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.57e+06   |\n",
      "|    n_updates            | 58110      |\n",
      "|    policy_gradient_loss | 0.0155     |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.69e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 806       |\n",
      "|    ep_rew_mean     | -3.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 686       |\n",
      "|    iterations      | 726       |\n",
      "|    time_elapsed    | 2166      |\n",
      "|    total_timesteps | 1486848   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 838        |\n",
      "|    ep_rew_mean          | -3.15e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 686        |\n",
      "|    iterations           | 727        |\n",
      "|    time_elapsed         | 2168       |\n",
      "|    total_timesteps      | 1488896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02775203 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2          |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 76         |\n",
      "|    n_updates            | 58120      |\n",
      "|    policy_gradient_loss | 0.0147     |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 371        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=-64974.73 +/- 94816.59\n",
      "Episode length: 1713.60 +/- 2069.07\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.71e+03   |\n",
      "|    mean_reward          | -6.5e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1490000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02303269 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.01       |\n",
      "|    explained_variance   | 0.898      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 207        |\n",
      "|    n_updates            | 58130      |\n",
      "|    policy_gradient_loss | 0.00326    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 3.02e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 838       |\n",
      "|    ep_rew_mean     | -3.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 685       |\n",
      "|    iterations      | 728       |\n",
      "|    time_elapsed    | 2174      |\n",
      "|    total_timesteps | 1490944   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 838         |\n",
      "|    ep_rew_mean          | -3.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 686         |\n",
      "|    iterations           | 729         |\n",
      "|    time_elapsed         | 2176        |\n",
      "|    total_timesteps      | 1492992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026928186 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 58140       |\n",
      "|    policy_gradient_loss | 0.00433     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 404         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1495000, episode_reward=23883.81 +/- 23172.98\n",
      "Episode length: 3045.00 +/- 2394.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.04e+03    |\n",
      "|    mean_reward          | 2.39e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1495000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019559963 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.6        |\n",
      "|    n_updates            | 58150       |\n",
      "|    policy_gradient_loss | 0.0139      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 287         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 813       |\n",
      "|    ep_rew_mean     | -2.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 730       |\n",
      "|    time_elapsed    | 2185      |\n",
      "|    total_timesteps | 1495040   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 813         |\n",
      "|    ep_rew_mean          | -2.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 2187        |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022230929 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.97e+06    |\n",
      "|    n_updates            | 58160       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.2e+07     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 842         |\n",
      "|    ep_rew_mean          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 2188        |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015738668 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.2        |\n",
      "|    n_updates            | 58170       |\n",
      "|    policy_gradient_loss | 0.00234     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 272         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1500000, episode_reward=-63791.36 +/- 67930.07\n",
      "Episode length: 1573.00 +/- 1643.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.57e+03    |\n",
      "|    mean_reward          | -6.38e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007243566 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 327         |\n",
      "|    n_updates            | 58180       |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.12e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 842       |\n",
      "|    ep_rew_mean     | -2.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 684       |\n",
      "|    iterations      | 733       |\n",
      "|    time_elapsed    | 2194      |\n",
      "|    total_timesteps | 1501184   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 874         |\n",
      "|    ep_rew_mean          | -2.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 684         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 2196        |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017162368 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.5        |\n",
      "|    n_updates            | 58190       |\n",
      "|    policy_gradient_loss | 0.0024      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 432         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1505000, episode_reward=-42834.38 +/- 60811.95\n",
      "Episode length: 1969.80 +/- 1679.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.97e+03   |\n",
      "|    mean_reward          | -4.28e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1505000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01158314 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.99       |\n",
      "|    explained_variance   | 0.465      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.49e+07   |\n",
      "|    n_updates            | 58200      |\n",
      "|    policy_gradient_loss | 0.00259    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 3.53e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 873       |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 735       |\n",
      "|    time_elapsed    | 2202      |\n",
      "|    total_timesteps | 1505280   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 873         |\n",
      "|    ep_rew_mean          | -2.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 2204        |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009557486 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+06    |\n",
      "|    n_updates            | 58210       |\n",
      "|    policy_gradient_loss | 0.000845    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.69e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 884          |\n",
      "|    ep_rew_mean          | -2.8e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 737          |\n",
      "|    time_elapsed         | 2206         |\n",
      "|    total_timesteps      | 1509376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040089386 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12e+07     |\n",
      "|    n_updates            | 58220        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.14e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=-75621.17 +/- 35214.43\n",
      "Episode length: 900.00 +/- 1063.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 900         |\n",
      "|    mean_reward          | -7.56e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018600585 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 58230       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 6.74e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 894       |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 738       |\n",
      "|    time_elapsed    | 2210      |\n",
      "|    total_timesteps | 1511424   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 919          |\n",
      "|    ep_rew_mean          | -3.18e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 739          |\n",
      "|    time_elapsed         | 2212         |\n",
      "|    total_timesteps      | 1513472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073546274 |\n",
      "|    clip_fraction        | 0.164        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.51         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.16e+07     |\n",
      "|    n_updates            | 58240        |\n",
      "|    policy_gradient_loss | 0.00194      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.2e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1515000, episode_reward=-91057.72 +/- 76191.69\n",
      "Episode length: 1624.60 +/- 1278.34\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.62e+03     |\n",
      "|    mean_reward          | -9.11e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1515000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011472316 |\n",
      "|    clip_fraction        | 0.00537      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+07      |\n",
      "|    n_updates            | 58250        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.08e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 919       |\n",
      "|    ep_rew_mean     | -3.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 683       |\n",
      "|    iterations      | 740       |\n",
      "|    time_elapsed    | 2218      |\n",
      "|    total_timesteps | 1515520   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 919         |\n",
      "|    ep_rew_mean          | -3.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 2220        |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008347193 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.98e+03    |\n",
      "|    n_updates            | 58260       |\n",
      "|    policy_gradient_loss | -0.00833    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.22e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 964         |\n",
      "|    ep_rew_mean          | -3.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 683         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 2221        |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011429748 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 367         |\n",
      "|    n_updates            | 58270       |\n",
      "|    policy_gradient_loss | 0.000459    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=25946.44 +/- 72926.75\n",
      "Episode length: 4833.20 +/- 333.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.83e+03     |\n",
      "|    mean_reward          | 2.59e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127987545 |\n",
      "|    clip_fraction        | 0.179        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.98         |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 134          |\n",
      "|    n_updates            | 58280        |\n",
      "|    policy_gradient_loss | 0.00973      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.13e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 964       |\n",
      "|    ep_rew_mean     | -3.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 680       |\n",
      "|    iterations      | 743       |\n",
      "|    time_elapsed    | 2235      |\n",
      "|    total_timesteps | 1521664   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -2.62e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 681        |\n",
      "|    iterations           | 744        |\n",
      "|    time_elapsed         | 2236       |\n",
      "|    total_timesteps      | 1523712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04087002 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.99       |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 194        |\n",
      "|    n_updates            | 58290      |\n",
      "|    policy_gradient_loss | 0.012      |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.83e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1525000, episode_reward=65824.68 +/- 4987.40\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.58e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1525000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007736991 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.65e+03    |\n",
      "|    n_updates            | 58300       |\n",
      "|    policy_gradient_loss | 1.28e-05    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.04e+05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -2.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 677       |\n",
      "|    iterations      | 745       |\n",
      "|    time_elapsed    | 2250      |\n",
      "|    total_timesteps | 1525760   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -2.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 678         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 2252        |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037967846 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 58310       |\n",
      "|    policy_gradient_loss | 0.00526     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 572         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -2.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 678         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 2254        |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037874915 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.3        |\n",
      "|    n_updates            | 58320       |\n",
      "|    policy_gradient_loss | 0.021       |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=63695.46 +/- 4582.23\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 6.37e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1530000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074465913 |\n",
      "|    clip_fraction        | 0.122        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.13e+03     |\n",
      "|    n_updates            | 58330        |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 5.9e+03      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.05e+03  |\n",
      "|    ep_rew_mean     | -2.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 675       |\n",
      "|    iterations      | 748       |\n",
      "|    time_elapsed    | 2267      |\n",
      "|    total_timesteps | 1531904   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -2.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 675         |\n",
      "|    iterations           | 749         |\n",
      "|    time_elapsed         | 2269        |\n",
      "|    total_timesteps      | 1533952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041682288 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 58340       |\n",
      "|    policy_gradient_loss | 0.00469     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1535000, episode_reward=53485.43 +/- 28239.77\n",
      "Episode length: 4002.00 +/- 1996.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4e+03       |\n",
      "|    mean_reward          | 5.35e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1535000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012818355 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.14e+03    |\n",
      "|    n_updates            | 58350       |\n",
      "|    policy_gradient_loss | 0.00227     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 3.37e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.08e+03  |\n",
      "|    ep_rew_mean     | -2.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 750       |\n",
      "|    time_elapsed    | 2281      |\n",
      "|    total_timesteps | 1536000   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.08e+03   |\n",
      "|    ep_rew_mean          | -2.51e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 673        |\n",
      "|    iterations           | 751        |\n",
      "|    time_elapsed         | 2282       |\n",
      "|    total_timesteps      | 1538048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01338627 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.01       |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 363        |\n",
      "|    n_updates            | 58360      |\n",
      "|    policy_gradient_loss | -0.00489   |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 1.43e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=-26232.56 +/- 199468.30\n",
      "Episode length: 4047.80 +/- 1904.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.05e+03    |\n",
      "|    mean_reward          | -2.62e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023524981 |\n",
      "|    clip_fraction        | 0.385       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 58370       |\n",
      "|    policy_gradient_loss | 0.0165      |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 719         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -2.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 671       |\n",
      "|    iterations      | 752       |\n",
      "|    time_elapsed    | 2294      |\n",
      "|    total_timesteps | 1540096   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -2.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 2296        |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004851383 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.513       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.55e+07    |\n",
      "|    n_updates            | 58380       |\n",
      "|    policy_gradient_loss | 0.00286     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.46e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -2.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 2298        |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017619116 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 58390       |\n",
      "|    policy_gradient_loss | 0.0119      |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1545000, episode_reward=-12538.09 +/- 80391.43\n",
      "Episode length: 2246.60 +/- 2281.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.25e+03    |\n",
      "|    mean_reward          | -1.25e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1545000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010309186 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.28e+03    |\n",
      "|    n_updates            | 58400       |\n",
      "|    policy_gradient_loss | -0.00161    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.99e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.17e+03  |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 670       |\n",
      "|    iterations      | 755       |\n",
      "|    time_elapsed    | 2305      |\n",
      "|    total_timesteps | 1546240   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -2.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 2307        |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012004346 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 58410       |\n",
      "|    policy_gradient_loss | -0.00921    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 799         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1550000, episode_reward=-527.82 +/- 28229.96\n",
      "Episode length: 1602.00 +/- 2050.32\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.6e+03    |\n",
      "|    mean_reward          | -528       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1550000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07120546 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.934      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 43.7       |\n",
      "|    n_updates            | 58420      |\n",
      "|    policy_gradient_loss | 0.0159     |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 128        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.22e+03  |\n",
      "|    ep_rew_mean     | -2.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 670       |\n",
      "|    iterations      | 757       |\n",
      "|    time_elapsed    | 2312      |\n",
      "|    total_timesteps | 1550336   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.22e+03   |\n",
      "|    ep_rew_mean          | -2.57e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 670        |\n",
      "|    iterations           | 758        |\n",
      "|    time_elapsed         | 2314       |\n",
      "|    total_timesteps      | 1552384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01028699 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.9        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 522        |\n",
      "|    n_updates            | 58430      |\n",
      "|    policy_gradient_loss | -0.00301   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 6.14e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | -2.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 671         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 2316        |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009660555 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 58440       |\n",
      "|    policy_gradient_loss | 0.00314     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 381         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1555000, episode_reward=64027.38 +/- 3025.14\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 6.4e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1555000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102841575 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | -0.0286      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 329          |\n",
      "|    n_updates            | 58450        |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 8.61e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.27e+03 |\n",
      "|    ep_rew_mean     | -2.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 667      |\n",
      "|    iterations      | 760      |\n",
      "|    time_elapsed    | 2330     |\n",
      "|    total_timesteps | 1556480  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | -2.34e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 2332        |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028999865 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 58460       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=18471.45 +/- 47143.01\n",
      "Episode length: 3686.20 +/- 1888.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.69e+03    |\n",
      "|    mean_reward          | 1.85e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010180775 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.07e+07    |\n",
      "|    n_updates            | 58470       |\n",
      "|    policy_gradient_loss | 0.00197     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 3.68e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.31e+03 |\n",
      "|    ep_rew_mean     | -2.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 666      |\n",
      "|    iterations      | 762      |\n",
      "|    time_elapsed    | 2342     |\n",
      "|    total_timesteps | 1560576  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.31e+03   |\n",
      "|    ep_rew_mean          | -2.8e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 666        |\n",
      "|    iterations           | 763        |\n",
      "|    time_elapsed         | 2344       |\n",
      "|    total_timesteps      | 1562624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01692135 |\n",
      "|    clip_fraction        | 0.0701     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.561      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.72e+07   |\n",
      "|    n_updates            | 58480      |\n",
      "|    policy_gradient_loss | 0.00813    |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 3.8e+07    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | -2.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 666         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 2346        |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023067575 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.7        |\n",
      "|    n_updates            | 58490       |\n",
      "|    policy_gradient_loss | -0.000468   |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1565000, episode_reward=65389.72 +/- 12414.38\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.54e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1565000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021299263 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.591       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.97e+05    |\n",
      "|    n_updates            | 58500       |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 8.14e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.36e+03  |\n",
      "|    ep_rew_mean     | -2.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 663       |\n",
      "|    iterations      | 765       |\n",
      "|    time_elapsed    | 2360      |\n",
      "|    total_timesteps | 1566720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | -2.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 664         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 2362        |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007953871 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.823       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 323         |\n",
      "|    n_updates            | 58510       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 8.58e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=77387.34 +/- 1561.75\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.74e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015728172 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 58520       |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.36e+03  |\n",
      "|    ep_rew_mean     | -2.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 661       |\n",
      "|    iterations      | 767       |\n",
      "|    time_elapsed    | 2375      |\n",
      "|    total_timesteps | 1570816   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.41e+03   |\n",
      "|    ep_rew_mean          | -2.71e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 661        |\n",
      "|    iterations           | 768        |\n",
      "|    time_elapsed         | 2377       |\n",
      "|    total_timesteps      | 1572864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01600539 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 50.2       |\n",
      "|    n_updates            | 58530      |\n",
      "|    policy_gradient_loss | 0.00149    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 142        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -2.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 661         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 2379        |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017163029 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 58540       |\n",
      "|    policy_gradient_loss | 5.77e-05    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 6.33e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1575000, episode_reward=34292.01 +/- 21378.69\n",
      "Episode length: 4390.60 +/- 1160.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.39e+03    |\n",
      "|    mean_reward          | 3.43e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1575000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006450168 |\n",
      "|    clip_fraction        | 0.0923      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 297         |\n",
      "|    n_updates            | 58550       |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -2.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 659       |\n",
      "|    iterations      | 770       |\n",
      "|    time_elapsed    | 2391      |\n",
      "|    total_timesteps | 1576960   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -2.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 659         |\n",
      "|    iterations           | 771         |\n",
      "|    time_elapsed         | 2393        |\n",
      "|    total_timesteps      | 1579008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021007117 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.9        |\n",
      "|    n_updates            | 58560       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=73908.88 +/- 2195.33\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.39e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011002973 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97          |\n",
      "|    n_updates            | 58570       |\n",
      "|    policy_gradient_loss | 0.00467     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 341         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -2.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 656       |\n",
      "|    iterations      | 772       |\n",
      "|    time_elapsed    | 2407      |\n",
      "|    total_timesteps | 1581056   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -2.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 2409        |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011580668 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 180         |\n",
      "|    n_updates            | 58580       |\n",
      "|    policy_gradient_loss | -0.000186   |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 854         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1585000, episode_reward=35522.21 +/- 37380.82\n",
      "Episode length: 3006.40 +/- 2441.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.01e+03    |\n",
      "|    mean_reward          | 3.55e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1585000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022317976 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.5        |\n",
      "|    n_updates            | 58590       |\n",
      "|    policy_gradient_loss | 0.0147      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 339         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -2.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 655       |\n",
      "|    iterations      | 774       |\n",
      "|    time_elapsed    | 2418      |\n",
      "|    total_timesteps | 1585152   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 2420        |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015218169 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 58600       |\n",
      "|    policy_gradient_loss | 0.00732     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 4.13e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 656         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 2422        |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009405022 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 58610       |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 959         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1590000, episode_reward=-59811.16 +/- 192062.93\n",
      "Episode length: 3898.40 +/- 1842.93\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.9e+03    |\n",
      "|    mean_reward          | -5.98e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1590000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01846018 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 45.1       |\n",
      "|    n_updates            | 58620      |\n",
      "|    policy_gradient_loss | 0.00146    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 389        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -2.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 653       |\n",
      "|    iterations      | 777       |\n",
      "|    time_elapsed    | 2433      |\n",
      "|    total_timesteps | 1591296   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -2.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 2435        |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005788327 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79e+03    |\n",
      "|    n_updates            | 58630       |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 5.43e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1595000, episode_reward=23718.54 +/- 21752.13\n",
      "Episode length: 4054.80 +/- 1117.10\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.05e+03   |\n",
      "|    mean_reward          | 2.37e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1595000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01354237 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.06       |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 116        |\n",
      "|    n_updates            | 58640      |\n",
      "|    policy_gradient_loss | 0.00195    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 670        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.57e+03 |\n",
      "|    ep_rew_mean     | -2.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 652      |\n",
      "|    iterations      | 779      |\n",
      "|    time_elapsed    | 2446     |\n",
      "|    total_timesteps | 1595392  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -2.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 2448        |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008403219 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 365         |\n",
      "|    n_updates            | 58650       |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.74e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -2.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 2450        |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004487425 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 58660       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.06e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=-17250.31 +/- 43079.67\n",
      "Episode length: 2560.00 +/- 1194.34\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.56e+03   |\n",
      "|    mean_reward          | -1.73e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1600000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02018023 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.06       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 115        |\n",
      "|    n_updates            | 58670      |\n",
      "|    policy_gradient_loss | 0.000664   |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 820        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -2.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 651       |\n",
      "|    iterations      | 782       |\n",
      "|    time_elapsed    | 2458      |\n",
      "|    total_timesteps | 1601536   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | -2.42e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 783          |\n",
      "|    time_elapsed         | 2460         |\n",
      "|    total_timesteps      | 1603584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154697085 |\n",
      "|    clip_fraction        | 0.222        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.06         |\n",
      "|    explained_variance   | 0.534        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.42e+07     |\n",
      "|    n_updates            | 58680        |\n",
      "|    policy_gradient_loss | 0.00193      |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.24e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1605000, episode_reward=-75534.35 +/- 65504.10\n",
      "Episode length: 2501.60 +/- 1249.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.5e+03     |\n",
      "|    mean_reward          | -7.55e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1605000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012641303 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 58690       |\n",
      "|    policy_gradient_loss | -0.000384   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 407         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -2.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 784       |\n",
      "|    time_elapsed    | 2467      |\n",
      "|    total_timesteps | 1605632   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -2.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 2469        |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062238142 |\n",
      "|    clip_fraction        | 0.388       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.91e+06    |\n",
      "|    n_updates            | 58700       |\n",
      "|    policy_gradient_loss | 0.0251      |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.58e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.65e+03     |\n",
      "|    ep_rew_mean          | -2.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 786          |\n",
      "|    time_elapsed         | 2471         |\n",
      "|    total_timesteps      | 1609728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086879525 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 380          |\n",
      "|    n_updates            | 58710        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 3.41e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=-98070.02 +/- 53284.29\n",
      "Episode length: 1680.60 +/- 780.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.68e+03    |\n",
      "|    mean_reward          | -9.81e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015138963 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 58720       |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 447         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -2.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 787       |\n",
      "|    time_elapsed    | 2477      |\n",
      "|    total_timesteps | 1611776   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.68e+03     |\n",
      "|    ep_rew_mean          | -2.45e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 788          |\n",
      "|    time_elapsed         | 2479         |\n",
      "|    total_timesteps      | 1613824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061041373 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.7e+07      |\n",
      "|    n_updates            | 58730        |\n",
      "|    policy_gradient_loss | 0.000585     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.64e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1615000, episode_reward=-88607.61 +/- 43444.73\n",
      "Episode length: 1679.40 +/- 831.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.68e+03     |\n",
      "|    mean_reward          | -8.86e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1615000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021818213 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+07     |\n",
      "|    n_updates            | 58740        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.72e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -2.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 789       |\n",
      "|    time_elapsed    | 2485      |\n",
      "|    total_timesteps | 1615872   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -2.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 2486        |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011436369 |\n",
      "|    clip_fraction        | 0.0475      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.568       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+05    |\n",
      "|    n_updates            | 58750       |\n",
      "|    policy_gradient_loss | 0.000978    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 2.5e+07     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -2.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 791          |\n",
      "|    time_elapsed         | 2488         |\n",
      "|    total_timesteps      | 1619968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016273367 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.553        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.2e+06      |\n",
      "|    n_updates            | 58760        |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.97e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=-108550.09 +/- 2093.72\n",
      "Episode length: 2015.40 +/- 84.01\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.02e+03   |\n",
      "|    mean_reward          | -1.09e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1620000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01750244 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.08       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 207        |\n",
      "|    n_updates            | 58770      |\n",
      "|    policy_gradient_loss | -0.00844   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.75e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -2.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 649       |\n",
      "|    iterations      | 792       |\n",
      "|    time_elapsed    | 2495      |\n",
      "|    total_timesteps | 1622016   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -2.76e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 650          |\n",
      "|    iterations           | 793          |\n",
      "|    time_elapsed         | 2497         |\n",
      "|    total_timesteps      | 1624064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058360775 |\n",
      "|    clip_fraction        | 0.0888       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.09e+06     |\n",
      "|    n_updates            | 58780        |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.48e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1625000, episode_reward=-114002.83 +/- 15696.83\n",
      "Episode length: 2130.60 +/- 27.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.13e+03     |\n",
      "|    mean_reward          | -1.14e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1625000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042849244 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.62e+05     |\n",
      "|    n_updates            | 58790        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.56e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.76e+03  |\n",
      "|    ep_rew_mean     | -2.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 649       |\n",
      "|    iterations      | 794       |\n",
      "|    time_elapsed    | 2504      |\n",
      "|    total_timesteps | 1626112   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.78e+03     |\n",
      "|    ep_rew_mean          | -2.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 649          |\n",
      "|    iterations           | 795          |\n",
      "|    time_elapsed         | 2506         |\n",
      "|    total_timesteps      | 1628160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034591756 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.71e+05     |\n",
      "|    n_updates            | 58800        |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 7.6e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=-108192.68 +/- 84601.45\n",
      "Episode length: 1887.40 +/- 933.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.89e+03     |\n",
      "|    mean_reward          | -1.08e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1630000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029058256 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.49e+06     |\n",
      "|    n_updates            | 58810        |\n",
      "|    policy_gradient_loss | -0.000433    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.25e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.78e+03  |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 648       |\n",
      "|    iterations      | 796       |\n",
      "|    time_elapsed    | 2512      |\n",
      "|    total_timesteps | 1630208   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.78e+03    |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 2514        |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004393233 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02e+07    |\n",
      "|    n_updates            | 58820       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.06e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -3.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 2516        |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013780199 |\n",
      "|    clip_fraction        | 0.09        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 490         |\n",
      "|    n_updates            | 58830       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 5.7e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1635000, episode_reward=59885.57 +/- 32204.26\n",
      "Episode length: 4004.00 +/- 1992.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4e+03        |\n",
      "|    mean_reward          | 5.99e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1635000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043076873 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+07     |\n",
      "|    n_updates            | 58840        |\n",
      "|    policy_gradient_loss | 0.0011       |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.99e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -3.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 647       |\n",
      "|    iterations      | 799       |\n",
      "|    time_elapsed    | 2527      |\n",
      "|    total_timesteps | 1636352   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.83e+03     |\n",
      "|    ep_rew_mean          | -3.11e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 800          |\n",
      "|    time_elapsed         | 2529         |\n",
      "|    total_timesteps      | 1638400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062716673 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+06     |\n",
      "|    n_updates            | 58850        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2e+06        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=61310.62 +/- 31743.60\n",
      "Episode length: 4003.40 +/- 1993.20\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4e+03      |\n",
      "|    mean_reward          | 6.13e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1640000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23951718 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.08       |\n",
      "|    explained_variance   | 0.565      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 372        |\n",
      "|    n_updates            | 58860      |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.44e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.83e+03  |\n",
      "|    ep_rew_mean     | -3.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 645       |\n",
      "|    iterations      | 801       |\n",
      "|    time_elapsed    | 2540      |\n",
      "|    total_timesteps | 1640448   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 2542        |\n",
      "|    total_timesteps      | 1642496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016079698 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 58870       |\n",
      "|    policy_gradient_loss | 0.013       |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.54e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 2544        |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013736652 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 918         |\n",
      "|    n_updates            | 58880       |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 9.79e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1645000, episode_reward=80485.41 +/- 3729.62\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.05e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1645000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007227678 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 632         |\n",
      "|    n_updates            | 58890       |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.76e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.9e+03   |\n",
      "|    ep_rew_mean     | -2.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 643       |\n",
      "|    iterations      | 804       |\n",
      "|    time_elapsed    | 2558      |\n",
      "|    total_timesteps | 1646592   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | -2.94e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 644         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 2559        |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009253729 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+03    |\n",
      "|    n_updates            | 58900       |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.68e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=-1845.94 +/- 65099.08\n",
      "Episode length: 2018.40 +/- 2434.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | -1.85e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012857968 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 58910       |\n",
      "|    policy_gradient_loss | 0.00169     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 745         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.9e+03   |\n",
      "|    ep_rew_mean     | -2.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 643       |\n",
      "|    iterations      | 806       |\n",
      "|    time_elapsed    | 2566      |\n",
      "|    total_timesteps | 1650688   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -2.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 643         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 2568        |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025169676 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 58920       |\n",
      "|    policy_gradient_loss | 0.00248     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 879         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -2.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 643         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 2570        |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011403693 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.11        |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 808         |\n",
      "|    n_updates            | 58930       |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 5.87e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1655000, episode_reward=-25753.99 +/- 112905.30\n",
      "Episode length: 2036.20 +/- 2420.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.04e+03    |\n",
      "|    mean_reward          | -2.58e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1655000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007791915 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.11        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.61e+03    |\n",
      "|    n_updates            | 58940       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 9.52e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.99e+03  |\n",
      "|    ep_rew_mean     | -2.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 642       |\n",
      "|    iterations      | 809       |\n",
      "|    time_elapsed    | 2577      |\n",
      "|    total_timesteps | 1656832   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.99e+03     |\n",
      "|    ep_rew_mean          | -2.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 810          |\n",
      "|    time_elapsed         | 2578         |\n",
      "|    total_timesteps      | 1658880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035090037 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.11         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 403          |\n",
      "|    n_updates            | 58950        |\n",
      "|    policy_gradient_loss | 0.0016       |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.66e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1660000, episode_reward=10147.19 +/- 94201.02\n",
      "Episode length: 3138.80 +/- 2289.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.14e+03     |\n",
      "|    mean_reward          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1660000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009827701 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.11         |\n",
      "|    explained_variance   | 0.476        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+07     |\n",
      "|    n_updates            | 58960        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.68e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.99e+03 |\n",
      "|    ep_rew_mean     | -2.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 641      |\n",
      "|    iterations      | 811      |\n",
      "|    time_elapsed    | 2588     |\n",
      "|    total_timesteps | 1660928  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.03e+03    |\n",
      "|    ep_rew_mean          | -2.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 642         |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 2590        |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009357198 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.11        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 329         |\n",
      "|    n_updates            | 58970       |\n",
      "|    policy_gradient_loss | -0.000765   |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1665000, episode_reward=32740.82 +/- 54635.48\n",
      "Episode length: 3008.40 +/- 2439.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.01e+03    |\n",
      "|    mean_reward          | 3.27e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1665000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010801109 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 58980       |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 4.42e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.03e+03  |\n",
      "|    ep_rew_mean     | -2.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 640       |\n",
      "|    iterations      | 813       |\n",
      "|    time_elapsed    | 2599      |\n",
      "|    total_timesteps | 1665024   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.03e+03     |\n",
      "|    ep_rew_mean          | -2.41e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 640          |\n",
      "|    iterations           | 814          |\n",
      "|    time_elapsed         | 2601         |\n",
      "|    total_timesteps      | 1667072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054084766 |\n",
      "|    clip_fraction        | 0.0632       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.1          |\n",
      "|    explained_variance   | 0.827        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+03     |\n",
      "|    n_updates            | 58990        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.02e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | -2.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 641         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 2602        |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024886325 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80          |\n",
      "|    n_updates            | 59000       |\n",
      "|    policy_gradient_loss | 0.022       |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 418         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1670000, episode_reward=40359.85 +/- 15372.01\n",
      "Episode length: 4571.80 +/- 856.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.57e+03     |\n",
      "|    mean_reward          | 4.04e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1670000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064887125 |\n",
      "|    clip_fraction        | 0.0722       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+04     |\n",
      "|    n_updates            | 59010        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 4.15e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.08e+03  |\n",
      "|    ep_rew_mean     | -2.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 816       |\n",
      "|    time_elapsed    | 2615      |\n",
      "|    total_timesteps | 1671168   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | -2.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 2617        |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021383291 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.6        |\n",
      "|    n_updates            | 59020       |\n",
      "|    policy_gradient_loss | 0.00299     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 392         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1675000, episode_reward=-4443.22 +/- 11764.82\n",
      "Episode length: 1063.60 +/- 563.69\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.06e+03   |\n",
      "|    mean_reward          | -4.44e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1675000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01507216 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.09       |\n",
      "|    explained_variance   | -0.345     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 431        |\n",
      "|    n_updates            | 59030      |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.02e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.13e+03  |\n",
      "|    ep_rew_mean     | -2.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 818       |\n",
      "|    time_elapsed    | 2621      |\n",
      "|    total_timesteps | 1675264   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.08e+03     |\n",
      "|    ep_rew_mean          | -2.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 639          |\n",
      "|    iterations           | 819          |\n",
      "|    time_elapsed         | 2623         |\n",
      "|    total_timesteps      | 1677312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063047716 |\n",
      "|    clip_fraction        | 0.0824       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.839        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.46e+03     |\n",
      "|    n_updates            | 59040        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 2.5e+05      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | -2.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 2625        |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049009558 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.584       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.55e+06    |\n",
      "|    n_updates            | 59050       |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.07e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1680000, episode_reward=-3655.94 +/- 15286.76\n",
      "Episode length: 1776.80 +/- 1726.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.78e+03    |\n",
      "|    mean_reward          | -3.66e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007784224 |\n",
      "|    clip_fraction        | 0.0541      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.618       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+04    |\n",
      "|    n_updates            | 59060       |\n",
      "|    policy_gradient_loss | -0.00688    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 4.9e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.1e+03   |\n",
      "|    ep_rew_mean     | -2.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 821       |\n",
      "|    time_elapsed    | 2631      |\n",
      "|    total_timesteps | 1681408   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | -2.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 639         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 2633        |\n",
      "|    total_timesteps      | 1683456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013489128 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 481         |\n",
      "|    n_updates            | 59070       |\n",
      "|    policy_gradient_loss | 0.00191     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 4.42e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1685000, episode_reward=28134.28 +/- 52019.03\n",
      "Episode length: 3289.20 +/- 2140.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.29e+03     |\n",
      "|    mean_reward          | 2.81e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1685000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067325127 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.855        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+03     |\n",
      "|    n_updates            | 59080        |\n",
      "|    policy_gradient_loss | -0.00035     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.14e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.12e+03 |\n",
      "|    ep_rew_mean     | -2.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 637      |\n",
      "|    iterations      | 823      |\n",
      "|    time_elapsed    | 2643     |\n",
      "|    total_timesteps | 1685504  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.14e+03   |\n",
      "|    ep_rew_mean          | -2.22e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 638        |\n",
      "|    iterations           | 824        |\n",
      "|    time_elapsed         | 2644       |\n",
      "|    total_timesteps      | 1687552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04127932 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.1        |\n",
      "|    explained_variance   | 0.782      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 699        |\n",
      "|    n_updates            | 59090      |\n",
      "|    policy_gradient_loss | -0.000363  |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 2.21e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.16e+03     |\n",
      "|    ep_rew_mean          | -2.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 638          |\n",
      "|    iterations           | 825          |\n",
      "|    time_elapsed         | 2646         |\n",
      "|    total_timesteps      | 1689600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030863825 |\n",
      "|    clip_fraction        | 0.094        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.1          |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.39e+05     |\n",
      "|    n_updates            | 59100        |\n",
      "|    policy_gradient_loss | 0.000206     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.28e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1690000, episode_reward=-31567.59 +/- 197237.96\n",
      "Episode length: 4049.20 +/- 1901.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.05e+03    |\n",
      "|    mean_reward          | -3.16e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1690000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013522052 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 540         |\n",
      "|    n_updates            | 59110       |\n",
      "|    policy_gradient_loss | -0.000912   |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1e+05       |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.16e+03  |\n",
      "|    ep_rew_mean     | -2.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 636       |\n",
      "|    iterations      | 826       |\n",
      "|    time_elapsed    | 2658      |\n",
      "|    total_timesteps | 1691648   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.16e+03    |\n",
      "|    ep_rew_mean          | -2.19e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 2660        |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012962088 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 286         |\n",
      "|    n_updates            | 59120       |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1695000, episode_reward=12345.86 +/- 6848.88\n",
      "Episode length: 1696.60 +/- 986.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 1.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1695000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030134864 |\n",
      "|    clip_fraction        | 0.358       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 59130       |\n",
      "|    policy_gradient_loss | 0.0209      |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.28e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.22e+03  |\n",
      "|    ep_rew_mean     | -2.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 636       |\n",
      "|    iterations      | 828       |\n",
      "|    time_elapsed    | 2665      |\n",
      "|    total_timesteps | 1695744   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.23e+03     |\n",
      "|    ep_rew_mean          | -2.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 829          |\n",
      "|    time_elapsed         | 2667         |\n",
      "|    total_timesteps      | 1697792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065592793 |\n",
      "|    clip_fraction        | 0.0862       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.552        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 59140        |\n",
      "|    policy_gradient_loss | 0.00134      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.03e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.23e+03    |\n",
      "|    ep_rew_mean          | -2.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 2669        |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008524895 |\n",
      "|    clip_fraction        | 0.0895      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 544         |\n",
      "|    n_updates            | 59150       |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=42909.61 +/- 21832.99\n",
      "Episode length: 4004.00 +/- 1992.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4e+03       |\n",
      "|    mean_reward          | 4.29e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024883516 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.9        |\n",
      "|    n_updates            | 59160       |\n",
      "|    policy_gradient_loss | 0.00304     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 271         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.28e+03  |\n",
      "|    ep_rew_mean     | -2.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 831       |\n",
      "|    time_elapsed    | 2681      |\n",
      "|    total_timesteps | 1701888   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.28e+03  |\n",
      "|    ep_rew_mean          | -2.05e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 635       |\n",
      "|    iterations           | 832       |\n",
      "|    time_elapsed         | 2682      |\n",
      "|    total_timesteps      | 1703936   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0086808 |\n",
      "|    clip_fraction        | 0.0813    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.07      |\n",
      "|    explained_variance   | 0.838     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 553       |\n",
      "|    n_updates            | 59170     |\n",
      "|    policy_gradient_loss | -0.00283  |\n",
      "|    std                  | 0.207     |\n",
      "|    value_loss           | 1.04e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1705000, episode_reward=61082.31 +/- 3212.71\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1705000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010694067 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.8        |\n",
      "|    n_updates            | 59180       |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 397         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.28e+03  |\n",
      "|    ep_rew_mean     | -2.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 632       |\n",
      "|    iterations      | 833       |\n",
      "|    time_elapsed    | 2696      |\n",
      "|    total_timesteps | 1705984   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.27e+03    |\n",
      "|    ep_rew_mean          | -2.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 2698        |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020893734 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.9        |\n",
      "|    n_updates            | 59190       |\n",
      "|    policy_gradient_loss | 0.0036      |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 404         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1710000, episode_reward=60112.69 +/- 31305.10\n",
      "Episode length: 4003.60 +/- 1992.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4e+03       |\n",
      "|    mean_reward          | 6.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004789154 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.93e+03    |\n",
      "|    n_updates            | 59200       |\n",
      "|    policy_gradient_loss | -0.000845   |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.19e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.27e+03  |\n",
      "|    ep_rew_mean     | -2.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 835       |\n",
      "|    time_elapsed    | 2709      |\n",
      "|    total_timesteps | 1710080   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.29e+03    |\n",
      "|    ep_rew_mean          | -2.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 2711        |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016462693 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.786       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.3        |\n",
      "|    n_updates            | 59210       |\n",
      "|    policy_gradient_loss | 0.00359     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 748         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.29e+03     |\n",
      "|    ep_rew_mean          | -2.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 837          |\n",
      "|    time_elapsed         | 2713         |\n",
      "|    total_timesteps      | 1714176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071938327 |\n",
      "|    clip_fraction        | 0.243        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.637        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.47e+04     |\n",
      "|    n_updates            | 59220        |\n",
      "|    policy_gradient_loss | 0.00525      |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.26e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1715000, episode_reward=-7562.58 +/- 41931.42\n",
      "Episode length: 2932.20 +/- 2372.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.93e+03    |\n",
      "|    mean_reward          | -7.56e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1715000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013849432 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 59230       |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 821         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.29e+03  |\n",
      "|    ep_rew_mean     | -2.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 838       |\n",
      "|    time_elapsed    | 2722      |\n",
      "|    total_timesteps | 1716224   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 2724        |\n",
      "|    total_timesteps      | 1718272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029751189 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 59240       |\n",
      "|    policy_gradient_loss | 0.00189     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 461         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1720000, episode_reward=-97229.60 +/- 150296.07\n",
      "Episode length: 1354.60 +/- 984.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.35e+03    |\n",
      "|    mean_reward          | -9.72e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013702639 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 59250       |\n",
      "|    policy_gradient_loss | 0.00802     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 1.46e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.36e+03  |\n",
      "|    ep_rew_mean     | -1.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 840       |\n",
      "|    time_elapsed    | 2729      |\n",
      "|    total_timesteps | 1720320   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.33e+03     |\n",
      "|    ep_rew_mean          | -1.99e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 841          |\n",
      "|    time_elapsed         | 2731         |\n",
      "|    total_timesteps      | 1722368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047158315 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.55         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+07     |\n",
      "|    n_updates            | 59260        |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.68e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.36e+03    |\n",
      "|    ep_rew_mean          | -1.96e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 2733        |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013995413 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.726       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 339         |\n",
      "|    n_updates            | 59270       |\n",
      "|    policy_gradient_loss | -0.00028    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 2.08e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1725000, episode_reward=15239.40 +/- 23207.82\n",
      "Episode length: 3207.60 +/- 1827.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.21e+03    |\n",
      "|    mean_reward          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1725000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018928308 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 287         |\n",
      "|    n_updates            | 59280       |\n",
      "|    policy_gradient_loss | 0.00148     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.36e+03  |\n",
      "|    ep_rew_mean     | -1.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 843       |\n",
      "|    time_elapsed    | 2742      |\n",
      "|    total_timesteps | 1726464   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | -1.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 2744        |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014596324 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 59290       |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 417         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1730000, episode_reward=-10663.23 +/- 28594.25\n",
      "Episode length: 1730.60 +/- 2035.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.73e+03     |\n",
      "|    mean_reward          | -1.07e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1730000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074246917 |\n",
      "|    clip_fraction        | 0.0788       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.09         |\n",
      "|    explained_variance   | 0.731        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 613          |\n",
      "|    n_updates            | 59300        |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.67e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.34e+03  |\n",
      "|    ep_rew_mean     | -1.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 845       |\n",
      "|    time_elapsed    | 2750      |\n",
      "|    total_timesteps | 1730560   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.38e+03   |\n",
      "|    ep_rew_mean          | -1.76e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 629        |\n",
      "|    iterations           | 846        |\n",
      "|    time_elapsed         | 2752       |\n",
      "|    total_timesteps      | 1732608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02697261 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.09       |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 139        |\n",
      "|    n_updates            | 59310      |\n",
      "|    policy_gradient_loss | -0.00125   |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 575        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -1.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 2754        |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008808361 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 473         |\n",
      "|    n_updates            | 59320       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1735000, episode_reward=60002.93 +/- 15919.46\n",
      "Episode length: 4663.40 +/- 673.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.66e+03    |\n",
      "|    mean_reward          | 6e+04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1735000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036172505 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.51e+06    |\n",
      "|    n_updates            | 59330       |\n",
      "|    policy_gradient_loss | -0.00232    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 5.51e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -1.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 627       |\n",
      "|    iterations      | 848       |\n",
      "|    time_elapsed    | 2767      |\n",
      "|    total_timesteps | 1736704   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -1.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 627         |\n",
      "|    iterations           | 849         |\n",
      "|    time_elapsed         | 2769        |\n",
      "|    total_timesteps      | 1738752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032258812 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90.3        |\n",
      "|    n_updates            | 59340       |\n",
      "|    policy_gradient_loss | 0.00741     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 518         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1740000, episode_reward=-21736.28 +/- 118213.31\n",
      "Episode length: 3030.80 +/- 2412.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.03e+03    |\n",
      "|    mean_reward          | -2.17e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004585201 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.44e+05    |\n",
      "|    n_updates            | 59350       |\n",
      "|    policy_gradient_loss | -0.000467   |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 1.75e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.39e+03 |\n",
      "|    ep_rew_mean     | -1.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 626      |\n",
      "|    iterations      | 850      |\n",
      "|    time_elapsed    | 2778     |\n",
      "|    total_timesteps | 1740800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | -1.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 2779        |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010258154 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.15e+03    |\n",
      "|    n_updates            | 59360       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 1.33e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | -1.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 627         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 2781        |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012223849 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.11        |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 59370       |\n",
      "|    policy_gradient_loss | 0.00222     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 5.25e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1745000, episode_reward=27980.14 +/- 25884.36\n",
      "Episode length: 3171.60 +/- 1588.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.17e+03    |\n",
      "|    mean_reward          | 2.8e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1745000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018017411 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.12        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.3        |\n",
      "|    n_updates            | 59380       |\n",
      "|    policy_gradient_loss | -0.00146    |\n",
      "|    std                  | 0.204       |\n",
      "|    value_loss           | 337         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.43e+03  |\n",
      "|    ep_rew_mean     | -1.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 625       |\n",
      "|    iterations      | 853       |\n",
      "|    time_elapsed    | 2791      |\n",
      "|    total_timesteps | 1746944   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.43e+03    |\n",
      "|    ep_rew_mean          | -1.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 854         |\n",
      "|    time_elapsed         | 2793        |\n",
      "|    total_timesteps      | 1748992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011299423 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.13        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 59390       |\n",
      "|    policy_gradient_loss | 0.00292     |\n",
      "|    std                  | 0.204       |\n",
      "|    value_loss           | 959         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1750000, episode_reward=66210.47 +/- 5142.45\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5e+03     |\n",
      "|    mean_reward          | 6.62e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1750000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0216939 |\n",
      "|    clip_fraction        | 0.253     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.15      |\n",
      "|    explained_variance   | 0.948     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 81.2      |\n",
      "|    n_updates            | 59400     |\n",
      "|    policy_gradient_loss | -0.0109   |\n",
      "|    std                  | 0.203     |\n",
      "|    value_loss           | 755       |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.43e+03  |\n",
      "|    ep_rew_mean     | -1.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 623       |\n",
      "|    iterations      | 855       |\n",
      "|    time_elapsed    | 2806      |\n",
      "|    total_timesteps | 1751040   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.48e+03   |\n",
      "|    ep_rew_mean          | -1.45e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 624        |\n",
      "|    iterations           | 856        |\n",
      "|    time_elapsed         | 2808       |\n",
      "|    total_timesteps      | 1753088    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04352278 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.17       |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 173        |\n",
      "|    n_updates            | 59410      |\n",
      "|    policy_gradient_loss | 2.92e-05   |\n",
      "|    std                  | 0.202      |\n",
      "|    value_loss           | 597        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1755000, episode_reward=12613.16 +/- 55473.65\n",
      "Episode length: 2015.40 +/- 2436.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | 1.26e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1755000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012612536 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+05    |\n",
      "|    n_updates            | 59420       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    std                  | 0.202       |\n",
      "|    value_loss           | 2.53e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.48e+03  |\n",
      "|    ep_rew_mean     | -1.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 623       |\n",
      "|    iterations      | 857       |\n",
      "|    time_elapsed    | 2815      |\n",
      "|    total_timesteps | 1755136   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.51e+03    |\n",
      "|    ep_rew_mean          | -1.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 623         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 2816        |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025991395 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 59430       |\n",
      "|    policy_gradient_loss | 0.0289      |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.51e+03    |\n",
      "|    ep_rew_mean          | -1.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 624         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 2818        |\n",
      "|    total_timesteps      | 1759232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009282926 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | -1.91       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.58e+04    |\n",
      "|    n_updates            | 59440       |\n",
      "|    policy_gradient_loss | 0.00281     |\n",
      "|    std                  | 0.202       |\n",
      "|    value_loss           | 4.61e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1760000, episode_reward=29046.78 +/- 59366.00\n",
      "Episode length: 3009.80 +/- 2437.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.01e+03    |\n",
      "|    mean_reward          | 2.9e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009622477 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 284         |\n",
      "|    n_updates            | 59450       |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.51e+03  |\n",
      "|    ep_rew_mean     | -1.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 622       |\n",
      "|    iterations      | 860       |\n",
      "|    time_elapsed    | 2827      |\n",
      "|    total_timesteps | 1761280   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54e+03    |\n",
      "|    ep_rew_mean          | -1.12e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 623         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 2829        |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027985025 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 284         |\n",
      "|    n_updates            | 59460       |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 410         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1765000, episode_reward=76400.41 +/- 8485.10\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1765000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009694649 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.848       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 378         |\n",
      "|    n_updates            | 59470       |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.54e+03  |\n",
      "|    ep_rew_mean     | -1.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 620       |\n",
      "|    iterations      | 862       |\n",
      "|    time_elapsed    | 2843      |\n",
      "|    total_timesteps | 1765376   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.56e+03    |\n",
      "|    ep_rew_mean          | -8.46e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 621         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 2845        |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013927329 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 59480       |\n",
      "|    policy_gradient_loss | -0.00195    |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 812         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.52e+03     |\n",
      "|    ep_rew_mean          | -9.33e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 621          |\n",
      "|    iterations           | 864          |\n",
      "|    time_elapsed         | 2846         |\n",
      "|    total_timesteps      | 1769472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056157606 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.18         |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+05     |\n",
      "|    n_updates            | 59490        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 2.29e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1770000, episode_reward=-58793.80 +/- 65667.95\n",
      "Episode length: 3021.80 +/- 991.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.02e+03     |\n",
      "|    mean_reward          | -5.88e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1770000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011657674 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.98e+07     |\n",
      "|    n_updates            | 59500        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 4.5e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.48e+03  |\n",
      "|    ep_rew_mean     | -1.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 620       |\n",
      "|    iterations      | 865       |\n",
      "|    time_elapsed    | 2855      |\n",
      "|    total_timesteps | 1771520   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.5e+03      |\n",
      "|    ep_rew_mean          | -1.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 620          |\n",
      "|    iterations           | 866          |\n",
      "|    time_elapsed         | 2857         |\n",
      "|    total_timesteps      | 1773568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004264693 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.6          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.48e+06     |\n",
      "|    n_updates            | 59510        |\n",
      "|    policy_gradient_loss | -0.0018      |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 2.06e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1775000, episode_reward=13321.12 +/- 85855.06\n",
      "Episode length: 4135.60 +/- 1059.47\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.14e+03     |\n",
      "|    mean_reward          | 1.33e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1775000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029647858 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.617        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.27e+06     |\n",
      "|    n_updates            | 59520        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 1.75e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.5e+03   |\n",
      "|    ep_rew_mean     | -1.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 618       |\n",
      "|    iterations      | 867       |\n",
      "|    time_elapsed    | 2869      |\n",
      "|    total_timesteps | 1775616   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.5e+03      |\n",
      "|    ep_rew_mean          | -1.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 619          |\n",
      "|    iterations           | 868          |\n",
      "|    time_elapsed         | 2871         |\n",
      "|    total_timesteps      | 1777664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023978804 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+05     |\n",
      "|    n_updates            | 59530        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 3.86e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.49e+03     |\n",
      "|    ep_rew_mean          | -1.15e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 619          |\n",
      "|    iterations           | 869          |\n",
      "|    time_elapsed         | 2873         |\n",
      "|    total_timesteps      | 1779712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055588745 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.44e+04     |\n",
      "|    n_updates            | 59540        |\n",
      "|    policy_gradient_loss | -0.00325     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 6.45e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1780000, episode_reward=11773.50 +/- 66095.08\n",
      "Episode length: 2017.20 +/- 2435.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | 1.18e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008111472 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 751         |\n",
      "|    n_updates            | 59550       |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 5.3e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.49e+03  |\n",
      "|    ep_rew_mean     | -1.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 618       |\n",
      "|    iterations      | 870       |\n",
      "|    time_elapsed    | 2879      |\n",
      "|    total_timesteps | 1781760   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.45e+03    |\n",
      "|    ep_rew_mean          | -1.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 619         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 2881        |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017627517 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 271         |\n",
      "|    n_updates            | 59560       |\n",
      "|    policy_gradient_loss | 0.0198      |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1785000, episode_reward=54977.09 +/- 55088.71\n",
      "Episode length: 4009.00 +/- 1982.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.01e+03    |\n",
      "|    mean_reward          | 5.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1785000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014915039 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.46e+07    |\n",
      "|    n_updates            | 59570       |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 7.18e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.45e+03  |\n",
      "|    ep_rew_mean     | -1.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 617       |\n",
      "|    iterations      | 872       |\n",
      "|    time_elapsed    | 2892      |\n",
      "|    total_timesteps | 1785856   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.45e+03     |\n",
      "|    ep_rew_mean          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 873          |\n",
      "|    time_elapsed         | 2894         |\n",
      "|    total_timesteps      | 1787904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121703455 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.854        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 219          |\n",
      "|    n_updates            | 59580        |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.11e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.5e+03     |\n",
      "|    ep_rew_mean          | -1.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 617         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 2896        |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015429244 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.5        |\n",
      "|    n_updates            | 59590       |\n",
      "|    policy_gradient_loss | 0.00669     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 611         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1790000, episode_reward=87671.81 +/- 267.27\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.77e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012901466 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 574         |\n",
      "|    n_updates            | 59600       |\n",
      "|    policy_gradient_loss | -0.00136    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 1.79e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.5e+03  |\n",
      "|    ep_rew_mean     | -1.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 615      |\n",
      "|    iterations      | 875      |\n",
      "|    time_elapsed    | 2910     |\n",
      "|    total_timesteps | 1792000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | -1.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 2912        |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011771532 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 59610       |\n",
      "|    policy_gradient_loss | 0.00422     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 655         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1795000, episode_reward=23480.29 +/- 71377.01\n",
      "Episode length: 3015.40 +/- 2430.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.02e+03    |\n",
      "|    mean_reward          | 2.35e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1795000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018261027 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.65e+06    |\n",
      "|    n_updates            | 59620       |\n",
      "|    policy_gradient_loss | 0.0162      |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 4.78e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -1.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 877       |\n",
      "|    time_elapsed    | 2921      |\n",
      "|    total_timesteps | 1796096   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.4e+03   |\n",
      "|    ep_rew_mean          | -1.58e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 615       |\n",
      "|    iterations           | 878       |\n",
      "|    time_elapsed         | 2922      |\n",
      "|    total_timesteps      | 1798144   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.027268  |\n",
      "|    clip_fraction        | 0.275     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.22      |\n",
      "|    explained_variance   | 0.948     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 39.2      |\n",
      "|    n_updates            | 59630     |\n",
      "|    policy_gradient_loss | 0.0169    |\n",
      "|    std                  | 0.2       |\n",
      "|    value_loss           | 170       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=81099.26 +/- 8051.81\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011525776 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2e+04     |\n",
      "|    n_updates            | 59640       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.2e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -1.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 879       |\n",
      "|    time_elapsed    | 2936      |\n",
      "|    total_timesteps | 1800192   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.4e+03    |\n",
      "|    ep_rew_mean          | -1.58e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 613        |\n",
      "|    iterations           | 880        |\n",
      "|    time_elapsed         | 2938       |\n",
      "|    total_timesteps      | 1802240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01030683 |\n",
      "|    clip_fraction        | 0.0881     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.22       |\n",
      "|    explained_variance   | 0.138      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 135        |\n",
      "|    n_updates            | 59650      |\n",
      "|    policy_gradient_loss | -0.00396   |\n",
      "|    std                  | 0.2        |\n",
      "|    value_loss           | 7.5e+04    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | -1.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 613         |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 2940        |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010098009 |\n",
      "|    clip_fraction        | 0.0975      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 59660       |\n",
      "|    policy_gradient_loss | 0.00258     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 473         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1805000, episode_reward=32338.61 +/- 34399.54\n",
      "Episode length: 3004.80 +/- 2443.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3e+03       |\n",
      "|    mean_reward          | 3.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1805000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007956958 |\n",
      "|    clip_fraction        | 0.0703      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.7e+04     |\n",
      "|    n_updates            | 59670       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 4.19e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.44e+03  |\n",
      "|    ep_rew_mean     | -1.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 882       |\n",
      "|    time_elapsed    | 2949      |\n",
      "|    total_timesteps | 1806336   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.48e+03    |\n",
      "|    ep_rew_mean          | -1.01e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 2950        |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010292649 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 59680       |\n",
      "|    policy_gradient_loss | 1.69e-05    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 664         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1810000, episode_reward=43369.62 +/- 20750.31\n",
      "Episode length: 4863.00 +/- 172.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.86e+03    |\n",
      "|    mean_reward          | 4.34e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005266181 |\n",
      "|    clip_fraction        | 0.0624      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.718       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 59690       |\n",
      "|    policy_gradient_loss | 0.000367    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 2.47e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.48e+03  |\n",
      "|    ep_rew_mean     | -1.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 884       |\n",
      "|    time_elapsed    | 2964      |\n",
      "|    total_timesteps | 1810432   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.47e+03    |\n",
      "|    ep_rew_mean          | -1.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 2966        |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008327469 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 287         |\n",
      "|    n_updates            | 59700       |\n",
      "|    policy_gradient_loss | 0.00193     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 940         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.47e+03    |\n",
      "|    ep_rew_mean          | -1.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 2967        |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010127468 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 332         |\n",
      "|    n_updates            | 59710       |\n",
      "|    policy_gradient_loss | -0.000386   |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 2.79e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1815000, episode_reward=10087.99 +/- 35609.02\n",
      "Episode length: 1822.00 +/- 2170.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.82e+03    |\n",
      "|    mean_reward          | 1.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1815000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020219037 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.1        |\n",
      "|    n_updates            | 59720       |\n",
      "|    policy_gradient_loss | 0.00201     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.5e+03   |\n",
      "|    ep_rew_mean     | -9.13e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 887       |\n",
      "|    time_elapsed    | 2974      |\n",
      "|    total_timesteps | 1816576   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.51e+03  |\n",
      "|    ep_rew_mean          | -9.56e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 611       |\n",
      "|    iterations           | 888       |\n",
      "|    time_elapsed         | 2975      |\n",
      "|    total_timesteps      | 1818624   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0095958 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.25      |\n",
      "|    explained_variance   | 0.673     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 317       |\n",
      "|    n_updates            | 59730     |\n",
      "|    policy_gradient_loss | -0.00939  |\n",
      "|    std                  | 0.198     |\n",
      "|    value_loss           | 3.48e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1820000, episode_reward=-68213.11 +/- 137427.56\n",
      "Episode length: 1994.60 +/- 1146.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.99e+03     |\n",
      "|    mean_reward          | -6.82e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1820000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039152857 |\n",
      "|    clip_fraction        | 0.0444       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.25         |\n",
      "|    explained_variance   | 0.493        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.11e+06     |\n",
      "|    n_updates            | 59740        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    std                  | 0.198        |\n",
      "|    value_loss           | 4.79e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.48e+03 |\n",
      "|    ep_rew_mean     | -1e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 610      |\n",
      "|    iterations      | 889      |\n",
      "|    time_elapsed    | 2982     |\n",
      "|    total_timesteps | 1820672  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | -1.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 2984        |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008579578 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 514         |\n",
      "|    n_updates            | 59750       |\n",
      "|    policy_gradient_loss | 0.000147    |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 7.32e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | -1.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 2986        |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011959264 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.56e+03    |\n",
      "|    n_updates            | 59760       |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 1.24e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1825000, episode_reward=-55476.47 +/- 65194.11\n",
      "Episode length: 787.00 +/- 904.64\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 787          |\n",
      "|    mean_reward          | -5.55e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1825000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080568865 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.25         |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 59770        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    std                  | 0.198        |\n",
      "|    value_loss           | 8.68e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -1.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 892       |\n",
      "|    time_elapsed    | 2989      |\n",
      "|    total_timesteps | 1826816   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.37e+03   |\n",
      "|    ep_rew_mean          | -1.16e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 611        |\n",
      "|    iterations           | 893        |\n",
      "|    time_elapsed         | 2991       |\n",
      "|    total_timesteps      | 1828864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08562634 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.24       |\n",
      "|    explained_variance   | 0.864      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 113        |\n",
      "|    n_updates            | 59780      |\n",
      "|    policy_gradient_loss | -0.00114   |\n",
      "|    std                  | 0.199      |\n",
      "|    value_loss           | 1.25e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1830000, episode_reward=-88876.10 +/- 99588.07\n",
      "Episode length: 1045.00 +/- 757.57\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.04e+03   |\n",
      "|    mean_reward          | -8.89e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1830000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00955811 |\n",
      "|    clip_fraction        | 0.0776     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.23       |\n",
      "|    explained_variance   | 0.881      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.85e+04   |\n",
      "|    n_updates            | 59790      |\n",
      "|    policy_gradient_loss | -0.00364   |\n",
      "|    std                  | 0.199      |\n",
      "|    value_loss           | 4.93e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.35e+03 |\n",
      "|    ep_rew_mean     | -1.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 611      |\n",
      "|    iterations      | 894      |\n",
      "|    time_elapsed    | 2996     |\n",
      "|    total_timesteps | 1830912  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.35e+03     |\n",
      "|    ep_rew_mean          | -1.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 611          |\n",
      "|    iterations           | 895          |\n",
      "|    time_elapsed         | 2998         |\n",
      "|    total_timesteps      | 1832960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062123253 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.674        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.57e+05     |\n",
      "|    n_updates            | 59800        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    std                  | 0.199        |\n",
      "|    value_loss           | 1.12e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1835000, episode_reward=-155910.29 +/- 45657.28\n",
      "Episode length: 546.60 +/- 251.53\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 547       |\n",
      "|    mean_reward          | -1.56e+05 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1835000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 6.911522  |\n",
      "|    clip_fraction        | 0.498     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.23      |\n",
      "|    explained_variance   | 0.945     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 102       |\n",
      "|    n_updates            | 59810     |\n",
      "|    policy_gradient_loss | 0.133     |\n",
      "|    std                  | 0.2       |\n",
      "|    value_loss           | 1.14e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.27e+03  |\n",
      "|    ep_rew_mean     | -1.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 611       |\n",
      "|    iterations      | 896       |\n",
      "|    time_elapsed    | 3001      |\n",
      "|    total_timesteps | 1835008   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | -1.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 3003        |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002233717 |\n",
      "|    clip_fraction        | 0.00479     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+07    |\n",
      "|    n_updates            | 59820       |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.82e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.25e+03     |\n",
      "|    ep_rew_mean          | -1.46e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 898          |\n",
      "|    time_elapsed         | 3004         |\n",
      "|    total_timesteps      | 1839104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013156718 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.22e+07     |\n",
      "|    n_updates            | 59830        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 4.56e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=-21439.14 +/- 19158.39\n",
      "Episode length: 531.00 +/- 274.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 531          |\n",
      "|    mean_reward          | -2.14e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055975337 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.543        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58e+04     |\n",
      "|    n_updates            | 59840        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.39e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.25e+03  |\n",
      "|    ep_rew_mean     | -1.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 899       |\n",
      "|    time_elapsed    | 3008      |\n",
      "|    total_timesteps | 1841152   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.17e+03     |\n",
      "|    ep_rew_mean          | -1.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 900          |\n",
      "|    time_elapsed         | 3009         |\n",
      "|    total_timesteps      | 1843200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035327417 |\n",
      "|    clip_fraction        | 0.0196       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+07     |\n",
      "|    n_updates            | 59850        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.32e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1845000, episode_reward=-23766.16 +/- 43604.17\n",
      "Episode length: 580.40 +/- 261.86\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 580          |\n",
      "|    mean_reward          | -2.38e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1845000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012719817 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.512        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.07e+07     |\n",
      "|    n_updates            | 59860        |\n",
      "|    policy_gradient_loss | 0.00217      |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.03e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.15e+03  |\n",
      "|    ep_rew_mean     | -1.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 901       |\n",
      "|    time_elapsed    | 3013      |\n",
      "|    total_timesteps | 1845248   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | -2.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 902          |\n",
      "|    time_elapsed         | 3014         |\n",
      "|    total_timesteps      | 1847296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035013368 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06e+07     |\n",
      "|    n_updates            | 59870        |\n",
      "|    policy_gradient_loss | -0.00636     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 3.31e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.93e+03     |\n",
      "|    ep_rew_mean          | -2.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 903          |\n",
      "|    time_elapsed         | 3016         |\n",
      "|    total_timesteps      | 1849344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061566858 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.572        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.38e+07     |\n",
      "|    n_updates            | 59880        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 7.39e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1850000, episode_reward=-90479.75 +/- 72263.86\n",
      "Episode length: 664.80 +/- 79.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 665         |\n",
      "|    mean_reward          | -9.05e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004582245 |\n",
      "|    clip_fraction        | 0.033       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.625       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.96e+06    |\n",
      "|    n_updates            | 59890       |\n",
      "|    policy_gradient_loss | -0.00437    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.7e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -2.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 904       |\n",
      "|    time_elapsed    | 3020      |\n",
      "|    total_timesteps | 1851392   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.86e+03     |\n",
      "|    ep_rew_mean          | -2.98e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 905          |\n",
      "|    time_elapsed         | 3022         |\n",
      "|    total_timesteps      | 1853440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047949776 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.588        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.58e+07     |\n",
      "|    n_updates            | 59900        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 5.1e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1855000, episode_reward=-74668.89 +/- 54410.29\n",
      "Episode length: 740.80 +/- 178.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 741          |\n",
      "|    mean_reward          | -7.47e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1855000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057450607 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.627        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.02e+06     |\n",
      "|    n_updates            | 59910        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.29e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.8e+03   |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 906       |\n",
      "|    time_elapsed    | 3025      |\n",
      "|    total_timesteps | 1855488   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 613         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 3027        |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002354525 |\n",
      "|    clip_fraction        | 0.0261      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.644       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.71e+06    |\n",
      "|    n_updates            | 59920       |\n",
      "|    policy_gradient_loss | -0.000487   |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.31e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.8e+03      |\n",
      "|    ep_rew_mean          | -3.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 908          |\n",
      "|    time_elapsed         | 3029         |\n",
      "|    total_timesteps      | 1859584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044175014 |\n",
      "|    clip_fraction        | 0.0396       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.614        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+07     |\n",
      "|    n_updates            | 59930        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.99e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1860000, episode_reward=-70289.98 +/- 63287.13\n",
      "Episode length: 383.80 +/- 425.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 384         |\n",
      "|    mean_reward          | -7.03e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007989052 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+07       |\n",
      "|    n_updates            | 59940       |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.58e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.74e+03  |\n",
      "|    ep_rew_mean     | -3.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 909       |\n",
      "|    time_elapsed    | 3032      |\n",
      "|    total_timesteps | 1861632   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -3.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 614          |\n",
      "|    iterations           | 910          |\n",
      "|    time_elapsed         | 3033         |\n",
      "|    total_timesteps      | 1863680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054207174 |\n",
      "|    clip_fraction        | 0.0411       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.632        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+07     |\n",
      "|    n_updates            | 59950        |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.32e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1865000, episode_reward=-54227.81 +/- 46617.56\n",
      "Episode length: 710.00 +/- 321.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 710         |\n",
      "|    mean_reward          | -5.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1865000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004469445 |\n",
      "|    clip_fraction        | 0.024       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.47e+07    |\n",
      "|    n_updates            | 59960       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.29e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.59e+03  |\n",
      "|    ep_rew_mean     | -4.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 911       |\n",
      "|    time_elapsed    | 3037      |\n",
      "|    total_timesteps | 1865728   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | -4.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 3039        |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005205678 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+07    |\n",
      "|    n_updates            | 59970       |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.99e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -4.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 3041        |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027207706 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+07    |\n",
      "|    n_updates            | 59980       |\n",
      "|    policy_gradient_loss | 0.00234     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 9.08e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1870000, episode_reward=-78408.24 +/- 44382.37\n",
      "Episode length: 904.40 +/- 138.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 904         |\n",
      "|    mean_reward          | -7.84e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005878045 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.637       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.91e+06    |\n",
      "|    n_updates            | 59990       |\n",
      "|    policy_gradient_loss | 0.000302    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.14e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -4.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 914       |\n",
      "|    time_elapsed    | 3045      |\n",
      "|    total_timesteps | 1871872   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.41e+03     |\n",
      "|    ep_rew_mean          | -4.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 614          |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 3047         |\n",
      "|    total_timesteps      | 1873920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043513332 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.01e+06     |\n",
      "|    n_updates            | 60000        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.23e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1875000, episode_reward=-65077.82 +/- 35802.14\n",
      "Episode length: 1011.00 +/- 85.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | -6.51e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1875000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028177015 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+07      |\n",
      "|    n_updates            | 60010        |\n",
      "|    policy_gradient_loss | -0.000355    |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.73e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | -4.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 614      |\n",
      "|    iterations      | 916      |\n",
      "|    time_elapsed    | 3051     |\n",
      "|    total_timesteps | 1875968  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.11e+03   |\n",
      "|    ep_rew_mean          | -5.61e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 615        |\n",
      "|    iterations           | 917        |\n",
      "|    time_elapsed         | 3053       |\n",
      "|    total_timesteps      | 1878016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00680306 |\n",
      "|    clip_fraction        | 0.0376     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.21       |\n",
      "|    explained_variance   | 0.659      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.03e+07   |\n",
      "|    n_updates            | 60020      |\n",
      "|    policy_gradient_loss | -0.00126   |\n",
      "|    std                  | 0.2        |\n",
      "|    value_loss           | 8.25e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1880000, episode_reward=-51531.35 +/- 42195.49\n",
      "Episode length: 894.60 +/- 110.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 895          |\n",
      "|    mean_reward          | -5.15e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028102386 |\n",
      "|    clip_fraction        | 0.0177       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.78e+07     |\n",
      "|    n_updates            | 60030        |\n",
      "|    policy_gradient_loss | -0.000783    |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 5.65e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -5.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 918       |\n",
      "|    time_elapsed    | 3057      |\n",
      "|    total_timesteps | 1880064   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -5.48e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 3058        |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007003321 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.665       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+07    |\n",
      "|    n_updates            | 60040       |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.09e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -5.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 3060        |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004768364 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.655       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34e+07    |\n",
      "|    n_updates            | 60050       |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.05e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1885000, episode_reward=-69727.05 +/- 7679.40\n",
      "Episode length: 1107.80 +/- 66.97\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.11e+03     |\n",
      "|    mean_reward          | -6.97e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1885000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058290944 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.624        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.41e+06     |\n",
      "|    n_updates            | 60060        |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.48e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.03e+03  |\n",
      "|    ep_rew_mean     | -5.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 615       |\n",
      "|    iterations      | 921       |\n",
      "|    time_elapsed    | 3065      |\n",
      "|    total_timesteps | 1886208   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 947          |\n",
      "|    ep_rew_mean          | -5.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 615          |\n",
      "|    iterations           | 922          |\n",
      "|    time_elapsed         | 3067         |\n",
      "|    total_timesteps      | 1888256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048691686 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.09e+06     |\n",
      "|    n_updates            | 60070        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.9e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1890000, episode_reward=-58581.66 +/- 60061.85\n",
      "Episode length: 940.00 +/- 200.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 940         |\n",
      "|    mean_reward          | -5.86e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005470286 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.25e+06    |\n",
      "|    n_updates            | 60080       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.35e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 870       |\n",
      "|    ep_rew_mean     | -5.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 615       |\n",
      "|    iterations      | 923       |\n",
      "|    time_elapsed    | 3071      |\n",
      "|    total_timesteps | 1890304   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 848          |\n",
      "|    ep_rew_mean          | -5.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 615          |\n",
      "|    iterations           | 924          |\n",
      "|    time_elapsed         | 3073         |\n",
      "|    total_timesteps      | 1892352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057799644 |\n",
      "|    clip_fraction        | 0.0331       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.65e+06     |\n",
      "|    n_updates            | 60090        |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.93e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 782          |\n",
      "|    ep_rew_mean          | -6.16e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 925          |\n",
      "|    time_elapsed         | 3074         |\n",
      "|    total_timesteps      | 1894400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024883025 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.08e+03     |\n",
      "|    n_updates            | 60100        |\n",
      "|    policy_gradient_loss | 0.0021       |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.09e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1895000, episode_reward=-63234.28 +/- 55397.07\n",
      "Episode length: 687.60 +/- 547.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 688          |\n",
      "|    mean_reward          | -6.32e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1895000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052741123 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+07     |\n",
      "|    n_updates            | 60110        |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.93e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 783       |\n",
      "|    ep_rew_mean     | -6.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 926       |\n",
      "|    time_elapsed    | 3078      |\n",
      "|    total_timesteps | 1896448   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 764          |\n",
      "|    ep_rew_mean          | -6.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 927          |\n",
      "|    time_elapsed         | 3080         |\n",
      "|    total_timesteps      | 1898496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057558096 |\n",
      "|    clip_fraction        | 0.0259       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.579        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.91e+07     |\n",
      "|    n_updates            | 60120        |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 3.24e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1900000, episode_reward=-61894.67 +/- 4315.36\n",
      "Episode length: 1219.00 +/- 114.68\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.22e+03     |\n",
      "|    mean_reward          | -6.19e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1900000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040128636 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+07      |\n",
      "|    n_updates            | 60130        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.08e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 730       |\n",
      "|    ep_rew_mean     | -6.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 928       |\n",
      "|    time_elapsed    | 3085      |\n",
      "|    total_timesteps | 1900544   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 728         |\n",
      "|    ep_rew_mean          | -6.91e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 3086        |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004633532 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+07    |\n",
      "|    n_updates            | 60140       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.36e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 712         |\n",
      "|    ep_rew_mean          | -6.88e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 3088        |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009168665 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.694       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.5e+06     |\n",
      "|    n_updates            | 60150       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.25e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1905000, episode_reward=-59666.51 +/- 19324.77\n",
      "Episode length: 1118.60 +/- 465.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.12e+03     |\n",
      "|    mean_reward          | -5.97e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1905000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149055915 |\n",
      "|    clip_fraction        | 0.0572       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.02e+06     |\n",
      "|    n_updates            | 60160        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 3.54e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 718       |\n",
      "|    ep_rew_mean     | -6.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 931       |\n",
      "|    time_elapsed    | 3093      |\n",
      "|    total_timesteps | 1906688   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 726          |\n",
      "|    ep_rew_mean          | -6.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 932          |\n",
      "|    time_elapsed         | 3095         |\n",
      "|    total_timesteps      | 1908736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025515223 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.49e+06     |\n",
      "|    n_updates            | 60170        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.37e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1910000, episode_reward=-62632.07 +/- 32270.83\n",
      "Episode length: 1009.00 +/- 509.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | -6.26e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1910000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061706705 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.638        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37e+06     |\n",
      "|    n_updates            | 60180        |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.02e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 732      |\n",
      "|    ep_rew_mean     | -6.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 616      |\n",
      "|    iterations      | 933      |\n",
      "|    time_elapsed    | 3099     |\n",
      "|    total_timesteps | 1910784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 735         |\n",
      "|    ep_rew_mean          | -6.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 934         |\n",
      "|    time_elapsed         | 3101        |\n",
      "|    total_timesteps      | 1912832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024208348 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+07    |\n",
      "|    n_updates            | 60190       |\n",
      "|    policy_gradient_loss | 0.00502     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.16e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 749         |\n",
      "|    ep_rew_mean          | -6.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 617         |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 3103        |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005546071 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.571       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.49e+07    |\n",
      "|    n_updates            | 60200       |\n",
      "|    policy_gradient_loss | 0.00517     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 3.07e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1915000, episode_reward=-91627.91 +/- 33682.57\n",
      "Episode length: 1193.00 +/- 563.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.19e+03    |\n",
      "|    mean_reward          | -9.16e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1915000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005848595 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.653       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47e+07    |\n",
      "|    n_updates            | 60210       |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.13e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 758       |\n",
      "|    ep_rew_mean     | -7.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 936       |\n",
      "|    time_elapsed    | 3107      |\n",
      "|    total_timesteps | 1916928   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 762          |\n",
      "|    ep_rew_mean          | -6.97e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 937          |\n",
      "|    time_elapsed         | 3109         |\n",
      "|    total_timesteps      | 1918976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028567056 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.644        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02e+07     |\n",
      "|    n_updates            | 60220        |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.5e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=-50843.86 +/- 20772.61\n",
      "Episode length: 1191.00 +/- 599.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.19e+03     |\n",
      "|    mean_reward          | -5.08e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056823064 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.21e+06     |\n",
      "|    n_updates            | 60230        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 7.8e+06      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 785      |\n",
      "|    ep_rew_mean     | -7e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 616      |\n",
      "|    iterations      | 938      |\n",
      "|    time_elapsed    | 3114     |\n",
      "|    total_timesteps | 1921024  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 798          |\n",
      "|    ep_rew_mean          | -7.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 939          |\n",
      "|    time_elapsed         | 3116         |\n",
      "|    total_timesteps      | 1923072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035595007 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.63         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66e+06     |\n",
      "|    n_updates            | 60240        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 2.37e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1925000, episode_reward=-60449.71 +/- 14988.62\n",
      "Episode length: 1613.00 +/- 85.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.61e+03    |\n",
      "|    mean_reward          | -6.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1925000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024287235 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.89e+05    |\n",
      "|    n_updates            | 60250       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 4.87e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 803       |\n",
      "|    ep_rew_mean     | -6.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 940       |\n",
      "|    time_elapsed    | 3121      |\n",
      "|    total_timesteps | 1925120   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 815        |\n",
      "|    ep_rew_mean          | -6.58e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 616        |\n",
      "|    iterations           | 941        |\n",
      "|    time_elapsed         | 3124       |\n",
      "|    total_timesteps      | 1927168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00901814 |\n",
      "|    clip_fraction        | 0.0378     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.2        |\n",
      "|    explained_variance   | 0.654      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.02e+06   |\n",
      "|    n_updates            | 60260      |\n",
      "|    policy_gradient_loss | -0.00242   |\n",
      "|    std                  | 0.2        |\n",
      "|    value_loss           | 1.26e+07   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 828          |\n",
      "|    ep_rew_mean          | -6.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 942          |\n",
      "|    time_elapsed         | 3127         |\n",
      "|    total_timesteps      | 1929216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071020424 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.668        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+06     |\n",
      "|    n_updates            | 60270        |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 1.63e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1930000, episode_reward=-51484.29 +/- 12056.64\n",
      "Episode length: 1635.40 +/- 68.17\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.64e+03   |\n",
      "|    mean_reward          | -5.15e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1930000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03120083 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.2        |\n",
      "|    explained_variance   | 0.697      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.95e+06   |\n",
      "|    n_updates            | 60280      |\n",
      "|    policy_gradient_loss | 0.0103     |\n",
      "|    std                  | 0.201      |\n",
      "|    value_loss           | 7.06e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 843       |\n",
      "|    ep_rew_mean     | -6.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 943       |\n",
      "|    time_elapsed    | 3134      |\n",
      "|    total_timesteps | 1931264   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 856          |\n",
      "|    ep_rew_mean          | -6.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 944          |\n",
      "|    time_elapsed         | 3136         |\n",
      "|    total_timesteps      | 1933312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022976315 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.38e+05     |\n",
      "|    n_updates            | 60290        |\n",
      "|    policy_gradient_loss | 0.000706     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 6.52e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1935000, episode_reward=-44409.49 +/- 54125.32\n",
      "Episode length: 964.80 +/- 751.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 965          |\n",
      "|    mean_reward          | -4.44e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1935000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118903555 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.871        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 60300        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 1.93e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 871       |\n",
      "|    ep_rew_mean     | -6.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 945       |\n",
      "|    time_elapsed    | 3140      |\n",
      "|    total_timesteps | 1935360   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 882        |\n",
      "|    ep_rew_mean          | -6.25e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 616        |\n",
      "|    iterations           | 946        |\n",
      "|    time_elapsed         | 3143       |\n",
      "|    total_timesteps      | 1937408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06756617 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.2        |\n",
      "|    explained_variance   | 0.776      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 336        |\n",
      "|    n_updates            | 60310      |\n",
      "|    policy_gradient_loss | 0.0176     |\n",
      "|    std                  | 0.201      |\n",
      "|    value_loss           | 3.55e+06   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 882          |\n",
      "|    ep_rew_mean          | -6.14e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 616          |\n",
      "|    iterations           | 947          |\n",
      "|    time_elapsed         | 3146         |\n",
      "|    total_timesteps      | 1939456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023746872 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.651        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.04e+06     |\n",
      "|    n_updates            | 60320        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 1.68e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1940000, episode_reward=258.93 +/- 18724.41\n",
      "Episode length: 1417.00 +/- 681.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.42e+03     |\n",
      "|    mean_reward          | 259          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1940000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061360043 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.692        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+03     |\n",
      "|    n_updates            | 60330        |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    std                  | 0.201        |\n",
      "|    value_loss           | 6.95e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 890       |\n",
      "|    ep_rew_mean     | -5.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 615       |\n",
      "|    iterations      | 948       |\n",
      "|    time_elapsed    | 3152      |\n",
      "|    total_timesteps | 1941504   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 912        |\n",
      "|    ep_rew_mean          | -5.97e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 616        |\n",
      "|    iterations           | 949        |\n",
      "|    time_elapsed         | 3154       |\n",
      "|    total_timesteps      | 1943552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06996493 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.2        |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.18e+03   |\n",
      "|    n_updates            | 60340      |\n",
      "|    policy_gradient_loss | 0.00503    |\n",
      "|    std                  | 0.201      |\n",
      "|    value_loss           | 9.99e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1945000, episode_reward=-38683.52 +/- 122214.35\n",
      "Episode length: 1879.40 +/- 1670.68\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.88e+03   |\n",
      "|    mean_reward          | -3.87e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1945000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00994017 |\n",
      "|    clip_fraction        | 0.097      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.2        |\n",
      "|    explained_variance   | 0.769      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 597        |\n",
      "|    n_updates            | 60350      |\n",
      "|    policy_gradient_loss | -0.000208  |\n",
      "|    std                  | 0.201      |\n",
      "|    value_loss           | 1.24e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 912       |\n",
      "|    ep_rew_mean     | -5.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 615       |\n",
      "|    iterations      | 950       |\n",
      "|    time_elapsed    | 3162      |\n",
      "|    total_timesteps | 1945600   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 912         |\n",
      "|    ep_rew_mean          | -5.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 3164        |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012629279 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 389         |\n",
      "|    n_updates            | 60360       |\n",
      "|    policy_gradient_loss | 0.00394     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 954         |\n",
      "|    ep_rew_mean          | -5.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 3166        |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012062261 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.708       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.01e+03    |\n",
      "|    n_updates            | 60370       |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.57e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1950000, episode_reward=26010.95 +/- 18846.28\n",
      "Episode length: 3403.80 +/- 1813.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.4e+03     |\n",
      "|    mean_reward          | 2.6e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018693808 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.69        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 836         |\n",
      "|    n_updates            | 60380       |\n",
      "|    policy_gradient_loss | 0.00429     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 4.05e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 954       |\n",
      "|    ep_rew_mean     | -5.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 953       |\n",
      "|    time_elapsed    | 3177      |\n",
      "|    total_timesteps | 1951744   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 984         |\n",
      "|    ep_rew_mean          | -5.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 3179        |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006911793 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 60390       |\n",
      "|    policy_gradient_loss | 0.00261     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1955000, episode_reward=-6667.52 +/- 42915.47\n",
      "Episode length: 2018.80 +/- 2434.21\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.02e+03  |\n",
      "|    mean_reward          | -6.67e+03 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1955000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0132946 |\n",
      "|    clip_fraction        | 0.117     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.22      |\n",
      "|    explained_variance   | 0.919     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 209       |\n",
      "|    n_updates            | 60400     |\n",
      "|    policy_gradient_loss | -0.00138  |\n",
      "|    std                  | 0.199     |\n",
      "|    value_loss           | 1.98e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 984       |\n",
      "|    ep_rew_mean     | -5.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 955       |\n",
      "|    time_elapsed    | 3188      |\n",
      "|    total_timesteps | 1955840   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -5.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 613         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 3190        |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009907713 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 60410       |\n",
      "|    policy_gradient_loss | 0.004       |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -5.68e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 957          |\n",
      "|    time_elapsed         | 3192         |\n",
      "|    total_timesteps      | 1959936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086771455 |\n",
      "|    clip_fraction        | 0.0741       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 366          |\n",
      "|    n_updates            | 60420        |\n",
      "|    policy_gradient_loss | 0.00265      |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.46e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1960000, episode_reward=353.29 +/- 16255.17\n",
      "Episode length: 1210.60 +/- 1464.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.21e+03    |\n",
      "|    mean_reward          | 353         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024311941 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 60430       |\n",
      "|    policy_gradient_loss | 0.0169      |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 560         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.06e+03  |\n",
      "|    ep_rew_mean     | -5.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 958       |\n",
      "|    time_elapsed    | 3199      |\n",
      "|    total_timesteps | 1961984   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.06e+03     |\n",
      "|    ep_rew_mean          | -5.56e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 959          |\n",
      "|    time_elapsed         | 3201         |\n",
      "|    total_timesteps      | 1964032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074273087 |\n",
      "|    clip_fraction        | 0.0669       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.19         |\n",
      "|    explained_variance   | 0.747        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 484          |\n",
      "|    n_updates            | 60440        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 1.34e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1965000, episode_reward=18847.72 +/- 20444.86\n",
      "Episode length: 3685.00 +/- 1917.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.68e+03    |\n",
      "|    mean_reward          | 1.88e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1965000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011159816 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.5        |\n",
      "|    n_updates            | 60450       |\n",
      "|    policy_gradient_loss | 0.00406     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 444         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.09e+03  |\n",
      "|    ep_rew_mean     | -5.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 611       |\n",
      "|    iterations      | 960       |\n",
      "|    time_elapsed    | 3213      |\n",
      "|    total_timesteps | 1966080   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -5.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 3215        |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019268405 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 60460       |\n",
      "|    policy_gradient_loss | -0.000331   |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 2.19e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1970000, episode_reward=31853.34 +/- 23877.49\n",
      "Episode length: 3188.80 +/- 1829.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.19e+03    |\n",
      "|    mean_reward          | 3.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009302799 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 60470       |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 421         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.11e+03  |\n",
      "|    ep_rew_mean     | -5.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 962       |\n",
      "|    time_elapsed    | 3224      |\n",
      "|    total_timesteps | 1970176   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | -5.16e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 611          |\n",
      "|    iterations           | 963          |\n",
      "|    time_elapsed         | 3227         |\n",
      "|    total_timesteps      | 1972224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054762177 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.2          |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.56e+06     |\n",
      "|    n_updates            | 60480        |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 0.2          |\n",
      "|    value_loss           | 7.51e+05     |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps = 5_000_000, callback = eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path + '/ppo_jl_ramp_top_v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "# model = PPO.load(\"/home/bmsit/Ascento/jointed_limited/Training/models_ascento/ppo_jl_ramp_top_v3.zip\", env = env)\n",
    "\n",
    "# #JL_10 -> STAYS AT SET POINT BUT KEEPS ON SPININING VERY VERY FAST\n",
    "# #JL_10_Best -> spins a bit slowly\n",
    "\n",
    "# # JL_11 -> MOVES AROUND, ALSO BENDS 1 LEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes = 30, render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n",
      "0.8022732578256428\n",
      "0.8021447758791348\n",
      "0.8017325688970213\n",
      "0.8011975390460414\n",
      "0.8004107937335961\n",
      "0.7994895468615938\n",
      "0.7984312593516595\n",
      "0.7971598723512643\n",
      "0.7956327068331461\n",
      "0.7940452573896347\n",
      "0.7925724453405882\n",
      "0.7908749335390616\n",
      "0.7889630454643203\n",
      "0.7869457228958705\n",
      "0.7846082021147041\n",
      "0.7821973558615923\n",
      "0.7798608876355306\n",
      "0.7773013506329114\n",
      "0.7744923944029702\n",
      "0.771408634151593\n",
      "0.7681602580667077\n",
      "0.7648252464466404\n",
      "0.7613407657860353\n",
      "0.75780859563732\n",
      "0.7540629672055771\n",
      "0.7499941125586721\n",
      "0.7456498729490616\n",
      "0.7410898842357572\n",
      "0.7362869408565491\n",
      "0.7314825435182232\n",
      "0.7264298208436711\n",
      "0.7212884960242643\n",
      "0.7160078775656229\n",
      "0.7104846197753131\n",
      "0.704740714469175\n",
      "0.6989930568906836\n",
      "0.6930936856750735\n",
      "0.6870441721440692\n",
      "0.6808543497109749\n",
      "0.6743802150583332\n",
      "0.6677436736254193\n",
      "0.6610795469415504\n",
      "0.6544795475191678\n",
      "0.6477875909885227\n",
      "0.6408748629168514\n",
      "0.6337071240755767\n",
      "0.6262980985445247\n",
      "0.6188842249472896\n",
      "0.6112436792315714\n",
      "0.6034326515852483\n",
      "0.5953549688973169\n",
      "0.5873514026764564\n",
      "0.5793433329198513\n",
      "0.5713132400441723\n",
      "0.562830137735455\n",
      "0.5540818851672351\n",
      "0.5452988824720164\n",
      "0.5363188242507938\n",
      "0.5271463676478318\n",
      "0.5178029562206066\n",
      "0.5082712373508008\n",
      "0.4986891068850509\n",
      "0.4886903490580561\n",
      "0.4786279595874474\n",
      "0.468570747763925\n",
      "0.4584945778636747\n",
      "0.4482948457123861\n",
      "0.43825663957901734\n",
      "0.42911451842206844\n",
      "0.42057595864068137\n",
      "0.41236776771525613\n",
      "0.40504217121166664\n",
      "0.3988430123176503\n",
      "0.393875311691613\n",
      "0.39030334314487874\n",
      "0.3883281721364848\n",
      "0.387820523455168\n",
      "0.3884502499910246\n",
      "0.3902375135473489\n",
      "0.39306212718519185\n",
      "0.39675704663689054\n",
      "0.4013372293032478\n",
      "0.40667567894364487\n",
      "0.41241459244590867\n",
      "0.418355919271305\n",
      "0.42472620513929527\n",
      "0.43145726281904756\n",
      "0.7929563648903495\n",
      "0.7926988539145484\n",
      "0.7933892580476093\n",
      "0.7957815909750782\n",
      "0.7996044454414953\n",
      "0.8043377066067982\n",
      "0.8097657855481611\n",
      "0.8157813315483081\n",
      "0.8222898950731502\n",
      "0.8291843649815052\n",
      "0.8363609970996129\n",
      "0.8436842709168574\n",
      "0.8510164667853138\n",
      "0.858280281099318\n",
      "0.8654939213342933\n",
      "0.8727216395816831\n",
      "0.8798947922974936\n",
      "0.8869039546037093\n",
      "0.8936697212659345\n",
      "0.9001873786604008\n",
      "0.906429802797059\n",
      "0.9124206345087832\n",
      "0.9182628933452522\n",
      "0.9240686987150882\n",
      "0.9297836774140692\n",
      "0.9352198983271864\n",
      "0.9403938334207996\n",
      "0.9453194050670126\n",
      "0.9500195518865346\n",
      "0.9543922448471787\n",
      "0.9585496318245772\n",
      "0.962654164382\n",
      "0.9667299669286519\n",
      "0.9707222993403909\n",
      "0.9746198942075395\n",
      "0.9782629256899837\n",
      "0.9818437337728786\n",
      "0.9852317650271872\n",
      "0.9885725555582476\n",
      "0.9918025614886972\n",
      "0.9948367750372441\n",
      "0.9979107124763219\n",
      "1.0009995552430162\n",
      "1.0040256641330607\n",
      "1.0068321972882255\n",
      "1.0095139240591593\n",
      "1.0120894331466717\n",
      "1.014506771166753\n",
      "1.0168427583326134\n",
      "1.0190309408484581\n",
      "1.021160721071818\n",
      "1.0231346780128643\n",
      "1.0249151272174997\n",
      "1.0265372128539156\n",
      "1.0279050592582883\n",
      "1.0290831712969426\n",
      "1.0302204366586738\n",
      "1.0312016111758522\n",
      "1.0318997775329588\n",
      "0.800564462234069\n",
      "0.8004537762130666\n",
      "0.8003036985292699\n",
      "0.8000059569235607\n",
      "0.7994513166074007\n",
      "0.7984859347786142\n",
      "0.7973631752156449\n",
      "0.7961953400403412\n",
      "0.794897627595862\n",
      "0.7934320024814869\n",
      "0.7918009553411264\n",
      "0.7900197620982373\n",
      "0.7878958045725206\n",
      "0.7854370218797182\n",
      "0.7827983169360416\n",
      "0.7802352449513421\n",
      "0.7775655786771558\n",
      "0.7747979526350183\n",
      "0.7718227466311933\n",
      "0.7686406097303795\n",
      "0.7654358070572893\n",
      "0.7620149804810807\n",
      "0.7584393723109404\n",
      "0.7545862999019852\n",
      "0.7505929522757189\n",
      "0.7464259964231972\n",
      "0.7423228303373317\n",
      "0.738099982316023\n",
      "0.7336317146426728\n",
      "0.7289633208911325\n",
      "0.7241817916418947\n",
      "0.7193010171215863\n",
      "0.7141861390265303\n",
      "0.7089414919813299\n",
      "0.7036006970314841\n",
      "0.6979593504896798\n",
      "0.6922373752543192\n",
      "0.6864626667506676\n",
      "0.6803066612114658\n",
      "0.6739085977245675\n",
      "0.6673702344176441\n",
      "0.6605523175698382\n",
      "0.6535068084669847\n",
      "0.6462353341329502\n",
      "0.63897914846109\n",
      "0.6316202408483694\n",
      "0.6240688400100352\n",
      "0.6162289601215658\n",
      "0.6083602911503231\n",
      "0.6004812088030496\n",
      "0.5925782687503994\n",
      "0.5845400217553993\n",
      "0.5764618438006418\n",
      "0.5681659987554726\n",
      "0.5597370907107068\n",
      "0.5509217419602411\n",
      "0.541933584761018\n",
      "0.5327564247113789\n",
      "0.5234614982085355\n",
      "0.5140418987192168\n",
      "0.5046923046431564\n",
      "0.49509699513128563\n",
      "0.4853906901692587\n",
      "0.4755200543478582\n",
      "0.46563317386537956\n",
      "0.4556120573293144\n",
      "0.44535285597061713\n",
      "0.4348996957666351\n",
      "0.42449008438868324\n",
      "0.4139518001223459\n",
      "0.4040662320064408\n",
      "0.3951055141467703\n",
      "0.3867073664777044\n",
      "0.37921970995165494\n",
      "0.3728402520582133\n",
      "0.36788215854871487\n",
      "0.36433140596901337\n",
      "0.3620202345487689\n",
      "0.36092413376501215\n",
      "0.36110575223695507\n",
      "0.3626091659351879\n",
      "0.3650518338269425\n",
      "0.3683725196743755\n",
      "0.37237516343291077\n",
      "0.3770863646110354\n",
      "0.382558832267462\n",
      "0.3887348422754358\n",
      "0.3953307108784572\n",
      "0.40224540816471327\n",
      "0.7912068063192134\n",
      "0.7909389467699233\n",
      "0.7905924602113776\n",
      "0.7901589676083164\n",
      "0.789731820459631\n",
      "0.7892984409263438\n",
      "0.7890849517016084\n",
      "0.7889924995875932\n",
      "0.7890087524677375\n",
      "0.7891518136877265\n",
      "0.7894718912834271\n",
      "0.789923246092836\n",
      "0.7904667104594484\n",
      "0.7911491014284145\n",
      "0.7917130791464769\n",
      "0.7922551944851859\n",
      "0.7929587074615317\n",
      "0.7935630778113799\n",
      "0.7940892261073949\n",
      "0.7944996338719609\n",
      "0.7948077776557629\n",
      "0.7949811158311149\n",
      "0.7950928276359753\n",
      "0.7952934974210565\n",
      "0.7953704293079498\n",
      "0.7953463012777601\n",
      "0.7952257811318653\n",
      "0.7950029947921585\n",
      "0.7947175762893146\n",
      "0.7942914746518256\n",
      "0.7937265932149675\n",
      "0.7931813929475596\n",
      "0.7924217642856729\n",
      "0.7916028917593254\n",
      "0.7906500046538839\n",
      "0.7896868118259627\n",
      "0.7886490014614924\n",
      "0.787546176414407\n",
      "0.7863882649475803\n",
      "0.7851907146949322\n",
      "0.7840107375045147\n",
      "0.7828891874400479\n",
      "0.7817758744249922\n",
      "0.7805196539063395\n",
      "0.7790250957665402\n",
      "0.7775772331193901\n",
      "0.7762534209924749\n",
      "0.7747993558653251\n",
      "0.7733377462950858\n",
      "0.7719361880749988\n",
      "0.7705024927616962\n",
      "0.7689619307030247\n",
      "0.7673398437027312\n",
      "0.7657222532268279\n",
      "0.7642211349524225\n",
      "0.7626310464291508\n",
      "0.7611003539164866\n",
      "0.7593494892538084\n",
      "0.7573766507928515\n",
      "0.7553108806156146\n",
      "0.7533706594645698\n",
      "0.7515602862744901\n",
      "0.7498334207960163\n",
      "0.7481602075554612\n",
      "0.7466114100686435\n",
      "0.7449572864339705\n",
      "0.7433416981298024\n",
      "0.7418501416058169\n",
      "0.7404099842446304\n",
      "0.7391407881374266\n",
      "0.7379023678717582\n",
      "0.7366506815044299\n",
      "0.735301850135979\n",
      "0.7341151633182778\n",
      "0.7329008105042168\n",
      "0.7317854548531423\n",
      "0.7307278819490409\n",
      "0.7298629682685579\n",
      "0.7288996862564314\n",
      "0.7280828208927069\n",
      "0.7269419442214705\n",
      "0.7256633720661518\n",
      "0.7244202338131297\n",
      "0.7230900568053591\n",
      "0.7217786845262064\n",
      "0.7205137326316806\n",
      "0.7191672011047515\n",
      "0.7178415562939506\n",
      "0.7163260700184835\n",
      "0.7147809886853429\n",
      "0.7131393253373537\n",
      "0.7114469656210398\n",
      "0.7096092275446205\n",
      "0.7076844755124081\n",
      "0.7057787739469673\n",
      "0.7037277494105456\n",
      "0.7017806966284238\n",
      "0.6997705700274557\n",
      "0.6978441580836093\n",
      "0.6959338314717441\n",
      "0.6939715124399463\n",
      "0.6921416727681259\n",
      "0.6902855558082701\n",
      "0.6882023812669067\n",
      "0.6860060990919101\n",
      "0.6837271342769201\n",
      "0.6815506093841777\n",
      "0.6793625761384072\n",
      "0.6771551768837479\n",
      "0.6748194024872688\n",
      "0.6727859498677584\n",
      "0.6711994799288974\n",
      "0.6694308092436339\n",
      "0.6674065543569802\n",
      "0.6653217225545035\n",
      "0.6630980748719809\n",
      "0.6610055098664525\n",
      "0.6590521524428136\n",
      "0.6572729624713388\n",
      "0.6555156827667568\n",
      "0.6536866830940391\n",
      "0.6515169442038314\n",
      "0.649393302287346\n",
      "0.6473473182537322\n",
      "0.6453067645198403\n",
      "0.6432813148386594\n",
      "0.6410229344374379\n",
      "0.6389112212494001\n",
      "0.6366867297232286\n",
      "0.6345120010486957\n",
      "0.6322687676663103\n",
      "0.6298985155713882\n",
      "0.6274111380050231\n",
      "0.6247807752122905\n",
      "0.6222704795383601\n",
      "0.6200696747199066\n",
      "0.6179471016810901\n",
      "0.6157178854622676\n",
      "0.6133882838659801\n",
      "0.6109259107207908\n",
      "0.6085525551978717\n",
      "0.606102353282681\n",
      "0.6036055075249767\n",
      "0.6012048777313314\n",
      "0.5989320982144678\n",
      "0.5967889655367771\n",
      "0.5947012636221756\n",
      "0.5926542784886999\n",
      "0.5905001548377377\n",
      "0.5882996585029796\n",
      "0.5859939134256007\n",
      "0.5835941096773799\n",
      "0.5813145622693063\n",
      "0.578988984128553\n",
      "0.5765039776447638\n",
      "0.5739072249284892\n",
      "0.5711404527520528\n",
      "0.5682258272758114\n",
      "0.5653786977101802\n",
      "0.5626928406343229\n",
      "0.5601091885948624\n",
      "0.5575556726974666\n",
      "0.5548476904285463\n",
      "0.5520713137623837\n",
      "0.5494260254086861\n",
      "0.5468326052832897\n",
      "0.5443287583524725\n",
      "0.5417798656733799\n",
      "0.5393934492298467\n",
      "0.5371931538977115\n",
      "0.5349917230898046\n",
      "0.5328418888276666\n",
      "0.5305453657099135\n",
      "0.5282320740426775\n",
      "0.5258436537158969\n",
      "0.5234448596325955\n",
      "0.5208020591316208\n",
      "0.5181877284936317\n",
      "0.5155144894989282\n",
      "0.5129916023706623\n",
      "0.5103902532762195\n",
      "0.5078171570939419\n",
      "0.5051312423341701\n",
      "0.5023837246659044\n",
      "0.49962177942734726\n",
      "0.4967123879448968\n",
      "0.49375433165398847\n",
      "0.49091469273143984\n",
      "0.48797995266659727\n",
      "0.4851426023975364\n",
      "0.4825067449022015\n",
      "0.4798355363155921\n",
      "0.4770283093513722\n",
      "0.47418549924199394\n",
      "0.4712860755018004\n",
      "0.4684964249247749\n",
      "0.4658165832189865\n",
      "0.4632006457436428\n",
      "0.4604757692597359\n",
      "0.45763303800934696\n",
      "0.45471729461658306\n",
      "0.451618596741084\n",
      "0.4483635967446473\n",
      "0.4452588886504167\n",
      "0.4421106968518943\n",
      "0.4389700086839539\n",
      "0.4358711476240113\n",
      "0.43277240612493917\n",
      "0.42974941378051384\n",
      "0.4266157864066901\n",
      "0.4235682749663869\n",
      "0.4206607509379393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41771021961731736\n",
      "0.4146979451461275\n",
      "0.4116615231139359\n",
      "0.4087372831972448\n",
      "0.4056687558740217\n",
      "0.4025619007604635\n",
      "0.39954354796674396\n",
      "0.3965309239477272\n",
      "0.3933729684053829\n",
      "0.3901786866836643\n",
      "0.38704945253134004\n",
      "0.3838812732851278\n",
      "0.38048770948004296\n",
      "0.37691223847663374\n",
      "0.37338745702917947\n",
      "0.3698639112565425\n",
      "0.36628917545148854\n",
      "0.3628000502206505\n",
      "0.3593731897496598\n",
      "0.3560037344136945\n",
      "0.35254383572014586\n",
      "0.3492008409489083\n",
      "0.3458894329137051\n",
      "0.34259873089831155\n",
      "0.3393419940004169\n",
      "0.3360032945768166\n",
      "0.3328071192984705\n",
      "0.32977982401879374\n",
      "0.32686306354707784\n",
      "0.3238499527651234\n",
      "0.32069823040915474\n",
      "0.31755129926790165\n",
      "0.31439239384478185\n",
      "0.3112847687679238\n",
      "0.3081027102590881\n",
      "0.3048293918794289\n",
      "0.3015159295926456\n",
      "0.2981712676875434\n",
      "0.2948412028704349\n",
      "0.2915918215517216\n",
      "0.288313405375964\n",
      "0.2849839028374482\n",
      "0.281528629274579\n",
      "0.2778217659972797\n",
      "0.2738735275266042\n",
      "0.2700235393477278\n",
      "0.26615713825315096\n",
      "0.26237302290715253\n",
      "0.25857340068383206\n",
      "0.2549149490320468\n",
      "0.2513351108163757\n",
      "0.24768431728371676\n",
      "0.24415914775724046\n",
      "0.24060127501576078\n",
      "0.2370618551654121\n",
      "0.2334223903894184\n",
      "0.22989305207334468\n",
      "0.2264823257280926\n",
      "0.22307139293239572\n",
      "0.21962850444368878\n",
      "0.21604618240999773\n",
      "0.21257209601283825\n",
      "0.20906045154966804\n",
      "0.2054675215373003\n",
      "0.20207946729155526\n",
      "0.19879892823365028\n",
      "0.19548473294448343\n",
      "0.19221119440688889\n",
      "0.18878601985056476\n",
      "0.1854528629310196\n",
      "0.18218260890165727\n",
      "0.17911405927773416\n",
      "0.1760618274704154\n",
      "0.17282210885235583\n",
      "0.16951322655279796\n",
      "0.16599104052300323\n",
      "0.1625996497054035\n",
      "0.15933406733157854\n",
      "0.15605426332601607\n",
      "0.15255919447071972\n",
      "0.1490773180456226\n",
      "0.14563792477585025\n",
      "0.14216293447548284\n",
      "0.13863137905122816\n",
      "0.1351070405935752\n",
      "0.13166996702611355\n",
      "0.12820263774821558\n",
      "0.12476391636607574\n",
      "0.1212146938929273\n",
      "0.1176984695703055\n",
      "0.11408461240982024\n",
      "0.11058789701754884\n",
      "0.10711675376411979\n",
      "0.10377890927769538\n",
      "0.10051897097362522\n",
      "0.09732597922268857\n",
      "0.09412271794094881\n",
      "0.09098725625525524\n",
      "0.08795731991884073\n",
      "0.08480380403942477\n",
      "0.08159124613329713\n",
      "0.07843661501770542\n",
      "0.07533495869273278\n",
      "0.07214356822949097\n",
      "0.06879685620342191\n",
      "0.0654153249908075\n",
      "0.06204104530110172\n",
      "0.05866951585870096\n",
      "0.05533006382748548\n",
      "0.05180825346203217\n",
      "0.04817728161344803\n",
      "0.0446271065321069\n",
      "0.04115344240812052\n",
      "0.03772185877263289\n",
      "0.03412840570819091\n",
      "0.03060424492853815\n",
      "0.02715543483587547\n",
      "0.0237767105528442\n",
      "0.02031577770082999\n",
      "0.016729475893817923\n",
      "0.013208242161965283\n",
      "0.009964642878202857\n",
      "0.006819511614576647\n",
      "0.0037615147532834453\n",
      "0.0009001019716062045\n",
      "-0.0018702628912040445\n",
      "-0.004615873419162007\n",
      "-0.007224618691802013\n",
      "-0.00962823876713881\n",
      "-0.011886913815313989\n",
      "-0.013975694286174697\n",
      "-0.015991516421639155\n",
      "-0.01792308779899334\n",
      "-0.01984540115597907\n",
      "-0.021648806881845162\n",
      "-0.02348235242708857\n",
      "-0.025056060363904748\n",
      "-0.02644005233597348\n",
      "-0.02764145601433558\n",
      "-0.028749012143573217\n",
      "-0.02955292138126736\n",
      "-0.030261662386564383\n",
      "-0.030778415911656108\n",
      "-0.030825935482933418\n",
      "-0.03046214938435391\n",
      "-0.029854680319932672\n",
      "-0.029225958458058865\n",
      "-0.02824090366405769\n",
      "-0.027249499425700305\n",
      "-0.0262036083198522\n",
      "-0.02451350651097257\n",
      "-0.022192305047169306\n",
      "-0.019213949122997898\n",
      "-0.015825542540617604\n",
      "-0.012250876285572025\n",
      "-0.008852714369692838\n",
      "-0.00547145337680209\n",
      "-0.0023759476398069576\n",
      "0.0006036848991625634\n",
      "0.0033043660488265487\n",
      "0.005926213987853654\n",
      "0.008526586580764727\n",
      "0.010766838163643724\n",
      "0.012668993712979892\n",
      "0.014313019874270255\n",
      "0.015528931206286456\n",
      "0.016573793465463726\n",
      "0.017784815459569198\n",
      "0.018647589207624334\n",
      "0.01914759472829181\n",
      "0.01935260690334136\n",
      "0.018981005900044014\n",
      "0.018602797267522272\n",
      "0.018107807881628864\n",
      "0.017484302382369473\n",
      "0.016445576636731823\n",
      "0.01521113515500244\n",
      "0.014311919479047714\n",
      "0.013104073262728704\n",
      "0.01170629006535736\n",
      "0.01052159792880344\n",
      "0.009595216326904594\n",
      "0.008558622937005007\n",
      "0.006711256921855413\n",
      "0.004708551412594011\n",
      "0.0029214653929199395\n",
      "0.001386672539812255\n",
      "-3.064372724469189e-05\n",
      "-0.0019040331157861461\n",
      "-0.003938533721535341\n",
      "-0.00552991203341019\n",
      "-0.007279697425765765\n",
      "-0.008625620278536042\n",
      "-0.009609561205031241\n",
      "-0.01047949429382838\n",
      "-0.01101927683515226\n",
      "-0.011426616526020563\n",
      "-0.011410086501995135\n",
      "-0.011140911620602436\n",
      "-0.01067825507061721\n",
      "-0.010313199953882645\n",
      "-0.009938342299974348\n",
      "-0.009460822791565657\n",
      "-0.008978915812674326\n",
      "-0.008439663571219294\n",
      "-0.007941137129687288\n",
      "-0.007908534522787659\n",
      "-0.0074521606817953044\n",
      "-0.007025068754469626\n",
      "-0.006613073514914816\n",
      "-0.006427375283912087\n",
      "-0.006342233870241618\n",
      "-0.006251078873306027\n",
      "-0.006004608818334759\n",
      "-0.005682041221287776\n",
      "-0.005643306640868844\n",
      "-0.005407210655023659\n",
      "-0.005272606706899632\n",
      "-0.005233804266109784\n",
      "-0.005387524434586317\n",
      "-0.00577057517500564\n",
      "-0.006108743464725804\n",
      "-0.0064814199327400115\n",
      "-0.007030221433632329\n",
      "-0.00794056863605069\n",
      "-0.008467283771226946\n",
      "-0.008971258260329623\n",
      "-0.009452413502789275\n",
      "-0.01008914815974131\n",
      "-0.010836289862589396\n",
      "-0.011200689584256211\n",
      "-0.011309704869383855\n",
      "-0.011569889661637626\n",
      "-0.011881755720047836\n",
      "-0.012137935732216776\n",
      "-0.012218985250606357\n",
      "-0.012574474524079967\n",
      "-0.012810586404860325\n",
      "-0.013011670051748431\n",
      "-0.013199539154073205\n",
      "-0.013500449745991832\n",
      "-0.013751967699426298\n",
      "-0.013892650070909979\n",
      "-0.01427866540655981\n",
      "-0.014628092617775442\n",
      "-0.014962175121627758\n",
      "-0.015004721343897713\n",
      "-0.015032547061185281\n",
      "-0.015181288381662297\n",
      "-0.01544658808295097\n",
      "-0.015465193850075597\n",
      "-0.015624233893390446\n",
      "-0.015733396802885474\n",
      "-0.01594979926019759\n",
      "-0.016399694481764537\n",
      "-0.01685657272500864\n",
      "-0.017125782419610654\n",
      "-0.017259648907156873\n",
      "-0.017794324027025566\n",
      "-0.01858491255612255\n",
      "-0.019312522409702455\n",
      "-0.019931521553235673\n",
      "-0.020395408129389225\n",
      "-0.02077107502442831\n",
      "-0.021231900901811485\n",
      "-0.02155774675230478\n",
      "-0.021640182005495244\n",
      "-0.021576452495382193\n",
      "-0.02165196320687191\n",
      "-0.022067111793259396\n",
      "-0.02267697929160659\n",
      "-0.02281116107760872\n",
      "-0.022998378958130925\n",
      "-0.023085122485101712\n",
      "-0.02291282176110608\n",
      "-0.022635170812617844\n",
      "-0.022417829237719494\n",
      "-0.02204157891204195\n",
      "-0.021708368096698717\n",
      "-0.021460296673898423\n",
      "-0.021165915590878534\n",
      "-0.020654372247269567\n",
      "-0.02039757034918661\n",
      "-0.02022005166635172\n",
      "-0.019535055690125366\n",
      "-0.018915250937369885\n",
      "-0.018323836992965258\n",
      "-0.01773736828508925\n",
      "-0.01741585379129743\n",
      "-0.01701453026162736\n",
      "-0.01633199647155166\n",
      "-0.015728780081602653\n",
      "-0.015360461144133147\n",
      "-0.015150654563069616\n",
      "-0.014869457581787095\n",
      "-0.014596129421146914\n",
      "-0.014215628260935337\n",
      "-0.014101036418760053\n",
      "-0.013999727502499443\n",
      "-0.01388916296059384\n",
      "-0.013619753165858764\n",
      "-0.013209674467406755\n",
      "-0.012827715345147955\n",
      "-0.01254981245283223\n",
      "-0.012087539297526083\n",
      "-0.011804990270298792\n",
      "-0.011366181660083675\n",
      "-0.010934840629690152\n",
      "-0.010494756348039497\n",
      "-0.010138877761385869\n",
      "-0.009978147829099933\n",
      "-0.00973329631016498\n",
      "-0.009301410687476586\n",
      "-0.00894624621449674\n",
      "-0.008657697165902055\n",
      "-0.008319884384122836\n",
      "-0.00793504388581509\n",
      "-0.00781512354541713\n",
      "-0.007674255428620485\n",
      "-0.007372739840465912\n",
      "-0.007174035729642062\n",
      "-0.007058512913076097\n",
      "-0.007144087517605268\n",
      "-0.00714860975737688\n",
      "-0.00722586010430745\n",
      "-0.007425546518788887\n",
      "-0.0075197683590632084\n",
      "-0.007686099673369174\n",
      "-0.00789562244368982\n",
      "-0.00800525806287957\n",
      "-0.008291849478555883\n",
      "-0.008839896654938825\n",
      "-0.008998185432420662\n",
      "-0.009164696168776477\n",
      "-0.009506422349141681\n",
      "-0.009718526413287869\n",
      "-0.009864735377095975\n",
      "-0.010007930517107478\n",
      "-0.010248948482423952\n",
      "-0.010449909931615988\n",
      "-0.010477662065042938\n",
      "-0.010628758383477823\n",
      "-0.010585411906138488\n",
      "-0.010643245300740685\n",
      "-0.01071896054106084\n",
      "-0.010628394574125358\n",
      "-0.010442129316831205\n",
      "-0.010107515849852356\n",
      "-0.00973657952985142\n",
      "-0.009399557030373564\n",
      "-0.009112901141500259\n",
      "-0.00881380939767766\n",
      "-0.008330213861116962\n",
      "-0.008047793378010076\n",
      "-0.00772975250713256\n",
      "-0.007357122214210028\n",
      "-0.007177880049680528\n",
      "-0.0070461676756633194\n",
      "-0.006893667186948356\n",
      "-0.006590848955373296\n",
      "-0.006504595227767421\n",
      "-0.006458457269255704\n",
      "-0.0067522665813481665\n",
      "-0.006917322722595234\n",
      "-0.0071115669919697986\n",
      "-0.007380916250611791\n",
      "-0.007674898621776882\n",
      "-0.007987836157114266\n",
      "-0.008347928653172442\n",
      "-0.008607305459776034\n",
      "-0.008896130587403654\n",
      "-0.009074984253210204\n",
      "-0.009122405590331104\n",
      "-0.009215298006864594\n",
      "-0.009121674304772774\n",
      "-0.009015373200262324\n",
      "-0.008890552534741756\n",
      "-0.00872794150452941\n",
      "-0.008565573841941728\n",
      "-0.008428307474320756\n",
      "-0.008154323766774435\n",
      "-0.008012786917477381\n",
      "-0.008052152991810065\n",
      "-0.007930854275001656\n",
      "-0.0076140265314200975\n",
      "-0.007539794800305345\n",
      "-0.007469686225438277\n",
      "-0.007531632894479852\n",
      "-0.0076959363877536794\n",
      "-0.008017871604234991\n",
      "-0.008375758673875992\n",
      "-0.00872727858819908\n",
      "-0.009060561941060873\n",
      "-0.00955208905464455\n",
      "-0.010243526902554275\n",
      "-0.010773179009419381\n",
      "-0.01118810221920989\n",
      "-0.01152720972475412\n",
      "-0.011715902190691942\n",
      "-0.012088425499828432\n",
      "-0.012568979453623827\n",
      "-0.013113485332487719\n",
      "-0.013325022195657014\n",
      "-0.013586249082271741\n",
      "-0.013886313649630175\n",
      "-0.014015575074537334\n",
      "-0.014224368993299721\n",
      "-0.01442354766883429\n",
      "-0.01449825303515971\n",
      "-0.01446557827118786\n",
      "-0.014232859490246162\n",
      "-0.014148933398574974\n",
      "-0.013893623406780005\n",
      "-0.013432666527984494\n",
      "-0.012972024295316457\n",
      "-0.012434763280982551\n",
      "-0.011854994580695931\n",
      "-0.011225948010285291\n",
      "-0.010706953474884878\n",
      "-0.01037858276171824\n",
      "-0.010010051528362773\n",
      "-0.009585991709882374\n",
      "-0.009248001434601059\n",
      "-0.009012637865288642\n",
      "-0.008743307712463374\n",
      "-0.008210066638449495\n",
      "-0.007937407315354347\n",
      "-0.007574456424561286\n",
      "-0.0072330726792731205\n",
      "-0.007045879272780373\n",
      "-0.006717875058754644\n",
      "-0.0065058043686547894\n",
      "-0.006172488983191632\n",
      "-0.0057206018684375515\n",
      "-0.005338714953586039\n",
      "-0.00492258762226036\n",
      "-0.0045224584615193185\n",
      "-0.004210692547645139\n",
      "-0.004010058152996286\n",
      "-0.003688227583917109\n",
      "-0.0034006918088859734\n",
      "-0.0033074828662159883\n",
      "-0.00319230874584591\n",
      "-0.003137587752336617\n",
      "-0.0029575042737727967\n",
      "-0.002772359610183769\n",
      "-0.0028427968386294878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0027459341202459046\n",
      "-0.002831566333701188\n",
      "-0.0030726727878206727\n",
      "-0.0033347153334969946\n",
      "-0.0035618532439498736\n",
      "-0.003862947150571349\n",
      "-0.004117829127605103\n",
      "-0.004203321523589726\n",
      "-0.004393470944145025\n",
      "-0.0046913814406728494\n",
      "-0.004999602155862271\n",
      "-0.005064577190149302\n",
      "-0.005281020886443968\n",
      "-0.005746443634699209\n",
      "-0.006340725877853112\n",
      "-0.006599846598518645\n",
      "-0.0067799776726549625\n",
      "-0.007126449129056674\n",
      "-0.007543873533358904\n",
      "-0.008038402600023354\n",
      "-0.008472769565287464\n",
      "-0.008966557204922124\n",
      "-0.00942465385026582\n",
      "-0.009832416461963638\n",
      "-0.01028552338571015\n",
      "-0.010637411773492296\n",
      "-0.010727638602299654\n",
      "-0.010744091345606607\n",
      "-0.010740813528568581\n",
      "-0.010661807022957494\n",
      "-0.010583817163384957\n",
      "-0.010366371181899843\n",
      "-0.010173578622176252\n",
      "-0.010190942576553364\n",
      "-0.010268199877722999\n",
      "-0.010380004132877853\n",
      "-0.010458986168440348\n",
      "-0.010567912165666897\n",
      "-0.010694419366845237\n",
      "-0.01076845719400313\n",
      "-0.01092826083429449\n",
      "-0.010989033442291976\n",
      "-0.011067133079823412\n",
      "-0.011026505264907635\n",
      "-0.011118617828732417\n",
      "-0.011338535130945855\n",
      "-0.011504573569081597\n",
      "-0.011508859507102571\n",
      "-0.011545416583133943\n",
      "-0.011619405201124382\n",
      "-0.011614908114702768\n",
      "-0.011532591107457364\n",
      "-0.011607667063454558\n",
      "-0.011980074756491498\n",
      "-0.012379031472260969\n",
      "-0.012690330856968128\n",
      "-0.012799405961938246\n",
      "-0.012774418795998022\n",
      "-0.012734680026759463\n",
      "-0.012872588850587787\n",
      "-0.012773621569611779\n",
      "-0.012855710942869782\n",
      "-0.012806384808656422\n",
      "-0.012823365123063438\n",
      "-0.01271304144666226\n",
      "-0.012453260560329147\n",
      "-0.012105656066279434\n",
      "-0.011627038798404302\n",
      "-0.011343303293925775\n",
      "-0.011090129687860727\n",
      "-0.010922316778591746\n",
      "-0.010726231295896999\n",
      "-0.01049627924056816\n",
      "-0.010429211642072464\n",
      "-0.010428980324606027\n",
      "-0.01066646030925501\n",
      "-0.010755569704072808\n",
      "-0.01067202936954675\n",
      "-0.010598250917846915\n",
      "-0.010496092877938314\n",
      "-0.010493873259446425\n",
      "-0.01054280764229085\n",
      "-0.010579183970115418\n",
      "-0.010568877034419758\n",
      "-0.010461080875916429\n",
      "-0.010230944617984954\n",
      "-0.0100066795641564\n",
      "-0.009685686431132932\n",
      "-0.009493083006957843\n",
      "-0.00934517423219801\n",
      "-0.009165455467901581\n",
      "-0.008908914767319915\n",
      "-0.008743613103201795\n",
      "-0.008633211558676667\n",
      "-0.008720818787061924\n",
      "-0.008783660562281137\n",
      "-0.008841882339769179\n",
      "-0.00894327729795715\n",
      "-0.009131754652614557\n",
      "-0.00952087505868431\n",
      "-0.009899809155079998\n",
      "-0.010189837074570336\n",
      "-0.010351277759364994\n",
      "-0.010370616286207899\n",
      "-0.010421444066941373\n",
      "-0.010282755118179486\n",
      "-0.010120009392013494\n",
      "-0.010052245716731717\n",
      "-0.009842632132614524\n",
      "-0.009539712299369934\n",
      "-0.009404515841151977\n",
      "-0.009419900892929062\n",
      "-0.009556092394963774\n",
      "-0.009725235449135812\n",
      "-0.009962384804463641\n",
      "-0.009906266648995915\n",
      "-0.009668492848895168\n",
      "-0.009347017082843153\n",
      "-0.009327976704854172\n",
      "-0.009296754162243837\n",
      "-0.009092695542572592\n",
      "-0.008919662814555916\n",
      "-0.008793785131447738\n",
      "-0.008508789062105023\n",
      "-0.008337582286555852\n",
      "-0.008268052623728902\n",
      "-0.00831786529928026\n",
      "-0.008570320774192062\n",
      "-0.008848930521112004\n",
      "-0.009048694496440877\n",
      "-0.008985872872224633\n",
      "-0.00871479571138045\n",
      "-0.00847127161288288\n",
      "-0.008263631827354212\n",
      "-0.008103350316089808\n",
      "-0.0080002916318115\n",
      "-0.00794259636563704\n",
      "-0.007934971010804882\n",
      "-0.008105684715725026\n",
      "-0.008091536552374911\n",
      "-0.008026077869039009\n",
      "-0.008065619391239363\n",
      "-0.008005959840752355\n",
      "-0.007935123104767444\n",
      "-0.007704471260436673\n",
      "-0.007739149381263997\n",
      "-0.007899740883736177\n",
      "-0.007920273770429958\n",
      "-0.007990975525420878\n",
      "-0.008211774706808886\n",
      "-0.008367690708601236\n",
      "-0.008556927624397666\n",
      "-0.008535196894531402\n",
      "-0.008469744416332928\n",
      "-0.008597730234252648\n",
      "-0.008645116784250223\n",
      "-0.008906671880301828\n",
      "-0.009155389517540122\n",
      "-0.009550447936213406\n",
      "-0.009990138670093858\n",
      "-0.010472975158079231\n",
      "-0.010879316786750933\n",
      "-0.011244654851082586\n",
      "-0.011700040480014546\n",
      "-0.012026423345666264\n",
      "-0.012279002137172836\n",
      "-0.01263707286771734\n",
      "-0.01296480947708276\n",
      "-0.013149502117013129\n",
      "-0.013180486260615118\n",
      "-0.013058509725104044\n",
      "-0.013005727125143241\n",
      "-0.012815348143385936\n",
      "-0.01249994380738142\n",
      "-0.012162759202265316\n",
      "-0.011918688913073535\n",
      "-0.011878378926519126\n",
      "-0.011628541685528576\n",
      "-0.011490690611939736\n",
      "-0.01148092432905418\n",
      "-0.011508212652712157\n",
      "-0.011276119479997654\n",
      "-0.010871124246048034\n",
      "-0.010526900349834516\n",
      "-0.010137094574947188\n",
      "-0.009977797708757292\n",
      "-0.009767689205858488\n",
      "-0.00970443050833266\n",
      "-0.009561853597371288\n",
      "-0.00923277127360896\n",
      "-0.009090372222849207\n",
      "-0.00900974058893692\n",
      "-0.009015339145926872\n",
      "-0.008884763137861029\n",
      "-0.008709343745276224\n",
      "-0.008498461664440168\n",
      "-0.008279278235964515\n",
      "-0.008154938435760492\n",
      "-0.008007778176592031\n",
      "-0.007956746509598938\n",
      "-0.00796700597840598\n",
      "-0.008067530937115635\n",
      "-0.008339729333084878\n",
      "-0.008664353216621583\n",
      "-0.00906426723477193\n",
      "-0.009569775641412029\n",
      "-0.009970193945236367\n",
      "-0.010290570344334877\n",
      "-0.010666420426648312\n",
      "-0.011113692450271603\n",
      "-0.01146331313131507\n",
      "-0.011781791206623683\n",
      "-0.011854105418446286\n",
      "-0.011778686983885355\n",
      "-0.011560458819773564\n",
      "-0.011302328685007702\n",
      "-0.010993376655456143\n",
      "-0.010718319117069984\n",
      "-0.010627661867581524\n",
      "-0.010378984557897956\n",
      "-0.010272128037423939\n",
      "-0.010205715467883798\n",
      "-0.010159854968475468\n",
      "-0.010150871674328099\n",
      "-0.010167050491514206\n",
      "-0.01010334923192808\n",
      "-0.010066985350441997\n",
      "-0.009952020173370529\n",
      "-0.009608625644426553\n",
      "-0.009325756834609523\n",
      "-0.009131556813064734\n",
      "-0.008768572965188235\n",
      "-0.008382752881755707\n",
      "-0.008041055105222595\n",
      "-0.007743791829132195\n",
      "-0.0075832540279205315\n",
      "-0.007570611516166439\n",
      "-0.0076206249772575825\n",
      "-0.007606811146255669\n",
      "-0.0074599745141695935\n",
      "-0.007466133983789446\n",
      "-0.007464876903835933\n",
      "-0.007544518141882201\n",
      "-0.007530870353546063\n",
      "-0.007412599562259651\n",
      "-0.007337354042681596\n",
      "-0.007325273094319301\n",
      "-0.007252925448227304\n",
      "-0.007082312259206506\n",
      "-0.006855635310562746\n",
      "-0.006782730385401529\n",
      "-0.006681361454229795\n",
      "-0.006703097065096385\n",
      "-0.006833939224422153\n",
      "-0.006935251269388882\n",
      "-0.007111088675381699\n",
      "-0.007291046139187302\n",
      "-0.007454865163475768\n",
      "-0.007572172074259599\n",
      "-0.007841594145126878\n",
      "-0.007936225675806808\n",
      "-0.00806708730900288\n",
      "-0.008291275596741546\n",
      "-0.008559876175704605\n",
      "-0.00870427996998875\n",
      "-0.008844211651858962\n",
      "-0.009028622452067293\n",
      "-0.009216458372375306\n",
      "-0.009339034659801172\n",
      "-0.00937822017851189\n",
      "-0.009450242685623328\n",
      "-0.009577421134449345\n",
      "-0.009803711256827607\n",
      "-0.009877935150196214\n",
      "-0.009877102327912278\n",
      "-0.009906018554636617\n",
      "-0.010159098940213043\n",
      "-0.01041172720988683\n",
      "-0.010582808965233361\n",
      "-0.010657158528058255\n",
      "-0.010740022635470239\n",
      "-0.010797938536198624\n",
      "-0.010815247130391498\n",
      "-0.010780575640130276\n",
      "-0.010598745173229951\n",
      "-0.010449555120379315\n",
      "-0.010267348495498324\n",
      "-0.01004633268843764\n",
      "-0.00970987184496902\n",
      "-0.009585062946645942\n",
      "-0.009470569152363873\n",
      "-0.009302825197096815\n",
      "-0.009124769601911066\n",
      "-0.009050687333736783\n",
      "-0.008982907475450587\n",
      "-0.008926840180409302\n",
      "-0.008869774941745685\n",
      "-0.008697646992217834\n",
      "-0.0085205205979006\n",
      "-0.008313634441774014\n",
      "-0.008292697686683177\n",
      "-0.00831951456935356\n",
      "-0.008347353863105299\n",
      "-0.008200965610184522\n",
      "-0.008066525839647606\n",
      "-0.007872335434055184\n",
      "-0.007662001034976196\n",
      "-0.007458869510055778\n",
      "-0.007367419943557149\n",
      "-0.007395678870546367\n",
      "-0.007554902291029323\n",
      "-0.007668488104073004\n",
      "-0.007811975097302121\n",
      "-0.007793018004838189\n",
      "-0.007650858790217327\n",
      "-0.0075531475156865886\n",
      "-0.007625785031285947\n",
      "-0.007824175625280157\n",
      "-0.00783834375797825\n",
      "-0.0077727607630929335\n",
      "-0.007666025119172907\n",
      "-0.007431720765375988\n",
      "-0.00717975016974866\n",
      "-0.006938570626055993\n",
      "-0.006787813125972451\n",
      "-0.006674211016278641\n",
      "-0.006807105947193754\n",
      "-0.007032242366028267\n",
      "-0.007395174925540504\n",
      "-0.0075888087507126195\n",
      "-0.007835688863514307\n",
      "-0.00822332631036799\n",
      "-0.008401948506449633\n",
      "-0.008507622391228755\n",
      "-0.008752625216909504\n",
      "-0.009026673106910774\n",
      "-0.009255330056170645\n",
      "-0.009295313128640863\n",
      "-0.009238404224290645\n",
      "-0.009170850595695385\n",
      "-0.009342808061313917\n",
      "-0.009722490532391548\n",
      "-0.0101240415139729\n",
      "-0.010493219787998722\n",
      "-0.010766134262619692\n",
      "-0.010893854904625699\n",
      "-0.010928358202879856\n",
      "-0.010841267226413102\n",
      "-0.010545814998349765\n",
      "-0.010246412786813002\n",
      "-0.009955377229145367\n",
      "-0.009606315881524972\n",
      "-0.00937377617207723\n",
      "-0.009303709327686156\n",
      "-0.00922192782275211\n",
      "-0.009127831390488537\n",
      "-0.009060961387206695\n",
      "-0.009054679121166812\n",
      "-0.009181903433818042\n",
      "-0.009277492651820372\n",
      "-0.009106128166465775\n",
      "-0.00890139203723449\n",
      "-0.008626647643626752\n",
      "-0.00838506705006887\n",
      "-0.00803390750910485\n",
      "-0.007671864340659829\n",
      "-0.007388129222953154\n",
      "-0.006977432884414803\n",
      "-0.006600429472822585\n",
      "-0.006227780457736689\n",
      "-0.00590647266314721\n",
      "-0.005697541723290419\n",
      "-0.005616157279537495\n",
      "-0.005576137103111596\n",
      "-0.005443897351454813\n",
      "-0.00520230779458217\n",
      "-0.005206823556527983\n",
      "-0.0051833524433328275\n",
      "-0.0050231606280803885\n",
      "-0.0050063352736697915\n",
      "-0.00501706714556836\n",
      "-0.0049963178957761955\n",
      "-0.004926138084577109\n",
      "-0.004908247998260049\n",
      "-0.004832943379036844\n",
      "-0.004661570751021399\n",
      "-0.004662553296168008\n",
      "-0.004677982881634799\n",
      "-0.004812454788260705\n",
      "-0.004895605589843757\n",
      "-0.0049035587805596895\n",
      "-0.0049512293429936245\n",
      "-0.004786604058065571\n",
      "-0.004521993872469059\n",
      "-0.004214247990809996\n",
      "-0.0039908007112675475\n",
      "-0.003975530580985343\n",
      "-0.00409776774754799\n",
      "-0.004202784315987645\n",
      "-0.0041972104833871236\n",
      "-0.00416750096485415\n",
      "-0.004047217277597907\n",
      "-0.004017898809583415\n",
      "-0.0039046868050785903\n",
      "-0.0038038659984449183\n",
      "-0.003745843480180971\n",
      "-0.0038347150510116\n",
      "-0.004075820980057923\n",
      "-0.004209526459143056\n",
      "-0.004256014072519658\n",
      "-0.004278802183645888\n",
      "-0.0042868149374845205\n",
      "-0.004307932958227392\n",
      "-0.004404955000732022\n",
      "-0.004308263505542982\n",
      "-0.004145885056627049\n",
      "-0.004126739824636872\n",
      "-0.004098146039641464\n",
      "-0.004245611504330341\n",
      "-0.004567251948554105\n",
      "-0.004880516025793546\n",
      "-0.005174840200674764\n",
      "-0.005344472569941811\n",
      "-0.005588215847053458\n",
      "-0.005765362392694639\n",
      "-0.00598726266266774\n",
      "-0.006040928812763777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.006071159498022847\n",
      "-0.006029431235915673\n",
      "-0.006013320950872387\n",
      "-0.006007934942296193\n",
      "-0.006018741334866173\n",
      "-0.0061230286899941104\n",
      "-0.006069166401273552\n",
      "-0.005925830618220815\n",
      "-0.005897642569637614\n",
      "-0.0058929213726417705\n",
      "-0.005822661947604742\n",
      "-0.005662803275721085\n",
      "-0.005649584853472502\n",
      "-0.005681545155040695\n",
      "-0.005554416007968822\n",
      "-0.005389937501600817\n",
      "-0.005229715647339557\n",
      "-0.005041273560141946\n",
      "-0.0046579669525618345\n",
      "-0.004257488861128527\n",
      "-0.0038290333390734017\n",
      "-0.003472844656454246\n",
      "-0.003122419046219805\n",
      "-0.0030146724705437345\n",
      "-0.0028756175010441667\n",
      "-0.0027667682375109542\n",
      "-0.0025680506974984593\n",
      "-0.0023465440403327813\n",
      "-0.002051068971369605\n",
      "-0.0017224294348556761\n",
      "-0.0013681593001477503\n",
      "-0.0009560081496658693\n",
      "-0.0006809147487852115\n",
      "-0.00041528019682665667\n",
      "-0.00034999194842388735\n",
      "-0.00027362762790812835\n",
      "-0.00020630618049454283\n",
      "-0.00011515937668135227\n",
      "-6.461376860426395e-05\n",
      "-3.196219698270592e-05\n",
      "-7.272600633563934e-05\n",
      "-0.00021535626963840616\n",
      "-0.00039613291868176585\n",
      "-0.0005005659559837079\n",
      "-0.00046992201079399103\n",
      "-0.0005234432778923238\n",
      "-0.0005580588411358025\n",
      "-0.0006926449283273156\n",
      "-0.0008933727450343189\n",
      "-0.0011122800074313695\n",
      "-0.0012141405583927243\n",
      "-0.0012974441401301935\n",
      "-0.0014342779248598403\n",
      "-0.0017410944923109874\n",
      "-0.00208828619872701\n",
      "-0.0023291930587116733\n",
      "-0.0024285075234213383\n",
      "-0.0027504928858008613\n",
      "-0.003049005033785808\n",
      "-0.0032446815520115694\n",
      "-0.003409194006222284\n",
      "-0.0037312536109088694\n",
      "-0.0040130683743139816\n",
      "-0.004268388947603385\n",
      "-0.004373617678370585\n",
      "-0.004470664698559278\n",
      "-0.004378065270325954\n",
      "-0.004312289862843406\n",
      "-0.004321677780445926\n",
      "-0.004343868653277557\n",
      "-0.004471504101330514\n",
      "-0.004726762760031897\n",
      "-0.004810230387440838\n",
      "-0.004757905052826961\n",
      "-0.004550614600793301\n",
      "-0.004470040301886247\n",
      "-0.004432322414789281\n",
      "-0.004376267698157705\n",
      "-0.0042897744785687355\n",
      "-0.004177524544987844\n",
      "-0.004221926475794184\n",
      "-0.004307405475521367\n",
      "-0.004319530568467093\n",
      "-0.00428880393735686\n",
      "-0.004352070848292984\n",
      "-0.00440479502969936\n",
      "-0.004464073127457077\n",
      "-0.004456728211580451\n",
      "-0.004399202662710084\n",
      "-0.004420508140543726\n",
      "-0.0045713672007942335\n",
      "-0.004776124618282248\n",
      "-0.004899441847442612\n",
      "-0.004941354478780785\n",
      "-0.004688793697224116\n",
      "-0.0044209344153877195\n",
      "-0.0041362765754312135\n",
      "-0.003767191973044316\n",
      "-0.0034009055026899613\n",
      "-0.0030049752601130565\n",
      "-0.002577588857456971\n",
      "-0.0020949168556012665\n",
      "-0.0016457930677607488\n",
      "-0.001190068457835368\n",
      "-0.0007992177708625657\n",
      "-0.0003374293794119425\n",
      "6.359702805234144e-05\n",
      "0.0003960535593191105\n",
      "0.0007393148587911553\n",
      "0.0010847589606340486\n",
      "0.0014720370715587642\n",
      "0.0017787486806314905\n",
      "0.002081113158834312\n",
      "0.0023792760967053647\n",
      "0.0025278065389316064\n",
      "0.0027179348044263432\n",
      "0.0028228414142408747\n",
      "0.0028862891659806864\n",
      "0.002904080669843831\n",
      "0.0027456823101825547\n",
      "0.0025265512619216854\n",
      "0.00228021370586967\n",
      "0.002074990578974428\n",
      "0.0018525739366770635\n",
      "0.001632067003717202\n",
      "0.0014945864063688275\n",
      "0.0013723496683182507\n",
      "0.0012090565742442203\n",
      "0.0010221025679706826\n",
      "0.0008822509882302665\n",
      "0.0007246980220702186\n",
      "0.0005378249623016571\n",
      "0.00045653467536450394\n",
      "0.00032580316133714606\n",
      "0.00027051997487727124\n",
      "0.0002357130100838415\n",
      "0.00026131244012158174\n",
      "0.00026521095996733955\n",
      "0.00015648776084468757\n",
      "0.00016555433675271097\n",
      "6.281570100719221e-05\n",
      "5.2609744830307034e-05\n",
      "0.00012471896310495696\n",
      "9.224784441965917e-05\n",
      "4.5342598612329885e-05\n",
      "-9.715291945051746e-06\n",
      "1.464416861947168e-05\n",
      "9.50323290825703e-05\n",
      "0.00020912501890525415\n",
      "0.00018214089384256237\n",
      "0.00011267415776668589\n",
      "4.9997195545735104e-05\n",
      "-9.050073331255451e-05\n",
      "-0.00023796705923846188\n",
      "-0.0003429735506616723\n",
      "-0.0004636824332112542\n",
      "-0.000723998476026406\n",
      "-0.0010482325972366023\n",
      "-0.0013860754733133205\n",
      "-0.0016911588214083304\n",
      "-0.002032789015833686\n",
      "-0.002328273426291966\n",
      "-0.002622334136141664\n",
      "-0.002919883997698573\n",
      "-0.0032232197038719124\n",
      "-0.003414249036219579\n",
      "-0.0036000474216542973\n",
      "-0.0038244188600126128\n",
      "-0.004122309535460363\n",
      "-0.004323922105599049\n",
      "-0.004412795486184289\n",
      "-0.004461412646946803\n",
      "-0.004454840013816806\n",
      "-0.004355287418407657\n",
      "-0.004240345030108198\n",
      "-0.0041598846287959675\n",
      "-0.0041179294141525016\n",
      "-0.004173620327615949\n",
      "-0.0041156077441302005\n",
      "-0.0040523588800418465\n",
      "-0.00406612005611821\n",
      "-0.004020464175431642\n",
      "-0.00387959868414779\n",
      "-0.003720211898430554\n",
      "-0.0035068885013586635\n",
      "-0.003312260844502267\n",
      "-0.0030624635321360536\n",
      "-0.00281329387709451\n",
      "-0.002633853173051261\n",
      "-0.0024979552123642976\n",
      "-0.0024148524902594427\n",
      "-0.0023700198732957093\n",
      "-0.0024164750501401693\n",
      "-0.0024784670943270755\n",
      "-0.0024454028605406094\n",
      "-0.002418758016150079\n",
      "-0.0025073275922260045\n",
      "-0.002620675114454991\n",
      "-0.0026281952655239924\n",
      "-0.0024948048047191106\n",
      "-0.002316911052625581\n",
      "-0.0021560574646271196\n",
      "-0.0019920835423722616\n",
      "-0.0018602721962656887\n",
      "-0.0016767584616725882\n",
      "-0.0013969821844499507\n",
      "-0.0011146729272935982\n",
      "-0.0009131746932640754\n",
      "-0.0006861106123206239\n",
      "-0.0005470873054258546\n",
      "-0.0004169498385378894\n",
      "-0.00012326106147543485\n",
      "0.0002338341512311666\n",
      "0.00045096916853163533\n",
      "0.0005808133007668937\n",
      "0.0006851967479879903\n",
      "0.0007665134055929516\n",
      "0.0008016416574161797\n",
      "0.0008186486696068877\n",
      "0.0008227024231846354\n",
      "0.0007690459713937935\n",
      "0.0006834750666082882\n",
      "0.0005900732340731674\n",
      "0.0005269108298733118\n",
      "0.00046345893970421335\n",
      "0.00034599484924726016\n",
      "0.00022790660145403146\n",
      "0.00014028529815728264\n",
      "5.523660415785198e-05\n",
      "4.957350581956759e-06\n",
      "6.128371335571018e-05\n",
      "0.00019403500444183845\n",
      "0.0003058712007338471\n",
      "0.0003111431089865077\n",
      "0.000246494051329709\n",
      "0.00011962923334795214\n",
      "-2.104646049129725e-05\n",
      "-0.00016449166593166182\n",
      "-0.00030937262419580787\n",
      "-0.0004564652461052472\n",
      "-0.000616590021661213\n",
      "-0.000783286923051141\n",
      "-0.000981317280330852\n",
      "-0.0012078775141770993\n",
      "-0.001415646175387601\n",
      "-0.001621606154565133\n",
      "-0.0017892029156186292\n",
      "-0.00185899926229219\n",
      "-0.00195112758506649\n",
      "-0.001973573472656808\n",
      "-0.0018666248679840723\n",
      "-0.0017535592444119156\n",
      "-0.0016683998708816408\n",
      "-0.001591633048399445\n",
      "-0.0015383355076461869\n",
      "-0.0014980522251353265\n",
      "-0.0014029891026437614\n",
      "-0.0012865042939239008\n",
      "-0.0011858990692842466\n",
      "-0.0010830592229259099\n",
      "-0.0009492728419156772\n",
      "-0.0008356169731411075\n",
      "-0.0006784311499742563\n",
      "-0.0005121482965219475\n",
      "-0.00040009931987866864\n",
      "-0.00028195299777013775\n",
      "-0.00017283613440836624\n",
      "-3.1257234693834085e-05\n",
      "0.00026629143644625467\n",
      "0.0006417045386210796\n",
      "0.0009815416987149382\n",
      "0.0012883350743168476\n",
      "0.0015559661632039386\n",
      "0.001823592452116733\n",
      "0.0021432263983697532\n",
      "0.0024642354258352325\n",
      "0.0027335990869554704\n",
      "0.0029557270070556083\n",
      "0.0030669008080682165\n",
      "0.0032129313533831917\n",
      "0.003516430353395804\n",
      "0.0038407161164258023\n",
      "0.00415277619708973\n",
      "0.004398375019961647\n",
      "0.004526123008433394\n",
      "0.0045314487509664535\n",
      "0.0044500776561436015\n",
      "0.004319100450008375\n",
      "0.0041371148954096205\n",
      "0.003957532056908466\n",
      "0.003760564347951377\n",
      "0.003619502529706418\n",
      "0.0035701360200835297\n",
      "0.003581499388307469\n",
      "0.0036214754579436768\n",
      "0.00372034527856151\n",
      "0.003913716298952119\n",
      "0.0041182361209483685\n",
      "0.00429087152653457\n",
      "0.004402405800186299\n",
      "0.0045895382147554484\n",
      "0.004885278955566099\n",
      "0.005193780342600443\n",
      "0.005521154407019582\n",
      "0.005882621795652751\n",
      "0.0062091579522368994\n",
      "0.006503327300121921\n",
      "0.006810861132435386\n",
      "0.0071001082206381145\n",
      "0.007351081084090531\n",
      "0.007552172083416504\n",
      "0.007716363399344168\n",
      "0.007877850039991714\n",
      "0.007975538708460366\n",
      "0.008029058893518915\n",
      "0.008043723983462921\n",
      "0.008047415592488769\n",
      "0.007997684950925496\n",
      "0.007878439673957592\n",
      "0.0077846717833829635\n",
      "0.007674772068407921\n",
      "0.00750839893227013\n",
      "0.007292497619173704\n",
      "0.0071225412544293895\n",
      "0.007113834681056413\n",
      "0.007061575606894219\n",
      "0.00698046251878007\n",
      "0.0069075557391029855\n",
      "0.00682760401422582\n",
      "0.006829234622140621\n",
      "0.006909305919710495\n",
      "0.007029307557069139\n",
      "0.0071207726000261234\n",
      "0.007212734996794538\n",
      "0.007260532106403138\n",
      "0.007297069953392941\n",
      "0.007349519457578717\n",
      "0.007430202266404654\n",
      "0.0075345563400796385\n",
      "0.007670994467062915\n",
      "0.007801702867370615\n",
      "0.007854804096839944\n",
      "0.007897452074673642\n",
      "0.008027135746437588\n",
      "0.008307807563683904\n",
      "0.008633073542007656\n",
      "0.008935015820175446\n",
      "0.00923057499388222\n",
      "0.00955672769731503\n",
      "0.00989157734367325\n",
      "0.010088290200981795\n",
      "0.01023226553170616\n",
      "0.010348529977524912\n",
      "0.010413335195786055\n",
      "0.010461599860859504\n",
      "0.010542412509526975\n",
      "0.01063291878603193\n",
      "0.010679595976104286\n",
      "0.010629097515165423\n",
      "0.010539480924056861\n",
      "0.010460928311370011\n",
      "0.010294517638256598\n",
      "0.010206616670047726\n",
      "0.01018959651255584\n",
      "0.010128013591420716\n",
      "0.010028480961585007\n",
      "0.00991640164490958\n",
      "0.009805597860659659\n",
      "0.009713764901329094\n",
      "0.009643442587598257\n",
      "0.00953265328527199\n",
      "0.00932325571851984\n",
      "0.009101570481533823\n",
      "0.00895492589696766\n",
      "0.008855831318831683\n",
      "0.008807196226522207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008774382428318942\n",
      "0.008730163234468047\n",
      "0.00869081263502944\n",
      "0.008653528770669534\n",
      "0.00860328472290261\n",
      "0.008564174148826383\n",
      "0.008533672158569134\n",
      "0.008470285115433535\n",
      "0.008354018982081048\n",
      "0.008288464701719343\n",
      "0.008322936841696089\n",
      "0.008358791250121721\n",
      "0.008426811311089487\n",
      "0.008530290209852595\n",
      "0.008658126501308804\n",
      "0.008778775313878563\n",
      "0.009090930175682951\n",
      "0.009477183570159982\n",
      "0.009853205512572325\n",
      "0.01034610885660724\n",
      "0.010809050176682733\n",
      "0.01121389831710504\n",
      "0.0115909581051251\n",
      "0.011920861086656546\n",
      "0.012211191662707583\n",
      "0.012404452005639863\n",
      "0.01261060936286375\n",
      "0.01282668325349649\n",
      "0.013035026871587552\n",
      "0.013242941693545562\n",
      "0.013380996364607033\n",
      "0.013534276559439565\n",
      "0.013693475598680995\n",
      "0.01364900959797131\n",
      "0.01367738929530684\n",
      "0.01375927232830398\n",
      "0.013872959042403644\n",
      "0.013890986820190111\n",
      "0.013898499874338525\n",
      "0.01384804983993996\n",
      "0.013810959042952884\n",
      "0.013789448543985242\n",
      "0.013706255460383737\n",
      "0.013619450862921904\n",
      "0.013554554679359093\n",
      "0.01353345799301319\n",
      "0.01360668664331119\n",
      "0.013605525925001473\n",
      "0.013546560762466882\n",
      "0.013470271618077363\n",
      "0.013499904856307251\n",
      "0.013630215982699175\n",
      "0.013781713229268019\n",
      "0.013925257358916905\n",
      "0.01417974216902172\n",
      "0.014421518908504382\n",
      "0.014578476136957874\n",
      "0.014745214803382783\n",
      "0.014932455177317895\n",
      "0.015065069879771199\n",
      "0.015139639712471235\n",
      "0.015236734613016117\n",
      "0.015429563072951197\n",
      "0.015736766641156405\n",
      "0.01606886438624335\n",
      "0.016304750431535807\n",
      "0.016542450437287606\n",
      "0.01686695756237714\n",
      "0.01715708914567579\n",
      "0.01743458843825648\n",
      "0.01759661634534614\n",
      "0.017698047896495983\n",
      "0.017874977453576062\n",
      "0.018019566236242717\n",
      "0.018161243521106384\n",
      "0.018205264651936927\n",
      "0.01825524323844611\n",
      "0.01825980411046948\n",
      "0.018371166768951185\n",
      "0.01840987046762759\n",
      "0.018380646577414728\n",
      "0.018319983266381037\n",
      "0.01832577124242192\n",
      "0.018486411567968843\n",
      "0.018593717093072226\n",
      "0.018647651931777094\n",
      "0.018750075492764872\n",
      "0.018765306401534686\n",
      "0.018911112439185113\n",
      "0.01897071022254389\n",
      "0.019021294785507858\n",
      "0.019187444153232487\n",
      "0.019347505027509652\n",
      "0.019539752342350912\n",
      "0.019774363573230806\n",
      "0.019942335981344858\n",
      "0.02013315409372245\n",
      "0.020252633562926243\n",
      "0.020394113043446935\n",
      "0.020492737275619625\n",
      "0.02060227384754631\n",
      "0.020725706940752243\n",
      "0.020739729037123608\n",
      "0.0208153012360724\n",
      "0.020833682180449346\n",
      "0.020914285271072055\n",
      "0.02110157508404375\n",
      "0.021319559246402903\n",
      "0.021505676475620815\n",
      "0.02165286024501078\n",
      "0.021585694167590853\n",
      "0.02141771742103142\n",
      "0.021261643013356313\n",
      "0.021351131021958715\n",
      "0.02135776357716592\n",
      "0.021349992096749756\n",
      "0.021154110024799187\n",
      "0.02069771675476425\n",
      "0.020292343373239735\n",
      "0.019882477422839585\n",
      "0.019556568750052575\n",
      "0.019399752074850844\n",
      "0.019277558881523386\n",
      "0.019108200079117347\n",
      "0.01892202195475022\n",
      "0.018690168134769602\n",
      "0.018557155426596573\n",
      "0.018515686315560727\n",
      "0.01860622690446799\n",
      "0.018477023249696807\n",
      "0.018415289429056722\n",
      "0.018485316340120826\n",
      "0.01849376327034188\n",
      "0.018594667162275768\n",
      "0.01877916019688202\n",
      "0.01890185810227778\n",
      "0.018868608019415426\n",
      "0.0189138319854136\n",
      "0.018986517989226494\n",
      "0.018802780280624015\n",
      "0.01864072356663453\n",
      "0.0185944940778814\n",
      "0.018563201785091632\n",
      "0.018624478302077738\n",
      "0.01858032481786823\n",
      "0.01861599800954346\n",
      "0.018642749971581794\n",
      "0.018753380085236814\n",
      "0.0188101532603535\n",
      "0.0189522924601786\n",
      "0.019037822038131733\n",
      "0.019002858865748654\n",
      "0.018898425415128588\n",
      "0.018706417963353913\n",
      "0.018554631944447387\n",
      "0.01854873611072372\n",
      "0.01847506961171902\n",
      "0.018572836591239015\n",
      "0.018791961004461007\n",
      "0.01903264874508653\n",
      "0.01923989117953889\n",
      "0.019450231130796726\n",
      "0.01961531437308431\n",
      "0.01970939415929087\n",
      "0.019866962032224548\n",
      "0.02022079006612796\n",
      "0.020566077892701262\n",
      "0.020736725685693874\n",
      "0.02092481902031723\n",
      "0.021188909526658018\n",
      "0.021349118687866202\n",
      "0.021520725246914722\n",
      "0.02169907973462963\n",
      "0.02175098194317539\n",
      "0.02190991442489531\n",
      "0.022103494766503973\n",
      "0.022333101428925087\n",
      "0.02249361664023446\n",
      "0.02261482133095026\n",
      "0.022740880238483488\n",
      "0.022863884774357357\n",
      "0.023046948512042295\n",
      "0.023253187943388685\n",
      "0.023438815354583777\n",
      "0.023690030681204913\n",
      "0.02391311431209756\n",
      "0.02395189631299432\n",
      "0.023976097545574945\n",
      "0.024111618610917793\n",
      "0.024184388993484237\n",
      "0.024086643604850615\n",
      "0.02394936521282299\n",
      "0.023770306678964917\n",
      "0.023725853314876744\n",
      "0.023633621936034552\n",
      "0.023566242322742143\n",
      "0.02342364528166391\n",
      "0.02335489434429365\n",
      "0.02331114649403076\n",
      "0.023169149568487885\n",
      "0.022956351383451593\n",
      "0.022781452494710603\n",
      "0.022598765609643155\n",
      "0.02243684408519853\n",
      "0.02227525410469151\n",
      "0.02200026973634965\n",
      "0.021820769211172746\n",
      "0.021654790938219287\n",
      "0.021502639109339985\n",
      "0.021258607409867673\n",
      "0.02101169791575177\n",
      "0.020810023915800585\n",
      "0.020580249201619254\n",
      "0.020422061001016213\n",
      "0.020231143086548827\n",
      "0.020091857248290854\n",
      "0.02002613496738677\n",
      "0.019995232406113204\n",
      "0.020024603841750976\n",
      "0.019995535661242018\n",
      "0.019946393855393613\n",
      "0.020071991345508404\n",
      "0.020224825667518393\n",
      "0.020355274748258868\n",
      "0.020582024009316142\n",
      "0.020669871463664072\n",
      "0.020775415131575502\n",
      "0.020843619589830477\n",
      "0.020956465999835652\n",
      "0.02086481162993667\n",
      "0.020812426043249958\n",
      "0.02078047049877546\n",
      "0.02059069440429421\n",
      "0.020433790541152658\n",
      "0.020251844199142485\n",
      "0.02022419364175364\n",
      "0.02024666259478946\n",
      "0.020180954131527738\n",
      "0.02005934838264161\n",
      "0.019870400150054368\n",
      "0.019814345223748964\n",
      "0.01962769593324368\n",
      "0.01948709886625226\n",
      "0.019353913167549107\n",
      "0.019135628479264758\n",
      "0.018964667200808725\n",
      "0.018905755918366556\n",
      "0.018929336266955754\n",
      "0.018900424513914767\n",
      "0.018743141365753748\n",
      "0.018618861384154\n",
      "0.018463695657188948\n",
      "0.01814965480769958\n",
      "0.017751922338803138\n",
      "0.017429148668041114\n",
      "0.017219994950790816\n",
      "0.017034658154043477\n",
      "0.017003444250292776\n",
      "0.016931052791763535\n",
      "0.01687465433258039\n",
      "0.01680053667932086\n",
      "0.01684140952476607\n",
      "0.01696396837867763\n",
      "0.01720088676449277\n",
      "0.017367778999732648\n",
      "0.01758406763707539\n",
      "0.017957881499453817\n",
      "0.018338263093070014\n",
      "0.01871184252454339\n",
      "0.018955779912746027\n",
      "0.019330321283031967\n",
      "0.019497339905924154\n",
      "0.019828287093011036\n",
      "0.019974574523373534\n",
      "0.020076731730633176\n",
      "0.020160303438706815\n",
      "0.020311319722487623\n",
      "0.02032827624619848\n",
      "0.02020258036702323\n",
      "0.02006622500072813\n",
      "0.020041629156228858\n",
      "0.02005113924229852\n",
      "0.019918718819651345\n",
      "0.019719349365233105\n",
      "0.019706455734138123\n",
      "0.019644741183308848\n",
      "0.019620477266633993\n",
      "0.01959022532160235\n",
      "0.019474504871289402\n",
      "0.01931656340484131\n",
      "0.019167351374641445\n",
      "0.01902854597908112\n",
      "0.01881466662764413\n",
      "0.018681699185840683\n",
      "0.01861198974918824\n",
      "0.018593936155311883\n",
      "0.01862172187414673\n",
      "0.01863316196095359\n",
      "0.018572015891444835\n",
      "0.01862552152888782\n",
      "0.0187523517249093\n",
      "0.018977158906705725\n",
      "0.019112403910515472\n",
      "0.01926580203885782\n",
      "0.01924714814235533\n",
      "0.019313474412993366\n",
      "0.019422851414571857\n",
      "0.019415857788739114\n",
      "0.019387666874506333\n",
      "0.019333129104779526\n",
      "0.019223807920781197\n",
      "0.01902621460763871\n",
      "0.018804555917703154\n",
      "0.018474418597887572\n",
      "0.018248150279598998\n",
      "0.0181787481831766\n",
      "0.018146638206823634\n",
      "0.018098803001977925\n",
      "0.01800993387809573\n",
      "0.01790178969064559\n",
      "0.01787757900802265\n",
      "0.017901925519605896\n",
      "0.01800813142896874\n",
      "0.018175587229422183\n",
      "0.01825363318441234\n",
      "0.018369895164631587\n",
      "0.01850716364426148\n",
      "0.01862943933810181\n",
      "0.018663553804459755\n",
      "0.01865680688993111\n",
      "0.018522252673097154\n",
      "0.01843695005164762\n",
      "0.018301603135551087\n",
      "0.018242214609534787\n",
      "0.01827283278712277\n",
      "0.018416938042867582\n",
      "0.018642103790612506\n",
      "0.01874387603330526\n",
      "0.018834348205911854\n",
      "0.018923158393355483\n",
      "0.01906975864520971\n",
      "0.019215660788365164\n",
      "0.019275580155853077\n",
      "0.019265832581487993\n",
      "0.019208183999986417\n",
      "0.019125625034738938\n",
      "0.01907877807069252\n",
      "0.019113940019878026\n",
      "0.019014524629347915\n",
      "0.018910682292149403\n",
      "0.018781901760535073\n",
      "0.01864161444600476\n",
      "0.018408530658756205\n",
      "0.018259881927917842\n",
      "0.01809535060677869\n",
      "0.01797102600407495\n",
      "0.017889187008167523\n",
      "0.017787562061475772\n",
      "0.017805258201666053\n",
      "0.017853168600686174\n",
      "0.017842136347081504\n",
      "0.017840766354470666\n",
      "0.017881074874317664\n",
      "0.017903351970724762\n",
      "0.017856432255673883\n",
      "0.017798005378388496\n",
      "0.01772431773724361\n",
      "0.017710695988517475\n",
      "0.01771879676925608\n",
      "0.017747320018062635\n",
      "0.017803814362270867\n",
      "0.01788709700255569\n",
      "0.01800885506154145\n",
      "0.018165772549385218\n",
      "0.018308158739256182\n",
      "0.01841020829443479\n",
      "0.01842963381333999\n",
      "0.018408649909250646\n",
      "0.01836964571412927\n",
      "0.018387055475861044\n",
      "0.018480034254671093\n",
      "0.018601148342736493\n",
      "0.018797344779731176\n",
      "0.01905612950799578\n",
      "0.019357905866526547\n",
      "0.019672518456889623\n",
      "0.019951453282774305\n",
      "0.020211795385308314\n",
      "0.02047384400072206\n",
      "0.02084086380987304\n",
      "0.021296931081727907\n",
      "0.021839139230227646\n",
      "0.022429833232385288\n",
      "0.022957489604542157\n",
      "0.023467188604864447\n",
      "0.023948014935548344\n",
      "0.024400534331471605\n",
      "0.024833875158709554\n",
      "0.025163952506796795\n",
      "0.025613795272489727\n",
      "0.02617303133951634\n",
      "0.026614788517262167\n",
      "0.027014313477123426\n",
      "0.02758061121735007\n",
      "0.028323455565911242\n",
      "0.02911575640382322\n",
      "0.02981810294037721\n",
      "0.03037134150550954\n",
      "0.03106196014999513\n",
      "0.031823049710927406\n",
      "0.03270260316206564\n",
      "0.033616827067872126\n",
      "0.03459981699159378\n",
      "0.03563406945787171\n",
      "0.03671304555716773\n",
      "0.03776197177112165\n",
      "0.03872764136939171\n",
      "0.03984528707763951\n",
      "0.04090526177688306\n",
      "0.04201105234762546\n",
      "0.04293614283103694\n",
      "0.04398773512607655\n",
      "0.044901132791247786\n",
      "0.04602370346784495\n",
      "0.04689836586519448\n",
      "0.047948760947776274\n",
      "0.049171596709858136\n",
      "0.050453399649952775\n",
      "0.05204275078907796\n",
      "0.05404383317616384\n",
      "0.05602764909774474\n",
      "0.058153180789898735\n",
      "0.060527331603006135\n",
      "0.06349404743380939\n",
      "0.06690069401088783\n",
      "0.07020793355896694\n",
      "0.07378402248773568\n",
      "0.07835400634877424\n",
      "0.08318611757556395\n",
      "0.08805694421285747\n",
      "0.09323058465176517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09808827503281534\n",
      "0.10269252886576337\n",
      "0.1074322396220487\n",
      "0.11211461969082456\n",
      "0.11661783683305493\n",
      "0.12168154568663075\n",
      "0.1268506085067558\n",
      "0.1318536576502161\n",
      "0.7953948521340549\n",
      "0.7951585821080913\n",
      "0.7947695841285745\n",
      "0.7942355715963288\n",
      "0.793581203264078\n",
      "0.7927444149766427\n",
      "0.7916941328915515\n",
      "0.7903444763286366\n",
      "0.7888336098287885\n",
      "0.7871593810659674\n",
      "0.7853899271770608\n",
      "0.783492135966168\n",
      "0.7814028754743801\n",
      "0.7790072729293257\n",
      "0.7765110077408145\n",
      "0.773974711662677\n",
      "0.7712825557623015\n",
      "0.7684046372480671\n",
      "0.765340767765021\n",
      "0.7620349416223334\n",
      "0.7585210744668867\n",
      "0.7548795894375366\n",
      "0.7512531158931868\n",
      "0.7475899288699714\n",
      "0.7436965937033778\n",
      "0.7396320560996053\n",
      "0.7354467637778666\n",
      "0.731016692997876\n",
      "0.7263349298202283\n",
      "0.7214673827839809\n",
      "0.7164479979230917\n",
      "0.7113033205039786\n",
      "0.7059026691834775\n",
      "0.7003829785724343\n",
      "0.6948585928796679\n",
      "0.6892721588131903\n",
      "0.6836446380945068\n",
      "0.6782477737230156\n",
      "0.673250700896895\n",
      "0.6684938245494517\n",
      "0.663792220322858\n",
      "0.6592468754164202\n",
      "0.6552236103880686\n",
      "0.6516985160033487\n",
      "0.6486472010659721\n",
      "0.6461633396292247\n",
      "0.6442033916164\n",
      "0.6426590364034287\n",
      "0.6415479042063902\n",
      "0.6407832450341736\n",
      "0.6405488374473042\n",
      "0.6406486703042296\n",
      "0.6411435188657562\n",
      "0.6418753796655137\n",
      "0.6426730425682339\n",
      "0.6436383160682771\n",
      "0.6447702896668074\n",
      "0.6461360453821104\n",
      "0.6473808934865892\n",
      "0.6486106218680523\n",
      "0.6498367283475865\n",
      "0.6510506152808463\n",
      "0.6520598176778803\n",
      "0.6530837616696723\n",
      "0.6540155480257035\n",
      "0.6544913299665633\n",
      "0.6548869911060311\n",
      "0.6551075865460723\n",
      "0.6551004306783881\n",
      "0.6553929488696363\n",
      "0.6559144293128666\n",
      "0.6564968858667469\n",
      "0.656686029319672\n",
      "0.6566105506675352\n",
      "0.6564670477994415\n",
      "0.6563806336011602\n",
      "0.6561277251857899\n",
      "0.6560325618777211\n",
      "0.6555604747613895\n",
      "0.6551512619709068\n",
      "0.6545373793843128\n",
      "0.6541878617977495\n",
      "0.6539058810881042\n",
      "0.6537129384140213\n",
      "0.653368236535732\n",
      "0.6532235293145462\n",
      "0.6531402601656235\n",
      "0.6528428599658027\n",
      "0.6525922447813317\n",
      "0.6524457430013831\n",
      "0.6526205379505099\n",
      "0.6529019957640703\n",
      "0.6530248635740569\n",
      "0.6531635566375366\n",
      "0.6532506738030212\n",
      "0.6528861141116333\n",
      "0.6527117747514993\n",
      "0.65275172731821\n",
      "0.6529059870336591\n",
      "0.6526853113975993\n",
      "0.6527146039828505\n",
      "0.6527469204289132\n",
      "0.6530783783971164\n",
      "0.6539043225759518\n",
      "0.6549198595757484\n",
      "0.656052502692031\n",
      "0.6570897381522535\n",
      "0.658183274913754\n",
      "0.6594105805704419\n",
      "0.6605422841106465\n",
      "0.6618151983236823\n",
      "0.6633371083200984\n",
      "0.6649445195855337\n",
      "0.6666726536338801\n",
      "0.6683742145993075\n",
      "0.6697984730139064\n",
      "0.6714495177008991\n",
      "0.672984310432081\n",
      "0.6744594967554514\n",
      "0.6758141954205604\n",
      "0.6771289744279543\n",
      "0.6784119513226579\n",
      "0.6797580855835769\n",
      "0.6810187415209836\n",
      "0.6820149685542142\n",
      "0.6830165728717046\n",
      "0.683963753179952\n",
      "0.6850024353436751\n",
      "0.6863124716826964\n",
      "0.6874462449054458\n",
      "0.6886894704301016\n",
      "0.6900019868679023\n",
      "0.6912301333784449\n",
      "0.6923448499445893\n",
      "0.6934402485250675\n",
      "0.6944155373549444\n",
      "0.6953301129208951\n",
      "0.6960482154491668\n",
      "0.6966825866912424\n",
      "0.6974121538521283\n",
      "0.6981028133184112\n",
      "0.6990770271254507\n",
      "0.6999464758559697\n",
      "0.7006333053462839\n",
      "0.701362473900849\n",
      "0.702183021774283\n",
      "0.7030458952026221\n",
      "0.7040156280438191\n",
      "0.7048699753170197\n",
      "0.705750061295309\n",
      "0.7064357484543722\n",
      "0.7070854758478166\n",
      "0.7077568359348543\n",
      "0.7084237307084503\n",
      "0.7092146375551593\n",
      "0.7099952886531309\n",
      "0.7107497994073761\n",
      "0.7114942755063617\n",
      "0.7122370468108277\n",
      "0.7925617210430284\n",
      "0.7925897385528156\n",
      "0.7926494084344329\n",
      "0.7926992467752034\n",
      "0.7927095637355255\n",
      "0.7924078749520198\n",
      "0.7916517945521185\n",
      "0.7905130433356028\n",
      "0.7889996398144262\n",
      "0.7873049976787059\n",
      "0.7853116871311997\n",
      "0.7831478896562218\n",
      "0.7807330995942341\n",
      "0.7782394104561516\n",
      "0.7757194922223604\n",
      "0.7731009874374102\n",
      "0.7702981156330244\n",
      "0.7673572799064052\n",
      "0.7642325262291141\n",
      "0.760960911498046\n",
      "0.7575136081338015\n",
      "0.7539717459453709\n",
      "0.7502650869540777\n",
      "0.7463517612032383\n",
      "0.7422708753619376\n",
      "0.738213252195328\n",
      "0.7341151033588714\n",
      "0.7298852963954561\n",
      "0.725701108623817\n",
      "0.7212795162405874\n",
      "0.7166916357113894\n",
      "0.7118630548108628\n",
      "0.7068230824795956\n",
      "0.7014485449742613\n",
      "0.6959588238198048\n",
      "0.6902751346731184\n",
      "0.6845856785644018\n",
      "0.6786047980249749\n",
      "0.6724472682324013\n",
      "0.666107134359582\n",
      "0.6596357014829174\n",
      "0.6529727398177594\n",
      "0.64625270584861\n",
      "0.6394147618383692\n",
      "0.6326733138791976\n",
      "0.6256206875898006\n",
      "0.6183400359011942\n",
      "0.610984584487514\n",
      "0.6034443364623006\n",
      "0.5957255397814681\n",
      "0.587663925604863\n",
      "0.5793609264020235\n",
      "0.5710606202510546\n",
      "0.5625839620130211\n",
      "0.5540069198806048\n",
      "0.545385287386857\n",
      "0.5367151851298043\n",
      "0.5278236554804724\n",
      "0.5186554341319263\n",
      "0.5093011285314643\n",
      "0.49982904989839544\n",
      "0.49016893515007126\n",
      "0.48047112222313304\n",
      "0.470832756764067\n",
      "0.4617627042640956\n",
      "0.4532302601970203\n",
      "0.4453281397258444\n",
      "0.4377936618244956\n",
      "0.43061522181452266\n",
      "0.4241344087111439\n",
      "0.41889332143971736\n",
      "0.41487169569248744\n",
      "0.4120373431160238\n",
      "0.4105194184586457\n",
      "0.4102110582299615\n",
      "0.4110163846785683\n",
      "0.412705491699083\n",
      "0.41530095626285596\n",
      "0.4187112274882563\n",
      "0.422728207676015\n",
      "0.4272730406697644\n",
      "0.43253945661011395\n",
      "0.4383689262821936\n",
      "0.4443040516120505\n",
      "0.45069186331749633\n",
      "0.4573269383787093\n",
      "0.8061160509102082\n",
      "0.8061054877611804\n",
      "0.8060219886334995\n",
      "0.8057886523050711\n",
      "0.8053595216126391\n",
      "0.8047708611440726\n",
      "0.8040487377056722\n",
      "0.8032013024267106\n",
      "0.8020068360416809\n",
      "0.8004781288454944\n",
      "0.7987202738783836\n",
      "0.7966552026860705\n",
      "0.7943507587792643\n",
      "0.7920075193938361\n",
      "0.7894693342546566\n",
      "0.7866808360375314\n",
      "0.7838365081935708\n",
      "0.7808325469708511\n",
      "0.7777582505530302\n",
      "0.7745099305524139\n",
      "0.7709888165801293\n",
      "0.7675428780845581\n",
      "0.7639233902790669\n",
      "0.7601887174476775\n",
      "0.7561589574699569\n",
      "0.7519975239247632\n",
      "0.747628421741923\n",
      "0.7431993659502091\n",
      "0.7385280718713465\n",
      "0.7336683201202041\n",
      "0.7287121965355841\n",
      "0.7236977501473589\n",
      "0.7186237177159015\n",
      "0.7134022152233258\n",
      "0.7078503230420966\n",
      "0.7023330291756739\n",
      "0.6969355723252334\n",
      "0.6916903381662289\n",
      "0.6864205645644661\n",
      "0.6811246051851817\n",
      "0.6758988382740951\n",
      "0.6705728076433078\n",
      "0.6654022549814116\n",
      "0.6605855994568017\n",
      "0.6562429404854128\n",
      "0.652391783035809\n",
      "0.6490492727319856\n",
      "0.6463865371780119\n",
      "0.6443123194294756\n",
      "0.6428044828304512\n",
      "0.6417328093923251\n",
      "0.6412667512882672\n",
      "0.641400126972692\n",
      "0.6418149551334409\n",
      "0.6425506111862032\n",
      "0.6435024825102108\n",
      "0.644415464033853\n",
      "0.6456294769568992\n",
      "0.6468823501113588\n",
      "0.64821300295875\n",
      "0.6497047843133765\n",
      "0.6511921749321014\n",
      "0.6527387141041163\n",
      "0.6544267913024835\n",
      "0.6560451616136806\n",
      "0.6575901546006209\n",
      "0.6590794313760596\n",
      "0.6603832409282634\n",
      "0.6615369208967042\n",
      "0.6624356949240494\n",
      "0.6631436209167991\n",
      "0.6635496174876203\n",
      "0.6638551396575766\n",
      "0.6638815993317703\n",
      "0.664003027905389\n",
      "0.6641286925707299\n",
      "0.6643334309919572\n",
      "0.6644237619405791\n",
      "0.6646160862736259\n",
      "0.6645237734821101\n",
      "0.6643103020907417\n",
      "0.6636879386544262\n",
      "0.6630292970942685\n",
      "0.6628663830901119\n",
      "0.6627907584352716\n",
      "0.6624538854499527\n",
      "0.662122521468237\n",
      "0.662060792920423\n",
      "0.6618375809276498\n",
      "0.6613646871169769\n",
      "0.6610962311564142\n",
      "0.6608161156737106\n",
      "0.6605324508490065\n",
      "0.659828887776014\n",
      "0.6591239763043945\n",
      "0.6586606062267278\n",
      "0.6585911602080696\n",
      "0.6586832254360163\n",
      "0.6590534033941694\n",
      "0.6597280675156376\n",
      "0.660713259484793\n",
      "0.6618373761174557\n",
      "0.6627130915191913\n",
      "0.6638122496017095\n",
      "0.6650862918675298\n",
      "0.6663514910899991\n",
      "0.6675863125859768\n",
      "0.6687099925866375\n",
      "0.6699156019567837\n",
      "0.671125218099414\n",
      "0.6723654922244466\n",
      "0.6736925674580796\n",
      "0.6750827119156687\n",
      "0.6764635051878557\n",
      "0.6781368002155881\n",
      "0.6797962440959117\n",
      "0.6811951685247759\n",
      "0.6825030434850063\n",
      "0.6837172730431558\n",
      "0.685104962000986\n",
      "0.6865798328355543\n",
      "0.6879149966743997\n",
      "0.6892239590531553\n",
      "0.6906873575759825\n",
      "0.6920297647453039\n",
      "0.6933544842388772\n",
      "0.6946889906316365\n",
      "0.6957507405269535\n",
      "0.6967304499003723\n",
      "0.6977238130179496\n",
      "0.6989021244876559\n",
      "0.7000634225884602\n",
      "0.7011204647462108\n",
      "0.7021537091215134\n",
      "0.7034535982691948\n",
      "0.7047203559719573\n",
      "0.7059106984995204\n",
      "0.7070943430910436\n",
      "0.708215567899055\n",
      "0.7093960605609965\n",
      "0.710490135605301\n",
      "0.711565336343071\n",
      "0.7125290911723638\n",
      "0.7133788413019633\n",
      "0.7141488578335846\n",
      "0.7148878477966549\n",
      "0.71550542655818\n",
      "0.7160383753783671\n",
      "0.716573925421247\n",
      "0.7171086128726543\n",
      "0.7176928300878168\n",
      "0.7183247673715781\n",
      "0.7189907456334437\n",
      "0.7197017994316529\n",
      "0.7204631007637767\n",
      "0.7211825493654241\n",
      "0.7218349957065778\n",
      "0.7224310428178337\n",
      "0.7230685307388807\n",
      "0.7237452680842779\n",
      "0.7242644557472052\n",
      "0.7247525127161656\n",
      "0.725306381267408\n",
      "0.7258722469624488\n",
      "0.7264647588909351\n",
      "0.8050067706152694\n",
      "0.8059394770640267\n",
      "0.8095892602285435\n",
      "0.8169806996465588\n",
      "0.8280862301115328\n",
      "0.8414372774401\n",
      "0.8564859440581482\n",
      "0.8730848688691144\n",
      "0.8908080588801843\n",
      "0.9093338328015651\n",
      "0.9283963488737915\n",
      "0.9477714221355431\n",
      "0.9672726139060824\n",
      "0.9867583128755114\n",
      "1.0060862269238275\n",
      "1.025143444805805\n",
      "1.0438798091069554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.062310249295846\n",
      "1.0804433677311058\n",
      "1.0982140739019235\n",
      "1.115659356185285\n",
      "1.1328315816837429\n",
      "1.1497632873100667\n",
      "1.1662925983330377\n",
      "1.1823999937957765\n",
      "1.198159952351943\n",
      "1.2136448889433917\n",
      "1.2288493041573572\n",
      "1.2435957114774687\n",
      "1.2580594349042908\n",
      "1.2724034498004064\n",
      "1.2864871505977422\n",
      "1.3001895556544676\n",
      "1.3138156114786674\n",
      "1.3271804444915967\n",
      "1.3404055757337325\n",
      "1.3533505885604207\n",
      "1.3661207161556934\n",
      "1.3788478232919594\n",
      "1.3912507762151431\n",
      "1.4033361383850194\n",
      "1.4152695390479453\n",
      "1.4270535901728452\n",
      "1.4385711840698827\n",
      "1.4500974362618104\n",
      "1.4613798066872834\n",
      "1.4725013110863872\n",
      "1.483371081722874\n",
      "1.4942279727238157\n",
      "1.5047965746592342\n",
      "1.5152212095495001\n",
      "0.8035138929140662\n",
      "0.8033807141240811\n",
      "0.8029236092440896\n",
      "0.8023524595909907\n",
      "0.8016807633974158\n",
      "0.8009931200018979\n",
      "0.8002759549205561\n",
      "0.7992646200779535\n",
      "0.7980024360089479\n",
      "0.7965584017603369\n",
      "0.79473126579907\n",
      "0.7927810971678196\n",
      "0.7908156774955132\n",
      "0.7886259551897168\n",
      "0.7861857269236614\n",
      "0.7836394908837266\n",
      "0.7808376465263835\n",
      "0.7779903793147384\n",
      "0.7750290971405547\n",
      "0.7717743864204376\n",
      "0.7686987347127315\n",
      "0.7654270014785968\n",
      "0.7620879086876376\n",
      "0.7584326648142559\n",
      "0.7546598832809112\n",
      "0.7507471387904424\n",
      "0.7465735351374142\n",
      "0.7423170735228676\n",
      "0.7377015512206392\n",
      "0.7328105529534061\n",
      "0.7277575145637316\n",
      "0.7227031521529207\n",
      "0.7177013962980044\n",
      "0.7125165837588308\n",
      "0.7071064954320596\n",
      "0.7014369343058112\n",
      "0.6958237046453555\n",
      "0.6900708807764769\n",
      "0.6841019650401939\n",
      "0.6780685904080824\n",
      "0.6718147774921\n",
      "0.6652561522457239\n",
      "0.6587021292289263\n",
      "0.6520356751585256\n",
      "0.6450094340582588\n",
      "0.6377367377862267\n",
      "0.6300777350721514\n",
      "0.6221856740011041\n",
      "0.6143252062527168\n",
      "0.6064080367255593\n",
      "0.598216050195746\n",
      "0.5899210308596913\n",
      "0.5814526428576634\n",
      "0.5728371486666771\n",
      "0.5642115514593142\n",
      "0.5555873790037527\n",
      "0.546712470667067\n",
      "0.5375704872701891\n",
      "0.5283347013376566\n",
      "0.5190455492463718\n",
      "0.5096678544145697\n",
      "0.5001982350998398\n",
      "0.4906894780490697\n",
      "0.48094109236647925\n",
      "0.4711010311128529\n",
      "0.46154630758997234\n",
      "0.4529399396948033\n",
      "0.4446931826465485\n",
      "0.437027634730263\n",
      "0.43010873941161176\n",
      "0.42440403899248963\n",
      "0.42000731861059754\n",
      "0.4168469654715691\n",
      "0.41501080519627404\n",
      "0.41456532766265564\n",
      "0.4150040377977921\n",
      "0.41626351637467185\n",
      "0.4184556831408017\n",
      "0.4213104737444197\n",
      "0.42487945666551563\n",
      "0.4291567165848722\n",
      "0.43396333035361534\n",
      "0.4391080912774934\n",
      "0.44456755191559794\n",
      "0.4504246212709034\n",
      "0.45662073810566467\n",
      "0.7975879554526915\n",
      "0.7973710639414834\n",
      "0.7970821331239363\n",
      "0.7966448981489687\n",
      "0.7959337799824379\n",
      "0.7950946407399959\n",
      "0.7941391058310586\n",
      "0.7929911361669365\n",
      "0.7914589566275024\n",
      "0.7896599461588049\n",
      "0.7876236017670829\n",
      "0.785407837788232\n",
      "0.7831153781286122\n",
      "0.7807677625209588\n",
      "0.7784257153540093\n",
      "0.7759183260588394\n",
      "0.7733542887123834\n",
      "0.7705832141137865\n",
      "0.7676865414463598\n",
      "0.7647060214538511\n",
      "0.7615786379346744\n",
      "0.758288135960346\n",
      "0.7550025427896511\n",
      "0.7514068682598374\n",
      "0.747569263126361\n",
      "0.7436446732406831\n",
      "0.7395531769031334\n",
      "0.7352802011355467\n",
      "0.7308639257757238\n",
      "0.7263133690672923\n",
      "0.7215347066703214\n",
      "0.7166069821869534\n",
      "0.7115264627026909\n",
      "0.7062374130906581\n",
      "0.7007626774256244\n",
      "0.6951725498207001\n",
      "0.68932483480121\n",
      "0.6832927821253907\n",
      "0.6772426805207598\n",
      "0.6712720055862335\n",
      "0.6649238461540827\n",
      "0.6583658085398849\n",
      "0.6516064921626596\n",
      "0.6446403394438968\n",
      "0.6376124660716305\n",
      "0.6308228102451232\n",
      "0.6243832486374513\n",
      "0.6183233904310902\n",
      "0.6122109975180526\n",
      "0.6063311480518\n",
      "0.6010161651498587\n",
      "0.5964093090038937\n",
      "0.5925707713580561\n",
      "0.5896252378339595\n",
      "0.5876288454068467\n",
      "0.5863413321559467\n",
      "0.5856396247445489\n",
      "0.5854056313209152\n",
      "0.5856272351831149\n",
      "0.586321059937974\n",
      "0.5875255173474792\n",
      "0.5889433729105532\n",
      "0.5906936209053749\n",
      "0.5925896654474245\n",
      "0.5947624343821336\n",
      "0.5969465242556103\n",
      "0.5994114701852427\n",
      "0.6018841770233123\n",
      "0.6044555478249553\n",
      "0.6072373897041731\n",
      "0.6100484283297193\n",
      "0.6125221308281332\n",
      "0.6148428872983913\n",
      "0.6168502967556282\n",
      "0.6187674553439908\n",
      "0.6204958797202894\n",
      "0.6220742522779115\n",
      "0.6232094920324605\n",
      "0.6241166268180613\n",
      "0.6246702934588265\n",
      "0.6249355429194825\n",
      "0.6247246779080421\n",
      "0.6246580130847815\n",
      "0.6244883084646629\n",
      "0.6247943679713585\n",
      "0.7965963591682812\n",
      "0.7967402823269483\n",
      "0.7969396387810129\n",
      "0.7970440290647057\n",
      "0.7969557616746435\n",
      "0.7964859236590691\n",
      "0.7956228863598309\n",
      "0.794312229084956\n",
      "0.7925580991862589\n",
      "0.7906528293466394\n",
      "0.7887482636941995\n",
      "0.7867088085354492\n",
      "0.784526153279534\n",
      "0.7821114011704499\n",
      "0.7795426784662992\n",
      "0.7768945912662801\n",
      "0.7740200167298317\n",
      "0.7709185866622079\n",
      "0.7676166930706722\n",
      "0.7641419275120532\n",
      "0.7606235669265382\n",
      "0.7570121044305576\n",
      "0.7533011030751483\n",
      "0.7494825609416446\n",
      "0.7455074061038498\n",
      "0.7414666795455283\n",
      "0.7373241647191204\n",
      "0.7329340012109367\n",
      "0.7283214181808562\n",
      "0.7235701931837106\n",
      "0.7186242200531933\n",
      "0.7135368752443184\n",
      "0.7083582164510348\n",
      "0.7030009885408991\n",
      "0.6973660845154698\n",
      "0.6918180736984226\n",
      "0.6862650802531013\n",
      "0.6805734353121005\n",
      "0.6746898598199018\n",
      "0.6686353987966331\n",
      "0.6623593539312009\n",
      "0.6558369726297806\n",
      "0.6491633173523482\n",
      "0.6423672954578924\n",
      "0.6354477176780874\n",
      "0.6284004309005776\n",
      "0.6212223500926138\n",
      "0.6138762511356861\n",
      "0.606438861740312\n",
      "0.599006062828054\n",
      "0.5914490517926346\n",
      "0.5835620210196262\n",
      "0.5755452565155574\n",
      "0.5671752580105265\n",
      "0.5586533955491109\n",
      "0.5500498984458136\n",
      "0.5413115239471599\n",
      "0.5324223608928184\n",
      "0.5232323422638951\n",
      "0.5138417452618927\n",
      "0.5043388721171287\n",
      "0.4946637358664207\n",
      "0.4848703132339584\n",
      "0.474962020921274\n",
      "0.465778746318568\n",
      "0.4574505763565346\n",
      "0.4497507818382718\n",
      "0.44220458389519923\n",
      "0.43503400985443796\n",
      "0.42892552019166147\n",
      "0.42378873738140577\n",
      "0.4196123043255507\n",
      "0.41669907828077596\n",
      "0.4152327611215787\n",
      "0.41485056087931704\n",
      "0.4156209322953821\n",
      "0.41729487074808486\n",
      "0.4197319530904032\n",
      "0.4230253141142238\n",
      "0.42688439983095616\n",
      "0.43132118506932093\n",
      "0.43618048544306764\n",
      "0.4413841130598491\n",
      "0.4469270473380254\n",
      "0.4526681044172672\n",
      "0.797447577956215\n",
      "0.7974562485747435\n",
      "0.7973644730782486\n",
      "0.7970793261822694\n",
      "0.7966943061282885\n",
      "0.7960557755429084\n",
      "0.7951669174802929\n",
      "0.7939154467078623\n",
      "0.7924410916683552\n",
      "0.7908232280407688\n",
      "0.7890299464817803\n",
      "0.7870998518201622\n",
      "0.7850534336045791\n",
      "0.7828787110494977\n",
      "0.7805405857815484\n",
      "0.7779291553435512\n",
      "0.7751546034696974\n",
      "0.7722868202610279\n",
      "0.769367977979577\n",
      "0.7665926700621358\n",
      "0.7636626917418974\n",
      "0.7602860427233613\n",
      "0.7565797200863914\n",
      "0.7526642980221465\n",
      "0.7485483464846192\n",
      "0.744419596755737\n",
      "0.7401068809387606\n",
      "0.7356210153889394\n",
      "0.7309992050017641\n",
      "0.726167295417683\n",
      "0.7211148708227655\n",
      "0.7158923158088965\n",
      "0.7106837264855203\n",
      "0.7053201849862599\n",
      "0.6998311032598595\n",
      "0.6941527358406967\n",
      "0.6883732443588899\n",
      "0.6825729091405204\n",
      "0.676734793554532\n",
      "0.6709419282636943\n",
      "0.6649160560968078\n",
      "0.6587560202032009\n",
      "0.6524333403139889\n",
      "0.6459677616898998\n",
      "0.6392705681065165\n",
      "0.6322755063676114\n",
      "0.6250034841493369\n",
      "0.6174899016151801\n",
      "0.6098203533478751\n",
      "0.6019043082101176\n",
      "0.5938403941966522\n",
      "0.5856333324640672\n",
      "0.5772846781935735\n",
      "0.5688173833825082\n",
      "0.5603313625703834\n",
      "0.5516820406786825\n",
      "0.5427376589853585\n",
      "0.5335815716042995\n",
      "0.524181710326026\n",
      "0.5147079409303991\n",
      "0.505028508305926\n",
      "0.49528264750423895\n",
      "0.4854747771602511\n",
      "0.47539456304421984\n",
      "0.4653448272313569\n",
      "0.45618809613539196\n",
      "0.44775118930110563\n",
      "0.4399183799852372\n",
      "0.4323121689218844\n",
      "0.4254654566144319\n",
      "0.4196338307432323\n",
      "0.4147978821648842\n",
      "0.4110910708904251\n",
      "0.40876573739602695\n",
      "0.4076498113654969\n",
      "0.4076820530734335\n",
      "0.40887570716409\n",
      "0.41107050157560865\n",
      "0.41411395981855564\n",
      "0.4181435300466276\n",
      "0.42285700895432243\n",
      "0.42793217387484433\n",
      "0.43342562621611075\n",
      "0.4393431463958068\n",
      "0.44549375371709976\n",
      "0.45176229672565443\n",
      "0.7952940314910318\n",
      "0.7950754394338303\n",
      "0.7946460729966276\n",
      "0.7940252408384361\n",
      "0.7932394458025167\n",
      "0.7922719289667933\n",
      "0.7910758714782651\n",
      "0.7898130998241107\n",
      "0.7883418548838622\n",
      "0.7866826200134565\n",
      "0.7849364484505363\n",
      "0.7832341990162971\n",
      "0.7812616230747818\n",
      "0.7789586146641018\n",
      "0.7763906098632969\n",
      "0.7736331135579154\n",
      "0.7709847193742655\n",
      "0.7682788323907338\n",
      "0.765390485943119\n",
      "0.7623899849938687\n",
      "0.7591874322691116\n",
      "0.7557692534706735\n",
      "0.7521351591527186\n",
      "0.7483144599614796\n",
      "0.7445410704568363\n",
      "0.7408090798710933\n",
      "0.7367491789865902\n",
      "0.7325666232099186\n",
      "0.7281234530967708\n",
      "0.7234858876765055\n",
      "0.7187357573276869\n",
      "0.7139325149367182\n",
      "0.7089746141844226\n",
      "0.7039445986809235\n",
      "0.6986275879226329\n",
      "0.6932716864454341\n",
      "0.6876304179099513\n",
      "0.6818740215023542\n",
      "0.6758757798915065\n",
      "0.6697735832519991\n",
      "0.6638401441967368\n",
      "0.6576611305619752\n",
      "0.6512188627455454\n",
      "0.6445424028544204\n",
      "0.6376598748374978\n",
      "0.6306180325170234\n",
      "0.6234348411204855\n",
      "0.6161638781419665\n",
      "0.6087037234847354\n",
      "0.6010254368636927\n",
      "0.5930718273200336\n",
      "0.5848959874597356\n",
      "0.576596972959815\n",
      "0.5681246184835622\n",
      "0.5596141777501584\n",
      "0.5508967208919183\n",
      "0.5419243042929084\n",
      "0.5329082258858283\n",
      "0.5236266440916187\n",
      "0.51417810382594\n",
      "0.5046866970736092\n",
      "0.49517727881710316\n",
      "0.48542588551189614\n",
      "0.475431408662054\n",
      "0.4654504091390896\n",
      "0.45535303822902506\n",
      "0.4452035567796125\n",
      "0.4348651672062259\n",
      "0.4242259607921436\n",
      "0.4133889830630111\n",
      "0.4025885967624517\n",
      "0.39193899751239897\n",
      "0.38247396389483773\n",
      "0.37423800497742893\n",
      "0.3664440292314339\n",
      "0.35927819812831363\n",
      "0.3531482668885515\n",
      "0.3483076895293182\n",
      "0.344849469876963\n",
      "0.3428853050812662\n",
      "0.34201797025249714\n",
      "0.3427331064220695\n",
      "0.34480154571371147\n",
      "0.34791662755966446\n",
      "0.35186813035679254\n",
      "0.3564941903824832\n",
      "0.36202615900879176\n",
      "0.3684301042251042\n",
      "0.37500294991601585\n",
      "0.7919308571278799\n",
      "0.7919323991314553\n",
      "0.7919399168546606\n",
      "0.7915896575201503\n",
      "0.7908647280323093\n",
      "0.7899356106277413\n",
      "0.7889239287572543\n",
      "0.7877709511105293\n",
      "0.7864723381449981\n",
      "0.7848427845247241\n",
      "0.7829807312551846\n",
      "0.7810322616955689\n",
      "0.7789781627072734\n",
      "0.7767771134334198\n",
      "0.7745939677829455\n",
      "0.7722694821913911\n",
      "0.7697165391829008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767017573297889\n",
      "0.7640464600107066\n",
      "0.7609745495624581\n",
      "0.757733005108688\n",
      "0.7542714545307657\n",
      "0.750456021798511\n",
      "0.7465864761370066\n",
      "0.7426677729382083\n",
      "0.7386234752242076\n",
      "0.7343818278558735\n",
      "0.729846991503406\n",
      "0.7251652302381375\n",
      "0.7204653636989029\n",
      "0.7157245565524126\n",
      "0.7107216591878812\n",
      "0.7056659131456835\n",
      "0.7004232832787246\n",
      "0.6949042129916649\n",
      "0.6893136448156941\n",
      "0.6836721442879085\n",
      "0.6780975586377462\n",
      "0.6723324216766643\n",
      "0.6664324761039666\n",
      "0.660829979399317\n",
      "0.6553863024351376\n",
      "0.6500993863105186\n",
      "0.644937769392044\n",
      "0.639691037078288\n",
      "0.6344980897851042\n",
      "0.6297445625211211\n",
      "0.6257727969468989\n",
      "0.6223727615180171\n",
      "0.6195737125670608\n",
      "0.6173540824490781\n",
      "0.6157143140558957\n",
      "0.6144200727018412\n",
      "0.6136344142414544\n",
      "0.6132115724183355\n",
      "0.613487100094726\n",
      "0.6141609638314173\n",
      "0.6150928362929753\n",
      "0.616177337357216\n",
      "0.6173741522254981\n",
      "0.6188364348836802\n",
      "0.6203532220573671\n",
      "0.6218426228756836\n",
      "0.6233730234048429\n",
      "0.6249870995467968\n",
      "0.6267589129466233\n",
      "0.6284681883384207\n",
      "0.6302156135597585\n",
      "0.6316483538653742\n",
      "0.6329106669015621\n",
      "0.6337784973525294\n",
      "0.6345539253045918\n",
      "0.6351665882409397\n",
      "0.6354064124510089\n",
      "0.6353816691267217\n",
      "0.6354000727972909\n",
      "0.6351215616135353\n",
      "0.6348580039936194\n",
      "0.6345690509299678\n",
      "0.6341103186177749\n",
      "0.633915735567725\n",
      "0.6338955536045626\n",
      "0.6339227316082893\n",
      "0.6338453886887075\n",
      "0.6340244169496232\n",
      "0.6341927167958177\n",
      "0.634767502654746\n",
      "0.6353294906238373\n",
      "0.635828197517414\n",
      "0.6361712945330685\n",
      "0.6363650631956794\n",
      "0.6365344454721051\n",
      "0.6368450326589925\n",
      "0.6372769899470281\n",
      "0.6378390134097182\n",
      "0.6383067054379782\n",
      "0.6389631826624456\n",
      "0.6395591950348349\n",
      "0.6401137467494772\n",
      "0.6406862337626492\n",
      "0.6411964818882172\n",
      "0.641965288801074\n",
      "0.6428311333969079\n",
      "0.6436913414491362\n",
      "0.644589616616149\n",
      "0.6456271969674298\n",
      "0.6466613681398499\n",
      "0.7945882679305746\n",
      "0.7947049602919928\n",
      "0.7947786460909699\n",
      "0.7948353005895857\n",
      "0.7947186632678565\n",
      "0.7943967350648502\n",
      "0.7938692555746039\n",
      "0.7931601873835304\n",
      "0.792007884097986\n",
      "0.790426185829778\n",
      "0.7884474941825088\n",
      "0.7863165582580245\n",
      "0.784074286657121\n",
      "0.7816386933498468\n",
      "0.779007651066649\n",
      "0.7762202779657729\n",
      "0.7733313168955523\n",
      "0.7703921049572401\n",
      "0.7673595563152332\n",
      "0.7641937211369326\n",
      "0.7607681177028603\n",
      "0.7570157803159344\n",
      "0.7530994820079663\n",
      "0.7489404103817794\n",
      "0.7446728023411947\n",
      "0.7402735672955479\n",
      "0.7359718258129725\n",
      "0.7314712807394176\n",
      "0.7266925895452395\n",
      "0.7218909737486455\n",
      "0.7169780976755366\n",
      "0.7120014819145949\n",
      "0.7068859346976663\n",
      "0.7016488232545325\n",
      "0.6961985349955285\n",
      "0.6905432125106226\n",
      "0.6847089072235824\n",
      "0.6787224468553533\n",
      "0.6724972168752305\n",
      "0.6660406340710475\n",
      "0.6595197850852313\n",
      "0.6528781164446196\n",
      "0.6460172899438272\n",
      "0.6389296094675349\n",
      "0.6316672228263557\n",
      "0.6246830911057567\n",
      "0.6175411107512432\n",
      "0.6102237688735543\n",
      "0.6027355782906614\n",
      "0.5949434349380787\n",
      "0.5869881630950097\n",
      "0.5792646533838609\n",
      "0.571364058819055\n",
      "0.5633890982152917\n",
      "0.5551966744441095\n",
      "0.5467492451790401\n",
      "0.5380121083267076\n",
      "0.5290714752099065\n",
      "0.5198781132871438\n",
      "0.5104151755941806\n",
      "0.5012094697965085\n",
      "0.4917942804653229\n",
      "0.482055919743562\n",
      "0.4725215506454602\n",
      "0.46275707766026625\n",
      "0.4526424973807225\n",
      "0.4426520706703467\n",
      "0.4332522215280331\n",
      "0.4246416367872163\n",
      "0.41647725677384845\n",
      "0.40844455639289534\n",
      "0.4010333270755376\n",
      "0.39467344561734424\n",
      "0.3895443752314149\n",
      "0.3857687956225696\n",
      "0.383260506065915\n",
      "0.38211713523827767\n",
      "0.38217897994993155\n",
      "0.38325132197388867\n",
      "0.3853830853445984\n",
      "0.38854270069420677\n",
      "0.3924271999893047\n",
      "0.3970374733755567\n",
      "0.40217221682815546\n",
      "0.40771738016323966\n",
      "0.4138693633964245\n",
      "0.4202169340529257\n",
      "0.42677707147758664\n"
     ]
    }
   ],
   "source": [
    "env = Ascento()\n",
    "env.reset_model()\n",
    "m1 = []\n",
    "m2 = []\n",
    "m3 = []\n",
    "m4 = []\n",
    "\n",
    "for i_episode in range(15):\n",
    "    observation = env.reset()\n",
    "    done = None\n",
    "    while not done:\n",
    "        env.render()\n",
    "        print(env.z)\n",
    "        action, _ = model.predict(env._get_obs())\n",
    "        m1.append(action[0])\n",
    "        m2.append(action[1])\n",
    "        m3.append(action[2])\n",
    "        m4.append(action[3])\n",
    "#         action[2] = 1\n",
    "#         action[3] = 1\n",
    "\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIkAAAEvCAYAAADBz5EMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACvFUlEQVR4nOzdd5gTVRcG8PfuLkvvTfrSe1O6qCAgCCrYwa4o9oq9d7H33htiVz5771iwSxNEVBCkdzb1fn9MJpkkM8nUTJJ9f8+j7CaTmbu7U8+99xwhpQQREREREREREVVtJX43gIiIiIiIiIiI/McgERERERERERERMUhEREREREREREQMEhERERERERERERgkIiIiIiIiIiIiMEhEREREREREREQAyvxugJEmTZrIiooKv5tBRERERERERFQ0vv/++7VSyqZ67+VtkKiiogJz5871uxlEREREREREREVDCPGX0XucbkZERERERERERAwSERERERERERERg0RERERERERERAQGiYiIiIiIiIiICAwSERERERERERERGCQiIiIiIiIiIiIwSERERERERERERHApSCSEeEwIsVoI8ZvB+0IIcZcQYokQ4hchxM5ubJeIiIiIiIiIiNzh1kiiJwCMy/D+3gA6x/6bBuB+l7ZLREREREREREQucCVIJKX8DMD6DItMBPCUVHwNoIEQooUb26Y89N2jwLo//G6Fd/75Dvj+Cb9bQUSFbvn3wG8v+90KouK1egHwNfsliQxJCcw6HPj3J79bQkR5pCxH22kF4B/N98tjr63ULiSEmAZlpBHatm2bo6aRq7asAt48R/n6yk3+tsUrj45W/u07BSir7m9biKhwPbKn8m+vA/1tB1Gxum+I8u/A44HSav62hSgfLf0YWPiG8l+x3rcTkWV5lbhaSvmQlHKAlHJA06ZN/W4O2RHc5ncLckdG/W4BERERZSOl3y0gyk9bVvndAiLKQ7kKEq0A0EbzfevYa0RERERERERElAdyFSSaDeCoWJWzIQA2SSlXZvsQERERERERERHlhis5iYQQzwEYAaCJEGI5gCsAVAMAKeUDAN4CMB7AEgDbARzrxnYpD3FINxEREREREVFBciVIJKWckuV9CeBUN7ZFRERERGQeO7CIiIjMyqvE1UQFhaOmiIiIiIiIqIgwSEQuY+CEiIiIiIiIqBAxSERERERERERERAwSERERERERERERg0REREREVMyYQ5CIiMg0BonIXbwRIyIiIiIiIipIDBIRERERERERERGDRET2cdQUERERERERFQ8GiYiIiPz09zd+t4CIiIiICACDROQ6jq4hIrJk419+t4CoyPHehIiIyCwGiYiIiIiIiIiIiEEiIiIiIiIiIiJikIiIiIiIiIiIiMAgEZF9kjkOiIiIiIiIqHgwSERk1ppFwJX1/W4FERERWcFOHSIiItMYJCIya96rfreAiIiIiMgdDKASkQ4GichdvNgQERERERERFSQGiYjMSg2ACeFPO4iIiIiIiIg8wCARERERERERERExSEREROQvjkokIiIiovzAIBG5rIhzEq36Jfl75l8iIlfwXELkLR5jRLqYOoGIdLgSJBJCjBNCLBJCLBFCXKjzflshxMdCiB+FEL8IIca7sV2inFr0lt8tICIiIiIiIvKM4yCREKIUwL0A9gbQA8AUIUSPlMUuBfCClLI/gMkA7nO6XSIiIiIiIrKJo+KJSIcbI4kGAVgipVwqpQwCmAVgYsoyEkC92Nf1AfzrwnaJiIiIiIiIiMglZS6soxWAfzTfLwcwOGWZKwG8J4Q4HUBtAKNd2C7lm0gIeG6y360gIiowzAlBRERERPkhV4mrpwB4QkrZGsB4AE8LIdK2LYSYJoSYK4SYu2bNmhw1jVzz07PAhmV+t4KIiIgogVNqiIiITHMjSLQCQBvN961jr2lNBfACAEgp5wCoAaBJ6oqklA9JKQdIKQc0bdrUhaZRToV2+N2CHONNJxERERERERUPN4JE3wHoLIRoL4Qoh5KYenbKMn8DGAUAQojuUIJEHCpERETEgDMREflBcLozEaVzHCSSUoYBnAbgXQALoFQxmyeEuFoIsV9ssekAThBC/AzgOQDHSMmxv8WHFxoiIiIiIiKiQuVG4mpIKd8C8FbKa5drvp4PYFc3tkV5LD3NVPGoclPpiCh3GGAnIiIfsM+eiHQU8VM95VwxD1n99iG/W0BERES28EGYiIjILAaJyD2/PO93C7yz5T+/W0BERERERETkKQaJyD3Lv/O7BbnFIbpERERERERURBgkIiIiIiIiIiIiBomITCnmfEtEREREREREYJCI3LLgf363wFucWkZERFSYeA0nIiIyjUEicsevL/ndAiIiIiIiMo0BVCJKxyARERERERERERExSEQuWfu73y3wFnMSERERERERUZFjkIjcsXq+3y0gIiIiIiLT2AlKROkYJCIiIiKiIsa8K0RERGYxSERkxrLP/W4BERERERERkacYJCIyI7DF7xYQEREREREReYpBolxY9RvwwlFAJOR3S4iIyA1b/gOurA/8PMvvlhAREdnEqZhElI5Bolx49URg/uvAmoV+t4TsEjxUiEhDrej4w9PO18XqiURERESUJ/jkm0uS0fqCpRsk4t+TiFzAawORt3iMERERmcYgUU6wl7jw8W9IRFp86CQiokLH+1siSscgUU7xoaJgcboZEan+/BxY8b3yNaeKEREREVERKfO7AVUCnyEKHx8EiUj15D5+t4CIiIiIyBMcHpFLnBNfuDiSiIi8wiA0kfuiEb9bQEREVJD45JsT6gMAg0QFiw9xREREheOdizTf8P6LiIjILAaJiExhkIiIiKhg/PqC3y0gIiIqSK4EiYQQ44QQi4QQS4QQFxosc4gQYr4QYp4QYqYb2yXKGb3pZpw+SERu4LmEiIh84fL1Z8MyILjN3XUSUc45DhIJIUoB3AtgbwA9AEwRQvRIWaYzgIsA7Cql7AngLKfbLSicqlT4+DckIj3LPgcWvuV3K4goFYOvRLl3Z1/g2UP8bgUROeTGSKJBAJZIKZdKKYMAZgGYmLLMCQDulVJuAAAp5WoXtlt4eMNSwBgkIiIDs6Y4+zyD0EREVCz++sLvFhCRQ24EiVoB+Efz/fLYa1pdAHQRQnwphPhaCDHOhe0WED4AEBEREREREVF+K8vhdjoDGAGgNYDPhBC9pZQbtQsJIaYBmAYAbdu2zVHTcokjiQqWXk4iIiIiyn8cyU1ERGSaG0++KwC00XzfOvaa1nIAs6WUISnlnwB+hxI0SiKlfEhKOUBKOaBp06YuNC1PqFMJeI9SuDgdhIiIiIiIiIqcG0Gi7wB0FkK0F0KUA5gMYHbKMq9BGUUEIUQTKNPPlrqw7QLBAEPB0x1JxKgfERFRXqrc6HcLiIiICpLjIJGUMgzgNADvAlgA4AUp5TwhxNVCiP1ii70LYJ0QYj6AjwGcJ6Vc53TbRDnD6WZERERERERU5FzJSSSlfAvAWymvXa75WgI4J/YfUeFhkIio+G34C3j7AuCgx4DyWn63hoiIiIgo5/jkm1NFOj3pn2/9boH3ymrovMhphERF5a1zgd/fBha/63dLiIiIiIh8wSBRLsQTVxdpkOiX5/Vf/+ru3LbDSzUb+N0CIvLS/NnA4veUr3ds8LctRERERIVGSuCbh3gfVQQYJMqJKjri5IOr/G4BEZE5815NfP3G2f61g4iIiKgQLf8OePs8YPYZfreEHGKQKKeKdCSRoWL/eYv95yMqEC8eC9zcydk61i1xpy1EREREVVG4UvmXI4kKniuJqykLUUVHEhXr9Doiyi/zXnF/naFKoLQcKGFfCpEtoR1AcBtQu4nfLSEiIiILePdLhWHHRmDZF363goiKVkpQ+7rmwLsX+9MUomLw5L7AzR39boWCnVZE3lm/FNi80u9WEJGLGCQiFxiNlHLxpmzW4cATE4DAVvfWSUTemj8bCAf8boV93z9hftnfXgaurA8s+dD6dv6bZ/0zRPlu+Xd+t4CIcuGu/sBt3fxuBRG5iEGiXKpqPVlu/ryrflX+jYbdWydRofj1JeC1U/1uhTVLPwFeOBL48Gq/W2KO09PVS8cp/y580/pnv7jN4caJKO63V5SALRER+aOqPfMWIQaJckIdaVPVDhg3f96q9rsj0nh5KvDTM363wpoNfyn/bvrH33aY5tI5ppBHTlFx+uxmJWgSjfrdktyYc4/fLSAiqjru6g+8rnZkFlAe3sBW5dr48/N+tyQvMUiUC1U1cbUX+Lskyn/b1wP/K7Dyp7q9XjYCR6s5dYzyzMfXx75gZwtZ8OhewMsn+N0KIsp365cCP9royPznW6VIiF82r1D+/fwW/9qQxxgkyiUOvSsu/HtSPpJS6Rn54nbzn9n4N7DuD/fa8MJR7q3LT3aO8X9/dL8dRE74fa3Kdc6tFd/rvMjrtWX/fAP8+oLfrSDPsfOVfLD+T+DRMcBb0/1uif/XyDzFIFFOuHQCvmcgcM8g4OZOwHuXubPOQhE/gHkxq7J+ek4Jfmxf73dLCsMHV5pf9o7ewN07u7ftDcsSXxfCxVdKjgCiKsCn6+f9w5x9PhICbqwAfnnRleYQkVYBXKOp+FRuVP5d+YuPjaiq6WDMYZAopxzuhGt/B9YuAratAb66S3ntz8+BiM/JnHMyBUwmtvX318DNnYHKTTnYLuWNbx9U/t3wp7/t8NvKn4G1S/xuRX6LhIAn9lHOFWZs/Nvb9pi17AuWES4WqxeaD5BWbgJemQbs2OhRYwr8BrhyE7BjA/D2+X63hPKFlMBb5wP/zfe7JYXhv/lKAQw9bnbkFEKnEOWJPOj0T31+lbLq5O4zgUGiXPAqiPLXHODJfYBPZ3iz/nyivfB8fB2wbXVup3XoXfjMPoBm8+dnygiZFT8o329fzwBYJoV+DxLc7mw01IO7A/fs4l578sUPTynHwY4Nzte1YRmw7HNNIsVsjHYqndfj+V088MQE4MHdvFs/ZWd1qqae5d8D9w0Gvro7+7KhHcBntwC/PA98fZ+z7RatPHiYoPyyeYXScfTsQfbXsXWN9/daa5fkRyDr/qFKAYw1i/xuCVUZsfsnKYFPbsyQ0iAHN/Ub/wGC24zfV5/xnpgAXN3Q+/YUCAaJCtnWVcq/a3/3tx25dGOFElTJB7OmuLOe399V/l32hfLvTe2BG9u7s+6iYuNBYePfykPfn5+73xy7Ht5T+Rt7RRvQnPuYd9tx2zexkWKbljtfl/o7MBuMM+r91Hv90xuzr2/bWuC6lsDyuea2n/TZNdY/Y2THRvbs2mFlqqaejcuUf//9Ifuyt3VPjAzOlW1rlfPi/Nm53a5jebYv//uj8nt0q8MoX61dDPz1ld+tcN8tnYDbe3u7jXt2UQI0Vvw337tp9fcO8ma95B0pge8eUSpx2RUJAXf2BRa84V67jKQOjNi6GvjkeuCpSZmX89IdvYCn99d5I6UNf32Zk+YUCgaJcsntm3V1fcu+8H/KmediP2u02H/OGBnxuwXFQb2x/fHp3G1zyQfKf0bWLPBmu/NeBW7tDkRDide+yodS0D4+2O3wKX/Vss+B0LbcPvxvXaM8sC5+H1i9ANj8L3BjO+DLO3PXhkITCSu/s7mPm/9M5SZnN+up3Bg5Z1Z4h/Lv6tjIhm8fyt22F74J/GIyCfJ3jwD3Dlb23SvruzNq2Itg6ZIPlX/Vjp5idc8A4PG9jd//7eXkPHROBLYCj09QAlNe+ufb2PZcHEkUjQLb1jlfz/1Dlc4ktwS2uLeubNgpYWz9UuD5I6xX8/rjI+DN6cC7F9nf9vZ1yjH65jmJqZqrfs38mSvrK+21Km0fiH2/yedp/f98k+FN7rd6GCTKCa+ipWpv+Trgo2s82kYe+PtrILTd71bkAE9S5uT49/TTc8kjkfTKAoeDiZvDZw5U/rNLSuDrB6w/iL45HdjyL6cqbl8PLH7P71bk3vLYQ8+zBwH3DQHWLFS+X5iDnsNCFYw9PH1whfnPzGgL3NLFm/ZofXoTsOo3d9f500zlXz8e5GYdBrxispz6m9OV/ff9y5Xv1WCrmXYHc3mvIBP/VuWH45eOAx4a4c66ln4M/PWF8Wi+SEh52HX6+350jLPP6/nsZuDmDsBNHYEPrnK2Lm3uxS2rlFx1b56rPLhbdWv35O/XLmHeFT+8dR6w4H9KJ5IV6vOPW6PLtq1RpmrqjqxJseB/DjYUe/bNdqz6eerM5WimAsQgUS78rQ7T9fBIsDOtwTUeH2SPjfVnu0mb8mBbG/9WqrXwJGWOX7+n105Scn+p9MoCv3yccnPohsXvAe9cADwwPD9yGeTau5dYmx747cPJ3z83GXjvEosbtZCTKF/Ney35e/UGcPl3wK3dqvZDrNtCGXIbaM171d76oxEl956bowmSFNi+oJ77Kzdm34/fz0Hl11mHAx9ek/g1fnG7MoX435+833a+cntE3I6N+omW37lImTYTn5brwn1BtuvNhmXmRuv//rby7/a1wBe3OW5W3K1dgdu6Ad89nH1Z1d27KIFmIBEMV92zC/DlHYnvtfdWzFmUvxa+AXx+q7N1OLkPiIQy5BWyg88++Y5BomIRCfi4cb9uOAvsRjfVo3sBrxzPhzer3Ph9SakEI7ZmyP8y71Xgt1fMrc9Rb0sKtddow5/WcxkAKb+fPN23AlvSH6jUdv/5aXJQLpvUm6Z1eVT5LVfH9uaV6YFLrS0rAcmeY0OVm/In151WJOjt+t0IvIeDyuiGj29wvi5Av8Lb0k8SX8+5N/Pnt6xypx2ZLHwD+PwWYJ1mStSODcBDe3i/7ariry+URMupD6VLP1b+Vctnu0FdJ6AEg27pmghQbVquBKU+vDL7evLpXm7dEiXQbNSm5d8lvtYuM/91hxvOo99BsdD+fT682uZKXDjXv3sJcPfOwOIM6RSSFNC+sH5p8vfX7qQUlKjiGCTKpXy6gJB/ln2h3MhuiZW6FiaHZFZ5LvY6/PICMOceJXGlkRePAV461r1tmuV4P9B83s661ixKDEX/96f0ESqZzLkPWPlL9uWem6I8UEVCxsuYfejM9jM+e0j6aKNURlP77P4t1uY4UOVrJ0EB0/59n9w387Lb1wPfZMjhI92ccuRxD6teO5d9kTjuN/+bPG0rGgHevgDYtCL9c+qoqq/vd6dtN7bL/H7GvBLwfnqlNrH+L897u61is/gD6/lYjFINeHW/FNyiFIV58xzle3XEUqZj34xoJPP1zitXNTB4w6NzzMqfvVlvvpBS2Y/t7H++3uM7vC8EEtPkns2STiGt8yHb9my0J7DV2X3Wih/Sp4Rqz+3hHelpXD6+Afj0ZvvbLEAMEhWy2Wcmvi7kAMOnNyk9kZYvoDkcqujm7/eJCcADemWuDbax6G1l6LAfNxj5JH6z6MLfYmsOepsBIBywkSPI4c/3xIT019YuVgKTC/6nJJA1supXpfqJOjrnoT2AF482v+13LzJXwl190FNHtyz7Elg9L3kZK0PrVVKmj5hZ/C7w1rmZP/fIaKMVKv/8/p61qmsfX6v8m09TSQv5GmHX7+8p1xY7SXDv3zX5gfa1U4C3zzNe/qVjMzyQWeXS3yoaVc5BqrQKVUIJBr15rnLeUBNZ39Y9Oa/asi+Abx4AXj9FZyPqPq5p87o/7OVOMcXu78al3+ntPd1ZT1Xz74/Kw+W7FyulqM3mxIlmKeLh1Tk2nm4q9kUkoIwu2r4e+PubRDVas2YeClzTxNUmOuJVns+HR3qz3nzx83PKfvzDkw5W4sI+G9zmwjXdg2MnEjafF87Jsfvswcq0yVSVmzIHoj++QQkuPTxSmRKqbUNoR+ZtfjojcW9XRTBIVMhS5xkXknmvJUYoqNV3whZ7mArZttVIO0Ev/VR/2f+dqQwd3u5C1YxCttpBfp5oRHkQWv9n9mXd9Ph4JdFtLqVOtwpuV6rT3NpVqVQx6zDjz6ojBbRD0VNFI8kPnrpMXvzVm5wnxqe/ZycB7VUNzOfGuLJ+oicp20icmQd7/3BoJQhF5syLTRfNtD8b+e835aYwsEXJSZLtoTAp/1COg4PRiHI9TX1oeO1k4Npmie/jpdo1y71xViIgu14ztedvTUBJDbzqTVnUGwnr5WgeJw9G/81nwl6/qOflNYuA61umB1y/uke/EmNOpskKna9j+5k2mPLyVCVJ92N76XfGpAYitVX5lrzvQjtdpJ1i56UlHyi5N4uFep3283q9aYVyDH3zgIUP6V2TLJ5LzdyDv3KCcr+UtBmd7az6NVEdMts5feGb6c9Hf6d2eMTMaJs5if6nM4CnJ2XeXjZVqMPelSCREGKcEGKREGKJEOLCDMsdKISQQogBbmy38BRrT66NG+IXj06MUKiKPdx6ln5sLWFvVWVnf1n5s/IgdFc/+9sNmkxWq7UillDeTNJLld6UDpU2N4cZ0bCz4Jrqx2cSX886PPnBU1e2oc06ow9ShbP06uhtyyoTyUW3BzV/uxU/WFu/lX11W4b8WOTM7NP1j99sPZlf3K589s6+Fjtl3LqmZVjPhmWJHtNvH1aupz/NTM7J88uszKsXAlj7u/H7VzcBvn9C+wG9laS3NR+v6cvnKjne5tztd0uqpviInFieLbXSnuq9S5RqdqnHqZv7UuVmYOvqzMukBj1Tg0GbM1yfU7lV8S3VtrXAJzOUIFS2kVZ+e+ZAJfdmIZv/eiJIYXZ/1J1eaPKzW1cD/8SqlW5do1TN09r4V6Jd2Wz4C7izX6L6KaT1ETxLPzUeGRoJJSeYn2cyj+cDwxNVRVfPyzyKZ9ZhwFP7KV+v+i25LX98lL78mgXAd48ary8p159egDiLdy82t1wRcBwkEkKUArgXwN4AegCYIoToobNcXQBnAsgyoZzsycObMrJu49+Jrys32wtM+OGzm4HVC4EfnrKQ1M5Hdm48Xzwm/bVQpVLlJpvNOr1Of+ucCtcvzVydR+15AZS8Ptls+if5M9ls+Tf2Rcrv5/d3NF+/bW67mZi9SdEGp7xyazfj96TEgpWa4IAbATffVOFrRDQMzH0s/XUz54HN/2Z+P7hdOVerVv1qrW1WVW5Wbszv7KuMbAASx+33TygjBhe+qX/sqMsZ/twpx2U0pIxk1e47K75PLsVsN6fe7NOV3HBW2Q0aqNdW7egO8s47FwN39E5/Pdu5/9UTk783HEkU2w8yjUD/9SUlgPr3N8D1rYAZbYBbOmfevpNRgFb3zdULlQfePz5S2nllfWD594n3jTqXnj0I+OQGJQj16Y22mxvndMpesVdhfeGoRJAiLsvv7KmJxtML1Y9uWwss1hlh9tAI4NExytevnwKsMpHn0cjcR5UiKM8fkXgt2/1ZqtQgldbntyWuQ04kdUZk8MCuyd+rVVxTvXlO8vOU1tb/9F/Xm76mVwjB6lTTAubGSKJBAJZIKZdKKYMAZgGYqLPcNQBuBFCF5hSRKZkuUPnYI+k27fB37Q3RjDbALV1y3x6rgtuBj64FHhur3PhnS2qXzY6N1pNb5oJewtRvH1Sq3OjJNnootXft15eAu/qbb8+it1JeMDiOPrne/DrfONv8sqrVC4BvHrT+OSD78f36qYmv1y5xr/yqNkeNmkDeDE/PR3mUv4jMu6OXcq5W/ZeSWystD1AGapXEr+5Kf2/zv8BNHZRtqT23S1IC8mpv8azDko8dQxYTjAoBPLwn8IRO9UH1Or5tnTICK5sfnlKmJhSz+bOBD670uxW588sLyoMvAHx9r/FDGmD+XCqjykO6Op0z/jl1f8swAvPlqUo+uhePBoIGxQmscvMaoE6Zmf96Im+eNuhzTWP9HILaQKffiaK3/GeuCusfHylBMHX/KHbLMswKUHehp/dXAn6po2jU0WrPH6GZIpzBoreV362Zqfbb1ijncADxY0jKzNNwM/0sWzJ0okgZu5c3ccxENffL4aAy9XTRO/pBNLOy5Rgy49au6a+tng88PEppZ5FzI0jUCoA2LLk89lqcEGJnAG2klBkyplYBVSHgYUem38uPT+euHX75WlvSN+V34daNjadShpE7dWM74FGjRMIuWLskMczViN6NWepuuvz79Nw82ov0MwdYa9fs000slNKIPz5WHkR0G2jC0k/0A3JWzlX37wq8fb65ZaUEfnvFXp6Je3ZRyq/qrdOKyk1KjqZc8Dpx9Zx7lWk0DDCZV7kpeeSPlpV96cNrlECwbq44zd/j8b0TwZ9wMHM+g9XzgTW/6wcWPrs5sa3UfCJ6uVwysnjMqL8XtTx9apJ57TKzT3O3PLlrfLj/euFIcwGzQvHmdGX6i5FXTkgesaDL4rlKRpUgit5IXrfoPlxL4Ged6nXrMiXBN7GPffdI+nkm03knrTModZMu7NdO1hEwOJcCyXkF58Tucwt+JJ+T33fKvq/mjzS6H1rwP/3fb+rf652LlH9nn6HcX11ZX5mWZda7lwBXN7SXry3TvhPcClzXXOlEzka9tiz5UKkq9v7lwHOHKkE0Jyo3K8Emt62Ya31EVgHyPHG1EKIEwG0ApptYdpoQYq4QYu6aNczPQAB+f9fvFnjH6gNkvgYZvWhXxikbdran+cxvL6W//eIxyfOcMyV3Vj2yZ/rPrp269Kcm0Z5enqHUH8NMtZHU7T09SXkQ+fFZG0PdFyhDojNVbIrLNNrPQk6En2YqVaDiAUVpXH7eLKsBJ0u9Sym/04DFYgFW/iZ2AkrvXgw8MsrcsoU4RDoSdvf8svh9JbHljDZKD3gqNZijZbT9z28BFuosr3wo+dtF7yh5Jq5tmn20oJUCDuFK4HsHVXbS9rks++DKn/RWkvhy+3rg7zn222NKSu6j1QtMfixlBIpX9KYnFIvvHgHeuSD5tdSHUcORmTaP49TrS3yfdfG8oM3LpZ0++eo097ahenM68NXdsdGsJvZFOzmHzOZC+m+eMs3NK9e3SH/t2YOAD6/2bpu5YqsDyCA4GNxmLRlyfJRorA0b/lT+XTBbub8CErl6zFw/v7k/0b7t680VDTEzqlsNcP38XPZlV3yvVAB85gD9kbR2bFimXOufO9Sd9VVBbgSJVgDQjLVG69hrqroAegH4RAixDMAQALP1kldLKR+SUg6QUg5o2rSpC02rQtTRAMvnKgdGLrndW75lFbDRRIQ2l+Wljba18W8luLDsS+vr1Hu41R1NUiijBLK0c8EbmZMyu2nDXxmGYeu0U1uZSK26Z8bi95K/N3rAU6t3PX+k+XVb8fopwI712ZfTUnsoVy/Ufz8pUaHOjcaDuydPd7nPxJDzbSlJQwNbgRta6S+rCgcTvUx6tpscvh7YCsxop5/o0CyvygY7lak3V+W0okeuRcLKdIv3LjW3fGCLsqw6um/j38mJxretTVSzA4Bbu6Tn67KakNLsA9xPzyRyoWTrfTQzelQbrPzfGebaoLqyvjvP12kPH1KZxmC2uqAb2/3lBeC+ISZ7ih380Gt+N59rSm96gl1zHwM+M5jO7JZVv1mbNiGjyvlYvUdLzRGSjRdBHimVEYI7Nij7oKMqphbat2lF8sgqsz/S+5cZj2ZNvdc084CdyuxonfuHJaa55dLnt+Z+m25x0mmhBoJSb0Fv6awESMza4GT/1ti2On3K8k3tzR3Td++sTBlePtedtiz9ODn3pRtmHpJ9GSfPkfnace8iN4JE3wHoLIRoL4QoBzAZgDr/AVLKTVLKJlLKCillBYCvAewnpXRpzyoSd/YDXj3Z/ufV4d+PjFISWhak2MF6a1clz8Pmld6W0nWDWo3M7LS41IoephTgiShUmf5g//zhwKN7WVvP8u+Vh5pZh1v73J19lCBGnMkLQSScqLqnZ1vK1JIVFk9jC2Ynf39HH2t5iNxKihsJJ3rz4lUvNFIT++mN6Fv5s1K5RGWU1HnhG8pIJ70RQ2Z+f88epExBdGrNQmUajJmhzxrJ9xAeHotOenTfMjMarMBEYsEevYTTga3pQeBPb1R66H94Sgl83tEbWLso8f6XdwD/pRw/qXnB9AI4VnPmvXqiUibbrncMC8QmZJuCkpVmVE3qlNmMy2uoU960vx+nDy9mqvVo26L+PdcuAlb+Yu78aOeh4N6BSjWeXHvjbGXqhVc2LVceCM1OF1bdM0C5R7PD6kizjzU59Z7YJzFFR+uHJ5URgp/dooxIMFG10pC6f5jpELi9B3BLJ+DnLFUEs9IeX1b3zwK5P0wNRhSif76z/9mFbyZy+zxzYPq6/rBQYMSKbOc77T2cej1bv9Tcumefrj/12CufzHB/nWael7992N5UvCLgOEgkpQwDOA3AuwAWAHhBSjlPCHG1ECI1HTwZ2fAn8PNMJTnlx9dXiQhlVlYfwM2IRj363Zq8sH9xh4NN5OuIIp3f58Mj9R/s9ap8bVsHXNVQGY2lzcUx517gtZOUr7XBQu3fb+mnycP7Xz8NeGRM5uam/h7fvSTx9dYMUwUCm0wmg7Vg41/ZL8jaxLfaKWxOZJuilRokigTNDUE28vopyoihzSlTEV4zERg3+pkjIWUOvlUWj/+cnYpTA4hWeD16I1f+m6eMAtTS+wO8eLQSBNbuk2ovbXArcN9g99qU62txaonuJR96c3MMKA/cdiv22d3nftIZGfHby8qNuJncSka9zQ/u5n0gp9juy9S/4fLvgJs7Aa+eZO5zmZJFuz3y+S/NKG1tAl3tsa92YminjeVSakU2J/y4z7OwzS+XrMWaLWYCy0XIKFfmuj+yz+BIPW8ZrctKoYP/TOQdMnXflq/PFik+ucGf7b51LvCLTn6yKsCVnERSyreklF2klB2llNfFXrtcSpl21yulHFF1RxGZuMF4aarSI6o797+KcfuGLBpVkrNpgwKuKbKbRzu0NxpWHjyWf6sELZ4Yn5zk892Ls9/0PbWfplIDlBFdeiNjkhua/O2cexJfZ9vnzEzrMU2zrUx5clKntLm9bT16JULTSsDa8G1KFbTKTfbX9eenSg+yZQ6O1X+y7VtOFMiNmpfuH6aMAgSQ8feh/h2Wfpw+1TdbVcF8l5rT5ZkDlJtjvRFVdqk5wTb+lf6eXk4dvUMm9VxpdipmUqGGmJeOU27EvQzCFFuAJ5Ov7gH+sjhiZ9saZWrTvNeUYgRu9ZyrVa0cTQHTkTR6J3au0F4rtaN+rVSwzCW3puo4ZebYWPgmEA7g8Ee+wSEPavatqnRcJdFcn+7e2Z0ZHAveUAodmJXpflS9B4/YDOglpRvIc3f2VZ7rvNwXC6KIkPs8T1xNKf75Lv0mTDsNIxx7WKyiQ9s8pSZATH1QdW39UqlAk6nsazHNf92xUbmQPLlvjjec8nvYnCHPkTpSxWyv9/zXsmzawd9AW3Y91f0Z5oDrJdj1w3IHQ629YPlPoUlIapcnATvKLMPfa9ZhiXxf+XZ+zGdGUy53rNfPqaM3mk8NNC162712/ftD9mXsindcVIFg7HuXAI+Py76c3jHz8vHKCAWzucCyeeMc5d9/vjFeZrvFfHoAsEhTgVSveIKpggwx2vuyhU6nclqgO0rWwf7570/uPNz/9rISwFJHZ/41RznXvn8FAODPtducb6MQgvnRaPxnTshwnfnmISXVgrbTb9ta5W+y9JPs29ML2tv183PALy9azJfq8jU0V/lxNyxTOnt1K42SEwwS5dqjo9MTvCblIPAgqZ/nvLrpKrDfwYY/lZvvO3oDc+4zXs7OuvORmn/CTJJEU3kvPKBOq9ImN87068x2Y/y3haHAqTLlGlmfoVLEz3byWGVRFA/UufkZSkMWK5pp/fmZN+VX0+TpOcIJKwH19y5LBP8jFpLwmpFpZKLd6Z8vH599GS8ZFYb49UX91/WqzajnypenutMmO6ycx3561oXtVYHOu2gsMKA34gtA1nPNhj+VzjLt94BxSe7QDiVZrhOpU3lW/pK5muMdfdJf++g65WE+NU+ZJRavSWoONLeux7bz2qRs/6XjlPymb5ylfK8WxdALYtjt+LxnF3ufy6WVPyq57PRsWw3MT5ks8/Z5Ssn363ZKvKbeH2fqPHYiU1DzleMz31uqcjnFce7j3ifj94IfCd7zAINEuaReCFKrEGmjn6kHazQKPLa3u711uRSNGFdPApSTbMigV6KQHmS3rFR6DFTvXpT8/oofgHcuyuO8Qim2/Kf09Hz7cGJO88pfkqcHpf19Mvxs1zYzfs/q31ld3vbUH5/+Bqk/Z7YqR56yeWxZLQHvpRyVmq62w2T1ND2VG82XX9U7NwS3Aa+dmr2nfY3JMuCFKFwJrFmk9G4b0QYxPrvJ+zapzBYsSPXri0rPslqVNNeCLhzHfvbaLnwz5ZiwcE7/7SX729VL4K/n5eOBxyfY306uqOccM7lNVPNeyb6M3ki11HNUuBJ4en/ggd3Mb9uslT/pT5lWpQY7pMzteSPVGk2Cfav3iKs9PPcv+J936851FWY7Mt2bzn0MeOHIzKkCAGQ8N4VTPmu1uiYAzJpi/TNGtDm/vPLGWd4l43/jbG/Wa6iAnlFtKvO7AUUvaBAACW4DymvHvslwEgluUUYvmBnBMMeo58dHH12j5Jk5bS7QpHP6+y84KAn+5L5A38OA/e+3vw6zsgUyln6cqPai57GxSg93407utssL29cr5aEbtFV6P9b9Aew9Q0kM2moAcILDKgyhSqBaDeftfDRLgmojhRKo85LdBzyrVea8smkFMPs0mx+2emHP1Y2Azn75/RNK+fQa9YBxPiVtzIVvHgS+Th19qfl93DtI+bfzXkrHg6u5wXzy1ES/W+DcSzZGEa36FXjLYjWtVLMOU/4dqpwDdoQiqGl1HZWblYfzNgPNfyb1oc6I0YisXJNSGfHVoC0wWCe58o8OR1fdWOHs83985Ozz+eTz2+yPYtSOVrTa+bXpH+CR0UBpOVDi7SPdL8s3err+NKEdSuW9UVcCtRvndttmZRtdWEi3m0/v73cLnHFS/IN0cSSR16IG826/eSDz5+yMorEThda6rSfw9AE2PpihreoFL1Ovjp31quxMxTH6m9hheQiinSuGBw+pf3+tDIOVMr36gZq/Rx0eq83nk6ninNne6Q+vMt9OPamlrwHl5zCdx6uQrtoeecxCckStv792tx12ZapC5+ZncilXwctwUJlOsFanlLRf3j7fXM/yDa31qyaSP+yOynE5L+Bt79uoajXrMGX6f9aRABpmS0O7betqc9O6U33zgJKrw6jE/TcOO9iKpaqiGyMoPrzKnepq21ZnXybV8u+UKnBuVT9VpRSW+G9zYuTjLte87+629PzyAvDDU8Bb04GXT1DyYPrN8rNZIdxvFkIbyQ8MEnnO4ODTRp+THg58zEm0ebmDOc0mBLdby01jpRSkX8xWdFE5eRB08yHysbHAQyOU3vvrWygJD5dY/NtXbrS3bW3AcN0f1pP1vXuRMvVN66oGSuU6M5KqouSQl8eWVZs8mh+fCzs2mizrmkLdvy3e5FXfvMz6tmzJfHzfPnM2PnnlYeebeXIfZerW/85wvi67tqwqrOnE5J3Uc3muqEEXK51GRgm/vfC6ZqTkfUOV67VVmfLyEMVlu7dMf3/dttioKU/P47F1z3sV+PUF4GuXZg0EtwF39jNRAdBgCrhWtp9fr1Mz36h5yMiabQ5SERQIBolyaHOliQMxNRBQCBUAzEahr28B3DPA/Gq/fchec/KReiFx0tPkxcV43qvKvw/toZRa1iNKgM3/pr/uZGjq398oP8/dO2dO6GzE1si0mLWLsi9D+uyWU3XTje2UQIdVcx+1tbny1b/a+pxlmYLAUuLs34/EiF/OxbqtDv8GmaoM5cLaxUoFrTn3+NsOyg8PepCTxop8DVZq811tt/kwkikAtsaFUS9UReTpMWLXql+VhOofpFYuS6GXLzU1ofsPT2Veh9OR85S/8mVasYcYJMqhLdog0fYNwM/PGy+s3rjc3MHbRnksWLk1+YWMGf59vhBFQkquhK1r/G1HGpeHgma7KU59WP15JvCBixe6314GHtsrEaCyw05giQiA1fPMm7/maJraNr3zjnIsPj83cd5889eV+Gf9dntTbHLpq7sTvah/fg5si+XBUqeVmSkJTGRCvxI7UyfTR21vDYSxYZvL1fH8lFr1S+teC7mYqOrIeH/o8bSkhW8pFeayFWqwYsNfwB8Z8oXqkVKZWvrkvtmXLYSRQkQ2MUjkNaPe4a/vBV6dppOHoQDnhmaY117+X+wEalT+NJ8sekvJlfD2ee6vO5+SJWdL7vbgHumv/ZIyRcsoIXuq4DZg/Z/67znJ77Auj/KpUGGxOHJge8D/odjbApH411ICU5/8Dnd9uNjHFpnw3qXAg7srDX5yn8QNt3rDvuQDZZn/5ut/Pp/OmZTXJpTarXSZbPiNH6F/LnKtEOUVzTXxk+vNLady8zytVqlcE6uI7MYov7v6A09PSn4tdb3b1iZ3Wsx9TPmcKUU2yoosKP6/PYNEnkucQHXPd4YlcB3ufH/7PKUg1aczEl+H9Xvq5v+7GT//s9HDRmS5mKl/oGjigQyRkIWEyMnOe1HTw5BPQ9qzJYg1Uznof2eZ21Y0DNzVT/+9Xx2UIiayy0peNLgUtn/5BGvLq6WHN/2T9paUEsFQGCWwd17KufmvKf+unqf8qx2u/9XdzpPnErlk43adgLDB/QpR0Zh9eub3UxJYuyY1EbXVUe5myEiGN2Pre3I/pdqkeu//5jnm1/9LhhkhRAWOQaIciuqVSkx9za2o/GN7ubMeq/a9S/917cl/zQLdRQ558CtMvPdLDxoVb4T15a5pArx2kq2tvfj9cluf85zTgNWzhwD//uC8HQb7AZGnzFbhi3ElvPvrC9aWX/S28m+sLHxLsS7p7XsrL8LSGke40TLvvXhM5vfNjkokclPsXmvN5kpUXPgmXpybHpAFYL9Ag56VP3N6ChWe107WfbkyFEEk6uAKOe+V5O//Uaunxp6DTD4PVYYiuPGdhdgRzBAQWvcH8NF1sfvflDbzXpRsKf7RzgwSeS3rSU7qLrNy43b8s95GBZ9UTrOvf/2A8XQhKwph6oDaxkDKQ6S2p6Bardy1RxUv3Z0no5EWv2t+ulc+jaAiskHmwY3AuNLv4l9LAD2jNpOvb1rhToO2r8+esNOshW+6sx4iS5TjelnsPuu8lwyqrLl5DXtwd+U/I2tdmEJqVOzk/uFKFdOfnwc+vsH5dqjK63bZO9jr9k/sr0A7ksjBcfbUnGW4/5M/8OBnfxgv9PT+wGc3AVtWJl4rhOcSymPF/3zDIFEOCb2HDRlNGXKpLHP6cz9it5ssJltLNe9V4OaOJso8GghsAd65AHgiQyWh1ARzZk66zx9prz1eWj4X+CpWbSdTQtV6rXLSHCIqbis37cj9Rhe9pfnGwQ3yqycpUxS8yjUXCftXGp0o5rPf12DgdR94vyEpgXsGKtVff3/X/nr+/VHJ86Xnv1+VKqavTkue/k9kknD7ofjDq5QpXlfWB768U7Mho2uT/uvBsDIjIxTJMAU7opk2mikgxY5NorgyvxtQ5ckosOxzb9b911fKv6t+AdoNTby+/k8laeigLHky1KlwmXLU3NQ+6dsdYYmaesvt2JD4euNfuqvyJaa/8W/gjt7pr4d2AJV6P7e1C8iS1VvQtlFtlNtrXYoC7PX435l+t4DIEa9GEk1/4WfMNHrzp2cNz7uO7mHfOtfBhzW2rVb+jVjL72TaNY29WS8Vl+8e9XT1X/z4G1oKh6OxzVizEFgbq1a4ej7QZay99Tw0wrUmEeVEOJaX9ROdwGXqxU4IJU/ollVAgzaGi2V0V3/gCHWam0hfwW8vW1gZUXHjSCKvLf00/qXUCzA8tnfy97H56gJAbXjU0/zEBOVhwWwuCM0JNBSJ4pznfzKcCidl/gQy/ttciTOe+xGVoQzzlP80CNA9NQm4tUvie5vDUkff9hmufmOerc+mWe5OBZeMbu7s7vrUpLVElCScLZeDmrw6xceLVrvTgO3rgM0rsy/ntbBR8QaiLMI275HeuRgIKMl4Zew4bIoNOKDks6TFLl4wCa9Xv9xRE03Ry1dJVBWo+feSZLjffutc4I5e6UmvYTBbI1W4EoadvVc3An5/J/s6iIBEpdYixiCR1xYl8i3oDtUMpQRqYjc95SKEeTWmetMm7ageVVQvkJJ+wv166Tq88uMKXPTKr/rrdjDH9+3qF+LVcvduyK5/awFm//wv3vltVfqbaxYpc/ONLhbxBHrOffenzu/bjheOcmc9mUZDbXPpAZSoSOTb4PNv/1yffSEz1iwAbuuW9NJP/2zEpa/9CunVkPstOudiolzTVtiLeaz8ZtxW/gAaYxMiUYkb31mYu/Zojze7xx6nyZDHuoj0YiyOR9q+nOE5R+95YvH7yr/BrTptsXgM6K3/1xetrYOqrg0u5OvNcwwS5VDzzy4xvWxNuFB21UwP7dbVwBtnA88e5Hx7AJxMiWot1qJ/icmEyBY9NWcZ5v+7MfHCvYOUuflmb6wcDEG9c+t0IKpTWtcvRoktiUhH/oyO9NqhD87BM1//jcpQlpENdh9It+TByCUiHb1LlgEAShDFxwtX4/5PMiTB9UvlZuDtC4GQzr3dPzkYaUxVzz+JogllIlM5eRdZzElERN5gkCiHyrf8ndsN/qdOc8pwYn3nQmDuY8AfHyVe+/3dRLQ+RbZngzyabRYnIXH56/Mw8d6vdN+1xvoP2C3yu+XPmLJlFTDvtezLPXuIkhhQxaHtRKZ5lZPI7loDYQ+O389vA1b9ipLYzblhj+x/85Rrxcqf3G8DkQ9qbPsn7bXb3nf5mv3by8C2demv3z8cuDE5r2PG0dif3Qx8cz9wQ+v09/KpI4qKx6Oj41+W6FwXXEtmrTd1VOeBY+1W4zx48elmH98AvHRc2rtxb05X/g3tiBXm4Sg8Ij1MXO21vDj3yLTvBIAel7+Dl1psRI/UxWceovw75XnNJ5LlVeXI56YAhzwNlCbvzqaaWMhDtJ/cD1i7COi8Eiivlf5+JJycAPa5KcCU54BPrs9dG4kKnGtniM0rgXot3Fqbuz68CvjoWgihpNI2TJd0/zDjdYQqlWqYe14O1DZIPL06h1N4iEyotWEh9ihJBHAEgPkrMxTrsOOl44A2Q9Jf/09n2n6me5JobBQwA0Lkg9SAUHuxEuXI7cj0YCSadnOfdsSo1ftKqukvtSZ2Hfr3B5dbR1RcOJLIazaDKY+U3+puO5IkGrV0bYbk1c8dmvTt2i2VwJb/sqzZh+jRoreApycBc+6LvySlVC4mWRVgkCgaARa+BaxXh8NrfobQDmBTbN54ahW5pPLXRJRTKfl/8o6MJEYSWQ2eb/xHyS3x/RPA+xnyyn33iP32EXmg01fn48nyG9Ner+7GlH+tzSuSv99ukFts3R/A1jUGK0m5v/rlBSXH5Ma/gcXvOW4iUSbava8+tuLj6tNxfTWPKgxuXgmEU0YNicyPVGmd17/MSnytm3eViDLhSCKv5UUMwp3Azb0zzsUV1Z5GR3EzgCaebsuyZZ8r/w09BQDw9Nd/4a1flSSpGZ93Cm0kUTgAXNtM/71vHwY+uhao3AhcuQm4e+f0ZfSGvBORoXwaNOk19WfNVngtzR29El//9Ayw7x0GG6hKv00qVB3FCnxY/Tx3V5p6r/G/M/WX++kZ4Jfn9d9bq5kGt3YJ8MoJ7rSNyASBRMdre6HcX3uSR/TXF4FvH8q4yKYdIcxbuxZDOyijVu+qdjeG/bgK6P2U/gdYlIXIMgaJitmK73VfFrGKasJsLYDgVuDdSzC85DcAysWhPNIOWPJB2qIyTx4C9HIK6M+dLrAg0aNj0l/79SVgl6OV0qCqf3/U//yPBhdQIsqpPDlVJlPbpD0trl4IbF4OdBqd4QMpXpmm//ry7/RfJ8oTPUr+Ql+Rg6TVAe2UtpT7EKPpZBHN6Ca9HC5EHirVBIleq+5eJeI0hgGixF38uDs+x0o0xv2HK52h+5XOAXYAeHA379pFVMW4Mt1MCDFOCLFICLFECHGhzvvnCCHmCyF+EUJ8KIRo58Z2yZnHym9GbZiogAYAc+7BqFIl8DC+9Bvc9+8hwDMH6izo/5PPqk2V2Lg9cZO1LZBhznShjSRa+XP6a398mP7atrXm1lfpcu4FIjJl2drt9j5X4zCXW5IgADTFRtS/qYlS0AAA7husnOujFhJmz3vFk/YRee2J8pv8bkIGmvuVdXlYfY2KmoRAE2zCqBL9Dmg/XPyqTl4vInKF4yCREKIUwL0A9gbQA8AUIURqLuQfAQyQUvYB8BKAfL4Kuyx/gxCDSxZiz9KfLH/ugNIv3G+MW6IRrN+WnEsg49SJN8+xuIH8/XuakxLEYwJMooxcq96SImx5TpdHNCNCS0oE2opY3rmfZyUvN//V9M8+PNLDhhFVDXvf+bm5BbWdWi8e7U1jiDJ4pvx6POppzlRjlZH0WqPtd8xDzYDJTlEissSNkUSDACyRUi6VUgYBzAIwUbuAlPJjKaXabfo1AJ36neSZ8A6sWP4X3p23yvNNCb/nUFzdCH+tS07GbTkJa4GxVBI79e+zfqm7jSEqMkeWve/Jev0+VcZpRoRqR2Cmqdyk/3qmRNVEBSj9UdSdtTr299fO10Fkk4BEhfD+OcLImi2JRNbq0fRK9Stxwrfj/GkQUZFzI0jUCsA/mu+Xx14zMhXA2y5st0DkwZPA+5ej1SN9cOLTuRgi6v/Pe/KzyWUtiztEBFQu+hC4sn7Sa2u3mpxGSEQZtRAGVYiKndng+pd3etsOohw7p9pLnq4/Gg7h3z9+sfFBjvylqqvmxt+r7vWYyAeu5CQySwhxBIABAG42eH+aEGKuEGLumjVGJUALS6SKlV00mQo7p7Zs2YL9Sz73bNqI3+qL9Nwmt723WH/h7axuRpQP/A+n60mcIyOpQSJpYcQiERn684UL0ZIPu0SWNFn6evzr/Lx+EhUXN4JEKwC00XzfOvZaEiHEaACXANhPShlIfR8ApJQPSSkHSCkHNG3a1IWm+e+rP/LsofzLu7xdv8hp3NGUel9cg9vL78fpZTo5NYpUIGwQnGSvP5F/rqwP/PsTAKAkb+abJSsXSqL/0hXfAT8+m3jjzek+tYiouASXfpn0fbF2YBERUeFy44n+OwCdhRDthRDlACYDmK1dQAjRH8CDUAJEq13YZsFYtSnPpv28f5m368/DB5/mYgMAoIVwI2CXfz+fnk2VHJZOlJfm3AsAWLU5z64NAFphLZ4rvy7xwuun+NcYomKiGcW7PZih4ipRHvMmXxcR5SPHQSIpZRjAaQDeBbAAwAtSynlCiKuFEPvFFrsZQB0ALwohfhJCzDZYHXnIy9LJCfk3kkh1oAtV2Qqlvy8cKZSWElU1+Xtsvlv9Ar+bQFScwsZBYT54UyHIp71UAjil9DW/m0FU1MrcWImU8i0Ab6W8drnm69FubIcKQJ5cRfqKJWgotuCTaH9X1xsMR1Hd1TV6Y9/Sr/xuAhHpkRJfLM7Pkr11RP6NbiIqdg3EVr+bQJRVwzzaT7uV/IPzq73gdzOIilr+DvsgsmlUyfd4vfrleKJcNz+6I1ZSt5ZYWtpdboyaIiJvHPHoN343gaj4tR7kdwt0tRP/JX2fNMWTiLJ6ovwmv5tAVPQYJKKi82j5rUnfuzm4yUqCyfPLnsekEgZriApGrcb2Pjd5poWF83e6GVFRqdfC7xboaiI2+90EIiKijBgk8lge5nH2WH79wKUwqPJlU2pV6EyGlMxDv5Ilrm6fiDw0/Bx7n2u1i/lll32ZfRkicq7ElYwKREREVQ6DROSuPIuKHVP6rm/broWAb9smIhuGnmrvc6LU/LJbV2FR9aPQEvmZl4iIiIiIqjZ2s3jMysiTYpBvVTouq/aMb9vuUrIC1cFS9EQFoUVf+0HuOk0tLV5dhDGm9Ht72yIic/ofCfz2st+tICIiKjgcSeSxPBtYkwPF/QOXRKyNDmpXstqjlhCRqxp3cvb5AVPdaQcROXflJqDjSL9bQUREVJAYJCJ3FXtUTPpXsYyIPLTf3TndXBUbZEpEREREBYJBIo9VtelmxY9/UKKiVF7b4Qp4biAiIiKiwscgkceKfWBNuuL+gQVHEhEREREREVGRYpCIXLU16G7J+XxTvoM5hohIB4eNEhEREVERYJDIY1XtueGiV3/1uwlERHkv3ypBEhEREREBDBJ5rqpNN5Oyiv3AREQArOYkuqbaE940g4iIiIjIAQaJiIiInOo81u8WEBERERE5xiARuYpTKIioSuo2Hugyzu9WEBGA2T//63cTiPJT+939bgERFQAGichVVSwFExFRQp1mfreAiAC8wSARkb4OI/xuAREVAAaJiIiIXMGRlERElKdKqgF9D/O7FURUABgk8lgLrPO7CTnF6WZEVKXsNt3vFhAREen6ONI38c2p3wD1WvjXGCIqGAwSeWzX0nl+NyGnGCQiIlc07uR3C8wZfo7mG064JcoH783/D6s3V/rdDCIiKkJvRwb63QTPMUhEruIjEhG54pg3c7q5HcGIvYdKwcA4kZ61sp6v2/9iyVpft0+Ud6rX9bsFREVhbbXiH5HHIBG5qthHEm2tU+F3E4g8d0Noit9NAOrulNPNHfLgHAy6/kMbnxQGXxNVbfOiFbY+t1XWcLchRFWYelW6PjQlUVzhmLeAAx/1rU1Eha5p3eK/TjFIRK4q9iARJMdKUX64KXSIZ+teLpt6tm6z5v+7GWGZu0vUrys2ubAWnh+IVMLm8bBr4C6cETw18cKxb7vUIiJ/PB4e63cT8Ltsk/imYlegfhvjhYkooyJ/2gXgUpBICDFOCLFICLFECHGhzvvVhRDPx97/RghR4cZ2iXLN7k0vkdvui0z0uwmuMAoEjb/rc0tB5+WyCRZFW7vVLPM43YzIVZtQBytlYwDAj6I70G4YcNIXpj9/R/gAADw0KX9cFT7a7yak4wFClNHlIePjtio8DToOEgkhSgHcC2BvAD0ATBFC9EhZbCqADVLKTgBuB3Cj0+0S+YMXVcoXApeGjnW8lpcjw/GvbORCe6ybFjwbYZS6sq5KWY5HIuNdWZdd/2xgolwi1TrYz0n0i+yAryI9cEvpVOWFnXpj+9TPTX12Vnik7e0S7Ra43e8muOqhyAQAwC/RDj63hKh4BMMRv5vgOTdGEg0CsERKuVRKGQQwC0BqF/dEAE/Gvn4JwCghGMIuRtEcTg/xR1WIHVOheCYyxvE6Xo/simGBe5Jey9WIuS2ohf9kQ8P3rbTihcgezhtkS+JS9vniNT61gYrRwmhhTwe5NHQcAGC7rG75swGU47DQpVhS0h4AcMNbC3DAfV+a+uwqNLa8PSLVP7K5J+sdWnm3J+vNZGLganwV7YWKyplYj3qY8tDXOW8DFb9Z4RGmly2knHOZAhUrNxV/p6AbT/StAPyj+X557DXdZaSUYQCbAF7Fi1G0yEfarKvRzu8mUJH5yefePbeO2O+jnW19bnLwMsfbPiJ4ER6K7JN4oXp9x+u0Y5nMbbJtKm4HBK/yuwkAgNciwzC48h48Ex5l6XPbUBOXhI7DvsFrHbfhwc+Wmgper5O5rd7UpfJJzImkDp6nfDEuMMPvJsStdPjYs1o2sPyZn2WnpO/nLF2X+IY5Nsmhp8OjAVgbNZoPOS/JnLwa9iGEmCaEmCuEmLtmDXtkC1GxB4nm/OfO1BgqbvOj5oOJ94f387Al5r0bGeDo8+ttlLuWEGk3zkuj1gMtEZQgKdzVPREwCsnMx+xK2QhvRAZb3macZlDs99Eu9tdDReXk4JmO17EdNbBn4BbLn3O7p3ZxtDX+Q/YpqTeGJse//i/2QPtsZDT+kKn9huYJCOxx88exr7M/1A4LJEZr/Lc5YHu7ZlwUmoogquHOyAGebofsWyjb2vrc8MAdjrf9YHiC43VonRQ8C2tsXGeJvKKOBI9aCCeo5/F8SOaeyf8iQ/xugu/cCBKtAKAdE9069pruMkKIMgD1AaxLWQZSyoeklAOklAOaNmWksRAVfXUzIhM2o5bpZefJ9pbXf2XoKMufyebE0NkYVnkX3ogMwfvRXVxfv1kHB6/AlOAlAOyfT7YFwvGv9wrelHHZycFLcVrI+QM9gHiyXT98F+0S/72R/9y6Fi6VLX3bNgDcGT4gnusr23q1IZxXI8OT3utc+ZSt7QsB/LVuu/K1iSBRAOXxr2e8vdDWNs16LmJtZBUVjuWymeN1fBLtl/aaGjy2M5V0A+piVOAWvBkZ5LRpRK74LtoNAPB1tLvpz/wUVUa3fRbt40mbVN857LTLNuLJ6/bnAzeCRN8B6CyEaC+EKAcwGcDslGVmA1BThB8E4CMpOc6xGHkZJPor6vyi7RR3WnKbnaG3T0TGubb9xIOXwL9ogtNCZyQ9aGUzL8uoqeOC52Zdx32a0VTrUB9zoj3jbbLjrV9XYoVsbKqnyvk5K/H57bCee8UtV4eO0vzeqKoxGyAcFbgZO6T54/v28EHx80Ekdsu40iDRvfZYSg3ohFCGisqZprerKoS8D1Kyc6xQXBU60vSy+wYyT5PMdszpnY/fjg7GhMD1mBy8FGuk9WnRm1EHF4ammVr27vAky+snsuIb2R3dKx/Dl9Hepj8zV3ZBr8pH8HG0f/w1q6O5zYyo+zrqfBqwUcdEx8qnLf3MhcpxkCiWY+g0AO8CWADgBSnlPCHE1UII9c7/UQCNhRBLAJwD4EKn26Wqh6OUKJfszP9XRX1+aLgmdEROtnNi8CzcHd4/4zIfRXc2fE99uLopPBmjAzelTa2xGpQNyjIAQCXKsWvgblNlh90M/OYq4Tf576jgBa6s54zgadgiawIA7gzvjz+iLdKWGVx5T9prWn9Gm5sOEP4hWyGIMusNBRCJVSIsg35VF6/3/nw9voTIz3ZVRat0CiEMrLw3/vVTkb1Mr+tX2QH9Kh80fH9etMJSwt7452QFNqIuBgbux0ZZ2/Lnzbo1fIjhe3+s2YoI++rJBTtgfXrzVguj7bUqZbX41/sHrsLf0cydrG5N+fwp2jHp+4hLVXnznSs5iaSUb0kpu0gpO0opr4u9drmUcnbs60op5cFSyk5SykFSyqVubJfyDwM5VCzs9PKpvDwO2lc+k3WZ2ZGheD9iHJxxy7vRQfg02gffRLthRjiRj2SvwI2W17VEtrY1tUbrjehQ3Bk+ADdq2pLpNnirrIF/HE4r+Hv9jvjXIZsP327I1wfoYrRZ1sJn0b62P79JJm6Qf5Qd8UYs98FK2Vh3NFq2fEBhzX63WdY03Bf+yXJDrfrKIBGzmnMwbHCDLCEwInArAODVyG6mtmVFSZZ9/Mdop4zvU/H7UxNkVa/ha2BcQTObbaiZ8f0Lw+ZG9bjJ6Zl+yeotGHXrp3hx7nJX2kPknLl75iXx/HYCP8rOmu/11ihxY3iK7RZJiPi1VHtt2SztBbgKUV4lriZ77CR6LUT58AiUixCY1QoyZOzllLwYxUCaOm2b31N/cVhdbQdq4NDg5UnJaX+X5vItrEfmSkRWg20RlOL28EFZe6nUinIDAvfD6VH98k+JFHxbUQsHBK50tD7Kf/eEJzr6/FTNFEw3A8oVlTPRJ/CobpDoyOCFOCB4JYDMe/yQyrtRGZte9m/KtDI1SPRiZHfdz0oILJMtUFE503bC4EyyBUKdJt8nf2kLPqy1kKD57ODJppd183gzs64HwvvgtODprrbH6c/w+k//AgB++HuDo/VkwyTbhcnKdGQjm2QtXBg6Xve9b2N5jLzyUaRf/Gsvnht3WEjHUOgYJCoCHL1TXD7SzNMl+1bJhpgeOsX25/90qZz5wMr7XFmPNdJ0tYn1FkqX2mX08LZYtvZ823peiuyBisqZqPQgh9APsgveiQx0fb3kP+3NpxO/yzbxUT2pgY9sV/PlsomtbX4e7WNqREUAieH8l4SmJr2n3mtEDCoGmrkhfzI8xsRS+rL9bvy6F2JOInf8rOmwOCB4lenPae+ZvJz616fy4aTvzWxpRvgwvBEdavh+pnVMCFyn+/oOVE8ajWjV3R8tAQAsWb3V9jrMmBi4Ni9yiVZlds633QNPxL++NnR4fHSoFb9EO2BWZM+015dEW+Iv3Xtr945btcqsXqfCYcGLLa3rj9jo9vkyEcB+ILyvg9YVFgaJikA+TTPwsiW3hw8CAEwMXO3hVqjYmC0hnZrL4PzQifGvh1Tenbp4kkwX4jVoYGr7bjMz9clKD6wTH2TIS2RG98rHDN/7JNIXP0Q7G76/2eWcDwGZ+ntNf0A8KXQ27tUk486FfLoOFLJM5eMXOyjlrrUZtXFM6Hw8Hh6Lf2Qz/BNLXr/WxBTX/U1c/5yELCQEtsam2KSeQ9QgTInhg3j2LWcLDO8XuMbwvWz7uF/HAHMSuUP7W/xbNnd8r6cXNIw6ODo2Q/9aEjIImjq1QPNgqhVFCfoGHvFkm5Tfjg9ON73sgmhbXBE+1tH2VslGWCbT8+RlYxSwN1uoxSivp5lzfKYlvor2MnxPb+TTZ9G+2CtwI16M7BF/7fHI3lnbUCwYJCJXedmTNzu6KyoqZ+JnybwD+Wp+lkpXuZA63Ueb50YvKazqL9k86fvtFpLxrY8Nq94g6wBwHhRRbZPVMTRLgEpf8nH4v1jOkwXR5Ckgr0aN84bcEjo4/vV5JqupHB68CPvoVISx+/Cmdz5ZJ5OnqB0TuiBjNTa9kVJOHibNfnZJ1J2Agl33V6HeLjctS+nltDqFKWJyVMkfslUssbrAA5H9cGzwPHwQ3Tnr/mUm6Ow0WHJp6FjcGJqML1JuqBMP2Mr6A5okosqr2X/2bG37RXY0fG+zzWSnbrGTpJisSN5/zN7rmdnfd8jyWElsa/eomdbsxv3uBVmurZ9HEsdgoYUiBSRui3Xukjs+iO7iy3a/jNirnNq18gk8HB5vYsnkY+ndqP51V+24UO+vMo3qEbB2jM6K7ImLQ1Pxcko+PSV9QtUcLcogURGoCtPN7CTCpdzbkiXJo5cODFyBAwNX4F/Z2HAZo/adFjwdJ2Toocl2jP0pWyAiBc4JnYxelY/gcZdK1M+TFVgJ458nE3XayEnBs+KBMivToJ6O6I+OCsgyPB0erVs14stob/wmjXMcpV58zdL+9r2ez55N6p6QLwVi1H10VOBmTApcnZS8uypY7FJQTps4+vNIL5wYOgfLZZO06iZ6JgauxuDAfXgqPMZSoDiKklg5YBHfv16N7Gr686m7oPrQbLyOzDvtZtTB/ZH9kLq3q1NYSxHV/ZzdURo3h4yrMGn9IVvhf5Eh+DVaYWs7lN2BgSv8boJrLgkdF/+6e+AJHBzLyeUWN+69M42sEJA4MnQxHgkrIxc2pYyKNZuI3k+vR4djXh50HlJmqZ1vqY4IXWRpfeq1IoByWzl8JAQ+iaQXh5gVGYkjgxfixNBZAIBvZXf0rnwkZSqo/eNyZmRUxs5kL6sR5iMGiYpAVZhmYDYRbqF5ILwPAOClyO74LNIbQGEH/b6PdjE96sRtP8lO+F52jX9v5ff4RnSo4VByM7agJjoGnsXH0f6xpMkCd4YPiP9NszHKM2J3X5AQuCp0JO4N74f3U3qeLgidAACYG5u3bWQT6uA3g4exy8LH4Ybw4abbo/4UYYvD8r06s+ViJFGuqe36Q7bCT1VwtOVH0X62Pjc9eFLS93r76PDAXZgUNJ4GpRIA1qI+Lg8fm1RxzAr17/hwhtK9t4cONLWuSzUPyW5Qg0BqlbHUIyH1Idb8es3fip4eOgPXWzj3uElAfzpiMeQkUkfAac9vV4SONv3576JdYiN17FsDZbrl3eFJGZd7NjwKvSozT7eaHLwU7xuMRnDbKzqdH2aro66RDbIuc334cAysvBcbUkbFZhpZZ+Y+bKvHnXoidlgU/tFRWNws2CLi53prf8XXI8PiX2s/a3T/9KNOJ8wJoUTH7V3hSeha+QRmRUbi82gfbEad+HtbUCvp/n1JrFP092hraPe+nSsf0N32smhz3ddTWzqw8j7sFrhTd9lixSARuaqQAxx+UHuRKmU1w7LChSSEMrwYGeF3M1xnZ7++PXwQjor1vmTLWZA6DcwNm1EHN4cnI4JSzAqPxB/RFnghMgJLY70kZkIdbk8ftBpeCcZGQwlInBQ8y7V2uHuWsj933ms/RTvaTnRcVbwcTa7U5WTfcCvZPZB+zjkzeArOjwV474wcmHEUwbTQOfgs0hvbDKbMvhmbfmpmu5ne046C+DLSE69FzY9+0sqHY8WsXgHj/GiFbKPmoWtA5f0YHrjD0ufXyfo4OHglngjvZWp5vd76bbIGKipn4tZw5pFll4Sn6lawVKd7O2HnfHlR+HhcFToSowI3x18bEbjN1GfXoj76Vj6U9PsIS+XRTD0uoigxlXRey8x9mNedr+n5+ygXHknpYBgbmIE1sh6+jXY1+IQ7jg5egBGBW9G+8pmUVAbZr6qPRsYnHT9Ack6828KHxNIKZF/Xe9GBGB+4Pul6tEXWjKcemBPpkbT8QcErMSV4Sdb1rkEDbPF5ynOuMUhUBBiYKQ6FdKNsZHbEuIqH18wdB/4cKwMD9+Hp8GjD943+9mZ+phtDk7FV1sDIwK3x3uDUta1EY4wK3oqVaGypZ8jJPjkrPAI/RJURLR9H+iEgy/BUxNwDhOqQ4OW4I3wAtrnc4/mPyeSJeox+b4FwxPY63ZDeKoFJwWswPnCDD63JPaO9+SaTU5lU22xWvKuonIlNcP6Qem7oRHwc6ZuWJPv16HC8EBmp+5nUffKzaN9YgFr/t3Jp+DgcFbwAm2XiuNJ+bSQae3gNoRQnBs9KurF+KbI7pIlbSr3jJ2SxgyRTono/bPegSqJXnjIosqA9169FfSyX1qpSWb1S2Lm2RKXAmMBNrq9Xa2lK8MrofP9geEL87x5FCR6P7I0/NMeslWvWJtTB/sFEkm6z9/Spy40NzDC9TdU26c2+G5EiHtgqhnvbfKcNzqppFRbFigQskm0xMPBAxpQK2WXfJz+N9sUy2SLtOmDury/wh2wVv2d0ar6sgNrmy0LHYKJmJPDfsXPb79FWmBneE2tRH3Oi9nIuFTsGichVXtws3RCa4vo681khXU61Q0pPDJ6ddJPkhunBkzLOD97DZG+dU3p/kzvD+5v+/EbUxVXho3BOytSWbP6KDYMdUnk3Jgauxm6B29OWuT+yH3oFHsOfskVSb3A2doPLhwQvN7XcheFpOCB247saDdE18FTswm3eYtkad3iQ+PIjG4nF1X39pNhceJWMjakPhPXztPjNyTTKQmL0IPKSpiqJGdqqhtmOkV0q7ze1ziODF2J0lodb1TzZHseGLsg6XW12hrLa2URQis+ifXFZKFH5xsz5QDvd7N3ooKTRDeqoPzvUUbRmR4JkSlTvh19lB5wdPLkg8lV8Ek3P8wHoPwJauReZ50KeqN9k+4zvPxsZpVsdbxNq4+XIcBwXPA9bYsHOTKN3MyWXPy10uqm2KtOt3et00jtPW137Iml9RLJXncyfJE3/TexJd4YP8GR7Vd030e6YGVY6EZbLZpgcvBQXxkaemnFO6BSvmmbJI6aSXFvzdGSvpAI28W1FxuPicHpFM7NHxKCKRg5blv8YJCoCqVWZ/OR2kACA7oPvz1Hj5LheUufMu2VhVBnuOzfatSDHg6mjY7bImng3aj4pslkvR3fHqOCthu//pTO9I9Pv8dzQiXgzMihrIsVTg2ckfb8RSlK/TTIx1PRXi/tgGGV4JWVqS9oyMnFKnhqcjsvDxwAAVqExfpad8I/JYz3TjZ/T/ayqVhe8K7w/elU+gg9NVhfJ1fH8SzTzg1WhqoxVztKr7qeXT0sbJNKO2jPTi71akxdEWw0v22fXmbwefB7tgyVZSr9bdUv4kHglx2ztNJpm8Ho0kbtiR6yDJ9Oa1HP825FB8dfUEUg/Z6hKlklECrwXGYBzgidhPxN5n/LB0+HRadeIV6O7eZ7jxQ3Z9pVs562Kypnxr3cL3I5DApfh6OAFuDcy0VI7Uq9RAyvvy1ieWu8ziddLMD10Cn6UnXF+6ETMCE3G99I4P9JewZviUzdTbXZhNKBTTjoKrwodaSlR9DyLHTd2aIO6t7PamWvejyTuRTagLi4OH4/2lc8AAL6O9kBlSqe93n4VlQI/RTvgUwvBY6vs5GzzsrNcXbfTn61lA/MVkAsVg0QF7tjgeTgzdJrfzci5icFrs2bj98Kd4fSEoatNJB40Mld2w5DKu/FaVJtorvDCRYtcmtv+lubhw2lFDL2LzBLZGqeGzso6veGzaB8AwMDKezEycCtCKENF5Uz0DSSSZXoxhPqBiFLOc2G0DT6M7mK5x/yPWG9JpvxWK6DkXPgo0t9mK53pV/mgL9t1g14ejHhRcJ+GAC6JBeb9rCzotorKmVgP4/O73rGnPWv+qBmyrres9jwDACMDxoHofCVRYiooMSpwM44JXpB1uSnBS3FT6NCMD8mLZWtUVM5MGhGojoCwu/93DDyLFWiKV6K7mw6CG/komptz2mXh4/BmND2v0zc+V14043uD5NJ2rmf/yOb4VnbHp9G+8SkmaiAnNen1TaFDM65rDRpY3v6SaEtcqhkNByhB3gd0KvNp/SFbJU3dfC6sP41TK5rD5OTq8WXnkHo8sjcmBM1PMT4hOD0t4Om2U4Jnerr+quLGUHLFUu2zx9fRHlCOYmuP9R0Cz2JS8FrD98MG6zskcJluB042+TD1UD1HOW2LEIX3rGYVs4oVqKnB6fgq2hM7DBJTVgV+nGxCHhwyq9JKnPt/EjVL7X1eJ+tlWdKc6aGTML70WwDImkhOO6oHyPxbmxS4Go3EZtPtiMQujGvQEGsMVmx3esWYwE14v/r5uu9tj1XO2WRzitAJwenoW/JHxilGy2VT9K98ABsyPIR7aaOL2+1vUK3CFyn7ybfS2ySRqktCx2F2ZJgnozj9dGLwHEwtewurTCZsNXs96Fv5ELahBsaXHhV/zUnOq/9FhqAM/uajyjRy0Ox+8adsgfssjgbREgK+Xrp6Vz7ieVLRbPtYpUf5Xdy0EXVRUTkT9bANv9RIjKb5SzZHA7HU8Z/w9vCBqIEgno+MwFXVnoy//lZ0EM7H847WHU3Zz0cHb3G0PtVF4RMwpexjV9blhqOCF6CrWG67QqIVm1Hbk4TG2mPlX7B4glUvR3bDuJJvUVsEfG2HdoZAReVMfFJ+NipK/sNqNMDKtGcXfZmuTw+E98GBpZ/Fv/8wujNejewaD4jtE7gWg0sW2mx9Zsa5QNV/iz8IlA1HEhWgispn8WF0F90A0UWhqT60SLEo6u5welXhhEyqnnmyPS4InZBWbvVXF/ITZOrRvjO8P4YFzPdi/CQ7mcpDYyWJ42dRc+XtUy2WrfFeRH/K0u+yNa4NHY7TbPbsbUIdfGYwbFhLKaWb/QKoBsIi0t1Lxa2hg7DWhcBiaklgK84abS357YNHWMtj5HRUhFk7UCMl/0Nx+FV2wFmh03R7RvVHEulfKVL38k2o4+rD1+mhM3By6GzX1ldoElMJeKUuJKkdCcHYMaE9Xuw8JG1GHVwUPiFtqksqs0HdcYEZ8eqffjy0+bHNzaiD72T+j0qzYlTgZhxtYkQjKS4OTcXfBvcQau6zXHSUR1JGpS+LpXgISPOj3LWt/EEm33fNCB+GgYFEZ18A5Tg7dGq88/w32QGPRtzNU5Ttt/ZEZByeC4/EA+F9Xd1uIWKQqCAZX7T8rPpxSsibIaVGP22uL95qjgzvFVb0+vnISNfm8QdRDY+G99atSPS/yBA8Fh4HANgk6xj2/qtlnz+NZA+WGDFz8bU6rFdrWki/yoQE8Ehkgq2h9164MTwZD4T3wezosOwLW3B35AAMCFgbBaT+Xd0atWZV9l4nPiRn83W0uyvr0Z4hT45NZbgvvF/SMqcGz8Dk4KWu5pFbGHtY/UMnCaaeqBRYEjW3rB35MHRf5Vdbvut6LgBgRx4ks86nv4cXPovY6xhxYqFsixcsJp93U6IaaP5R23ZW8BQMD9zpc2sy+0O2Msx7Q+kkBLbG7nlSi7eMC8xIGml/scXBAamj8K04I3Qajg9ONz2KCEg8q70dGYi78iJxudD8P9121MBF4RN00wtUNZxuRq7Z4EOOoFwyDlZRqq+jPdC7ZJnlz0VQimvCR6a93rXyCYRQhkvLnjH8rHoh2oza2LXyTvxncpqK3jpy4fHwWBxY+jmA/A0LbkZtzAgf5nczAACfR3vjgtAJeD0yDEeUfeh4fe0au3sD4FdOomJRUTkTy2qY29fUntRbQgfj7ejgpGS6Km3OmA8j/TGq9EfLbfowZfThq9HhmB9oZ7qKUKfA0zm5Pvg5LN7Jz5ctT40ZCyqOxME/W69WSNmpufkAoEflY65Wr7WyzybGquV+P08EiZRt/xjthP4lS3LejkwWy1ZYLps6WEO+3oHkv6AsRbkwP934ufBIjC39Do3E1qzLqvucWrxHPdeuQmOsijbGviVzLLfXqc2ojQ9MFu9ItUS2QtTDsSmLo63wvom2uZWTqCrgSKI84WVvYy7sF7gmqSpMVeLWjUsxnbBmhKdgusVy75kEUI4oSkz/jlagaU7m8ztxVfho9NEkwgY4BzozgecjI+PTGJz0hgHApH7WcvjUq5F5fyqeo9c7bk1bfC2yK84LTYsnek+VehzZ/ds8ERmb8oqwVGY6ihJHIw6Lkfq3eTY8ylEOpPj68urAy6vGWKKOQl+nuY/7S+6EHbFpJcpPZu/6FJBlWCnNjzxIJRCNtcHPYKiy7cOCF9tK2EsJ/zko9lLoLgqfgHcjiTw/t4YOwoWh4/FwSul3M/v6k5G9sFXWwIcWi5D4dRR5/YwzJngzbgpPzr5gTDE9c3mFdy954sXIHvFSsk5skvYS3jrlZYCoqh3GxRAoiKAUf+qUp3eL830iP3/HvGiZ8+2+H2BE4DZH67BamaJpXf3z8+YdIQCAzK+n1byzINomY9U9lbYymZ6vIj3wdnQwXoyMMAwE/ybbp6zT7jTs/DxP5JNbwspooNXS+shNNxwyoA0m9G6RfUEXFOv5+eNIX9wUnoxxgRlYanIqpRVdA08hgHL0q3wQ+waMKyll48dvP4xSLIq2xjmhkwEoOeCsTLXJDf/PU2rpdTPuCzsPDucLO7/5y8LH4uNYOoQNqItZkT3xScpUPDP7+iLZFr0Cj+E/NDK55eytXSPdm56tyreRO/nRisLAIFGemBUZiYDNakla6ZWyyC3/Sv0TsVsnPu16ulc+hg3SnTw/flsaTQ8WvR/ZBcui1hP7vhcdAAD4xqXcJqkuDh2Pf2WjeNU2PacFT8fegeQSs1/YTGJN9siGHSwlrX4gvC8eCk9wvN3T90wPYDw55y+lTY7XXvzUc9xvBont+1U+iMnBSzOu48LwCVkrCy6WyUUU7ovsl7bMlOAlOCaoX2WwUKyKXZNejuxmex3XhQ7DccFzbX9+dnQYKipnImAxJ5Bb182a5aW4/dB++P7S0ThkgDfFMwqZmSISn0X7IIJSLMwwSk7bebV34AacGzrR1PYjmtLxG1E3nlvOCn9DIAJjgzfhfy7n5XPDdeHDsVw2wR/SaZDU+bEoUZJU+CPT8V1VrpVfRXrovh5GGVbI5IpvqdOw/NjnRwVuxl6BG11fr/r39j+U6a4a1Yo/hFL8P2GB2ORS4l+/2OlEfzycOpTfmn8dDF+2I5Sj6UsSSm+VmV73XHk9MgxnBU/BzjZKjm/U2bdPCE3HiODtltc1J9oTFZUzMV9W6Lxr/hK0TerfqM6ODsOwwD0Z502/ER2KBbIdAMQrdLm1bxTDKLJcGNTebM+ZYkZ4Cq4PH572+osnDTW/kjrNMKGP8c04BxJlthm14xWUIgbH10bUtRxsMENvytecaM+kqnCHBC7DWcFTXN+2lzahDjpWPo2HI/YDoA9H9jFV+dEtbp7jPon1xpeXlaBxneqoVlqct7ROOozmRytwUvCsjMukT6tM0HvYXyDb4SUTyaS7Vz6GnoHHkl5TCw+8ER2CAwJXZl2Htg1e5jPpU/kw+lY+5Nn6zbgpdCgODFxhevmvor0wPHCXbiW5Ly4Yieb1zOWQKnEpbOPWsd3fxn1mPjoldCYuCk3FraGDsi77TbQ7Hg3vrfveI+Hx+CzSG7MiI91uYpI/ZKukzretBvfJ1uXXfa1bI5tql+d3Sgs3FOcVlXLO4swNAM4frI/NcTlNowug9nWj0uZW5NfpVHFm6DS8Fh1ue1rh0cELcFrw9LTXDw1chrvCkxy2zrqzQqfiZp0KalbtEbgd/SofdLyefBmGWwgO2qU1hBCYf7WzIDMADKywEGyq1QjlFh9C50fb4TYTN4hVQViW4qLQCXggvC++jPZKei+1eosfvpXd8Vp0uN/NsEwpUZyPVw3zHj92IK6Z1Cv7ghqDK+/BwhH3J71m5z7ETermL7JYbSib/2RDR3lctsYqgX4R6an7vpm8WXYCADtQIy2AsQl10LPyUdwRPhA/yC6m1qN2NK33sDjKZtT2vbP2vshEfC+7urKu1g3N5+yL5llezVx1yLoh9We+N1Zlc7OsiY2oi+cio3B3JHtFryhKcE34yHhAWLvWtbI+jgpdhI3IXXGggZX3YVjA3dxb+XKfy85Y8xgkygNmbpAXRzMnWR1QeT8GVt7rVpNywukJY62LpY0z+SWq5Ld4MUvP2UZZ27C0uZ+sJvh9W5NUzw0CwKfRvvhMZ0rWN7I7bgsfgqODF2B2xMKoDofWoAHujUxyvJ5tqJnTCzcBNx+kVNypVV6G0pLcXuw7NDV+iJA657PxwRtwl4kbRMuqOa/MtjxluLvbwjpJqtegAWaEpxiOJKLip+aq0+aNGtm1GY4c0s7Sev5DI4RF8qgz4fHN/0LZxtRybj2EhGRpbH3A4MB9aSNdjII+WtpcJ3ba9UFslJmbx+w21LSU0P2lyO44LzTN0Yi5qsjs6NY1aIhLQ8fi00if7Au7wMyIsA4Wchzli0pZDU+ExwFA1pkARkfigcErcXXoSN8Lr6xBA2yGOzlu8zUo4/QZ1O9OiVzgnZrPDglchoOD2YeXbsjSw7EW9bHGRslvt5i9GG2sa5xA1I1yuHZky1VyW/hgAMCbkSG677t9AjT6Vb4csdfLfa/FJIEnh862tR0nPo32xRmh9JFGVUW+XkS1xgRuwuHBi/xuRlLC6fo1nedxc00uO8ku+CuHG9P3Ynj3jO8/FdnL8L3UX5WV/T8/+iLJrjnRnhgduAkzI3u6vm4zN+1Oqm4+FtGfDqLKNp3SqkT1Pv3pEW9HB2ddx9vRwfFP2bnOnBM6BcMq7/LsofX60BSsypL0XKIEL0ZGxEbN5bcJgetwXmia382w7JnImHiOM9Pa7Rr/srREJO1fVve01ZqRchLC06mFt4cOtLT8HoHbDDtb1WPy2tDh6Bt4OP6sdnM4+Xlms8HnU4/JpbJl1vNMoXkrOggA8KrNZxi3FWuOJC84OgqFEI2EEO8LIRbH/k070wsh+gkh5ggh5gkhfhFC+BMJ8EmmBJubZS18K7tnncLzWaQ3Lg8di4fD43FM8Dy3m+iIk97o91OmZi2S+kknt7lQ9S2ThdHMvYOfRPuhonKmYUWL1KG6XvWA5OKEtiIHeZ4qZR492OeJfBmGm8li2Rpf+pyge9a05EBt9TLrlzA3qkhaZabH34hugveycmDyc8BRs02v58+U9Uhp/owyKXB12mu3hBPTNd+PpOe0yfRAWghBUfLOEtkablzRUjunzKxRCPvn2myjX24JH4r7w/t69jCUep0wexx9He2BJ8NjcL6N4EUQ1fAvvBt1+FBkXwwJFNYo+EzmyfZ4MTLC9ucP2DnzrIFM1CDpXj2Uc73VPV1N8H9A4Eq8GRmUdo+eplbifrFaqbPjOeu2XHRnxHyQqKJyJv6SO2FGeErG5R6L7I0AyhFGGSoqZ+K5yKik90cEbsOegVsstfOZ8BgAwFLHiclT5fZ+8y+5EyoqZ+J3kyMxvZZv1dbymdNQ7YUAPpRSdgbwYez7VNsBHCWl7AlgHIA7hBANHG63YGS6iG+GuSkDR4UuwkLZFteFj8An0f5uNc1fA47Dt7I7hgfuyLjYxaGp8Si0nn6VD5pKCpeJ01vV1L9xFCXYXsv+hd5ovXZZWUtq1S4n0tuvfJ+tMlFVxofnzIZ0SA5iWv1tDa68B8MDd7rXII1MtxvHh6xVj9LmNvvAKKlwt/FAh+zJYwFgYuBqHBC8Cv9Em8Zfs3J7pDfNRtvTe2LoHAtrAz6KKNcxNVFnrvZ7L8r7kjMPHunew2HjOpkT9W6UNqZPVJivHLcFtXBjeEr8QTFfRFCKK8LHsvptAejfpoHtz161X08svGYc7j9COaasFlNQH+Z/kF1waugsnGAhfcJjxwzEscHzbXXCRKXA1eEjLX8uG700HdproBG9xNnPRUahc+VTOCN4WtLrV4SPQaWsljWv03rUw1LZMuu2tdTKketcSq3B+0uFa89WVWC+mdMg0UQAT8a+fhLApNQFpJS/SykXx77+F8BqANmP0iJRVtNcIryzRhtPw8pn5Q56D4Z1bIzlshnOD50AAFikU351ZmRUxt67jaibVkoy176Lmkg0uJv5h8TUKPdpwdPxeHgsXnDQO2XWZguJG+8M28u1UrM8/4eM55o6mrDSg8pO+ejSCd192e5/aGRpH9czurvOyB4A0Qx35HrVZ4zcHZ6EZbG8LQAylqU262fZCRtQD3eEEz2oVpKD6t9USZ2v9N5V/CI7JLWnonJmvFpLtmcZN/KVda58CkNdTsRJzo3tuVPS9wfubL6Mfep+c/KIjhmXXyfrWRpBByAvEk8k7gmSOU3JtlfgRpwdPNnZSgrYNaEj9Edq+qxva3tBgV3aNUSNaqW5y9WnOTYGVTSCbDsUdze+FABQgqilVQVQHu80cKsjUW/a5/Mm7qM3oB7+ijZLez2EMmxPuZY/ExmDboEnwclLhWNLLJH/Dgv3ZVWV0yBRcynlytjXqwBkPNsKIQYBKAfwh8PtFozSqe/j2lB66WUAqF6WeFhuWb8mng4rORy+dDA1wW37Bq7N+P7imkqP8DZYL5X4zFRlPv0LkZF484CFmH7IaOsNzAM3hSYDyBKdHnVZ/MtrQkdYWv830W64Knw0vo72yIveSfXieXvY3Aiu1CGdQgBNsvT4VjVXhI7GJaHjMCfaw++m5MRuna33EzxwRPqIAz96ch45eoCtz5ktY31r+JCkXsmVVvNEZKA9Tx8XOg/HB71LtJ96g66dnqZaLpsgIgVujeV9M3JG6PR4D3Cm86xaEl1PCGWm86qMDtyE8YHrTS1LCjsPpqlTaxZdOy6emN6M1LhsNYvVB21txAfqNXRLyujzLs2dFU34XbbBq1HzI6WKzaOR8RgRvN3vZqSxu8f1bOn+SMnUacpGykpL8NLJw9Crt/JM8LmNqenXhg9H18onXKtupnetuMdkwZI9gnfkxf22mwKx4Nsrkap7zAPAveFJuDZ0OF6KZM6rmM0hA/Jj+pyXsl5RhRAfCCF+0/kvKRuulFIiw7lNCNECwNMAjpVS6oaYhRDThBBzhRBz16xZY/FHyVNNOuERg4oMTesmHpRrVy/DXZEDUFE5E8eELkCflCoWVtgZ7nl3eBIuDR2b9vqvmt5fPV/3vAwjA7ear/AUv+ESKCkROH54exy4c2tM6NMC+/c334OYT7JVMUi1tvfxuq/bzTfglqhBD+uNsSCYamLwGowLzLC9HQcpIYrWNtTEs5HRyHVv1NFDrVUU8lPn5v6WJ9Z6PTIs6ftQJOrys6SyH9wWOgjrXJwi9UM0MWL1L7lTvNKUU3rnqv7DJ+DTnY6Jf3/O2PQA6A7UQMfAs5hTPiztPTtOCE1H78pHHK9niWyN+bLCeYOqkIEV1gtntG+cPP2relkpSiwEm44bXpF1mSXR5Ckeb0SHYFZ4hOlt+Cn1lBJKmcZWu3ryvcfKbsd43yjylASwX19r05IAo5xAzi9KE4I34Nd2R5te/sU/yrBL5f22KtFJlCCgM5r622hX3bx42ehPAXN2j+VWHhs/8uEEUQ09Kx/F1eGjcr7tfBJAOR6JTHCUCL9+zWro1Cx/7km9kjVIJKUcLaXspfPf6wD+iwV/1CDQar11CCHqAXgTwCVSyq8zbOshKeUAKeWApk2rwow0/ZNVCGWOpkT0CTyaVCnAjJGTpuL7aBfL2zpzbC80bGNh6khKz/+l+/TArYck9/4aBSvcMCdifqTGd9Eu+F1nTnMq96ubKetbJpUenGxBqEVRb4Nr98eSGao2oq4rU2DIf3ZG4jSr688osFx16Ksjd7ZK49GRZ4aS8xKs2xrEM19nrjhmp/khlCXfTE7/HZj2SdIy7Rqby20HAKtdrIC5DZk7IwZ1aIo9TlLyP30U6YdTR3bSXa6zizdaIZSljbYgb50zxvp9g8rpIV23RvZpKd9GuyV9H0A5LgwXRvUp9exsdI8hUl7f0UD/GKPCMnV4e8ufaaozOtuNa+Z21ECgZvrUK0X6frm5MhTLoWP+3iKc5VH0zcgQ/CSt79s9WzWw/Jlszwip082cynVn8DbU9LRyHBUXp3vKbABqiPloAK+nLiCEKAfwKoCnpJQvOdxelfT6qbvijdOtVctYJzNXTEvVq2U91KxmcXdoWIGy0hLs0s69B48ZnWZiUOA+19aXKqgZxvpVpAe+jnbHVoOHnQanfoS9gjdnXWc0ni8gcUVe3WKk4fICwOTgpWk9I2tjyel2SKUnZVrwHBwfnI4NmarfjbwE+wUzTwk08orH5SiNLn4exgAdy9VU/qpO2ng8rFsjfQi6F7PNHgmPBwDL5YDv+8S9WdR65xQAQN3mQEtnxQs+i1ifBqB3LG/PNsVYKNeTisqZOC50vuFitauXmQpWqhVeAqyO6KrvL3U2zbtG7L4hNWBhRkGcbvNgupmRTR0m4OdoB6xqrEzdb1rX+rT/YjK4vXtTc/2Uej4sNzGN0su9tJ9RMu2a9u79UzuxJwWvsbWe7LKfYQ4LXpz0/b9Zkrt/Ge2Fi0NTHbUqH5wcPBNjAjf53YyC1dSnztJccxokmgFgjBBiMYDRse8hhBgghFDHfB8CYHcAxwghfor918/hdgvap5HYnPt6mUep/HrUfOCi5ejbpgF6tbI25eDo4AWWRs0AiYvMgqjJUSInz7G0fgDYViNWyrGJfqJu2bhDPFhilpUbzSDK4omurwkficnBy/BudAAu0jnpdzY531/v4ryo74VAxz11lxdC4Otoj7SekUtDx+GC0An4Xio9sxtRFx9EM1R+adEP2ON8vHiacUBK1tnJMJnnOaFTjNedRRcTU3/+lcrF9p3IwKTXS/MgEaiRC/fuhp3qmb/RblFfWdZq+ddOzeqgY1MblXZcdvKIjtits7XE7113cpYHw67mOn+X88d101nSHVZ6+Mzs0lbWlzkltDNHhS7KTa6FDL+UCb0TJX3vntIf0sSD+Omh03F08AKscXE0VKqGtapeAKpxneqoV6MMzevZu+mtUU0Z6dqwtvXfnZWpZW6wmkwXAKCfHSEvNGrSHL2u/AHN2yr3DGZGVmWy8JpxbjQryZtnDMfjxw7MviABABrUSp9u1auVtU5flVtXj7JS89NyzMRU34sOwCnBMwAAESm8m9orsj/ifhXtBRz2Ij6MmO18EZiZUt5ea1xPc1O4X4/sCgD4OupPEY+3o4OxWBZmio980Kh21Sgy4yhIJKVcJ6UcJaXsHJuWtj72+lwp5fGxr5+RUlaTUvbT/PeTC20vWA9E9lW+0JzA9O6no9VqA9XtPZCtRkNTWfy1LHeYlesP6/8x2gnzovq5Tsq6jweOeRMYdKLu+2eP7oLr97fe023FlljOpsTvXOC51JN+afINc6sGxlMr9B7+ZEkZULeFztLA+eOUamgjuiZPqdyGmng+MhLmw17KH6xP6waGSwgh0KCm+SSADVIekioNeu0b1irHnzeMz7iu1WiIXpWPxPd3owotqXZu28BUW63ap4/+30Nr2u4dcdk+1pNH983wNzCSD+Uzm9ergaenDsb+/bNPq1RdbuP3k8qtznltsME9UvN/f6yWSiDErdK3RrQjlX6MGg/nzx7g0rzfop/yby3jHtkT91By3bVtVAttGiWuIz9fvpfhZzajNj6NGiemdqpO9TL8mGH7uTL7tF3xw2Vj0Ntix5ATv1w5FndOtjdCbffOTXHNxJ64ZmIvl1vlvlIrQaJDn3G8vb9NlNvWMhqhkOlcVFoiNMex/nE6qV/2HDcNalWLB/yc6tAk0QHSs2V9jOzaDD1amAt0zDjA+v3foAplBJHRJbVOdXcSIefCvjr3KXVsBv/MBN/NcfteReDD6M6ml14by8t3W8hEsZQ2Q4Cz5ylf9zvM3Aa67IW3IoNNtycTswn8v5HdUVE5E0ul9fxTRLnCiYk+++y8kfj6IuOodC5FY0GrtDLcrTJX80m9Du0fvBoHBa/QXbZ5z92BiuFAif6uV6NaKQ4bnBjJtOS6vbO02rpGtZUA0Ftn7G66FHd5mXuHSov6NbFsxgQ8cewg19ZpaNjpphcVAvj+0jFJr+0auEt32VsO7gshhO4UICDR87UVtaDeYKiVFdD7YHTQjKK5e0ryw0mJR8ETs0GZXMVu3NrMtN0zJ5c3w8rP7LQH5ezRXeJViDo0qW1qKH0uqb8KK/P23d5lno6Mwe31L8ALkT083XZNzUOhlceJ80MnGL953LvAES8DLfvFX2oc22fU84WdqUlmjO1pv5y12qIjh+QmmXuFQS6pPq0b+NJLaecvcteU/qhoUhtHDq1AHYNrgVdqlZsLaNwePjA+xdJsZSMAiWmd3feJv7ToWmsjbZRiBOYZJbPVBlKTlldP3G2HKv82i93P9EiqK4PhnZvGj/UxPfSPkSv2da+y5vS9uqa9Zub80qFJbcP2ZTI8Nhp2ZNf03Dmfnz8y6/GUT9PM1b/p01MT94cH75J9xMcJuzm/DzDU91DTi9awmrZC87l3ztKvuvVmVAng3BU5IPuKhADqtwau3AQMPB4o1x/1fmjgMhwYuCJeTfHCvb0blUxUqPLr7rwKatu4FnaqnzyNYmiHxhjbszl6tLQ3xNSuf6tV4PbQgXii1ZXJbxzzBnC4tXRShj3PDa0l5CsrLcExwyosfSaTMT120iTedX+sQGLEUQ7uOjTRuWBFbGrb9EWJ96/cBAw9VfejTw1+I+01gUQvyE/RDrggdILhSIZ6NavFP6PnsaPTh5cHUQ3ygr+A8TejduwG/7FjBmBfG5U8tF42mVtJr1dtTqQHQrI0ZTnrbbD6kSmD2sYDM7NP29X6BjUm9WuFrg5LIZtxxqjO+PjcEWhcpzr27mW/KtaZozVTTX26OT9pj8QUzPZNkqf9qblvFknz5U3/2bDdnYbFRFGCeY3GQHp8iX5maqL3NPVP8UA48XCcun+/EtnN+MGrWg2gU+Lh+MnjBuGNM7zLf6adIrZ3L/sjyw4ZqPy9LxrfDX1b18d9h5vv6bZjYj/zo/dyYUBFI8vXWjtVmLTcG+lgbA0axqdYvhDRmZo95FSgiU7y7fqtgYuWA0Ni07Jb9kf1Mmsjbaz+dKlBogl7KUGp1M6YE4Nn48TgWYkX+h2ujJ5oM0i57h/yFN6rOR4/aEYHqgnGUwuFAMoDcrbqsgfsbH5/tRv3b1CrGhrXqY4PzrFWmrpP6/pYNmMCBqbkJPrigpFo06hW/FrboYn/U7zN2q1zYhRadROdlMfpJLt27eiqbjCqUad36QibQfaF1+yNbjsZPfNYuVHQLCuE4We/kd3xW2l3HBwrY243x8whA1rjj+sTo+rzYIA4kWsYJPJBLzX4Y3A26bpTXTx45IB4b7tdVi8Q1auV4c7IgTj34JSRTdVqAp3H6H/Iqnw4g+q0Ie0he6j9fD2Gzl2SGAbrsvKjXgYuXw/U1Xl475Le+zl5jHFgomPT2pgUvDY29c1AbOcyGp3TrF4N3HJw+s2oqNkAKMl8o211v32t7SXoXvlY1uX01jsldCk6B562uMWEtrEe3jKLXZFTh7ePj6aoVloSHy5v1yCPE3a+e9buOGtU53hA5f4jdkmaomZ2Hr5eboqODqpbmX3I7Nq8LibGplx8fO6IpF7D504YkrTsR9GdsXfgBrwUMf+gsnF7KHtbTdzoflV3bPzrqMkDQb3JtaN+zUSARfuAekbXTzCr/vGZtxvr3V7cbGzG5fbo0hQt6seC57FNtGlUE4cMaI0HjsiQcw0wlbdLbfUbpw/HJAvTJrUWXjMOl4xXRmHUKi/D66cNx3gLUxlfOmmoqeVeiQyPFyZwanR3o4pD9pSWCFy5X09X1+mH/51mMSA57nrg5K/SRt8AUKb7C6FcW4//yJ0GZjAwpQhIh07KPimgTMNSO6HejQ7E0iZ7Yg81kKCOntB4pP4ZOCCYKI5xwu4dsGzGBNSrUQ1TBhmfMz44Z3fdQim3HJR5qucvVyZP1bx4fDc8YTEXkXosd2rmTqdHapqA/E1B7g33ZpuZv7/Zua25nHHZrofaKqrqSP4vL9TP82lHt53q4rerNNeu2L3zsmhiJFtq+gU9Nx3UN2mKmVcj4XNFm6T8zsn9fGuHG4xmOmh9et4I7xtSwBgk8oF6M2qkdnV35oVbmuuqObFZPcf5feHdnFLy2LBqV4eRwJhrkq6cQzsqeTOu2E8z1PrKTcDoK5M+qvcrGVB5P/pWPoTzxypDq7UXvaTf4b6xKVt1mqbdyNmxujx2gzf87MSLJSWJ4MuQlNFDzdL3t0zT5145JT2AdM2kXjhjVHqy8Ux5fjI9wF8yoTsGVTTCkA6ZK0mYcdzunfDNlftlX9CDHfXBI3fBg0fugiY65Wez6d5CuRGuU70Mz584JMvSmV2+bw9PL+hdd6qblmT2wr27YUiHRphz0Z64Y3I/U8O19aYDtGpgvyKP2T9paYnAjQf2wUsnDU0bOZQ6khMAFsh2OS9NCwCBksS5LBo7fv6QLfFPtClw6LO6nzllREccMsCdBJQLom2BXgfhrin98cl5iSCx7u9CALhyEz7seYPl7QghcNNBfeOjZdW8amUpCeBft/DAn/pAWNNCfpUa1UodJVHuopPMXS/AdU7oFHQPPAEg+76b7Tr8iM5oTbO6+ZR83k1Gl5ferY1zOV0zySBvUmm1tDyESUpKDafIZ5K1AmCKTmpBiH5HAOctTdoJJg9qiy8v3BNX7tsDr54yDO+fswfqe5BovVOzurqFUvSOj0ePTqQiqKfJm1NeVoJpu3fECJ3zveqmA/tgfG/7I1K11M6q1BYavZ7KjVuDug7zHn1xwUh8e3F+pJ4wrXV6yoQ2jWqlXWO1Xj7ZXED9xtg0MK3GdqbhxvaBB8MTcEbwtPjLL540NLkjvuOeOCJ4Ee7VTEn9KQ9y1Flx15T+6Oyg0+2aiT3x2qm7xguxjOpuf/q2m4Z3slZcRWXmit6ucW18cu4IzLnIWgDyAJsdUoWGQaI8od2ZT99Tv/KXVb/KDhgbmJFW4tFtWXsrSsv1v3bJ+9FdkhJEGlbtOuo1oElyctaeLZVhysM6ZjkJ6Zxt1qI+NqEO2mfr7c5QYeGulHw8Zuwojd3gGwWcxl2vBLq0SqoZVluLi11MtaMLVEcMbhsfrq51zcReuG5/5cb7+JThzupu0apBTVy+Tw+8dmoi+NSpWV28cNJQ1Cq3d2PVoUlt/H7t3lh4zTiM7Nos6QbViPrQbTSlwkzFNq1jhlWgQa1yjO25k6mS7t1TEnfecEAfPD9tSGw4fPbLWadmdZJuRDs1q4Mpg9qg6051Ua20BBP7tcJZo7OfO8b2bI6jhrbTfYi2MvWveb0amDVtKFrUr4ka1UrRqamV319uQ8sSSiBggMMRW0YWrtrizoo0+0EkNpTo2D26Ys5+HyflRkn+iECZ7VGnib9Dr1b10PriH4CDHs34iWj9dtija4t4Dgy1xQsbjgBG6eeiy+b+I3bGyycPQ23N/r1sxoSkhLM3HdgnPk1VtUeXpobXn6ReYh/s0cX4AflEF/KIpWqnyXGkl4j+nsP647PzRmLywDboHysOcJXPI4dyXl0+xxucFRuNG5QWr3Nl1YHajXXbe8yu7dHf5GgNYyLDd4qJ/VpmHaG6R5fkxNw/XjYGZ4zqjBEZ9n3VIQPboGX95MBu6vduOSeWI0mt4NfXqKS7A1MGt8V5Y7vqjsIyo3XDWmiWUsHzvLFdcdyu1lI0aLk2ndPo/qTvZMvb3aWdsk9l64RJetfKj2HQ1nvDk3DECdPj3+tVAvwi2ttSLkILm8+J/fq2xENHZc4ha4Y2T6SZ0ThWPGyjfc8cP9iwE3L+1cnXeW3gucLk9NKKJrUTo50N1KuRfG8yeZDJKuAFjkGiPKH2fj105C6uVZgAgEWyrVLiMeYHaEaVtNckRS1LHCCmristLFSZ0QZJskw1skckRf+zL279LG663pjFi7JR8lJzLPwcl68FjnzV/pYMfmclJQKHD26HZTMm4NKUqlfq72JYx8Y4bnj7pGGsqQbEhtmfvmcnUz9Vq4Y1UV5WYulYUf80PWOjFy4en7jo9G5VH++drRwPRvP/F1w9Dpfv0wMX7d0Ny2ZMsDw1Y1bKtKaa5aUYbDCSqq9Ob3jqvtWhSW3ccECfpKHOjWMjmowuqH3bNMCDRw7A1RN7YYGm3HHPlsr2jhicmwuf+qMImEsofptOHg0gf4Z23/zuoqzLxP96GZLJa2+c1aDmzm0b4hAHU8rMKhM6N85tBiNcozFu11S+KjnwYTx67KD46Dn1eHmr+03AbueY2lbqn61ujWrYRTPVRq8U/SED28RHfqq6tagbPy5S11laItIeBs1WWMom9cFNby/MtGu6Vfr91VOGxb/+9LyRmHfVWPx0+Zik418dYSUg0LZxLcw4MHHO0GtGpgpzVtjpAPGSGwn+rQqjDMMDd2CMvNfU8sZXMxv7i4WP6N213Dm5P144MXnUx+un7ppUfSw1ON2wdjnOGdNFd/9Wj9P2TWob9sJfNdH8NbV3q/poERsFqm6te4t6utfO/fq2xLIZE+IdI6nNGx0bMTHa5MiJ504YklaF7fyxXXHqyE66o7DsOnVkJ1y+bw/bnRtujNQ2JEpci4joTevq0rwucOq3wOk/JDZpanNp48li/0rPp+Xrbd2piywm1HazyA6AjAG6Dk1qW55SaicxPaB0rPxwWXrak9SO5vsO3wVvnjEcd0/pb1gc6NSRHXVfz+RYB8HaQsYgkS/Sj7rWDWth2YwJ2Mtkbg+75tTU5Nk4ejZw4d/AQY8DTXUSNwJpPbcAgFO+AY7+X/xbvVEUuZ6q8XU0FvxqYOIh10bvipkHWQEZP0ErOWqyfyZT+XpPNEgkFfxMM50EbYcBh9jPzaMnHggwsSuoo5f6tm6A2w/th8MHt0VLnWlAKitTSeLtie2ndaqXYdmMCZi2u/6FYs9u+r2gNctLcdzw9jhxj/TPnTrSuHw4oOQPsTI1QDvlT60Wok1kCQAtG6T3fBw2qC1mHNAbxw9vj046w46N/hTH7VqBt87YzTBo5Qa96YpCmKtzdcDO+qPmSkuE48TfuXJ/OJbzZOSlppavUaY+0GT/DZk9pZ0xqjOm64wIBAB01JnqMPU9lF24FPv1MR5hdtjgdjhrdGeckuUYAIBGdZSRpJl+ooXXjMMcg4qftx7SD+eNTVROOm+vrrhjcj/0bV1ft2f42om9knpF1RlDUwa1xZAO9h4Y9u/fKm1anN6v3ygONKpbMxw/vD2O3619xiHrmXISHhg7HlJHlNSuXoYGtcrRXDMioXfsoVWvPXrttjuFqby0JGm0ZKbztxv0pqNkMn2vLlkuRt6MMloum2EtGphaNj6a1YWHb2HwtXb1uvd3GfRt08BxD/o9h/XHbYf2A5D+G7cybXu/vi3RMWX0ao1qpXj9tOE4zcS5SKtN7P77oSN3Saquq6VOeSktERjasTEmD2qLUZp7BaPRnGZG52abqm232uGdk/vjvbOtJQHXeuCInfGiUb61yTNtr1erRAjMPjV99FXLBjWBpl2BxhYf6MtS9qHYvv7UcfZK3L9x+nBL57JDByr7T6Zjy0qhkRP36IgXThyaNbG2Or25VYOauHNyP3tT0LOcd1KnZPVqVT+pkzLVTvX0f2/azg2zU5+FEKaPg54t62Pfvi0Nl69dvQwvnzwMtx9qfrDD2Ub3TUWOQaIc+POG8dkX8sjdU/rjqeMS0dQjh1YkL1CjPtAruayk9jxRUxulbdEXmHAr0Kyb8jmz7Ax57XMoMPk585tQrwRlDoYr9zow7aVLxnfHzBOSLy73hVPy38R+PgmBayb1wkl7pM7F9ztrk8ZJnwNn/gJAqawXd9zbutNZXjllGK620Lunx8xDrlrCtl3jWmjTqBau27837tCMXkjNfTTjwPQHhJdPHoYbD+yNT84dgeenDcHCa8ZhoWa0jNmglZ1e/p4t62es/nJU6nGXhfbCqz7kaRPp3nRgH1w0Pv3GsrREYPKgtigrLdEd1Wa0JwohPK+m2FoT1HLziPAq0Or2UftYZG90Dc9Sqn8Z0O55Z47ujBb1azhOaq51zpguOF0brGvYXgmsT7wXGGl2WnLyb6a8rARnje5ialTfzBOG4IYDeusGdFQ1qpUarqt+zWrxAEnzetVRVlqCPbs1x+unDde9We3duj5+v27vtNcPG9QWs6aZy42RakyP5jhlREfDyl53x0bQGAU2Hz1mIBrXqY56NarFH5b1ZKpoZGZ6qyqqM9LKTGg2W0Wla1Py+wgh8PaZu+GgWELzTAlsswUDzPSGO62s5qt+R+i+nNiFE6MfvODt2s2zcmu4W+f0lAAdYg/GDWslPwyeO7Yrls2YYLk9JSUCuxnkP2kSC3Bfv79BXisDE0wkwD9Jp+PJDTXLS5UROTaN69UCA42uP+WxqTzTfwfO/DnpLTN/VnUZIVLuRe06/Qeg5wHApPuTX9/1TABAvw72zhe9WtXH5xfsmXUk4uzTdsXPl++FoR0b45NzR+DHDCMyrVb7HNS+Ed4+c7eMy7x0UiLwMrFfq6RjQj1XnjwifT8rLy3JWHjkieMSI4X0pmTVyZCLS72vP2G35FE42s6NbFNn97I58iiTHi3qYZd2DbNWdCQGiXLCzCgUr+zbtyV218wbN5O7RUpg3ZEf4+TgmckP1Cd+BgzMXPHGNQc8BHRTgmuTM1TiUP0tmwG7TQcOm5V93UZ/jwMeAS5dnfTSCbt3wLCOTZJuqW8KT0ZFpX4vSsNa5bhw727KA4tHf/bUMrmW1KgPNDRfonTntg11Axylpdl/uEn9W+HQAW1w/rjsw2WPGVaBby8ehc6aGxrt0OB7DkuUo57YT7+HYJd2DXHowLaoaFIbgzs0TnvY7BDrdWxsorcyNX+QFTen9HBPGdQm6Ri0Sh0RVK9m4mI8ttdOlssx2+WkJ1JL++CnjpJp3bBm2qgMO+45LPPUllyU2jbjkaOzzMfXnJv6tG6AOReN8iQ5bVy1GsBZvwL9j8gyFdidk1mrBjUxxeFIhMZ1ytGucS1cO6l39oUdevb4wWkJ4cf3boEGtcoNp1PtG5va4uQcAigPum0a1cQbpw/HIw7yTCQexsz/Db+7ZDR+uGwMBlYY38CP6Kp/Trvl4L5YNmOCqWC70VH5xfkj8abFBykrJvXL8sDY1NoUj0xqVCtRkowf+oymATrTzy78O/F16t/Kxj1kps4ZdcqHOsUzl3eo2gClNti5a6fMo1ifOm4QFl2bXKn1kgnd8dRxgzImK3eb06rDbhvUvhEO92CauOmKrXWbAw0rXN++1uDYqE/dffrgJ4GpHygjjg5+XGmP1m7TlRydZYl7RqsJsEtLBKbt3gF9W9fHHQaB/T6tG8Sv1RVNapue9qUdGav64oKRaa9lC6w3TPmZtOdWtRhS64Y18d7ZuyeNCPr9ur3RuE7yZ2tpAj9qDikj/ds2xN1T+qeNwBveKfHc1DlDtUK9WQHPT0ukZtDe+wOJTlO7Pj9/ZMaE+qoOJvMZFbv8OttVFeqUKLfKyptR21q53EjTHng7am54ptfPX912qmeiV0gAoy4HGnXADQfYfHgoKUkfqupEk9jJv567WfBdnXN80GPACeZL+z49dRBuO6Rvxt4DVY1qpbjxoD6mhogKIdKSNrpt+l5d8NRxg4x7xjSy9dpkkvowpu0lfOyYAXh6qv486SOH6Afvrti3J56ZOhjddqpn6W7+xgP7pOVnaKCTlDzVM1OTj3snPZGAkkD4rNGdk0aDtW1cC/cdvjPunNwfV+3XCwfv0jpeUcMOp7mJUitj+cfez5Ft1Icet0uo50q10hJ8et5I27kNrNi1UxNM7Jf9/F27vAz1apTh1oMt5OqLefK4QfjgnD3SXt+5bUN8fv6e6NWqPkan/qyaa+7NB/XBO2cZn6/UAKn2GFHPyUadRk3rVkft6mWOS5EblRfOdrg2q1cjnifNTWpy/aEdGwNTngcmPZC+0B4XAlPfc2V7rRvWxIKrxynby5bHsUZ9oNsEZTT0Lsc63vbNByc6K1J/3yO6NksKZOYihK4mwDWanvLs8ck5+146aWjSw7IQIq1jpHpZqaMOGHUqt5aaU+j2Q/viu0tGx1/fNTbCSHs9HBjryJp5vPG9sl5+NTe9cOJQXLe/+wHzrJfU5tZGVAHAR9MT5zkrKSkePHIXvHvW7voBup6TgDbm8+L8dtVYfHmhfhGXA/q3wgNH7Kz7XpM61fH6acMxKTZF+Oiym4CjXje93SOHtMNXF+6JD6cnn+tPHdkJS68fH5+W+Py0IWjdsBY6Nq2dNlpSiMwVhbMREOjSvG7WJM0vnDgUF4/vlvU+Xz1v7Nu3JWqlBHue0RwTmUa+Tt+rCw4b3DapUqI27UHq887/Th+Orwz+fnoGtEvu6GjTyHjU2sR+LePLazvn9PKcVRXupi0ncxp1AM5dDNS2f3GzrNsE4PvHlbPMTr2BnTLfsNSJXdAzTaGxRiBXg5unDGoLvJVhgZ2PBt4+z7XgjTqyJ+2nG3oa0GYQ0NZZeXNVi/o1cP3+vdH8sxqAS8WU9KbYZZKaFyfVq6cMc70agluqlZZYuqF86rhBuOaN+Vi8equp5dW51S01Jd1P3L0D2jVO9Ejs2c34wfaaSb3w9Nd/pb1eo1ppfNiuFQMqGuH104aj4sI3ASiVjMzkRxjeuQn26NIUn/6+xvI2U9WtUYY61ctw1uj0+dza6XM3H9wXNx/cF+e++DNe+n550nJDvUy+GdO/bQOs2Lgj6TUv8qpZyblhxblju6J29VLc+/EfppZfev14a4MTtAvneFTWwIqG+G3F5pxu06yfL98LokR58P3lyvRqalOHt8ejX/yZcR2pFaKsOjhLUvOd2zXEBwtWo3XDxIPBqSM7oUX9Gp5P2TIKCJRlSJztFQEll8xH0/dQSnSLlNEXo64AKjcrieWr2y8jrTW+d4vsI7j2fygRQKrfGrh0VeK95r2VKTS7n2d5260b1sL+/Vvh1R9XWP6sF+45bGe88sOKpCqi6qlkgs6Db7ZkzVamXBrRm3bZplEt3U7Jgwe0wZ7dmiWNRJ62Wwfs3WunpGu81iNHDcDgDo1xzcSeqFOjDIPaN8auMz5Cy/o18O+mSsft901q9VyTOliqgJpQq7wMXU3mrskmU+Aj0/RfrQeO2AV9Wu8JWOhcGtdrp3geSbVyqaqkRGDGAb2xd6+d4gGSD6ePSFvHnzco++Ubv7xpert2tG9S2zBn54iuTfHJovR7w+Y6nbxm7jFqVy/D9RaDnHr5OI08edwgrN4SwMhbPsm67J2T++P7vzbgwPu/Sn4j9oNMGdQWf63bZqWpBS8/n+aK2ObqLVAPAOrkuhc3PugcOOmLrEvXKi/D/KvHxqeFON72OfOBrauzL5oLg6cp/1nQvF4Nw2BBR50EwQCUkUkuBYiumdgThw1up9x0f+7KKj3hvDRvsi8v3DM+SuLcvbrglvd+d3X9mezepSlmTRuCM2b9iDsOzV6p5/jhHTCwolHS7yA/JjkpPT1HD6swvbyTgTmNa5dj3bagsh77q7HUlmxxi2yj7wZWNMIbv6y00Cp7sk9Bsvcbq1O9DOeN7WY6SORWda1ceFGTa8GpTk3r4LcVm+PD78364JzdMfq2z9LKW2ebCmglntagVjVs3B4ytayV88pJu3fE3r1aKIGRmPKyEksJiC+d0B1Pf/0X/lq3Pf5ag1rZR4iWlegfdyfs1gF/rt2G44bbqxhzvM3PARkeVBu0AQ5/wfZ6s6ppcG3se6jxZ0rLlCk0Np0zpgtWbarMOuou09mgSZ3qWLs1YLsNqub1aujmRAGAXSzcN5SXliAYiTqabl3RuDZ+/HsjLhrfDb+t2IQzdYoq6Emdql5SInQDRLcc3Bc//L0hPgJQzQUaiUrs3WsnnLhHR/Rr0yDegWNG64Y1sXzDjuwLusQwb1k169NwRndvlhYYyXVxGzeN62WtwNCia8cl7a+lJQKNa5cnrad29bKkjjOnpg5vj4c+W2pq2dqxwJmZEcmp+b9Uxw1vj+veWmC6fd9eMion1WlrVy9DexMzH1TdW9RFm0Y1ceG4bjj0oa8BJArr2J6lUsAYJMqxHeWN4G16WANDTweWfQH0mGj6I6mlBR2p11L5L9d2PROY9yrQxlmwpnuLuvhiyVrd9xrXUm4cvLzolZaUZKwiUKy004BaN3QhuaEBo17JxnWqpw2DN1JSIlwPkrnhx8vGxEcG5kLv1vV1e5rMiHo0SuW+w/WHkKuOHNIOV8yel/Ta79HMIzS2yhqoI1zuDfYxf11GQijn0H++9rsljtxwQB8cuEvreKDgmamDTU3f7dSsrq1EuKky5c764oI9EQxHDd+f1K8lXvvpX8vbLCkRSQEiO2pUK8UeXZriqTnKSMcjhrQ1NeV4p/o1cOmE7rj2zeSHh9rVS3HNJOvTVVS1LFbl8kszbUWi6ikjIaYvUsqIe6hNo1p4bpqze5+3zhyOf9ZvT3ptXM+dMEyTQ8hs6fhUUiepeqrzx3XFPM1IwoMHtMaz3/xtK9A9rtdO+HjRGpw1ujMOG9wWA9o19CRn6EG7tI4ncNcqLRG4/4hdbK3zlVOGYdB1HzptmnMXLc+6iHoZVwPfJ4/omDW3jWr2abtia2XYSQsd27NbM+yfofKkVXoBze91yrm7qXm9GhjVrRl+XbEpa2fFWaM7o16NsozVNvWcvmeiimBpicDCa8ah22XvmPpss7rpI4++u2S0o7QDbqhVXobPz0+eznb7IdankRcLBolyLFjmzjBmy5p0Ak7/3p9t+6n1IGDM1d5uI3bzd194Ii6xkax0ZNem+DjLQ7XufUy+PlBSXF0LPRheSU1oaIaTPatUs19mm56YqqlH07GyBRj1HjjWoj4qKmdiWY3DdD+zZ+BWtBbOp+QltUPky9gzHX0PVYJEHicp9VLN8tKkfdLONE4n9ulj3FFSp3oZkGH3v2Nyf5w7tiuG3/gxDskyxcwtasXDisa1cejANohEpfKAbuHac+yu7dOCRGZduHc3zHh7oa3P+u3ew3bOPOKgrrXRCH5pVrdG2gPdA0cmAh1zLx3teIp5pr3plBHJ5ezVvDR2+swOGdAG+/VthZrlpYZTxFJ9NH0PUwFRr+k9VLsRuDZk9Ps1GB2ox3Tyaw2vqpVa8dgx5nMc5QOj3/OjsZ/jwpeVisZGp+1a5WU4bU9zo+nUVdx6cN+0fJU1qpXi0aMHYFswkva5z88fiUCGThBAyYWXj8wUuylWTFydY24/1rdplC8JV/OVOw9dmXqbRLXqqKiciUcj4231bj1+bHIi42OGVeBgnV6oNHlSsamQqWV1M5VrtkOt9FDPRKJorSZ1TAZ0PP7Tq/v7BSYq02Vy5mhzNx4qvUpnx1iYJpdLq9EQP8j0XEtGxvfO/lC4U+VSjOnRHIcMcLc0a+Pa5Xj91F2drWSXY4HL1wP13BsSX+y0eYDcWZ+SL2VoR+/zdAHAEYPb4q0zdsPwzk1QrbQknhckV5eeA3fWPw78rBhr1oQ+LfJ+9O+Ju3fAmB7NLU09TNWkTnXbU7/s7Ebn7NUFx+5aoTtSJxshBGpaHIXWoWkdz4tq+M3r3GRVWTeXcikZufHA3njnrMwVaNXppv3bNrC1jXE9E/cu2Y7ZUd2b6+5PbRrVilfqpcLhf3i8inGSC+KtM3ZDeVkJRt/2afy1R48eiC7N61qa2+w2vfLSSVOvJj/neRvShp/XagJs158eZkcu70lHdW+GUiHw4vfZh/VWJaN7NMeunRpj+pj0kqF2DWjXCJ8vXmuq6pcV6mgaq/vNW2fshj/XKonxzhnTBQ9+mpxjJtePHJ0dXtStnu5Se6Y87SnNoUXXjjPMzwIAsyNDsV/pHIjeB+LhcfbLneslRO3ftgFePmmY8zxEQgCiMKb56OnXpkHOt3nMsAq0b1Ibxz7xXc637QYhRHw0kZbTpMGG+U5MOnyI9aBGAcSVcq5xnep4+Cj75xu3WAn61atRDVfs29PD1hQfvSmfqn36tIjnXPGKXlA5/lLPA+ytdNgZQKdRdpuUE5+dNxKNzHb82fDBObubqkA5qntz/HnDeNvB9XsP3xnhaPIoIDOrUqtn1tApc2+G2RF8y2ZM8PUZuJgxSJRjpQ7uVPRu1sKR/BxNkhQk6jzaeEGX/HzFXskv7HIM8PktQB3vyiQ/PXUQPpj/n+vrLSspScuTobvXVLG73jrVy0znB7IqX46iZvVqxHstzxjVGWekJNRUe6bdqOySyfG7tcdHC1ejn82eJ1VHi9VM9uvbEp2a1cGEu7In1zfjqKHt4qWL/dKqQc2sPe0hKO932cnZiLbXTt0Vg65PzltRo6y0oBJVO3Xi7h2SEiwDwOLr9s5JksxUJSUCI7s1w4wDemOXdu6OVvSD+pDh9yBWvak3VHiOGtoO//v5X4ztWRhT7wrV8bt1wPG7dbD0IO3kbCm1hXJ0KMnHgS8mfY3hvTvpLpPVXtfY+1wOtW3sXR5NAKYCRConoy9LSwRKS6wHeqbv1RU71a+BfTNMszby42VjUM1EvkCzTty9Ax763Fwib0pgkChHfqs9FL22zXF9vR2aGs+rHljh301pKMe7ljpPPW7ERUDHPZUS9B7ZtWMT7Na5qe5IKqs+PW8EVmzYgZ+Wb8SQDkqCv6sn9kQkKnHV/+aji3bI6uCTgVeOBxp1cLzdqq7Q4myzpg3Fqz+u8Lznb1jHJpZH8ahB7IMHtMaHC5VKhlZvTIQQ6NmyvqXPZHL1RPvJcZPUtleN8tPzRqBBTZ2exNLqQCRRMWhBtB1Q+gXQwP60D0AJMnZtXheL/tsSf63Q9nGnLhrfPe21tOtDjjmZzpNP1F3J8RXP433y8WMGFuzoraqkU7O6+PHyvbIvSDnz/LQhOPShr9HEhTws6rUn9XwxrFNjfLJoDYI1GgGl3t7LkLum7d4Bny9ei927ZM83WbO8FMfvZu85xU4uzUwuGt9d994gk4+m72F5emqxYZAoR75odKAnQSKjYXwfnzsiubKGh/JlFEaS0jKgwmEOjhxq17g22jWujWGaUQ9HxcqmTujdInlOfJ+Dlf+oyum6U11cuLezPEFeadmgZjyw9MKJQ/Hn2q0+t8i50d2bA0dvsv15w+So0xcCNyXKeD8a2RuXnjoNaNnP9raIcsVuv4hb5dSzGdnNXlCXqFDs2smbvGSDOzTGzQf1cSXvmVEsuIr1WxSV7i3qYe6l3s8OyQcdLI6EL0ZMXJ0juQ6ktG9SG7XzoCJDsXCaQ8EJP5ImFsPUCD91bq5cXNpkqapVrAa1b4RDB+Zu9IRX0+/6tnZvVFOSWsnlgCVKXAsQVbWRQ2TM7apMdvat0hKBy/bpgQ/O2QPX7a+M7OvroILR0UPb2f6sm9o3SQ4A72GiZ53ILU8dN9iV9UikXz8PHtAma0XQjOv08oGnw0gPV05EWowi5Egub9yPsnkTxYcLY9l+N2UlApdMsDaUMZ89d8IQhCKZy1UWilsP7osFKzfrvlc9Nue53OXpKEcOaYfereqjv8tV0yi3CvGc2KAWh+8T8PixAx0nnk8lbE44mzpcGTXXqVkdLLlub5SZPN/qTattZbJi3FFD2+GpOX/Fv3f7UE4NwD12zECEo1F0vfQdl7dElOzXK/fK68p5JSmFO1KDRj1b1sfHi9bYyy122PNAcJvDFlKhO29sVzR2eUoapWOQKEcOG9QW+BtoWtf5Tv3BObtj9G2fpfVkqezm4bAb/W/byN/REg8csYvn28h0ORZCYMn14z1vQy6Vl6Unzy5UB2YolXv0sApsDYRxwu7u5ncSQjBAVAQKodR2qieOHYShN3yIew/fGYc9/A267ZRe8ICK38iu7k+5Ug+HqIP+A7MBIkC5Dj113CAc9di39jeYI6aSu466Amjl/f0KFbe6NfK7I+CxYwbiuW//xs//bMR/mwNpeTvPHtMFe/Vsjl6tbIzULauu/EdV2qkjbSY8J0scBYmEEI0APA+gAsAyAIdIKTcYLFsPwHwAr0kpT3Oy3UJUL9Yj5kaFlU7N6uLPG/SDEmN6eFfNy8hxu7ZHt53q4c4Pf8d3y3T//AVP789WgM+PlKJGtVJM36ur382gPOXkfP3QkeYfBicPbGN7O6lqVCuNJ4N9+eSh6ONgag+Rlh+XPLuHoFdt/eGyMQCAo2OBq0sndEdTs/kfdzvHo1YRmXfmqM6488PFAIDWDWpiayDs6vo7NauDy/bpgYMf+Er3/dISweuSAxWNa2FZSgVPIi84HSpwIYAPpZSdAXwY+97INQA+c7g9ihFC6PZyP+hgVI3dm7GSEoHhnXXKTNduClTPRS+29xmf/MxJRFTVvHnGcHx54Z6ml08dBTmsY2PspndOykCvmpuTEf1mA/b/ykZJCevdtEu7Rr5X9qLi41UOMD2ped38vhY3ql2ORrXL47+DQe0bYWK/VknLWD33UNU0rGPjeDXbXDpzVOf415Y6yZoWT0qFQvbOWbvj1ytZFZC853S62UQAI2JfPwngEwAXpC4khNgFQHMA7wAY4HCbhcnTTG4JJT7OU067eZu+KGc/t9fyef43UbHp2dJ+wugDdm6F2w7p50o7GtbSnx48omtTfLJoTcbPmp2qtl/gOlxuuWVEuaeOrMvlZb3CYFp9NrmaKpp63/P7tXvzfoFMmXnCEEvLv3zyUHy9dL2rbSgvKzGX2+XUb4E61mYqqMdGcTwF5I8a1UoNK1sTuclpF2NzKeXK2NeroASCkgghSgDcCuBch9sij913+M6Y0LsFWjYwlxgyVdo9WUmpUoqeiCgHJvRp4VqA6Oih7TCpfyvd9x4+yr2+jrXwqIIakdvURLQ+NsFsACY1sbTbQSN1/SUpd9HlZSUMEpEndmnXyJVcLKmHgpqTMWMBj6ZdgZoNLG7I2uJElF+yBomEEB8IIX7T+W+idjmpZCbTu3c4BcBbUsrlJrY1TQgxVwgxd82azL20BacAEtj0ad0A9x6+s+0bnFz8iCO6Nk3r9chFr2YB/PmIyEVXTexlmLzdrSlc30aZD4sKj58DhA8f0tbUcqft6W1i07um9McF47qhRwsmhqfCpl7P3L7PPXZYBQC4XmWR3NGusb9Fh9zWyuYABzKWdZiHlHK00XtCiP+EEC2klCuFEC0ArNZZbCiA3YQQpwCoA6BcCLFVSpmWv0hK+RCAhwBgwIABHKFoweD2jfDNn+4OQ7XK61wB310yGvVqlmHYDR95uh0iKiy7d26Kisa1cLrHD4auOv0HHHPzT363gsg0v/tK7jmsP6qXmZtm4fV0jGZ1a+DkER093QaRm2pUK0FlKJoW5PUq6Lt37xa6uf7If79dNRZlRTTi8csL90TdGpy54janv9HZAI4GMCP27+upC0gpD1e/FkIcA2CAXoCInJl5whBEfc7/kzrs2m2pFURqVivFjlAkJ0Pf9UYOFGJ5bKJiVL9WNXxy3ki/m2FN447YjoUAkFYimCgfje/dAu/8tgrn7NXF76YQkUWvnzocHy1cbZi7lLe0VUfqdNxCx1FE3nD6WD8DwBghxGIAo2PfQwgxQAjxiNPGkXmlJcL3KjY1q+XmpKM+TvVulbtcHlOHt8eJsXnbRERPHDvQ7yYQ5VTt6mV49JiBvt2Q+13ZjKiQdd2pLke/EZFpjqIKUsp1UspRUsrOUsrRUsr1sdfnSimP11n+CSnlaU62Sfmre4u6Od2empugX5sGnm+rRrVSXDSe5T+JSDGiazO/m0BERERE5LriGm9GVYI6NWN4pyY5n+/con4NrNxUmdNtEhERkX0cg0SUUFrCcXlElJm/85Oqkhb9lH93PdPXZhQTP3ICvXPW7jnfJhEREVnTsn4Nv5tAlJfmXTUWv1011u9mEFEeY5AoV2o1Aq7cBHTc0++WeOawweZK0zrlZ4rX+jWr+bh1Isp3u3VugnE9d/K7GURFZ1R3a1M8x/bicUikp0a10rQKgKyfQERanG5GrmlRP5HM8q4p/T3fHofKElG+OWt0F+zSrqHfzSAqGq+eMgyRqPS8rD1RVcSqZkSkhyOJyBMNPBxxs2csYWz1atx9iYiIiln/tg0xoKKR380gIiKqMjiSiDzh5ajVGQf2wfSxXVGrnLsvERERZcbREkREROZxKAYVnPKyErRqUDP7gkRERFQlsX4TERGRPQwSkScGt+fQcCKqeprWqe53E4gIQIemtf1uAlHeY8JqItLDIBF5ggkmiagqatu4lt9NICIAh+eo4ipRMeCUTCLSYpCIiIjIR/3aNPC7CURFR/Cpl4iIyBYGiYiIiAC0qF/Dl+22a8xpMUReYsCIKDNOOyMiLQaJiGzoy55/oqIzuntzv5tARESUM4yfEpEeBonIdcWetPrz80di5vGD/W4GEbnsin17+N0EInLRhN4tUK2UT8FERERWlPndACou868ei2qlxR17bNOIiWmJilFZkZ+7iKqaew/f2e8mEBERFRzeEZOrapWXFX2QiIgIAPbs1szvJhARERERuYpP80RERDY4ncQyqMin5hIRERFR4eF0MyIiIhtSE352b1HP0uefPHYQNu4IutgiIiIiIiJnGCQiIiJywT59WlhavmZ5KWqW1/SoNURERERE1nG6GRERkS3JQ4mklD61g4iIiIjIHQwSERER2ZA63YyIiKiQlMQuZMyRR0RanG5GRERkQ2qMSDBqREREBaS8rATvnLUb2jSs5XdTiCiPcCQRERGRAx2a1va7CURERLZ026kealfnuAEiSnAUJBJCNBJCvC+EWBz7t6HBcm2FEO8JIRYIIeYLISqcbJeIiMgrnZrVMbVcfOAQUxERERERUZFwOpLoQgAfSik7A/gw9r2epwDcLKXsDmAQgNUOt0tEROS6ny/fC2+cPtzUsvVqVAOgDNcnIiIiIioGTscWTgQwIvb1kwA+AXCBdgEhRA8AZVLK9wFASrnV4TaJiIg8Ub9WNdPLXr5vD3RqVgfrtwexcNUWD1tFRERERJQbTrs/m0spV8a+XgWguc4yXQBsFEK8IoT4UQhxsxCi1OF2iYiIfFW3RjWcuEfHeHUYIiIiIqJCl3UkkRDiAwA76bx1ifYbKaUUQuhlZigDsBuA/gD+BvA8gGMAPKqzrWkApgFA27ZtszWNiIjIdwPaKen4+rVp4G9DiIiIiIgcElLaz7gphFgEYISUcqUQogWAT6SUXVOWGQLgRinlHrHvjwQwREp5aqZ1DxgwQM6dO9d224iIiHJl/bYgGtUu97sZRERERERZCSG+l1IO0HvP6XSz2QCOjn19NIDXdZb5DkADIUTT2Pd7ApjvcLtERER5gwEiIiIiIioGToNEMwCMEUIsBjA69j2EEAOEEI8AgJQyAuBcAB8KIX4FIAA87HC7RERERERERETkIkfVzaSU6wCM0nl9LoDjNd+/D6CPk20REREREREREZF3nI4kIiIiIiIiIiKiIsAgERERERERERERMUhEREREREREREQMEhERERERERERERgkIiIiIiIiIiIiMEhERERERERERERgkIiIiIiIiIiIiMAgERERERERERERARBSSr/boEsIsQbAX363wyVNAKz1uxFELuN+TcWI+zUVI+7XVIy4X1Mx4n5NudJOStlU7428DRIVEyHEXCnlAL/bQeQm7tdUjLhfUzHifk3FiPs1FSPu15QPON2MiIiIiIiIiIgYJCIiIiIiIiIiIgaJcuUhvxtA5AHu11SMuF9TMeJ+TcWI+zUVI+7X5DvmJCIiIiIiIiIiIo4kIiIiIiIiIiIiBok8J4QYJ4RYJIRYIoS40O/2EKUSQjwmhFgthPhN81ojIcT7QojFsX8bxl4XQoi7YvvzL0KInTWfOTq2/GIhxNGa13cRQvwa+8xdQgiR25+QqhohRBshxMdCiPlCiHlCiDNjr3O/poIlhKghhPhWCPFzbL++KvZ6eyHEN7F98XkhRHns9eqx75fE3q/QrOui2OuLhBBjNa/znoV8IYQoFUL8KIR4I/Y992sqaEKIZbH7hJ+EEHNjr/E+hAoCg0QeEkKUArgXwN4AegCYIoTo4W+riNI8AWBcymsXAvhQStkZwIex7wFlX+4c+28agPsB5aIH4AoAgwEMAnCFeuGLLXOC5nOp2yJyWxjAdCllDwBDAJwaO/dyv6ZCFgCwp5SyL4B+AMYJIYYAuBHA7VLKTgA2AJgaW34qgA2x12+PLYfYsTAZQE8o++19sQd03rOQn84EsEDzPfdrKgYjpZT9NCXteR9CBYFBIm8NArBESrlUShkEMAvARJ/bRJRESvkZgPUpL08E8GTs6ycBTNK8/pRUfA2ggRCiBYCxAN6XUq6XUm4A8D6UB5gWAOpJKb+WSgK0pzTrIvKElHKllPKH2NdboDx4tAL3aypgsf1za+zbarH/JIA9AbwUez11v1b395cAjIr1NE8EMEtKGZBS/glgCZT7Fd6zkC+EEK0BTADwSOx7Ae7XVJx4H0IFgUEib7UC8I/m++Wx14jyXXMp5crY16sANI99bbRPZ3p9uc7rRDkRm4rQH8A34H5NBS42MuInAKuhPCz8AWCjlDIcW0S7L8b339j7mwA0hvX9nchrdwA4H0A09n1jcL+mwicBvCeE+F4IMS32Gu9DqCCU+d0AIspvUkophGAZRCo4Qog6AF4GcJaUcrN2uj73aypEUsoIgH5CiAYAXgXQzd8WETkjhNgHwGop5fdCiBE+N4fITcOllCuEEM0AvC+EWKh9k/chlM84kshbKwC00XzfOvYaUb77LzaUFbF/V8deN9qnM73eWud1Ik8JIapBCRA9K6V8JfYy92sqClLKjQA+BjAUyrQEtdNPuy/G99/Y+/UBrIP1/Z3IS7sC2E8IsQzKVLA9AdwJ7tdU4KSUK2L/roYS1B8E3odQgWCQyFvfAegcq9BQDiWh3myf20RkxmwAagWFowG8rnn9qFgVhiEANsWGzb4LYC8hRMNYQr29ALwbe2+zEGJILGfAUZp1EXkitq89CmCBlPI2zVvcr6lgCSGaxkYQQQhRE8AYKPm2PgZwUGyx1P1a3d8PAv7f3h2j7lEHcRz+jNqI2AlBSGHOYWPtASQQUoid2kssNYWnEERQ+TdCCNEqB9DCwiSVjZDa0iowFrspPECILz4PLLvFFlv8FoYvzEwPz9kV96qb55aoGx0DT39JzcJLsLt3dvf67r7TceYe7u6tnGsu2My8MTNvPn/uqB8epQ7hQmg3e4F299nMfNrxg79afb27j1/yZ8G/zMz31XvVWzPztGOLwlfV1cx8VP1ZfXC+/qB6v2Mg5N/Vh1W7+9fMfNlRjFV9sbvPh2F/3LFB7fXqp/OCF+nd6nb1+zm/perznGsu29vVN+e2pleqq929PzNPqh9m5m71W0dA2nn/dmb+6FhOcLNqdx/PzFX1pGMT4CdnG1tqFv5DPsu55nJdq34829xfq77b3Z9n5tfUIVyAOcJ3AAAAAP7PtJsBAAAAICQCAAAAQEgEAAAAQEIiAAAAABISAQAAAJCQCAAAAICERAAAAAAkJAIAAACg+gd0cwtbHfwqawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(m1)\n",
    "plt.plot(m2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
