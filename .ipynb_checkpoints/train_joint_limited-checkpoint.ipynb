{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install squaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "from ascento_gym import Ascento\n",
    "# from balance_pend import InvertedPendulumEnv as Ascento\n",
    "from stable_baselines3 import PPO, DDPG, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# env = Ascento()\n",
    "# env.reset_model()\n",
    "# for i_episode in range(150):\n",
    "#     observation = env.reset()\n",
    "#     done = None\n",
    "#     while not done:\n",
    "#         env.render()\n",
    "# #         print(env.yaw)\n",
    "#         action = env.action_space.sample()\n",
    "# #         action[2] = 1\n",
    "# #         action[3] = 1\n",
    "\n",
    "#         observation, reward, done, info = env.step(action)\n",
    "        \n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurav/.local/lib/python3.6/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "env = Ascento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.99203269e+00, -3.94715705e-03,  9.08574160e-03, -1.87771423e-02,\n",
       "       -2.14901822e-03, -7.26330789e-03,  5.96406654e-03, -3.54618384e-03,\n",
       "       -1.79297070e-03,  7.47014570e-03, -9.87179929e-03, -3.85978500e-03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1. -1. -1. -1.], [1. 1. 1. 1.], (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19845325,  0.16769633,  0.7630682 , -0.9116251 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.05407269e-01,  1.89018772e-03,  6.42801380e-01, -1.26879187e+00,\n",
       "       -4.80540373e-01,  6.40902331e-01,  4.36875153e-01,  1.06286889e+00,\n",
       "       -7.64407159e-01, -8.86302845e-01, -1.19013299e+00, -2.61399310e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = make_vec_env(Ascento, n_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Ascento()\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'models_ascento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold = 20*1e5, verbose = 1)\n",
    "\n",
    "eval_callback = EvalCallback(env, callback_on_new_best = stop_callback,\n",
    "                            eval_freq = 5000, best_model_save_path = save_path, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "logs_dir = os.path.join('Training', 'logs_dir_ascento')\n",
    "model = SAC('MlpPolicy', vec_env, verbose = 1, tensorboard_log = logs_dir, create_eval_env = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load('/home/bmsit/Ascento/jointed_limited/Training/models_ascento/best_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"/home/gaurav/final_year_project/Ascetno_RL_Joint_Limited/Training/model_for_demo.zip\", env = vec_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/logs_dir_ascento/PPO_71\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 86.7      |\n",
      "|    ep_rew_mean     | -2.07e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 4         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 670         |\n",
      "|    ep_rew_mean          | -8.41e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004705847 |\n",
      "|    clip_fraction        | 0.0308      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.8         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52e+05    |\n",
      "|    n_updates            | 15920       |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    std                  | 0.257       |\n",
      "|    value_loss           | 2.9e+05     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurav/.local/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5000, episode_reward=-31095.95 +/- 587.72\n",
      "Episode length: 2999.80 +/- 0.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3e+03        |\n",
      "|    mean_reward          | -3.11e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051278244 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.31e+04     |\n",
      "|    n_updates            | 15930        |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 1.09e+05     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 670       |\n",
      "|    ep_rew_mean     | -8.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 333       |\n",
      "|    iterations      | 3         |\n",
      "|    time_elapsed    | 18        |\n",
      "|    total_timesteps | 6144      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -1.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 393         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008903028 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 373         |\n",
      "|    n_updates            | 15940       |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    std                  | 0.257       |\n",
      "|    value_loss           | 4.79e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gaurav/.local/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=-13774.84 +/- 14394.37\n",
      "Episode length: 1254.00 +/- 1425.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.25e+03    |\n",
      "|    mean_reward          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009116658 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 838         |\n",
      "|    n_updates            | 15950       |\n",
      "|    policy_gradient_loss | -0.00825    |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 8.13e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -1.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 377       |\n",
      "|    iterations      | 5         |\n",
      "|    time_elapsed    | 27        |\n",
      "|    total_timesteps | 10240     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -1.52e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 413          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072469665 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.804        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.59e+03     |\n",
      "|    n_updates            | 15960        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    std                  | 0.256        |\n",
      "|    value_loss           | 8.38e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | -1.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 444         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015542664 |\n",
      "|    clip_fraction        | 0.0998      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.8        |\n",
      "|    n_updates            | 15970       |\n",
      "|    policy_gradient_loss | 0.000516    |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 2.74e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-40855.26 +/- 249.05\n",
      "Episode length: 3000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3e+03       |\n",
      "|    mean_reward          | -4.09e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 15000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006744818 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.67e+03    |\n",
      "|    n_updates            | 15980       |\n",
      "|    policy_gradient_loss | -0.00309    |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 5.89e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -2.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 372       |\n",
      "|    iterations      | 8         |\n",
      "|    time_elapsed    | 44        |\n",
      "|    total_timesteps | 16384     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.54e+03   |\n",
      "|    ep_rew_mean          | -2.15e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 396        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00805895 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.74       |\n",
      "|    explained_variance   | 0.666      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.45e+03   |\n",
      "|    n_updates            | 15990      |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    std                  | 0.255      |\n",
      "|    value_loss           | 3.71e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-40706.79 +/- 19328.07\n",
      "Episode length: 2418.80 +/- 1162.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.42e+03    |\n",
      "|    mean_reward          | -4.07e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012687143 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.2        |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | -0.00644    |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -2.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 362       |\n",
      "|    iterations      | 10        |\n",
      "|    time_elapsed    | 56        |\n",
      "|    total_timesteps | 20480     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -2.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006242174 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.75        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.52e+03    |\n",
      "|    n_updates            | 16010       |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 4.46e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.75e+03     |\n",
      "|    ep_rew_mean          | -2.79e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 400          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 61           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053266995 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.847        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 16020        |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    std                  | 0.254        |\n",
      "|    value_loss           | 3.54e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=25000, episode_reward=-32262.30 +/- 24653.81\n",
      "Episode length: 1837.00 +/- 1424.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.84e+03     |\n",
      "|    mean_reward          | -3.23e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 25000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053492263 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.5e+05      |\n",
      "|    n_updates            | 16030        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    std                  | 0.254        |\n",
      "|    value_loss           | 9.74e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -2.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 383       |\n",
      "|    iterations      | 13        |\n",
      "|    time_elapsed    | 69        |\n",
      "|    total_timesteps | 26624     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | -2.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 398          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 71           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064933877 |\n",
      "|    clip_fraction        | 0.0858       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 329          |\n",
      "|    n_updates            | 16040        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    std                  | 0.254        |\n",
      "|    value_loss           | 1.72e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-31488.92 +/- 24029.39\n",
      "Episode length: 1837.20 +/- 1424.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.84e+03    |\n",
      "|    mean_reward          | -3.15e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 30000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009613531 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.76        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.66e+05    |\n",
      "|    n_updates            | 16050       |\n",
      "|    policy_gradient_loss | 0.000534    |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 3.26e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -2.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 383       |\n",
      "|    iterations      | 15        |\n",
      "|    time_elapsed    | 80        |\n",
      "|    total_timesteps | 30720     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -2.61e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 396         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 82          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022256164 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.76        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.1        |\n",
      "|    n_updates            | 16060       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 438         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | -2.82e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 406          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 85           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075575924 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+04     |\n",
      "|    n_updates            | 16070        |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    std                  | 0.253        |\n",
      "|    value_loss           | 1.54e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-37934.98 +/- 29347.21\n",
      "Episode length: 1835.40 +/- 1426.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.84e+03    |\n",
      "|    mean_reward          | -3.79e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 35000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030486658 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.76        |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 16080       |\n",
      "|    policy_gradient_loss | -0.000901   |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 1.31e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.61e+03  |\n",
      "|    ep_rew_mean     | -2.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 390       |\n",
      "|    iterations      | 18        |\n",
      "|    time_elapsed    | 94        |\n",
      "|    total_timesteps | 36864     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.68e+03     |\n",
      "|    ep_rew_mean          | -3e+04       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 402          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059409775 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 209          |\n",
      "|    n_updates            | 16090        |\n",
      "|    policy_gradient_loss | 0.0012       |\n",
      "|    std                  | 0.252        |\n",
      "|    value_loss           | 789          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-51181.96 +/- 24558.36\n",
      "Episode length: 2417.80 +/- 1164.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.42e+03    |\n",
      "|    mean_reward          | -5.12e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008359274 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.36e+03    |\n",
      "|    n_updates            | 16100       |\n",
      "|    policy_gradient_loss | 0.00039     |\n",
      "|    std                  | 0.252       |\n",
      "|    value_loss           | 2.93e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -3.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 384       |\n",
      "|    iterations      | 20        |\n",
      "|    time_elapsed    | 106       |\n",
      "|    total_timesteps | 40960     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -3.34e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 394         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 109         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006006279 |\n",
      "|    clip_fraction        | 0.0616      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 791         |\n",
      "|    n_updates            | 16110       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 0.252       |\n",
      "|    value_loss           | 1.25e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=-65694.48 +/- 694.65\n",
      "Episode length: 3000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3e+03        |\n",
      "|    mean_reward          | -6.57e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 45000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056116134 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.77         |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.68e+04     |\n",
      "|    n_updates            | 16120        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    std                  | 0.252        |\n",
      "|    value_loss           | 1.8e+04      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -3.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 373       |\n",
      "|    iterations      | 22        |\n",
      "|    time_elapsed    | 120       |\n",
      "|    total_timesteps | 45056     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.84e+03    |\n",
      "|    ep_rew_mean          | -3.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 382         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 123         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014153546 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31          |\n",
      "|    n_updates            | 16130       |\n",
      "|    policy_gradient_loss | 0.00434     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.81e+03     |\n",
      "|    ep_rew_mean          | -3.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 391          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049015675 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.79         |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 373          |\n",
      "|    n_updates            | 16140        |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    std                  | 0.251        |\n",
      "|    value_loss           | 3.07e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-39240.44 +/- 30358.15\n",
      "Episode length: 1836.00 +/- 1425.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.84e+03     |\n",
      "|    mean_reward          | -3.92e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058280453 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.79         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.54e+04     |\n",
      "|    n_updates            | 16150        |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    std                  | 0.251        |\n",
      "|    value_loss           | 1.23e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.81e+03  |\n",
      "|    ep_rew_mean     | -3.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 382       |\n",
      "|    iterations      | 25        |\n",
      "|    time_elapsed    | 133       |\n",
      "|    total_timesteps | 51200     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.8e+03    |\n",
      "|    ep_rew_mean          | -3.54e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 391        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 136        |\n",
      "|    total_timesteps      | 53248      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01296087 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.78       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 74.1       |\n",
      "|    n_updates            | 16160      |\n",
      "|    policy_gradient_loss | -0.00232   |\n",
      "|    std                  | 0.251      |\n",
      "|    value_loss           | 191        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-37441.89 +/- 28850.70\n",
      "Episode length: 1837.60 +/- 1423.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.84e+03    |\n",
      "|    mean_reward          | -3.74e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 55000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006640255 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+04    |\n",
      "|    n_updates            | 16170       |\n",
      "|    policy_gradient_loss | 0.00288     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 8.85e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.84e+03  |\n",
      "|    ep_rew_mean     | -3.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 381       |\n",
      "|    iterations      | 27        |\n",
      "|    time_elapsed    | 144       |\n",
      "|    total_timesteps | 55296     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.84e+03    |\n",
      "|    ep_rew_mean          | -3.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 389         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009460507 |\n",
      "|    clip_fraction        | 0.0619      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.77e+03    |\n",
      "|    n_updates            | 16180       |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 3.7e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.87e+03   |\n",
      "|    ep_rew_mean          | -3.75e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 397        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 149        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02181631 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.79       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 56.2       |\n",
      "|    n_updates            | 16190      |\n",
      "|    policy_gradient_loss | 0.000585   |\n",
      "|    std                  | 0.251      |\n",
      "|    value_loss           | 181        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-50774.03 +/- 24348.02\n",
      "Episode length: 2419.80 +/- 1160.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.42e+03     |\n",
      "|    mean_reward          | -5.08e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072878357 |\n",
      "|    clip_fraction        | 0.0829       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.78         |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.41e+03     |\n",
      "|    n_updates            | 16200        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    std                  | 0.251        |\n",
      "|    value_loss           | 1.75e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.91e+03  |\n",
      "|    ep_rew_mean     | -3.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 384       |\n",
      "|    iterations      | 30        |\n",
      "|    time_elapsed    | 159       |\n",
      "|    total_timesteps | 61440     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.91e+03    |\n",
      "|    ep_rew_mean          | -3.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 391         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 162         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006686285 |\n",
      "|    clip_fraction        | 0.049       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.52e+03    |\n",
      "|    n_updates            | 16210       |\n",
      "|    policy_gradient_loss | -0.000879   |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 1.77e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-53027.17 +/- 25488.38\n",
      "Episode length: 2418.00 +/- 1164.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.42e+03    |\n",
      "|    mean_reward          | -5.3e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 65000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013399678 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 16220       |\n",
      "|    policy_gradient_loss | 0.0052      |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 280         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -3.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 381       |\n",
      "|    iterations      | 32        |\n",
      "|    time_elapsed    | 171       |\n",
      "|    total_timesteps | 65536     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.82e+03     |\n",
      "|    ep_rew_mean          | -3.77e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 387          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052411244 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.79         |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.29e+04     |\n",
      "|    n_updates            | 16230        |\n",
      "|    policy_gradient_loss | -0.000867    |\n",
      "|    std                  | 0.251        |\n",
      "|    value_loss           | 1.08e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.82e+03     |\n",
      "|    ep_rew_mean          | -3.77e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 393          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 176          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032029082 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.79         |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.31e+04     |\n",
      "|    n_updates            | 16240        |\n",
      "|    policy_gradient_loss | -0.00075     |\n",
      "|    std                  | 0.251        |\n",
      "|    value_loss           | 1.76e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-78555.04 +/- 426.36\n",
      "Episode length: 3000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3e+03       |\n",
      "|    mean_reward          | -7.86e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019398432 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.7        |\n",
      "|    n_updates            | 16250       |\n",
      "|    policy_gradient_loss | 0.0022      |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.85e+03  |\n",
      "|    ep_rew_mean     | -3.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 380       |\n",
      "|    iterations      | 35        |\n",
      "|    time_elapsed    | 188       |\n",
      "|    total_timesteps | 71680     |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.88e+03  |\n",
      "|    ep_rew_mean          | -3.99e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 386       |\n",
      "|    iterations           | 36        |\n",
      "|    time_elapsed         | 190       |\n",
      "|    total_timesteps      | 73728     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0319851 |\n",
      "|    clip_fraction        | 0.154     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.79      |\n",
      "|    explained_variance   | 0.946     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 180       |\n",
      "|    n_updates            | 16260     |\n",
      "|    policy_gradient_loss | 0.00417   |\n",
      "|    std                  | 0.25      |\n",
      "|    value_loss           | 5.53e+03  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=75000, episode_reward=-38336.31 +/- 44290.92\n",
      "Episode length: 1258.00 +/- 1422.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.26e+03    |\n",
      "|    mean_reward          | -3.83e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 75000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008116335 |\n",
      "|    clip_fraction        | 0.0472      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.07e+04    |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | 0.000237    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 2.48e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -3.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 384       |\n",
      "|    iterations      | 37        |\n",
      "|    time_elapsed    | 197       |\n",
      "|    total_timesteps | 75776     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | -4.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 389         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 199         |\n",
      "|    total_timesteps      | 77824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012944131 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 16280       |\n",
      "|    policy_gradient_loss | 0.00252     |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 6.38e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.92e+03    |\n",
      "|    ep_rew_mean          | -4.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 202         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019551637 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38e+03    |\n",
      "|    n_updates            | 16290       |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 5.43e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-97672.06 +/- 1497.78\n",
      "Episode length: 3000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3e+03       |\n",
      "|    mean_reward          | -9.77e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005876804 |\n",
      "|    clip_fraction        | 0.0851      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.05e+03    |\n",
      "|    n_updates            | 16300       |\n",
      "|    policy_gradient_loss | -0.00409    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 5.63e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -4.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 382       |\n",
      "|    iterations      | 40        |\n",
      "|    time_elapsed    | 213       |\n",
      "|    total_timesteps | 81920     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | -4.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 216         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010490429 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.85e+03    |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 1.35e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-67478.22 +/- 53313.03\n",
      "Episode length: 1839.20 +/- 1421.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.84e+03    |\n",
      "|    mean_reward          | -6.75e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 85000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008117375 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.4e+04     |\n",
      "|    n_updates            | 16320       |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 1.23e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.91e+03  |\n",
      "|    ep_rew_mean     | -4.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 383       |\n",
      "|    iterations      | 42        |\n",
      "|    time_elapsed    | 224       |\n",
      "|    total_timesteps | 86016     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.91e+03     |\n",
      "|    ep_rew_mean          | -4.33e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 387          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 226          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057525034 |\n",
      "|    clip_fraction        | 0.0589       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.79         |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.8e+03      |\n",
      "|    n_updates            | 16330        |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    std                  | 0.25         |\n",
      "|    value_loss           | 5.43e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=-79176.71 +/- 365.97\n",
      "Episode length: 2453.40 +/- 3.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.45e+03    |\n",
      "|    mean_reward          | -7.92e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015283942 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 319         |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | 2.33e-05    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 4.71e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.91e+03  |\n",
      "|    ep_rew_mean     | -4.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 380       |\n",
      "|    iterations      | 44        |\n",
      "|    time_elapsed    | 236       |\n",
      "|    total_timesteps | 90112     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | -4.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 384         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 239         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008071557 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 689         |\n",
      "|    n_updates            | 16350       |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 5.16e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -4.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 389         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 241         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010615084 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.07e+04    |\n",
      "|    n_updates            | 16360       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 2.14e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=-33616.63 +/- 79.30\n",
      "Episode length: 1639.20 +/- 6.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.64e+03    |\n",
      "|    mean_reward          | -3.36e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 95000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016481692 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.91e+03    |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | 0.00615     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 7.97e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.78e+03  |\n",
      "|    ep_rew_mean     | -4.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 385       |\n",
      "|    iterations      | 47        |\n",
      "|    time_elapsed    | 249       |\n",
      "|    total_timesteps | 96256     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | -4e+04      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 389         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 252         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008390933 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.78e+04    |\n",
      "|    n_updates            | 16380       |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 2.47e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-24232.77 +/- 11061.64\n",
      "Episode length: 1276.00 +/- 590.63\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.28e+03   |\n",
      "|    mean_reward          | -2.42e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 100000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01091264 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.78       |\n",
      "|    explained_variance   | 0.911      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 122        |\n",
      "|    n_updates            | 16390      |\n",
      "|    policy_gradient_loss | 0.0176     |\n",
      "|    std                  | 0.251      |\n",
      "|    value_loss           | 2.05e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.77e+03  |\n",
      "|    ep_rew_mean     | -3.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 387       |\n",
      "|    iterations      | 49        |\n",
      "|    time_elapsed    | 258       |\n",
      "|    total_timesteps | 100352    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | -3.87e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 391         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 261         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011975982 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.5        |\n",
      "|    n_updates            | 16400       |\n",
      "|    policy_gradient_loss | 0.000851    |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 4.11e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -3.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 263         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010072789 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 210         |\n",
      "|    n_updates            | 16410       |\n",
      "|    policy_gradient_loss | 0.00767     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 7.97e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-22558.61 +/- 66.62\n",
      "Episode length: 1340.40 +/- 7.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.34e+03    |\n",
      "|    mean_reward          | -2.26e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 105000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024402369 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 84.1        |\n",
      "|    n_updates            | 16420       |\n",
      "|    policy_gradient_loss | 0.00748     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 378         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -3.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 393       |\n",
      "|    iterations      | 52        |\n",
      "|    time_elapsed    | 270       |\n",
      "|    total_timesteps | 106496    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -3.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 397         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 272         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009258775 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.789       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+04    |\n",
      "|    n_updates            | 16430       |\n",
      "|    policy_gradient_loss | -4.35e-05   |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 1.12e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-20674.81 +/- 64.11\n",
      "Episode length: 1279.60 +/- 5.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.28e+03    |\n",
      "|    mean_reward          | -2.07e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009308188 |\n",
      "|    clip_fraction        | 0.0813      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 16440       |\n",
      "|    policy_gradient_loss | -0.000606   |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 1.2e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -3.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 395       |\n",
      "|    iterations      | 54        |\n",
      "|    time_elapsed    | 279       |\n",
      "|    total_timesteps | 110592    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -3.53e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 281         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014078844 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 16450       |\n",
      "|    policy_gradient_loss | 0.00268     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 557         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | -3.51e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 403          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 284          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074192923 |\n",
      "|    clip_fraction        | 0.0689       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.78         |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.96e+05     |\n",
      "|    n_updates            | 16460        |\n",
      "|    policy_gradient_loss | 0.000808     |\n",
      "|    std                  | 0.251        |\n",
      "|    value_loss           | 1.02e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-13920.72 +/- 5877.28\n",
      "Episode length: 948.60 +/- 424.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 949         |\n",
      "|    mean_reward          | -1.39e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 115000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014519209 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.1        |\n",
      "|    n_updates            | 16470       |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 768         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -3.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 403       |\n",
      "|    iterations      | 57        |\n",
      "|    time_elapsed    | 289       |\n",
      "|    total_timesteps | 116736    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -3.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 406         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 291         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008700211 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.8         |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.21e+04    |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | 0.00199     |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 7.85e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-14150.36 +/- 55.46\n",
      "Episode length: 1051.00 +/- 5.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.05e+03    |\n",
      "|    mean_reward          | -1.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030054618 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.8         |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 16490       |\n",
      "|    policy_gradient_loss | 0.00998     |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 574         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -3.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 405       |\n",
      "|    iterations      | 59        |\n",
      "|    time_elapsed    | 297       |\n",
      "|    total_timesteps | 120832    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -3.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 300         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008369174 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.8         |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 16500       |\n",
      "|    policy_gradient_loss | 0.00442     |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 840         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | -3.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 302         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016951948 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.8         |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68          |\n",
      "|    n_updates            | 16510       |\n",
      "|    policy_gradient_loss | 0.00436     |\n",
      "|    std                  | 0.249       |\n",
      "|    value_loss           | 1.97e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-11828.56 +/- 67.59\n",
      "Episode length: 942.00 +/- 10.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 942         |\n",
      "|    mean_reward          | -1.18e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 125000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016260728 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.81        |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 16520       |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    std                  | 0.249       |\n",
      "|    value_loss           | 2.8e+04     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -3.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 412       |\n",
      "|    iterations      | 62        |\n",
      "|    time_elapsed    | 307       |\n",
      "|    total_timesteps | 126976    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -3.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 415         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 310         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016669802 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.81        |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6e+03       |\n",
      "|    n_updates            | 16530       |\n",
      "|    policy_gradient_loss | 0.00954     |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 1.17e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-9178.41 +/- 3869.86\n",
      "Episode length: 742.60 +/- 333.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 743         |\n",
      "|    mean_reward          | -9.18e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023049317 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.81        |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+05    |\n",
      "|    n_updates            | 16540       |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 1.75e+05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.41e+03  |\n",
      "|    ep_rew_mean     | -2.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 416       |\n",
      "|    iterations      | 64        |\n",
      "|    time_elapsed    | 315       |\n",
      "|    total_timesteps | 131072    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.38e+03     |\n",
      "|    ep_rew_mean          | -2.89e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 419          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 317          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063181436 |\n",
      "|    clip_fraction        | 0.196        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.8          |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+04     |\n",
      "|    n_updates            | 16550        |\n",
      "|    policy_gradient_loss | 0.00905      |\n",
      "|    std                  | 0.25         |\n",
      "|    value_loss           | 8.45e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-8542.99 +/- 3563.70\n",
      "Episode length: 713.40 +/- 319.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 713         |\n",
      "|    mean_reward          | -8.54e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 135000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012770726 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.8         |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.77e+04    |\n",
      "|    n_updates            | 16560       |\n",
      "|    policy_gradient_loss | 0.00983     |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 7.74e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.37e+03  |\n",
      "|    ep_rew_mean     | -2.84e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 419       |\n",
      "|    iterations      | 66        |\n",
      "|    time_elapsed    | 322       |\n",
      "|    total_timesteps | 135168    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | -2.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 422         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 324         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010927744 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.81        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 985         |\n",
      "|    n_updates            | 16570       |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    std                  | 0.249       |\n",
      "|    value_loss           | 1.09e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.36e+03   |\n",
      "|    ep_rew_mean          | -2.83e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 425        |\n",
      "|    iterations           | 68         |\n",
      "|    time_elapsed         | 326        |\n",
      "|    total_timesteps      | 139264     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01624644 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.81       |\n",
      "|    explained_variance   | 0.724      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 222        |\n",
      "|    n_updates            | 16580      |\n",
      "|    policy_gradient_loss | -0.00238   |\n",
      "|    std                  | 0.248      |\n",
      "|    value_loss           | 2.98e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=140000, episode_reward=-8982.21 +/- 22.44\n",
      "Episode length: 813.40 +/- 5.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 813          |\n",
      "|    mean_reward          | -8.98e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 140000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067705223 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.81         |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 190          |\n",
      "|    n_updates            | 16590        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    std                  | 0.248        |\n",
      "|    value_loss           | 4.99e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -2.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 425       |\n",
      "|    iterations      | 69        |\n",
      "|    time_elapsed    | 331       |\n",
      "|    total_timesteps | 141312    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.28e+03  |\n",
      "|    ep_rew_mean          | -2.7e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 428       |\n",
      "|    iterations           | 70        |\n",
      "|    time_elapsed         | 334       |\n",
      "|    total_timesteps      | 143360    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0282729 |\n",
      "|    clip_fraction        | 0.209     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.82      |\n",
      "|    explained_variance   | 0.988     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 264       |\n",
      "|    n_updates            | 16600     |\n",
      "|    policy_gradient_loss | 0.00301   |\n",
      "|    std                  | 0.248     |\n",
      "|    value_loss           | 810       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-8614.84 +/- 18.53\n",
      "Episode length: 797.60 +/- 4.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 798         |\n",
      "|    mean_reward          | -8.61e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 145000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032729946 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.82        |\n",
      "|    explained_variance   | 0.586       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+05    |\n",
      "|    n_updates            | 16610       |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 1.05e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -2.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 428       |\n",
      "|    iterations      | 71        |\n",
      "|    time_elapsed    | 339       |\n",
      "|    total_timesteps | 145408    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -2.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017092897 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.82        |\n",
      "|    explained_variance   | 0.66        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 281         |\n",
      "|    n_updates            | 16620       |\n",
      "|    policy_gradient_loss | -0.00443    |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 2.93e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -2.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 434         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 344         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024816647 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.85e+04    |\n",
      "|    n_updates            | 16630       |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 6.1e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-6800.56 +/- 55.20\n",
      "Episode length: 685.60 +/- 8.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 686         |\n",
      "|    mean_reward          | -6.8e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058498528 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.89e+04    |\n",
      "|    n_updates            | 16640       |\n",
      "|    policy_gradient_loss | 0.00789     |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.57e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.11e+03  |\n",
      "|    ep_rew_mean     | -2.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 433       |\n",
      "|    iterations      | 74        |\n",
      "|    time_elapsed    | 349       |\n",
      "|    total_timesteps | 151552    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -2.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 435         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 352         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011067089 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 321         |\n",
      "|    n_updates            | 16650       |\n",
      "|    policy_gradient_loss | 0.00732     |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.85e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-6179.79 +/- 20.97\n",
      "Episode length: 638.80 +/- 3.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 639         |\n",
      "|    mean_reward          | -6.18e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 155000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013387368 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.87        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 378         |\n",
      "|    n_updates            | 16660       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 832         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 436       |\n",
      "|    iterations      | 76        |\n",
      "|    time_elapsed    | 356       |\n",
      "|    total_timesteps | 155648    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 930        |\n",
      "|    ep_rew_mean          | -1.77e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 438        |\n",
      "|    iterations           | 77         |\n",
      "|    time_elapsed         | 359        |\n",
      "|    total_timesteps      | 157696     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02422098 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.87       |\n",
      "|    explained_variance   | 0.372      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 481        |\n",
      "|    n_updates            | 16670      |\n",
      "|    policy_gradient_loss | 0.003      |\n",
      "|    std                  | 0.243      |\n",
      "|    value_loss           | 1.87e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 864        |\n",
      "|    ep_rew_mean          | -1.55e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 441        |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 361        |\n",
      "|    total_timesteps      | 159744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01959342 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.87       |\n",
      "|    explained_variance   | 0.455      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.63e+03   |\n",
      "|    n_updates            | 16680      |\n",
      "|    policy_gradient_loss | 0.00201    |\n",
      "|    std                  | 0.242      |\n",
      "|    value_loss           | 1.15e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=-5033.61 +/- 22.09\n",
      "Episode length: 565.20 +/- 4.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 565         |\n",
      "|    mean_reward          | -5.03e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010083219 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.87        |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.4e+05     |\n",
      "|    n_updates            | 16690       |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 1.21e+05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 782       |\n",
      "|    ep_rew_mean     | -1.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 442       |\n",
      "|    iterations      | 79        |\n",
      "|    time_elapsed    | 366       |\n",
      "|    total_timesteps | 161792    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 742         |\n",
      "|    ep_rew_mean          | -1.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 444         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 368         |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024076663 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.87        |\n",
      "|    explained_variance   | -0.549      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 560         |\n",
      "|    n_updates            | 16700       |\n",
      "|    policy_gradient_loss | 0.00103     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 4.61e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-3839.01 +/- 1265.93\n",
      "Episode length: 429.00 +/- 178.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 429         |\n",
      "|    mean_reward          | -3.84e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 165000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023128241 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.88        |\n",
      "|    explained_variance   | -0.0128     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 16710       |\n",
      "|    policy_gradient_loss | 0.00857     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.14e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 729       |\n",
      "|    ep_rew_mean     | -1.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 444       |\n",
      "|    iterations      | 81        |\n",
      "|    time_elapsed    | 372       |\n",
      "|    total_timesteps | 165888    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 688         |\n",
      "|    ep_rew_mean          | -9.69e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 446         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 376         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021621313 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | -0.273      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.6        |\n",
      "|    n_updates            | 16720       |\n",
      "|    policy_gradient_loss | 0.0239      |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 3.1e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 674        |\n",
      "|    ep_rew_mean          | -9.26e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 448        |\n",
      "|    iterations           | 83         |\n",
      "|    time_elapsed         | 379        |\n",
      "|    total_timesteps      | 169984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01829444 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.87       |\n",
      "|    explained_variance   | 0.419      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.06e+04   |\n",
      "|    n_updates            | 16730      |\n",
      "|    policy_gradient_loss | 0.0157     |\n",
      "|    std                  | 0.242      |\n",
      "|    value_loss           | 1.06e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-3971.07 +/- 18.64\n",
      "Episode length: 469.60 +/- 2.06\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 470       |\n",
      "|    mean_reward          | -3.97e+03 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 170000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0589972 |\n",
      "|    clip_fraction        | 0.301     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.87      |\n",
      "|    explained_variance   | -1.12     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 202       |\n",
      "|    n_updates            | 16740     |\n",
      "|    policy_gradient_loss | 0.013     |\n",
      "|    std                  | 0.241     |\n",
      "|    value_loss           | 3.27e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 644       |\n",
      "|    ep_rew_mean     | -8.52e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 449       |\n",
      "|    iterations      | 84        |\n",
      "|    time_elapsed    | 383       |\n",
      "|    total_timesteps | 172032    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 616        |\n",
      "|    ep_rew_mean          | -7.88e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 451        |\n",
      "|    iterations           | 85         |\n",
      "|    time_elapsed         | 385        |\n",
      "|    total_timesteps      | 174080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01315015 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.87       |\n",
      "|    explained_variance   | -2.09      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.54e+04   |\n",
      "|    n_updates            | 16750      |\n",
      "|    policy_gradient_loss | 0.00753    |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 5.62e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=-3721.58 +/- 17.50\n",
      "Episode length: 460.40 +/- 6.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 460         |\n",
      "|    mean_reward          | -3.72e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 175000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023608176 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.87        |\n",
      "|    explained_variance   | -2.37       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 16760       |\n",
      "|    policy_gradient_loss | 0.00792     |\n",
      "|    std                  | 0.239       |\n",
      "|    value_loss           | 6.08e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 599       |\n",
      "|    ep_rew_mean     | -7.47e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 452       |\n",
      "|    iterations      | 86        |\n",
      "|    time_elapsed    | 389       |\n",
      "|    total_timesteps | 176128    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 568        |\n",
      "|    ep_rew_mean          | -6.86e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 454        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 391        |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01717418 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.89       |\n",
      "|    explained_variance   | 0.272      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.51e+04   |\n",
      "|    n_updates            | 16770      |\n",
      "|    policy_gradient_loss | 0.00666    |\n",
      "|    std                  | 0.237      |\n",
      "|    value_loss           | 1.53e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-3502.65 +/- 20.47\n",
      "Episode length: 461.20 +/- 10.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 461         |\n",
      "|    mean_reward          | -3.5e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030719325 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.9         |\n",
      "|    explained_variance   | -0.94       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.1e+04     |\n",
      "|    n_updates            | 16780       |\n",
      "|    policy_gradient_loss | 0.00734     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 2.49e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 541       |\n",
      "|    ep_rew_mean     | -6.36e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 453       |\n",
      "|    iterations      | 88        |\n",
      "|    time_elapsed    | 397       |\n",
      "|    total_timesteps | 180224    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 541         |\n",
      "|    ep_rew_mean          | -6.24e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 456         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 399         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018571071 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.92        |\n",
      "|    explained_variance   | -1.29       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.2        |\n",
      "|    n_updates            | 16790       |\n",
      "|    policy_gradient_loss | 0.00615     |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 2.39e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 522       |\n",
      "|    ep_rew_mean          | -5.91e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 458       |\n",
      "|    iterations           | 90        |\n",
      "|    time_elapsed         | 402       |\n",
      "|    total_timesteps      | 184320    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0380077 |\n",
      "|    clip_fraction        | 0.229     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.96      |\n",
      "|    explained_variance   | -3.03     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.7e+04   |\n",
      "|    n_updates            | 16800     |\n",
      "|    policy_gradient_loss | 0.00711   |\n",
      "|    std                  | 0.23      |\n",
      "|    value_loss           | 4.54e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-3290.86 +/- 24.57\n",
      "Episode length: 441.60 +/- 2.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 442         |\n",
      "|    mean_reward          | -3.29e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 185000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037747294 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.321       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.53e+04    |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | 0.0193      |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 1.37e+05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 509       |\n",
      "|    ep_rew_mean     | -5.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 459       |\n",
      "|    iterations      | 91        |\n",
      "|    time_elapsed    | 405       |\n",
      "|    total_timesteps | 186368    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 489         |\n",
      "|    ep_rew_mean          | -5.24e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 461         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 408         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035356477 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | -7.73       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+05    |\n",
      "|    n_updates            | 16820       |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 1.02e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=190000, episode_reward=-3079.46 +/- 22.61\n",
      "Episode length: 428.20 +/- 7.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 428         |\n",
      "|    mean_reward          | -3.08e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026439372 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | -1.76       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 16830       |\n",
      "|    policy_gradient_loss | 0.0133      |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 2.55e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 473       |\n",
      "|    ep_rew_mean     | -4.96e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 461       |\n",
      "|    iterations      | 93        |\n",
      "|    time_elapsed    | 412       |\n",
      "|    total_timesteps | 190464    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 456        |\n",
      "|    ep_rew_mean          | -4.71e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 464        |\n",
      "|    iterations           | 94         |\n",
      "|    time_elapsed         | 414        |\n",
      "|    total_timesteps      | 192512     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19575173 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.05       |\n",
      "|    explained_variance   | -4.49      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.4e+05    |\n",
      "|    n_updates            | 16840      |\n",
      "|    policy_gradient_loss | 0.0124     |\n",
      "|    std                  | 0.223      |\n",
      "|    value_loss           | 1.21e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 438         |\n",
      "|    ep_rew_mean          | -4.44e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 466         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 417         |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025152998 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | -5.89       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68          |\n",
      "|    n_updates            | 16850       |\n",
      "|    policy_gradient_loss | 0.00764     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 6.12e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-2933.95 +/- 12.31\n",
      "Episode length: 416.00 +/- 4.34\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 416        |\n",
      "|    mean_reward          | -2.93e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 195000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03973975 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.1        |\n",
      "|    explained_variance   | -0.94      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.8       |\n",
      "|    n_updates            | 16860      |\n",
      "|    policy_gradient_loss | 0.00118    |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 4.96e+04   |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 434       |\n",
      "|    ep_rew_mean     | -4.34e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 466       |\n",
      "|    iterations      | 96        |\n",
      "|    time_elapsed    | 421       |\n",
      "|    total_timesteps | 196608    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 420        |\n",
      "|    ep_rew_mean          | -4.13e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 468        |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 423        |\n",
      "|    total_timesteps      | 198656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03156539 |\n",
      "|    clip_fraction        | 0.318      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.16       |\n",
      "|    explained_variance   | -6.81      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.49e+05   |\n",
      "|    n_updates            | 16870      |\n",
      "|    policy_gradient_loss | 0.0122     |\n",
      "|    std                  | 0.215      |\n",
      "|    value_loss           | 6.64e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-2321.98 +/- 16.18\n",
      "Episode length: 322.00 +/- 7.29\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 322       |\n",
      "|    mean_reward          | -2.32e+03 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 200000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2713638 |\n",
      "|    clip_fraction        | 0.418     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.21      |\n",
      "|    explained_variance   | -7.85     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 21.4      |\n",
      "|    n_updates            | 16880     |\n",
      "|    policy_gradient_loss | 0.0426    |\n",
      "|    std                  | 0.212     |\n",
      "|    value_loss           | 9.4e+04   |\n",
      "---------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 401       |\n",
      "|    ep_rew_mean     | -3.87e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 469       |\n",
      "|    iterations      | 98        |\n",
      "|    time_elapsed    | 427       |\n",
      "|    total_timesteps | 200704    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 385         |\n",
      "|    ep_rew_mean          | -3.67e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 429         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014582813 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | -3.09       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 16890       |\n",
      "|    policy_gradient_loss | 0.00716     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.61e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 373         |\n",
      "|    ep_rew_mean          | -3.51e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 474         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 432         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021736883 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | -5.4        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.4        |\n",
      "|    n_updates            | 16900       |\n",
      "|    policy_gradient_loss | 0.0046      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 9.07e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=205000, episode_reward=-2325.69 +/- 29.85\n",
      "Episode length: 330.40 +/- 6.25\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 330        |\n",
      "|    mean_reward          | -2.33e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 205000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02878189 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.27       |\n",
      "|    explained_variance   | -3.64      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28.1       |\n",
      "|    n_updates            | 16910      |\n",
      "|    policy_gradient_loss | 0.00714    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 5.04e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 362       |\n",
      "|    ep_rew_mean     | -3.36e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 474       |\n",
      "|    iterations      | 101       |\n",
      "|    time_elapsed    | 435       |\n",
      "|    total_timesteps | 206848    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 351         |\n",
      "|    ep_rew_mean          | -3.22e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 437         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033151988 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.31        |\n",
      "|    explained_variance   | -5.32       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.3e+04     |\n",
      "|    n_updates            | 16920       |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 7.47e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-2327.92 +/- 37.81\n",
      "Episode length: 335.00 +/- 13.08\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 335        |\n",
      "|    mean_reward          | -2.33e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 210000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04192047 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.33       |\n",
      "|    explained_variance   | -2.63      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.86e+04   |\n",
      "|    n_updates            | 16930      |\n",
      "|    policy_gradient_loss | 0.0164     |\n",
      "|    std                  | 0.203      |\n",
      "|    value_loss           | 4.33e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 344       |\n",
      "|    ep_rew_mean     | -3.11e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 477       |\n",
      "|    iterations      | 103       |\n",
      "|    time_elapsed    | 441       |\n",
      "|    total_timesteps | 210944    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 332         |\n",
      "|    ep_rew_mean          | -2.99e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 479         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054006517 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.36        |\n",
      "|    explained_variance   | -4.22       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+05    |\n",
      "|    n_updates            | 16940       |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    std                  | 0.201       |\n",
      "|    value_loss           | 5.86e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=-2102.93 +/- 5.03\n",
      "Episode length: 291.40 +/- 2.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 291         |\n",
      "|    mean_reward          | -2.1e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 215000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011089619 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.4         |\n",
      "|    explained_variance   | -4.63       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43          |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | 0.00428     |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 6.75e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 323       |\n",
      "|    ep_rew_mean     | -2.88e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 480       |\n",
      "|    iterations      | 105       |\n",
      "|    time_elapsed    | 447       |\n",
      "|    total_timesteps | 215040    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 308        |\n",
      "|    ep_rew_mean          | -2.75e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 482        |\n",
      "|    iterations           | 106        |\n",
      "|    time_elapsed         | 449        |\n",
      "|    total_timesteps      | 217088     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00954802 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.43       |\n",
      "|    explained_variance   | -4.14      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 16960      |\n",
      "|    policy_gradient_loss | 0.00464    |\n",
      "|    std                  | 0.197      |\n",
      "|    value_loss           | 4.22e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 297         |\n",
      "|    ep_rew_mean          | -2.65e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 484         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 452         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025082575 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.44        |\n",
      "|    explained_variance   | -7.04       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 421         |\n",
      "|    n_updates            | 16970       |\n",
      "|    policy_gradient_loss | 0.00893     |\n",
      "|    std                  | 0.196       |\n",
      "|    value_loss           | 4.93e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-2064.67 +/- 14.07\n",
      "Episode length: 280.40 +/- 3.01\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 280       |\n",
      "|    mean_reward          | -2.06e+03 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 220000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0234221 |\n",
      "|    clip_fraction        | 0.246     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.46      |\n",
      "|    explained_variance   | 0.432     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 72.9      |\n",
      "|    n_updates            | 16980     |\n",
      "|    policy_gradient_loss | 0.0157    |\n",
      "|    std                  | 0.194     |\n",
      "|    value_loss           | 851       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 288       |\n",
      "|    ep_rew_mean     | -2.56e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 485       |\n",
      "|    iterations      | 108       |\n",
      "|    time_elapsed    | 455       |\n",
      "|    total_timesteps | 221184    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 280        |\n",
      "|    ep_rew_mean          | -2.49e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 487        |\n",
      "|    iterations           | 109        |\n",
      "|    time_elapsed         | 457        |\n",
      "|    total_timesteps      | 223232     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04124272 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.5        |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.7       |\n",
      "|    n_updates            | 16990      |\n",
      "|    policy_gradient_loss | 0.0103     |\n",
      "|    std                  | 0.19       |\n",
      "|    value_loss           | 47.2       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=-1971.02 +/- 27.82\n",
      "Episode length: 264.40 +/- 6.44\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 264        |\n",
      "|    mean_reward          | -1.97e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 225000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03381774 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.54       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 17000      |\n",
      "|    policy_gradient_loss | 0.0105     |\n",
      "|    std                  | 0.187      |\n",
      "|    value_loss           | 42.8       |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 270       |\n",
      "|    ep_rew_mean     | -2.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 488       |\n",
      "|    iterations      | 110       |\n",
      "|    time_elapsed    | 461       |\n",
      "|    total_timesteps | 225280    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 257        |\n",
      "|    ep_rew_mean          | -2.31e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 490        |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 463        |\n",
      "|    total_timesteps      | 227328     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02368912 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.59       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.71       |\n",
      "|    n_updates            | 17010      |\n",
      "|    policy_gradient_loss | 0.00843    |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 38.1       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 242          |\n",
      "|    ep_rew_mean          | -2.21e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 492          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 465          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063099507 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.62         |\n",
      "|    explained_variance   | -0.364       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.72e+03     |\n",
      "|    n_updates            | 17020        |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    std                  | 0.182        |\n",
      "|    value_loss           | 3.14e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=-1705.68 +/- 266.14\n",
      "Episode length: 215.20 +/- 58.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 215         |\n",
      "|    mean_reward          | -1.71e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010201268 |\n",
      "|    clip_fraction        | 0.079       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.62        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.16e+04    |\n",
      "|    n_updates            | 17030       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.182       |\n",
      "|    value_loss           | 8.44e+03    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 224       |\n",
      "|    ep_rew_mean     | -2.09e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 113       |\n",
      "|    time_elapsed    | 469       |\n",
      "|    total_timesteps | 231424    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 207          |\n",
      "|    ep_rew_mean          | -1.97e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 495          |\n",
      "|    iterations           | 114          |\n",
      "|    time_elapsed         | 471          |\n",
      "|    total_timesteps      | 233472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069598127 |\n",
      "|    clip_fraction        | 0.0758       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.63         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+03     |\n",
      "|    n_updates            | 17040        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    std                  | 0.183        |\n",
      "|    value_loss           | 6.01e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=-1534.77 +/- 266.61\n",
      "Episode length: 173.00 +/- 61.69\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 173        |\n",
      "|    mean_reward          | -1.53e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 235000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00830503 |\n",
      "|    clip_fraction        | 0.0649     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.63       |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.38e+03   |\n",
      "|    n_updates            | 17050      |\n",
      "|    policy_gradient_loss | -0.0017    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 2.78e+03   |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 193       |\n",
      "|    ep_rew_mean     | -1.88e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 115       |\n",
      "|    time_elapsed    | 474       |\n",
      "|    total_timesteps | 235520    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 174         |\n",
      "|    ep_rew_mean          | -1.76e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 476         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012394048 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.64        |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 432         |\n",
      "|    n_updates            | 17060       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    std                  | 0.182       |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 142         |\n",
      "|    ep_rew_mean          | -1.57e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 479         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021020995 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.67        |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.4        |\n",
      "|    n_updates            | 17070       |\n",
      "|    policy_gradient_loss | 0.00895     |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-1078.52 +/- 30.63\n",
      "Episode length: 83.80 +/- 4.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 83.8        |\n",
      "|    mean_reward          | -1.08e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011705875 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.7         |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 17080       |\n",
      "|    policy_gradient_loss | 0.00439     |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 780         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 126       |\n",
      "|    ep_rew_mean     | -1.46e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 118       |\n",
      "|    time_elapsed    | 482       |\n",
      "|    total_timesteps | 241664    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 107         |\n",
      "|    ep_rew_mean          | -1.33e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 484         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026414027 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 70.1        |\n",
      "|    n_updates            | 17090       |\n",
      "|    policy_gradient_loss | 0.00481     |\n",
      "|    std                  | 0.177       |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=-1068.22 +/- 60.74\n",
      "Episode length: 81.00 +/- 7.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 81          |\n",
      "|    mean_reward          | -1.07e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 245000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016909208 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.73        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 17100       |\n",
      "|    policy_gradient_loss | 0.0163      |\n",
      "|    std                  | 0.175       |\n",
      "|    value_loss           | 286         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 89.2      |\n",
      "|    ep_rew_mean     | -1.21e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 120       |\n",
      "|    time_elapsed    | 487       |\n",
      "|    total_timesteps | 245760    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 78.8       |\n",
      "|    ep_rew_mean          | -1.13e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 489        |\n",
      "|    total_timesteps      | 247808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06446868 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.76       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 82.6       |\n",
      "|    n_updates            | 17110      |\n",
      "|    policy_gradient_loss | 0.0188     |\n",
      "|    std                  | 0.173      |\n",
      "|    value_loss           | 147        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 75.6        |\n",
      "|    ep_rew_mean          | -1.1e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 492         |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027090356 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58          |\n",
      "|    n_updates            | 17120       |\n",
      "|    policy_gradient_loss | 0.0117      |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-963.57 +/- 120.32\n",
      "Episode length: 69.40 +/- 13.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 69.4        |\n",
      "|    mean_reward          | -964        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014490514 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 185         |\n",
      "|    n_updates            | 17130       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 770         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 70.5      |\n",
      "|    ep_rew_mean     | -1.06e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 123       |\n",
      "|    time_elapsed    | 494       |\n",
      "|    total_timesteps | 251904    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 67.7        |\n",
      "|    ep_rew_mean          | -1.03e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 497         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029131379 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.81        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 17140       |\n",
      "|    policy_gradient_loss | 0.00593     |\n",
      "|    std                  | 0.169       |\n",
      "|    value_loss           | 257         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=255000, episode_reward=-912.88 +/- 65.25\n",
      "Episode length: 62.80 +/- 7.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 62.8        |\n",
      "|    mean_reward          | -913        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 255000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017501522 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.83        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 17150       |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 384         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 66.3      |\n",
      "|    ep_rew_mean     | -1.02e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 511       |\n",
      "|    iterations      | 125       |\n",
      "|    time_elapsed    | 500       |\n",
      "|    total_timesteps | 256000    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 64.6        |\n",
      "|    ep_rew_mean          | -1e+03      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 502         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015500251 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.84        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 210         |\n",
      "|    n_updates            | 17160       |\n",
      "|    policy_gradient_loss | -0.000805   |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 507         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-835.75 +/- 67.32\n",
      "Episode length: 56.00 +/- 7.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 56          |\n",
      "|    mean_reward          | -836        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 260000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019858353 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.88        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.7        |\n",
      "|    n_updates            | 17170       |\n",
      "|    policy_gradient_loss | 0.00324     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 63.4     |\n",
      "|    ep_rew_mean     | -981     |\n",
      "| time/              |          |\n",
      "|    fps             | 514      |\n",
      "|    iterations      | 127      |\n",
      "|    time_elapsed    | 505      |\n",
      "|    total_timesteps | 260096   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 60.6       |\n",
      "|    ep_rew_mean          | -939       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 516        |\n",
      "|    iterations           | 128        |\n",
      "|    time_elapsed         | 507        |\n",
      "|    total_timesteps      | 262144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02201625 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.9        |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 61.3       |\n",
      "|    n_updates            | 17180      |\n",
      "|    policy_gradient_loss | 0.00714    |\n",
      "|    std                  | 0.164      |\n",
      "|    value_loss           | 175        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 59.9        |\n",
      "|    ep_rew_mean          | -929        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024466861 |\n",
      "|    clip_fraction        | 0.357       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.1        |\n",
      "|    n_updates            | 17190       |\n",
      "|    policy_gradient_loss | 0.00822     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=-836.72 +/- 67.65\n",
      "Episode length: 57.60 +/- 6.34\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 57.6       |\n",
      "|    mean_reward          | -837       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 265000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05520255 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.95       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 49.7       |\n",
      "|    n_updates            | 17200      |\n",
      "|    policy_gradient_loss | 0.0132     |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 96.4       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 58.6     |\n",
      "|    ep_rew_mean     | -912     |\n",
      "| time/              |          |\n",
      "|    fps             | 519      |\n",
      "|    iterations      | 130      |\n",
      "|    time_elapsed    | 512      |\n",
      "|    total_timesteps | 266240   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 58.3        |\n",
      "|    ep_rew_mean          | -906        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021083158 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.99        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.1        |\n",
      "|    n_updates            | 17210       |\n",
      "|    policy_gradient_loss | 0.0123      |\n",
      "|    std                  | 0.159       |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-812.42 +/- 49.25\n",
      "Episode length: 54.00 +/- 5.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 54          |\n",
      "|    mean_reward          | -812        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034525942 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.03        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 17220       |\n",
      "|    policy_gradient_loss | 0.0128      |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 55       |\n",
      "|    ep_rew_mean     | -864     |\n",
      "| time/              |          |\n",
      "|    fps             | 522      |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 517      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 54.7        |\n",
      "|    ep_rew_mean          | -853        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 520         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014607983 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.05        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 17230       |\n",
      "|    policy_gradient_loss | 0.00697     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 53.9        |\n",
      "|    ep_rew_mean          | -845        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 134         |\n",
      "|    time_elapsed         | 522         |\n",
      "|    total_timesteps      | 274432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020424865 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.7        |\n",
      "|    n_updates            | 17240       |\n",
      "|    policy_gradient_loss | 0.00121     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=-801.51 +/- 93.38\n",
      "Episode length: 55.00 +/- 8.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 55           |\n",
      "|    mean_reward          | -802         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 275000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149552915 |\n",
      "|    clip_fraction        | 0.233        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.1          |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 92.4         |\n",
      "|    n_updates            | 17250        |\n",
      "|    policy_gradient_loss | 0.00306      |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 193          |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 53.9     |\n",
      "|    ep_rew_mean     | -845     |\n",
      "| time/              |          |\n",
      "|    fps             | 526      |\n",
      "|    iterations      | 135      |\n",
      "|    time_elapsed    | 525      |\n",
      "|    total_timesteps | 276480   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 53.2        |\n",
      "|    ep_rew_mean          | -835        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 136         |\n",
      "|    time_elapsed         | 527         |\n",
      "|    total_timesteps      | 278528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030919101 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.2        |\n",
      "|    n_updates            | 17260       |\n",
      "|    policy_gradient_loss | -1.99e-06   |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-770.54 +/- 54.40\n",
      "Episode length: 50.60 +/- 4.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50.6        |\n",
      "|    mean_reward          | -771        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036723755 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.13        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76          |\n",
      "|    n_updates            | 17270       |\n",
      "|    policy_gradient_loss | 0.00565     |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 53.8     |\n",
      "|    ep_rew_mean     | -837     |\n",
      "| time/              |          |\n",
      "|    fps             | 528      |\n",
      "|    iterations      | 137      |\n",
      "|    time_elapsed    | 530      |\n",
      "|    total_timesteps | 280576   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 52.8       |\n",
      "|    ep_rew_mean          | -819       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 530        |\n",
      "|    iterations           | 138        |\n",
      "|    time_elapsed         | 533        |\n",
      "|    total_timesteps      | 282624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02579773 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.14       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 94.9       |\n",
      "|    n_updates            | 17280      |\n",
      "|    policy_gradient_loss | 0.00957    |\n",
      "|    std                  | 0.153      |\n",
      "|    value_loss           | 173        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 51.8        |\n",
      "|    ep_rew_mean          | -806        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 535         |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024507634 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.15        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.5        |\n",
      "|    n_updates            | 17290       |\n",
      "|    policy_gradient_loss | 0.00888     |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=-750.94 +/- 57.22\n",
      "Episode length: 50.00 +/- 6.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50          |\n",
      "|    mean_reward          | -751        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 285000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025719883 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.17        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.5        |\n",
      "|    n_updates            | 17300       |\n",
      "|    policy_gradient_loss | 0.00861     |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 51.4     |\n",
      "|    ep_rew_mean     | -804     |\n",
      "| time/              |          |\n",
      "|    fps             | 532      |\n",
      "|    iterations      | 140      |\n",
      "|    time_elapsed    | 538      |\n",
      "|    total_timesteps | 286720   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 52.4        |\n",
      "|    ep_rew_mean          | -817        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 534         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 540         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023356397 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.2         |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.7        |\n",
      "|    n_updates            | 17310       |\n",
      "|    policy_gradient_loss | 0.00714     |\n",
      "|    std                  | 0.149       |\n",
      "|    value_loss           | 89.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=-730.37 +/- 33.46\n",
      "Episode length: 47.40 +/- 3.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 47.4        |\n",
      "|    mean_reward          | -730        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 290000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025155073 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.23        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.3        |\n",
      "|    n_updates            | 17320       |\n",
      "|    policy_gradient_loss | 0.00152     |\n",
      "|    std                  | 0.149       |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 51.4     |\n",
      "|    ep_rew_mean     | -802     |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 142      |\n",
      "|    time_elapsed    | 543      |\n",
      "|    total_timesteps | 290816   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 52.3        |\n",
      "|    ep_rew_mean          | -804        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 545         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041807972 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.4        |\n",
      "|    n_updates            | 17330       |\n",
      "|    policy_gradient_loss | 0.00693     |\n",
      "|    std                  | 0.148       |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 51.8        |\n",
      "|    ep_rew_mean          | -797        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 537         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020622462 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.1        |\n",
      "|    n_updates            | 17340       |\n",
      "|    policy_gradient_loss | 0.00577     |\n",
      "|    std                  | 0.146       |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=-725.38 +/- 50.85\n",
      "Episode length: 48.80 +/- 5.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 48.8        |\n",
      "|    mean_reward          | -725        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 295000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013534332 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.1        |\n",
      "|    n_updates            | 17350       |\n",
      "|    policy_gradient_loss | 0.00678     |\n",
      "|    std                  | 0.146       |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 52.2     |\n",
      "|    ep_rew_mean     | -809     |\n",
      "| time/              |          |\n",
      "|    fps             | 539      |\n",
      "|    iterations      | 145      |\n",
      "|    time_elapsed    | 550      |\n",
      "|    total_timesteps | 296960   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 51.2        |\n",
      "|    ep_rew_mean          | -797        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 540         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 553         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062822625 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 17360       |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    std                  | 0.145       |\n",
      "|    value_loss           | 241         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=-736.29 +/- 92.10\n",
      "Episode length: 51.60 +/- 6.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 51.6        |\n",
      "|    mean_reward          | -736        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018466316 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.9        |\n",
      "|    n_updates            | 17370       |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    std                  | 0.145       |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 51.1     |\n",
      "|    ep_rew_mean     | -786     |\n",
      "| time/              |          |\n",
      "|    fps             | 541      |\n",
      "|    iterations      | 147      |\n",
      "|    time_elapsed    | 556      |\n",
      "|    total_timesteps | 301056   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.9        |\n",
      "|    ep_rew_mean          | -781        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 558         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028672703 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 17380       |\n",
      "|    policy_gradient_loss | 0.00904     |\n",
      "|    std                  | 0.145       |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=305000, episode_reward=-710.97 +/- 31.71\n",
      "Episode length: 46.00 +/- 2.90\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 46          |\n",
      "|    mean_reward          | -711        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 305000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041714523 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.2        |\n",
      "|    n_updates            | 17390       |\n",
      "|    policy_gradient_loss | 0.0208      |\n",
      "|    std                  | 0.146       |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50.1     |\n",
      "|    ep_rew_mean     | -772     |\n",
      "| time/              |          |\n",
      "|    fps             | 542      |\n",
      "|    iterations      | 149      |\n",
      "|    time_elapsed    | 562      |\n",
      "|    total_timesteps | 305152   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.6        |\n",
      "|    ep_rew_mean          | -766        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 543         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 565         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016878203 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | 0.00878     |\n",
      "|    std                  | 0.145       |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.7        |\n",
      "|    ep_rew_mean          | -774        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 567         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017655594 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.8        |\n",
      "|    n_updates            | 17410       |\n",
      "|    policy_gradient_loss | 0.00353     |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-690.67 +/- 46.34\n",
      "Episode length: 47.20 +/- 5.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 47.2        |\n",
      "|    mean_reward          | -691        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041856393 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.5        |\n",
      "|    n_updates            | 17420       |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 51.3     |\n",
      "|    ep_rew_mean     | -774     |\n",
      "| time/              |          |\n",
      "|    fps             | 545      |\n",
      "|    iterations      | 152      |\n",
      "|    time_elapsed    | 570      |\n",
      "|    total_timesteps | 311296   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 51          |\n",
      "|    ep_rew_mean          | -768        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 153         |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 313344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049996812 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 17430       |\n",
      "|    policy_gradient_loss | 0.0093      |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=-686.98 +/- 44.29\n",
      "Episode length: 44.60 +/- 1.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 44.6        |\n",
      "|    mean_reward          | -687        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 315000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031573582 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.4        |\n",
      "|    n_updates            | 17440       |\n",
      "|    policy_gradient_loss | 0.0164      |\n",
      "|    std                  | 0.141       |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50.3     |\n",
      "|    ep_rew_mean     | -767     |\n",
      "| time/              |          |\n",
      "|    fps             | 547      |\n",
      "|    iterations      | 154      |\n",
      "|    time_elapsed    | 575      |\n",
      "|    total_timesteps | 315392   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.7        |\n",
      "|    ep_rew_mean          | -772        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 549         |\n",
      "|    iterations           | 155         |\n",
      "|    time_elapsed         | 577         |\n",
      "|    total_timesteps      | 317440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020154078 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 83.9        |\n",
      "|    n_updates            | 17450       |\n",
      "|    policy_gradient_loss | 0.00133     |\n",
      "|    std                  | 0.14        |\n",
      "|    value_loss           | 350         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 50.1       |\n",
      "|    ep_rew_mean          | -760       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 550        |\n",
      "|    iterations           | 156        |\n",
      "|    time_elapsed         | 580        |\n",
      "|    total_timesteps      | 319488     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04454786 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.43       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 68         |\n",
      "|    n_updates            | 17460      |\n",
      "|    policy_gradient_loss | 0.00581    |\n",
      "|    std                  | 0.14       |\n",
      "|    value_loss           | 146        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=320000, episode_reward=-698.65 +/- 58.13\n",
      "Episode length: 47.60 +/- 4.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 47.6        |\n",
      "|    mean_reward          | -699        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022885617 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.9        |\n",
      "|    n_updates            | 17470       |\n",
      "|    policy_gradient_loss | 0.0013      |\n",
      "|    std                  | 0.139       |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49.7     |\n",
      "|    ep_rew_mean     | -755     |\n",
      "| time/              |          |\n",
      "|    fps             | 551      |\n",
      "|    iterations      | 157      |\n",
      "|    time_elapsed    | 583      |\n",
      "|    total_timesteps | 321536   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.8        |\n",
      "|    ep_rew_mean          | -744        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 552         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 585         |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042702187 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.8        |\n",
      "|    n_updates            | 17480       |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    std                  | 0.139       |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=-700.54 +/- 57.63\n",
      "Episode length: 48.80 +/- 4.83\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 48.8       |\n",
      "|    mean_reward          | -701       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 325000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07053216 |\n",
      "|    clip_fraction        | 0.349      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.42       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 64.7       |\n",
      "|    n_updates            | 17490      |\n",
      "|    policy_gradient_loss | 0.0185     |\n",
      "|    std                  | 0.138      |\n",
      "|    value_loss           | 102        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 48.4     |\n",
      "|    ep_rew_mean     | -740     |\n",
      "| time/              |          |\n",
      "|    fps             | 553      |\n",
      "|    iterations      | 159      |\n",
      "|    time_elapsed    | 588      |\n",
      "|    total_timesteps | 325632   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.6        |\n",
      "|    ep_rew_mean          | -738        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 554         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 590         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020281333 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.44        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | 0.008       |\n",
      "|    std                  | 0.137       |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 48.6       |\n",
      "|    ep_rew_mean          | -737       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 555        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 593        |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03966693 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.45       |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 74.1       |\n",
      "|    n_updates            | 17510      |\n",
      "|    policy_gradient_loss | 0.0135     |\n",
      "|    std                  | 0.137      |\n",
      "|    value_loss           | 194        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-710.17 +/- 79.80\n",
      "Episode length: 51.00 +/- 6.99\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 51         |\n",
      "|    mean_reward          | -710       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 330000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01995381 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.45       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 58.1       |\n",
      "|    n_updates            | 17520      |\n",
      "|    policy_gradient_loss | 0.00521    |\n",
      "|    std                  | 0.138      |\n",
      "|    value_loss           | 218        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49.4     |\n",
      "|    ep_rew_mean     | -739     |\n",
      "| time/              |          |\n",
      "|    fps             | 556      |\n",
      "|    iterations      | 162      |\n",
      "|    time_elapsed    | 595      |\n",
      "|    total_timesteps | 331776   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50.1        |\n",
      "|    ep_rew_mean          | -748        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 598         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036265157 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.44        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 84.9        |\n",
      "|    n_updates            | 17530       |\n",
      "|    policy_gradient_loss | 0.00707     |\n",
      "|    std                  | 0.138       |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=-657.53 +/- 33.49\n",
      "Episode length: 44.00 +/- 1.67\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 44         |\n",
      "|    mean_reward          | -658       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 335000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02324046 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.43       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 61.4       |\n",
      "|    n_updates            | 17540      |\n",
      "|    policy_gradient_loss | 0.0102     |\n",
      "|    std                  | 0.137      |\n",
      "|    value_loss           | 199        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49.9     |\n",
      "|    ep_rew_mean     | -745     |\n",
      "| time/              |          |\n",
      "|    fps             | 558      |\n",
      "|    iterations      | 164      |\n",
      "|    time_elapsed    | 600      |\n",
      "|    total_timesteps | 335872   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.1        |\n",
      "|    ep_rew_mean          | -738        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 603         |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026408045 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.44        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43          |\n",
      "|    n_updates            | 17550       |\n",
      "|    policy_gradient_loss | 0.00626     |\n",
      "|    std                  | 0.136       |\n",
      "|    value_loss           | 445         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 48.8       |\n",
      "|    ep_rew_mean          | -738       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 561        |\n",
      "|    iterations           | 166        |\n",
      "|    time_elapsed         | 605        |\n",
      "|    total_timesteps      | 339968     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04416441 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.44       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 54.6       |\n",
      "|    n_updates            | 17560      |\n",
      "|    policy_gradient_loss | 0.00974    |\n",
      "|    std                  | 0.137      |\n",
      "|    value_loss           | 130        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-734.67 +/- 63.59\n",
      "Episode length: 53.00 +/- 6.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 53          |\n",
      "|    mean_reward          | -735        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037683968 |\n",
      "|    clip_fraction        | 0.413       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 17570       |\n",
      "|    policy_gradient_loss | 0.0286      |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 86.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 48.7     |\n",
      "|    ep_rew_mean     | -737     |\n",
      "| time/              |          |\n",
      "|    fps             | 562      |\n",
      "|    iterations      | 167      |\n",
      "|    time_elapsed    | 608      |\n",
      "|    total_timesteps | 342016   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.2        |\n",
      "|    ep_rew_mean          | -739        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 610         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028153418 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.47        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.7        |\n",
      "|    n_updates            | 17580       |\n",
      "|    policy_gradient_loss | 0.0101      |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 96.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=-719.54 +/- 64.09\n",
      "Episode length: 50.20 +/- 5.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50.2        |\n",
      "|    mean_reward          | -720        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 345000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025980867 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.49        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.5        |\n",
      "|    n_updates            | 17590       |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49.2     |\n",
      "|    ep_rew_mean     | -740     |\n",
      "| time/              |          |\n",
      "|    fps             | 564      |\n",
      "|    iterations      | 169      |\n",
      "|    time_elapsed    | 613      |\n",
      "|    total_timesteps | 346112   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.6        |\n",
      "|    ep_rew_mean          | -731        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 616         |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024678156 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.5         |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 17600       |\n",
      "|    policy_gradient_loss | 0.00871     |\n",
      "|    std                  | 0.133       |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-681.93 +/- 64.66\n",
      "Episode length: 47.00 +/- 4.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 47         |\n",
      "|    mean_reward          | -682       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 350000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04465769 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.52       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 85.1       |\n",
      "|    n_updates            | 17610      |\n",
      "|    policy_gradient_loss | 0.013      |\n",
      "|    std                  | 0.132      |\n",
      "|    value_loss           | 150        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49.3     |\n",
      "|    ep_rew_mean     | -737     |\n",
      "| time/              |          |\n",
      "|    fps             | 566      |\n",
      "|    iterations      | 171      |\n",
      "|    time_elapsed    | 618      |\n",
      "|    total_timesteps | 350208   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.9        |\n",
      "|    ep_rew_mean          | -741        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 621         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.057150327 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.54        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 17620       |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    std                  | 0.131       |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.5        |\n",
      "|    ep_rew_mean          | -735        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 173         |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 354304      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034902215 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.55        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.2        |\n",
      "|    n_updates            | 17630       |\n",
      "|    policy_gradient_loss | 0.0117      |\n",
      "|    std                  | 0.131       |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=-738.42 +/- 61.51\n",
      "Episode length: 53.40 +/- 5.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 53.4        |\n",
      "|    mean_reward          | -738        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 355000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019088667 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.56        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 154         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49.9     |\n",
      "|    ep_rew_mean     | -743     |\n",
      "| time/              |          |\n",
      "|    fps             | 568      |\n",
      "|    iterations      | 174      |\n",
      "|    time_elapsed    | 626      |\n",
      "|    total_timesteps | 356352   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49          |\n",
      "|    ep_rew_mean          | -730        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 175         |\n",
      "|    time_elapsed         | 629         |\n",
      "|    total_timesteps      | 358400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021576833 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.59        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 17650       |\n",
      "|    policy_gradient_loss | 0.00589     |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-695.75 +/- 65.39\n",
      "Episode length: 50.20 +/- 6.37\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 50.2       |\n",
      "|    mean_reward          | -696       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 360000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06520012 |\n",
      "|    clip_fraction        | 0.346      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.63       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 26         |\n",
      "|    n_updates            | 17660      |\n",
      "|    policy_gradient_loss | 0.0138     |\n",
      "|    std                  | 0.126      |\n",
      "|    value_loss           | 92.6       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50.1     |\n",
      "|    ep_rew_mean     | -741     |\n",
      "| time/              |          |\n",
      "|    fps             | 570      |\n",
      "|    iterations      | 176      |\n",
      "|    time_elapsed    | 631      |\n",
      "|    total_timesteps | 360448   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 52        |\n",
      "|    ep_rew_mean          | -757      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 570       |\n",
      "|    iterations           | 177       |\n",
      "|    time_elapsed         | 635       |\n",
      "|    total_timesteps      | 362496    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8670056 |\n",
      "|    clip_fraction        | 0.358     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.66      |\n",
      "|    explained_variance   | 0.977     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 104       |\n",
      "|    n_updates            | 17670     |\n",
      "|    policy_gradient_loss | 0.0193    |\n",
      "|    std                  | 0.126     |\n",
      "|    value_loss           | 142       |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 53.7        |\n",
      "|    ep_rew_mean          | -782        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 638         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015410183 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.67        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.8        |\n",
      "|    n_updates            | 17680       |\n",
      "|    policy_gradient_loss | -8.59e-05   |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=-757.08 +/- 130.24\n",
      "Episode length: 56.60 +/- 14.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 56.6       |\n",
      "|    mean_reward          | -757       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 365000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01978771 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.67       |\n",
      "|    explained_variance   | 0.698      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 268        |\n",
      "|    n_updates            | 17690      |\n",
      "|    policy_gradient_loss | 0.00142    |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 1.1e+03    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 52.2     |\n",
      "|    ep_rew_mean     | -767     |\n",
      "| time/              |          |\n",
      "|    fps             | 572      |\n",
      "|    iterations      | 179      |\n",
      "|    time_elapsed    | 640      |\n",
      "|    total_timesteps | 366592   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 52          |\n",
      "|    ep_rew_mean          | -764        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 573         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 643         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017336804 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.67        |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 17700       |\n",
      "|    policy_gradient_loss | 0.00612     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 380         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=370000, episode_reward=-632.06 +/- 15.90\n",
      "Episode length: 42.80 +/- 0.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 42.8        |\n",
      "|    mean_reward          | -632        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 370000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030666774 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.67        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 285         |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | 0.00952     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 466         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 52.3     |\n",
      "|    ep_rew_mean     | -760     |\n",
      "| time/              |          |\n",
      "|    fps             | 573      |\n",
      "|    iterations      | 181      |\n",
      "|    time_elapsed    | 645      |\n",
      "|    total_timesteps | 370688   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 53.5        |\n",
      "|    ep_rew_mean          | -780        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 574         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 648         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014235394 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.68        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 17720       |\n",
      "|    policy_gradient_loss | 0.00317     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 334         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 51.8        |\n",
      "|    ep_rew_mean          | -771        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 575         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 650         |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026923953 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.68        |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 17730       |\n",
      "|    policy_gradient_loss | 0.00637     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 4.01e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=-698.54 +/- 76.48\n",
      "Episode length: 48.00 +/- 8.02\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 48        |\n",
      "|    mean_reward          | -699      |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 375000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1351099 |\n",
      "|    clip_fraction        | 0.275     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.68      |\n",
      "|    explained_variance   | 0.916     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 263       |\n",
      "|    n_updates            | 17740     |\n",
      "|    policy_gradient_loss | 0.0227    |\n",
      "|    std                  | 0.125     |\n",
      "|    value_loss           | 572       |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49.3     |\n",
      "|    ep_rew_mean     | -773     |\n",
      "| time/              |          |\n",
      "|    fps             | 576      |\n",
      "|    iterations      | 184      |\n",
      "|    time_elapsed    | 653      |\n",
      "|    total_timesteps | 376832   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.8        |\n",
      "|    ep_rew_mean          | -776        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 577         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 656         |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010789486 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.68        |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 381         |\n",
      "|    n_updates            | 17750       |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.2e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=-810.78 +/- 187.63\n",
      "Episode length: 59.40 +/- 20.92\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 59.4       |\n",
      "|    mean_reward          | -811       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 380000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02328679 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.69       |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 500        |\n",
      "|    n_updates            | 17760      |\n",
      "|    policy_gradient_loss | -0.000686  |\n",
      "|    std                  | 0.124      |\n",
      "|    value_loss           | 779        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 50.5     |\n",
      "|    ep_rew_mean     | -782     |\n",
      "| time/              |          |\n",
      "|    fps             | 578      |\n",
      "|    iterations      | 186      |\n",
      "|    time_elapsed    | 658      |\n",
      "|    total_timesteps | 380928   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 50          |\n",
      "|    ep_rew_mean          | -772        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 579         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 661         |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022824883 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.69        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 17770       |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    std                  | 0.124       |\n",
      "|    value_loss           | 750         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=-737.68 +/- 76.78\n",
      "Episode length: 43.00 +/- 1.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 43          |\n",
      "|    mean_reward          | -738        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 385000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016409006 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.7         |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 402         |\n",
      "|    n_updates            | 17780       |\n",
      "|    policy_gradient_loss | 0.000325    |\n",
      "|    std                  | 0.124       |\n",
      "|    value_loss           | 830         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 49.5     |\n",
      "|    ep_rew_mean     | -760     |\n",
      "| time/              |          |\n",
      "|    fps             | 579      |\n",
      "|    iterations      | 188      |\n",
      "|    time_elapsed    | 663      |\n",
      "|    total_timesteps | 385024   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 48.1        |\n",
      "|    ep_rew_mean          | -739        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 580         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 666         |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027305923 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.7         |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 17790       |\n",
      "|    policy_gradient_loss | 0.00828     |\n",
      "|    std                  | 0.124       |\n",
      "|    value_loss           | 451         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 49.7        |\n",
      "|    ep_rew_mean          | -804        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 581         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 668         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022667097 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.72        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 262         |\n",
      "|    n_updates            | 17800       |\n",
      "|    policy_gradient_loss | 0.0129      |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 378         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=-737.18 +/- 91.51\n",
      "Episode length: 50.40 +/- 4.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 50.4        |\n",
      "|    mean_reward          | -737        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009833888 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.72        |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.08e+03    |\n",
      "|    n_updates            | 17810       |\n",
      "|    policy_gradient_loss | -0.00381    |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 4.46e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 51.3     |\n",
      "|    ep_rew_mean     | -831     |\n",
      "| time/              |          |\n",
      "|    fps             | 582      |\n",
      "|    iterations      | 191      |\n",
      "|    time_elapsed    | 671      |\n",
      "|    total_timesteps | 391168   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 51.1        |\n",
      "|    ep_rew_mean          | -798        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 674         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021026324 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.72        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 447         |\n",
      "|    n_updates            | 17820       |\n",
      "|    policy_gradient_loss | 0.00672     |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=-693.62 +/- 60.77\n",
      "Episode length: 44.00 +/- 3.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 44          |\n",
      "|    mean_reward          | -694        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 395000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025786875 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.72        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 279         |\n",
      "|    n_updates            | 17830       |\n",
      "|    policy_gradient_loss | 0.00621     |\n",
      "|    std                  | 0.124       |\n",
      "|    value_loss           | 570         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 47.9     |\n",
      "|    ep_rew_mean     | -752     |\n",
      "| time/              |          |\n",
      "|    fps             | 584      |\n",
      "|    iterations      | 193      |\n",
      "|    time_elapsed    | 676      |\n",
      "|    total_timesteps | 395264   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.9        |\n",
      "|    ep_rew_mean          | -724        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 584         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 679         |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018488295 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.71        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 17840       |\n",
      "|    policy_gradient_loss | 0.00501     |\n",
      "|    std                  | 0.124       |\n",
      "|    value_loss           | 764         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.4        |\n",
      "|    ep_rew_mean          | -720        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 585         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 681         |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037229232 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.71        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 99.1        |\n",
      "|    n_updates            | 17850       |\n",
      "|    policy_gradient_loss | 0.01        |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-679.03 +/- 36.85\n",
      "Episode length: 41.20 +/- 1.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 41.2        |\n",
      "|    mean_reward          | -679        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023143573 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.73        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.5        |\n",
      "|    n_updates            | 17860       |\n",
      "|    policy_gradient_loss | 0.0144      |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 44.2     |\n",
      "|    ep_rew_mean     | -713     |\n",
      "| time/              |          |\n",
      "|    fps             | 586      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 684      |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.8        |\n",
      "|    ep_rew_mean          | -719        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 686         |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031615343 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.74        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 17870       |\n",
      "|    policy_gradient_loss | 0.0042      |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 298         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=-663.52 +/- 39.42\n",
      "Episode length: 42.60 +/- 2.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 42.6        |\n",
      "|    mean_reward          | -664        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 405000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025150694 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.75        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.2        |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    std                  | 0.121       |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 45.1     |\n",
      "|    ep_rew_mean     | -726     |\n",
      "| time/              |          |\n",
      "|    fps             | 588      |\n",
      "|    iterations      | 198      |\n",
      "|    time_elapsed    | 689      |\n",
      "|    total_timesteps | 405504   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.6        |\n",
      "|    ep_rew_mean          | -726        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 199         |\n",
      "|    time_elapsed         | 691         |\n",
      "|    total_timesteps      | 407552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019502804 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.75        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90          |\n",
      "|    n_updates            | 17890       |\n",
      "|    policy_gradient_loss | 0.00947     |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 358         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 45.6      |\n",
      "|    ep_rew_mean          | -720      |\n",
      "| time/                   |           |\n",
      "|    fps                  | 590       |\n",
      "|    iterations           | 200       |\n",
      "|    time_elapsed         | 694       |\n",
      "|    total_timesteps      | 409600    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0387665 |\n",
      "|    clip_fraction        | 0.325     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.75      |\n",
      "|    explained_variance   | 0.977     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 97.6      |\n",
      "|    n_updates            | 17900     |\n",
      "|    policy_gradient_loss | 0.00738   |\n",
      "|    std                  | 0.121     |\n",
      "|    value_loss           | 223       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=-686.03 +/- 53.72\n",
      "Episode length: 42.00 +/- 1.90\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 42          |\n",
      "|    mean_reward          | -686        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 410000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036768924 |\n",
      "|    clip_fraction        | 0.373       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.76        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.5        |\n",
      "|    n_updates            | 17910       |\n",
      "|    policy_gradient_loss | 0.0126      |\n",
      "|    std                  | 0.121       |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 45.7     |\n",
      "|    ep_rew_mean     | -723     |\n",
      "| time/              |          |\n",
      "|    fps             | 590      |\n",
      "|    iterations      | 201      |\n",
      "|    time_elapsed    | 696      |\n",
      "|    total_timesteps | 411648   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.7        |\n",
      "|    ep_rew_mean          | -740        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 699         |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031294823 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.77        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 17920       |\n",
      "|    policy_gradient_loss | 0.00775     |\n",
      "|    std                  | 0.12        |\n",
      "|    value_loss           | 419         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=-639.88 +/- 26.89\n",
      "Episode length: 42.00 +/- 1.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 42          |\n",
      "|    mean_reward          | -640        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 415000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022510171 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.78        |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78.8        |\n",
      "|    n_updates            | 17930       |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    std                  | 0.12        |\n",
      "|    value_loss           | 755         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 47       |\n",
      "|    ep_rew_mean     | -739     |\n",
      "| time/              |          |\n",
      "|    fps             | 592      |\n",
      "|    iterations      | 203      |\n",
      "|    time_elapsed    | 701      |\n",
      "|    total_timesteps | 415744   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 46.8        |\n",
      "|    ep_rew_mean          | -727        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 204         |\n",
      "|    time_elapsed         | 704         |\n",
      "|    total_timesteps      | 417792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031852238 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.79        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 17940       |\n",
      "|    policy_gradient_loss | 0.00379     |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 352         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 45.1        |\n",
      "|    ep_rew_mean          | -711        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 706         |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029385254 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.81        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 358         |\n",
      "|    n_updates            | 17950       |\n",
      "|    policy_gradient_loss | 0.00865     |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 378         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=-665.58 +/- 53.18\n",
      "Episode length: 41.00 +/- 1.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 41          |\n",
      "|    mean_reward          | -666        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 420000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.115733504 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.82        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.4        |\n",
      "|    n_updates            | 17960       |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 44.2     |\n",
      "|    ep_rew_mean     | -710     |\n",
      "| time/              |          |\n",
      "|    fps             | 594      |\n",
      "|    iterations      | 206      |\n",
      "|    time_elapsed    | 709      |\n",
      "|    total_timesteps | 421888   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 43.9        |\n",
      "|    ep_rew_mean          | -703        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 711         |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031854987 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.83        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 219         |\n",
      "|    n_updates            | 17970       |\n",
      "|    policy_gradient_loss | 0.00816     |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=-641.12 +/- 11.99\n",
      "Episode length: 40.40 +/- 2.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 40.4        |\n",
      "|    mean_reward          | -641        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 425000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020732366 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.83        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.3        |\n",
      "|    n_updates            | 17980       |\n",
      "|    policy_gradient_loss | 0.0163      |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 44       |\n",
      "|    ep_rew_mean     | -706     |\n",
      "| time/              |          |\n",
      "|    fps             | 596      |\n",
      "|    iterations      | 208      |\n",
      "|    time_elapsed    | 714      |\n",
      "|    total_timesteps | 425984   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 43.4       |\n",
      "|    ep_rew_mean          | -707       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 597        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 716        |\n",
      "|    total_timesteps      | 428032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03220302 |\n",
      "|    clip_fraction        | 0.306      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.85       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 87.6       |\n",
      "|    n_updates            | 17990      |\n",
      "|    policy_gradient_loss | 0.00574    |\n",
      "|    std                  | 0.119      |\n",
      "|    value_loss           | 218        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=-652.24 +/- 24.29\n",
      "Episode length: 40.40 +/- 1.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 40.4        |\n",
      "|    mean_reward          | -652        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 430000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040101305 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.85        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.4        |\n",
      "|    n_updates            | 18000       |\n",
      "|    policy_gradient_loss | 0.0126      |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 248         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 42.8     |\n",
      "|    ep_rew_mean     | -702     |\n",
      "| time/              |          |\n",
      "|    fps             | 597      |\n",
      "|    iterations      | 210      |\n",
      "|    time_elapsed    | 719      |\n",
      "|    total_timesteps | 430080   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 42.8       |\n",
      "|    ep_rew_mean          | -696       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 598        |\n",
      "|    iterations           | 211        |\n",
      "|    time_elapsed         | 721        |\n",
      "|    total_timesteps      | 432128     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04392064 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.85       |\n",
      "|    explained_variance   | 0.926      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 59.6       |\n",
      "|    n_updates            | 18010      |\n",
      "|    policy_gradient_loss | -0.00484   |\n",
      "|    std                  | 0.118      |\n",
      "|    value_loss           | 418        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 42.6       |\n",
      "|    ep_rew_mean          | -683       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 599        |\n",
      "|    iterations           | 212        |\n",
      "|    time_elapsed         | 724        |\n",
      "|    total_timesteps      | 434176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03832532 |\n",
      "|    clip_fraction        | 0.412      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.88       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 49.3       |\n",
      "|    n_updates            | 18020      |\n",
      "|    policy_gradient_loss | 0.0174     |\n",
      "|    std                  | 0.117      |\n",
      "|    value_loss           | 155        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=435000, episode_reward=-675.48 +/- 16.93\n",
      "Episode length: 40.40 +/- 1.74\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 40.4       |\n",
      "|    mean_reward          | -675       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 435000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03952852 |\n",
      "|    clip_fraction        | 0.386      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.88       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 56.5       |\n",
      "|    n_updates            | 18030      |\n",
      "|    policy_gradient_loss | 0.0187     |\n",
      "|    std                  | 0.117      |\n",
      "|    value_loss           | 117        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 42.4     |\n",
      "|    ep_rew_mean     | -679     |\n",
      "| time/              |          |\n",
      "|    fps             | 600      |\n",
      "|    iterations      | 213      |\n",
      "|    time_elapsed    | 726      |\n",
      "|    total_timesteps | 436224   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.9        |\n",
      "|    ep_rew_mean          | -675        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 600         |\n",
      "|    iterations           | 214         |\n",
      "|    time_elapsed         | 729         |\n",
      "|    total_timesteps      | 438272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027196098 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.89        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.2        |\n",
      "|    n_updates            | 18040       |\n",
      "|    policy_gradient_loss | 0.013       |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-652.28 +/- 21.15\n",
      "Episode length: 39.40 +/- 1.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 39.4        |\n",
      "|    mean_reward          | -652        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021937829 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.9         |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 18050       |\n",
      "|    policy_gradient_loss | 0.00428     |\n",
      "|    std                  | 0.116       |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.6     |\n",
      "|    ep_rew_mean     | -674     |\n",
      "| time/              |          |\n",
      "|    fps             | 601      |\n",
      "|    iterations      | 215      |\n",
      "|    time_elapsed    | 732      |\n",
      "|    total_timesteps | 440320   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 41.8       |\n",
      "|    ep_rew_mean          | -685       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 602        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 734        |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03017046 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.91       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 53.7       |\n",
      "|    n_updates            | 18060      |\n",
      "|    policy_gradient_loss | 0.00126    |\n",
      "|    std                  | 0.116      |\n",
      "|    value_loss           | 150        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42.1        |\n",
      "|    ep_rew_mean          | -691        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 736         |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039229862 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.92        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 18070       |\n",
      "|    policy_gradient_loss | 0.00276     |\n",
      "|    std                  | 0.115       |\n",
      "|    value_loss           | 363         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=-676.50 +/- 43.87\n",
      "Episode length: 44.00 +/- 3.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 44          |\n",
      "|    mean_reward          | -676        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 445000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037531063 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 165         |\n",
      "|    n_updates            | 18080       |\n",
      "|    policy_gradient_loss | 0.0053      |\n",
      "|    std                  | 0.114       |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.7     |\n",
      "|    ep_rew_mean     | -680     |\n",
      "| time/              |          |\n",
      "|    fps             | 603      |\n",
      "|    iterations      | 218      |\n",
      "|    time_elapsed    | 739      |\n",
      "|    total_timesteps | 446464   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.9        |\n",
      "|    ep_rew_mean          | -678        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 742         |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030427735 |\n",
      "|    clip_fraction        | 0.398       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.97        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.1        |\n",
      "|    n_updates            | 18090       |\n",
      "|    policy_gradient_loss | 0.0279      |\n",
      "|    std                  | 0.113       |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=-658.56 +/- 59.86\n",
      "Episode length: 43.00 +/- 3.90\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 43         |\n",
      "|    mean_reward          | -659       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 450000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02674236 |\n",
      "|    clip_fraction        | 0.338      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.98       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 56.9       |\n",
      "|    n_updates            | 18100      |\n",
      "|    policy_gradient_loss | 0.0105     |\n",
      "|    std                  | 0.113      |\n",
      "|    value_loss           | 133        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.6     |\n",
      "|    ep_rew_mean     | -677     |\n",
      "| time/              |          |\n",
      "|    fps             | 605      |\n",
      "|    iterations      | 220      |\n",
      "|    time_elapsed    | 744      |\n",
      "|    total_timesteps | 450560   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.3        |\n",
      "|    ep_rew_mean          | -673        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 605         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 747         |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029189503 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 83.3        |\n",
      "|    n_updates            | 18110       |\n",
      "|    policy_gradient_loss | 0.014       |\n",
      "|    std                  | 0.113       |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.4        |\n",
      "|    ep_rew_mean          | -673        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 606         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 749         |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026790455 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 18120       |\n",
      "|    policy_gradient_loss | 0.015       |\n",
      "|    std                  | 0.113       |\n",
      "|    value_loss           | 81.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=-641.34 +/- 29.84\n",
      "Episode length: 43.20 +/- 3.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 43.2        |\n",
      "|    mean_reward          | -641        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 455000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055062953 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4           |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.1        |\n",
      "|    n_updates            | 18130       |\n",
      "|    policy_gradient_loss | 0.0152      |\n",
      "|    std                  | 0.112       |\n",
      "|    value_loss           | 81.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.3     |\n",
      "|    ep_rew_mean     | -671     |\n",
      "| time/              |          |\n",
      "|    fps             | 607      |\n",
      "|    iterations      | 223      |\n",
      "|    time_elapsed    | 752      |\n",
      "|    total_timesteps | 456704   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.7        |\n",
      "|    ep_rew_mean          | -673        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 606         |\n",
      "|    iterations           | 224         |\n",
      "|    time_elapsed         | 755         |\n",
      "|    total_timesteps      | 458752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019267349 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4           |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 18140       |\n",
      "|    policy_gradient_loss | 0.00649     |\n",
      "|    std                  | 0.112       |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=-646.75 +/- 78.73\n",
      "Episode length: 43.60 +/- 5.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 43.6        |\n",
      "|    mean_reward          | -647        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 460000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026531138 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.5        |\n",
      "|    n_updates            | 18150       |\n",
      "|    policy_gradient_loss | 0.000835    |\n",
      "|    std                  | 0.111       |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.9     |\n",
      "|    ep_rew_mean     | -669     |\n",
      "| time/              |          |\n",
      "|    fps             | 607      |\n",
      "|    iterations      | 225      |\n",
      "|    time_elapsed    | 758      |\n",
      "|    total_timesteps | 460800   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.4        |\n",
      "|    ep_rew_mean          | -665        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 761         |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025475278 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.02        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.7        |\n",
      "|    n_updates            | 18160       |\n",
      "|    policy_gradient_loss | 0.0196      |\n",
      "|    std                  | 0.11        |\n",
      "|    value_loss           | 112         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 41.3       |\n",
      "|    ep_rew_mean          | -671       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 608        |\n",
      "|    iterations           | 227        |\n",
      "|    time_elapsed         | 763        |\n",
      "|    total_timesteps      | 464896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04093061 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.04       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 39.4       |\n",
      "|    n_updates            | 18170      |\n",
      "|    policy_gradient_loss | 0.00971    |\n",
      "|    std                  | 0.11       |\n",
      "|    value_loss           | 136        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=-662.37 +/- 19.71\n",
      "Episode length: 39.60 +/- 1.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 39.6        |\n",
      "|    mean_reward          | -662        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 465000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033376582 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 18180       |\n",
      "|    policy_gradient_loss | 0.00848     |\n",
      "|    std                  | 0.11        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 42       |\n",
      "|    ep_rew_mean     | -680     |\n",
      "| time/              |          |\n",
      "|    fps             | 609      |\n",
      "|    iterations      | 228      |\n",
      "|    time_elapsed    | 766      |\n",
      "|    total_timesteps | 466944   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 42          |\n",
      "|    ep_rew_mean          | -675        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 609         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 768         |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015860243 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 18190       |\n",
      "|    policy_gradient_loss | 0.00769     |\n",
      "|    std                  | 0.11        |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=-677.75 +/- 19.93\n",
      "Episode length: 41.20 +/- 2.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 41.2        |\n",
      "|    mean_reward          | -678        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 470000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028474484 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.05        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.5        |\n",
      "|    n_updates            | 18200       |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    std                  | 0.11        |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.7     |\n",
      "|    ep_rew_mean     | -667     |\n",
      "| time/              |          |\n",
      "|    fps             | 609      |\n",
      "|    iterations      | 230      |\n",
      "|    time_elapsed    | 772      |\n",
      "|    total_timesteps | 471040   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.7        |\n",
      "|    ep_rew_mean          | -669        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 775         |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022937814 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.05        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.7        |\n",
      "|    n_updates            | 18210       |\n",
      "|    policy_gradient_loss | 0.0164      |\n",
      "|    std                  | 0.11        |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=-624.58 +/- 20.01\n",
      "Episode length: 42.20 +/- 0.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 42.2        |\n",
      "|    mean_reward          | -625        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 475000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.065449975 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.07        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.2        |\n",
      "|    n_updates            | 18220       |\n",
      "|    policy_gradient_loss | 0.00458     |\n",
      "|    std                  | 0.109       |\n",
      "|    value_loss           | 141         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.4     |\n",
      "|    ep_rew_mean     | -673     |\n",
      "| time/              |          |\n",
      "|    fps             | 610      |\n",
      "|    iterations      | 232      |\n",
      "|    time_elapsed    | 778      |\n",
      "|    total_timesteps | 475136   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.1        |\n",
      "|    ep_rew_mean          | -667        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 780         |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031047914 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.08        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.3        |\n",
      "|    n_updates            | 18230       |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    std                  | 0.109       |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.4        |\n",
      "|    ep_rew_mean          | -665        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 782         |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042740665 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.08        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.7        |\n",
      "|    n_updates            | 18240       |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    std                  | 0.109       |\n",
      "|    value_loss           | 143         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=-615.12 +/- 20.69\n",
      "Episode length: 41.00 +/- 1.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 41          |\n",
      "|    mean_reward          | -615        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 480000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041546404 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.07        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.1        |\n",
      "|    n_updates            | 18250       |\n",
      "|    policy_gradient_loss | 0.0191      |\n",
      "|    std                  | 0.109       |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.5     |\n",
      "|    ep_rew_mean     | -671     |\n",
      "| time/              |          |\n",
      "|    fps             | 612      |\n",
      "|    iterations      | 235      |\n",
      "|    time_elapsed    | 785      |\n",
      "|    total_timesteps | 481280   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41          |\n",
      "|    ep_rew_mean          | -665        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 613         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 788         |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035968546 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.08        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.9        |\n",
      "|    n_updates            | 18260       |\n",
      "|    policy_gradient_loss | 0.00784     |\n",
      "|    std                  | 0.108       |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=485000, episode_reward=-628.44 +/- 33.90\n",
      "Episode length: 39.40 +/- 2.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 39.4        |\n",
      "|    mean_reward          | -628        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 485000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027907245 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.12        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 18270       |\n",
      "|    policy_gradient_loss | 0.0138      |\n",
      "|    std                  | 0.107       |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.1     |\n",
      "|    ep_rew_mean     | -656     |\n",
      "| time/              |          |\n",
      "|    fps             | 613      |\n",
      "|    iterations      | 237      |\n",
      "|    time_elapsed    | 790      |\n",
      "|    total_timesteps | 485376   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.7        |\n",
      "|    ep_rew_mean          | -660        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 793         |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028587282 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.15        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 18280       |\n",
      "|    policy_gradient_loss | 0.0147      |\n",
      "|    std                  | 0.107       |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.5        |\n",
      "|    ep_rew_mean          | -661        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 795         |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029570566 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.17        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.7        |\n",
      "|    n_updates            | 18290       |\n",
      "|    policy_gradient_loss | 0.0128      |\n",
      "|    std                  | 0.106       |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=-629.82 +/- 17.43\n",
      "Episode length: 39.20 +/- 2.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 39.2        |\n",
      "|    mean_reward          | -630        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 490000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034464736 |\n",
      "|    clip_fraction        | 0.327       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.18        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.5        |\n",
      "|    n_updates            | 18300       |\n",
      "|    policy_gradient_loss | 0.00903     |\n",
      "|    std                  | 0.106       |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.3     |\n",
      "|    ep_rew_mean     | -662     |\n",
      "| time/              |          |\n",
      "|    fps             | 615      |\n",
      "|    iterations      | 240      |\n",
      "|    time_elapsed    | 798      |\n",
      "|    total_timesteps | 491520   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.5        |\n",
      "|    ep_rew_mean          | -663        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 800         |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036485795 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.16        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.9        |\n",
      "|    n_updates            | 18310       |\n",
      "|    policy_gradient_loss | 0.0136      |\n",
      "|    std                  | 0.107       |\n",
      "|    value_loss           | 125         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=-611.19 +/- 8.52\n",
      "Episode length: 39.20 +/- 1.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 39.2        |\n",
      "|    mean_reward          | -611        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 495000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026484773 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.16        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 83.8        |\n",
      "|    n_updates            | 18320       |\n",
      "|    policy_gradient_loss | 0.0128      |\n",
      "|    std                  | 0.106       |\n",
      "|    value_loss           | 127         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.4     |\n",
      "|    ep_rew_mean     | -663     |\n",
      "| time/              |          |\n",
      "|    fps             | 616      |\n",
      "|    iterations      | 242      |\n",
      "|    time_elapsed    | 803      |\n",
      "|    total_timesteps | 495616   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.9        |\n",
      "|    ep_rew_mean          | -660        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 617         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 805         |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048445463 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.18        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.7        |\n",
      "|    n_updates            | 18330       |\n",
      "|    policy_gradient_loss | 0.0148      |\n",
      "|    std                  | 0.106       |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 40.9        |\n",
      "|    ep_rew_mean          | -659        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 618         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 808         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025204767 |\n",
      "|    clip_fraction        | 0.314       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.19        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 18340       |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    std                  | 0.106       |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500000, episode_reward=-638.26 +/- 28.71\n",
      "Episode length: 41.00 +/- 1.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 41          |\n",
      "|    mean_reward          | -638        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034087803 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.21        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.4        |\n",
      "|    n_updates            | 18350       |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    std                  | 0.105       |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 41.2     |\n",
      "|    ep_rew_mean     | -659     |\n",
      "| time/              |          |\n",
      "|    fps             | 618      |\n",
      "|    iterations      | 245      |\n",
      "|    time_elapsed    | 810      |\n",
      "|    total_timesteps | 501760   |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f069a2a6cf8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps = 500_000, callback = eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path + '/ppo_jl_ramp_jump_sac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PPO.load(\"/home/bmsit/Ascento/jointed_limited/Training/model_for_demo.zip\", env = env)\n",
    "\n",
    "# #JL_10 -> STAYS AT SET POINT BUT KEEPS ON SPININING VERY VERY FAST\n",
    "# #JL_10_Best -> spins a bit slowly\n",
    "\n",
    "# # JL_11 -> MOVES AROUND, ALSO BENDS 1 LEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-644.9167245546977, 43.079922781843955)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes = 30, render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n",
      "0.007270701910780568\n",
      "-0.07225427313757425\n",
      "-0.09571033199787349\n",
      "-0.0294578150126919\n",
      "0.09365336801173937\n",
      "0.05307917448659929\n",
      "0.0915611491310038\n",
      "0.05780071788563733\n",
      "0.010003543535196516\n",
      "0.10141999142553963\n",
      "-0.027326996625955842\n",
      "-0.09793219571738124\n",
      "-0.15439683622563868\n",
      "0.002602645229315366\n",
      "0.012772014631051418\n",
      "-0.040802540265139325\n",
      "0.005288804320986279\n",
      "-0.05882564290027515\n",
      "0.042063260554434566\n",
      "-0.03621972650236005\n",
      "-0.06993023523262912\n",
      "-0.03966331577658201\n",
      "-0.06886642302612234\n",
      "-0.11304996445305443\n",
      "-0.13189285863652328\n",
      "-0.19988856495313112\n",
      "-0.00571318709083285\n",
      "-0.07958828352703706\n",
      "-0.10499085871619082\n",
      "-0.06015570994729336\n",
      "-0.07960849501220922\n",
      "-0.047087450657083356\n",
      "-0.1857458262205962\n",
      "-0.1716303526409259\n",
      "-0.16069771697042168\n",
      "-0.1382070182872473\n",
      "-0.1936027822310818\n",
      "-0.10029181718974528\n",
      "-0.013389595414484538\n",
      "0.020659838658022532\n",
      "-0.052321025557425155\n",
      "-0.13678326544355332\n",
      "-0.1570903526616769\n",
      "-0.3217225389225839\n",
      "-0.27778468209829127\n",
      "-0.31723118761866254\n",
      "-0.2836569829962262\n",
      "-0.23469363370632562\n",
      "-0.26162843269462016\n",
      "-0.26021393064282905\n",
      "-0.14039908650977617\n",
      "-0.15750781618210868\n",
      "-0.22120066997542015\n",
      "-0.31607983885559293\n",
      "-0.237860755093692\n",
      "-0.28454246471728584\n",
      "-0.3154356948933737\n",
      "-0.31624906924844026\n",
      "-0.35624861544468756\n",
      "-0.3795331683840412\n",
      "-0.3316157194353758\n",
      "-0.3172229642915347\n",
      "-0.25420307922792745\n",
      "-0.3012419088930204\n",
      "-0.38493161215337196\n",
      "-0.3554794029160097\n",
      "-0.34597356758063064\n",
      "-0.2665565163191828\n",
      "-0.2899783709386174\n",
      "-0.29296404172767077\n",
      "-0.2991613615622251\n",
      "-0.3030879405595013\n",
      "-0.38695998911928076\n",
      "-0.3585812369087685\n",
      "-0.34129172355483267\n",
      "-0.40521593262717714\n",
      "-0.29546537656357663\n",
      "-0.3511283226652688\n",
      "-0.31520477269884983\n",
      "-0.40131521142420745\n",
      "-0.45774111473137236\n",
      "-0.3604803235487942\n",
      "-0.31473143769248557\n",
      "-0.43805015411026715\n",
      "-0.336221336600896\n",
      "-0.3761510861274642\n",
      "-0.52421179379377\n",
      "-0.4616446922194224\n",
      "-0.4346044733970599\n",
      "-0.43365790481581795\n",
      "-0.4454386669459309\n",
      "-0.40129329744534364\n",
      "-0.4735672083784362\n",
      "-0.35910902887308294\n",
      "-0.466940340744722\n",
      "-0.4361937468296022\n",
      "-0.5632809414171835\n",
      "-0.5199073075960836\n",
      "-0.5600335374302305\n",
      "-0.5427860646788999\n",
      "-0.5068011909013758\n",
      "-0.5826663059372859\n",
      "-0.5399657315844528\n",
      "-0.5372320510896128\n",
      "-0.5052653331157444\n",
      "-0.4751434063185852\n",
      "-0.5610316969954812\n",
      "-0.5943721940736929\n",
      "-0.47658205398243125\n",
      "-0.5981070365276131\n",
      "-0.5628430860065218\n",
      "-0.6831882203923758\n",
      "-0.609840969792806\n",
      "-0.5867643322649336\n",
      "-0.6558707807420658\n",
      "-0.5547824851807045\n",
      "-0.6432473744254004\n",
      "-0.6030486420758183\n",
      "-0.6597946278564628\n",
      "-0.5875560564355459\n",
      "-0.5794098876465863\n",
      "-0.5647335398579416\n",
      "-0.6455452668682696\n",
      "-0.6866505911365015\n",
      "-0.7859041953489456\n",
      "-0.7202903162695715\n",
      "-0.6994889366487409\n",
      "-0.7360414688716685\n",
      "-0.5945573630605827\n",
      "-0.6711642403928626\n",
      "-0.7304721473156706\n",
      "-0.6591441776704654\n",
      "-0.7576609000036866\n",
      "-0.710065076439036\n",
      "-0.7632679695671479\n",
      "-0.8391018555825293\n",
      "-0.8166666077394339\n",
      "-0.7655793351724329\n",
      "-0.7416247591821044\n",
      "-0.7290727547019602\n",
      "-0.6741508318593233\n",
      "-0.7976184819512191\n",
      "-0.7287870325316144\n",
      "-0.7213573574178834\n",
      "-0.7111876217090531\n",
      "-0.7691189770854179\n",
      "-0.8600851508106946\n",
      "-0.8049824013675809\n",
      "-0.8353577977330235\n",
      "-0.8255643142750654\n",
      "-0.8342318489193046\n",
      "-0.7797100142290168\n",
      "-0.9026868017630374\n",
      "-0.8078911454684601\n",
      "-0.8488838322428949\n",
      "-0.6967020329806289\n",
      "-0.8528751103638678\n",
      "-0.9511429280236525\n",
      "-0.8061338456361318\n",
      "-0.7861198449482263\n",
      "-0.8507174479100748\n",
      "-0.8888749663168586\n",
      "-0.9036335930761878\n",
      "-0.8461690202131208\n",
      "-0.835749340624787\n",
      "-0.7225221911529516\n",
      "-0.8203136613697917\n",
      "-0.8775292949858686\n",
      "-0.8856422905818876\n",
      "-0.8763679008124564\n",
      "-0.9004203720102365\n",
      "-0.8923242776059064\n",
      "-0.9460340609692113\n",
      "-0.9932819342898691\n",
      "-0.9163931368917384\n",
      "-0.9045356039008607\n",
      "-0.9508504609701087\n",
      "-0.9641764650438943\n",
      "-0.8670821182927768\n",
      "-0.8939983982884163\n",
      "-0.948704441636591\n",
      "-0.8858146448414287\n",
      "-0.9272666718842436\n",
      "-0.8627931023214725\n",
      "-0.9167199854046322\n",
      "-0.9021820355281865\n",
      "-0.9190416711033244\n",
      "-0.9632623014220972\n",
      "-0.9319646486611932\n",
      "-0.8945202252933455\n",
      "-1.0525786212684043\n",
      "-1.0034897493520007\n",
      "-0.9396086955707921\n",
      "-1.0046274424882675\n",
      "-0.9998199070561131\n",
      "-0.9998247632752817\n",
      "-1.0147278950480112\n",
      "-0.9562952584393456\n",
      "-1.0049443843408243\n",
      "-0.9869153748848154\n",
      "-1.0594058351356095\n",
      "-1.0325485188803902\n",
      "-1.1108137220491636\n",
      "-1.1608387858996412\n",
      "-1.155413847753496\n",
      "-1.164810177121514\n",
      "-1.1431559959719513\n",
      "-1.065209790240383\n",
      "-1.101323964087423\n",
      "-1.0498931903171083\n",
      "-1.0868181742383023\n",
      "-1.1024792361026041\n",
      "-1.0842082067273215\n",
      "-1.1479507227629944\n",
      "-1.0520462406944655\n",
      "-0.9690650564336719\n",
      "-1.0108273182232237\n",
      "-1.0193942775220806\n",
      "-1.079337065251852\n",
      "-1.0222599268012722\n",
      "-0.9755898390538605\n",
      "-1.0443615017300272\n",
      "-1.0291762286371475\n",
      "-1.140069081385557\n",
      "-1.0865726866462564\n",
      "-1.1715915063922904\n",
      "-1.0555657835039296\n",
      "-1.0778947843383337\n",
      "-1.0933070432493994\n",
      "-1.151277229105407\n",
      "-1.110263978264118\n",
      "-1.163071453305724\n",
      "-1.1524992724325573\n",
      "-1.1965270719131966\n",
      "-1.0501247958674216\n",
      "-1.114901460638582\n",
      "-1.0062251999907053\n",
      "-1.0478510183058705\n",
      "-0.9987715851703631\n",
      "-1.1524381612230659\n",
      "-1.0728407610869124\n",
      "-1.072988448035432\n",
      "-1.1090042811257632\n",
      "-1.177911242776926\n",
      "-1.0882355968190405\n",
      "-1.1709476577808078\n",
      "-1.1739808503380642\n",
      "-1.1012343332821612\n",
      "-1.1485345015598045\n",
      "-1.0949512704949094\n",
      "-1.0814883827047277\n",
      "-1.0522802815962666\n",
      "-1.1700743982027784\n",
      "-1.1417746772364188\n",
      "-1.1725702735873373\n",
      "-1.1081994861086222\n",
      "-1.0946473049473107\n",
      "-1.1655112552725724\n",
      "-1.1078587213220812\n",
      "-1.2290725154838695\n",
      "-1.1874953831472395\n",
      "-1.2164955861632518\n",
      "-1.1625533571757052\n",
      "-1.204464366440349\n",
      "-1.2756680842219794\n",
      "-1.2068587406575362\n",
      "-1.256079373860271\n",
      "-1.313638759336233\n",
      "-1.2206915264323308\n",
      "-1.2585668773815404\n",
      "-1.1514167544333966\n",
      "-1.1050972770766239\n",
      "-1.1919204010139128\n",
      "-1.273847948000542\n",
      "-1.2101357971839064\n",
      "-1.1704741403365913\n",
      "-1.127500060718741\n",
      "-1.1777178678178475\n",
      "-1.1357433241381374\n",
      "-1.169999591142004\n",
      "-1.1675873007519235\n",
      "-1.2772439238883069\n",
      "-1.1894631921823005\n",
      "-1.2614093101203288\n",
      "-1.3814329418761686\n",
      "-1.314749777509986\n",
      "-1.3486463915085434\n",
      "-1.2393579921218787\n",
      "-1.156871333581393\n",
      "-1.1222448792075035\n",
      "-1.0550077549326513\n",
      "-1.1266984356697114\n",
      "-1.2002455502785467\n",
      "-1.207140266462491\n",
      "-1.2394593559078035\n",
      "-1.2639799649723202\n",
      "-1.2843680947302114\n",
      "-1.2679991939807114\n",
      "-1.2078902018208986\n",
      "-1.2805028591219\n",
      "-1.2907058075178088\n",
      "-1.281000699087421\n",
      "-1.160778224655457\n",
      "-1.238662792851688\n",
      "-1.1901694654409785\n",
      "-1.1857830134136793\n",
      "-1.099973735811825\n",
      "-1.1486628272504618\n",
      "-1.2671533531213557\n",
      "-1.190516277139933\n",
      "-1.2278367327741935\n",
      "-1.1728265607017447\n",
      "-1.229023176159497\n",
      "-1.3066008693285625\n",
      "-1.3629110597003817\n",
      "-1.2872715009962603\n",
      "-1.2194678721166687\n",
      "-1.104246993964364\n",
      "-1.1660713761771657\n",
      "-1.195443499948625\n",
      "-1.2061449369939061\n",
      "-1.274543814824235\n",
      "-1.2122792517280006\n",
      "-1.2230842497539185\n",
      "-1.1751202694274743\n",
      "-1.1217838298071103\n",
      "-1.3087535442467526\n",
      "-1.2426887014245163\n",
      "-1.2126344296501952\n",
      "-1.1791005743547416\n",
      "-1.1822106007496622\n",
      "-1.1261501277255357\n",
      "-1.2084513556395815\n",
      "-1.1669027641029026\n",
      "-1.2240020075304126\n",
      "-1.1613116014111995\n",
      "-1.180361281951926\n",
      "-1.2483679781284966\n",
      "-1.2600696318415383\n",
      "-1.3170175823609311\n",
      "-1.3427165423495855\n",
      "-1.2658422984008713\n",
      "-1.1933368334080845\n",
      "-1.1844735593237719\n",
      "-1.264077802484595\n",
      "-1.1327008569350434\n",
      "-1.2033865144321516\n",
      "-1.2157795825127655\n",
      "-1.199954665375948\n",
      "-1.1047242422229318\n",
      "-1.1572551916597884\n",
      "-1.3920920375865926\n",
      "-1.31384260486897\n",
      "-1.3274158106370302\n",
      "-1.3338086463472758\n",
      "-1.2313292374405775\n",
      "-1.255902856366068\n",
      "-1.3380625149855538\n",
      "-1.3730778731900555\n",
      "-1.303658032742503\n",
      "-1.2200879124096986\n",
      "-1.2845445412446002\n",
      "-1.3065004287454343\n",
      "-1.3156265955615394\n",
      "-1.3516827216426008\n",
      "-1.3288514439272208\n",
      "-1.3278726767652043\n",
      "-1.2604344255314386\n",
      "-1.210705555425386\n",
      "-1.1664915726474252\n",
      "-1.284904910824528\n",
      "-1.3164938039758758\n",
      "-1.2843741159418576\n",
      "-1.3484868931060996\n",
      "-1.3146144221929477\n",
      "-1.310858409291681\n",
      "-1.3127945105978591\n",
      "-1.3573169402030123\n",
      "-1.279264730672305\n",
      "-1.339997032259741\n",
      "-1.3275556115569744\n",
      "-1.2851661848931781\n",
      "-1.2132713148608456\n",
      "-1.1587463624887293\n",
      "-1.3628094878292751\n",
      "-1.3669845965794545\n",
      "-1.3527766941903592\n",
      "-1.2460997408125651\n",
      "-1.2318380460952414\n",
      "-1.2360747336126154\n",
      "-1.2619687664644985\n",
      "-1.3534818564067952\n",
      "-1.207996349600215\n",
      "-1.364370320345601\n",
      "-1.2624941985893148\n",
      "-1.3508543951558507\n",
      "-1.300583258207349\n",
      "-1.224828187820893\n",
      "-1.2866467747251351\n",
      "-1.2830554112462176\n",
      "-1.1939323703655698\n",
      "-1.2346613541688034\n",
      "-1.3065529153628168\n",
      "-1.3133353514537984\n",
      "-1.3304234669156019\n",
      "-1.2316482101260677\n",
      "-1.191281638636787\n",
      "-1.248855082315193\n",
      "-1.2823826826181635\n",
      "-1.221705168798524\n",
      "-1.2721748126970713\n",
      "-1.2324763145660933\n",
      "-1.2321580331273094\n",
      "-1.2912061038981746\n",
      "-1.2729622752739975\n",
      "-1.1696163920230997\n",
      "-1.2111914680562592\n",
      "-1.2720638887393645\n",
      "-1.2165106024688834\n",
      "-1.119953326992149\n",
      "-1.2916801794581183\n",
      "-1.2937445516912702\n",
      "-1.1993209659344473\n",
      "-1.2059898354901342\n",
      "-1.1863414828371084\n",
      "-1.1773754758690045\n",
      "-1.1693362848670281\n",
      "-1.3015203164492215\n",
      "-1.2548980024277177\n",
      "-1.2827129749005368\n",
      "-1.2477235486348275\n",
      "-1.178256162949048\n",
      "-1.165802604118005\n",
      "-1.2035305692460807\n",
      "-1.247615144868313\n",
      "-1.3032003279238136\n",
      "-1.179023675739944\n",
      "-1.1367546626836713\n",
      "-1.2279291099431255\n",
      "-1.179422290631819\n",
      "-1.2684130726506244\n",
      "-1.2908430144977983\n",
      "-1.2748765824225934\n",
      "-1.250625322972716\n",
      "-1.2073811945421051\n",
      "-1.2959141021146776\n",
      "-1.2689877285426714\n",
      "-1.2699774130787225\n",
      "-1.2633475204794051\n",
      "-1.1811818535731513\n",
      "-1.1128798538335456\n",
      "-1.113794878208645\n",
      "-1.169584554662854\n",
      "-1.2009616342921874\n",
      "-1.2403075717941074\n",
      "-1.235816049275782\n",
      "-1.2086328371335704\n",
      "-1.2406131571982597\n",
      "-1.2187090979636375\n",
      "-1.1689521205497666\n",
      "-1.246871733328472\n",
      "-1.1746563518871398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2422401658492275\n",
      "-1.1613612438267031\n",
      "-1.155257558305382\n",
      "-1.2283689393253434\n",
      "-1.2226663568601148\n",
      "-1.2084068873245848\n",
      "-1.2894715818049225\n",
      "-1.277999863281363\n",
      "-1.185008507938658\n",
      "-1.1651893508279385\n",
      "-1.2213682640336692\n",
      "-1.2072453617682888\n",
      "-1.2770688542030888\n",
      "-1.2353398967466382\n",
      "-1.142337867282584\n",
      "-1.2195694103067292\n",
      "-1.187997170888369\n",
      "-1.1885885531472615\n",
      "-1.2211868109161166\n",
      "-1.2495739622619373\n",
      "-1.2695148568494228\n",
      "-1.254487945095638\n",
      "-1.206036911909576\n",
      "-1.1787175223437354\n",
      "-1.1628249559517176\n",
      "-1.134584215215526\n",
      "-0.991712455370852\n",
      "-1.0707276744707783\n",
      "-1.1806500396638882\n",
      "-1.1011382911406138\n",
      "-1.1269808595743187\n",
      "-1.0943284492180751\n",
      "-1.169526661341516\n",
      "-1.0579730173629636\n",
      "-1.1743511666623725\n",
      "-1.1044028993654704\n",
      "-1.1144500412578724\n",
      "-1.070662055502384\n",
      "-1.0966195720882563\n",
      "-1.0983985196854074\n",
      "-1.0868839975264453\n",
      "-1.121264524393405\n",
      "-1.1338985887975053\n",
      "-1.1102256743183174\n",
      "-1.1784801682096318\n",
      "-1.192398220933741\n",
      "-1.0598240049848962\n",
      "-1.1430244569615864\n",
      "-1.1768434569881616\n",
      "-1.181775436769008\n",
      "-1.178921125965285\n",
      "-1.1050886602489702\n",
      "-1.0213008507848638\n",
      "-1.0886704221757202\n",
      "-1.0614609544459694\n",
      "-1.0247215305066832\n",
      "-1.0974758796935802\n",
      "-1.160665893766452\n",
      "-1.046078240198135\n",
      "-1.061080471782368\n",
      "-1.212501105115537\n",
      "-1.1413451727469086\n",
      "-1.1357912002701818\n",
      "-1.1252555281847492\n",
      "-1.2474989493806325\n",
      "-1.1575959568925456\n",
      "-1.1793699825329218\n",
      "-1.2324449533135517\n",
      "-1.2217985517093306\n",
      "-1.2204171947278344\n",
      "-1.2382439217772025\n",
      "-1.2189680672748195\n",
      "-1.0688917183222273\n",
      "-0.9998721098020354\n",
      "-1.0892687583472607\n",
      "-1.0754250884127534\n",
      "-1.1455498004572149\n",
      "-1.0625581962075559\n",
      "-1.0902917049370917\n",
      "-1.106309092373517\n",
      "-1.1744491859240953\n",
      "-1.144223891021936\n",
      "-1.2295880976221292\n",
      "-1.1444144599251527\n",
      "-1.2400588854627228\n",
      "-1.1217354792442127\n",
      "-1.1938311838693998\n",
      "-1.1731413588969506\n",
      "-1.137786263006368\n",
      "-1.0530745802649448\n",
      "-1.1904529609853596\n",
      "-1.0473934372514828\n",
      "-1.0304072649328786\n",
      "-1.0373342591354453\n",
      "-1.0556224286347575\n",
      "-1.2695147072912951\n",
      "-1.129528773548506\n",
      "-1.0719537604394431\n",
      "-1.027080572524783\n",
      "-1.0877113628392123\n",
      "-0.9830423028840491\n",
      "-0.9775852668267744\n",
      "-1.100396515220226\n",
      "-1.0994625371517868\n",
      "-1.0960420488533102\n",
      "-1.1454357428715005\n",
      "-1.1884257539181566\n",
      "-1.1888122710576583\n",
      "-1.1671583354837833\n",
      "-1.093929265312701\n",
      "-1.2637492045914678\n",
      "-1.2275183925936595\n",
      "-1.1468561069652428\n",
      "-1.0316725116067456\n",
      "-1.1636333507770578\n",
      "-1.1577312952022105\n",
      "-1.1442350995608768\n",
      "-1.1632670745221518\n",
      "-1.0878492957015686\n",
      "-1.0000266310733907\n",
      "-1.194000578332652\n",
      "-1.2613883545068096\n",
      "-1.2997331185404364\n",
      "-1.3305817762698402\n",
      "-1.351949260294648\n",
      "-1.2093382551050769\n",
      "-1.1948630714733457\n",
      "-1.19574569176151\n",
      "-1.2216796365194116\n",
      "-1.1547711437629133\n",
      "-1.115080949832967\n",
      "-1.102912729691056\n",
      "-1.1120948947059288\n",
      "-0.9845577361961165\n",
      "-1.065790801347633\n",
      "-1.0247299517282351\n",
      "-1.1711411179515427\n",
      "-1.1659882749878725\n",
      "-1.141317234294137\n",
      "-1.1639176757490524\n",
      "-1.1675594071747342\n",
      "-1.1135853530035875\n",
      "-1.1010433155429906\n",
      "-1.2192603460378049\n",
      "-1.190146286178134\n",
      "-1.1569625377638069\n",
      "-1.1526766418696615\n",
      "-1.0535123392795696\n",
      "-1.073776322654743\n",
      "-1.1560016739275145\n",
      "-1.1775928943264133\n",
      "-1.1091446521700388\n",
      "-1.1636612673506321\n",
      "-0.9984962744653061\n",
      "-1.0813556710203633\n",
      "-1.1220242813056307\n",
      "-1.0721758159340993\n",
      "-1.010794128631635\n",
      "-1.0558968064502217\n",
      "-1.0653171231025813\n",
      "-1.0643896711017375\n",
      "-0.9578804014278663\n",
      "-1.0981129725246883\n",
      "-1.0304444008640652\n",
      "-1.1523215425079396\n",
      "-1.1196882705137559\n",
      "-1.12059595643534\n",
      "-1.1331907863214532\n",
      "-1.0647802199512375\n",
      "-1.1532989015679873\n",
      "-1.0836923869762451\n",
      "-1.0306213161832987\n",
      "-1.1092801959037122\n",
      "-1.01715451933086\n",
      "-0.987353445312147\n",
      "-1.0410253533421037\n",
      "-1.1215742427476278\n",
      "-1.032771969895828\n",
      "-0.9674697658322952\n",
      "-0.9702147239491442\n",
      "-1.0587535576650933\n",
      "-1.0196497141178105\n",
      "-1.1649604596008387\n",
      "-1.0041957641006463\n",
      "-1.0516486754335992\n",
      "-0.9184611198576703\n",
      "-0.9918550091998652\n",
      "-1.0524628184777618\n",
      "-1.146741614378374\n",
      "-1.066873774341788\n",
      "-0.899166124227535\n",
      "-0.9639484525144779\n",
      "-1.0119033186600845\n",
      "-0.973875233421253\n",
      "-0.9653316032154714\n",
      "-1.0460491287409064\n",
      "-1.089585367881294\n",
      "-0.9888462016325265\n",
      "-1.0768679875246\n",
      "-0.9609755766074237\n",
      "-1.0726471673512612\n",
      "-1.0044601929556431\n",
      "-0.9766946408976747\n",
      "-0.9900040200527566\n",
      "-1.0390930210931049\n",
      "-1.1161727868962532\n",
      "-1.0119661267097833\n",
      "-1.0491754592555176\n",
      "-1.0399150705533708\n",
      "-1.0619778567508515\n",
      "-1.0473825587481465\n",
      "-1.0489966097535937\n",
      "-0.9735269217668739\n",
      "-1.0775384267247334\n",
      "-0.9810180142780892\n",
      "-1.0476935653313337\n",
      "-1.0470475478654646\n",
      "-0.9253793899478854\n",
      "-0.9733759414731349\n",
      "-0.8398686646200385\n",
      "-0.8936844719158553\n",
      "-0.9734931729524434\n",
      "-0.9922569413119245\n",
      "-1.0151199216729652\n",
      "-0.932185101415853\n",
      "-1.019520900992509\n",
      "-0.9134492181379098\n",
      "-1.0777701359921557\n",
      "-0.9979878731770161\n",
      "-0.895213889886989\n",
      "-0.9812528935291753\n",
      "-0.9864333738587355\n",
      "-1.1162593749668819\n",
      "-1.1489334020707251\n",
      "-0.9794379453953697\n",
      "-1.0031316529537062\n",
      "-1.0236807495373943\n",
      "-1.0028472484578104\n",
      "-0.9218389643563628\n",
      "-0.9469090218295175\n",
      "-1.0145623942734834\n",
      "-0.9705934968593243\n",
      "-0.9281889264123494\n",
      "-1.074253254614376\n",
      "-0.903873288138528\n",
      "-1.0067812128403388\n",
      "-1.001850717560255\n",
      "-1.0314642404134131\n",
      "-0.9569695053517536\n",
      "-0.9318321308400597\n",
      "-0.862667613229665\n",
      "-0.9720603140434831\n",
      "-1.0553953503897084\n",
      "-0.9833446188006743\n",
      "-1.0441114605709736\n",
      "-0.9843842841913786\n",
      "-0.9228189134411915\n",
      "-1.1134091356420104\n",
      "-1.076924832569442\n",
      "-1.0351286493824066\n",
      "-1.0213732454303857\n",
      "-1.0248287590946157\n",
      "-0.9568528019761917\n",
      "-1.0347057585581745\n",
      "-1.0096264838096258\n",
      "-1.0936815175891847\n",
      "-0.9479485791120168\n",
      "-0.9929034218505755\n",
      "-0.9439744854488208\n",
      "-0.933041084631247\n",
      "-0.9530515805442324\n",
      "-0.9286343808937637\n",
      "-1.0197817818729837\n",
      "-1.0854276886373477\n",
      "-1.0579573937625002\n",
      "-0.9644523880757662\n",
      "-0.9127068827832338\n",
      "-0.9675015619288851\n",
      "-0.878679666870733\n",
      "-0.9569560704163766\n",
      "-0.9771251773844087\n",
      "-0.8771981393171004\n",
      "-0.9982460999888133\n",
      "-0.8512382972422909\n",
      "-0.8776490543032467\n",
      "-0.8302572410842781\n",
      "-0.908118981486226\n",
      "-0.9244562498303746\n",
      "-0.9292916627434286\n",
      "-0.894541017711122\n",
      "-0.9054906523386292\n",
      "-0.8803893341779846\n",
      "-0.9867053231500627\n",
      "-1.0443732878405485\n",
      "-0.876613867873562\n",
      "-0.9032962182956521\n",
      "-0.8722333378962441\n",
      "-0.834758117797492\n",
      "-0.8780139870016965\n",
      "-0.8176747207487791\n",
      "-0.8894263010063993\n",
      "-0.9049657635234931\n",
      "-0.9245115760139521\n",
      "-0.9380532733827271\n",
      "-1.0107598882721207\n",
      "-0.9995521962757334\n",
      "-0.9344640243803488\n",
      "-0.9855631829570604\n",
      "-0.8990907604154443\n",
      "-0.9078075873071136\n",
      "-0.8770475983362397\n",
      "-0.9554659317211135\n",
      "-0.8923614828658935\n",
      "-0.86341564535917\n",
      "-0.8526496411748177\n",
      "-0.8667247508861677\n",
      "-0.9771654770151295\n",
      "-0.9993762102378565\n",
      "-0.8999737678600542\n",
      "-0.872376463574966\n",
      "-0.884237745995537\n",
      "-0.8365682498791219\n",
      "-0.9214380916383482\n",
      "-0.9481084262248791\n",
      "-0.8692496720872884\n",
      "-0.9307904244363215\n",
      "-0.9413830377792034\n",
      "-0.9571808782115371\n",
      "-0.9544193821249551\n",
      "-1.0555516907344762\n",
      "-1.0628630266808625\n",
      "-1.0303244271821692\n",
      "-1.084894341599004\n",
      "-0.9563220776481267\n",
      "-0.9663567625000092\n",
      "-0.9303630991209701\n",
      "-0.9241477196441426\n",
      "-0.9980988529236952\n",
      "-1.0803087130737088\n",
      "-1.0246297177570274\n",
      "-0.9348722862372232\n",
      "-1.0933997128662425\n",
      "-0.9875036505730785\n",
      "-0.980709712006814\n",
      "-1.0288276876384848\n",
      "-1.0223814471004349\n",
      "-0.9067206011220913\n",
      "-0.9423045596269815\n",
      "-0.9259196827716618\n",
      "-0.84984549438824\n",
      "-0.8842503341430139\n",
      "-0.9446769124420279\n",
      "-0.9413690547931938\n",
      "-0.9457633804660578\n",
      "-0.9608571185249569\n",
      "-0.9776558228577404\n",
      "-0.9565722585490072\n",
      "-0.9153837844910048\n",
      "-0.9784738729618219\n",
      "-0.9806083864501149\n",
      "-0.8268560259808635\n",
      "-0.9244507130263421\n",
      "-0.8667402545013031\n",
      "-0.9890602131516903\n",
      "-1.070474482042947\n",
      "-1.0101768172734744\n",
      "-1.0618703025544185\n",
      "-0.9550278592719494\n",
      "-0.9247527893651202\n",
      "-1.0218541628816498\n",
      "-0.9934817189304587\n",
      "-0.8988460563612841\n",
      "-0.9629442635545801\n",
      "-0.9501973271005355\n",
      "-0.9020822506377901\n",
      "-0.9512417224335267\n",
      "-1.0195333139998324\n",
      "-0.9431380728828326\n",
      "-0.8849382181992025\n",
      "-0.904496466277815\n",
      "-0.9121651406127063\n",
      "-0.949803019648321\n",
      "-0.9730738675113735\n",
      "-0.9071004777601022\n",
      "-0.9022979247907483\n",
      "-0.830133401258446\n",
      "-0.8019949256562691\n",
      "-0.8644749205329505\n",
      "-0.8735053161834117\n",
      "-0.9046982715489993\n",
      "-0.8816913302336464\n",
      "-0.9350328778474785\n",
      "-0.9282776081574431\n",
      "-0.9164679911743012\n",
      "-0.9428556157029067\n",
      "-0.9828567004531759\n",
      "-1.0504634022773929\n",
      "-0.9259203586880222\n",
      "-0.9602408690520926\n",
      "-0.921862379772714\n",
      "-0.9857849816213514\n",
      "-0.9109645691991922\n",
      "-1.025034629924923\n",
      "-0.9473149955047057\n",
      "-0.9609970319118911\n",
      "-0.9566150169075267\n",
      "-0.9012616279410517\n",
      "-0.8558267543356776\n",
      "-0.8605243012474508\n",
      "-0.8574260145334882\n",
      "-1.0445276896343263\n",
      "-0.9884278017264808\n",
      "-1.0404345401911836\n",
      "-1.0657171961902123\n",
      "-1.0520939838384535\n",
      "-1.0169984232753269\n",
      "-0.928939737744812\n",
      "-0.8657352111774237\n",
      "-0.8746536766925929\n",
      "-0.889311043660442\n",
      "-0.8688343024987409\n",
      "-0.9132292527768971\n",
      "-0.8942366880438987\n",
      "-1.0048908410056927\n",
      "-0.929534037123127\n",
      "-0.9443150885400539\n",
      "-0.9020075986300998\n",
      "-0.904543717601683\n",
      "-0.9553927164828727\n",
      "-0.917457751630704\n",
      "-0.8325516639193243\n",
      "-0.9364649628760631\n",
      "-1.0489836077999513\n",
      "-0.9923975898404424\n",
      "-1.1234289026902264\n",
      "-1.0392677293963295\n",
      "-1.0468505721373829\n",
      "-1.017162026103466\n",
      "-1.0692494341384329\n",
      "-1.0160116666941756\n",
      "-1.134957711421458\n",
      "-0.9901191982437888\n",
      "-1.0262031712058712\n",
      "-0.9711798452854812\n",
      "-1.009666189673513\n",
      "-0.8932480634110757\n",
      "-0.9951441329074243\n",
      "-0.9128922676826564\n",
      "-1.0631937594386682\n",
      "-0.985423101229442\n",
      "-0.994928177801401\n",
      "-0.9640440741872875\n",
      "-1.028938040039317\n",
      "-1.0233613057279634\n",
      "-0.9506379950114552\n",
      "-0.970895953908973\n",
      "-0.8986159175981386\n",
      "-0.9943745226529259\n",
      "-0.9835168774842485\n",
      "-0.9326333167813123\n",
      "-0.9224012816506254\n",
      "-0.9876390993704982\n",
      "-0.9264745425478221\n",
      "-0.8886044443611447\n",
      "-0.900291166670315\n",
      "-0.9902972827243629\n",
      "-0.9362991523062422\n",
      "-1.039556139813391\n",
      "-0.8974447056659418\n",
      "-0.9850586819418112\n",
      "-0.9860750087097171\n",
      "-0.8864514528592641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.024337751750337\n",
      "-0.9538739483073375\n",
      "-1.0398288562509197\n",
      "-1.0732022444160134\n",
      "-0.9516148642037977\n",
      "-0.9898076681837853\n",
      "-1.0049623249185529\n",
      "-0.9549033832837139\n",
      "-0.9260563389426968\n",
      "-1.0110997931067063\n",
      "-0.9360852881618297\n",
      "-0.9487074639206486\n",
      "-1.055596204836765\n",
      "-0.8992997463590935\n",
      "-1.023311865094088\n",
      "-1.028780601116488\n",
      "-0.9894393070370289\n",
      "-1.0226303315584175\n",
      "-0.9049087107559389\n",
      "-0.8627789680921024\n",
      "-0.9342115238347471\n",
      "-0.9098748291297896\n",
      "-0.9430641036930432\n",
      "-0.9581100355684272\n",
      "-0.8455636538638768\n",
      "-0.981524482686036\n",
      "-1.0431867066954736\n",
      "-1.05598951940674\n",
      "-0.9503725247715056\n",
      "-1.0033725561038978\n",
      "-1.0300790191004683\n",
      "-1.0187738937406658\n",
      "-1.0179659937322614\n",
      "-0.9640988642039031\n",
      "-0.9515013679026763\n",
      "-1.0022803295804052\n",
      "-0.9759503669382064\n",
      "-0.9516443993817798\n",
      "-0.9135197360220929\n",
      "-0.909465038433109\n",
      "-0.8742489840798569\n",
      "-0.9558782990859124\n",
      "-1.0003791234218005\n",
      "-1.0571427219529292\n",
      "-0.9661034118484415\n",
      "-0.9604719715361169\n",
      "-1.0094980541025387\n",
      "-1.0281708941352252\n",
      "-0.9912064578172591\n",
      "-0.9534537576370211\n",
      "-0.9680526092545089\n",
      "-1.0140756016115746\n",
      "-0.974069794063613\n",
      "-0.9953834002696037\n",
      "-0.9610061084001469\n",
      "-1.0397756151916149\n",
      "-0.9704374473100716\n",
      "-0.9703578282225549\n",
      "-0.9197170029406067\n",
      "-0.8969708219140435\n",
      "-0.9005074236808962\n",
      "-0.7857086371579562\n",
      "-0.8065735492487757\n",
      "-0.9064757486954788\n",
      "-0.9669631300697281\n",
      "-0.9713285016121319\n",
      "-0.9518410794847083\n",
      "-0.939316493614327\n",
      "-0.9953376050590106\n",
      "-0.9453703374209284\n",
      "-1.0762313545306124\n",
      "-1.0893777771808681\n",
      "-1.0533014989143863\n",
      "-1.0381542263288912\n",
      "-1.127496088647833\n",
      "-1.1248335338303321\n",
      "-1.0792433499735965\n",
      "-1.0236404907731553\n",
      "-1.0436354831724546\n",
      "-0.9922374927959771\n",
      "-1.0428612463783915\n",
      "-1.0205912881708412\n",
      "-1.0615645489183383\n",
      "-1.0589886659412142\n",
      "-1.0046071752460213\n",
      "-1.004774218651044\n",
      "-0.9685722293726969\n",
      "-0.9390253962576751\n",
      "-0.9112553826639691\n",
      "-1.0200146786017241\n",
      "-0.9698437900839844\n",
      "-1.0640833745206817\n",
      "-1.088352315120863\n",
      "-1.0990556603220578\n",
      "-1.107844771904456\n",
      "-1.0604922342400562\n",
      "-1.0329259143633187\n",
      "-1.0169071876625169\n",
      "-0.9726781989874381\n",
      "-1.0315603096293702\n",
      "-0.9153526469244467\n",
      "-1.018118090841282\n",
      "-1.0596640085469133\n",
      "-1.0204626921876778\n",
      "-1.1061131372842339\n",
      "-0.9994424787600764\n",
      "-0.8902780918182458\n",
      "-0.9197960377717899\n",
      "-0.9269902986726022\n",
      "-1.0507325442764364\n",
      "-1.05288470308735\n",
      "-0.9081745717510588\n",
      "-0.9967030385025656\n",
      "-0.9160872732779011\n",
      "-0.9926168111439876\n",
      "-1.0093196886797797\n",
      "-1.029244289277799\n",
      "-0.9929894147987259\n",
      "-1.113024178482543\n",
      "-0.9518513136436276\n",
      "-1.0357900352042553\n",
      "-1.0815292451861225\n",
      "-1.0895426317249135\n",
      "-1.0803530045876204\n",
      "-1.13984442590336\n",
      "-1.0285035344613602\n",
      "-1.1045228386196226\n",
      "-1.0097563377780427\n",
      "-1.0574560280316494\n",
      "-1.0556110457220713\n",
      "-0.9469502729678512\n",
      "-1.0643479842162036\n",
      "-0.9634273870196828\n",
      "-1.0417704461475985\n",
      "-0.9559555741316548\n",
      "-1.020768688635407\n",
      "-1.0010764766423739\n",
      "-1.0933907045927918\n",
      "-1.0940013322545503\n",
      "-1.1458138394164492\n",
      "-1.1295599173746078\n",
      "-1.1517603172967383\n",
      "-1.2009954704781656\n",
      "-1.120083750930918\n",
      "-1.1204561438823413\n",
      "-1.1005013183332641\n",
      "-1.1798846735941804\n",
      "-0.9977813797956101\n",
      "-1.1888818994403092\n",
      "-1.1495111468968346\n",
      "-1.164378118654201\n",
      "-1.101039769455688\n",
      "-1.181705201127353\n",
      "-1.1843263293204005\n",
      "-1.024687183865529\n",
      "-1.0920412999636262\n",
      "-1.0636547335213906\n",
      "-0.9858415853365512\n",
      "-1.0770082548273725\n",
      "-0.9883643966784424\n",
      "-1.0261683141044184\n",
      "-1.068441541076822\n",
      "-1.1525115806594641\n",
      "-1.1048620518144174\n",
      "-1.0852305083842912\n",
      "-1.0909539480558093\n",
      "-1.0411130712726067\n",
      "-0.9907967496301141\n",
      "-1.0544519141302195\n",
      "-1.058243358626976\n",
      "-1.074301846623421\n",
      "-1.0824384806133234\n",
      "-1.0421977994018312\n",
      "-1.1268726053419793\n",
      "-1.0278915138411437\n",
      "-1.0308295041145026\n",
      "-1.08259694265432\n",
      "-1.127972129080924\n",
      "-1.1011978817576091\n",
      "-1.0916204356990205\n",
      "-1.022186197843686\n",
      "-1.1035670497173058\n",
      "-1.0437334501293574\n",
      "-1.0539685735954918\n",
      "-1.0077604158097138\n",
      "-1.159969877516079\n",
      "-1.0637662363832876\n",
      "-0.9574819365780182\n",
      "-1.1026227017530756\n",
      "-1.0428426912106998\n",
      "-1.000082877954244\n",
      "-1.0739279212034076\n",
      "-1.0234412482412232\n",
      "-1.0996465044821848\n",
      "-1.0639236882685517\n",
      "-1.0022525067891646\n",
      "-0.9295182554685263\n",
      "-1.0890641593414272\n",
      "-1.0337887378827548\n",
      "-1.0206084769027337\n",
      "-1.028033983944717\n",
      "-1.058843766778802\n",
      "-1.102273796206015\n",
      "-1.141392205663275\n",
      "-1.1473451040635245\n",
      "-1.0684737773325723\n",
      "-1.1826028227622742\n",
      "-1.170616049784413\n",
      "-1.0504272386241484\n",
      "-1.0380271889863435\n",
      "-1.0243971896465787\n",
      "-0.9105045100294562\n",
      "-0.930042163814615\n",
      "-0.9271773830564071\n",
      "-0.9837115509796943\n",
      "-1.0098202915201893\n",
      "-1.0740822800075842\n",
      "-1.0864604795378918\n",
      "-1.122160453186614\n",
      "-1.0799322437205128\n",
      "-1.0509576692501068\n",
      "-1.080580410396255\n",
      "-0.9289704558363849\n",
      "-1.0054178732301606\n",
      "-1.0830796654917283\n",
      "-1.0248848479339927\n",
      "-1.0869320647575222\n",
      "-1.0999438602300844\n",
      "-1.1567862257124917\n",
      "-1.0704010181118306\n",
      "-1.0421312546555175\n",
      "-1.120407057556507\n",
      "-1.073902956868033\n",
      "-1.070116490165719\n",
      "-1.0732486420515586\n",
      "-1.091947778129014\n",
      "-0.9695941477671932\n",
      "-1.1868863474564486\n",
      "-1.072362357902886\n",
      "-1.0357192143665055\n",
      "-1.0427089250317974\n",
      "-0.9939292003512918\n",
      "-1.0509669047808807\n",
      "-0.9796052547308891\n",
      "-1.0398908070421915\n",
      "-0.9762789426526137\n",
      "-0.9642412528115454\n",
      "-1.0326474250700994\n",
      "-1.0649723658126788\n",
      "-1.1234604345967112\n",
      "-1.1156754892983112\n",
      "-1.1353309443254782\n",
      "-1.0744877003437943\n",
      "-1.2694295376522855\n",
      "-1.1499936023197135\n",
      "-1.0423793373033141\n",
      "-1.1419666692314423\n",
      "-1.0766747957138636\n",
      "-1.1778515304712887\n",
      "-1.10214414576802\n",
      "-1.0484639434113494\n",
      "-1.0545678130583114\n",
      "-1.0124115160026248\n",
      "-1.0677235696692413\n",
      "-1.2051780730690347\n",
      "-1.0476658696011656\n",
      "-1.0473413045129805\n",
      "-1.1394441064635417\n",
      "-1.0722690531198056\n",
      "-1.0854693901149286\n",
      "-1.0922477994293547\n",
      "-0.9963145615024421\n",
      "-0.9864605737857143\n",
      "-1.1619277266309591\n",
      "-1.059919822709986\n",
      "-1.1195346231055157\n",
      "-1.0770601694443562\n",
      "-1.1081108850109267\n",
      "-1.1359533767002712\n",
      "-1.0865938118751965\n",
      "-1.1046563619434588\n",
      "-1.0050174416537907\n",
      "-1.0517314293132793\n",
      "-1.106810068928048\n",
      "-1.068678261446573\n",
      "-1.0921495478456227\n",
      "-0.9762227196652545\n",
      "-1.1193224977257055\n",
      "-1.1634829517795244\n",
      "-1.0562418559010343\n",
      "-1.1765114036307809\n",
      "-1.1608808276143336\n",
      "-1.1111010053466406\n",
      "-1.0795350826267973\n",
      "-1.0918060958762763\n",
      "-1.1814993275892922\n",
      "-1.176234841730602\n",
      "-1.1517712240947393\n",
      "-1.0919362535137405\n",
      "-1.0623981897538624\n",
      "-1.145257471978784\n",
      "-1.2019226637116804\n",
      "-1.1238128385476223\n",
      "-1.046658652046664\n",
      "-1.08628053626876\n",
      "-1.0522236587657436\n",
      "-1.003554594653503\n",
      "-1.0878392172674507\n",
      "-1.1100288710516777\n",
      "-1.0152936199994582\n",
      "-1.0648536408146831\n",
      "-1.0168888892774628\n",
      "-1.1245304100737765\n",
      "-1.0265765173897845\n",
      "-1.1159121541864279\n",
      "-0.9853467476333386\n",
      "-1.092038826156491\n",
      "-1.1009078801572432\n",
      "-1.0486979504746567\n",
      "-1.1217727459280378\n",
      "-1.1342661987722125\n",
      "-1.080159634407159\n",
      "-1.1187110116292533\n",
      "-1.0957992684391529\n",
      "-1.0266550371103154\n",
      "-1.0082460641197515\n",
      "-1.066831192112221\n",
      "-1.077714716450107\n",
      "-1.1091881835749637\n",
      "-1.1592853389481994\n",
      "-1.1233429921354632\n",
      "-1.047294033485676\n",
      "-1.1350259122032045\n",
      "-1.0608601936977013\n",
      "-1.009278138720564\n",
      "-1.0060878922545686\n",
      "-0.9294317793113605\n",
      "-1.054810572740472\n",
      "-1.0239584321499133\n",
      "-1.0609593221548075\n",
      "-1.1272127502936606\n",
      "-1.0433686837762601\n",
      "-1.0901669553562672\n",
      "-1.1086120245176665\n",
      "-1.071993241883238\n",
      "-1.030947838007954\n",
      "-1.127855128268847\n",
      "-1.0647031976327397\n",
      "-1.0093368606866928\n",
      "-1.1182143295466218\n",
      "-1.1187854782228175\n",
      "-1.2012543593824345\n",
      "-1.09880130042456\n",
      "-1.246761457798355\n",
      "-1.0905965176901056\n",
      "-1.0681139787170133\n",
      "-1.0641999852860153\n",
      "-1.0372436561887382\n",
      "-0.8823130260913733\n",
      "-0.916267220849616\n",
      "-0.9628379839703167\n",
      "-1.0310045468457558\n",
      "-1.0238630071068064\n",
      "-1.0245502453288178\n",
      "-1.087305149688495\n",
      "-1.1461596042543323\n",
      "-1.1316334336833767\n",
      "-1.0689747402740963\n",
      "-1.067506969336376\n",
      "-1.0603950315967907\n",
      "-1.208555236574637\n",
      "-1.1381758878460906\n",
      "-1.1539017695904683\n",
      "-1.2249185356397656\n",
      "-1.177231748591626\n",
      "-1.082450115301003\n",
      "-1.095457295877433\n",
      "-1.1287745954195147\n",
      "-1.0472501315496119\n",
      "-1.194878945880421\n",
      "-1.154730542473743\n",
      "-1.1192374277294812\n",
      "-1.0553756400824519\n",
      "-1.0891016706837375\n",
      "-1.0853435293473261\n",
      "-0.9634265654529338\n",
      "-1.0180561108500346\n",
      "-1.0311579166408653\n",
      "-1.093963743366898\n",
      "-1.166283746437232\n",
      "-1.1859850377119818\n",
      "-1.1435916503029047\n",
      "-1.095963828198691\n",
      "-1.0406898040172523\n",
      "-1.0887358537199134\n",
      "-1.0632924149441092\n",
      "-1.001673941537657\n",
      "-1.0624858859012738\n",
      "-1.085504884393821\n",
      "-1.024497236948558\n",
      "-1.1152695740090002\n",
      "-1.187038635434793\n",
      "-1.121653723096703\n",
      "-1.0975208114967019\n",
      "-1.035105155037265\n",
      "-1.1292090291842265\n",
      "-1.1190612366550867\n",
      "-1.075405655863889\n",
      "-1.0946292471684258\n",
      "-0.9956116260226351\n",
      "-1.0395092293795212\n",
      "-1.1316372195442626\n",
      "-1.0582806551831547\n",
      "-1.108987835870667\n",
      "-1.0807403569612344\n",
      "-1.076303489289066\n",
      "-1.1388375204380883\n",
      "-1.1658186934358994\n",
      "-1.146787616432856\n",
      "-1.141535863648643\n",
      "-1.1306025546753606\n",
      "-1.1129958138915514\n",
      "-1.0875767818768518\n",
      "-1.1784877778822596\n",
      "-1.1588254794036108\n",
      "-1.1179069062699225\n",
      "-1.1494077589109168\n",
      "-1.1750319075526383\n",
      "-1.1622822811740394\n",
      "-1.1545471590970735\n",
      "-1.1161873009779646\n",
      "-1.272621094215257\n",
      "-1.161650990980093\n",
      "-1.0852891495699386\n",
      "-0.9982393934658033\n",
      "-1.0453835807104397\n",
      "-1.2025989753693138\n",
      "-1.190072062185069\n",
      "-1.0478729647985947\n",
      "-1.1846343143591571\n",
      "-1.1255408508692584\n",
      "-1.1914464538405884\n",
      "-1.057319698136223\n",
      "-1.0140938929176189\n",
      "-0.9813112530956162\n",
      "-0.9686459242680449\n",
      "-1.060099236201975\n",
      "-0.9385884656053443\n",
      "-1.004706028026539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0331057252097087\n",
      "-1.002468139115762\n",
      "-0.9756718734453793\n",
      "-1.0059525221182108\n",
      "-1.0786041162094349\n",
      "-0.9963942730984235\n",
      "-0.8799819972924903\n",
      "-0.9170243376373005\n",
      "-0.9083702691846975\n",
      "-1.053280182573774\n",
      "-0.9738175500999839\n",
      "-1.083675458930602\n",
      "-1.029605590059111\n",
      "-1.0386967925929982\n",
      "-1.1155094073940428\n",
      "-1.0950845088462144\n",
      "-1.1430522464090171\n",
      "-1.1077116818804384\n",
      "-1.1126143757356974\n",
      "-1.0107976599048354\n",
      "-1.0010668543929815\n",
      "-1.1208977179498276\n",
      "-1.191853555034519\n",
      "-1.038545306976691\n",
      "-1.1446929822015486\n",
      "-1.109277747985433\n",
      "-1.050029482825276\n",
      "-1.0945645877409358\n",
      "-1.160886097512327\n",
      "-1.0889564552245719\n",
      "-1.0968871264424132\n",
      "-1.1313134549411414\n",
      "-1.0987005597525217\n",
      "-1.0849989136650326\n",
      "-1.0255371444696433\n",
      "-1.155608421037811\n",
      "-1.0737740894059415\n",
      "-1.0532550160486647\n",
      "-1.0528286008845935\n",
      "-1.0736368828333884\n",
      "-1.084699007049046\n",
      "-1.1593923426555128\n",
      "-1.0856925720141657\n",
      "-1.0645817015816756\n",
      "-1.0581258520274166\n",
      "-1.082784525422043\n",
      "-1.0552549493156818\n",
      "-1.0261039411236468\n",
      "-0.9865152736957576\n",
      "-1.0119814667210874\n",
      "-1.1607506262443628\n",
      "-1.1377303344210534\n",
      "-1.0749763603219011\n",
      "-1.1341857396424033\n",
      "-1.1013556494741679\n",
      "-1.1560713938260967\n",
      "-1.1274044008129016\n",
      "-1.1462698818411639\n",
      "-1.0879135256453873\n",
      "-1.0427706039683666\n",
      "-1.0136701879103225\n",
      "-1.0739226240393756\n",
      "-1.101543191628677\n",
      "-1.1338755769419375\n",
      "-1.1338918880124074\n",
      "-1.0908343617930027\n",
      "-1.0557676744190243\n",
      "-1.0651901436483946\n",
      "-0.9696126654241087\n",
      "-0.9923559035633521\n",
      "-1.0393871284425984\n",
      "-0.9925273505148849\n",
      "-1.0885063400037494\n",
      "-1.0081307712502117\n",
      "-1.1335476868219556\n",
      "-1.1031004942277463\n",
      "-1.055139137506737\n",
      "-0.9993757279676244\n",
      "-1.1378976802629055\n",
      "-0.978566858059891\n",
      "-1.0733010228242308\n",
      "-1.0606630142252083\n",
      "-1.11446369485054\n",
      "-0.9972055895906824\n",
      "-1.043459865363495\n",
      "-1.0223279811644939\n",
      "-0.977242932837987\n",
      "-1.118937150816474\n",
      "-1.0203228903908144\n",
      "-1.0345990784718209\n",
      "-1.0173471265448726\n",
      "-1.1271950206100045\n",
      "-1.120919571525531\n",
      "-1.2295728854186647\n",
      "-1.1785277186443681\n",
      "-1.1025150228768448\n",
      "-1.125805807030849\n",
      "-1.144576172156532\n",
      "-1.0855286403362043\n",
      "-1.0346298018124582\n",
      "-1.1030629185194605\n",
      "-1.0686943501069501\n",
      "-1.0171576845466335\n",
      "-1.0160938000958646\n",
      "-1.0165355351082173\n",
      "-1.0105750692147715\n",
      "-0.9696824049161245\n",
      "-1.032987525365797\n",
      "-1.1017399244884745\n",
      "-1.128056322302054\n",
      "-1.0727626217481394\n",
      "-1.1253185300137187\n",
      "-1.009945085213691\n",
      "-0.9950767426624615\n",
      "-1.0722204261868449\n",
      "-1.063651327319781\n",
      "-1.0988835706620261\n",
      "-1.0620741564674006\n",
      "-1.0734887978488972\n",
      "-1.0989506365226538\n",
      "-1.0068213216091229\n",
      "-1.0403698856225418\n",
      "-1.1249386825516883\n",
      "-1.0610666775910502\n",
      "-1.0506480232883149\n",
      "-1.0237307996432061\n",
      "-1.1741408602708507\n",
      "-1.140621904288206\n",
      "-1.066291655509569\n",
      "-1.1836106965819888\n",
      "-1.2464389894729127\n",
      "-1.140752664648234\n",
      "-1.2570586294485144\n",
      "-1.1403633621657034\n",
      "-1.157066884617522\n",
      "-1.1846159221989314\n",
      "-1.0886585934310486\n",
      "-1.1363832085699657\n",
      "-1.1297520604245956\n",
      "-1.1063223120351924\n",
      "-1.1350166790875476\n",
      "-1.1079361429230612\n",
      "-1.1564265939389995\n",
      "-1.1100332056582713\n",
      "-1.2205374373804454\n",
      "-1.1196100086949632\n",
      "-1.1555642084493827\n",
      "-1.1144279259091734\n",
      "-1.184217909777049\n",
      "-1.1447795192237813\n",
      "-1.070889928335198\n",
      "-1.0845907738263694\n",
      "-1.0355844085048087\n",
      "-1.0568307604868692\n",
      "-1.1483988617559335\n",
      "-1.0481664787282892\n",
      "-1.0636512593939476\n",
      "-1.1930182054331844\n",
      "-1.2147477913713565\n",
      "-1.2547597690474936\n",
      "-1.2835831851771247\n",
      "-1.1360414509591554\n",
      "-1.1658578632721648\n",
      "-1.111602981737967\n",
      "-0.9748825386932694\n",
      "-1.0079952618903796\n",
      "-0.9972919675007773\n",
      "-1.1038666852624124\n",
      "-1.1768038166785646\n",
      "-1.2461453863752925\n",
      "-1.2684453008696481\n",
      "-1.1332259694561393\n",
      "-1.2399792168700723\n",
      "-1.27827935475618\n",
      "-1.078824739633181\n",
      "-1.1229117593216114\n",
      "-1.1790835849869843\n",
      "-1.1940932922047551\n",
      "-1.1634998346601495\n",
      "-1.1324000110568953\n",
      "-1.2233597886802225\n",
      "-1.2063575076452298\n",
      "-1.2308759231979778\n",
      "-1.1489642339383912\n",
      "-1.0559835425661648\n",
      "-1.0830500281697462\n",
      "-1.0955733314962215\n",
      "-1.0633211632598651\n",
      "-1.1622923338817417\n",
      "-1.1161887903952095\n",
      "-1.173850977779768\n",
      "-1.2476768018050988\n",
      "-1.2053818964021135\n",
      "-1.1384895207347123\n",
      "-1.142371350035951\n",
      "-1.1089838931875795\n",
      "-1.077111423983701\n",
      "-1.0418736952677945\n",
      "-0.9592945240460901\n",
      "-1.0208705237660969\n",
      "-1.0591418376910307\n",
      "-1.1254449056854208\n",
      "-1.0747970750661648\n",
      "-1.0775694187226579\n",
      "-1.069032712735773\n",
      "-1.1695102110193936\n",
      "-1.1159581299410173\n",
      "-1.2032713240346526\n",
      "-1.1495496131666159\n",
      "-1.2526973212732835\n",
      "-1.254547112711473\n",
      "-1.3107242703761397\n",
      "-1.2149969105331875\n",
      "-1.3043937658245257\n",
      "-1.2214914239037715\n",
      "-1.341906692650104\n",
      "-1.3697099405216782\n",
      "-1.325377053409429\n",
      "-1.283870004373153\n",
      "-1.2755957471986688\n",
      "-1.2450213594825712\n",
      "-1.1507375991387756\n",
      "-1.1665351028251376\n",
      "-1.1571994061299884\n",
      "-1.1679517458055397\n",
      "-1.1524141310226585\n",
      "-1.1803349903153535\n",
      "-1.263877580155034\n",
      "-1.1921299791696964\n",
      "-1.2416622387917065\n",
      "-1.2488360497443716\n",
      "-1.2841670581497773\n",
      "-1.226381969686953\n",
      "-1.2462571649243952\n",
      "-1.2507840317701302\n",
      "-1.1439893202958498\n",
      "-1.18314101177871\n",
      "-1.2032395659153665\n",
      "-1.1300333881253617\n",
      "-1.1790448958962434\n",
      "-1.2081663942945144\n",
      "-1.1590408850902931\n",
      "-1.1378550536890348\n",
      "-0.9899851086778376\n",
      "-1.0732000924636782\n",
      "-1.0120463872659666\n",
      "-1.038131349452098\n",
      "-1.1238050472604577\n",
      "-1.1361180713882024\n",
      "-1.14490957237194\n",
      "-1.197265107687895\n",
      "-1.182986272940475\n",
      "-1.1673572069048948\n",
      "-1.2553369113774189\n",
      "-1.206204718691668\n",
      "-1.195502909777806\n",
      "-1.2029292049843745\n",
      "-1.2570210792840428\n",
      "-1.2074253379784203\n",
      "-1.2503290824485025\n",
      "-1.30096806826506\n",
      "-1.3216987534229785\n",
      "-1.200741358848752\n",
      "-1.124708785642194\n",
      "-1.1570098660467474\n",
      "-1.2152280698940217\n",
      "-1.231540714459979\n",
      "-1.1847757249721949\n",
      "-1.224774602558002\n",
      "-1.242937016419434\n",
      "-1.2102402326871242\n",
      "-1.1548606281115008\n",
      "-1.21254468289776\n",
      "-1.215840299935378\n",
      "-1.2690921086908729\n",
      "-1.1926772883396073\n",
      "-1.1532373788619887\n",
      "-1.206002930633125\n",
      "-1.2420395316390536\n",
      "-1.2413495160110517\n",
      "-1.3079915271590545\n",
      "-1.2530109128997349\n",
      "-1.3191077688588582\n",
      "-1.2297018656016643\n",
      "-1.3241331486807955\n",
      "-1.3928150640278272\n",
      "-1.3135958029447918\n",
      "-1.2812035974602465\n",
      "-1.2011136432456457\n",
      "-1.2000882792359828\n",
      "-1.261892751014457\n",
      "-1.2367824039750326\n",
      "-1.3704489668827953\n",
      "-1.3427240272378744\n",
      "-1.290852180953174\n",
      "-1.3342521979648845\n",
      "-1.2677377607495082\n",
      "-1.2580971043085285\n",
      "-1.2550381840321228\n",
      "-1.2418832547503071\n",
      "-1.3317224268121504\n",
      "-1.2450820091968064\n",
      "-1.3256074089348504\n",
      "-1.46928894548205\n",
      "-1.3629447898341018\n",
      "-1.326159011336667\n",
      "-1.4369120761593548\n",
      "-1.4166242403707934\n",
      "-1.3622522020026269\n",
      "-1.3175672964549632\n",
      "-1.350952970061796\n",
      "-1.4377199206358189\n",
      "-1.3222535903501274\n",
      "-1.317614775482913\n",
      "-1.314247772758523\n",
      "-1.2749734672917625\n",
      "-1.336991626661933\n",
      "-1.4026405786111291\n",
      "-1.286458590585479\n",
      "-1.3124541770666787\n",
      "-1.4484993215323911\n",
      "-1.3308459470946508\n",
      "-1.3120387080250882\n",
      "-1.2520760864063543\n",
      "-1.2633457574499982\n",
      "-1.2584223179368328\n",
      "-1.2881893128587718\n",
      "-1.3309530410312018\n",
      "-1.3288078001952932\n",
      "-1.2576749140217651\n",
      "-1.2416916880493654\n",
      "-1.1602874371517877\n",
      "-1.183646983844815\n",
      "-1.2574303332849475\n",
      "-1.1599772817704948\n",
      "-1.243929737752979\n",
      "-1.2665431982240556\n",
      "-1.2644153335446493\n",
      "-1.268944915981472\n",
      "-1.310367946182659\n",
      "-1.3218729127790176\n",
      "-1.2736868265506722\n",
      "-1.288218482334261\n",
      "-1.3530794639879553\n",
      "-1.254733548938547\n",
      "-1.237563839975367\n",
      "-1.2322689022961109\n",
      "-1.2836950339634425\n",
      "-1.3268652025638747\n",
      "-1.3931672685309004\n",
      "-1.4047161728917563\n",
      "-1.2933003150400841\n",
      "-1.301172073551855\n",
      "-1.2609264393764679\n",
      "-1.2651037050346794\n",
      "-1.282427541794296\n",
      "-1.2580462110176696\n",
      "-1.3206895665398466\n",
      "-1.3035805076319193\n",
      "-1.2978797121708399\n",
      "-1.2636471266362375\n",
      "-1.29732597808848\n",
      "-1.2651868843925307\n",
      "-1.2862709841748723\n",
      "-1.3389535250275377\n",
      "-1.4361648008336485\n",
      "-1.4683629376946474\n",
      "-1.3590862869067144\n",
      "-1.3813767370783314\n",
      "-1.294828502926582\n",
      "-1.3517447535270457\n",
      "-1.2795214683486529\n",
      "-1.250982510791668\n",
      "-1.3115879091087415\n",
      "-1.2631144004815507\n",
      "-1.3495907434167882\n",
      "-1.2778628202006033\n",
      "-1.2449984905489109\n",
      "-1.3044806646231744\n",
      "-1.3341649151955148\n",
      "-1.277602321576496\n",
      "-1.2200977493891467\n",
      "-1.2907360287483596\n",
      "-1.2934084137406086\n",
      "-1.1981214699472604\n",
      "-1.193356340649877\n",
      "-1.2338215870267668\n",
      "-1.2074727774643972\n",
      "-1.2453997741748768\n",
      "-1.1671007931686506\n",
      "-1.2054698344696362\n",
      "-1.2735179896851252\n",
      "-1.2110514984377652\n",
      "-1.2670784399752177\n",
      "-1.426386673617461\n",
      "-1.4047933814338163\n",
      "-1.3875718844150404\n",
      "-1.3999836510424777\n",
      "-1.2878497642120825\n",
      "-1.4356971863610308\n",
      "-1.2828201176441747\n",
      "-1.3212190281314862\n",
      "-1.219050878312081\n",
      "-1.2489668097618145\n",
      "-1.3113634364501254\n",
      "-1.3008681183120514\n",
      "-1.318783167531594\n",
      "-1.2971368831840198\n",
      "-1.4256122945500806\n",
      "-1.3053698115767953\n",
      "-1.3094585972593042\n",
      "-1.3431391694050725\n",
      "-1.2872036267063434\n",
      "-1.2641438028143006\n",
      "-1.2831185683062587\n",
      "-1.2414392824444889\n",
      "-1.3405034126318662\n",
      "-1.3188381314167992\n",
      "-1.203762426798838\n",
      "-1.1898108234685132\n",
      "-1.3061885073129484\n",
      "-1.2374658709292092\n",
      "-1.318334397868797\n",
      "-1.23907192967197\n",
      "-1.2188745551985696\n",
      "-1.3422260122787604\n",
      "-1.2380679801071535\n",
      "-1.244777866084653\n",
      "-1.2960534650373359\n",
      "-1.2819508013447842\n",
      "-1.3590816933636298\n",
      "-1.2954685586071286\n",
      "-1.2444110039895695\n",
      "-1.1645151351423637\n",
      "-1.3368833634990358\n",
      "-1.3430248012836905\n",
      "-1.2912550886084835\n",
      "-1.2338836133111581\n",
      "-1.280453128377537\n",
      "-1.3118983624394323\n",
      "-1.2976795593829156\n",
      "-1.3721689741041436\n",
      "-1.382130820597869\n",
      "-1.3231612403100705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3416818047064687\n",
      "-1.2143778001542562\n",
      "-1.2154932162658698\n",
      "-1.2606414258441143\n",
      "-1.2411332674971771\n",
      "-1.2981461544992634\n",
      "-1.2359771708669691\n",
      "-1.2079353592539688\n",
      "-1.2637913868713855\n",
      "-1.2958055836983966\n",
      "-1.3571650531162938\n",
      "-1.4436294055209937\n",
      "-1.4882964720507836\n",
      "-1.390249379082979\n",
      "-1.3680672509769016\n",
      "-1.3761796996687345\n",
      "-1.2631674621099616\n",
      "-1.2654032964172641\n",
      "-1.2563075173690648\n",
      "-1.1920574917360793\n",
      "-1.2190236924370739\n",
      "-1.2886406544210856\n",
      "-1.1849920309772735\n",
      "-1.2503900726926729\n",
      "-1.243896188167387\n",
      "-1.202208817758216\n",
      "-1.2902692983394248\n",
      "-1.222327217312482\n",
      "-1.2653161449597332\n",
      "-1.2681697939865586\n",
      "-1.2740130613928142\n",
      "-1.31223261058926\n",
      "-1.273396328826766\n",
      "-1.315422089142782\n",
      "-1.3456717003010918\n",
      "-1.251003801361453\n",
      "-1.2639404157689498\n",
      "-1.2503744763355134\n",
      "-1.3192353063107183\n",
      "-1.2351059541956135\n",
      "-1.1920192683558148\n",
      "-1.16878972857151\n",
      "-1.3633870874617215\n",
      "-1.2625747793400344\n",
      "-1.1691087530903213\n",
      "-1.2065714584165739\n",
      "-1.1344406604175443\n",
      "-1.2237228696516111\n",
      "-1.3246667714726998\n",
      "-1.3026872854918905\n",
      "-1.2901423348697065\n",
      "-1.210941892366934\n",
      "-1.2777088320267431\n",
      "-1.2460249269446142\n",
      "-1.2659347978672488\n",
      "-1.3667738135967584\n",
      "-1.2750098596646535\n",
      "-1.369041039028774\n",
      "-1.3052406223713804\n",
      "-1.3791003872255165\n",
      "-1.3892186596336182\n",
      "-1.3165446255842914\n",
      "-1.313306976052167\n",
      "-1.251404863834366\n",
      "-1.4213983869484752\n",
      "-1.3980998446268749\n",
      "-1.356824144582861\n",
      "-1.2544025367984921\n",
      "-1.3330711725278663\n",
      "-1.2795728552937222\n",
      "-1.3272153685748909\n",
      "-1.3090511218398162\n",
      "-1.3173942046375333\n",
      "-1.3526003446812067\n",
      "-1.376116248764584\n",
      "-1.3375405947883927\n",
      "-1.3381651812637656\n",
      "-1.291890703949684\n",
      "-1.3251953741914877\n",
      "-1.3584755566547386\n",
      "-1.3033601079244936\n",
      "-1.3419784813491062\n",
      "-1.3999810417383456\n",
      "-1.3182192672921287\n",
      "-1.4112799174778177\n",
      "-1.30346009005341\n",
      "-1.215704514281518\n",
      "-1.221217798467938\n",
      "-1.2056634866867602\n",
      "-1.2040234456663144\n",
      "-1.1644456216640324\n",
      "-1.1933280344560884\n",
      "-1.2336646013731913\n",
      "-1.3243707402703269\n",
      "-1.256489501031499\n",
      "-1.2478474379038613\n",
      "-1.251125538579365\n",
      "-1.2670917914104836\n",
      "-1.2357007116932253\n",
      "-1.2376651531230185\n",
      "-1.3194488354323923\n",
      "-1.240441683075546\n",
      "-1.2004223492818336\n",
      "-1.2613139545316565\n",
      "-1.1844242271323686\n",
      "-1.2042030373217203\n",
      "-1.1824053990612369\n",
      "-1.245191602091854\n",
      "-1.2340481187414374\n",
      "-1.1634832321459785\n",
      "-1.2287963135662134\n",
      "-1.3161433362459372\n",
      "-1.2575300988911775\n",
      "-1.2403224461854971\n",
      "-1.2254458146022102\n",
      "-1.1775114943021414\n",
      "-1.2066627783869988\n",
      "-1.2536331331246995\n",
      "-1.2498541858780106\n",
      "-1.2330473109680415\n",
      "-1.1759206799449002\n",
      "-1.2447301978203844\n",
      "-1.1659010432528487\n",
      "-1.263947177362312\n",
      "-1.2266443444379445\n",
      "-1.237094461494031\n",
      "-1.2485157506893985\n",
      "-1.170574711041588\n",
      "-1.2088675475429087\n",
      "-1.19872101257488\n",
      "-1.2839181811754834\n",
      "-1.248399421746505\n",
      "-1.243452128050163\n",
      "-1.2946386833496542\n",
      "-1.3285549729468802\n",
      "-1.1549558343423643\n",
      "-1.1784405176045931\n",
      "-1.1223620943103871\n",
      "-1.1601616689965533\n",
      "-1.1329141373330829\n",
      "-1.125615892707036\n",
      "-1.0739183134634611\n",
      "-1.1294769260693258\n",
      "-1.0816630516466639\n",
      "-1.1663899627733376\n",
      "-1.2308965109938768\n",
      "-1.2159524714093983\n",
      "-1.2162236034262552\n",
      "-1.2478246064545266\n",
      "-1.2672154218352607\n",
      "-1.201963652326515\n",
      "-1.1830982563582642\n",
      "-1.1859682136692682\n",
      "-1.1774881081066042\n",
      "-1.1234190188652393\n",
      "-1.2281752247626831\n",
      "-1.3033555829452477\n",
      "-1.1231085379817813\n",
      "-1.2636761671401822\n",
      "-1.2026133357779671\n",
      "-1.1692700510526703\n",
      "-1.1567728880988264\n",
      "-1.1439683219940768\n",
      "-1.1054844378223945\n",
      "-1.0973488624908534\n",
      "-1.0954156925694392\n",
      "-1.1458464214615514\n",
      "-1.0038426212840732\n",
      "-1.017719378983759\n",
      "-1.1281277660545288\n",
      "-1.1018214139150855\n",
      "-1.0245106513935809\n",
      "-1.0594651076584305\n",
      "-0.9919648289750586\n",
      "-1.1330888452108152\n",
      "-1.2722538285436673\n",
      "-1.2213464885119303\n",
      "-1.25508573585462\n",
      "-1.21935347922722\n",
      "-1.1913859632300436\n",
      "-1.1080041691354328\n",
      "-1.1200012142939257\n",
      "-1.0477674521779858\n",
      "-1.1152534887031214\n",
      "-1.120193971453835\n",
      "-1.0781589923540447\n",
      "-1.0965468627515138\n",
      "-1.0804922532267658\n",
      "-1.0745915183470762\n",
      "-1.046291685836666\n",
      "-0.9903310985282411\n",
      "-0.990849026039919\n",
      "-1.0159932411904693\n",
      "-0.976430515259974\n",
      "-0.9980817010420362\n",
      "-0.9839898726270803\n",
      "-1.1145138670118535\n",
      "-1.0091031276544873\n",
      "-1.0578860615455432\n",
      "-1.044863219788164\n",
      "-1.0584822629708466\n",
      "-1.2118447017193028\n",
      "-1.2268345971514283\n",
      "-1.093662076931022\n",
      "-1.0463324638220544\n",
      "-1.0580743709662168\n",
      "-1.104478434917107\n",
      "-1.030153461592683\n",
      "-1.1744066963808197\n",
      "-1.0828541445483086\n",
      "-0.9577275711902976\n",
      "-0.9834922238572934\n",
      "-0.919609482330229\n",
      "-1.0676902550908196\n",
      "-0.9826446917397094\n",
      "-0.9915856692722446\n",
      "-0.9737820252506428\n",
      "-0.9496376578034181\n",
      "-0.9097747968440002\n",
      "-0.8998441010459958\n",
      "-0.9036067028354804\n",
      "-0.9133490723340555\n",
      "-0.8859649494127917\n",
      "-1.0102740263819314\n",
      "-0.9626762692788886\n",
      "-1.0293205934039655\n",
      "-1.0621755789694258\n",
      "-0.9833686506360105\n",
      "-0.9217845509161585\n",
      "-0.9412539465852615\n",
      "-0.9930171121101362\n",
      "-0.9433312350463046\n",
      "-1.088503884110132\n",
      "-0.9391034570038953\n",
      "-0.9618424289943626\n",
      "-0.9418571381824122\n",
      "-0.9506740651346037\n",
      "-0.9492781612349339\n",
      "-1.0077204796333294\n",
      "-0.9843592518653547\n",
      "-1.0874077806166509\n",
      "-1.057074278747181\n",
      "-1.1140887365672543\n",
      "-1.0201237755353652\n",
      "-1.0762980673268394\n",
      "-1.1222111567529442\n",
      "-1.073399705204253\n",
      "-1.0059061878754645\n",
      "-1.06583208093131\n",
      "-1.1336374323809948\n",
      "-1.1097038366793952\n",
      "-1.056908058889627\n",
      "-1.0524673691430668\n",
      "-1.0857095969122355\n",
      "-1.0291935835808892\n",
      "-1.0242028251704574\n",
      "-0.9066657990318733\n",
      "-0.9013090223014573\n",
      "-0.8655208445226208\n",
      "-0.9213346201644476\n",
      "-0.9458490296272266\n",
      "-0.9571072922796184\n",
      "-0.9935960850475283\n",
      "-0.9488998780367596\n",
      "-0.9825532462682232\n",
      "-0.9260278378308975\n",
      "-1.0090303768931879\n",
      "-0.968111304000549\n",
      "-1.005797374273395\n",
      "-1.0253691803251213\n",
      "-0.9290211535036015\n",
      "-0.987563212360089\n",
      "-1.0214273501974436\n",
      "-1.0004269427808536\n",
      "-0.8929391707776577\n",
      "-0.9466594454248624\n",
      "-0.9604991775648162\n",
      "-0.9803860474991999\n",
      "-0.929483239418471\n",
      "-0.9390826158125356\n",
      "-1.0465310511509314\n",
      "-0.9556774896528024\n",
      "-0.9314736421873716\n",
      "-0.9919965301789065\n",
      "-0.973297831200982\n",
      "-0.9496777054954788\n",
      "-0.8951411060797405\n",
      "-0.894406095821617\n",
      "-0.9303829179298578\n",
      "-0.9427148550351419\n",
      "-0.8947244820072416\n",
      "-0.9940174552256759\n",
      "-0.9413270341255388\n",
      "-0.9212861685625723\n",
      "-0.9438032776835811\n",
      "-0.9195920682175495\n",
      "-0.9112048526719135\n",
      "-0.9048008461730589\n",
      "-0.9460542952886676\n",
      "-0.9268514585895588\n",
      "-0.9051006608992757\n",
      "-0.8902337649402428\n",
      "-0.9002038484977055\n",
      "-0.8329234214081727\n",
      "-0.857266487434608\n",
      "-0.9558868218444235\n",
      "-1.0499657796397135\n",
      "-0.9451808284804147\n",
      "-0.9503332015677777\n",
      "-1.0169270975919629\n",
      "-1.1403185033329863\n",
      "-1.0401097103855725\n",
      "-1.096595397204523\n",
      "-1.058975371064242\n",
      "-1.1708915950628906\n",
      "-1.1799317657751573\n",
      "-1.0996117767364004\n",
      "-1.1565822128731889\n",
      "-1.0367595649609822\n",
      "-1.1114147228657498\n",
      "-1.0146008387374317\n",
      "-1.0580223940763467\n",
      "-1.0506863565345588\n",
      "-0.9964738654406928\n",
      "-0.9910700802517974\n",
      "-0.9483404197697992\n",
      "-0.9818587391274788\n",
      "-1.060642720535083\n",
      "-1.0740186588206093\n",
      "-1.1168971008247748\n",
      "-1.050907617200826\n",
      "-1.033194638173415\n",
      "-0.9971439270809666\n",
      "-1.0144172978557933\n",
      "-0.9675895686451961\n",
      "-0.912079233900499\n",
      "-0.9533897485925164\n",
      "-1.0221982486591876\n",
      "-0.9640485154533402\n",
      "-1.091071164776619\n",
      "-1.0096559348587766\n",
      "-1.060774631961165\n",
      "-0.9552485853123092\n",
      "-0.9930277506104324\n",
      "-1.0030955435434603\n",
      "-0.9883639390341044\n",
      "-0.9766858539137164\n",
      "-1.0200893981799932\n",
      "-1.1157956257155217\n",
      "-1.115522890963539\n",
      "-1.0873629967081544\n",
      "-1.1133121919678803\n",
      "-1.1215377880400161\n",
      "-1.1110970351432783\n",
      "-1.0433876427051925\n",
      "-1.024629834436971\n",
      "-1.1208364124877115\n",
      "-1.0846287095972562\n",
      "-1.0996457489418314\n",
      "-1.0607018363217726\n",
      "-1.1236010017812779\n",
      "-1.094947422594211\n",
      "-1.1022546230357573\n",
      "-1.1130175202761585\n",
      "-1.1802183360764764\n",
      "-1.1835364397397017\n",
      "-1.0527152426036985\n",
      "-1.1250470823817778\n",
      "-1.177328535695804\n",
      "-1.1077246968222807\n",
      "-1.1836612010846805\n",
      "-1.116052594768816\n",
      "-1.1164509549696655\n",
      "-1.1003101242070012\n",
      "-1.0874370728285412\n",
      "-1.0342647422896427\n",
      "-0.929697896926626\n",
      "-1.0351686568470049\n",
      "-1.0260144368657884\n",
      "-1.1258354950643088\n",
      "-1.0631343437944591\n",
      "-1.0341231906469717\n",
      "-1.092411041106115\n",
      "-1.119383468972082\n",
      "-1.1920275142944998\n",
      "-1.1087367305877251\n",
      "-1.1892215155823795\n",
      "-1.2252480240196413\n",
      "-1.2111084910705805\n",
      "-1.1599866660199276\n",
      "-1.072164704881919\n",
      "-1.152184905890263\n",
      "-1.1487381016705605\n",
      "-1.1116475435447408\n",
      "-1.1289889657503234\n",
      "-1.2006211806495846\n",
      "-1.0943206213926544\n",
      "-1.067469746587522\n",
      "-1.0580118694622573\n",
      "-1.1371776420779582\n",
      "-1.1123382125371801\n",
      "-1.0625182791408334\n",
      "-1.0015332232645062\n",
      "-1.0656376587796177\n",
      "-1.1058926279673538\n",
      "-1.0992367803833394\n",
      "-1.1146314714621486\n",
      "-1.1586124261377275\n",
      "-1.1560493594791874\n",
      "-1.2483746117484267\n",
      "-1.1770697353001607\n",
      "-1.1636232014847399\n",
      "-1.107740957710445\n",
      "-1.2360052970943052\n",
      "-1.2727554786899735\n",
      "-1.287994120074139\n",
      "-1.178863635603004\n",
      "-1.14515213070065\n",
      "-1.2112887313327163\n",
      "-1.16500891357422\n",
      "-1.175703104875704\n",
      "-1.118615340999179\n",
      "-1.1690194803345904\n",
      "-1.114290797808669\n",
      "-1.144152863575611\n",
      "-1.102490147920184\n",
      "-1.118301252856327\n",
      "-1.1684672568935777\n",
      "-1.2372052389813848\n",
      "-1.12519798684826\n",
      "-1.2138165037218305\n",
      "-1.2489576936559479\n",
      "-1.2533120386128462\n",
      "-1.297312722754699\n",
      "-1.2146484253159506\n",
      "-1.1806486986770275\n",
      "-1.259487166341866\n",
      "-1.2506736131808325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.2860492236934546\n",
      "-1.253431987252137\n",
      "-1.221624244462054\n",
      "-1.2192449503350424\n",
      "-1.1385270037099144\n",
      "-1.174732791970174\n",
      "-1.2451118257917912\n",
      "-1.1350368098244632\n",
      "-1.076796559219443\n",
      "-1.0900264925727678\n",
      "-1.2029621952678964\n",
      "-1.071070685584929\n",
      "-1.0886323385836825\n",
      "-1.173110336177602\n",
      "-1.2296430441444632\n",
      "-1.1589681091023472\n",
      "-1.0965656658629948\n",
      "-1.1239822601004819\n",
      "-1.0909962233354653\n",
      "-1.0507348138374908\n",
      "-1.127214610661443\n",
      "-1.1638678851234356\n",
      "-1.246640787777656\n",
      "-1.2061300991953972\n",
      "-1.2250087632323268\n",
      "-1.2206926434515941\n",
      "-1.1072022786668947\n",
      "-1.0803549523363842\n",
      "-1.058541973348434\n",
      "-1.0972901241046176\n",
      "-1.1712149510137502\n",
      "-1.164159336343869\n",
      "-1.0306189326088404\n",
      "-1.0529202375848676\n",
      "-1.0527548220380152\n",
      "-1.114617041185284\n",
      "-1.1730662915935977\n",
      "-1.131889237012436\n",
      "-1.1969334304668573\n",
      "-1.1379775328787018\n",
      "-1.2028697373904698\n",
      "-1.146062132351635\n",
      "-1.1717767255154785\n",
      "-1.1284957949711971\n",
      "-1.2227536812503705\n",
      "-1.1582174504104457\n",
      "-1.2114689639314946\n",
      "-1.2230046222097946\n",
      "-1.2264208807005164\n",
      "-1.2148107796539132\n",
      "-1.221718628071412\n",
      "-1.1341423080716606\n",
      "-1.1721201277912638\n",
      "-1.2475399730932815\n",
      "-1.2123407691772004\n",
      "-1.1875598002540273\n",
      "-1.1912902187686416\n",
      "-1.2684290356842989\n",
      "-1.3079994160611386\n",
      "-1.2589082800186326\n",
      "-1.172789045286813\n",
      "-1.17783822186067\n",
      "-1.2279904122782919\n",
      "-1.1901573700460746\n",
      "-1.0970422322700195\n",
      "-1.2212871181731317\n",
      "-1.1878091878518862\n",
      "-1.1423725769239206\n",
      "-1.1469088846464277\n",
      "-1.1880839439086934\n",
      "-1.0781920684730066\n",
      "-1.0993678900556973\n",
      "-1.1932497908101738\n",
      "-1.0521328149962985\n",
      "-1.1331955661566293\n",
      "-1.2287927111681134\n",
      "-1.2343150443333517\n",
      "-1.2590391474538138\n",
      "-1.1917414285987828\n",
      "-1.3028554240490773\n",
      "-1.2016343997775327\n",
      "-1.1692798262728874\n",
      "-1.1503663532285717\n",
      "-1.2121410882110273\n",
      "-1.2076355788628748\n",
      "-1.2211640000436375\n",
      "-1.2026613721801611\n",
      "-1.1487067463927543\n",
      "-1.2362453804859768\n",
      "-1.2144027950217233\n",
      "-1.1123283416841163\n",
      "-1.1950074088019926\n",
      "-1.10982629264387\n",
      "-0.9966546933129451\n",
      "-1.1671729701056732\n",
      "-1.1220708667466395\n",
      "-1.0699620954882185\n",
      "-1.1036497640377427\n",
      "-1.117596720333824\n",
      "-1.1718928751469795\n",
      "-1.1909109503994113\n",
      "-1.250014642209995\n",
      "-1.2890464055980295\n",
      "-1.172692049923472\n",
      "-1.229597693783344\n",
      "-1.1493816014966771\n",
      "-1.1173682795214945\n",
      "-1.008753610668179\n",
      "-1.071956866273034\n",
      "-1.0222119117013373\n",
      "-1.2133622251558407\n",
      "-1.1953778046255696\n",
      "-1.1762038500258207\n",
      "-1.0851341342023375\n",
      "-1.1538943034979847\n",
      "-1.1212109056239223\n",
      "-1.1997848044284096\n",
      "-1.1966699621001178\n",
      "-1.1618110170372564\n",
      "-1.228592534452516\n",
      "-1.271459027330501\n",
      "-1.337455580500673\n",
      "-1.1441680730788382\n",
      "-1.2887906061856045\n",
      "-1.249015619829899\n",
      "-1.1086969064041192\n",
      "-1.1535305012419201\n",
      "-1.2390557566064326\n",
      "-1.150947901933175\n",
      "-1.0753802172873805\n",
      "-1.1108082849812055\n",
      "-1.100940537275595\n",
      "-1.1846273040834674\n",
      "-1.2005302480699638\n",
      "-1.0586135996609098\n",
      "-1.1294491207529478\n",
      "-1.207032552659871\n",
      "-1.1088723828271603\n",
      "-1.1267498409048926\n",
      "-1.0307636384887502\n",
      "-1.0952964348615428\n",
      "-1.0461201626189258\n",
      "-1.1555487887002178\n",
      "-1.2139942422401258\n",
      "-1.2236918638000776\n",
      "-1.2408944890678701\n",
      "-1.2129728725505773\n",
      "-1.2659769071027094\n",
      "-1.202988924449282\n",
      "-1.1900430819239716\n",
      "-1.1934098504194346\n",
      "-1.1222278895210274\n",
      "-1.218733787833628\n",
      "-1.2449604777986147\n",
      "-1.1789336460111453\n",
      "-1.1530692692205555\n",
      "-1.2026895915245965\n",
      "-1.18510891460473\n",
      "-1.099104786030918\n",
      "-1.0948666172599058\n",
      "-1.1028509469211616\n",
      "-1.1702589806998775\n",
      "-1.1892878699028293\n",
      "-1.183792143954967\n",
      "-1.1918943069181955\n",
      "-1.1240087342843308\n",
      "-1.1284546755173583\n",
      "-1.10504776913803\n",
      "-1.1523273572572703\n",
      "-1.1227587283921139\n",
      "-1.0737883266291999\n",
      "-1.2263930330743014\n",
      "-1.1518203180484137\n",
      "-1.1654957910275305\n",
      "-1.2294548755702006\n",
      "-1.2788380827465198\n",
      "-1.2255184730628739\n",
      "-1.1152396531728364\n",
      "-1.3132686551319017\n",
      "-1.2146314671052014\n",
      "-1.1756336499637796\n",
      "-1.0680267416136189\n",
      "-1.1581993334476635\n",
      "-1.0661964736497418\n",
      "-1.1598045234264622\n",
      "-1.1593365058230816\n",
      "-1.180635941535479\n",
      "-1.1092567065572516\n",
      "-1.1812613424400826\n",
      "-1.0969816167938313\n",
      "-1.0423305135095\n",
      "-1.0703273263733224\n",
      "-0.9859518106537948\n",
      "-1.0871714600586158\n",
      "-1.0714406782327823\n",
      "-1.0522549979437776\n",
      "-1.1449944854712282\n",
      "-1.15076831676583\n",
      "-1.2020294251571562\n",
      "-1.118980822802602\n",
      "-1.0689712060908203\n",
      "-1.0579436196964511\n",
      "-1.0150246133774534\n",
      "-0.9559618051836836\n",
      "-1.0364664701544668\n",
      "-1.002648600574865\n",
      "-0.9893815514237009\n",
      "-0.9397758554583094\n",
      "-0.924139070430071\n",
      "-0.9077152470114702\n",
      "-0.8612262635456475\n",
      "-0.9602869781299478\n",
      "-0.9878674507109615\n",
      "-1.118214099704152\n",
      "-1.1426938759718364\n",
      "-1.1128397351150645\n",
      "-1.0963601289076876\n",
      "-1.124994643263819\n",
      "-0.9895490197137726\n",
      "-1.0117346060099162\n",
      "-1.163686776942957\n",
      "-1.089604579938525\n",
      "-1.0096167522006914\n",
      "-1.0684768450635118\n",
      "-1.169468787343195\n",
      "-1.2028669000035848\n",
      "-1.104028183417954\n",
      "-1.0911199902355935\n",
      "-1.1422033304761328\n",
      "-1.1396991594501624\n",
      "-1.1473038170502767\n",
      "-1.0920256739707086\n",
      "-1.1003999024771365\n",
      "-1.2330282674858215\n"
     ]
    }
   ],
   "source": [
    "env = Ascento()\n",
    "env.reset_model()\n",
    "m1 = []\n",
    "m2 = []\n",
    "m3 = []\n",
    "\n",
    "m4 = []\n",
    "\n",
    "for i_episode in range(1):\n",
    "    observation = env.reset()\n",
    "    done = None\n",
    "    while not done:\n",
    "        env.render()\n",
    "        print(env.vx)\n",
    "        action, _ = model.predict(env._get_obs())\n",
    "        m1.append(action[0])\n",
    "        m2.append(action[1])\n",
    "        m3.append(action[2])\n",
    "        m4.append(action[3])\n",
    "#         action[2] = 1\n",
    "#         action[3] = 1\n",
    "\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(env.roll_list)\n",
    "plt.plot(m2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.figure(figsize = (20, 8))\n",
    "plt.plot(env.roll_pitch, label=\"Roll\")\n",
    "plt.plot(env.pitch_pitch , label=\"Pitch\")\n",
    "plt.title(\"RL on Flat Terrain with External Disturbance\")\n",
    "plt.xlabel(\"Time in mili-seconds\")\n",
    "plt.ylabel(\"Degrees\")\n",
    "# plt.xlim(0, 5000)\n",
    "plt.ylim(-15, 15)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.roll_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 20})\n",
    "plt.subplot_tool()\n",
    "plt.tight_layout()\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(env.roll_list, label=\"Roll\")\n",
    "plt.plot(env.pitch_list, label=\"Pitch\")\n",
    "# plt.ylim(-90, 90)\n",
    "plt.title(\"Orientation\")\n",
    "plt.xlabel(\"Time in mili-seconds\")\n",
    "plt.ylabel(\"Degrees\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(env.z_list, label=\"Z Position\")\n",
    "plt.title(\"Position\")\n",
    "plt.xlabel(\"Time in mili-seconds\")\n",
    "plt.ylabel(\"Meter\")\n",
    "plt.legend()\n",
    "\n",
    "plt.suptitle(\"PID on Bump Terrain with External Distrubance\")\n",
    "# plt.suptitle(\"PID on Bump Terrain Terrain with No External Distrubance\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
