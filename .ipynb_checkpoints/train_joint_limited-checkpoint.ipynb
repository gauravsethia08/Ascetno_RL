{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install squaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "from ascento_gym import Ascento\n",
    "# from balance_pend import InvertedPendulumEnv as Ascento\n",
    "from stable_baselines3 import PPO, DDPG, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# env = Ascento()\n",
    "# env.reset_model()\n",
    "# for i_episode in range(150):\n",
    "#     observation = env.reset()\n",
    "#     done = None\n",
    "#     while not done:\n",
    "#         env.render()\n",
    "# #         print(env.yaw)\n",
    "#         action = env.action_space.sample()\n",
    "# #         action[2] = 1\n",
    "# #         action[3] = 1\n",
    "\n",
    "#         observation, reward, done, info = env.step(action)\n",
    "        \n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "env = Ascento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.75064980e-03,  1.44676281e-03,  3.78354074e-03, -5.49464006e-03,\n",
       "       -1.41421932e-02, -7.42634898e-03, -1.02097739e-03,  8.70990202e-03,\n",
       "       -9.37718847e-03,  5.84081191e-03,  3.81917354e-05, -7.01642260e-03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1. -1. -1. -1.], [1. 1. 1. 1.], (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24209215, -0.2307276 , -0.6285826 , -0.87697107], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.54013509, -0.7895249 , -0.36891275,  1.58581063,  1.06329953,\n",
       "       -0.4099463 ,  1.28639543,  0.97594256,  1.19143961, -0.73386956,\n",
       "       -0.15245442,  0.68555726])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = make_vec_env(Ascento, n_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Ascento()\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'models_ascento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold = 20*1e5, verbose = 1)\n",
    "\n",
    "eval_callback = EvalCallback(env, callback_on_new_best = stop_callback,\n",
    "                            eval_freq = 5000, best_model_save_path = save_path, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "logs_dir = os.path.join('Training', 'logs_dir_ascento')\n",
    "model = PPO('MlpPolicy', vec_env, verbose = 1, tensorboard_log = logs_dir, create_eval_env = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load('/home/bmsit/Ascento/jointed_limited/Training/models_ascento/best_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = PPO.load(\"/home/bmsit/Ascento/jointed_limited/Training/models_ascento/ppo_jl_ramp_top_v3.zip\", env = vec_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/logs_dir_ascento/PPO_64\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 87.3      |\n",
      "|    ep_rew_mean     | -7.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 1628      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 1         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 90.5          |\n",
      "|    ep_rew_mean          | -7.7e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1203          |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 3             |\n",
      "|    total_timesteps      | 4096          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070979283 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.68         |\n",
      "|    explained_variance   | -2.16e-05     |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.76e+08      |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | -0.00136      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.87e+08      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5000, episode_reward=-7400.58 +/- 18054.14\n",
      "Episode length: 86.80 +/- 2.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 86.8         |\n",
      "|    mean_reward          | -7.4e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010711405 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0.000445     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+08     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.94e+08     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 93        |\n",
      "|    ep_rew_mean     | -8.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 1088      |\n",
      "|    iterations      | 3         |\n",
      "|    time_elapsed    | 5         |\n",
      "|    total_timesteps | 6144      |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 96.9          |\n",
      "|    ep_rew_mean          | -7.97e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 1063          |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 7             |\n",
      "|    total_timesteps      | 8192          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00060076854 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.68         |\n",
      "|    explained_variance   | 0.000531      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.12e+08      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -0.00145      |\n",
      "|    std                  | 1             |\n",
      "|    value_loss           | 2.9e+08       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=-28907.51 +/- 15932.93\n",
      "Episode length: 94.40 +/- 6.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 94.4         |\n",
      "|    mean_reward          | -2.89e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012829216 |\n",
      "|    clip_fraction        | 0.000781     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 0.000236     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.29e+08     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 2.13e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 98.2      |\n",
      "|    ep_rew_mean     | -7.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 1036      |\n",
      "|    iterations      | 5         |\n",
      "|    time_elapsed    | 9         |\n",
      "|    total_timesteps | 10240     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 99.3         |\n",
      "|    ep_rew_mean          | -6.51e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 856          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009888615 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.68        |\n",
      "|    explained_variance   | 0.000232     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.99e+07     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.29e+08     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 99.1        |\n",
      "|    ep_rew_mean          | -5.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 863         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000982624 |\n",
      "|    clip_fraction        | 0.000244    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 9.86e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.98e+07    |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.23e+08    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-9484.41 +/- 13530.15\n",
      "Episode length: 82.80 +/- 2.32\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 82.8       |\n",
      "|    mean_reward          | -9.48e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 15000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00125028 |\n",
      "|    clip_fraction        | 0.0019     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.68      |\n",
      "|    explained_variance   | 0.000221   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.27e+07   |\n",
      "|    n_updates            | 70         |\n",
      "|    policy_gradient_loss | -0.00214   |\n",
      "|    std                  | 1          |\n",
      "|    value_loss           | 1.11e+08   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 94.8      |\n",
      "|    ep_rew_mean     | -4.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 869       |\n",
      "|    iterations      | 8         |\n",
      "|    time_elapsed    | 18        |\n",
      "|    total_timesteps | 16384     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 92.4         |\n",
      "|    ep_rew_mean          | -4e+04       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 849          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010070405 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 9.53e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.25e+07     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    std                  | 1            |\n",
      "|    value_loss           | 1.13e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=-19756.06 +/- 16003.78\n",
      "Episode length: 86.40 +/- 4.27\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 86.4         |\n",
      "|    mean_reward          | -1.98e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 20000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015248831 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 6.79e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.56e+07     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00323     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 7.25e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 90.2      |\n",
      "|    ep_rew_mean     | -3.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 832       |\n",
      "|    iterations      | 10        |\n",
      "|    time_elapsed    | 24        |\n",
      "|    total_timesteps | 20480     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93.5         |\n",
      "|    ep_rew_mean          | -3.4e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 838          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028886602 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 4e-05        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.13e+07     |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 7.81e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 93.8         |\n",
      "|    ep_rew_mean          | -2.83e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 842          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 29           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021958465 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.00011      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.72e+07     |\n",
      "|    n_updates            | 110          |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.67e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=25000, episode_reward=-3951.78 +/- 5686.81\n",
      "Episode length: 93.40 +/- 10.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 93.4         |\n",
      "|    mean_reward          | -3.95e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 25000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037461913 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.00113      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.42e+07     |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.77e+07     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 94.8      |\n",
      "|    ep_rew_mean     | -2.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 842       |\n",
      "|    iterations      | 13        |\n",
      "|    time_elapsed    | 31        |\n",
      "|    total_timesteps | 26624     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95.6         |\n",
      "|    ep_rew_mean          | -2.28e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 816          |\n",
      "|    iterations           | 14           |\n",
      "|    time_elapsed         | 35           |\n",
      "|    total_timesteps      | 28672        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015238964 |\n",
      "|    clip_fraction        | 0.00308      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.00162      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.74e+07     |\n",
      "|    n_updates            | 130          |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.96e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=-834.54 +/- 3806.36\n",
      "Episode length: 92.60 +/- 5.61\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 92.6         |\n",
      "|    mean_reward          | -835         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013198482 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.000701     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.27e+07     |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.28e+07     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 96.3      |\n",
      "|    ep_rew_mean     | -2.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 809       |\n",
      "|    iterations      | 15        |\n",
      "|    time_elapsed    | 37        |\n",
      "|    total_timesteps | 30720     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 94.6        |\n",
      "|    ep_rew_mean          | -1.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 816         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003695464 |\n",
      "|    clip_fraction        | 0.0173      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.00438     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+07    |\n",
      "|    n_updates            | 150         |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 4.75e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 96.2         |\n",
      "|    ep_rew_mean          | -2.18e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 823          |\n",
      "|    iterations           | 17           |\n",
      "|    time_elapsed         | 42           |\n",
      "|    total_timesteps      | 34816        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032998153 |\n",
      "|    clip_fraction        | 0.0119       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.00455      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07e+07     |\n",
      "|    n_updates            | 160          |\n",
      "|    policy_gradient_loss | -0.00512     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.4e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-1670.16 +/- 3925.24\n",
      "Episode length: 114.00 +/- 9.70\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 114          |\n",
      "|    mean_reward          | -1.67e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 35000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015988926 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.00611      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+07     |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.43e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 103       |\n",
      "|    ep_rew_mean     | -2.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 821       |\n",
      "|    iterations      | 18        |\n",
      "|    time_elapsed    | 44        |\n",
      "|    total_timesteps | 36864     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 108          |\n",
      "|    ep_rew_mean          | -2e+04       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 832          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 46           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012222213 |\n",
      "|    clip_fraction        | 0.00688      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.00479      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.14e+07     |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.43e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-2668.35 +/- 3718.74\n",
      "Episode length: 131.00 +/- 13.28\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 131          |\n",
      "|    mean_reward          | -2.67e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 40000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018330581 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.0077       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.49e+07     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00449     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.51e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 110       |\n",
      "|    ep_rew_mean     | -2.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 823       |\n",
      "|    iterations      | 20        |\n",
      "|    time_elapsed    | 49        |\n",
      "|    total_timesteps | 40960     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 115          |\n",
      "|    ep_rew_mean          | -1.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 819          |\n",
      "|    iterations           | 21           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 43008        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004990302 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.00822      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.58e+07     |\n",
      "|    n_updates            | 200          |\n",
      "|    policy_gradient_loss | -0.00089     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.42e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=1385.30 +/- 18.39\n",
      "Episode length: 110.20 +/- 2.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 110          |\n",
      "|    mean_reward          | 1.39e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 45000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022745812 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.0114       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.32e+06     |\n",
      "|    n_updates            | 210          |\n",
      "|    policy_gradient_loss | -0.00385     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.34e+07     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 120       |\n",
      "|    ep_rew_mean     | -2.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 817       |\n",
      "|    iterations      | 22        |\n",
      "|    time_elapsed    | 55        |\n",
      "|    total_timesteps | 45056     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 122          |\n",
      "|    ep_rew_mean          | -1.96e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 815          |\n",
      "|    iterations           | 23           |\n",
      "|    time_elapsed         | 57           |\n",
      "|    total_timesteps      | 47104        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022466937 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.00838      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.25e+07     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.42e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 120          |\n",
      "|    ep_rew_mean          | -1.89e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 813          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 60           |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017413584 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.00675      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+07     |\n",
      "|    n_updates            | 230          |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.37e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=-3318.63 +/- 2668.81\n",
      "Episode length: 123.80 +/- 7.19\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 124          |\n",
      "|    mean_reward          | -3.32e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 50000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027883048 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.00844      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+06     |\n",
      "|    n_updates            | 240          |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 6.19e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 119       |\n",
      "|    ep_rew_mean     | -1.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 798       |\n",
      "|    iterations      | 25        |\n",
      "|    time_elapsed    | 64        |\n",
      "|    total_timesteps | 51200     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 121          |\n",
      "|    ep_rew_mean          | -1.79e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 806          |\n",
      "|    iterations           | 26           |\n",
      "|    time_elapsed         | 66           |\n",
      "|    total_timesteps      | 53248        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029698135 |\n",
      "|    clip_fraction        | 0.00742      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.75        |\n",
      "|    explained_variance   | 0.0133       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.54e+06     |\n",
      "|    n_updates            | 250          |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.59e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-2998.34 +/- 3604.79\n",
      "Episode length: 112.80 +/- 12.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 113          |\n",
      "|    mean_reward          | -3e+03       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 55000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008743211 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0.0146       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.09e+06     |\n",
      "|    n_updates            | 260          |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 2.75e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 116       |\n",
      "|    ep_rew_mean     | -1.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 789       |\n",
      "|    iterations      | 27        |\n",
      "|    time_elapsed    | 70        |\n",
      "|    total_timesteps | 55296     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 114         |\n",
      "|    ep_rew_mean          | -1.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 794         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 57344       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002594526 |\n",
      "|    clip_fraction        | 0.00762     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.75       |\n",
      "|    explained_variance   | 0.0166      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.82e+06    |\n",
      "|    n_updates            | 270         |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 5.91e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 112          |\n",
      "|    ep_rew_mean          | -1.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 798          |\n",
      "|    iterations           | 29           |\n",
      "|    time_elapsed         | 74           |\n",
      "|    total_timesteps      | 59392        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013021224 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.0366       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.55e+05     |\n",
      "|    n_updates            | 280          |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 2.45e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-2995.79 +/- 2560.47\n",
      "Episode length: 103.60 +/- 11.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 104          |\n",
      "|    mean_reward          | -3e+03       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 60000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007311609 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.017        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51e+07     |\n",
      "|    n_updates            | 290          |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.96e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 106       |\n",
      "|    ep_rew_mean     | -1.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 783       |\n",
      "|    iterations      | 30        |\n",
      "|    time_elapsed    | 78        |\n",
      "|    total_timesteps | 61440     |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 105           |\n",
      "|    ep_rew_mean          | -1.5e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 786           |\n",
      "|    iterations           | 31            |\n",
      "|    time_elapsed         | 80            |\n",
      "|    total_timesteps      | 63488         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080305524 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.73         |\n",
      "|    explained_variance   | 0.0164        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.03e+07      |\n",
      "|    n_updates            | 300           |\n",
      "|    policy_gradient_loss | -0.0021       |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 2.32e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=840.71 +/- 763.98\n",
      "Episode length: 90.80 +/- 3.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 90.8         |\n",
      "|    mean_reward          | 841          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 65000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020056367 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.0109       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.77e+07     |\n",
      "|    n_updates            | 310          |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.47e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 106       |\n",
      "|    ep_rew_mean     | -1.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 773       |\n",
      "|    iterations      | 32        |\n",
      "|    time_elapsed    | 84        |\n",
      "|    total_timesteps | 65536     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 103          |\n",
      "|    ep_rew_mean          | -1.99e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 775          |\n",
      "|    iterations           | 33           |\n",
      "|    time_elapsed         | 87           |\n",
      "|    total_timesteps      | 67584        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023992066 |\n",
      "|    clip_fraction        | 0.00894      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.0092       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.52e+07     |\n",
      "|    n_updates            | 320          |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 4.55e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 104          |\n",
      "|    ep_rew_mean          | -1.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 91           |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013364481 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.75        |\n",
      "|    explained_variance   | 0.0131       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.5e+06      |\n",
      "|    n_updates            | 330          |\n",
      "|    policy_gradient_loss | -0.00315     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.88e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-4026.98 +/- 2715.20\n",
      "Episode length: 94.80 +/- 6.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 94.8         |\n",
      "|    mean_reward          | -4.03e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008824251 |\n",
      "|    clip_fraction        | 0.00176      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0.0196       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86e+06     |\n",
      "|    n_updates            | 340          |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.04e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 103       |\n",
      "|    ep_rew_mean     | -1.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 763       |\n",
      "|    iterations      | 35        |\n",
      "|    time_elapsed    | 93        |\n",
      "|    total_timesteps | 71680     |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 102           |\n",
      "|    ep_rew_mean          | -1.3e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 765           |\n",
      "|    iterations           | 36            |\n",
      "|    time_elapsed         | 96            |\n",
      "|    total_timesteps      | 73728         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051733654 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.77         |\n",
      "|    explained_variance   | 0.015         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.17e+06      |\n",
      "|    n_updates            | 350           |\n",
      "|    policy_gradient_loss | -0.00175      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 1.97e+07      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=75000, episode_reward=-1729.88 +/- 4726.41\n",
      "Episode length: 93.80 +/- 7.63\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 93.8          |\n",
      "|    mean_reward          | -1.73e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 75000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062298065 |\n",
      "|    clip_fraction        | 0.000732      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.77         |\n",
      "|    explained_variance   | 0.0265        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.77e+06      |\n",
      "|    n_updates            | 360           |\n",
      "|    policy_gradient_loss | -0.00163      |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 4.31e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 101       |\n",
      "|    ep_rew_mean     | -9.48e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 755       |\n",
      "|    iterations      | 37        |\n",
      "|    time_elapsed    | 100       |\n",
      "|    total_timesteps | 75776     |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 103           |\n",
      "|    ep_rew_mean          | -8.69e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 753           |\n",
      "|    iterations           | 38            |\n",
      "|    time_elapsed         | 103           |\n",
      "|    total_timesteps      | 77824         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084174017 |\n",
      "|    clip_fraction        | 0.00161       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.78         |\n",
      "|    explained_variance   | 0.0254        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.66e+06      |\n",
      "|    n_updates            | 370           |\n",
      "|    policy_gradient_loss | -0.0031       |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 5.68e+06      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 104          |\n",
      "|    ep_rew_mean          | -8.73e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 754          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015673114 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0.0347       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.89e+06     |\n",
      "|    n_updates            | 380          |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 4.23e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-1798.64 +/- 3613.98\n",
      "Episode length: 101.60 +/- 13.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 102          |\n",
      "|    mean_reward          | -1.8e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 80000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013631529 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.77        |\n",
      "|    explained_variance   | 0.0289       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.16e+06     |\n",
      "|    n_updates            | 390          |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 6.84e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 105       |\n",
      "|    ep_rew_mean     | -8.23e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 755       |\n",
      "|    iterations      | 40        |\n",
      "|    time_elapsed    | 108       |\n",
      "|    total_timesteps | 81920     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 106          |\n",
      "|    ep_rew_mean          | -9e+03       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 732          |\n",
      "|    iterations           | 41           |\n",
      "|    time_elapsed         | 114          |\n",
      "|    total_timesteps      | 83968        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009550104 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.77        |\n",
      "|    explained_variance   | 0.018        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.6e+06      |\n",
      "|    n_updates            | 400          |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.19e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=-1594.20 +/- 5686.89\n",
      "Episode length: 109.00 +/- 29.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 109          |\n",
      "|    mean_reward          | -1.59e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 85000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027427592 |\n",
      "|    clip_fraction        | 0.00659      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0.051        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+06     |\n",
      "|    n_updates            | 410          |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 3.01e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 106       |\n",
      "|    ep_rew_mean     | -7.99e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 729       |\n",
      "|    iterations      | 42        |\n",
      "|    time_elapsed    | 117       |\n",
      "|    total_timesteps | 86016     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 105          |\n",
      "|    ep_rew_mean          | -8.11e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 733          |\n",
      "|    iterations           | 43           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 88064        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032655185 |\n",
      "|    clip_fraction        | 0.00737      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.75        |\n",
      "|    explained_variance   | 0.0309       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.62e+06     |\n",
      "|    n_updates            | 420          |\n",
      "|    policy_gradient_loss | -0.00402     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 2.63e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=442.56 +/- 1572.56\n",
      "Episode length: 93.20 +/- 2.23\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 93.2          |\n",
      "|    mean_reward          | 443           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 90000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00017063075 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.74         |\n",
      "|    explained_variance   | 0.0362        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.06e+05      |\n",
      "|    n_updates            | 430           |\n",
      "|    policy_gradient_loss | -0.000721     |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 4.33e+06      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 107       |\n",
      "|    ep_rew_mean     | -7.58e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 735       |\n",
      "|    iterations      | 44        |\n",
      "|    time_elapsed    | 122       |\n",
      "|    total_timesteps | 90112     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 107          |\n",
      "|    ep_rew_mean          | -7.37e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 45           |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 92160        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026500635 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.75        |\n",
      "|    explained_variance   | 0.0683       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.13e+05     |\n",
      "|    n_updates            | 440          |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 2.03e+06     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 108           |\n",
      "|    ep_rew_mean          | -6.85e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 737           |\n",
      "|    iterations           | 46            |\n",
      "|    time_elapsed         | 127           |\n",
      "|    total_timesteps      | 94208         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084281125 |\n",
      "|    clip_fraction        | 0.00293       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.74         |\n",
      "|    explained_variance   | 0.0217        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.71e+06      |\n",
      "|    n_updates            | 450           |\n",
      "|    policy_gradient_loss | -0.00352      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 1.02e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=894.39 +/- 118.61\n",
      "Episode length: 108.80 +/- 4.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 109          |\n",
      "|    mean_reward          | 894          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 95000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018505352 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.0416       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.82e+05     |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 2.21e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 111       |\n",
      "|    ep_rew_mean     | -7.11e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 740       |\n",
      "|    iterations      | 47        |\n",
      "|    time_elapsed    | 129       |\n",
      "|    total_timesteps | 96256     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 115          |\n",
      "|    ep_rew_mean          | -7.35e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 745          |\n",
      "|    iterations           | 48           |\n",
      "|    time_elapsed         | 131          |\n",
      "|    total_timesteps      | 98304        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013453721 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.0395       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.57e+06     |\n",
      "|    n_updates            | 470          |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 4.65e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=-9.47 +/- 1687.71\n",
      "Episode length: 122.20 +/- 5.27\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 122          |\n",
      "|    mean_reward          | -9.47        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031035189 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.163        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.6e+05      |\n",
      "|    n_updates            | 480          |\n",
      "|    policy_gradient_loss | -0.00431     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 4.28e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 115       |\n",
      "|    ep_rew_mean     | -6.89e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 737       |\n",
      "|    iterations      | 49        |\n",
      "|    time_elapsed    | 136       |\n",
      "|    total_timesteps | 100352    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 117         |\n",
      "|    ep_rew_mean          | -6.35e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 738         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 138         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002566341 |\n",
      "|    clip_fraction        | 0.00425     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.0835      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.66e+05    |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.86e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 116          |\n",
      "|    ep_rew_mean          | -6.61e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 741          |\n",
      "|    iterations           | 51           |\n",
      "|    time_elapsed         | 140          |\n",
      "|    total_timesteps      | 104448       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006091202 |\n",
      "|    clip_fraction        | 0.000195     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.0108       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.19e+06     |\n",
      "|    n_updates            | 500          |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.87e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=-8398.98 +/- 1957.85\n",
      "Episode length: 161.00 +/- 18.03\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 161           |\n",
      "|    mean_reward          | -8.4e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 105000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047732244 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.73         |\n",
      "|    explained_variance   | 0.0358        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.02e+06      |\n",
      "|    n_updates            | 510           |\n",
      "|    policy_gradient_loss | -0.00134      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 3.39e+06      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 113       |\n",
      "|    ep_rew_mean     | -6.99e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 733       |\n",
      "|    iterations      | 52        |\n",
      "|    time_elapsed    | 145       |\n",
      "|    total_timesteps | 106496    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 113           |\n",
      "|    ep_rew_mean          | -6.78e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 732           |\n",
      "|    iterations           | 53            |\n",
      "|    time_elapsed         | 148           |\n",
      "|    total_timesteps      | 108544        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063221395 |\n",
      "|    clip_fraction        | 0.00127       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.72         |\n",
      "|    explained_variance   | 0.024         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.04e+05      |\n",
      "|    n_updates            | 520           |\n",
      "|    policy_gradient_loss | -0.00251      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 4.85e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=-883.48 +/- 3835.23\n",
      "Episode length: 134.40 +/- 38.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 134          |\n",
      "|    mean_reward          | -883         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 110000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020877318 |\n",
      "|    clip_fraction        | 0.00386      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.0521       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.81e+05     |\n",
      "|    n_updates            | 530          |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.11e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 113       |\n",
      "|    ep_rew_mean     | -6.75e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 735       |\n",
      "|    iterations      | 54        |\n",
      "|    time_elapsed    | 150       |\n",
      "|    total_timesteps | 110592    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 113          |\n",
      "|    ep_rew_mean          | -6.27e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 740          |\n",
      "|    iterations           | 55           |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 112640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006289297 |\n",
      "|    clip_fraction        | 0.00103      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.0874       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.42e+04     |\n",
      "|    n_updates            | 540          |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 9.28e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 114          |\n",
      "|    ep_rew_mean          | -6.06e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 744          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017057103 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.0626       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.18e+06     |\n",
      "|    n_updates            | 550          |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.96e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=-4771.70 +/- 5154.59\n",
      "Episode length: 122.00 +/- 20.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 122          |\n",
      "|    mean_reward          | -4.77e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 115000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032098684 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.0911       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.83e+05     |\n",
      "|    n_updates            | 560          |\n",
      "|    policy_gradient_loss | -0.0046      |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.06e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 114       |\n",
      "|    ep_rew_mean     | -5.02e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 747       |\n",
      "|    iterations      | 57        |\n",
      "|    time_elapsed    | 156       |\n",
      "|    total_timesteps | 116736    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 112          |\n",
      "|    ep_rew_mean          | -4.7e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 745          |\n",
      "|    iterations           | 58           |\n",
      "|    time_elapsed         | 159          |\n",
      "|    total_timesteps      | 118784       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019728718 |\n",
      "|    clip_fraction        | 0.0062       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.0774       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.06e+05     |\n",
      "|    n_updates            | 570          |\n",
      "|    policy_gradient_loss | -0.0073      |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.58e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-4353.35 +/- 4684.65\n",
      "Episode length: 111.00 +/- 14.63\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 111          |\n",
      "|    mean_reward          | -4.35e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 120000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029766066 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.0807       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.68e+05     |\n",
      "|    n_updates            | 580          |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.47e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 112       |\n",
      "|    ep_rew_mean     | -4.82e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 744       |\n",
      "|    iterations      | 59        |\n",
      "|    time_elapsed    | 162       |\n",
      "|    total_timesteps | 120832    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 111          |\n",
      "|    ep_rew_mean          | -3.99e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 745          |\n",
      "|    iterations           | 60           |\n",
      "|    time_elapsed         | 164          |\n",
      "|    total_timesteps      | 122880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047640866 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.128        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+06     |\n",
      "|    n_updates            | 590          |\n",
      "|    policy_gradient_loss | -0.008       |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 8.82e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 111         |\n",
      "|    ep_rew_mean          | -4.04e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 747         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 167         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004602429 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.71e+03    |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.34e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-3798.14 +/- 3658.95\n",
      "Episode length: 176.60 +/- 26.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 177          |\n",
      "|    mean_reward          | -3.8e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 125000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042043068 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.115        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.12e+05     |\n",
      "|    n_updates            | 610          |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 9.6e+05      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 109       |\n",
      "|    ep_rew_mean     | -3.48e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 739       |\n",
      "|    iterations      | 62        |\n",
      "|    time_elapsed    | 171       |\n",
      "|    total_timesteps | 126976    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 107          |\n",
      "|    ep_rew_mean          | -3.99e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 740          |\n",
      "|    iterations           | 63           |\n",
      "|    time_elapsed         | 174          |\n",
      "|    total_timesteps      | 129024       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036987364 |\n",
      "|    clip_fraction        | 0.0158       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.75        |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.53e+03     |\n",
      "|    n_updates            | 620          |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.72e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-3272.40 +/- 4912.23\n",
      "Episode length: 126.40 +/- 14.61\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 126           |\n",
      "|    mean_reward          | -3.27e+03     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 130000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00076269195 |\n",
      "|    clip_fraction        | 0.00278       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.77         |\n",
      "|    explained_variance   | 0.0913        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.95e+05      |\n",
      "|    n_updates            | 630           |\n",
      "|    policy_gradient_loss | -0.00383      |\n",
      "|    std                  | 1.03          |\n",
      "|    value_loss           | 1.35e+06      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 109      |\n",
      "|    ep_rew_mean     | -4e+03   |\n",
      "| time/              |          |\n",
      "|    fps             | 724      |\n",
      "|    iterations      | 64       |\n",
      "|    time_elapsed    | 180      |\n",
      "|    total_timesteps | 131072   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 109          |\n",
      "|    ep_rew_mean          | -4.26e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 725          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010949785 |\n",
      "|    clip_fraction        | 0.0021       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0.0693       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.64e+06     |\n",
      "|    n_updates            | 640          |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 1.51e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-3889.35 +/- 5456.14\n",
      "Episode length: 135.80 +/- 28.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 136         |\n",
      "|    mean_reward          | -3.89e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 135000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004065526 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.161       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.39e+05    |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 7.07e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 113      |\n",
      "|    ep_rew_mean     | -5e+03   |\n",
      "| time/              |          |\n",
      "|    fps             | 725      |\n",
      "|    iterations      | 66       |\n",
      "|    time_elapsed    | 186      |\n",
      "|    total_timesteps | 135168   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 117          |\n",
      "|    ep_rew_mean          | -4.91e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 728          |\n",
      "|    iterations           | 67           |\n",
      "|    time_elapsed         | 188          |\n",
      "|    total_timesteps      | 137216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022905837 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | 0.0352       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+06     |\n",
      "|    n_updates            | 660          |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 3.89e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 123          |\n",
      "|    ep_rew_mean          | -5.17e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 68           |\n",
      "|    time_elapsed         | 190          |\n",
      "|    total_timesteps      | 139264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.976047e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | 0.0259       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.77e+06     |\n",
      "|    n_updates            | 670          |\n",
      "|    policy_gradient_loss | -0.000304    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 6.32e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=140000, episode_reward=152.31 +/- 2406.78\n",
      "Episode length: 135.20 +/- 15.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 135          |\n",
      "|    mean_reward          | 152          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 140000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002901835 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.67e+04     |\n",
      "|    n_updates            | 680          |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 3.61e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 130       |\n",
      "|    ep_rew_mean     | -5.14e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 730       |\n",
      "|    iterations      | 69        |\n",
      "|    time_elapsed    | 193       |\n",
      "|    total_timesteps | 141312    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 135         |\n",
      "|    ep_rew_mean          | -4.9e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 196         |\n",
      "|    total_timesteps      | 143360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002301302 |\n",
      "|    clip_fraction        | 0.00332     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.133       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.47e+05    |\n",
      "|    n_updates            | 690         |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 8.78e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-2689.74 +/- 5040.09\n",
      "Episode length: 135.40 +/- 16.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 135         |\n",
      "|    mean_reward          | -2.69e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 145000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006354579 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+04    |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 3.52e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 137       |\n",
      "|    ep_rew_mean     | -4.69e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 729       |\n",
      "|    iterations      | 71        |\n",
      "|    time_elapsed    | 199       |\n",
      "|    total_timesteps | 145408    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 144          |\n",
      "|    ep_rew_mean          | -4.75e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 724          |\n",
      "|    iterations           | 72           |\n",
      "|    time_elapsed         | 203          |\n",
      "|    total_timesteps      | 147456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052568223 |\n",
      "|    clip_fraction        | 0.0305       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.6e+04      |\n",
      "|    n_updates            | 710          |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 3.69e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 148          |\n",
      "|    ep_rew_mean          | -4.54e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 725          |\n",
      "|    iterations           | 73           |\n",
      "|    time_elapsed         | 206          |\n",
      "|    total_timesteps      | 149504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039976947 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.07e+04     |\n",
      "|    n_updates            | 720          |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 5.15e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-1863.49 +/- 3211.43\n",
      "Episode length: 180.60 +/- 11.64\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 181          |\n",
      "|    mean_reward          | -1.86e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 150000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016079139 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.8         |\n",
      "|    explained_variance   | 0.112        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.35e+03     |\n",
      "|    n_updates            | 730          |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 1.3e+06      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 148       |\n",
      "|    ep_rew_mean     | -4.22e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 724       |\n",
      "|    iterations      | 74        |\n",
      "|    time_elapsed    | 209       |\n",
      "|    total_timesteps | 151552    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 150          |\n",
      "|    ep_rew_mean          | -4.64e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 723          |\n",
      "|    iterations           | 75           |\n",
      "|    time_elapsed         | 212          |\n",
      "|    total_timesteps      | 153600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022034696 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.8         |\n",
      "|    explained_variance   | 0.0879       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.74e+04     |\n",
      "|    n_updates            | 740          |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 1.95e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-2862.33 +/- 3665.71\n",
      "Episode length: 192.00 +/- 15.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 192          |\n",
      "|    mean_reward          | -2.86e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 155000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020389296 |\n",
      "|    clip_fraction        | 0.00771      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | 0.0987       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.28e+05     |\n",
      "|    n_updates            | 750          |\n",
      "|    policy_gradient_loss | -0.00545     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 1.64e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 149       |\n",
      "|    ep_rew_mean     | -4.99e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 723       |\n",
      "|    iterations      | 76        |\n",
      "|    time_elapsed    | 215       |\n",
      "|    total_timesteps | 155648    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 147          |\n",
      "|    ep_rew_mean          | -4.88e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 722          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 218          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013943226 |\n",
      "|    clip_fraction        | 0.000732     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.8         |\n",
      "|    explained_variance   | 0.0674       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.71e+06     |\n",
      "|    n_updates            | 760          |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 4.6e+06      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 150         |\n",
      "|    ep_rew_mean          | -5.24e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 721         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 221         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003656275 |\n",
      "|    clip_fraction        | 0.0129      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.162       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+06    |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    std                  | 1.04        |\n",
      "|    value_loss           | 6.84e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=137.78 +/- 3111.39\n",
      "Episode length: 150.20 +/- 7.25\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 150          |\n",
      "|    mean_reward          | 138          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 160000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056028897 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.8         |\n",
      "|    explained_variance   | 0.124        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.52e+04     |\n",
      "|    n_updates            | 780          |\n",
      "|    policy_gradient_loss | -0.0144      |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 1.2e+06      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 150       |\n",
      "|    ep_rew_mean     | -5.55e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 720       |\n",
      "|    iterations      | 79        |\n",
      "|    time_elapsed    | 224       |\n",
      "|    total_timesteps | 161792    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 147          |\n",
      "|    ep_rew_mean          | -5.46e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 719          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 227          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052154474 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.79        |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.34e+03     |\n",
      "|    n_updates            | 790          |\n",
      "|    policy_gradient_loss | -0.00573     |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 4.14e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-1089.55 +/- 4102.90\n",
      "Episode length: 268.20 +/- 56.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 268          |\n",
      "|    mean_reward          | -1.09e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 165000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006632946 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.78        |\n",
      "|    explained_variance   | 0.0584       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.33e+06     |\n",
      "|    n_updates            | 800          |\n",
      "|    policy_gradient_loss | -0.000616    |\n",
      "|    std                  | 1.03         |\n",
      "|    value_loss           | 1.68e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 152      |\n",
      "|    ep_rew_mean     | -5.1e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 717      |\n",
      "|    iterations      | 81       |\n",
      "|    time_elapsed    | 231      |\n",
      "|    total_timesteps | 165888   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 162         |\n",
      "|    ep_rew_mean          | -5.08e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 715         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004595299 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.79       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.16e+04    |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.00423    |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 9.23e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 166         |\n",
      "|    ep_rew_mean          | -4.54e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 237         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004319852 |\n",
      "|    clip_fraction        | 0.0136      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.8        |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.63e+03    |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    std                  | 1.03        |\n",
      "|    value_loss           | 5.17e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-906.73 +/- 5216.91\n",
      "Episode length: 318.80 +/- 45.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 319         |\n",
      "|    mean_reward          | -907        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 170000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003765788 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.78       |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+05    |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 2.83e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 173       |\n",
      "|    ep_rew_mean     | -4.08e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 715       |\n",
      "|    iterations      | 84        |\n",
      "|    time_elapsed    | 240       |\n",
      "|    total_timesteps | 172032    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 179          |\n",
      "|    ep_rew_mean          | -3.95e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 85           |\n",
      "|    time_elapsed         | 242          |\n",
      "|    total_timesteps      | 174080       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036143092 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.76        |\n",
      "|    explained_variance   | 0.241        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86e+05     |\n",
      "|    n_updates            | 840          |\n",
      "|    policy_gradient_loss | -0.00585     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.76e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=1231.56 +/- 3803.08\n",
      "Episode length: 231.40 +/- 15.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 231          |\n",
      "|    mean_reward          | 1.23e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 175000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051263925 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.74        |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.42e+03     |\n",
      "|    n_updates            | 850          |\n",
      "|    policy_gradient_loss | -0.00807     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5e+05        |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 184       |\n",
      "|    ep_rew_mean     | -4.11e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 714       |\n",
      "|    iterations      | 86        |\n",
      "|    time_elapsed    | 246       |\n",
      "|    total_timesteps | 176128    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 187          |\n",
      "|    ep_rew_mean          | -4.35e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 248          |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032882537 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.9e+04      |\n",
      "|    n_updates            | 860          |\n",
      "|    policy_gradient_loss | -0.00561     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.22e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=1221.90 +/- 3703.76\n",
      "Episode length: 233.00 +/- 21.29\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 233           |\n",
      "|    mean_reward          | 1.22e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 180000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016809566 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.72         |\n",
      "|    explained_variance   | 0.0581        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.58e+05      |\n",
      "|    n_updates            | 870           |\n",
      "|    policy_gradient_loss | -0.000372     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 5.51e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 188       |\n",
      "|    ep_rew_mean     | -4.59e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 713       |\n",
      "|    iterations      | 88        |\n",
      "|    time_elapsed    | 252       |\n",
      "|    total_timesteps | 180224    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 188          |\n",
      "|    ep_rew_mean          | -5.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 712          |\n",
      "|    iterations           | 89           |\n",
      "|    time_elapsed         | 255          |\n",
      "|    total_timesteps      | 182272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.414927e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.0705       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4e+06        |\n",
      "|    n_updates            | 880          |\n",
      "|    policy_gradient_loss | -0.000438    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.86e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 182          |\n",
      "|    ep_rew_mean          | -5.17e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 90           |\n",
      "|    time_elapsed         | 259          |\n",
      "|    total_timesteps      | 184320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004578657 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.0675       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.32e+06     |\n",
      "|    n_updates            | 890          |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 5.49e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-3696.16 +/- 3512.71\n",
      "Episode length: 233.80 +/- 19.89\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 234           |\n",
      "|    mean_reward          | -3.7e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 185000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067069096 |\n",
      "|    clip_fraction        | 0.00122       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.73         |\n",
      "|    explained_variance   | 0.0477        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.68e+06      |\n",
      "|    n_updates            | 900           |\n",
      "|    policy_gradient_loss | -0.00255      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 2.63e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 180       |\n",
      "|    ep_rew_mean     | -5.11e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 709       |\n",
      "|    iterations      | 91        |\n",
      "|    time_elapsed    | 262       |\n",
      "|    total_timesteps | 186368    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 185          |\n",
      "|    ep_rew_mean          | -5.63e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 705          |\n",
      "|    iterations           | 92           |\n",
      "|    time_elapsed         | 267          |\n",
      "|    total_timesteps      | 188416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034218433 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.81e+04     |\n",
      "|    n_updates            | 910          |\n",
      "|    policy_gradient_loss | -0.00619     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.41e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=190000, episode_reward=-2540.76 +/- 4220.71\n",
      "Episode length: 374.80 +/- 102.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 375         |\n",
      "|    mean_reward          | -2.54e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004929124 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+04    |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 9.63e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 186       |\n",
      "|    ep_rew_mean     | -5.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 93        |\n",
      "|    time_elapsed    | 270       |\n",
      "|    total_timesteps | 190464    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 187         |\n",
      "|    ep_rew_mean          | -5.6e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 700         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 274         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005071299 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.74       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.08e+03    |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 3.95e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 191          |\n",
      "|    ep_rew_mean          | -5.62e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 700          |\n",
      "|    iterations           | 95           |\n",
      "|    time_elapsed         | 277          |\n",
      "|    total_timesteps      | 194560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064127794 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.44e+04     |\n",
      "|    n_updates            | 940          |\n",
      "|    policy_gradient_loss | -0.00899     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 3.5e+05      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=393.62 +/- 4979.77\n",
      "Episode length: 374.00 +/- 51.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 374          |\n",
      "|    mean_reward          | 394          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 195000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012843013 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.126        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+05     |\n",
      "|    n_updates            | 950          |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.84e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 195      |\n",
      "|    ep_rew_mean     | -5.2e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 700      |\n",
      "|    iterations      | 96       |\n",
      "|    time_elapsed    | 280      |\n",
      "|    total_timesteps | 196608   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 202        |\n",
      "|    ep_rew_mean          | -5.02e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 703        |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 282        |\n",
      "|    total_timesteps      | 198656     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00466124 |\n",
      "|    clip_fraction        | 0.0125     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.72      |\n",
      "|    explained_variance   | 0.179      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.51e+03   |\n",
      "|    n_updates            | 960        |\n",
      "|    policy_gradient_loss | -0.00452   |\n",
      "|    std                  | 1.01       |\n",
      "|    value_loss           | 9.85e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=1113.15 +/- 4818.47\n",
      "Episode length: 351.60 +/- 90.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 352          |\n",
      "|    mean_reward          | 1.11e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 200000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033312654 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.72        |\n",
      "|    explained_variance   | 0.615        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.65e+04     |\n",
      "|    n_updates            | 970          |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 9.71e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 211       |\n",
      "|    ep_rew_mean     | -5.35e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 98        |\n",
      "|    time_elapsed    | 285       |\n",
      "|    total_timesteps | 200704    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 217         |\n",
      "|    ep_rew_mean          | -4.38e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 705         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 287         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004983116 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.73       |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.85e+05    |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    std                  | 1.02        |\n",
      "|    value_loss           | 6.11e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 226          |\n",
      "|    ep_rew_mean          | -7.22e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 100          |\n",
      "|    time_elapsed         | 289          |\n",
      "|    total_timesteps      | 204800       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058792927 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.73        |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+04     |\n",
      "|    n_updates            | 990          |\n",
      "|    policy_gradient_loss | -0.00782     |\n",
      "|    std                  | 1.02         |\n",
      "|    value_loss           | 1.97e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=205000, episode_reward=-43825.96 +/- 90520.72\n",
      "Episode length: 390.80 +/- 111.13\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 391           |\n",
      "|    mean_reward          | -4.38e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 205000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025917255 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.72         |\n",
      "|    explained_variance   | 0.0452        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+07      |\n",
      "|    n_updates            | 1000          |\n",
      "|    policy_gradient_loss | -0.00165      |\n",
      "|    std                  | 1.02          |\n",
      "|    value_loss           | 5.9e+07       |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 233      |\n",
      "|    ep_rew_mean     | -7e+03   |\n",
      "| time/              |          |\n",
      "|    fps             | 707      |\n",
      "|    iterations      | 101      |\n",
      "|    time_elapsed    | 292      |\n",
      "|    total_timesteps | 206848   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 240         |\n",
      "|    ep_rew_mean          | -1.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 295         |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002714448 |\n",
      "|    clip_fraction        | 0.00449     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.71       |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.44e+03    |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.15e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=-29721.03 +/- 56386.82\n",
      "Episode length: 379.40 +/- 100.17\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 379          |\n",
      "|    mean_reward          | -2.97e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 210000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.358406e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0384       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.53e+07     |\n",
      "|    n_updates            | 1020         |\n",
      "|    policy_gradient_loss | -0.000764    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.61e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 244       |\n",
      "|    ep_rew_mean     | -2.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 705       |\n",
      "|    iterations      | 103       |\n",
      "|    time_elapsed    | 298       |\n",
      "|    total_timesteps | 210944    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 250           |\n",
      "|    ep_rew_mean          | -2.99e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 708           |\n",
      "|    iterations           | 104           |\n",
      "|    time_elapsed         | 300           |\n",
      "|    total_timesteps      | 212992        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00012154592 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.7          |\n",
      "|    explained_variance   | 0.0293        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.14e+07      |\n",
      "|    n_updates            | 1030          |\n",
      "|    policy_gradient_loss | -0.000538     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 1.59e+08      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=-69577.48 +/- 84007.97\n",
      "Episode length: 425.60 +/- 93.29\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 426           |\n",
      "|    mean_reward          | -6.96e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 215000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5844387e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.7          |\n",
      "|    explained_variance   | 0.0206        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.11e+07      |\n",
      "|    n_updates            | 1040          |\n",
      "|    policy_gradient_loss | -0.000126     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 1.68e+08      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 252       |\n",
      "|    ep_rew_mean     | -3.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 707       |\n",
      "|    iterations      | 105       |\n",
      "|    time_elapsed    | 303       |\n",
      "|    total_timesteps | 215040    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 258          |\n",
      "|    ep_rew_mean          | -3.39e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 707          |\n",
      "|    iterations           | 106          |\n",
      "|    time_elapsed         | 306          |\n",
      "|    total_timesteps      | 217088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015663055 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0114       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.47e+07     |\n",
      "|    n_updates            | 1050         |\n",
      "|    policy_gradient_loss | -0.00569     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 4.81e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 256          |\n",
      "|    ep_rew_mean          | -3.8e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 708          |\n",
      "|    iterations           | 107          |\n",
      "|    time_elapsed         | 309          |\n",
      "|    total_timesteps      | 219136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.610202e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0159       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.18e+06     |\n",
      "|    n_updates            | 1060         |\n",
      "|    policy_gradient_loss | -0.00031     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.43e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=-16425.18 +/- 13898.01\n",
      "Episode length: 369.80 +/- 90.88\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 370           |\n",
      "|    mean_reward          | -1.64e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 220000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016296247 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.7          |\n",
      "|    explained_variance   | 0.017         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.76e+07      |\n",
      "|    n_updates            | 1070          |\n",
      "|    policy_gradient_loss | -0.000908     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 7.82e+07      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 252       |\n",
      "|    ep_rew_mean     | -3.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 705       |\n",
      "|    iterations      | 108       |\n",
      "|    time_elapsed    | 313       |\n",
      "|    total_timesteps | 221184    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 252          |\n",
      "|    ep_rew_mean          | -4.27e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 706          |\n",
      "|    iterations           | 109          |\n",
      "|    time_elapsed         | 315          |\n",
      "|    total_timesteps      | 223232       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004769421 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.00905      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.42e+06     |\n",
      "|    n_updates            | 1080         |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.79e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=-14202.87 +/- 13046.92\n",
      "Episode length: 432.20 +/- 76.66\n",
      "--------------------------------------------\n",
      "| eval/                   |                |\n",
      "|    mean_ep_length       | 432            |\n",
      "|    mean_reward          | -1.42e+04      |\n",
      "| time/                   |                |\n",
      "|    total_timesteps      | 225000         |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 0.000119370176 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -5.71          |\n",
      "|    explained_variance   | 0.0134         |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 3.34e+07       |\n",
      "|    n_updates            | 1090           |\n",
      "|    policy_gradient_loss | -0.000678      |\n",
      "|    std                  | 1.01           |\n",
      "|    value_loss           | 8.23e+07       |\n",
      "--------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 251       |\n",
      "|    ep_rew_mean     | -4.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 702       |\n",
      "|    iterations      | 110       |\n",
      "|    time_elapsed    | 320       |\n",
      "|    total_timesteps | 225280    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 243           |\n",
      "|    ep_rew_mean          | -4.58e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 703           |\n",
      "|    iterations           | 111           |\n",
      "|    time_elapsed         | 323           |\n",
      "|    total_timesteps      | 227328        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038407053 |\n",
      "|    clip_fraction        | 0.000244      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.7          |\n",
      "|    explained_variance   | 0.0224        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.03e+06      |\n",
      "|    n_updates            | 1100          |\n",
      "|    policy_gradient_loss | -0.0016       |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 1.9e+07       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 244          |\n",
      "|    ep_rew_mean          | -4.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 705          |\n",
      "|    iterations           | 112          |\n",
      "|    time_elapsed         | 325          |\n",
      "|    total_timesteps      | 229376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003674624 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0248       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+07      |\n",
      "|    n_updates            | 1110         |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.51e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=1078.33 +/- 6368.61\n",
      "Episode length: 488.60 +/- 93.52\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 489          |\n",
      "|    mean_reward          | 1.08e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 230000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016123591 |\n",
      "|    clip_fraction        | 0.00117      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.69        |\n",
      "|    explained_variance   | 0.142        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.22e+04     |\n",
      "|    n_updates            | 1120         |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.79e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 242       |\n",
      "|    ep_rew_mean     | -4.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 113       |\n",
      "|    time_elapsed    | 329       |\n",
      "|    total_timesteps | 231424    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 245           |\n",
      "|    ep_rew_mean          | -3.63e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 702           |\n",
      "|    iterations           | 114           |\n",
      "|    time_elapsed         | 332           |\n",
      "|    total_timesteps      | 233472        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028522417 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.69         |\n",
      "|    explained_variance   | 0.0516        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.84e+06      |\n",
      "|    n_updates            | 1130          |\n",
      "|    policy_gradient_loss | -0.000669     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 1.27e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=1913.38 +/- 2902.77\n",
      "Episode length: 430.00 +/- 69.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 430         |\n",
      "|    mean_reward          | 1.91e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 235000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004932396 |\n",
      "|    clip_fraction        | 0.0183      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.68       |\n",
      "|    explained_variance   | 0.369       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.25e+05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 242      |\n",
      "|    ep_rew_mean     | -2.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 696      |\n",
      "|    iterations      | 115      |\n",
      "|    time_elapsed    | 338      |\n",
      "|    total_timesteps | 235520   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 240         |\n",
      "|    ep_rew_mean          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 698         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 339         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005244858 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.69       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.11e+05    |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 1.98e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 236         |\n",
      "|    ep_rew_mean          | -1.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 701         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 341         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007252178 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.26e+03    |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 5.48e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=-64379.37 +/- 54220.70\n",
      "Episode length: 425.40 +/- 39.70\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 425           |\n",
      "|    mean_reward          | -6.44e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 240000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013893552 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.71         |\n",
      "|    explained_variance   | 0.0476        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.3e+07       |\n",
      "|    n_updates            | 1170          |\n",
      "|    policy_gradient_loss | -0.000983     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 2.2e+07       |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 243       |\n",
      "|    ep_rew_mean     | -1.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 701       |\n",
      "|    iterations      | 118       |\n",
      "|    time_elapsed    | 344       |\n",
      "|    total_timesteps | 241664    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 248          |\n",
      "|    ep_rew_mean          | -1.71e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 119          |\n",
      "|    time_elapsed         | 346          |\n",
      "|    total_timesteps      | 243712       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003235736 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.0466       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+07     |\n",
      "|    n_updates            | 1180         |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 3.35e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=-68391.82 +/- 64630.13\n",
      "Episode length: 470.60 +/- 97.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 471          |\n",
      "|    mean_reward          | -6.84e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 245000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.345263e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.0504       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.98e+07     |\n",
      "|    n_updates            | 1190         |\n",
      "|    policy_gradient_loss | -0.000752    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.47e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 254       |\n",
      "|    ep_rew_mean     | -1.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 703       |\n",
      "|    iterations      | 120       |\n",
      "|    time_elapsed    | 349       |\n",
      "|    total_timesteps | 245760    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 255          |\n",
      "|    ep_rew_mean          | -1.61e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 705          |\n",
      "|    iterations           | 121          |\n",
      "|    time_elapsed         | 351          |\n",
      "|    total_timesteps      | 247808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007340036 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.71        |\n",
      "|    explained_variance   | 0.0438       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.91e+07     |\n",
      "|    n_updates            | 1200         |\n",
      "|    policy_gradient_loss | -0.00265     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 6.11e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 262           |\n",
      "|    ep_rew_mean          | -1.67e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 707           |\n",
      "|    iterations           | 122           |\n",
      "|    time_elapsed         | 353           |\n",
      "|    total_timesteps      | 249856        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047272188 |\n",
      "|    clip_fraction        | 4.88e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.7          |\n",
      "|    explained_variance   | 0.381         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.94e+05      |\n",
      "|    n_updates            | 1210          |\n",
      "|    policy_gradient_loss | -0.00156      |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 2.22e+05      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-5955.69 +/- 11173.85\n",
      "Episode length: 454.80 +/- 130.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 455          |\n",
      "|    mean_reward          | -5.96e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 250000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004906723 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0507       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+07     |\n",
      "|    n_updates            | 1220         |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 5.66e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 263      |\n",
      "|    ep_rew_mean     | -1.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 707      |\n",
      "|    iterations      | 123      |\n",
      "|    time_elapsed    | 356      |\n",
      "|    total_timesteps | 251904   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 268          |\n",
      "|    ep_rew_mean          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 709          |\n",
      "|    iterations           | 124          |\n",
      "|    time_elapsed         | 357          |\n",
      "|    total_timesteps      | 253952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014435191 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.202        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.42e+06     |\n",
      "|    n_updates            | 1230         |\n",
      "|    policy_gradient_loss | -0.000869    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 1.37e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=255000, episode_reward=-4443.83 +/- 10131.49\n",
      "Episode length: 467.00 +/- 71.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 467         |\n",
      "|    mean_reward          | -4.44e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 255000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001208855 |\n",
      "|    clip_fraction        | 0.00308     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.7        |\n",
      "|    explained_variance   | 0.0552      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.62e+06    |\n",
      "|    n_updates            | 1240        |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 1.01        |\n",
      "|    value_loss           | 2.85e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 268      |\n",
      "|    ep_rew_mean     | -1.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 709      |\n",
      "|    iterations      | 125      |\n",
      "|    time_elapsed    | 360      |\n",
      "|    total_timesteps | 256000   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 269          |\n",
      "|    ep_rew_mean          | -1.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 711          |\n",
      "|    iterations           | 126          |\n",
      "|    time_elapsed         | 362          |\n",
      "|    total_timesteps      | 258048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.318697e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.0675       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.98e+07     |\n",
      "|    n_updates            | 1250         |\n",
      "|    policy_gradient_loss | -0.000493    |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.82e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=-45605.83 +/- 94227.50\n",
      "Episode length: 542.20 +/- 190.57\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 542           |\n",
      "|    mean_reward          | -4.56e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 260000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 7.7602745e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.7          |\n",
      "|    explained_variance   | 0.0496        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.2e+06       |\n",
      "|    n_updates            | 1260          |\n",
      "|    policy_gradient_loss | -0.000802     |\n",
      "|    std                  | 1.01          |\n",
      "|    value_loss           | 3.31e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 270       |\n",
      "|    ep_rew_mean     | -1.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 706       |\n",
      "|    iterations      | 127       |\n",
      "|    time_elapsed    | 368       |\n",
      "|    total_timesteps | 260096    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 274          |\n",
      "|    ep_rew_mean          | -1.91e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 707          |\n",
      "|    iterations           | 128          |\n",
      "|    time_elapsed         | 370          |\n",
      "|    total_timesteps      | 262144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009703238 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.7         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.34e+05     |\n",
      "|    n_updates            | 1270         |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    std                  | 1.01         |\n",
      "|    value_loss           | 2.63e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 278        |\n",
      "|    ep_rew_mean          | -1.92e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 707        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 373        |\n",
      "|    total_timesteps      | 264192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00563378 |\n",
      "|    clip_fraction        | 0.0174     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.68      |\n",
      "|    explained_variance   | 0.745      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.14e+03   |\n",
      "|    n_updates            | 1280       |\n",
      "|    policy_gradient_loss | -0.0053    |\n",
      "|    std                  | 0.997      |\n",
      "|    value_loss           | 3.93e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=2641.21 +/- 298.42\n",
      "Episode length: 286.60 +/- 14.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 287         |\n",
      "|    mean_reward          | 2.64e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 265000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006388789 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.64       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.68e+03    |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    std                  | 0.99        |\n",
      "|    value_loss           | 2.07e+05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 281       |\n",
      "|    ep_rew_mean     | -1.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 707       |\n",
      "|    iterations      | 130       |\n",
      "|    time_elapsed    | 376       |\n",
      "|    total_timesteps | 266240    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 283         |\n",
      "|    ep_rew_mean          | -1.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 707         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 379         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007000385 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.61       |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78e+03    |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00827    |\n",
      "|    std                  | 0.983       |\n",
      "|    value_loss           | 2.2e+05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=-78.93 +/- 3307.11\n",
      "Episode length: 332.80 +/- 37.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 333          |\n",
      "|    mean_reward          | -78.9        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 270000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084706675 |\n",
      "|    clip_fraction        | 0.0692       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.6         |\n",
      "|    explained_variance   | 0.5          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.21e+03     |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | -0.00815     |\n",
      "|    std                  | 0.984        |\n",
      "|    value_loss           | 1.65e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 284      |\n",
      "|    ep_rew_mean     | -1.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 705      |\n",
      "|    iterations      | 132      |\n",
      "|    time_elapsed    | 383      |\n",
      "|    total_timesteps | 270336   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 288         |\n",
      "|    ep_rew_mean          | -1.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 705         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 386         |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002998758 |\n",
      "|    clip_fraction        | 0.00771     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.57       |\n",
      "|    explained_variance   | 0.145       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.58e+04    |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    std                  | 0.975       |\n",
      "|    value_loss           | 6.31e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 287           |\n",
      "|    ep_rew_mean          | -1.38e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 704           |\n",
      "|    iterations           | 134           |\n",
      "|    time_elapsed         | 389           |\n",
      "|    total_timesteps      | 274432        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010520572 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.56         |\n",
      "|    explained_variance   | 0.0608        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.68e+07      |\n",
      "|    n_updates            | 1330          |\n",
      "|    policy_gradient_loss | -0.000845     |\n",
      "|    std                  | 0.975         |\n",
      "|    value_loss           | 4.31e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=2211.11 +/- 2305.49\n",
      "Episode length: 316.40 +/- 16.48\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 316           |\n",
      "|    mean_reward          | 2.21e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 275000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1596388e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.56         |\n",
      "|    explained_variance   | 0.0521        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.75e+07      |\n",
      "|    n_updates            | 1340          |\n",
      "|    policy_gradient_loss | -0.000998     |\n",
      "|    std                  | 0.975         |\n",
      "|    value_loss           | 1.95e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 292       |\n",
      "|    ep_rew_mean     | -1.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 704       |\n",
      "|    iterations      | 135       |\n",
      "|    time_elapsed    | 392       |\n",
      "|    total_timesteps | 276480    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 293          |\n",
      "|    ep_rew_mean          | -1.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 706          |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 394          |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006998599 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.56        |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.69e+06     |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.975        |\n",
      "|    value_loss           | 1.79e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=-1262.39 +/- 4520.22\n",
      "Episode length: 402.40 +/- 60.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 402          |\n",
      "|    mean_reward          | -1.26e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 280000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021188557 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.55        |\n",
      "|    explained_variance   | 0.125        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.5e+04      |\n",
      "|    n_updates            | 1360         |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    std                  | 0.971        |\n",
      "|    value_loss           | 5.21e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 302       |\n",
      "|    ep_rew_mean     | -1.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 706       |\n",
      "|    iterations      | 137       |\n",
      "|    time_elapsed    | 397       |\n",
      "|    total_timesteps | 280576    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 301         |\n",
      "|    ep_rew_mean          | -1.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 708         |\n",
      "|    iterations           | 138         |\n",
      "|    time_elapsed         | 399         |\n",
      "|    total_timesteps      | 282624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004055757 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.11e+03    |\n",
      "|    n_updates            | 1370        |\n",
      "|    policy_gradient_loss | -0.00535    |\n",
      "|    std                  | 0.966       |\n",
      "|    value_loss           | 1.38e+05    |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 305           |\n",
      "|    ep_rew_mean          | -1.07e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 709           |\n",
      "|    iterations           | 139           |\n",
      "|    time_elapsed         | 401           |\n",
      "|    total_timesteps      | 284672        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022503608 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.52         |\n",
      "|    explained_variance   | 0.0842        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.05e+06      |\n",
      "|    n_updates            | 1380          |\n",
      "|    policy_gradient_loss | -0.0022       |\n",
      "|    std                  | 0.965         |\n",
      "|    value_loss           | 5.04e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=-3363.54 +/- 3910.33\n",
      "Episode length: 302.20 +/- 23.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 302         |\n",
      "|    mean_reward          | -3.36e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 285000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007015886 |\n",
      "|    clip_fraction        | 0.0436      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.53       |\n",
      "|    explained_variance   | 0.626       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -0.00785    |\n",
      "|    std                  | 0.969       |\n",
      "|    value_loss           | 1.1e+05     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 306       |\n",
      "|    ep_rew_mean     | -8.65e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 710       |\n",
      "|    iterations      | 140       |\n",
      "|    time_elapsed    | 403       |\n",
      "|    total_timesteps | 286720    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 306         |\n",
      "|    ep_rew_mean          | -6.63e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 712         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 405         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006412833 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.49       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.19e+03    |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    std                  | 0.95        |\n",
      "|    value_loss           | 3.16e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=373.69 +/- 4718.08\n",
      "Episode length: 293.00 +/- 7.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 293          |\n",
      "|    mean_reward          | 374          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 290000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005689692 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.45        |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.05e+04     |\n",
      "|    n_updates            | 1410         |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    std                  | 0.95         |\n",
      "|    value_loss           | 1.39e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 311       |\n",
      "|    ep_rew_mean     | -6.44e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 712       |\n",
      "|    iterations      | 142       |\n",
      "|    time_elapsed    | 408       |\n",
      "|    total_timesteps | 290816    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 313         |\n",
      "|    ep_rew_mean          | -6.42e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 714         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 409         |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007141504 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.45       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.82e+03    |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    std                  | 0.951       |\n",
      "|    value_loss           | 6.92e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 317          |\n",
      "|    ep_rew_mean          | -7.18e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 144          |\n",
      "|    time_elapsed         | 411          |\n",
      "|    total_timesteps      | 294912       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053978073 |\n",
      "|    clip_fraction        | 0.0318       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.45        |\n",
      "|    explained_variance   | 0.607        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.5e+03      |\n",
      "|    n_updates            | 1430         |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    std                  | 0.95         |\n",
      "|    value_loss           | 1.06e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=570.74 +/- 3916.83\n",
      "Episode length: 399.40 +/- 42.14\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 399          |\n",
      "|    mean_reward          | 571          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 295000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002733435 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.45        |\n",
      "|    explained_variance   | 0.0937       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.53e+06     |\n",
      "|    n_updates            | 1440         |\n",
      "|    policy_gradient_loss | -0.000516    |\n",
      "|    std                  | 0.949        |\n",
      "|    value_loss           | 8.1e+06      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 319       |\n",
      "|    ep_rew_mean     | -8.14e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 716       |\n",
      "|    iterations      | 145       |\n",
      "|    time_elapsed    | 414       |\n",
      "|    total_timesteps | 296960    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 322          |\n",
      "|    ep_rew_mean          | -8.43e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 146          |\n",
      "|    time_elapsed         | 416          |\n",
      "|    total_timesteps      | 299008       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008937671 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.44        |\n",
      "|    explained_variance   | 0.0521       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+07     |\n",
      "|    n_updates            | 1450         |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    std                  | 0.947        |\n",
      "|    value_loss           | 2.09e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=2163.55 +/- 2284.38\n",
      "Episode length: 377.80 +/- 12.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 378         |\n",
      "|    mean_reward          | 2.16e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002980672 |\n",
      "|    clip_fraction        | 0.0042      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.43       |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.3e+04     |\n",
      "|    n_updates            | 1460        |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    std                  | 0.945       |\n",
      "|    value_loss           | 4.2e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 324       |\n",
      "|    ep_rew_mean     | -9.51e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 715       |\n",
      "|    iterations      | 147       |\n",
      "|    time_elapsed    | 421       |\n",
      "|    total_timesteps | 301056    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 328           |\n",
      "|    ep_rew_mean          | -9.31e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 715           |\n",
      "|    iterations           | 148           |\n",
      "|    time_elapsed         | 423           |\n",
      "|    total_timesteps      | 303104        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047782142 |\n",
      "|    clip_fraction        | 0.000391      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.43         |\n",
      "|    explained_variance   | 0.0603        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.88e+06      |\n",
      "|    n_updates            | 1470          |\n",
      "|    policy_gradient_loss | -0.00181      |\n",
      "|    std                  | 0.945         |\n",
      "|    value_loss           | 1.61e+07      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=305000, episode_reward=1061.26 +/- 2744.48\n",
      "Episode length: 346.60 +/- 16.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 347         |\n",
      "|    mean_reward          | 1.06e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 305000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004577333 |\n",
      "|    clip_fraction        | 0.0248      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.42       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.3e+03     |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    std                  | 0.943       |\n",
      "|    value_loss           | 1.57e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 331       |\n",
      "|    ep_rew_mean     | -7.36e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 712       |\n",
      "|    iterations      | 149       |\n",
      "|    time_elapsed    | 427       |\n",
      "|    total_timesteps | 305152    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 338         |\n",
      "|    ep_rew_mean          | -6.93e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 712         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 431         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007257497 |\n",
      "|    clip_fraction        | 0.0391      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.39       |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.3e+03     |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    std                  | 0.932       |\n",
      "|    value_loss           | 3.46e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 339         |\n",
      "|    ep_rew_mean          | -5.67e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 713         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 433         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004919663 |\n",
      "|    clip_fraction        | 0.0239      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.36       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+03    |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    std                  | 0.928       |\n",
      "|    value_loss           | 7.59e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-8540.81 +/- 16285.91\n",
      "Episode length: 382.20 +/- 140.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 382          |\n",
      "|    mean_reward          | -8.54e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 310000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067527676 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.35        |\n",
      "|    explained_variance   | 0.636        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.22e+03     |\n",
      "|    n_updates            | 1510         |\n",
      "|    policy_gradient_loss | -0.00808     |\n",
      "|    std                  | 0.929        |\n",
      "|    value_loss           | 1.18e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 342       |\n",
      "|    ep_rew_mean     | -5.28e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 713       |\n",
      "|    iterations      | 152       |\n",
      "|    time_elapsed    | 436       |\n",
      "|    total_timesteps | 311296    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 349          |\n",
      "|    ep_rew_mean          | -4.73e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 715          |\n",
      "|    iterations           | 153          |\n",
      "|    time_elapsed         | 438          |\n",
      "|    total_timesteps      | 313344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054005696 |\n",
      "|    clip_fraction        | 0.0299       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.34        |\n",
      "|    explained_variance   | 0.649        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.78e+03     |\n",
      "|    n_updates            | 1520         |\n",
      "|    policy_gradient_loss | -0.00698     |\n",
      "|    std                  | 0.923        |\n",
      "|    value_loss           | 1.04e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=-9208.69 +/- 17019.58\n",
      "Episode length: 364.20 +/- 49.64\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 364          |\n",
      "|    mean_reward          | -9.21e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 315000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016687284 |\n",
      "|    clip_fraction        | 0.00264      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.32        |\n",
      "|    explained_variance   | 0.202        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.8e+06      |\n",
      "|    n_updates            | 1530         |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    std                  | 0.922        |\n",
      "|    value_loss           | 1.8e+06      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 350       |\n",
      "|    ep_rew_mean     | -4.87e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 715       |\n",
      "|    iterations      | 154       |\n",
      "|    time_elapsed    | 440       |\n",
      "|    total_timesteps | 315392    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 359          |\n",
      "|    ep_rew_mean          | -4.39e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 717          |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 442          |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037098248 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.31        |\n",
      "|    explained_variance   | 0.573        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.57e+05     |\n",
      "|    n_updates            | 1540         |\n",
      "|    policy_gradient_loss | -0.00597     |\n",
      "|    std                  | 0.918        |\n",
      "|    value_loss           | 1.75e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 364          |\n",
      "|    ep_rew_mean          | -3.97e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 718          |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 444          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011699332 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.3         |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.51e+04     |\n",
      "|    n_updates            | 1550         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 1.02e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=320000, episode_reward=1669.66 +/- 2196.38\n",
      "Episode length: 336.00 +/- 20.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 336          |\n",
      "|    mean_reward          | 1.67e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 320000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056396206 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.3         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.43e+05     |\n",
      "|    n_updates            | 1560         |\n",
      "|    policy_gradient_loss | -0.00583     |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 6.22e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 361       |\n",
      "|    ep_rew_mean     | -4.15e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 719       |\n",
      "|    iterations      | 157       |\n",
      "|    time_elapsed    | 447       |\n",
      "|    total_timesteps | 321536    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 370          |\n",
      "|    ep_rew_mean          | -4e+03       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 720          |\n",
      "|    iterations           | 158          |\n",
      "|    time_elapsed         | 449          |\n",
      "|    total_timesteps      | 323584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009948182 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.3         |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.22e+05     |\n",
      "|    n_updates            | 1570         |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    std                  | 0.919        |\n",
      "|    value_loss           | 6.71e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=2835.61 +/- 2159.64\n",
      "Episode length: 396.60 +/- 19.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 397         |\n",
      "|    mean_reward          | 2.84e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 325000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005242586 |\n",
      "|    clip_fraction        | 0.0353      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.31       |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.78e+05    |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    std                  | 0.921       |\n",
      "|    value_loss           | 6.42e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 376       |\n",
      "|    ep_rew_mean     | -3.94e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 720       |\n",
      "|    iterations      | 159       |\n",
      "|    time_elapsed    | 451       |\n",
      "|    total_timesteps | 325632    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 381          |\n",
      "|    ep_rew_mean          | -4.05e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 722          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 453          |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068849865 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.3         |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37e+03     |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | -0.00854     |\n",
      "|    std                  | 0.916        |\n",
      "|    value_loss           | 1.29e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 390          |\n",
      "|    ep_rew_mean          | -4.23e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 723          |\n",
      "|    iterations           | 161          |\n",
      "|    time_elapsed         | 455          |\n",
      "|    total_timesteps      | 329728       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034703112 |\n",
      "|    clip_fraction        | 0.00942      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.29        |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.74e+03     |\n",
      "|    n_updates            | 1600         |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    std                  | 0.914        |\n",
      "|    value_loss           | 4.3e+05      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=-47116.51 +/- 21184.09\n",
      "Episode length: 329.00 +/- 10.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 329          |\n",
      "|    mean_reward          | -4.71e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 330000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059023695 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.28        |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+03     |\n",
      "|    n_updates            | 1610         |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    std                  | 0.913        |\n",
      "|    value_loss           | 6.05e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 390      |\n",
      "|    ep_rew_mean     | -4.2e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 724      |\n",
      "|    iterations      | 162      |\n",
      "|    time_elapsed    | 458      |\n",
      "|    total_timesteps | 331776   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 394         |\n",
      "|    ep_rew_mean          | -3.31e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 725         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 460         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005052508 |\n",
      "|    clip_fraction        | 0.0267      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.24       |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.94e+03    |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    std                  | 0.897       |\n",
      "|    value_loss           | 3.22e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=390.15 +/- 4219.70\n",
      "Episode length: 442.60 +/- 49.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 443         |\n",
      "|    mean_reward          | 390         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 335000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006065755 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.18       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.62e+04    |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 1.01e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 396       |\n",
      "|    ep_rew_mean     | -4.72e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 725       |\n",
      "|    iterations      | 164       |\n",
      "|    time_elapsed    | 462       |\n",
      "|    total_timesteps | 335872    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 400           |\n",
      "|    ep_rew_mean          | -3.31e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 727           |\n",
      "|    iterations           | 165           |\n",
      "|    time_elapsed         | 464           |\n",
      "|    total_timesteps      | 337920        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019412834 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.15         |\n",
      "|    explained_variance   | 0.0667        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.88e+05      |\n",
      "|    n_updates            | 1640          |\n",
      "|    policy_gradient_loss | -0.000987     |\n",
      "|    std                  | 0.887         |\n",
      "|    value_loss           | 1.72e+07      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 408         |\n",
      "|    ep_rew_mean          | -3.14e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 728         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 466         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006618165 |\n",
      "|    clip_fraction        | 0.0294      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.794       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.41e+03    |\n",
      "|    n_updates            | 1650        |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    std                  | 0.888       |\n",
      "|    value_loss           | 1.76e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=1897.22 +/- 3415.52\n",
      "Episode length: 420.80 +/- 18.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 421         |\n",
      "|    mean_reward          | 1.9e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003521041 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.15       |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+04       |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    std                  | 0.884       |\n",
      "|    value_loss           | 2.5e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 413       |\n",
      "|    ep_rew_mean     | -3.21e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 728       |\n",
      "|    iterations      | 167       |\n",
      "|    time_elapsed    | 469       |\n",
      "|    total_timesteps | 342016    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 420         |\n",
      "|    ep_rew_mean          | -2.1e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 471         |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005666044 |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+03    |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    std                  | 0.882       |\n",
      "|    value_loss           | 5.89e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=-106165.14 +/- 8993.55\n",
      "Episode length: 416.80 +/- 15.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 417         |\n",
      "|    mean_reward          | -1.06e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 345000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009755669 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    std                  | 0.885       |\n",
      "|    value_loss           | 6.18e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 424       |\n",
      "|    ep_rew_mean     | -5.19e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 729       |\n",
      "|    iterations      | 169       |\n",
      "|    time_elapsed    | 474       |\n",
      "|    total_timesteps | 346112    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 431          |\n",
      "|    ep_rew_mean          | -8.08e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 731          |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 475          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002152714 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.14        |\n",
      "|    explained_variance   | 0.0747       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.72e+07     |\n",
      "|    n_updates            | 1690         |\n",
      "|    policy_gradient_loss | -0.000633    |\n",
      "|    std                  | 0.886        |\n",
      "|    value_loss           | 6.75e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-113900.91 +/- 12568.93\n",
      "Episode length: 435.80 +/- 19.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 436          |\n",
      "|    mean_reward          | -1.14e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 350000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.002622e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.14        |\n",
      "|    explained_variance   | 0.0701       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.47e+07     |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.000159    |\n",
      "|    std                  | 0.886        |\n",
      "|    value_loss           | 4.15e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 429       |\n",
      "|    ep_rew_mean     | -1.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 731       |\n",
      "|    iterations      | 171       |\n",
      "|    time_elapsed    | 478       |\n",
      "|    total_timesteps | 350208    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 434           |\n",
      "|    ep_rew_mean          | -1.73e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 732           |\n",
      "|    iterations           | 172           |\n",
      "|    time_elapsed         | 480           |\n",
      "|    total_timesteps      | 352256        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.4180626e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.14         |\n",
      "|    explained_variance   | 0.0951        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.14e+07      |\n",
      "|    n_updates            | 1710          |\n",
      "|    policy_gradient_loss | -0.000315     |\n",
      "|    std                  | 0.886         |\n",
      "|    value_loss           | 3.75e+07      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 437           |\n",
      "|    ep_rew_mean          | -1.88e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 732           |\n",
      "|    iterations           | 173           |\n",
      "|    time_elapsed         | 483           |\n",
      "|    total_timesteps      | 354304        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7037179e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.14         |\n",
      "|    explained_variance   | 0.0569        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.61e+07      |\n",
      "|    n_updates            | 1720          |\n",
      "|    policy_gradient_loss | -0.000209     |\n",
      "|    std                  | 0.886         |\n",
      "|    value_loss           | 1e+08         |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=-130699.11 +/- 5417.01\n",
      "Episode length: 485.80 +/- 16.80\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 486           |\n",
      "|    mean_reward          | -1.31e+05     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 355000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00037594745 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.14         |\n",
      "|    explained_variance   | 0.0825        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.57e+06      |\n",
      "|    n_updates            | 1730          |\n",
      "|    policy_gradient_loss | -0.00118      |\n",
      "|    std                  | 0.884         |\n",
      "|    value_loss           | 9.81e+06      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 439       |\n",
      "|    ep_rew_mean     | -2.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 730       |\n",
      "|    iterations      | 174       |\n",
      "|    time_elapsed    | 488       |\n",
      "|    total_timesteps | 356352    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 443           |\n",
      "|    ep_rew_mean          | -2.41e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 731           |\n",
      "|    iterations           | 175           |\n",
      "|    time_elapsed         | 490           |\n",
      "|    total_timesteps      | 358400        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.1917526e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.13         |\n",
      "|    explained_variance   | 0.0542        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.89e+06      |\n",
      "|    n_updates            | 1740          |\n",
      "|    policy_gradient_loss | -0.000902     |\n",
      "|    std                  | 0.884         |\n",
      "|    value_loss           | 1.54e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=-146886.84 +/- 11210.21\n",
      "Episode length: 562.20 +/- 43.26\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 562           |\n",
      "|    mean_reward          | -1.47e+05     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 360000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041837464 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.13         |\n",
      "|    explained_variance   | 0.0229        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.8e+07       |\n",
      "|    n_updates            | 1750          |\n",
      "|    policy_gradient_loss | -0.00102      |\n",
      "|    std                  | 0.884         |\n",
      "|    value_loss           | 6.32e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 447       |\n",
      "|    ep_rew_mean     | -2.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 730       |\n",
      "|    iterations      | 176       |\n",
      "|    time_elapsed    | 493       |\n",
      "|    total_timesteps | 360448    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 449          |\n",
      "|    ep_rew_mean          | -2.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 177          |\n",
      "|    time_elapsed         | 496          |\n",
      "|    total_timesteps      | 362496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013138362 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.14        |\n",
      "|    explained_variance   | 0.0754       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+06      |\n",
      "|    n_updates            | 1760         |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    std                  | 0.887        |\n",
      "|    value_loss           | 1.03e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 452         |\n",
      "|    ep_rew_mean          | -2.48e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004498827 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.13       |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 757         |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    std                  | 0.883       |\n",
      "|    value_loss           | 1.9e+05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=4255.52 +/- 2248.17\n",
      "Episode length: 540.20 +/- 50.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 540          |\n",
      "|    mean_reward          | 4.26e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 365000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058752373 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.11        |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.49e+05     |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    std                  | 0.88         |\n",
      "|    value_loss           | 5.2e+04      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 463       |\n",
      "|    ep_rew_mean     | -2.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 729       |\n",
      "|    iterations      | 179       |\n",
      "|    time_elapsed    | 502       |\n",
      "|    total_timesteps | 366592    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 468         |\n",
      "|    ep_rew_mean          | -2.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 730         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 504         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005161476 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.1        |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.23e+03    |\n",
      "|    n_updates            | 1790        |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    std                  | 0.877       |\n",
      "|    value_loss           | 4.17e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=370000, episode_reward=4252.24 +/- 3233.83\n",
      "Episode length: 480.20 +/- 34.14\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 480          |\n",
      "|    mean_reward          | 4.25e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 370000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065744896 |\n",
      "|    clip_fraction        | 0.0436       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.1         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 707          |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.00776     |\n",
      "|    std                  | 0.883        |\n",
      "|    value_loss           | 1.78e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 466       |\n",
      "|    ep_rew_mean     | -2.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 729       |\n",
      "|    iterations      | 181       |\n",
      "|    time_elapsed    | 508       |\n",
      "|    total_timesteps | 370688    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 465          |\n",
      "|    ep_rew_mean          | -2.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 730          |\n",
      "|    iterations           | 182          |\n",
      "|    time_elapsed         | 510          |\n",
      "|    total_timesteps      | 372736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063030776 |\n",
      "|    clip_fraction        | 0.0508       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.11        |\n",
      "|    explained_variance   | 0.724        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.05e+03     |\n",
      "|    n_updates            | 1810         |\n",
      "|    policy_gradient_loss | -0.00759     |\n",
      "|    std                  | 0.88         |\n",
      "|    value_loss           | 8.53e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 461         |\n",
      "|    ep_rew_mean          | -2.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 731         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 512         |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010083052 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5.07       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    std                  | 0.868       |\n",
      "|    value_loss           | 1.79e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=705.72 +/- 2279.32\n",
      "Episode length: 391.40 +/- 20.02\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 391           |\n",
      "|    mean_reward          | 706           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 375000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00038445977 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -5.04         |\n",
      "|    explained_variance   | 0.0952        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.3e+06       |\n",
      "|    n_updates            | 1830          |\n",
      "|    policy_gradient_loss | -0.000231     |\n",
      "|    std                  | 0.868         |\n",
      "|    value_loss           | 1.05e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 462       |\n",
      "|    ep_rew_mean     | -2.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 731       |\n",
      "|    iterations      | 184       |\n",
      "|    time_elapsed    | 515       |\n",
      "|    total_timesteps | 376832    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 458        |\n",
      "|    ep_rew_mean          | -2.62e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 732        |\n",
      "|    iterations           | 185        |\n",
      "|    time_elapsed         | 517        |\n",
      "|    total_timesteps      | 378880     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00143669 |\n",
      "|    clip_fraction        | 0.00117    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.03      |\n",
      "|    explained_variance   | 0.346      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.43e+04   |\n",
      "|    n_updates            | 1840       |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    std                  | 0.867      |\n",
      "|    value_loss           | 3.34e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=3714.05 +/- 91.30\n",
      "Episode length: 337.40 +/- 1.85\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 337        |\n",
      "|    mean_reward          | 3.71e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 380000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00593199 |\n",
      "|    clip_fraction        | 0.0332     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -5.03      |\n",
      "|    explained_variance   | 0.573      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 386        |\n",
      "|    n_updates            | 1850       |\n",
      "|    policy_gradient_loss | -0.00588   |\n",
      "|    std                  | 0.868      |\n",
      "|    value_loss           | 1.65e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 458       |\n",
      "|    ep_rew_mean     | -2.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 729       |\n",
      "|    iterations      | 186       |\n",
      "|    time_elapsed    | 522       |\n",
      "|    total_timesteps | 380928    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 457          |\n",
      "|    ep_rew_mean          | -2.51e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 729          |\n",
      "|    iterations           | 187          |\n",
      "|    time_elapsed         | 524          |\n",
      "|    total_timesteps      | 382976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053520883 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -5.03        |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.06e+04     |\n",
      "|    n_updates            | 1860         |\n",
      "|    policy_gradient_loss | -0.0079      |\n",
      "|    std                  | 0.867        |\n",
      "|    value_loss           | 9.32e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=3164.41 +/- 2647.21\n",
      "Episode length: 375.40 +/- 13.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 375         |\n",
      "|    mean_reward          | 3.16e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 385000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008248672 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -5          |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    std                  | 0.857       |\n",
      "|    value_loss           | 1.58e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 452       |\n",
      "|    ep_rew_mean     | -2.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 727       |\n",
      "|    iterations      | 188       |\n",
      "|    time_elapsed    | 529       |\n",
      "|    total_timesteps | 385024    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 450          |\n",
      "|    ep_rew_mean          | -2.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 727          |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 531          |\n",
      "|    total_timesteps      | 387072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017899122 |\n",
      "|    clip_fraction        | 0.00557      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.98        |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58e+06     |\n",
      "|    n_updates            | 1880         |\n",
      "|    policy_gradient_loss | -0.00373     |\n",
      "|    std                  | 0.858        |\n",
      "|    value_loss           | 5.86e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 438         |\n",
      "|    ep_rew_mean          | -2.65e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 727         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 534         |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008569619 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.98       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.07e+04    |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.858       |\n",
      "|    value_loss           | 9.81e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=2556.20 +/- 3170.08\n",
      "Episode length: 440.40 +/- 20.82\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 440          |\n",
      "|    mean_reward          | 2.56e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 390000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002938837 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.98        |\n",
      "|    explained_variance   | 0.0846       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.49e+06     |\n",
      "|    n_updates            | 1900         |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    std                  | 0.858        |\n",
      "|    value_loss           | 1.5e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 430       |\n",
      "|    ep_rew_mean     | -2.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 726       |\n",
      "|    iterations      | 191       |\n",
      "|    time_elapsed    | 538       |\n",
      "|    total_timesteps | 391168    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 425          |\n",
      "|    ep_rew_mean          | -1.78e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 725          |\n",
      "|    iterations           | 192          |\n",
      "|    time_elapsed         | 541          |\n",
      "|    total_timesteps      | 393216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057338905 |\n",
      "|    clip_fraction        | 0.0313       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.96        |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 1910         |\n",
      "|    policy_gradient_loss | -0.00777     |\n",
      "|    std                  | 0.848        |\n",
      "|    value_loss           | 1.93e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=4073.20 +/- 3352.28\n",
      "Episode length: 455.80 +/- 28.64\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 456           |\n",
      "|    mean_reward          | 4.07e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 395000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00056632847 |\n",
      "|    clip_fraction        | 0.002         |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.93         |\n",
      "|    explained_variance   | 0.0705        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.31e+07      |\n",
      "|    n_updates            | 1920          |\n",
      "|    policy_gradient_loss | -0.00306      |\n",
      "|    std                  | 0.847         |\n",
      "|    value_loss           | 4e+07         |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 429       |\n",
      "|    ep_rew_mean     | -1.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 724       |\n",
      "|    iterations      | 193       |\n",
      "|    time_elapsed    | 545       |\n",
      "|    total_timesteps | 395264    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 435         |\n",
      "|    ep_rew_mean          | -1.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 724         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 548         |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007857264 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.93       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.18e+05    |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    std                  | 0.846       |\n",
      "|    value_loss           | 1e+05       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 432          |\n",
      "|    ep_rew_mean          | -1.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 725          |\n",
      "|    iterations           | 195          |\n",
      "|    time_elapsed         | 550          |\n",
      "|    total_timesteps      | 399360       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034053884 |\n",
      "|    clip_fraction        | 0.0134       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.92        |\n",
      "|    explained_variance   | 0.503        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.24e+03     |\n",
      "|    n_updates            | 1940         |\n",
      "|    policy_gradient_loss | -0.0052      |\n",
      "|    std                  | 0.845        |\n",
      "|    value_loss           | 2.8e+05      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=-156936.25 +/- 201350.92\n",
      "Episode length: 567.00 +/- 82.10\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 567          |\n",
      "|    mean_reward          | -1.57e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 400000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081600705 |\n",
      "|    clip_fraction        | 0.0592       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.91        |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.3e+04      |\n",
      "|    n_updates            | 1950         |\n",
      "|    policy_gradient_loss | -0.0092      |\n",
      "|    std                  | 0.84         |\n",
      "|    value_loss           | 1.3e+05      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 427      |\n",
      "|    ep_rew_mean     | -1.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 723      |\n",
      "|    iterations      | 196      |\n",
      "|    time_elapsed    | 554      |\n",
      "|    total_timesteps | 401408   |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 430           |\n",
      "|    ep_rew_mean          | -1.49e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 723           |\n",
      "|    iterations           | 197           |\n",
      "|    time_elapsed         | 557           |\n",
      "|    total_timesteps      | 403456        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00010324479 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.89         |\n",
      "|    explained_variance   | 0.0772        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.14e+07      |\n",
      "|    n_updates            | 1960          |\n",
      "|    policy_gradient_loss | -0.000872     |\n",
      "|    std                  | 0.839         |\n",
      "|    value_loss           | 1.08e+08      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=770.84 +/- 2811.38\n",
      "Episode length: 544.00 +/- 14.99\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 544          |\n",
      "|    mean_reward          | 771          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 405000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008984242 |\n",
      "|    clip_fraction        | 0.00122      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | 0.0625       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.33e+07     |\n",
      "|    n_updates            | 1970         |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    std                  | 0.839        |\n",
      "|    value_loss           | 1.13e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 429       |\n",
      "|    ep_rew_mean     | -1.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 721       |\n",
      "|    iterations      | 198       |\n",
      "|    time_elapsed    | 561       |\n",
      "|    total_timesteps | 405504    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 422          |\n",
      "|    ep_rew_mean          | -1.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 722          |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 564          |\n",
      "|    total_timesteps      | 407552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003324887 |\n",
      "|    clip_fraction        | 0.000488     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | 0.0767       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+07     |\n",
      "|    n_updates            | 1980         |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    std                  | 0.839        |\n",
      "|    value_loss           | 3.25e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 423          |\n",
      "|    ep_rew_mean          | -1.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 722          |\n",
      "|    iterations           | 200          |\n",
      "|    time_elapsed         | 566          |\n",
      "|    total_timesteps      | 409600       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.150484e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.89        |\n",
      "|    explained_variance   | 0.0672       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.2e+07      |\n",
      "|    n_updates            | 1990         |\n",
      "|    policy_gradient_loss | -0.000364    |\n",
      "|    std                  | 0.839        |\n",
      "|    value_loss           | 3.68e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=5574.96 +/- 3189.10\n",
      "Episode length: 519.20 +/- 20.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 519         |\n",
      "|    mean_reward          | 5.57e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 410000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002034457 |\n",
      "|    clip_fraction        | 0.000977    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.89       |\n",
      "|    explained_variance   | 0.541       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.72e+03    |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    std                  | 0.838       |\n",
      "|    value_loss           | 7.76e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 427       |\n",
      "|    ep_rew_mean     | -1.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 721       |\n",
      "|    iterations      | 201       |\n",
      "|    time_elapsed    | 570       |\n",
      "|    total_timesteps | 411648    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 427           |\n",
      "|    ep_rew_mean          | -1.96e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 720           |\n",
      "|    iterations           | 202           |\n",
      "|    time_elapsed         | 573           |\n",
      "|    total_timesteps      | 413696        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.9667946e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.88         |\n",
      "|    explained_variance   | 0.0545        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.58e+04      |\n",
      "|    n_updates            | 2010          |\n",
      "|    policy_gradient_loss | -0.000869     |\n",
      "|    std                  | 0.837         |\n",
      "|    value_loss           | 2.95e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=5130.12 +/- 3703.93\n",
      "Episode length: 617.80 +/- 36.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 618          |\n",
      "|    mean_reward          | 5.13e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 415000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026378748 |\n",
      "|    clip_fraction        | 0.00361      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.88        |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06e+06     |\n",
      "|    n_updates            | 2020         |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    std                  | 0.837        |\n",
      "|    value_loss           | 9.9e+05      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 429       |\n",
      "|    ep_rew_mean     | -1.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 717       |\n",
      "|    iterations      | 203       |\n",
      "|    time_elapsed    | 579       |\n",
      "|    total_timesteps | 415744    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 438          |\n",
      "|    ep_rew_mean          | -1.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 204          |\n",
      "|    time_elapsed         | 583          |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012639647 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.87        |\n",
      "|    explained_variance   | 0.318        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.39e+04     |\n",
      "|    n_updates            | 2030         |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    std                  | 0.835        |\n",
      "|    value_loss           | 6.16e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 442         |\n",
      "|    ep_rew_mean          | -1.84e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 717         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 585         |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008382693 |\n",
      "|    clip_fraction        | 0.0495      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.83       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 354         |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    std                  | 0.82        |\n",
      "|    value_loss           | 4.72e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=4857.02 +/- 2534.92\n",
      "Episode length: 618.80 +/- 49.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 619         |\n",
      "|    mean_reward          | 4.86e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 420000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008291058 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.78       |\n",
      "|    explained_variance   | 0.734       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 734         |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.00744    |\n",
      "|    std                  | 0.819       |\n",
      "|    value_loss           | 7.34e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 447       |\n",
      "|    ep_rew_mean     | -1.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 715       |\n",
      "|    iterations      | 206       |\n",
      "|    time_elapsed    | 589       |\n",
      "|    total_timesteps | 421888    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 454          |\n",
      "|    ep_rew_mean          | -1.81e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 716          |\n",
      "|    iterations           | 207          |\n",
      "|    time_elapsed         | 591          |\n",
      "|    total_timesteps      | 423936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051344694 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.76        |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 806          |\n",
      "|    n_updates            | 2060         |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    std                  | 0.812        |\n",
      "|    value_loss           | 5.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=2040.63 +/- 8887.04\n",
      "Episode length: 541.00 +/- 30.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 541         |\n",
      "|    mean_reward          | 2.04e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 425000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005831346 |\n",
      "|    clip_fraction        | 0.0237      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.72       |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+03    |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    std                  | 0.807       |\n",
      "|    value_loss           | 3.73e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 456      |\n",
      "|    ep_rew_mean     | -2e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 709      |\n",
      "|    iterations      | 208      |\n",
      "|    time_elapsed    | 600      |\n",
      "|    total_timesteps | 425984   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 455          |\n",
      "|    ep_rew_mean          | -2.14e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 703          |\n",
      "|    iterations           | 209          |\n",
      "|    time_elapsed         | 608          |\n",
      "|    total_timesteps      | 428032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007878946 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.71        |\n",
      "|    explained_variance   | 0.0767       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+07     |\n",
      "|    n_updates            | 2080         |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    std                  | 0.806        |\n",
      "|    value_loss           | 3.74e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=3749.92 +/- 3828.79\n",
      "Episode length: 527.00 +/- 12.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 527          |\n",
      "|    mean_reward          | 3.75e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 430000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014500899 |\n",
      "|    clip_fraction        | 0.00483      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.7         |\n",
      "|    explained_variance   | 0.0973       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.57e+06     |\n",
      "|    n_updates            | 2090         |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    std                  | 0.806        |\n",
      "|    value_loss           | 2e+07        |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 458       |\n",
      "|    ep_rew_mean     | -2.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 210       |\n",
      "|    time_elapsed    | 620       |\n",
      "|    total_timesteps | 430080    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 451         |\n",
      "|    ep_rew_mean          | -2.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 693         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 622         |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001259658 |\n",
      "|    clip_fraction        | 0.00366     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.0875      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+07    |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    std                  | 0.806       |\n",
      "|    value_loss           | 3.12e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 456         |\n",
      "|    ep_rew_mean          | -2.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 694         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 624         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000550141 |\n",
      "|    clip_fraction        | 0.000391    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.7        |\n",
      "|    explained_variance   | 0.0826      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.96e+07    |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    std                  | 0.805       |\n",
      "|    value_loss           | 9.12e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=435000, episode_reward=3935.42 +/- 2381.21\n",
      "Episode length: 545.60 +/- 9.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 546          |\n",
      "|    mean_reward          | 3.94e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 435000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016380874 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.7         |\n",
      "|    explained_variance   | 0.0831       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 2120         |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    std                  | 0.804        |\n",
      "|    value_loss           | 3e+07        |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 452       |\n",
      "|    ep_rew_mean     | -3.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 694       |\n",
      "|    iterations      | 213       |\n",
      "|    time_elapsed    | 627       |\n",
      "|    total_timesteps | 436224    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 458          |\n",
      "|    ep_rew_mean          | -3.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 214          |\n",
      "|    time_elapsed         | 629          |\n",
      "|    total_timesteps      | 438272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006317307 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.7         |\n",
      "|    explained_variance   | 0.0839       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.27e+07     |\n",
      "|    n_updates            | 2130         |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    std                  | 0.805        |\n",
      "|    value_loss           | 9.61e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=605.19 +/- 4074.74\n",
      "Episode length: 534.20 +/- 18.76\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 534           |\n",
      "|    mean_reward          | 605           |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 440000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087482063 |\n",
      "|    clip_fraction        | 0.00313       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.7          |\n",
      "|    explained_variance   | 0.0853        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.17e+07      |\n",
      "|    n_updates            | 2140          |\n",
      "|    policy_gradient_loss | -0.00237      |\n",
      "|    std                  | 0.807         |\n",
      "|    value_loss           | 4.37e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 449       |\n",
      "|    ep_rew_mean     | -3.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 695       |\n",
      "|    iterations      | 215       |\n",
      "|    time_elapsed    | 632       |\n",
      "|    total_timesteps | 440320    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 444           |\n",
      "|    ep_rew_mean          | -3.77e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 696           |\n",
      "|    iterations           | 216           |\n",
      "|    time_elapsed         | 634           |\n",
      "|    total_timesteps      | 442368        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00022312682 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.71         |\n",
      "|    explained_variance   | 0.089         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.05e+07      |\n",
      "|    n_updates            | 2150          |\n",
      "|    policy_gradient_loss | -0.0012       |\n",
      "|    std                  | 0.807         |\n",
      "|    value_loss           | 9.92e+07      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 449          |\n",
      "|    ep_rew_mean          | -3.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 217          |\n",
      "|    time_elapsed         | 636          |\n",
      "|    total_timesteps      | 444416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075631994 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.7         |\n",
      "|    explained_variance   | 0.868        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+03     |\n",
      "|    n_updates            | 2160         |\n",
      "|    policy_gradient_loss | -0.00666     |\n",
      "|    std                  | 0.803        |\n",
      "|    value_loss           | 8.56e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=7581.99 +/- 2390.07\n",
      "Episode length: 760.80 +/- 51.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 761         |\n",
      "|    mean_reward          | 7.58e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 445000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011989037 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.68       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.801       |\n",
      "|    value_loss           | 1.33e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 451       |\n",
      "|    ep_rew_mean     | -3.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 697       |\n",
      "|    iterations      | 218       |\n",
      "|    time_elapsed    | 640       |\n",
      "|    total_timesteps | 446464    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 460           |\n",
      "|    ep_rew_mean          | -4.04e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 698           |\n",
      "|    iterations           | 219           |\n",
      "|    time_elapsed         | 642           |\n",
      "|    total_timesteps      | 448512        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00052892294 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.67         |\n",
      "|    explained_variance   | 0.0988        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.75e+07      |\n",
      "|    n_updates            | 2180          |\n",
      "|    policy_gradient_loss | -0.000863     |\n",
      "|    std                  | 0.801         |\n",
      "|    value_loss           | 1.31e+08      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=8249.64 +/- 1476.17\n",
      "Episode length: 775.00 +/- 68.59\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 775          |\n",
      "|    mean_reward          | 8.25e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 450000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017824932 |\n",
      "|    clip_fraction        | 0.00874      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.67        |\n",
      "|    explained_variance   | 0.0964       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.19e+07     |\n",
      "|    n_updates            | 2190         |\n",
      "|    policy_gradient_loss | -0.00764     |\n",
      "|    std                  | 0.801        |\n",
      "|    value_loss           | 4.12e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 463       |\n",
      "|    ep_rew_mean     | -4.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 696       |\n",
      "|    iterations      | 220       |\n",
      "|    time_elapsed    | 646       |\n",
      "|    total_timesteps | 450560    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 483          |\n",
      "|    ep_rew_mean          | -3.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 221          |\n",
      "|    time_elapsed         | 649          |\n",
      "|    total_timesteps      | 452608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018688987 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.66        |\n",
      "|    explained_variance   | 0.568        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.9e+04      |\n",
      "|    n_updates            | 2200         |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    std                  | 0.801        |\n",
      "|    value_loss           | 1.61e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 489          |\n",
      "|    ep_rew_mean          | -3.41e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 222          |\n",
      "|    time_elapsed         | 653          |\n",
      "|    total_timesteps      | 454656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022490004 |\n",
      "|    clip_fraction        | 0.00493      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.66        |\n",
      "|    explained_variance   | 0.73         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+04     |\n",
      "|    n_updates            | 2210         |\n",
      "|    policy_gradient_loss | -0.00437     |\n",
      "|    std                  | 0.799        |\n",
      "|    value_loss           | 1.02e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=4861.61 +/- 2608.25\n",
      "Episode length: 627.20 +/- 15.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 627          |\n",
      "|    mean_reward          | 4.86e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 455000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060136775 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.65        |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+03     |\n",
      "|    n_updates            | 2220         |\n",
      "|    policy_gradient_loss | -0.00673     |\n",
      "|    std                  | 0.798        |\n",
      "|    value_loss           | 5.73e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 490       |\n",
      "|    ep_rew_mean     | -3.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 694       |\n",
      "|    iterations      | 223       |\n",
      "|    time_elapsed    | 657       |\n",
      "|    total_timesteps | 456704    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 497          |\n",
      "|    ep_rew_mean          | -3.83e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 660          |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012873751 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.65        |\n",
      "|    explained_variance   | 0.0767       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.46e+07     |\n",
      "|    n_updates            | 2230         |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    std                  | 0.798        |\n",
      "|    value_loss           | 1.31e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=-144773.38 +/- 76674.78\n",
      "Episode length: 543.40 +/- 41.96\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 543          |\n",
      "|    mean_reward          | -1.45e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 460000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031338509 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.77e+05     |\n",
      "|    n_updates            | 2240         |\n",
      "|    policy_gradient_loss | -0.00491     |\n",
      "|    std                  | 0.796        |\n",
      "|    value_loss           | 2.15e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 492       |\n",
      "|    ep_rew_mean     | -4.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 225       |\n",
      "|    time_elapsed    | 664       |\n",
      "|    total_timesteps | 460800    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 490          |\n",
      "|    ep_rew_mean          | -5.33e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 226          |\n",
      "|    time_elapsed         | 666          |\n",
      "|    total_timesteps      | 462848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008412123 |\n",
      "|    clip_fraction        | 0.00107      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.102        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.89e+07     |\n",
      "|    n_updates            | 2250         |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    std                  | 0.796        |\n",
      "|    value_loss           | 1.69e+08     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 481           |\n",
      "|    ep_rew_mean          | -6.31e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 694           |\n",
      "|    iterations           | 227           |\n",
      "|    time_elapsed         | 669           |\n",
      "|    total_timesteps      | 464896        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00013447372 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.64         |\n",
      "|    explained_variance   | 0.093         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.65e+07      |\n",
      "|    n_updates            | 2260          |\n",
      "|    policy_gradient_loss | -0.000721     |\n",
      "|    std                  | 0.796         |\n",
      "|    value_loss           | 1.53e+08      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=-117506.46 +/- 104963.00\n",
      "Episode length: 594.60 +/- 66.70\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 595           |\n",
      "|    mean_reward          | -1.18e+05     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 465000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016631783 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.64         |\n",
      "|    explained_variance   | 0.0803        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.46e+08      |\n",
      "|    n_updates            | 2270          |\n",
      "|    policy_gradient_loss | -0.000719     |\n",
      "|    std                  | 0.796         |\n",
      "|    value_loss           | 2.1e+08       |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 491      |\n",
      "|    ep_rew_mean     | -6.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 693      |\n",
      "|    iterations      | 228      |\n",
      "|    time_elapsed    | 673      |\n",
      "|    total_timesteps | 466944   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 495          |\n",
      "|    ep_rew_mean          | -7.2e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 674          |\n",
      "|    total_timesteps      | 468992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019892557 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.104        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.41e+07     |\n",
      "|    n_updates            | 2280         |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    std                  | 0.797        |\n",
      "|    value_loss           | 3.26e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=3246.87 +/- 3833.37\n",
      "Episode length: 628.40 +/- 17.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 628          |\n",
      "|    mean_reward          | 3.25e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 470000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018431472 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.0856       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.92e+07     |\n",
      "|    n_updates            | 2290         |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    std                  | 0.797        |\n",
      "|    value_loss           | 1.47e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 487       |\n",
      "|    ep_rew_mean     | -7.71e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 694       |\n",
      "|    iterations      | 230       |\n",
      "|    time_elapsed    | 678       |\n",
      "|    total_timesteps | 471040    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 487           |\n",
      "|    ep_rew_mean          | -7.73e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 695           |\n",
      "|    iterations           | 231           |\n",
      "|    time_elapsed         | 680           |\n",
      "|    total_timesteps      | 473088        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027061213 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.64         |\n",
      "|    explained_variance   | 0.0808        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.49e+07      |\n",
      "|    n_updates            | 2300          |\n",
      "|    policy_gradient_loss | -0.00178      |\n",
      "|    std                  | 0.797         |\n",
      "|    value_loss           | 1.03e+08      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=4272.51 +/- 3274.97\n",
      "Episode length: 595.60 +/- 13.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 596          |\n",
      "|    mean_reward          | 4.27e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 475000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010517352 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.64        |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05e+04     |\n",
      "|    n_updates            | 2310         |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    std                  | 0.797        |\n",
      "|    value_loss           | 1.05e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 491       |\n",
      "|    ep_rew_mean     | -7.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 232       |\n",
      "|    time_elapsed    | 685       |\n",
      "|    total_timesteps | 475136    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 497          |\n",
      "|    ep_rew_mean          | -7.69e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 693          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 687          |\n",
      "|    total_timesteps      | 477184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043985303 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.63        |\n",
      "|    explained_variance   | 0.803        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.74e+03     |\n",
      "|    n_updates            | 2320         |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    std                  | 0.791        |\n",
      "|    value_loss           | 3.8e+04      |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 502           |\n",
      "|    ep_rew_mean          | -7.67e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 694           |\n",
      "|    iterations           | 234           |\n",
      "|    time_elapsed         | 689           |\n",
      "|    total_timesteps      | 479232        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018566733 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.61         |\n",
      "|    explained_variance   | 0.0728        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.15e+07      |\n",
      "|    n_updates            | 2330          |\n",
      "|    policy_gradient_loss | -0.000631     |\n",
      "|    std                  | 0.79          |\n",
      "|    value_loss           | 6.94e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=2673.05 +/- 3950.51\n",
      "Episode length: 585.00 +/- 18.19\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 585          |\n",
      "|    mean_reward          | 2.67e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025415693 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.61        |\n",
      "|    explained_variance   | 0.091        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.3e+07      |\n",
      "|    n_updates            | 2340         |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    std                  | 0.791        |\n",
      "|    value_loss           | 3.59e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 504       |\n",
      "|    ep_rew_mean     | -7.84e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 235       |\n",
      "|    time_elapsed    | 693       |\n",
      "|    total_timesteps | 481280    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 502          |\n",
      "|    ep_rew_mean          | -7.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 694          |\n",
      "|    iterations           | 236          |\n",
      "|    time_elapsed         | 695          |\n",
      "|    total_timesteps      | 483328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028397758 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.61        |\n",
      "|    explained_variance   | 0.0846       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.18e+07     |\n",
      "|    n_updates            | 2350         |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    std                  | 0.789        |\n",
      "|    value_loss           | 8.77e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=485000, episode_reward=2360.87 +/- 3569.98\n",
      "Episode length: 599.80 +/- 31.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 600          |\n",
      "|    mean_reward          | 2.36e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 485000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003948383 |\n",
      "|    clip_fraction        | 0.002        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.6         |\n",
      "|    explained_variance   | 0.0798       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.43e+07     |\n",
      "|    n_updates            | 2360         |\n",
      "|    policy_gradient_loss | -0.00205     |\n",
      "|    std                  | 0.789        |\n",
      "|    value_loss           | 3.77e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 505       |\n",
      "|    ep_rew_mean     | -8.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 694       |\n",
      "|    iterations      | 237       |\n",
      "|    time_elapsed    | 698       |\n",
      "|    total_timesteps | 485376    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 505          |\n",
      "|    ep_rew_mean          | -8.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 695          |\n",
      "|    iterations           | 238          |\n",
      "|    time_elapsed         | 700          |\n",
      "|    total_timesteps      | 487424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005399784 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.61        |\n",
      "|    explained_variance   | 0.0909       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.01e+07     |\n",
      "|    n_updates            | 2370         |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    std                  | 0.79         |\n",
      "|    value_loss           | 1e+08        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 511           |\n",
      "|    ep_rew_mean          | -8.03e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 696           |\n",
      "|    iterations           | 239           |\n",
      "|    time_elapsed         | 702           |\n",
      "|    total_timesteps      | 489472        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00027043218 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.61         |\n",
      "|    explained_variance   | 0.0903        |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.46e+07      |\n",
      "|    n_updates            | 2380          |\n",
      "|    policy_gradient_loss | -0.000848     |\n",
      "|    std                  | 0.79          |\n",
      "|    value_loss           | 5.35e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=4659.77 +/- 2795.02\n",
      "Episode length: 587.00 +/- 21.67\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 587          |\n",
      "|    mean_reward          | 4.66e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 490000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049474724 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.61        |\n",
      "|    explained_variance   | 0.853        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.32e+04     |\n",
      "|    n_updates            | 2390         |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    std                  | 0.787        |\n",
      "|    value_loss           | 3.25e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 524       |\n",
      "|    ep_rew_mean     | -7.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 696       |\n",
      "|    iterations      | 240       |\n",
      "|    time_elapsed    | 705       |\n",
      "|    total_timesteps | 491520    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 527          |\n",
      "|    ep_rew_mean          | -7.28e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 697          |\n",
      "|    iterations           | 241          |\n",
      "|    time_elapsed         | 707          |\n",
      "|    total_timesteps      | 493568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063517527 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.58        |\n",
      "|    explained_variance   | 0.768        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 707          |\n",
      "|    n_updates            | 2400         |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    std                  | 0.782        |\n",
      "|    value_loss           | 4.82e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=2439.60 +/- 4463.72\n",
      "Episode length: 643.80 +/- 33.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 644          |\n",
      "|    mean_reward          | 2.44e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 495000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049923407 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.54        |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.13e+03     |\n",
      "|    n_updates            | 2410         |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    std                  | 0.775        |\n",
      "|    value_loss           | 2.07e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 535       |\n",
      "|    ep_rew_mean     | -7.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 697       |\n",
      "|    iterations      | 242       |\n",
      "|    time_elapsed    | 711       |\n",
      "|    total_timesteps | 495616    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 535          |\n",
      "|    ep_rew_mean          | -7.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 698          |\n",
      "|    iterations           | 243          |\n",
      "|    time_elapsed         | 712          |\n",
      "|    total_timesteps      | 497664       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052561415 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.52        |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.68e+05     |\n",
      "|    n_updates            | 2420         |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    std                  | 0.776        |\n",
      "|    value_loss           | 5.57e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 525         |\n",
      "|    ep_rew_mean          | -7.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 699         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 714         |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005018284 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.121       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27e+07    |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    std                  | 0.778       |\n",
      "|    value_loss           | 2.29e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500000, episode_reward=7729.47 +/- 2035.18\n",
      "Episode length: 731.00 +/- 13.16\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 731           |\n",
      "|    mean_reward          | 7.73e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 500000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00051179074 |\n",
      "|    clip_fraction        | 0.00146       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.54         |\n",
      "|    explained_variance   | 0.103         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.53e+07      |\n",
      "|    n_updates            | 2440          |\n",
      "|    policy_gradient_loss | -0.00253      |\n",
      "|    std                  | 0.778         |\n",
      "|    value_loss           | 1.02e+08      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 522       |\n",
      "|    ep_rew_mean     | -7.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 698       |\n",
      "|    iterations      | 245       |\n",
      "|    time_elapsed    | 718       |\n",
      "|    total_timesteps | 501760    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 487           |\n",
      "|    ep_rew_mean          | -8.94e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 699           |\n",
      "|    iterations           | 246           |\n",
      "|    time_elapsed         | 720           |\n",
      "|    total_timesteps      | 503808        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015166309 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.54         |\n",
      "|    explained_variance   | 0.229         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.94e+06      |\n",
      "|    n_updates            | 2450          |\n",
      "|    policy_gradient_loss | -0.000466     |\n",
      "|    std                  | 0.778         |\n",
      "|    value_loss           | 2.9e+06       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=505000, episode_reward=7413.42 +/- 2758.34\n",
      "Episode length: 716.60 +/- 35.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 717          |\n",
      "|    mean_reward          | 7.41e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 505000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006339846 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.54        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+08     |\n",
      "|    n_updates            | 2460         |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    std                  | 0.778        |\n",
      "|    value_loss           | 3.46e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 496       |\n",
      "|    ep_rew_mean     | -8.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 696       |\n",
      "|    iterations      | 247       |\n",
      "|    time_elapsed    | 725       |\n",
      "|    total_timesteps | 505856    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 495          |\n",
      "|    ep_rew_mean          | -8.41e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 697          |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 727          |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005562026 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.54        |\n",
      "|    explained_variance   | 0.108        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+07     |\n",
      "|    n_updates            | 2470         |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    std                  | 0.778        |\n",
      "|    value_loss           | 2.87e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 500           |\n",
      "|    ep_rew_mean          | -7.96e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 698           |\n",
      "|    iterations           | 249           |\n",
      "|    time_elapsed         | 729           |\n",
      "|    total_timesteps      | 509952        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063653087 |\n",
      "|    clip_fraction        | 0.00117       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.54         |\n",
      "|    explained_variance   | 0.233         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.45e+03      |\n",
      "|    n_updates            | 2480          |\n",
      "|    policy_gradient_loss | -0.00285      |\n",
      "|    std                  | 0.777         |\n",
      "|    value_loss           | 2.88e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=8127.10 +/- 311.58\n",
      "Episode length: 691.20 +/- 20.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 691         |\n",
      "|    mean_reward          | 8.13e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 510000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005117704 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.589       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05e+03    |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    std                  | 0.775       |\n",
      "|    value_loss           | 2.02e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 506       |\n",
      "|    ep_rew_mean     | -7.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 698       |\n",
      "|    iterations      | 250       |\n",
      "|    time_elapsed    | 733       |\n",
      "|    total_timesteps | 512000    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 506         |\n",
      "|    ep_rew_mean          | -7.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 698         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 735         |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005632135 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.53       |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    std                  | 0.775       |\n",
      "|    value_loss           | 3.67e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=515000, episode_reward=7672.03 +/- 342.26\n",
      "Episode length: 708.80 +/- 21.76\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 709           |\n",
      "|    mean_reward          | 7.67e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 515000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00034187385 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.52         |\n",
      "|    explained_variance   | 0.11          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1e+08         |\n",
      "|    n_updates            | 2510          |\n",
      "|    policy_gradient_loss | -0.000146     |\n",
      "|    std                  | 0.775         |\n",
      "|    value_loss           | 1.98e+08      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 517      |\n",
      "|    ep_rew_mean     | -7e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 697      |\n",
      "|    iterations      | 252      |\n",
      "|    time_elapsed    | 740      |\n",
      "|    total_timesteps | 516096   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 510          |\n",
      "|    ep_rew_mean          | -6.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 696          |\n",
      "|    iterations           | 253          |\n",
      "|    time_elapsed         | 743          |\n",
      "|    total_timesteps      | 518144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085090455 |\n",
      "|    clip_fraction        | 0.0527       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.5         |\n",
      "|    explained_variance   | 0.694        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 994          |\n",
      "|    n_updates            | 2520         |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    std                  | 0.767        |\n",
      "|    value_loss           | 7.13e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-53323.46 +/- 116801.94\n",
      "Episode length: 726.60 +/- 282.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 727          |\n",
      "|    mean_reward          | -5.33e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 520000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013789558 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.48        |\n",
      "|    explained_variance   | 0.109        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.62e+07     |\n",
      "|    n_updates            | 2530         |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    std                  | 0.766        |\n",
      "|    value_loss           | 9.27e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 515       |\n",
      "|    ep_rew_mean     | -7.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 693       |\n",
      "|    iterations      | 254       |\n",
      "|    time_elapsed    | 749       |\n",
      "|    total_timesteps | 520192    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 519          |\n",
      "|    ep_rew_mean          | -6.86e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 685          |\n",
      "|    iterations           | 255          |\n",
      "|    time_elapsed         | 762          |\n",
      "|    total_timesteps      | 522240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010823642 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.48        |\n",
      "|    explained_variance   | 0.112        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.74e+07     |\n",
      "|    n_updates            | 2540         |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    std                  | 0.767        |\n",
      "|    value_loss           | 1.26e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 529        |\n",
      "|    ep_rew_mean          | -6.55e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 681        |\n",
      "|    iterations           | 256        |\n",
      "|    time_elapsed         | 769        |\n",
      "|    total_timesteps      | 524288     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00861887 |\n",
      "|    clip_fraction        | 0.0787     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -4.47      |\n",
      "|    explained_variance   | 0.486      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 525        |\n",
      "|    n_updates            | 2550       |\n",
      "|    policy_gradient_loss | -0.00601   |\n",
      "|    std                  | 0.764      |\n",
      "|    value_loss           | 4.16e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=-33057.63 +/- 80777.87\n",
      "Episode length: 627.40 +/- 259.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 627          |\n",
      "|    mean_reward          | -3.31e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 525000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048391055 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.45        |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 940          |\n",
      "|    n_updates            | 2560         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    std                  | 0.758        |\n",
      "|    value_loss           | 2.34e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 532       |\n",
      "|    ep_rew_mean     | -6.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 673       |\n",
      "|    iterations      | 257       |\n",
      "|    time_elapsed    | 781       |\n",
      "|    total_timesteps | 526336    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 546          |\n",
      "|    ep_rew_mean          | -6.51e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 670          |\n",
      "|    iterations           | 258          |\n",
      "|    time_elapsed         | 788          |\n",
      "|    total_timesteps      | 528384       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059359656 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.43        |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 526          |\n",
      "|    n_updates            | 2570         |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    std                  | 0.758        |\n",
      "|    value_loss           | 3e+03        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=6882.49 +/- 4405.64\n",
      "Episode length: 702.80 +/- 26.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 703         |\n",
      "|    mean_reward          | 6.88e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 530000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006770119 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.41       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 991         |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    std                  | 0.753       |\n",
      "|    value_loss           | 3.44e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 544       |\n",
      "|    ep_rew_mean     | -6.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 663       |\n",
      "|    iterations      | 259       |\n",
      "|    time_elapsed    | 799       |\n",
      "|    total_timesteps | 530432    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 553          |\n",
      "|    ep_rew_mean          | -6.74e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 260          |\n",
      "|    time_elapsed         | 802          |\n",
      "|    total_timesteps      | 532480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002573877 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | 0.111        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.81e+07     |\n",
      "|    n_updates            | 2590         |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    std                  | 0.752        |\n",
      "|    value_loss           | 1.11e+08     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 558         |\n",
      "|    ep_rew_mean          | -6.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 664         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 804         |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005085543 |\n",
      "|    clip_fraction        | 0.0114      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.4        |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.751       |\n",
      "|    value_loss           | 4.42e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=535000, episode_reward=6701.10 +/- 4920.55\n",
      "Episode length: 718.80 +/- 19.52\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 719           |\n",
      "|    mean_reward          | 6.7e+03       |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 535000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00041649482 |\n",
      "|    clip_fraction        | 0.000293      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.39         |\n",
      "|    explained_variance   | 0.106         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.79e+07      |\n",
      "|    n_updates            | 2610          |\n",
      "|    policy_gradient_loss | -0.00135      |\n",
      "|    std                  | 0.751         |\n",
      "|    value_loss           | 4.33e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 563       |\n",
      "|    ep_rew_mean     | -6.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 663       |\n",
      "|    iterations      | 262       |\n",
      "|    time_elapsed    | 808       |\n",
      "|    total_timesteps | 536576    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 558          |\n",
      "|    ep_rew_mean          | -6.86e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 664          |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 810          |\n",
      "|    total_timesteps      | 538624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029001194 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.39        |\n",
      "|    explained_variance   | 0.107        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61e+07     |\n",
      "|    n_updates            | 2620         |\n",
      "|    policy_gradient_loss | -0.00827     |\n",
      "|    std                  | 0.752        |\n",
      "|    value_loss           | 3.48e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=5754.51 +/- 3938.29\n",
      "Episode length: 696.00 +/- 34.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 696          |\n",
      "|    mean_reward          | 5.75e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 540000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009306448 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | 0.0952       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.59e+06     |\n",
      "|    n_updates            | 2630         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    std                  | 0.753        |\n",
      "|    value_loss           | 6.67e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 556       |\n",
      "|    ep_rew_mean     | -7.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 663       |\n",
      "|    iterations      | 264       |\n",
      "|    time_elapsed    | 814       |\n",
      "|    total_timesteps | 540672    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 566           |\n",
      "|    ep_rew_mean          | -6.92e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 664           |\n",
      "|    iterations           | 265           |\n",
      "|    time_elapsed         | 816           |\n",
      "|    total_timesteps      | 542720        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00047516654 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.4          |\n",
      "|    explained_variance   | 0.107         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.92e+07      |\n",
      "|    n_updates            | 2640          |\n",
      "|    policy_gradient_loss | -0.00143      |\n",
      "|    std                  | 0.753         |\n",
      "|    value_loss           | 1.3e+08       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 552          |\n",
      "|    ep_rew_mean          | -7.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 665          |\n",
      "|    iterations           | 266          |\n",
      "|    time_elapsed         | 818          |\n",
      "|    total_timesteps      | 544768       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009501079 |\n",
      "|    clip_fraction        | 0.0019       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | 0.11         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.32e+07     |\n",
      "|    n_updates            | 2650         |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 0.753        |\n",
      "|    value_loss           | 1.17e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=545000, episode_reward=-36466.54 +/- 81748.54\n",
      "Episode length: 572.80 +/- 231.55\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 573          |\n",
      "|    mean_reward          | -3.65e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 545000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016156478 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | 0.117        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.4e+07      |\n",
      "|    n_updates            | 2660         |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    std                  | 0.753        |\n",
      "|    value_loss           | 1e+08        |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 546       |\n",
      "|    ep_rew_mean     | -7.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 665       |\n",
      "|    iterations      | 267       |\n",
      "|    time_elapsed    | 821       |\n",
      "|    total_timesteps | 546816    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 545          |\n",
      "|    ep_rew_mean          | -7.8e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 666          |\n",
      "|    iterations           | 268          |\n",
      "|    time_elapsed         | 823          |\n",
      "|    total_timesteps      | 548864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011399083 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | 0.111        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+07     |\n",
      "|    n_updates            | 2670         |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    std                  | 0.753        |\n",
      "|    value_loss           | 2.76e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=550000, episode_reward=5088.60 +/- 2635.94\n",
      "Episode length: 670.20 +/- 20.82\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 670          |\n",
      "|    mean_reward          | 5.09e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 550000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051583964 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.39        |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 615          |\n",
      "|    n_updates            | 2680         |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    std                  | 0.749        |\n",
      "|    value_loss           | 3.42e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 547       |\n",
      "|    ep_rew_mean     | -7.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 665       |\n",
      "|    iterations      | 269       |\n",
      "|    time_elapsed    | 827       |\n",
      "|    total_timesteps | 550912    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 542           |\n",
      "|    ep_rew_mean          | -7.89e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 666           |\n",
      "|    iterations           | 270           |\n",
      "|    time_elapsed         | 829           |\n",
      "|    total_timesteps      | 552960        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00079058413 |\n",
      "|    clip_fraction        | 0.000781      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.37         |\n",
      "|    explained_variance   | 0.117         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.34e+07      |\n",
      "|    n_updates            | 2690          |\n",
      "|    policy_gradient_loss | -0.00289      |\n",
      "|    std                  | 0.749         |\n",
      "|    value_loss           | 4.39e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=555000, episode_reward=8135.05 +/- 828.56\n",
      "Episode length: 659.00 +/- 32.42\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 659           |\n",
      "|    mean_reward          | 8.14e+03      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 555000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035211837 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.37         |\n",
      "|    explained_variance   | 0.1           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.71e+07      |\n",
      "|    n_updates            | 2700          |\n",
      "|    policy_gradient_loss | -0.000881     |\n",
      "|    std                  | 0.749         |\n",
      "|    value_loss           | 1e+08         |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 536      |\n",
      "|    ep_rew_mean     | -8.7e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 666      |\n",
      "|    iterations      | 271      |\n",
      "|    time_elapsed    | 833      |\n",
      "|    total_timesteps | 555008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 543         |\n",
      "|    ep_rew_mean          | -7.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 667         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 835         |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.000501354 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.37       |\n",
      "|    explained_variance   | 0.113       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+08    |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    std                  | 0.749       |\n",
      "|    value_loss           | 1.58e+08    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 547          |\n",
      "|    ep_rew_mean          | -7.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 668          |\n",
      "|    iterations           | 273          |\n",
      "|    time_elapsed         | 836          |\n",
      "|    total_timesteps      | 559104       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025290714 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.38        |\n",
      "|    explained_variance   | 0.118        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.68e+07     |\n",
      "|    n_updates            | 2720         |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    std                  | 0.753        |\n",
      "|    value_loss           | 5.52e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=5233.59 +/- 2808.86\n",
      "Episode length: 710.00 +/- 17.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 710         |\n",
      "|    mean_reward          | 5.23e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008752511 |\n",
      "|    clip_fraction        | 0.0508      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.41       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 2730        |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    std                  | 0.758       |\n",
      "|    value_loss           | 2.27e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 539       |\n",
      "|    ep_rew_mean     | -7.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 667       |\n",
      "|    iterations      | 274       |\n",
      "|    time_elapsed    | 840       |\n",
      "|    total_timesteps | 561152    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 540          |\n",
      "|    ep_rew_mean          | -7.41e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 667          |\n",
      "|    iterations           | 275          |\n",
      "|    time_elapsed         | 843          |\n",
      "|    total_timesteps      | 563200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008687151 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.41        |\n",
      "|    explained_variance   | 0.113        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.95e+07     |\n",
      "|    n_updates            | 2740         |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    std                  | 0.758        |\n",
      "|    value_loss           | 8.78e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=565000, episode_reward=6558.30 +/- 4669.71\n",
      "Episode length: 726.60 +/- 42.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 727          |\n",
      "|    mean_reward          | 6.56e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 565000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039361576 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.4         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 748          |\n",
      "|    n_updates            | 2750         |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    std                  | 0.754        |\n",
      "|    value_loss           | 2.61e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 535       |\n",
      "|    ep_rew_mean     | -7.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 666       |\n",
      "|    iterations      | 276       |\n",
      "|    time_elapsed    | 848       |\n",
      "|    total_timesteps | 565248    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 537          |\n",
      "|    ep_rew_mean          | -6.98e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 666          |\n",
      "|    iterations           | 277          |\n",
      "|    time_elapsed         | 851          |\n",
      "|    total_timesteps      | 567296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020895964 |\n",
      "|    clip_fraction        | 0.017        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.39        |\n",
      "|    explained_variance   | 0.115        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+07     |\n",
      "|    n_updates            | 2760         |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    std                  | 0.754        |\n",
      "|    value_loss           | 5.33e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 549         |\n",
      "|    ep_rew_mean          | -6.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 666         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 854         |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008823454 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.36       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 426         |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    std                  | 0.745       |\n",
      "|    value_loss           | 1.58e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=7945.41 +/- 3514.14\n",
      "Episode length: 861.80 +/- 42.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 862          |\n",
      "|    mean_reward          | 7.95e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 570000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031185662 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.32        |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61e+03     |\n",
      "|    n_updates            | 2780         |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    std                  | 0.742        |\n",
      "|    value_loss           | 6.08e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 541       |\n",
      "|    ep_rew_mean     | -6.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 665       |\n",
      "|    iterations      | 279       |\n",
      "|    time_elapsed    | 859       |\n",
      "|    total_timesteps | 571392    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 539         |\n",
      "|    ep_rew_mean          | -6.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 665         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 862         |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002748496 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.31       |\n",
      "|    explained_variance   | 0.116       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.39e+06    |\n",
      "|    n_updates            | 2790        |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    std                  | 0.743       |\n",
      "|    value_loss           | 4.45e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=7071.39 +/- 3995.65\n",
      "Episode length: 762.80 +/- 32.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 763          |\n",
      "|    mean_reward          | 7.07e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 575000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028481677 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.31        |\n",
      "|    explained_variance   | 0.122        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.65e+07     |\n",
      "|    n_updates            | 2800         |\n",
      "|    policy_gradient_loss | -0.00766     |\n",
      "|    std                  | 0.743        |\n",
      "|    value_loss           | 6.23e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 540       |\n",
      "|    ep_rew_mean     | -6.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 663       |\n",
      "|    iterations      | 281       |\n",
      "|    time_elapsed    | 867       |\n",
      "|    total_timesteps | 575488    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 544         |\n",
      "|    ep_rew_mean          | -6.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 663         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 870         |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009290917 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.28       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 294         |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    std                  | 0.736       |\n",
      "|    value_loss           | 1.53e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 550          |\n",
      "|    ep_rew_mean          | -6.86e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 283          |\n",
      "|    time_elapsed         | 872          |\n",
      "|    total_timesteps      | 579584       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019449128 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+07     |\n",
      "|    n_updates            | 2820         |\n",
      "|    policy_gradient_loss | -0.00364     |\n",
      "|    std                  | 0.736        |\n",
      "|    value_loss           | 5.9e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=9518.54 +/- 2573.40\n",
      "Episode length: 847.20 +/- 37.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 847          |\n",
      "|    mean_reward          | 9.52e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 580000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010254205 |\n",
      "|    clip_fraction        | 0.00322      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.2e+07      |\n",
      "|    n_updates            | 2830         |\n",
      "|    policy_gradient_loss | -0.00193     |\n",
      "|    std                  | 0.735        |\n",
      "|    value_loss           | 9.23e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 537       |\n",
      "|    ep_rew_mean     | -7.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 662       |\n",
      "|    iterations      | 284       |\n",
      "|    time_elapsed    | 878       |\n",
      "|    total_timesteps | 581632    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 539          |\n",
      "|    ep_rew_mean          | -7.46e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 662          |\n",
      "|    iterations           | 285          |\n",
      "|    time_elapsed         | 880          |\n",
      "|    total_timesteps      | 583680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012234187 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.26        |\n",
      "|    explained_variance   | 0.135        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.91e+07     |\n",
      "|    n_updates            | 2840         |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    std                  | 0.735        |\n",
      "|    value_loss           | 5.64e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=585000, episode_reward=11612.00 +/- 984.64\n",
      "Episode length: 836.60 +/- 52.32\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 837           |\n",
      "|    mean_reward          | 1.16e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 585000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048315784 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.26         |\n",
      "|    explained_variance   | 0.139         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.21e+07      |\n",
      "|    n_updates            | 2850          |\n",
      "|    policy_gradient_loss | -0.00115      |\n",
      "|    std                  | 0.735         |\n",
      "|    value_loss           | 1.93e+08      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 541       |\n",
      "|    ep_rew_mean     | -7.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 659       |\n",
      "|    iterations      | 286       |\n",
      "|    time_elapsed    | 888       |\n",
      "|    total_timesteps | 585728    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 542          |\n",
      "|    ep_rew_mean          | -7.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 655          |\n",
      "|    iterations           | 287          |\n",
      "|    time_elapsed         | 897          |\n",
      "|    total_timesteps      | 587776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042811073 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.25        |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 2860         |\n",
      "|    policy_gradient_loss | -0.00795     |\n",
      "|    std                  | 0.734        |\n",
      "|    value_loss           | 1.43e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 544         |\n",
      "|    ep_rew_mean          | -8.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 288         |\n",
      "|    time_elapsed         | 904         |\n",
      "|    total_timesteps      | 589824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008870689 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.22       |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 569         |\n",
      "|    n_updates            | 2870        |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    std                  | 0.722       |\n",
      "|    value_loss           | 2.52e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=11193.36 +/- 3514.42\n",
      "Episode length: 1079.40 +/- 62.03\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.08e+03     |\n",
      "|    mean_reward          | 1.12e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 590000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009794091 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.95e+07     |\n",
      "|    n_updates            | 2880         |\n",
      "|    policy_gradient_loss | -0.000496    |\n",
      "|    std                  | 0.722        |\n",
      "|    value_loss           | 9.92e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 558       |\n",
      "|    ep_rew_mean     | -7.91e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 642       |\n",
      "|    iterations      | 289       |\n",
      "|    time_elapsed    | 921       |\n",
      "|    total_timesteps | 591872    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 562          |\n",
      "|    ep_rew_mean          | -7.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 290          |\n",
      "|    time_elapsed         | 923          |\n",
      "|    total_timesteps      | 593920       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037197252 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.17        |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 825          |\n",
      "|    n_updates            | 2890         |\n",
      "|    policy_gradient_loss | -0.00374     |\n",
      "|    std                  | 0.719        |\n",
      "|    value_loss           | 6.21e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=595000, episode_reward=-192561.11 +/- 170931.11\n",
      "Episode length: 589.00 +/- 448.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 589         |\n",
      "|    mean_reward          | -1.93e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 595000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009276496 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.11       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.96e+04    |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.00818    |\n",
      "|    std                  | 0.708       |\n",
      "|    value_loss           | 3.2e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 578       |\n",
      "|    ep_rew_mean     | -7.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 643       |\n",
      "|    iterations      | 291       |\n",
      "|    time_elapsed    | 926       |\n",
      "|    total_timesteps | 595968    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 593          |\n",
      "|    ep_rew_mean          | -7.68e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 292          |\n",
      "|    time_elapsed         | 928          |\n",
      "|    total_timesteps      | 598016       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027301454 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.08        |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.15e+07     |\n",
      "|    n_updates            | 2910         |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    std                  | 0.708        |\n",
      "|    value_loss           | 3.4e+07      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=600000, episode_reward=-185439.90 +/- 242513.60\n",
      "Episode length: 798.00 +/- 320.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 798         |\n",
      "|    mean_reward          | -1.85e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 600000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008756513 |\n",
      "|    clip_fraction        | 0.076       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.04       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 600         |\n",
      "|    n_updates            | 2920        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    std                  | 0.696       |\n",
      "|    value_loss           | 2.27e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 607       |\n",
      "|    ep_rew_mean     | -7.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 642       |\n",
      "|    iterations      | 293       |\n",
      "|    time_elapsed    | 933       |\n",
      "|    total_timesteps | 600064    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 612          |\n",
      "|    ep_rew_mean          | -8.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 294          |\n",
      "|    time_elapsed         | 935          |\n",
      "|    total_timesteps      | 602112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048410236 |\n",
      "|    clip_fraction        | 0.031        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.99        |\n",
      "|    explained_variance   | 0.643        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.2e+04      |\n",
      "|    n_updates            | 2930         |\n",
      "|    policy_gradient_loss | -0.00717     |\n",
      "|    std                  | 0.695        |\n",
      "|    value_loss           | 1.57e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 619          |\n",
      "|    ep_rew_mean          | -8.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 644          |\n",
      "|    iterations           | 295          |\n",
      "|    time_elapsed         | 937          |\n",
      "|    total_timesteps      | 604160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014434104 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.99        |\n",
      "|    explained_variance   | 0.141        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06e+08     |\n",
      "|    n_updates            | 2940         |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    std                  | 0.695        |\n",
      "|    value_loss           | 2.38e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=605000, episode_reward=-70130.40 +/- 163652.69\n",
      "Episode length: 844.40 +/- 269.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 844         |\n",
      "|    mean_reward          | -7.01e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 605000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006486171 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.99       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 649         |\n",
      "|    n_updates            | 2950        |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    std                  | 0.698       |\n",
      "|    value_loss           | 1.05e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 633       |\n",
      "|    ep_rew_mean     | -8.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 296       |\n",
      "|    time_elapsed    | 941       |\n",
      "|    total_timesteps | 606208    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 642          |\n",
      "|    ep_rew_mean          | -8.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 644          |\n",
      "|    iterations           | 297          |\n",
      "|    time_elapsed         | 943          |\n",
      "|    total_timesteps      | 608256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022356266 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.99        |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.24e+07     |\n",
      "|    n_updates            | 2960         |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    std                  | 0.698        |\n",
      "|    value_loss           | 1.55e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=-60429.98 +/- 146009.24\n",
      "Episode length: 880.60 +/- 308.95\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 881        |\n",
      "|    mean_reward          | -6.04e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 610000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00419024 |\n",
      "|    clip_fraction        | 0.0177     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.99      |\n",
      "|    explained_variance   | 0.88       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.01e+03   |\n",
      "|    n_updates            | 2970       |\n",
      "|    policy_gradient_loss | -0.00397   |\n",
      "|    std                  | 0.696      |\n",
      "|    value_loss           | 4.17e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 654      |\n",
      "|    ep_rew_mean     | -8.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 643      |\n",
      "|    iterations      | 298      |\n",
      "|    time_elapsed    | 948      |\n",
      "|    total_timesteps | 610304   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 669          |\n",
      "|    ep_rew_mean          | -8.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 299          |\n",
      "|    time_elapsed         | 951          |\n",
      "|    total_timesteps      | 612352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083531095 |\n",
      "|    clip_fraction        | 0.0533       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.97        |\n",
      "|    explained_variance   | 0.889        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11e+03     |\n",
      "|    n_updates            | 2980         |\n",
      "|    policy_gradient_loss | -0.00889     |\n",
      "|    std                  | 0.693        |\n",
      "|    value_loss           | 3.18e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 681         |\n",
      "|    ep_rew_mean          | -8.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 644         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 953         |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009174515 |\n",
      "|    clip_fraction        | 0.0766      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.94       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 770         |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    std                  | 0.687       |\n",
      "|    value_loss           | 1.6e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=615000, episode_reward=-59877.49 +/- 142074.59\n",
      "Episode length: 830.80 +/- 275.64\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 831          |\n",
      "|    mean_reward          | -5.99e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 615000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005382238 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.82e+07     |\n",
      "|    n_updates            | 3000         |\n",
      "|    policy_gradient_loss | -0.0001      |\n",
      "|    std                  | 0.687        |\n",
      "|    value_loss           | 1.2e+08      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 688       |\n",
      "|    ep_rew_mean     | -8.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 301       |\n",
      "|    time_elapsed    | 957       |\n",
      "|    total_timesteps | 616448    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 681           |\n",
      "|    ep_rew_mean          | -9.66e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 644           |\n",
      "|    iterations           | 302           |\n",
      "|    time_elapsed         | 959           |\n",
      "|    total_timesteps      | 618496        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0664458e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.92         |\n",
      "|    explained_variance   | 0.121         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.95e+07      |\n",
      "|    n_updates            | 3010          |\n",
      "|    policy_gradient_loss | -0.000145     |\n",
      "|    std                  | 0.687         |\n",
      "|    value_loss           | 1.09e+08      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=12282.94 +/- 3425.79\n",
      "Episode length: 974.40 +/- 37.28\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 974           |\n",
      "|    mean_reward          | 1.23e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 620000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077348447 |\n",
      "|    clip_fraction        | 0.00166       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.92         |\n",
      "|    explained_variance   | 0.146         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.75e+07      |\n",
      "|    n_updates            | 3020          |\n",
      "|    policy_gradient_loss | -0.00227      |\n",
      "|    std                  | 0.687         |\n",
      "|    value_loss           | 5.77e+07      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 694       |\n",
      "|    ep_rew_mean     | -9.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 303       |\n",
      "|    time_elapsed    | 963       |\n",
      "|    total_timesteps | 620544    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 701          |\n",
      "|    ep_rew_mean          | -9.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 645          |\n",
      "|    iterations           | 304          |\n",
      "|    time_elapsed         | 965          |\n",
      "|    total_timesteps      | 622592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035109657 |\n",
      "|    clip_fraction        | 0.0124       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.856        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21e+03     |\n",
      "|    n_updates            | 3030         |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    std                  | 0.688        |\n",
      "|    value_loss           | 5.18e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 709         |\n",
      "|    ep_rew_mean          | -9.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 966         |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002426586 |\n",
      "|    clip_fraction        | 0.0124      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.92       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.32e+07    |\n",
      "|    n_updates            | 3040        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    std                  | 0.688       |\n",
      "|    value_loss           | 1.01e+08    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=13966.12 +/- 3549.47\n",
      "Episode length: 1079.40 +/- 34.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.08e+03     |\n",
      "|    mean_reward          | 1.4e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 625000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011351509 |\n",
      "|    clip_fraction        | 0.00562      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.93        |\n",
      "|    explained_variance   | 0.241        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.16e+06     |\n",
      "|    n_updates            | 3050         |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    std                  | 0.688        |\n",
      "|    value_loss           | 1.83e+07     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 722       |\n",
      "|    ep_rew_mean     | -9.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 645       |\n",
      "|    iterations      | 306       |\n",
      "|    time_elapsed    | 971       |\n",
      "|    total_timesteps | 626688    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 724           |\n",
      "|    ep_rew_mean          | -1.01e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 646           |\n",
      "|    iterations           | 307           |\n",
      "|    time_elapsed         | 973           |\n",
      "|    total_timesteps      | 628736        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023542653 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.93         |\n",
      "|    explained_variance   | 0.153         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.22e+07      |\n",
      "|    n_updates            | 3060          |\n",
      "|    policy_gradient_loss | -0.000398     |\n",
      "|    std                  | 0.688         |\n",
      "|    value_loss           | 1.3e+08       |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=15769.60 +/- 1088.28\n",
      "Episode length: 1057.00 +/- 46.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.06e+03     |\n",
      "|    mean_reward          | 1.58e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 630000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006246767 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.93        |\n",
      "|    explained_variance   | 0.143        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.61e+07     |\n",
      "|    n_updates            | 3070         |\n",
      "|    policy_gradient_loss | -0.000985    |\n",
      "|    std                  | 0.688        |\n",
      "|    value_loss           | 1.61e+08     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 720       |\n",
      "|    ep_rew_mean     | -1.07e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 645       |\n",
      "|    iterations      | 308       |\n",
      "|    time_elapsed    | 977       |\n",
      "|    total_timesteps | 630784    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 722         |\n",
      "|    ep_rew_mean          | -1.15e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 646         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 979         |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002007873 |\n",
      "|    clip_fraction        | 0.0251      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.56e+07    |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    std                  | 0.689       |\n",
      "|    value_loss           | 6.16e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 734          |\n",
      "|    ep_rew_mean          | -1.11e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 310          |\n",
      "|    time_elapsed         | 981          |\n",
      "|    total_timesteps      | 634880       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016124747 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.93        |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.3e+07      |\n",
      "|    n_updates            | 3090         |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    std                  | 0.689        |\n",
      "|    value_loss           | 1.3e+08      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=635000, episode_reward=-180902.83 +/- 159586.77\n",
      "Episode length: 555.40 +/- 403.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 555          |\n",
      "|    mean_reward          | -1.81e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 635000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023786423 |\n",
      "|    clip_fraction        | 0.00239      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.93        |\n",
      "|    explained_variance   | 0.656        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.8e+03      |\n",
      "|    n_updates            | 3100         |\n",
      "|    policy_gradient_loss | -0.00406     |\n",
      "|    std                  | 0.688        |\n",
      "|    value_loss           | 7.14e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 739       |\n",
      "|    ep_rew_mean     | -1.14e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 646       |\n",
      "|    iterations      | 311       |\n",
      "|    time_elapsed    | 984       |\n",
      "|    total_timesteps | 636928    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 749          |\n",
      "|    ep_rew_mean          | -1.15e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 312          |\n",
      "|    time_elapsed         | 986          |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013728946 |\n",
      "|    clip_fraction        | 0.0144       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.73e+07     |\n",
      "|    n_updates            | 3110         |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    std                  | 0.69         |\n",
      "|    value_loss           | 5.8e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=-41382.82 +/- 112412.34\n",
      "Episode length: 871.00 +/- 345.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 871          |\n",
      "|    mean_reward          | -4.14e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 640000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024194042 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.17         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.56e+07     |\n",
      "|    n_updates            | 3120         |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    std                  | 0.689        |\n",
      "|    value_loss           | 6.26e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 753       |\n",
      "|    ep_rew_mean     | -1.18e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 647       |\n",
      "|    iterations      | 313       |\n",
      "|    time_elapsed    | 990       |\n",
      "|    total_timesteps | 641024    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 762          |\n",
      "|    ep_rew_mean          | -1.21e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 648          |\n",
      "|    iterations           | 314          |\n",
      "|    time_elapsed         | 992          |\n",
      "|    total_timesteps      | 643072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011110852 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.23e+07     |\n",
      "|    n_updates            | 3130         |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    std                  | 0.689        |\n",
      "|    value_loss           | 8.38e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=645000, episode_reward=13001.12 +/- 2961.69\n",
      "Episode length: 1089.80 +/- 28.99\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.09e+03     |\n",
      "|    mean_reward          | 1.3e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 645000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037399342 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.94        |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.39e+06     |\n",
      "|    n_updates            | 3140         |\n",
      "|    policy_gradient_loss | -0.00788     |\n",
      "|    std                  | 0.691        |\n",
      "|    value_loss           | 1.26e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 762       |\n",
      "|    ep_rew_mean     | -1.21e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 647       |\n",
      "|    iterations      | 315       |\n",
      "|    time_elapsed    | 996       |\n",
      "|    total_timesteps | 645120    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 765         |\n",
      "|    ep_rew_mean          | -1.25e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 647         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 999         |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008652372 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 3150        |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    std                  | 0.688       |\n",
      "|    value_loss           | 2.85e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 762          |\n",
      "|    ep_rew_mean          | -1.27e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 648          |\n",
      "|    iterations           | 317          |\n",
      "|    time_elapsed         | 1001         |\n",
      "|    total_timesteps      | 649216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015845172 |\n",
      "|    clip_fraction        | 0.00449      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.91        |\n",
      "|    explained_variance   | 0.164        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.12e+07     |\n",
      "|    n_updates            | 3160         |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    std                  | 0.687        |\n",
      "|    value_loss           | 1.17e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=11586.32 +/- 4491.18\n",
      "Episode length: 971.60 +/- 29.05\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 972          |\n",
      "|    mean_reward          | 1.16e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 650000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015238518 |\n",
      "|    clip_fraction        | 0.0061       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.91        |\n",
      "|    explained_variance   | 0.148        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.99e+07     |\n",
      "|    n_updates            | 3170         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    std                  | 0.688        |\n",
      "|    value_loss           | 8.49e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 758       |\n",
      "|    ep_rew_mean     | -1.36e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 647       |\n",
      "|    iterations      | 318       |\n",
      "|    time_elapsed    | 1006      |\n",
      "|    total_timesteps | 651264    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 763           |\n",
      "|    ep_rew_mean          | -1.32e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 647           |\n",
      "|    iterations           | 319           |\n",
      "|    time_elapsed         | 1008          |\n",
      "|    total_timesteps      | 653312        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00071490556 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.92         |\n",
      "|    explained_variance   | 0.164         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.8e+07       |\n",
      "|    n_updates            | 3180          |\n",
      "|    policy_gradient_loss | -0.00149      |\n",
      "|    std                  | 0.688         |\n",
      "|    value_loss           | 1.33e+08      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=655000, episode_reward=-49514.03 +/- 121846.73\n",
      "Episode length: 864.40 +/- 307.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 864         |\n",
      "|    mean_reward          | -4.95e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 655000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003328975 |\n",
      "|    clip_fraction        | 0.0117      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.91       |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.97e+03    |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    std                  | 0.686       |\n",
      "|    value_loss           | 2.24e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 755       |\n",
      "|    ep_rew_mean     | -1.34e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 646       |\n",
      "|    iterations      | 320       |\n",
      "|    time_elapsed    | 1013      |\n",
      "|    total_timesteps | 655360    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 753          |\n",
      "|    ep_rew_mean          | -1.33e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 321          |\n",
      "|    time_elapsed         | 1015         |\n",
      "|    total_timesteps      | 657408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016580245 |\n",
      "|    clip_fraction        | 0.00278      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.147        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.08e+07     |\n",
      "|    n_updates            | 3200         |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    std                  | 0.687        |\n",
      "|    value_loss           | 9.48e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 741          |\n",
      "|    ep_rew_mean          | -1.34e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 322          |\n",
      "|    time_elapsed         | 1018         |\n",
      "|    total_timesteps      | 659456       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009827509 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.139        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.63e+06     |\n",
      "|    n_updates            | 3210         |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    std                  | 0.686        |\n",
      "|    value_loss           | 4.2e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=-111057.24 +/- 150091.07\n",
      "Episode length: 730.20 +/- 394.53\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 730           |\n",
      "|    mean_reward          | -1.11e+05     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 660000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00019380046 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.9          |\n",
      "|    explained_variance   | 0.128         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.77e+07      |\n",
      "|    n_updates            | 3220          |\n",
      "|    policy_gradient_loss | -0.000311     |\n",
      "|    std                  | 0.686         |\n",
      "|    value_loss           | 2.11e+08      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 725       |\n",
      "|    ep_rew_mean     | -1.39e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 323       |\n",
      "|    time_elapsed    | 1026      |\n",
      "|    total_timesteps | 661504    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 720           |\n",
      "|    ep_rew_mean          | -1.41e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 644           |\n",
      "|    iterations           | 324           |\n",
      "|    time_elapsed         | 1030          |\n",
      "|    total_timesteps      | 663552        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6679714e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.9          |\n",
      "|    explained_variance   | 0.109         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.97e+07      |\n",
      "|    n_updates            | 3230          |\n",
      "|    policy_gradient_loss | -0.000254     |\n",
      "|    std                  | 0.686         |\n",
      "|    value_loss           | 1.43e+08      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=665000, episode_reward=-45562.07 +/- 121242.94\n",
      "Episode length: 867.60 +/- 312.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 868          |\n",
      "|    mean_reward          | -4.56e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 665000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017221172 |\n",
      "|    clip_fraction        | 0.00337      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.91        |\n",
      "|    explained_variance   | 0.129        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.85e+07     |\n",
      "|    n_updates            | 3240         |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.686        |\n",
      "|    value_loss           | 9.63e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 718       |\n",
      "|    ep_rew_mean     | -1.45e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 643       |\n",
      "|    iterations      | 325       |\n",
      "|    time_elapsed    | 1033      |\n",
      "|    total_timesteps | 665600    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 713          |\n",
      "|    ep_rew_mean          | -1.43e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 643          |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 1036         |\n",
      "|    total_timesteps      | 667648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013151048 |\n",
      "|    clip_fraction        | 0.00186      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.91        |\n",
      "|    explained_variance   | 0.556        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.83e+05     |\n",
      "|    n_updates            | 3250         |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    std                  | 0.688        |\n",
      "|    value_loss           | 8.07e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 692          |\n",
      "|    ep_rew_mean          | -1.48e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 644          |\n",
      "|    iterations           | 327          |\n",
      "|    time_elapsed         | 1039         |\n",
      "|    total_timesteps      | 669696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067166863 |\n",
      "|    clip_fraction        | 0.0482       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.892        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 3260         |\n",
      "|    policy_gradient_loss | -0.00828     |\n",
      "|    std                  | 0.691        |\n",
      "|    value_loss           | 7.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=-50095.16 +/- 122620.07\n",
      "Episode length: 700.20 +/- 226.12\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 700           |\n",
      "|    mean_reward          | -5.01e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 670000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.0028334e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.93         |\n",
      "|    explained_variance   | 0.138         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.59e+07      |\n",
      "|    n_updates            | 3270          |\n",
      "|    policy_gradient_loss | -0.000142     |\n",
      "|    std                  | 0.691         |\n",
      "|    value_loss           | 1.49e+08      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 694       |\n",
      "|    ep_rew_mean     | -1.41e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 328       |\n",
      "|    time_elapsed    | 1042      |\n",
      "|    total_timesteps | 671744    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 681          |\n",
      "|    ep_rew_mean          | -1.41e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 644          |\n",
      "|    iterations           | 329          |\n",
      "|    time_elapsed         | 1044         |\n",
      "|    total_timesteps      | 673792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007913322 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.93        |\n",
      "|    explained_variance   | 0.166        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.1e+06      |\n",
      "|    n_updates            | 3280         |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    std                  | 0.69         |\n",
      "|    value_loss           | 3.1e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=5563.37 +/- 3672.18\n",
      "Episode length: 683.60 +/- 4.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 684        |\n",
      "|    mean_reward          | 5.56e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 675000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00678428 |\n",
      "|    clip_fraction        | 0.0572     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.92      |\n",
      "|    explained_variance   | 0.867      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 589        |\n",
      "|    n_updates            | 3290       |\n",
      "|    policy_gradient_loss | -0.00678   |\n",
      "|    std                  | 0.688      |\n",
      "|    value_loss           | 6.59e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 666       |\n",
      "|    ep_rew_mean     | -1.43e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 330       |\n",
      "|    time_elapsed    | 1048      |\n",
      "|    total_timesteps | 675840    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 650           |\n",
      "|    ep_rew_mean          | -1.43e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 645           |\n",
      "|    iterations           | 331           |\n",
      "|    time_elapsed         | 1050          |\n",
      "|    total_timesteps      | 677888        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00063926756 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.9          |\n",
      "|    explained_variance   | 0.144         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.93e+07      |\n",
      "|    n_updates            | 3300          |\n",
      "|    policy_gradient_loss | -0.000871     |\n",
      "|    std                  | 0.688         |\n",
      "|    value_loss           | 1.59e+08      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 642          |\n",
      "|    ep_rew_mean          | -1.4e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 646          |\n",
      "|    iterations           | 332          |\n",
      "|    time_elapsed         | 1051         |\n",
      "|    total_timesteps      | 679936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017547134 |\n",
      "|    clip_fraction        | 0.00801      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.168        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.7e+07      |\n",
      "|    n_updates            | 3310         |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    std                  | 0.687        |\n",
      "|    value_loss           | 5.47e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=680000, episode_reward=6904.85 +/- 3697.28\n",
      "Episode length: 712.40 +/- 29.25\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 712          |\n",
      "|    mean_reward          | 6.9e+03      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 680000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030130865 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.9         |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06e+07     |\n",
      "|    n_updates            | 3320         |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.689        |\n",
      "|    value_loss           | 4.84e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 644       |\n",
      "|    ep_rew_mean     | -1.37e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 646       |\n",
      "|    iterations      | 333       |\n",
      "|    time_elapsed    | 1055      |\n",
      "|    total_timesteps | 681984    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 619          |\n",
      "|    ep_rew_mean          | -1.53e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 646          |\n",
      "|    iterations           | 334          |\n",
      "|    time_elapsed         | 1057         |\n",
      "|    total_timesteps      | 684032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024757385 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.16         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.65e+07     |\n",
      "|    n_updates            | 3330         |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    std                  | 0.69         |\n",
      "|    value_loss           | 1.01e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=685000, episode_reward=-61031.96 +/- 132813.44\n",
      "Episode length: 622.60 +/- 166.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 623          |\n",
      "|    mean_reward          | -6.1e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 685000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033301704 |\n",
      "|    clip_fraction        | 0.00913      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.152        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.58e+07     |\n",
      "|    n_updates            | 3340         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    std                  | 0.691        |\n",
      "|    value_loss           | 1.77e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 618       |\n",
      "|    ep_rew_mean     | -1.48e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 646       |\n",
      "|    iterations      | 335       |\n",
      "|    time_elapsed    | 1060      |\n",
      "|    total_timesteps | 686080    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 612          |\n",
      "|    ep_rew_mean          | -1.48e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 336          |\n",
      "|    time_elapsed         | 1062         |\n",
      "|    total_timesteps      | 688128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021475449 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.92        |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.74e+07     |\n",
      "|    n_updates            | 3350         |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    std                  | 0.692        |\n",
      "|    value_loss           | 5.12e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=8724.25 +/- 1569.88\n",
      "Episode length: 725.40 +/- 24.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 725         |\n",
      "|    mean_reward          | 8.72e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 690000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002686548 |\n",
      "|    clip_fraction        | 0.0192      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.43e+07    |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.0045     |\n",
      "|    std                  | 0.695       |\n",
      "|    value_loss           | 5.83e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 623       |\n",
      "|    ep_rew_mean     | -1.37e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 647       |\n",
      "|    iterations      | 337       |\n",
      "|    time_elapsed    | 1066      |\n",
      "|    total_timesteps | 690176    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 606          |\n",
      "|    ep_rew_mean          | -1.36e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 338          |\n",
      "|    time_elapsed         | 1068         |\n",
      "|    total_timesteps      | 692224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068944823 |\n",
      "|    clip_fraction        | 0.0872       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.91        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 235          |\n",
      "|    n_updates            | 3370         |\n",
      "|    policy_gradient_loss | -0.00805     |\n",
      "|    std                  | 0.688        |\n",
      "|    value_loss           | 6.75e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 609          |\n",
      "|    ep_rew_mean          | -1.3e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 648          |\n",
      "|    iterations           | 339          |\n",
      "|    time_elapsed         | 1070         |\n",
      "|    total_timesteps      | 694272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020188512 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.89        |\n",
      "|    explained_variance   | 0.159        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.23e+07     |\n",
      "|    n_updates            | 3380         |\n",
      "|    policy_gradient_loss | -0.00441     |\n",
      "|    std                  | 0.688        |\n",
      "|    value_loss           | 9.96e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=695000, episode_reward=-90630.05 +/- 200729.80\n",
      "Episode length: 673.40 +/- 94.01\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 673          |\n",
      "|    mean_reward          | -9.06e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 695000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005070153 |\n",
      "|    clip_fraction        | 0.00127      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.89        |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.24e+07     |\n",
      "|    n_updates            | 3390         |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    std                  | 0.688        |\n",
      "|    value_loss           | 3.7e+07      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 598      |\n",
      "|    ep_rew_mean     | -1.3e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 648      |\n",
      "|    iterations      | 340      |\n",
      "|    time_elapsed    | 1073     |\n",
      "|    total_timesteps | 696320   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 595         |\n",
      "|    ep_rew_mean          | -1.23e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 1075        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003618319 |\n",
      "|    clip_fraction        | 0.0134      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54e+03    |\n",
      "|    n_updates            | 3400        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    std                  | 0.687       |\n",
      "|    value_loss           | 3.75e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=-86701.92 +/- 189612.77\n",
      "Episode length: 613.80 +/- 65.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 614         |\n",
      "|    mean_reward          | -8.67e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008347776 |\n",
      "|    clip_fraction        | 0.0731      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.87       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 363         |\n",
      "|    n_updates            | 3410        |\n",
      "|    policy_gradient_loss | -0.00664    |\n",
      "|    std                  | 0.682       |\n",
      "|    value_loss           | 1.51e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 590       |\n",
      "|    ep_rew_mean     | -1.17e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 649       |\n",
      "|    iterations      | 342       |\n",
      "|    time_elapsed    | 1078      |\n",
      "|    total_timesteps | 700416    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 575         |\n",
      "|    ep_rew_mean          | -1.17e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 1080        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008273818 |\n",
      "|    clip_fraction        | 0.0628      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.83       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 299         |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    std                  | 0.68        |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 573         |\n",
      "|    ep_rew_mean          | -1.14e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 650         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 1082        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011303783 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.8        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 305         |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    std                  | 0.674       |\n",
      "|    value_loss           | 809         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=705000, episode_reward=-91009.14 +/- 202682.49\n",
      "Episode length: 671.20 +/- 74.59\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 671          |\n",
      "|    mean_reward          | -9.1e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 705000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029873978 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.78        |\n",
      "|    explained_variance   | 0.153        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.44e+07     |\n",
      "|    n_updates            | 3440         |\n",
      "|    policy_gradient_loss | -0.00725     |\n",
      "|    std                  | 0.673        |\n",
      "|    value_loss           | 1.16e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 568       |\n",
      "|    ep_rew_mean     | -1.15e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 345       |\n",
      "|    time_elapsed    | 1086      |\n",
      "|    total_timesteps | 706560    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 579          |\n",
      "|    ep_rew_mean          | -1.06e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 346          |\n",
      "|    time_elapsed         | 1088         |\n",
      "|    total_timesteps      | 708608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010758454 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.78        |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+07     |\n",
      "|    n_updates            | 3450         |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    std                  | 0.674        |\n",
      "|    value_loss           | 5.08e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=-73490.33 +/- 161713.54\n",
      "Episode length: 678.80 +/- 152.26\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 679        |\n",
      "|    mean_reward          | -7.35e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 710000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01122847 |\n",
      "|    clip_fraction        | 0.0919     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.76      |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 231        |\n",
      "|    n_updates            | 3460       |\n",
      "|    policy_gradient_loss | -0.0111    |\n",
      "|    std                  | 0.669      |\n",
      "|    value_loss           | 6.35e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 567       |\n",
      "|    ep_rew_mean     | -1.05e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 651       |\n",
      "|    iterations      | 347       |\n",
      "|    time_elapsed    | 1091      |\n",
      "|    total_timesteps | 710656    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 565          |\n",
      "|    ep_rew_mean          | -1.05e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 348          |\n",
      "|    time_elapsed         | 1094         |\n",
      "|    total_timesteps      | 712704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020258063 |\n",
      "|    clip_fraction        | 0.00879      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.148        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.92e+06     |\n",
      "|    n_updates            | 3470         |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    std                  | 0.669        |\n",
      "|    value_loss           | 3.23e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 571          |\n",
      "|    ep_rew_mean          | -1.03e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 349          |\n",
      "|    time_elapsed         | 1097         |\n",
      "|    total_timesteps      | 714752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016986583 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+07     |\n",
      "|    n_updates            | 3480         |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.669        |\n",
      "|    value_loss           | 5.3e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=715000, episode_reward=9543.31 +/- 1923.82\n",
      "Episode length: 775.00 +/- 26.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 775          |\n",
      "|    mean_reward          | 9.54e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 715000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025780967 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.2e+07      |\n",
      "|    n_updates            | 3490         |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    std                  | 0.669        |\n",
      "|    value_loss           | 5.48e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 574       |\n",
      "|    ep_rew_mean     | -9.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 350       |\n",
      "|    time_elapsed    | 1101      |\n",
      "|    total_timesteps | 716800    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 589          |\n",
      "|    ep_rew_mean          | -9.42e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 351          |\n",
      "|    time_elapsed         | 1103         |\n",
      "|    total_timesteps      | 718848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008592416 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.72        |\n",
      "|    explained_variance   | 0.179        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.94e+07     |\n",
      "|    n_updates            | 3500         |\n",
      "|    policy_gradient_loss | -0.000952    |\n",
      "|    std                  | 0.669        |\n",
      "|    value_loss           | 5.26e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=10211.53 +/- 2848.90\n",
      "Episode length: 784.80 +/- 30.39\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 785       |\n",
      "|    mean_reward          | 1.02e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 720000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0085464 |\n",
      "|    clip_fraction        | 0.09      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -3.69     |\n",
      "|    explained_variance   | 0.982     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 265       |\n",
      "|    n_updates            | 3510      |\n",
      "|    policy_gradient_loss | -0.00845  |\n",
      "|    std                  | 0.663     |\n",
      "|    value_loss           | 899       |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 600       |\n",
      "|    ep_rew_mean     | -8.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 651       |\n",
      "|    iterations      | 352       |\n",
      "|    time_elapsed    | 1107      |\n",
      "|    total_timesteps | 720896    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 592          |\n",
      "|    ep_rew_mean          | -8.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 353          |\n",
      "|    time_elapsed         | 1109         |\n",
      "|    total_timesteps      | 722944       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009307353 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.66        |\n",
      "|    explained_variance   | 0.166        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.18e+07     |\n",
      "|    n_updates            | 3520         |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    std                  | 0.663        |\n",
      "|    value_loss           | 2.9e+07      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 575          |\n",
      "|    ep_rew_mean          | -9.05e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 652          |\n",
      "|    iterations           | 354          |\n",
      "|    time_elapsed         | 1111         |\n",
      "|    total_timesteps      | 724992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012669656 |\n",
      "|    clip_fraction        | 0.00254      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.66        |\n",
      "|    explained_variance   | 0.153        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.51e+07     |\n",
      "|    n_updates            | 3530         |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.663        |\n",
      "|    value_loss           | 8.45e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=8040.38 +/- 4455.28\n",
      "Episode length: 766.40 +/- 25.46\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 766          |\n",
      "|    mean_reward          | 8.04e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 725000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019343928 |\n",
      "|    clip_fraction        | 0.011        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.66        |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.35e+07     |\n",
      "|    n_updates            | 3540         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    std                  | 0.664        |\n",
      "|    value_loss           | 6.32e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -8.71e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 652       |\n",
      "|    iterations      | 355       |\n",
      "|    time_elapsed    | 1114      |\n",
      "|    total_timesteps | 727040    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 588         |\n",
      "|    ep_rew_mean          | -8.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 1116        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007634367 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.66       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.27e+03    |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    std                  | 0.664       |\n",
      "|    value_loss           | 8.39e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=730000, episode_reward=12247.58 +/- 2128.81\n",
      "Episode length: 860.80 +/- 17.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 861          |\n",
      "|    mean_reward          | 1.22e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 730000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029407497 |\n",
      "|    clip_fraction        | 0.0163       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.65        |\n",
      "|    explained_variance   | 0.204        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.73e+07     |\n",
      "|    n_updates            | 3560         |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    std                  | 0.664        |\n",
      "|    value_loss           | 6.56e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 582       |\n",
      "|    ep_rew_mean     | -8.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 651       |\n",
      "|    iterations      | 357       |\n",
      "|    time_elapsed    | 1122      |\n",
      "|    total_timesteps | 731136    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 587          |\n",
      "|    ep_rew_mean          | -8.39e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 358          |\n",
      "|    time_elapsed         | 1124         |\n",
      "|    total_timesteps      | 733184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013029536 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.65        |\n",
      "|    explained_variance   | 0.165        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.14e+07     |\n",
      "|    n_updates            | 3570         |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    std                  | 0.663        |\n",
      "|    value_loss           | 4.47e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=735000, episode_reward=-175993.86 +/- 149907.36\n",
      "Episode length: 476.40 +/- 315.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 476          |\n",
      "|    mean_reward          | -1.76e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 735000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009732451 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.65        |\n",
      "|    explained_variance   | 0.176        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05e+07     |\n",
      "|    n_updates            | 3580         |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.664        |\n",
      "|    value_loss           | 4.56e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 596       |\n",
      "|    ep_rew_mean     | -7.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 651       |\n",
      "|    iterations      | 359       |\n",
      "|    time_elapsed    | 1127      |\n",
      "|    total_timesteps | 735232    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 585         |\n",
      "|    ep_rew_mean          | -8.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 360         |\n",
      "|    time_elapsed         | 1129        |\n",
      "|    total_timesteps      | 737280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013334807 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.6        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 262         |\n",
      "|    n_updates            | 3590        |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    std                  | 0.649       |\n",
      "|    value_loss           | 2e+03       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 591          |\n",
      "|    ep_rew_mean          | -8.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 653          |\n",
      "|    iterations           | 361          |\n",
      "|    time_elapsed         | 1131         |\n",
      "|    total_timesteps      | 739328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013324944 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.53        |\n",
      "|    explained_variance   | 0.168        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+08      |\n",
      "|    n_updates            | 3600         |\n",
      "|    policy_gradient_loss | 0.000471     |\n",
      "|    std                  | 0.648        |\n",
      "|    value_loss           | 2.17e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=-44116.13 +/- 112592.98\n",
      "Episode length: 748.80 +/- 278.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 749          |\n",
      "|    mean_reward          | -4.41e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 740000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017507537 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.53        |\n",
      "|    explained_variance   | 0.191        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.23e+07     |\n",
      "|    n_updates            | 3610         |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    std                  | 0.649        |\n",
      "|    value_loss           | 5.34e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 586       |\n",
      "|    ep_rew_mean     | -8.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 653       |\n",
      "|    iterations      | 362       |\n",
      "|    time_elapsed    | 1135      |\n",
      "|    total_timesteps | 741376    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 590          |\n",
      "|    ep_rew_mean          | -8.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 653          |\n",
      "|    iterations           | 363          |\n",
      "|    time_elapsed         | 1136         |\n",
      "|    total_timesteps      | 743424       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014983804 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.54        |\n",
      "|    explained_variance   | 0.168        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.03e+07     |\n",
      "|    n_updates            | 3620         |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    std                  | 0.649        |\n",
      "|    value_loss           | 1.72e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=745000, episode_reward=-43777.51 +/- 110558.28\n",
      "Episode length: 803.20 +/- 307.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 803         |\n",
      "|    mean_reward          | -4.38e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 745000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002287084 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.54       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+07    |\n",
      "|    n_updates            | 3630        |\n",
      "|    policy_gradient_loss | -0.000727   |\n",
      "|    std                  | 0.651       |\n",
      "|    value_loss           | 1.88e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 600       |\n",
      "|    ep_rew_mean     | -7.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 653       |\n",
      "|    iterations      | 364       |\n",
      "|    time_elapsed    | 1140      |\n",
      "|    total_timesteps | 745472    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 599          |\n",
      "|    ep_rew_mean          | -7.58e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 654          |\n",
      "|    iterations           | 365          |\n",
      "|    time_elapsed         | 1142         |\n",
      "|    total_timesteps      | 747520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028221733 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | 0.174        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.59e+06     |\n",
      "|    n_updates            | 3640         |\n",
      "|    policy_gradient_loss | -0.00527     |\n",
      "|    std                  | 0.652        |\n",
      "|    value_loss           | 3e+07        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 593          |\n",
      "|    ep_rew_mean          | -7.82e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 654          |\n",
      "|    iterations           | 366          |\n",
      "|    time_elapsed         | 1145         |\n",
      "|    total_timesteps      | 749568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009124945 |\n",
      "|    clip_fraction        | 0.00205      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.56        |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.72e+07     |\n",
      "|    n_updates            | 3650         |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    std                  | 0.652        |\n",
      "|    value_loss           | 9.26e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=13624.72 +/- 2581.49\n",
      "Episode length: 1113.40 +/- 16.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.11e+03    |\n",
      "|    mean_reward          | 1.36e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 750000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007460365 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.39e+06    |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    std                  | 0.651       |\n",
      "|    value_loss           | 6.58e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 603       |\n",
      "|    ep_rew_mean     | -7.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 653       |\n",
      "|    iterations      | 367       |\n",
      "|    time_elapsed    | 1149      |\n",
      "|    total_timesteps | 751616    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 614         |\n",
      "|    ep_rew_mean          | -7.72e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 1151        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009120101 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.51       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 230         |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.642       |\n",
      "|    value_loss           | 805         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=755000, episode_reward=-53417.91 +/- 136697.07\n",
      "Episode length: 943.60 +/- 345.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 944          |\n",
      "|    mean_reward          | -5.34e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 755000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003145576 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.48        |\n",
      "|    explained_variance   | 0.175        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+07     |\n",
      "|    n_updates            | 3680         |\n",
      "|    policy_gradient_loss | -0.00146     |\n",
      "|    std                  | 0.642        |\n",
      "|    value_loss           | 4.3e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 617       |\n",
      "|    ep_rew_mean     | -8.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 653       |\n",
      "|    iterations      | 369       |\n",
      "|    time_elapsed    | 1155      |\n",
      "|    total_timesteps | 755712    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 622           |\n",
      "|    ep_rew_mean          | -8.33e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 654           |\n",
      "|    iterations           | 370           |\n",
      "|    time_elapsed         | 1157          |\n",
      "|    total_timesteps      | 757760        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044277805 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.48         |\n",
      "|    explained_variance   | 0.193         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.02e+07      |\n",
      "|    n_updates            | 3690          |\n",
      "|    policy_gradient_loss | -0.000567     |\n",
      "|    std                  | 0.643         |\n",
      "|    value_loss           | 1.9e+08       |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 636          |\n",
      "|    ep_rew_mean          | -8.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 655          |\n",
      "|    iterations           | 371          |\n",
      "|    time_elapsed         | 1159         |\n",
      "|    total_timesteps      | 759808       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057390034 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.47        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 603          |\n",
      "|    n_updates            | 3700         |\n",
      "|    policy_gradient_loss | -0.00505     |\n",
      "|    std                  | 0.64         |\n",
      "|    value_loss           | 4.79e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=-48013.92 +/- 125100.08\n",
      "Episode length: 889.40 +/- 334.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 889         |\n",
      "|    mean_reward          | -4.8e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005651381 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 741         |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    std                  | 0.635       |\n",
      "|    value_loss           | 3.68e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 644       |\n",
      "|    ep_rew_mean     | -8.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 654       |\n",
      "|    iterations      | 372       |\n",
      "|    time_elapsed    | 1163      |\n",
      "|    total_timesteps | 761856    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 646         |\n",
      "|    ep_rew_mean          | -9.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 1165        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008118651 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.43       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.51e+05    |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    std                  | 0.637       |\n",
      "|    value_loss           | 8.72e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=765000, episode_reward=-52789.36 +/- 137627.47\n",
      "Episode length: 827.60 +/- 297.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 828          |\n",
      "|    mean_reward          | -5.28e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 765000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021713371 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.05e+07     |\n",
      "|    n_updates            | 3730         |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    std                  | 0.637        |\n",
      "|    value_loss           | 1.58e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 651       |\n",
      "|    ep_rew_mean     | -9.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 655       |\n",
      "|    iterations      | 374       |\n",
      "|    time_elapsed    | 1169      |\n",
      "|    total_timesteps | 765952    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 653           |\n",
      "|    ep_rew_mean          | -9.86e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 655           |\n",
      "|    iterations           | 375           |\n",
      "|    time_elapsed         | 1171          |\n",
      "|    total_timesteps      | 768000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00083050644 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.45         |\n",
      "|    explained_variance   | 0.667         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.74e+03      |\n",
      "|    n_updates            | 3740          |\n",
      "|    policy_gradient_loss | -0.00203      |\n",
      "|    std                  | 0.637         |\n",
      "|    value_loss           | 6.54e+04      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=13403.02 +/- 2928.41\n",
      "Episode length: 973.20 +/- 28.49\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 973           |\n",
      "|    mean_reward          | 1.34e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 770000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00025413063 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.45         |\n",
      "|    explained_variance   | 0.153         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.39e+07      |\n",
      "|    n_updates            | 3750          |\n",
      "|    policy_gradient_loss | -0.000868     |\n",
      "|    std                  | 0.637         |\n",
      "|    value_loss           | 1.25e+08      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 659       |\n",
      "|    ep_rew_mean     | -9.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 655       |\n",
      "|    iterations      | 376       |\n",
      "|    time_elapsed    | 1175      |\n",
      "|    total_timesteps | 770048    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 670          |\n",
      "|    ep_rew_mean          | -9.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 656          |\n",
      "|    iterations           | 377          |\n",
      "|    time_elapsed         | 1176         |\n",
      "|    total_timesteps      | 772096       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011711963 |\n",
      "|    clip_fraction        | 0.00635      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+07     |\n",
      "|    n_updates            | 3760         |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    std                  | 0.637        |\n",
      "|    value_loss           | 5.3e+07      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 674          |\n",
      "|    ep_rew_mean          | -9.8e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 656          |\n",
      "|    iterations           | 378          |\n",
      "|    time_elapsed         | 1178         |\n",
      "|    total_timesteps      | 774144       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012331966 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.149        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+07     |\n",
      "|    n_updates            | 3770         |\n",
      "|    policy_gradient_loss | -0.00578     |\n",
      "|    std                  | 0.637        |\n",
      "|    value_loss           | 5.24e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=-60421.72 +/- 145861.61\n",
      "Episode length: 852.40 +/- 292.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 852          |\n",
      "|    mean_reward          | -6.04e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 775000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024736319 |\n",
      "|    clip_fraction        | 0.0141       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.45        |\n",
      "|    explained_variance   | 0.178        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.07e+07     |\n",
      "|    n_updates            | 3780         |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    std                  | 0.638        |\n",
      "|    value_loss           | 6.08e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 678       |\n",
      "|    ep_rew_mean     | -1.02e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 656       |\n",
      "|    iterations      | 379       |\n",
      "|    time_elapsed    | 1182      |\n",
      "|    total_timesteps | 776192    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 676          |\n",
      "|    ep_rew_mean          | -1.05e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 657          |\n",
      "|    iterations           | 380          |\n",
      "|    time_elapsed         | 1184         |\n",
      "|    total_timesteps      | 778240       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015097735 |\n",
      "|    clip_fraction        | 0.0174       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.46        |\n",
      "|    explained_variance   | 0.199        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.71e+07     |\n",
      "|    n_updates            | 3790         |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    std                  | 0.639        |\n",
      "|    value_loss           | 7.18e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=780000, episode_reward=14774.19 +/- 2983.45\n",
      "Episode length: 1030.40 +/- 36.47\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.03e+03      |\n",
      "|    mean_reward          | 1.48e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 780000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043419658 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.47         |\n",
      "|    explained_variance   | 0.176         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.73e+07      |\n",
      "|    n_updates            | 3800          |\n",
      "|    policy_gradient_loss | -0.00194      |\n",
      "|    std                  | 0.639         |\n",
      "|    value_loss           | 5.1e+07       |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 685       |\n",
      "|    ep_rew_mean     | -1.04e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 656       |\n",
      "|    iterations      | 381       |\n",
      "|    time_elapsed    | 1188      |\n",
      "|    total_timesteps | 780288    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 689          |\n",
      "|    ep_rew_mean          | -1.04e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 657          |\n",
      "|    iterations           | 382          |\n",
      "|    time_elapsed         | 1190         |\n",
      "|    total_timesteps      | 782336       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027394048 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.47        |\n",
      "|    explained_variance   | 0.191        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.26e+07     |\n",
      "|    n_updates            | 3810         |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.641        |\n",
      "|    value_loss           | 6.78e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 696         |\n",
      "|    ep_rew_mean          | -1.04e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 1192        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006730951 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.46       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    std                  | 0.635       |\n",
      "|    value_loss           | 3.72e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=785000, episode_reward=18474.35 +/- 722.99\n",
      "Episode length: 1146.00 +/- 29.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.15e+03    |\n",
      "|    mean_reward          | 1.85e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 785000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013783911 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.38       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.8        |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    std                  | 0.618       |\n",
      "|    value_loss           | 452         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 709      |\n",
      "|    ep_rew_mean     | -1e+05   |\n",
      "| time/              |          |\n",
      "|    fps             | 657      |\n",
      "|    iterations      | 384      |\n",
      "|    time_elapsed    | 1196     |\n",
      "|    total_timesteps | 786432   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 719         |\n",
      "|    ep_rew_mean          | -1e+05      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 1198        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009553621 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 175         |\n",
      "|    n_updates            | 3840        |\n",
      "|    policy_gradient_loss | -0.00987    |\n",
      "|    std                  | 0.613       |\n",
      "|    value_loss           | 451         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=-63789.71 +/- 155215.24\n",
      "Episode length: 947.20 +/- 316.74\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 947          |\n",
      "|    mean_reward          | -6.38e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 790000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021384135 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.181        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.93e+06     |\n",
      "|    n_updates            | 3850         |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    std                  | 0.613        |\n",
      "|    value_loss           | 6.08e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 710       |\n",
      "|    ep_rew_mean     | -1.05e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 657       |\n",
      "|    iterations      | 386       |\n",
      "|    time_elapsed    | 1202      |\n",
      "|    total_timesteps | 790528    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 712          |\n",
      "|    ep_rew_mean          | -1.06e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 657          |\n",
      "|    iterations           | 387          |\n",
      "|    time_elapsed         | 1204         |\n",
      "|    total_timesteps      | 792576       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018695181 |\n",
      "|    clip_fraction        | 0.00747      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.202        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.33e+07     |\n",
      "|    n_updates            | 3860         |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.613        |\n",
      "|    value_loss           | 6.73e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 712           |\n",
      "|    ep_rew_mean          | -1.12e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 658           |\n",
      "|    iterations           | 388           |\n",
      "|    time_elapsed         | 1206          |\n",
      "|    total_timesteps      | 794624        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073544646 |\n",
      "|    clip_fraction        | 0.00381       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -3.28         |\n",
      "|    explained_variance   | 0.187         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.28e+07      |\n",
      "|    n_updates            | 3870          |\n",
      "|    policy_gradient_loss | -0.00128      |\n",
      "|    std                  | 0.613         |\n",
      "|    value_loss           | 7.36e+07      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=795000, episode_reward=-43085.96 +/- 118861.95\n",
      "Episode length: 876.80 +/- 341.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 877         |\n",
      "|    mean_reward          | -4.31e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 795000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002134602 |\n",
      "|    clip_fraction        | 0.0041      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.208       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.54e+07    |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    std                  | 0.613       |\n",
      "|    value_loss           | 1.53e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 719       |\n",
      "|    ep_rew_mean     | -1.13e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 658       |\n",
      "|    iterations      | 389       |\n",
      "|    time_elapsed    | 1210      |\n",
      "|    total_timesteps | 796672    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 719          |\n",
      "|    ep_rew_mean          | -1.16e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 658          |\n",
      "|    iterations           | 390          |\n",
      "|    time_elapsed         | 1212         |\n",
      "|    total_timesteps      | 798720       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 7.794745e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.28        |\n",
      "|    explained_variance   | 0.185        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8e+07        |\n",
      "|    n_updates            | 3890         |\n",
      "|    policy_gradient_loss | -0.000261    |\n",
      "|    std                  | 0.613        |\n",
      "|    value_loss           | 1.35e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=14226.22 +/- 2031.64\n",
      "Episode length: 1074.20 +/- 41.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.07e+03    |\n",
      "|    mean_reward          | 1.42e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003536113 |\n",
      "|    clip_fraction        | 0.00869     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.28       |\n",
      "|    explained_variance   | 0.508       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.93e+03    |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    std                  | 0.612       |\n",
      "|    value_loss           | 4.89e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 726       |\n",
      "|    ep_rew_mean     | -1.11e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 658       |\n",
      "|    iterations      | 391       |\n",
      "|    time_elapsed    | 1216      |\n",
      "|    total_timesteps | 800768    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 718         |\n",
      "|    ep_rew_mean          | -1.17e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 658         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 1218        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009195892 |\n",
      "|    clip_fraction        | 0.0946      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.24       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.5        |\n",
      "|    n_updates            | 3910        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    std                  | 0.601       |\n",
      "|    value_loss           | 455         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 719         |\n",
      "|    ep_rew_mean          | -1.21e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 659         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 1220        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003985751 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.19       |\n",
      "|    explained_variance   | 0.189       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.21e+07    |\n",
      "|    n_updates            | 3920        |\n",
      "|    policy_gradient_loss | -0.000629   |\n",
      "|    std                  | 0.6         |\n",
      "|    value_loss           | 9.95e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=805000, episode_reward=18995.93 +/- 3627.88\n",
      "Episode length: 1293.80 +/- 69.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.29e+03     |\n",
      "|    mean_reward          | 1.9e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 805000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011039901 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.12e+07     |\n",
      "|    n_updates            | 3930         |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    std                  | 0.6          |\n",
      "|    value_loss           | 1.16e+08     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 726       |\n",
      "|    ep_rew_mean     | -1.21e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 658       |\n",
      "|    iterations      | 394       |\n",
      "|    time_elapsed    | 1224      |\n",
      "|    total_timesteps | 806912    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 732          |\n",
      "|    ep_rew_mean          | -1.21e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 659          |\n",
      "|    iterations           | 395          |\n",
      "|    time_elapsed         | 1226         |\n",
      "|    total_timesteps      | 808960       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025422713 |\n",
      "|    clip_fraction        | 0.0193       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.19        |\n",
      "|    explained_variance   | 0.187        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.31e+07     |\n",
      "|    n_updates            | 3940         |\n",
      "|    policy_gradient_loss | -0.00768     |\n",
      "|    std                  | 0.601        |\n",
      "|    value_loss           | 4.9e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=-89973.05 +/- 143408.28\n",
      "Episode length: 1040.60 +/- 703.09\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.04e+03   |\n",
      "|    mean_reward          | -9e+04     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 810000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00917509 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -3.16      |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 115        |\n",
      "|    n_updates            | 3950       |\n",
      "|    policy_gradient_loss | -0.00657   |\n",
      "|    std                  | 0.593      |\n",
      "|    value_loss           | 1.37e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 735      |\n",
      "|    ep_rew_mean     | -1.2e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 658      |\n",
      "|    iterations      | 396      |\n",
      "|    time_elapsed    | 1231     |\n",
      "|    total_timesteps | 811008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 754         |\n",
      "|    ep_rew_mean          | -1.17e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 659         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 1232        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002211513 |\n",
      "|    clip_fraction        | 0.0041      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.13       |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.83e+07    |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    std                  | 0.593       |\n",
      "|    value_loss           | 1.51e+08    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=815000, episode_reward=-83035.49 +/- 138197.42\n",
      "Episode length: 1202.40 +/- 845.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.2e+03     |\n",
      "|    mean_reward          | -8.3e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 815000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008061905 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.12       |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    std                  | 0.592       |\n",
      "|    value_loss           | 7.23e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 758       |\n",
      "|    ep_rew_mean     | -1.17e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 658       |\n",
      "|    iterations      | 398       |\n",
      "|    time_elapsed    | 1237      |\n",
      "|    total_timesteps | 815104    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 771         |\n",
      "|    ep_rew_mean          | -1.16e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 659         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 1239        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011225669 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.09       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 3980        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    std                  | 0.59        |\n",
      "|    value_loss           | 428         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 771          |\n",
      "|    ep_rew_mean          | -1.16e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 660          |\n",
      "|    iterations           | 400          |\n",
      "|    time_elapsed         | 1241         |\n",
      "|    total_timesteps      | 819200       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032372975 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -3.07        |\n",
      "|    explained_variance   | 0.189        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.95e+07     |\n",
      "|    n_updates            | 3990         |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    std                  | 0.59         |\n",
      "|    value_loss           | 4.88e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=-50528.68 +/- 101779.09\n",
      "Episode length: 1291.20 +/- 965.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.29e+03    |\n",
      "|    mean_reward          | -5.05e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015026631 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.98       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.578       |\n",
      "|    value_loss           | 320         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 795       |\n",
      "|    ep_rew_mean     | -1.13e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 659       |\n",
      "|    iterations      | 401       |\n",
      "|    time_elapsed    | 1246      |\n",
      "|    total_timesteps | 821248    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 812         |\n",
      "|    ep_rew_mean          | -1.08e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 659         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 1247        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008648253 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | -0.00915    |\n",
      "|    std                  | 0.576       |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=825000, episode_reward=19239.93 +/- 104419.44\n",
      "Episode length: 3055.20 +/- 1606.70\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 3.06e+03      |\n",
      "|    mean_reward          | 1.92e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 825000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00061108574 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.92         |\n",
      "|    explained_variance   | 0.181         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.99e+07      |\n",
      "|    n_updates            | 4020          |\n",
      "|    policy_gradient_loss | -0.00316      |\n",
      "|    std                  | 0.576         |\n",
      "|    value_loss           | 2.97e+07      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 812       |\n",
      "|    ep_rew_mean     | -1.08e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 656       |\n",
      "|    iterations      | 403       |\n",
      "|    time_elapsed    | 1256      |\n",
      "|    total_timesteps | 825344    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 843         |\n",
      "|    ep_rew_mean          | -1.06e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 1258        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010081226 |\n",
      "|    clip_fraction        | 0.0921      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.91       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 393         |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.00854    |\n",
      "|    std                  | 0.574       |\n",
      "|    value_loss           | 1.03e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 843         |\n",
      "|    ep_rew_mean          | -1.06e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 658         |\n",
      "|    iterations           | 405         |\n",
      "|    time_elapsed         | 1260        |\n",
      "|    total_timesteps      | 829440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002245902 |\n",
      "|    clip_fraction        | 0.00669     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.45e+06    |\n",
      "|    n_updates            | 4040        |\n",
      "|    policy_gradient_loss | -0.000702   |\n",
      "|    std                  | 0.574       |\n",
      "|    value_loss           | 2.87e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=-27875.52 +/- 87514.02\n",
      "Episode length: 2521.40 +/- 1220.03\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.52e+03     |\n",
      "|    mean_reward          | -2.79e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 830000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065381634 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.39e+03     |\n",
      "|    n_updates            | 4050         |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    std                  | 0.573        |\n",
      "|    value_loss           | 1.91e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 859       |\n",
      "|    ep_rew_mean     | -1.08e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 655       |\n",
      "|    iterations      | 406       |\n",
      "|    time_elapsed    | 1268      |\n",
      "|    total_timesteps | 831488    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 881          |\n",
      "|    ep_rew_mean          | -1.1e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 656          |\n",
      "|    iterations           | 407          |\n",
      "|    time_elapsed         | 1270         |\n",
      "|    total_timesteps      | 833536       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019958792 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.69e+07     |\n",
      "|    n_updates            | 4060         |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    std                  | 0.574        |\n",
      "|    value_loss           | 3.6e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=835000, episode_reward=-160046.89 +/- 99490.01\n",
      "Episode length: 969.40 +/- 1659.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 969          |\n",
      "|    mean_reward          | -1.6e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 835000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027886266 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.89        |\n",
      "|    explained_variance   | 0.177        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.16e+07     |\n",
      "|    n_updates            | 4070         |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    std                  | 0.576        |\n",
      "|    value_loss           | 4.33e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 875       |\n",
      "|    ep_rew_mean     | -1.11e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 655       |\n",
      "|    iterations      | 408       |\n",
      "|    time_elapsed    | 1274      |\n",
      "|    total_timesteps | 835584    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 891           |\n",
      "|    ep_rew_mean          | -1.1e+05      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 656           |\n",
      "|    iterations           | 409           |\n",
      "|    time_elapsed         | 1276          |\n",
      "|    total_timesteps      | 837632        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026946233 |\n",
      "|    clip_fraction        | 0.000146      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.9          |\n",
      "|    explained_variance   | 0.208         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.03e+07      |\n",
      "|    n_updates            | 4080          |\n",
      "|    policy_gradient_loss | -0.000691     |\n",
      "|    std                  | 0.576         |\n",
      "|    value_loss           | 1.14e+08      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 916         |\n",
      "|    ep_rew_mean          | -1.08e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 657         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 1277        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004468322 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.9        |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 4090        |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    std                  | 0.576       |\n",
      "|    value_loss           | 6.45e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=-53980.04 +/- 125712.00\n",
      "Episode length: 2345.40 +/- 1827.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.35e+03    |\n",
      "|    mean_reward          | -5.4e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 840000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006797302 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.89       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 215         |\n",
      "|    n_updates            | 4100        |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    std                  | 0.574       |\n",
      "|    value_loss           | 3.56e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 916       |\n",
      "|    ep_rew_mean     | -1.08e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 654       |\n",
      "|    iterations      | 411       |\n",
      "|    time_elapsed    | 1285      |\n",
      "|    total_timesteps | 841728    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 923         |\n",
      "|    ep_rew_mean          | -1.13e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 1287        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008551236 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.86       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76          |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    std                  | 0.572       |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=845000, episode_reward=-130345.33 +/- 91963.14\n",
      "Episode length: 1146.80 +/- 1236.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.15e+03     |\n",
      "|    mean_reward          | -1.3e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 845000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008469778 |\n",
      "|    clip_fraction        | 0.000439     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.2          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.29e+07     |\n",
      "|    n_updates            | 4120         |\n",
      "|    policy_gradient_loss | 0.00152      |\n",
      "|    std                  | 0.572        |\n",
      "|    value_loss           | 9.34e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 948       |\n",
      "|    ep_rew_mean     | -1.12e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 654       |\n",
      "|    iterations      | 413       |\n",
      "|    time_elapsed    | 1291      |\n",
      "|    total_timesteps | 845824    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 935          |\n",
      "|    ep_rew_mean          | -1.11e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 655          |\n",
      "|    iterations           | 414          |\n",
      "|    time_elapsed         | 1293         |\n",
      "|    total_timesteps      | 847872       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046808524 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.84        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.73e+03     |\n",
      "|    n_updates            | 4130         |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    std                  | 0.572        |\n",
      "|    value_loss           | 9.76e+03     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 951           |\n",
      "|    ep_rew_mean          | -1.08e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 656           |\n",
      "|    iterations           | 415           |\n",
      "|    time_elapsed         | 1295          |\n",
      "|    total_timesteps      | 849920        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00091502967 |\n",
      "|    clip_fraction        | 0.00327       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.187         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.79e+07      |\n",
      "|    n_updates            | 4140          |\n",
      "|    policy_gradient_loss | -0.00275      |\n",
      "|    std                  | 0.572         |\n",
      "|    value_loss           | 7.99e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=-129523.57 +/- 95417.70\n",
      "Episode length: 1234.60 +/- 1341.74\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.23e+03      |\n",
      "|    mean_reward          | -1.3e+05      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 850000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00073300954 |\n",
      "|    clip_fraction        | 0.00103       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.84         |\n",
      "|    explained_variance   | 0.211         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+07      |\n",
      "|    n_updates            | 4150          |\n",
      "|    policy_gradient_loss | -0.00241      |\n",
      "|    std                  | 0.572         |\n",
      "|    value_loss           | 1.55e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 951       |\n",
      "|    ep_rew_mean     | -1.08e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 655       |\n",
      "|    iterations      | 416       |\n",
      "|    time_elapsed    | 1300      |\n",
      "|    total_timesteps | 851968    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 941         |\n",
      "|    ep_rew_mean          | -1.11e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 655         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 1301        |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011469599 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.82       |\n",
      "|    explained_variance   | 0.629       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 798         |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    std                  | 0.566       |\n",
      "|    value_loss           | 4.66e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=855000, episode_reward=-56511.45 +/- 128425.56\n",
      "Episode length: 2176.20 +/- 1658.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.18e+03    |\n",
      "|    mean_reward          | -5.65e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 855000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002668959 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.8        |\n",
      "|    explained_variance   | 0.202       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.5e+07     |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.00838    |\n",
      "|    std                  | 0.566       |\n",
      "|    value_loss           | 1.14e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 941       |\n",
      "|    ep_rew_mean     | -1.11e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 654       |\n",
      "|    iterations      | 418       |\n",
      "|    time_elapsed    | 1308      |\n",
      "|    total_timesteps | 856064    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 965         |\n",
      "|    ep_rew_mean          | -1.11e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 654         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 1310        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011861567 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.74       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.6        |\n",
      "|    n_updates            | 4180        |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    std                  | 0.554       |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=-67305.60 +/- 114075.37\n",
      "Episode length: 2292.20 +/- 1752.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.29e+03    |\n",
      "|    mean_reward          | -6.73e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 860000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012068462 |\n",
      "|    clip_fraction        | 0.0812      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.69       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 4190        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    std                  | 0.55        |\n",
      "|    value_loss           | 727         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 977       |\n",
      "|    ep_rew_mean     | -1.11e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 652       |\n",
      "|    iterations      | 420       |\n",
      "|    time_elapsed    | 1317      |\n",
      "|    total_timesteps | 860160    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 990         |\n",
      "|    ep_rew_mean          | -1.1e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 653         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 1319        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011698063 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.66       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.00489    |\n",
      "|    std                  | 0.548       |\n",
      "|    value_loss           | 4.91e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -1.06e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 653          |\n",
      "|    iterations           | 422          |\n",
      "|    time_elapsed         | 1321         |\n",
      "|    total_timesteps      | 864256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038370301 |\n",
      "|    clip_fraction        | 0.0557       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.66        |\n",
      "|    explained_variance   | 0.183        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.92e+05     |\n",
      "|    n_updates            | 4210         |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    std                  | 0.549        |\n",
      "|    value_loss           | 3.18e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=865000, episode_reward=-19859.50 +/- 114958.76\n",
      "Episode length: 2512.80 +/- 1162.67\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.51e+03     |\n",
      "|    mean_reward          | -1.99e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 865000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037061009 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.66        |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.78e+07     |\n",
      "|    n_updates            | 4220         |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    std                  | 0.55         |\n",
      "|    value_loss           | 4.68e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.06e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 651       |\n",
      "|    iterations      | 423       |\n",
      "|    time_elapsed    | 1329      |\n",
      "|    total_timesteps | 866304    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -1.09e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 652         |\n",
      "|    iterations           | 424         |\n",
      "|    time_elapsed         | 1331        |\n",
      "|    total_timesteps      | 868352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015917683 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 326         |\n",
      "|    n_updates            | 4230        |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    std                  | 0.542       |\n",
      "|    value_loss           | 770         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=-152214.02 +/- 155564.75\n",
      "Episode length: 1153.80 +/- 1128.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.15e+03    |\n",
      "|    mean_reward          | -1.52e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 870000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005532055 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.59       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34e+07    |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | 0.000921    |\n",
      "|    std                  | 0.542       |\n",
      "|    value_loss           | 8.17e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -1.11e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 651       |\n",
      "|    iterations      | 425       |\n",
      "|    time_elapsed    | 1335      |\n",
      "|    total_timesteps | 870400    |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -1.08e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 652           |\n",
      "|    iterations           | 426           |\n",
      "|    time_elapsed         | 1337          |\n",
      "|    total_timesteps      | 872448        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00044823173 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.59         |\n",
      "|    explained_variance   | 0.208         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.28e+07      |\n",
      "|    n_updates            | 4250          |\n",
      "|    policy_gradient_loss | -0.00186      |\n",
      "|    std                  | 0.542         |\n",
      "|    value_loss           | 7.42e+07      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | -1.08e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 652          |\n",
      "|    iterations           | 427          |\n",
      "|    time_elapsed         | 1339         |\n",
      "|    total_timesteps      | 874496       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065264567 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.59        |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.57e+06     |\n",
      "|    n_updates            | 4260         |\n",
      "|    policy_gradient_loss | -0.00871     |\n",
      "|    std                  | 0.541        |\n",
      "|    value_loss           | 7.87e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=875000, episode_reward=-33195.01 +/- 141118.00\n",
      "Episode length: 2399.00 +/- 1050.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.4e+03     |\n",
      "|    mean_reward          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 875000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008060083 |\n",
      "|    clip_fraction        | 0.0588      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.000993   |\n",
      "|    std                  | 0.542       |\n",
      "|    value_loss           | 473         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.06e+03  |\n",
      "|    ep_rew_mean     | -1.08e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 650       |\n",
      "|    iterations      | 428       |\n",
      "|    time_elapsed    | 1347      |\n",
      "|    total_timesteps | 876544    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.07e+03     |\n",
      "|    ep_rew_mean          | -1.08e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 651          |\n",
      "|    iterations           | 429          |\n",
      "|    time_elapsed         | 1348         |\n",
      "|    total_timesteps      | 878592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032283408 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.58        |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.94e+07     |\n",
      "|    n_updates            | 4280         |\n",
      "|    policy_gradient_loss | -0.006       |\n",
      "|    std                  | 0.542        |\n",
      "|    value_loss           | 5e+07        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=-71782.58 +/- 167646.96\n",
      "Episode length: 3667.20 +/- 435.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.67e+03    |\n",
      "|    mean_reward          | -7.18e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 880000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009174114 |\n",
      "|    clip_fraction        | 0.0691      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    std                  | 0.539       |\n",
      "|    value_loss           | 500         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.1e+03   |\n",
      "|    ep_rew_mean     | -1.05e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 647       |\n",
      "|    iterations      | 430       |\n",
      "|    time_elapsed    | 1359      |\n",
      "|    total_timesteps | 880640    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | -1.09e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 648         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 1361        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003007168 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.55       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+07    |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    std                  | 0.539       |\n",
      "|    value_loss           | 5.48e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -1.09e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 649          |\n",
      "|    iterations           | 432          |\n",
      "|    time_elapsed         | 1363         |\n",
      "|    total_timesteps      | 884736       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038068632 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.56        |\n",
      "|    explained_variance   | 0.678        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.34e+05     |\n",
      "|    n_updates            | 4310         |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    std                  | 0.54         |\n",
      "|    value_loss           | 1.91e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=885000, episode_reward=-305821.51 +/- 173332.43\n",
      "Episode length: 1043.00 +/- 921.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.04e+03     |\n",
      "|    mean_reward          | -3.06e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 885000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040158024 |\n",
      "|    clip_fraction        | 0.0389       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.251        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.7e+07      |\n",
      "|    n_updates            | 4320         |\n",
      "|    policy_gradient_loss | -0.00968     |\n",
      "|    std                  | 0.541        |\n",
      "|    value_loss           | 4.81e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -1.09e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 648       |\n",
      "|    iterations      | 433       |\n",
      "|    time_elapsed    | 1367      |\n",
      "|    total_timesteps | 886784    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -1.09e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 649         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 1369        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009573057 |\n",
      "|    clip_fraction        | 0.085       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.57       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    std                  | 0.544       |\n",
      "|    value_loss           | 441         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=-25304.43 +/- 141366.65\n",
      "Episode length: 3184.60 +/- 1443.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.18e+03     |\n",
      "|    mean_reward          | -2.53e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 890000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051761423 |\n",
      "|    clip_fraction        | 0.0655       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 4340         |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    std                  | 0.544        |\n",
      "|    value_loss           | 7.5e+03      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -1.14e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 646       |\n",
      "|    iterations      | 435       |\n",
      "|    time_elapsed    | 1378      |\n",
      "|    total_timesteps | 890880    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -1.13e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 646          |\n",
      "|    iterations           | 436          |\n",
      "|    time_elapsed         | 1380         |\n",
      "|    total_timesteps      | 892928       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023300839 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.3e+07      |\n",
      "|    n_updates            | 4350         |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    std                  | 0.544        |\n",
      "|    value_loss           | 1.57e+08     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -1.21e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 437          |\n",
      "|    time_elapsed         | 1382         |\n",
      "|    total_timesteps      | 894976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013171235 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.6e+07      |\n",
      "|    n_updates            | 4360         |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.545        |\n",
      "|    value_loss           | 4.37e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=895000, episode_reward=-51090.57 +/- 189207.73\n",
      "Episode length: 3401.00 +/- 1266.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.4e+03      |\n",
      "|    mean_reward          | -5.11e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 895000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038980546 |\n",
      "|    clip_fraction        | 0.0166       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.015        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.85e+07     |\n",
      "|    n_updates            | 4370         |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    std                  | 0.545        |\n",
      "|    value_loss           | 1.24e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -1.28e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 644       |\n",
      "|    iterations      | 438       |\n",
      "|    time_elapsed    | 1392      |\n",
      "|    total_timesteps | 897024    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -1.34e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 644          |\n",
      "|    iterations           | 439          |\n",
      "|    time_elapsed         | 1394         |\n",
      "|    total_timesteps      | 899072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017318752 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.57        |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.12e+07     |\n",
      "|    n_updates            | 4380         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    std                  | 0.545        |\n",
      "|    value_loss           | 6.8e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=-48034.26 +/- 192178.68\n",
      "Episode length: 3403.00 +/- 911.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.4e+03      |\n",
      "|    mean_reward          | -4.8e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 900000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032629762 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.58        |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.63e+07     |\n",
      "|    n_updates            | 4390         |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    std                  | 0.545        |\n",
      "|    value_loss           | 1.35e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -1.34e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 641       |\n",
      "|    iterations      | 440       |\n",
      "|    time_elapsed    | 1403      |\n",
      "|    total_timesteps | 901120    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.13e+03   |\n",
      "|    ep_rew_mean          | -1.38e+05  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 642        |\n",
      "|    iterations           | 441        |\n",
      "|    time_elapsed         | 1405       |\n",
      "|    total_timesteps      | 903168     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01278701 |\n",
      "|    clip_fraction        | 0.0938     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.55      |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 44.4       |\n",
      "|    n_updates            | 4400       |\n",
      "|    policy_gradient_loss | -0.00287   |\n",
      "|    std                  | 0.539      |\n",
      "|    value_loss           | 476        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=905000, episode_reward=-75127.90 +/- 4520.26\n",
      "Episode length: 3523.00 +/- 8.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.52e+03     |\n",
      "|    mean_reward          | -7.51e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 905000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031114435 |\n",
      "|    clip_fraction        | 0.0811       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.52        |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+07     |\n",
      "|    n_updates            | 4410         |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    std                  | 0.54         |\n",
      "|    value_loss           | 4.42e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.14e+03  |\n",
      "|    ep_rew_mean     | -1.38e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 639       |\n",
      "|    iterations      | 442       |\n",
      "|    time_elapsed    | 1415      |\n",
      "|    total_timesteps | 905216    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.15e+03     |\n",
      "|    ep_rew_mean          | -1.38e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 639          |\n",
      "|    iterations           | 443          |\n",
      "|    time_elapsed         | 1417         |\n",
      "|    total_timesteps      | 907264       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006027991 |\n",
      "|    clip_fraction        | 0.000146     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.52        |\n",
      "|    explained_variance   | 0.207        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.09e+07     |\n",
      "|    n_updates            | 4420         |\n",
      "|    policy_gradient_loss | -0.001       |\n",
      "|    std                  | 0.54         |\n",
      "|    value_loss           | 7.97e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -1.35e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 640         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 1419        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006418857 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.71e+04    |\n",
      "|    n_updates            | 4430        |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    std                  | 0.541       |\n",
      "|    value_loss           | 1.76e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=910000, episode_reward=-150592.63 +/- 163763.21\n",
      "Episode length: 1672.40 +/- 1755.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.67e+03    |\n",
      "|    mean_reward          | -1.51e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 910000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004700019 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+04       |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.000482   |\n",
      "|    std                  | 0.541       |\n",
      "|    value_loss           | 2.23e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.17e+03  |\n",
      "|    ep_rew_mean     | -1.38e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 639       |\n",
      "|    iterations      | 445       |\n",
      "|    time_elapsed    | 1425      |\n",
      "|    total_timesteps | 911360    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -1.35e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 639          |\n",
      "|    iterations           | 446          |\n",
      "|    time_elapsed         | 1427         |\n",
      "|    total_timesteps      | 913408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017881761 |\n",
      "|    clip_fraction        | 0.00864      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.53        |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.33e+07     |\n",
      "|    n_updates            | 4450         |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    std                  | 0.541        |\n",
      "|    value_loss           | 9.71e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=915000, episode_reward=-191029.69 +/- 114675.85\n",
      "Episode length: 873.60 +/- 1348.70\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 874           |\n",
      "|    mean_reward          | -1.91e+05     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 915000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00050783606 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.54         |\n",
      "|    explained_variance   | 0.205         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.47e+07      |\n",
      "|    n_updates            | 4460          |\n",
      "|    policy_gradient_loss | -0.000535     |\n",
      "|    std                  | 0.541         |\n",
      "|    value_loss           | 1.13e+08      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -1.35e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 639       |\n",
      "|    iterations      | 447       |\n",
      "|    time_elapsed    | 1431      |\n",
      "|    total_timesteps | 915456    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -1.4e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 640          |\n",
      "|    iterations           | 448          |\n",
      "|    time_elapsed         | 1432         |\n",
      "|    total_timesteps      | 917504       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042716134 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.54        |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.22e+07     |\n",
      "|    n_updates            | 4470         |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    std                  | 0.541        |\n",
      "|    value_loss           | 8.42e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.19e+03     |\n",
      "|    ep_rew_mean          | -1.4e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 640          |\n",
      "|    iterations           | 449          |\n",
      "|    time_elapsed         | 1434         |\n",
      "|    total_timesteps      | 919552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024282727 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.54        |\n",
      "|    explained_variance   | 0.196        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92e+07     |\n",
      "|    n_updates            | 4480         |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    std                  | 0.541        |\n",
      "|    value_loss           | 8.46e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=-215804.22 +/- 115382.98\n",
      "Episode length: 883.80 +/- 1320.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 884         |\n",
      "|    mean_reward          | -2.16e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 920000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010312967 |\n",
      "|    clip_fraction        | 0.0628      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.53       |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 363         |\n",
      "|    n_updates            | 4490        |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    std                  | 0.542       |\n",
      "|    value_loss           | 8.62e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.19e+03 |\n",
      "|    ep_rew_mean     | -1.4e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 640      |\n",
      "|    iterations      | 450      |\n",
      "|    time_elapsed    | 1438     |\n",
      "|    total_timesteps | 921600   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -1.39e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 641         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 1440        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008663667 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.51       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 214         |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    std                  | 0.54        |\n",
      "|    value_loss           | 6.12e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=925000, episode_reward=-97477.44 +/- 148200.96\n",
      "Episode length: 1617.80 +/- 1127.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.62e+03     |\n",
      "|    mean_reward          | -9.75e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 925000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036480245 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.5         |\n",
      "|    explained_variance   | 0.198        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.56e+07     |\n",
      "|    n_updates            | 4510         |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    std                  | 0.54         |\n",
      "|    value_loss           | 1.26e+08     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.19e+03  |\n",
      "|    ep_rew_mean     | -1.42e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 640       |\n",
      "|    iterations      | 452       |\n",
      "|    time_elapsed    | 1446      |\n",
      "|    total_timesteps | 925696    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.19e+03     |\n",
      "|    ep_rew_mean          | -1.42e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 640          |\n",
      "|    iterations           | 453          |\n",
      "|    time_elapsed         | 1447         |\n",
      "|    total_timesteps      | 927744       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024741187 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.5         |\n",
      "|    explained_variance   | 0.214        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.7e+07      |\n",
      "|    n_updates            | 4520         |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    std                  | 0.539        |\n",
      "|    value_loss           | 1.3e+08      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -1.41e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 641         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 1449        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012120702 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.48       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90.5        |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.00622    |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 1.34e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=-159108.02 +/- 154192.95\n",
      "Episode length: 1416.40 +/- 1437.12\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.42e+03   |\n",
      "|    mean_reward          | -1.59e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 930000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00486173 |\n",
      "|    clip_fraction        | 0.0787     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.45      |\n",
      "|    explained_variance   | 0.231      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.01e+07   |\n",
      "|    n_updates            | 4540       |\n",
      "|    policy_gradient_loss | -0.00274   |\n",
      "|    std                  | 0.535      |\n",
      "|    value_loss           | 8.5e+07    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -1.38e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 640       |\n",
      "|    iterations      | 455       |\n",
      "|    time_elapsed    | 1454      |\n",
      "|    total_timesteps | 931840    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | -1.38e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 641          |\n",
      "|    iterations           | 456          |\n",
      "|    time_elapsed         | 1456         |\n",
      "|    total_timesteps      | 933888       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049366634 |\n",
      "|    clip_fraction        | 0.0404       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 4550         |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    std                  | 0.535        |\n",
      "|    value_loss           | 1.9e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=935000, episode_reward=-127792.32 +/- 78637.81\n",
      "Episode length: 2050.20 +/- 896.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.05e+03     |\n",
      "|    mean_reward          | -1.28e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 935000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053705378 |\n",
      "|    clip_fraction        | 0.0614       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 95           |\n",
      "|    n_updates            | 4560         |\n",
      "|    policy_gradient_loss | -0.00354     |\n",
      "|    std                  | 0.535        |\n",
      "|    value_loss           | 1.97e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.2e+03   |\n",
      "|    ep_rew_mean     | -1.47e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 639       |\n",
      "|    iterations      | 457       |\n",
      "|    time_elapsed    | 1463      |\n",
      "|    total_timesteps | 935936    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -1.52e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 640         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 1465        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001764848 |\n",
      "|    clip_fraction        | 0.00464     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.213       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.92e+07    |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.00139    |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 1.31e+08    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=-227399.39 +/- 109672.96\n",
      "Episode length: 1167.60 +/- 1046.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.17e+03    |\n",
      "|    mean_reward          | -2.27e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 940000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004307131 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.197       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6e+07       |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.00778    |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 1.1e+08     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.14e+03  |\n",
      "|    ep_rew_mean     | -1.59e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 639       |\n",
      "|    iterations      | 459       |\n",
      "|    time_elapsed    | 1469      |\n",
      "|    total_timesteps | 940032    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -1.58e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 640         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 1471        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002476832 |\n",
      "|    clip_fraction        | 0.00688     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.68e+07    |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 1.23e+08    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -1.61e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 640          |\n",
      "|    iterations           | 461          |\n",
      "|    time_elapsed         | 1473         |\n",
      "|    total_timesteps      | 944128       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012907108 |\n",
      "|    clip_fraction        | 0.00225      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.219        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+07     |\n",
      "|    n_updates            | 4600         |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    std                  | 0.535        |\n",
      "|    value_loss           | 2.66e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=945000, episode_reward=-176592.89 +/- 106938.11\n",
      "Episode length: 1773.20 +/- 1188.17\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.77e+03     |\n",
      "|    mean_reward          | -1.77e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 945000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038507523 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.182        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.93e+07     |\n",
      "|    n_updates            | 4610         |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    std                  | 0.535        |\n",
      "|    value_loss           | 4.8e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -1.63e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 639       |\n",
      "|    iterations      | 462       |\n",
      "|    time_elapsed    | 1479      |\n",
      "|    total_timesteps | 946176    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -1.62e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 640         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 1481        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002736747 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.44e+07    |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    std                  | 0.535       |\n",
      "|    value_loss           | 4.7e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=-173176.52 +/- 123862.56\n",
      "Episode length: 1705.00 +/- 1081.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.70e+03     |\n",
      "|    mean_reward          | -1.73e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 950000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048327725 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.191        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.98e+07     |\n",
      "|    n_updates            | 4630         |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    std                  | 0.534        |\n",
      "|    value_loss           | 8.6e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.16e+03  |\n",
      "|    ep_rew_mean     | -1.62e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 464       |\n",
      "|    time_elapsed    | 1487      |\n",
      "|    total_timesteps | 950272    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.16e+03     |\n",
      "|    ep_rew_mean          | -1.62e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 639          |\n",
      "|    iterations           | 465          |\n",
      "|    time_elapsed         | 1489         |\n",
      "|    total_timesteps      | 952320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042421743 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.2e+07      |\n",
      "|    n_updates            | 4640         |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    std                  | 0.535        |\n",
      "|    value_loss           | 3.58e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -1.64e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 640         |\n",
      "|    iterations           | 466         |\n",
      "|    time_elapsed         | 1490        |\n",
      "|    total_timesteps      | 954368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008590359 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 770         |\n",
      "|    n_updates            | 4650        |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    std                  | 0.534       |\n",
      "|    value_loss           | 8.57e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=955000, episode_reward=-129326.08 +/- 108316.46\n",
      "Episode length: 2544.00 +/- 1065.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.54e+03     |\n",
      "|    mean_reward          | -1.29e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 955000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038555455 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.208        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+07     |\n",
      "|    n_updates            | 4660         |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    std                  | 0.535        |\n",
      "|    value_loss           | 7.37e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -1.64e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 638       |\n",
      "|    iterations      | 467       |\n",
      "|    time_elapsed    | 1498      |\n",
      "|    total_timesteps | 956416    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -1.65e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 638         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 1500        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004223532 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.62e+06    |\n",
      "|    n_updates            | 4670        |\n",
      "|    policy_gradient_loss | -0.00667    |\n",
      "|    std                  | 0.537       |\n",
      "|    value_loss           | 1.45e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=960000, episode_reward=-43930.14 +/- 154357.31\n",
      "Episode length: 2397.40 +/- 925.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.4e+03     |\n",
      "|    mean_reward          | -4.39e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 960000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007192701 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.46       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | 0.000104    |\n",
      "|    std                  | 0.536       |\n",
      "|    value_loss           | 6.61e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.17e+03  |\n",
      "|    ep_rew_mean     | -1.64e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 636       |\n",
      "|    iterations      | 469       |\n",
      "|    time_elapsed    | 1508      |\n",
      "|    total_timesteps | 960512    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.15e+03     |\n",
      "|    ep_rew_mean          | -1.66e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 637          |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 1509         |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033481487 |\n",
      "|    clip_fraction        | 0.0639       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.45        |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.77e+07     |\n",
      "|    n_updates            | 4690         |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    std                  | 0.536        |\n",
      "|    value_loss           | 2.04e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.16e+03     |\n",
      "|    ep_rew_mean          | -1.64e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 638          |\n",
      "|    iterations           | 471          |\n",
      "|    time_elapsed         | 1511         |\n",
      "|    total_timesteps      | 964608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031350337 |\n",
      "|    clip_fraction        | 0.0235       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.46        |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.84e+06     |\n",
      "|    n_updates            | 4700         |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    std                  | 0.536        |\n",
      "|    value_loss           | 5.08e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=965000, episode_reward=-213106.74 +/- 187590.14\n",
      "Episode length: 2770.00 +/- 1127.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.77e+03     |\n",
      "|    mean_reward          | -2.13e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 965000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051257224 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.46        |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+07     |\n",
      "|    n_updates            | 4710         |\n",
      "|    policy_gradient_loss | -0.00541     |\n",
      "|    std                  | 0.538        |\n",
      "|    value_loss           | 4.57e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -1.71e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 472       |\n",
      "|    time_elapsed    | 1519      |\n",
      "|    total_timesteps | 966656    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -1.69e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 473          |\n",
      "|    time_elapsed         | 1521         |\n",
      "|    total_timesteps      | 968704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050786543 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.46        |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.29e+07     |\n",
      "|    n_updates            | 4720         |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    std                  | 0.537        |\n",
      "|    value_loss           | 8.87e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=-57087.12 +/- 171414.38\n",
      "Episode length: 2505.00 +/- 849.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.50e+03    |\n",
      "|    mean_reward          | -5.71e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 970000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011004505 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.45       |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    std                  | 0.533       |\n",
      "|    value_loss           | 5.97e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.16e+03  |\n",
      "|    ep_rew_mean     | -1.67e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 474       |\n",
      "|    time_elapsed    | 1529      |\n",
      "|    total_timesteps | 970752    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | -1.65e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 1531        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010952188 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.43       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 202         |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    std                  | 0.532       |\n",
      "|    value_loss           | 796         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -1.65e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 1533        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015699258 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.39       |\n",
      "|    explained_variance   | 0.83        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32e+04    |\n",
      "|    n_updates            | 4750        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    std                  | 0.523       |\n",
      "|    value_loss           | 4.57e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=975000, episode_reward=13799.66 +/- 2361.01\n",
      "Episode length: 1960.80 +/- 11.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.96e+03    |\n",
      "|    mean_reward          | 1.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 975000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014030621 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.35       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.3        |\n",
      "|    n_updates            | 4760        |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    std                  | 0.52        |\n",
      "|    value_loss           | 2.9e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -1.66e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 477       |\n",
      "|    time_elapsed    | 1539      |\n",
      "|    total_timesteps | 976896    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -1.64e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 1541        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004213503 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.34       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.99e+07    |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.00654    |\n",
      "|    std                  | 0.52        |\n",
      "|    value_loss           | 4.6e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=-244815.65 +/- 211895.52\n",
      "Episode length: 1492.20 +/- 563.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.49e+03    |\n",
      "|    mean_reward          | -2.45e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 980000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008339858 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    std                  | 0.519       |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -1.61e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 479       |\n",
      "|    time_elapsed    | 1546      |\n",
      "|    total_timesteps | 980992    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -1.57e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 1548        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011757698 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 662         |\n",
      "|    n_updates            | 4790        |\n",
      "|    policy_gradient_loss | 0.000131    |\n",
      "|    std                  | 0.52        |\n",
      "|    value_loss           | 585         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=985000, episode_reward=-71546.67 +/- 174782.62\n",
      "Episode length: 1527.60 +/- 349.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.53e+03     |\n",
      "|    mean_reward          | -7.15e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 985000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041112714 |\n",
      "|    clip_fraction        | 0.0513       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.32        |\n",
      "|    explained_variance   | 0.188        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+07     |\n",
      "|    n_updates            | 4800         |\n",
      "|    policy_gradient_loss | -0.000888    |\n",
      "|    std                  | 0.52         |\n",
      "|    value_loss           | 2.52e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.1e+03  |\n",
      "|    ep_rew_mean     | -1.6e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 633      |\n",
      "|    iterations      | 481      |\n",
      "|    time_elapsed    | 1553     |\n",
      "|    total_timesteps | 985088   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -1.56e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 1555        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002737266 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.239       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.3e+07     |\n",
      "|    n_updates            | 4810        |\n",
      "|    policy_gradient_loss | -0.00413    |\n",
      "|    std                  | 0.521       |\n",
      "|    value_loss           | 5.1e+07     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -1.56e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 1557        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010456706 |\n",
      "|    clip_fraction        | 0.0878      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.32       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 502         |\n",
      "|    n_updates            | 4820        |\n",
      "|    policy_gradient_loss | -0.00977    |\n",
      "|    std                  | 0.518       |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=-152387.54 +/- 204527.53\n",
      "Episode length: 1737.60 +/- 707.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.74e+03    |\n",
      "|    mean_reward          | -1.52e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 990000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003122107 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.3        |\n",
      "|    explained_variance   | 0.195       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.77e+07    |\n",
      "|    n_updates            | 4830        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    std                  | 0.519       |\n",
      "|    value_loss           | 9.05e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | -1.6e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 633      |\n",
      "|    iterations      | 484      |\n",
      "|    time_elapsed    | 1563     |\n",
      "|    total_timesteps | 991232   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.07e+03     |\n",
      "|    ep_rew_mean          | -1.57e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 485          |\n",
      "|    time_elapsed         | 1565         |\n",
      "|    total_timesteps      | 993280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062065385 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.03e+06     |\n",
      "|    n_updates            | 4840         |\n",
      "|    policy_gradient_loss | -0.00547     |\n",
      "|    std                  | 0.519        |\n",
      "|    value_loss           | 5.4e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=995000, episode_reward=-252123.45 +/- 217577.91\n",
      "Episode length: 1128.80 +/- 400.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.13e+03    |\n",
      "|    mean_reward          | -2.52e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 995000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005082875 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 537         |\n",
      "|    n_updates            | 4850        |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    std                  | 0.519       |\n",
      "|    value_loss           | 1.03e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.05e+03 |\n",
      "|    ep_rew_mean     | -1.6e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 634      |\n",
      "|    iterations      | 486      |\n",
      "|    time_elapsed    | 1569     |\n",
      "|    total_timesteps | 995328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -1.54e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 1571        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003304788 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.59e+07    |\n",
      "|    n_updates            | 4860        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    std                  | 0.519       |\n",
      "|    value_loss           | 4.97e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.06e+03   |\n",
      "|    ep_rew_mean          | -1.53e+05  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 635        |\n",
      "|    iterations           | 488        |\n",
      "|    time_elapsed         | 1573       |\n",
      "|    total_timesteps      | 999424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00821278 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.32      |\n",
      "|    explained_variance   | 0.926      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 499        |\n",
      "|    n_updates            | 4870       |\n",
      "|    policy_gradient_loss | -0.00421   |\n",
      "|    std                  | 0.52       |\n",
      "|    value_loss           | 1.6e+04    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=-45367.77 +/- 119389.30\n",
      "Episode length: 1303.40 +/- 527.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.3e+03      |\n",
      "|    mean_reward          | -4.54e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043378365 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.32        |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.44e+07     |\n",
      "|    n_updates            | 4880         |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    std                  | 0.52         |\n",
      "|    value_loss           | 5.07e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -1.45e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 489       |\n",
      "|    time_elapsed    | 1578      |\n",
      "|    total_timesteps | 1001472   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.07e+03     |\n",
      "|    ep_rew_mean          | -1.41e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 490          |\n",
      "|    time_elapsed         | 1580         |\n",
      "|    total_timesteps      | 1003520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046650893 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.32        |\n",
      "|    explained_variance   | 0.215        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+07     |\n",
      "|    n_updates            | 4890         |\n",
      "|    policy_gradient_loss | -0.00757     |\n",
      "|    std                  | 0.521        |\n",
      "|    value_loss           | 4.81e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1005000, episode_reward=-89132.97 +/- 127993.46\n",
      "Episode length: 942.80 +/- 622.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 943         |\n",
      "|    mean_reward          | -8.91e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1005000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004085913 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.32       |\n",
      "|    explained_variance   | 0.225       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.72e+07    |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    std                  | 0.522       |\n",
      "|    value_loss           | 4.2e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -1.38e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 491       |\n",
      "|    time_elapsed    | 1584      |\n",
      "|    total_timesteps | 1005568   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -1.34e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 1586        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008074718 |\n",
      "|    clip_fraction        | 0.0832      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 798         |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    std                  | 0.521       |\n",
      "|    value_loss           | 3.72e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | -1.31e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 493          |\n",
      "|    time_elapsed         | 1588         |\n",
      "|    total_timesteps      | 1009664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032697292 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.33        |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.34e+07     |\n",
      "|    n_updates            | 4920         |\n",
      "|    policy_gradient_loss | -0.00418     |\n",
      "|    std                  | 0.52         |\n",
      "|    value_loss           | 5.13e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=-43854.27 +/- 117476.60\n",
      "Episode length: 1191.20 +/- 489.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.19e+03     |\n",
      "|    mean_reward          | -4.39e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1010000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045488933 |\n",
      "|    clip_fraction        | 0.0277       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.33        |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.91e+06     |\n",
      "|    n_updates            | 4930         |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    std                  | 0.521        |\n",
      "|    value_loss           | 2.37e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -1.35e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 494       |\n",
      "|    time_elapsed    | 1592      |\n",
      "|    total_timesteps | 1011712   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -1.3e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 1594        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005398281 |\n",
      "|    clip_fraction        | 0.0393      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.34       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.19e+07    |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.521       |\n",
      "|    value_loss           | 9.38e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1015000, episode_reward=-109534.56 +/- 152235.26\n",
      "Episode length: 959.20 +/- 566.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 959          |\n",
      "|    mean_reward          | -1.1e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1015000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042059934 |\n",
      "|    clip_fraction        | 0.0729       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.34        |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+07     |\n",
      "|    n_updates            | 4950         |\n",
      "|    policy_gradient_loss | -0.00639     |\n",
      "|    std                  | 0.522        |\n",
      "|    value_loss           | 3.75e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -1.26e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 496       |\n",
      "|    time_elapsed    | 1598      |\n",
      "|    total_timesteps | 1015808   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -1.23e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 497         |\n",
      "|    time_elapsed         | 1600        |\n",
      "|    total_timesteps      | 1017856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013700483 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.34       |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.4        |\n",
      "|    n_updates            | 4960        |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    std                  | 0.523       |\n",
      "|    value_loss           | 3.39e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -1.23e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 1602        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010915169 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.4        |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    std                  | 0.523       |\n",
      "|    value_loss           | 301         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=-95925.71 +/- 145373.10\n",
      "Episode length: 1391.40 +/- 942.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.39e+03     |\n",
      "|    mean_reward          | -9.59e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1020000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030071042 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.33        |\n",
      "|    explained_variance   | 0.0712       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.57e+07     |\n",
      "|    n_updates            | 4980         |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    std                  | 0.522        |\n",
      "|    value_loss           | 5.28e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.04e+03  |\n",
      "|    ep_rew_mean     | -1.23e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 499       |\n",
      "|    time_elapsed    | 1607      |\n",
      "|    total_timesteps | 1021952   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | -1.3e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 500          |\n",
      "|    time_elapsed         | 1609         |\n",
      "|    total_timesteps      | 1024000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039852425 |\n",
      "|    clip_fraction        | 0.0407       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.32        |\n",
      "|    explained_variance   | -5.96e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59e+06     |\n",
      "|    n_updates            | 4990         |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    std                  | 0.52         |\n",
      "|    value_loss           | 3.18e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1025000, episode_reward=-31959.45 +/- 115909.27\n",
      "Episode length: 2244.40 +/- 1014.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.24e+03     |\n",
      "|    mean_reward          | -3.2e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1025000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066141714 |\n",
      "|    clip_fraction        | 0.073        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.31        |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.01e+05     |\n",
      "|    n_updates            | 5000         |\n",
      "|    policy_gradient_loss | -0.0062      |\n",
      "|    std                  | 0.519        |\n",
      "|    value_loss           | 1.67e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.1e+03   |\n",
      "|    ep_rew_mean     | -1.27e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 501       |\n",
      "|    time_elapsed    | 1616      |\n",
      "|    total_timesteps | 1026048   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -1.28e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 1618        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011669515 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.3        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    std                  | 0.517       |\n",
      "|    value_loss           | 414         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1030000, episode_reward=-39636.77 +/- 126153.26\n",
      "Episode length: 1810.80 +/- 782.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.81e+03     |\n",
      "|    mean_reward          | -3.96e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1030000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019285486 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.179        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.62e+07     |\n",
      "|    n_updates            | 5020         |\n",
      "|    policy_gradient_loss | 0.00698      |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 2.85e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.09e+03  |\n",
      "|    ep_rew_mean     | -1.33e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 503       |\n",
      "|    time_elapsed    | 1624      |\n",
      "|    total_timesteps | 1030144   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.08e+03     |\n",
      "|    ep_rew_mean          | -1.35e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 504          |\n",
      "|    time_elapsed         | 1626         |\n",
      "|    total_timesteps      | 1032192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010635473 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.59e+07     |\n",
      "|    n_updates            | 5030         |\n",
      "|    policy_gradient_loss | -0.00114     |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 1.63e+08     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | -1.32e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 505          |\n",
      "|    time_elapsed         | 1628         |\n",
      "|    total_timesteps      | 1034240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014477795 |\n",
      "|    clip_fraction        | 0.000244     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.187        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.63e+07     |\n",
      "|    n_updates            | 5040         |\n",
      "|    policy_gradient_loss | -0.000901    |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 7.23e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1035000, episode_reward=-220369.56 +/- 119069.63\n",
      "Episode length: 625.80 +/- 797.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 626         |\n",
      "|    mean_reward          | -2.2e+05    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1035000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003050949 |\n",
      "|    clip_fraction        | 0.0101      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.159       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.55e+07    |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    std                  | 0.517       |\n",
      "|    value_loss           | 9.25e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | -1.3e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 635      |\n",
      "|    iterations      | 506      |\n",
      "|    time_elapsed    | 1631     |\n",
      "|    total_timesteps | 1036288  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | -1.34e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 507          |\n",
      "|    time_elapsed         | 1633         |\n",
      "|    total_timesteps      | 1038336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024885372 |\n",
      "|    clip_fraction        | 0.00708      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.204        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.77e+07     |\n",
      "|    n_updates            | 5060         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 5.47e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=-103262.49 +/- 148060.69\n",
      "Episode length: 1435.60 +/- 979.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.44e+03     |\n",
      "|    mean_reward          | -1.03e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023249038 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.227        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.41e+07     |\n",
      "|    n_updates            | 5070         |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 1.35e+08     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.1e+03   |\n",
      "|    ep_rew_mean     | -1.35e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 508       |\n",
      "|    time_elapsed    | 1638      |\n",
      "|    total_timesteps | 1040384   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.07e+03     |\n",
      "|    ep_rew_mean          | -1.36e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 509          |\n",
      "|    time_elapsed         | 1640         |\n",
      "|    total_timesteps      | 1042432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036018607 |\n",
      "|    clip_fraction        | 0.0109       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+07     |\n",
      "|    n_updates            | 5080         |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 3.22e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | -1.36e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 510          |\n",
      "|    time_elapsed         | 1642         |\n",
      "|    total_timesteps      | 1044480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008198291 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.205        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.82e+07     |\n",
      "|    n_updates            | 5090         |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 5.63e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1045000, episode_reward=-98740.46 +/- 2123.56\n",
      "Episode length: 1739.00 +/- 5.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.74e+03    |\n",
      "|    mean_reward          | -9.87e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1045000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003031148 |\n",
      "|    clip_fraction        | 0.00576     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.105       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+08    |\n",
      "|    n_updates            | 5100        |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    std                  | 0.517       |\n",
      "|    value_loss           | 2.43e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -1.35e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 511       |\n",
      "|    time_elapsed    | 1648      |\n",
      "|    total_timesteps | 1046528   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -1.32e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 1649        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004379756 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.38e+06    |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    std                  | 0.517       |\n",
      "|    value_loss           | 3.06e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=-144142.43 +/- 61426.96\n",
      "Episode length: 1380.80 +/- 586.41\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.38e+03     |\n",
      "|    mean_reward          | -1.44e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1050000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035813435 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.141        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+07     |\n",
      "|    n_updates            | 5120         |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 5.53e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.05e+03  |\n",
      "|    ep_rew_mean     | -1.33e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 513       |\n",
      "|    time_elapsed    | 1654      |\n",
      "|    total_timesteps | 1050624   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | -1.33e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 514          |\n",
      "|    time_elapsed         | 1656         |\n",
      "|    total_timesteps      | 1052672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015787334 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.14e+07     |\n",
      "|    n_updates            | 5130         |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 7.47e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.06e+03     |\n",
      "|    ep_rew_mean          | -1.3e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 515          |\n",
      "|    time_elapsed         | 1658         |\n",
      "|    total_timesteps      | 1054720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032270302 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.15         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.39e+07     |\n",
      "|    n_updates            | 5140         |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    std                  | 0.517        |\n",
      "|    value_loss           | 6.6e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1055000, episode_reward=-83979.88 +/- 128163.66\n",
      "Episode length: 1364.40 +/- 961.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.36e+03     |\n",
      "|    mean_reward          | -8.4e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1055000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064013824 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.29        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.15e+03     |\n",
      "|    n_updates            | 5150         |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    std                  | 0.516        |\n",
      "|    value_loss           | 3.64e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.06e+03  |\n",
      "|    ep_rew_mean     | -1.28e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 516       |\n",
      "|    time_elapsed    | 1663      |\n",
      "|    total_timesteps | 1056768   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -1.29e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 1665        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007296147 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.27       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.03e+03    |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.00691    |\n",
      "|    std                  | 0.512       |\n",
      "|    value_loss           | 8.51e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=12509.47 +/- 2351.86\n",
      "Episode length: 1497.20 +/- 4.07\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.5e+03      |\n",
      "|    mean_reward          | 1.25e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1060000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076495055 |\n",
      "|    clip_fraction        | 0.0567       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.26        |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+06     |\n",
      "|    n_updates            | 5170         |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    std                  | 0.512        |\n",
      "|    value_loss           | 4.64e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.06e+03  |\n",
      "|    ep_rew_mean     | -1.25e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 518       |\n",
      "|    time_elapsed    | 1670      |\n",
      "|    total_timesteps | 1060864   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -1.23e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 1672        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007089882 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    std                  | 0.51        |\n",
      "|    value_loss           | 1.09e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -1.21e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 1674        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003166341 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.187       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.78e+06    |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 3.92e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1065000, episode_reward=11738.31 +/- 2273.74\n",
      "Episode length: 1363.00 +/- 6.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.36e+03    |\n",
      "|    mean_reward          | 1.17e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1065000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004336941 |\n",
      "|    clip_fraction        | 0.0207      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.193       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+07    |\n",
      "|    n_updates            | 5200        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    std                  | 0.512       |\n",
      "|    value_loss           | 3.86e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -1.17e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 521       |\n",
      "|    time_elapsed    | 1679      |\n",
      "|    total_timesteps | 1067008   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 982          |\n",
      "|    ep_rew_mean          | -1.2e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 522          |\n",
      "|    time_elapsed         | 1681         |\n",
      "|    total_timesteps      | 1069056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055918423 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.21         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.24e+07     |\n",
      "|    n_updates            | 5210         |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.51         |\n",
      "|    value_loss           | 4.03e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1070000, episode_reward=9911.91 +/- 3194.13\n",
      "Episode length: 1497.80 +/- 5.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.5e+03     |\n",
      "|    mean_reward          | 9.91e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005026903 |\n",
      "|    clip_fraction        | 0.0516      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.185       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.39e+07    |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 7.07e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 945       |\n",
      "|    ep_rew_mean     | -1.28e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 523       |\n",
      "|    time_elapsed    | 1686      |\n",
      "|    total_timesteps | 1071104   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 946          |\n",
      "|    ep_rew_mean          | -1.28e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 524          |\n",
      "|    time_elapsed         | 1688         |\n",
      "|    total_timesteps      | 1073152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037843983 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.58e+07     |\n",
      "|    n_updates            | 5230         |\n",
      "|    policy_gradient_loss | -0.00466     |\n",
      "|    std                  | 0.511        |\n",
      "|    value_loss           | 8.72e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1075000, episode_reward=13538.00 +/- 1578.31\n",
      "Episode length: 1521.00 +/- 7.29\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.52e+03     |\n",
      "|    mean_reward          | 1.35e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1075000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031071415 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.223        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+07     |\n",
      "|    n_updates            | 5240         |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    std                  | 0.512        |\n",
      "|    value_loss           | 3.91e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 950       |\n",
      "|    ep_rew_mean     | -1.28e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 525       |\n",
      "|    time_elapsed    | 1693      |\n",
      "|    total_timesteps | 1075200   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 951         |\n",
      "|    ep_rew_mean          | -1.26e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 1695        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004619719 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+03    |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 4.01e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 947         |\n",
      "|    ep_rew_mean          | -1.29e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 1697        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013648327 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.91e+06    |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.00189    |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 3.71e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=21244.59 +/- 2944.23\n",
      "Episode length: 2153.20 +/- 28.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.15e+03    |\n",
      "|    mean_reward          | 2.12e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003886471 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5e+07     |\n",
      "|    n_updates            | 5270        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 2.49e+07    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 954       |\n",
      "|    ep_rew_mean     | -1.26e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 528       |\n",
      "|    time_elapsed    | 1704      |\n",
      "|    total_timesteps | 1081344   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 950          |\n",
      "|    ep_rew_mean          | -1.25e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 529          |\n",
      "|    time_elapsed         | 1706         |\n",
      "|    total_timesteps      | 1083392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009368408 |\n",
      "|    clip_fraction        | 0.00259      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.19         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.33e+07     |\n",
      "|    n_updates            | 5280         |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    std                  | 0.511        |\n",
      "|    value_loss           | 2.9e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1085000, episode_reward=-174449.59 +/- 3182.94\n",
      "Episode length: 907.40 +/- 964.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 907          |\n",
      "|    mean_reward          | -1.74e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1085000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034432188 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.24        |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.85e+07     |\n",
      "|    n_updates            | 5290         |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    std                  | 0.512        |\n",
      "|    value_loss           | 4.58e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 931       |\n",
      "|    ep_rew_mean     | -1.25e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 530       |\n",
      "|    time_elapsed    | 1710      |\n",
      "|    total_timesteps | 1085440   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 936         |\n",
      "|    ep_rew_mean          | -1.25e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 1711        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003971525 |\n",
      "|    clip_fraction        | 0.0181      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+07    |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    std                  | 0.513       |\n",
      "|    value_loss           | 6.32e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 948         |\n",
      "|    ep_rew_mean          | -1.2e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 1713        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008253962 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 815         |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    std                  | 0.512       |\n",
      "|    value_loss           | 4.01e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1090000, episode_reward=-28787.81 +/- 87750.87\n",
      "Episode length: 1689.00 +/- 779.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.69e+03     |\n",
      "|    mean_reward          | -2.88e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1090000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044389945 |\n",
      "|    clip_fraction        | 0.0917       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.26        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 245          |\n",
      "|    n_updates            | 5320         |\n",
      "|    policy_gradient_loss | -0.00155     |\n",
      "|    std                  | 0.514        |\n",
      "|    value_loss           | 2.49e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 941       |\n",
      "|    ep_rew_mean     | -1.23e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 533       |\n",
      "|    time_elapsed    | 1719      |\n",
      "|    total_timesteps | 1091584   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 943          |\n",
      "|    ep_rew_mean          | -1.23e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 534          |\n",
      "|    time_elapsed         | 1721         |\n",
      "|    total_timesteps      | 1093632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057488405 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.207        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+07     |\n",
      "|    n_updates            | 5330         |\n",
      "|    policy_gradient_loss | -0.0061      |\n",
      "|    std                  | 0.514        |\n",
      "|    value_loss           | 3.6e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1095000, episode_reward=24980.85 +/- 1622.99\n",
      "Episode length: 2338.20 +/- 8.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.34e+03    |\n",
      "|    mean_reward          | 2.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1095000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018323192 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.26       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.71e+04    |\n",
      "|    n_updates            | 5340        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    std                  | 0.514       |\n",
      "|    value_loss           | 2.77e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 957       |\n",
      "|    ep_rew_mean     | -1.21e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 535       |\n",
      "|    time_elapsed    | 1728      |\n",
      "|    total_timesteps | 1095680   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 960        |\n",
      "|    ep_rew_mean          | -1.2e+05   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 634        |\n",
      "|    iterations           | 536        |\n",
      "|    time_elapsed         | 1730       |\n",
      "|    total_timesteps      | 1097728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00266578 |\n",
      "|    clip_fraction        | 0.0467     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.26      |\n",
      "|    explained_variance   | 0.22       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.32e+07   |\n",
      "|    n_updates            | 5350       |\n",
      "|    policy_gradient_loss | -0.00243   |\n",
      "|    std                  | 0.514      |\n",
      "|    value_loss           | 3.95e+07   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 962          |\n",
      "|    ep_rew_mean          | -1.2e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 537          |\n",
      "|    time_elapsed         | 1732         |\n",
      "|    total_timesteps      | 1099776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019806996 |\n",
      "|    clip_fraction        | 0.00151      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.27        |\n",
      "|    explained_variance   | 0.199        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.64e+07     |\n",
      "|    n_updates            | 5360         |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    std                  | 0.514        |\n",
      "|    value_loss           | 3.41e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=-21190.63 +/- 82687.17\n",
      "Episode length: 1864.00 +/- 871.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.86e+03     |\n",
      "|    mean_reward          | -2.12e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1100000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050679026 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.26        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 614          |\n",
      "|    n_updates            | 5370         |\n",
      "|    policy_gradient_loss | -0.00356     |\n",
      "|    std                  | 0.512        |\n",
      "|    value_loss           | 3.08e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 979       |\n",
      "|    ep_rew_mean     | -1.17e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 538       |\n",
      "|    time_elapsed    | 1738      |\n",
      "|    total_timesteps | 1101824   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 987          |\n",
      "|    ep_rew_mean          | -1.17e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 539          |\n",
      "|    time_elapsed         | 1740         |\n",
      "|    total_timesteps      | 1103872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013899665 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.31e+04     |\n",
      "|    n_updates            | 5380         |\n",
      "|    policy_gradient_loss | -0.000977    |\n",
      "|    std                  | 0.512        |\n",
      "|    value_loss           | 2.01e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1105000, episode_reward=-21612.15 +/- 88651.20\n",
      "Episode length: 1868.80 +/- 868.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.87e+03    |\n",
      "|    mean_reward          | -2.16e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1105000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006018447 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 359         |\n",
      "|    n_updates            | 5390        |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    std                  | 0.513       |\n",
      "|    value_loss           | 1.9e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 995       |\n",
      "|    ep_rew_mean     | -1.19e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 540       |\n",
      "|    time_elapsed    | 1746      |\n",
      "|    total_timesteps | 1105920   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -1.21e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 1748        |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005062056 |\n",
      "|    clip_fraction        | 0.0369      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.55e+07    |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    std                  | 0.512       |\n",
      "|    value_loss           | 2.77e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=-17339.36 +/- 84291.15\n",
      "Episode length: 1871.80 +/- 868.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.87e+03     |\n",
      "|    mean_reward          | -1.73e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1110000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029764646 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.25        |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+07     |\n",
      "|    n_updates            | 5410         |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    std                  | 0.513        |\n",
      "|    value_loss           | 6.83e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.01e+03 |\n",
      "|    ep_rew_mean     | -1.2e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 632      |\n",
      "|    iterations      | 542      |\n",
      "|    time_elapsed    | 1754     |\n",
      "|    total_timesteps | 1110016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -1.2e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 543         |\n",
      "|    time_elapsed         | 1756        |\n",
      "|    total_timesteps      | 1112064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003327088 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.22        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.29e+07    |\n",
      "|    n_updates            | 5420        |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    std                  | 0.513       |\n",
      "|    value_loss           | 2.97e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -1.21e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 1758        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009588538 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.25       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 289         |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 7.99e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1115000, episode_reward=-169315.00 +/- 27234.32\n",
      "Episode length: 1110.00 +/- 795.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.11e+03    |\n",
      "|    mean_reward          | -1.69e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1115000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003157547 |\n",
      "|    clip_fraction        | 0.0288      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.21        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.88e+07    |\n",
      "|    n_updates            | 5440        |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 1.19e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -1.21e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 545       |\n",
      "|    time_elapsed    | 1762      |\n",
      "|    total_timesteps | 1116160   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -1.2e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 1764        |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004607749 |\n",
      "|    clip_fraction        | 0.0255      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.233       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52e+07    |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 3.35e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=19343.31 +/- 181.27\n",
      "Episode length: 2438.80 +/- 6.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.44e+03    |\n",
      "|    mean_reward          | 1.93e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003226637 |\n",
      "|    clip_fraction        | 0.0343      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 5460        |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    std                  | 0.511       |\n",
      "|    value_loss           | 7.77e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.04e+03 |\n",
      "|    ep_rew_mean     | -1.2e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 632      |\n",
      "|    iterations      | 547      |\n",
      "|    time_elapsed    | 1772     |\n",
      "|    total_timesteps | 1120256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.03e+03    |\n",
      "|    ep_rew_mean          | -1.2e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 1774        |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007213774 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 337         |\n",
      "|    n_updates            | 5470        |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    std                  | 0.509       |\n",
      "|    value_loss           | 4.11e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 963         |\n",
      "|    ep_rew_mean          | -1.14e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 1776        |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014859488 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 83          |\n",
      "|    n_updates            | 5480        |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    std                  | 0.502       |\n",
      "|    value_loss           | 2.27e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1125000, episode_reward=-34233.95 +/- 92807.35\n",
      "Episode length: 1791.40 +/- 823.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.79e+03    |\n",
      "|    mean_reward          | -3.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1125000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003054034 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.19        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.8e+07     |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.00105    |\n",
      "|    std                  | 0.502       |\n",
      "|    value_loss           | 6.15e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 953       |\n",
      "|    ep_rew_mean     | -1.08e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 632       |\n",
      "|    iterations      | 550       |\n",
      "|    time_elapsed    | 1782      |\n",
      "|    total_timesteps | 1126400   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 944          |\n",
      "|    ep_rew_mean          | -1.11e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 632          |\n",
      "|    iterations           | 551          |\n",
      "|    time_elapsed         | 1783         |\n",
      "|    total_timesteps      | 1128448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021111746 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.206        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.8e+07      |\n",
      "|    n_updates            | 5500         |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    std                  | 0.502        |\n",
      "|    value_loss           | 1.55e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1130000, episode_reward=19208.02 +/- 1557.21\n",
      "Episode length: 2321.60 +/- 5.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.32e+03     |\n",
      "|    mean_reward          | 1.92e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1130000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009824035 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.194        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.06e+07     |\n",
      "|    n_updates            | 5510         |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    std                  | 0.502        |\n",
      "|    value_loss           | 7.97e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 940       |\n",
      "|    ep_rew_mean     | -1.09e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 552       |\n",
      "|    time_elapsed    | 1791      |\n",
      "|    total_timesteps | 1130496   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 949          |\n",
      "|    ep_rew_mean          | -1.08e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 553          |\n",
      "|    time_elapsed         | 1793         |\n",
      "|    total_timesteps      | 1132544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039201174 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.85e+07     |\n",
      "|    n_updates            | 5520         |\n",
      "|    policy_gradient_loss | -0.00707     |\n",
      "|    std                  | 0.503        |\n",
      "|    value_loss           | 7.5e+07      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 971          |\n",
      "|    ep_rew_mean          | -1.02e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 632          |\n",
      "|    iterations           | 554          |\n",
      "|    time_elapsed         | 1794         |\n",
      "|    total_timesteps      | 1134592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068346434 |\n",
      "|    clip_fraction        | 0.0759       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 5530         |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    std                  | 0.503        |\n",
      "|    value_loss           | 4.74e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1135000, episode_reward=-115172.73 +/- 101338.85\n",
      "Episode length: 738.40 +/- 741.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 738          |\n",
      "|    mean_reward          | -1.15e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1135000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064816475 |\n",
      "|    clip_fraction        | 0.0621       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 479          |\n",
      "|    n_updates            | 5540         |\n",
      "|    policy_gradient_loss | -0.00055     |\n",
      "|    std                  | 0.503        |\n",
      "|    value_loss           | 2.2e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 973      |\n",
      "|    ep_rew_mean     | -1e+05   |\n",
      "| time/              |          |\n",
      "|    fps             | 632      |\n",
      "|    iterations      | 555      |\n",
      "|    time_elapsed    | 1798     |\n",
      "|    total_timesteps | 1136640  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 973        |\n",
      "|    ep_rew_mean          | -9.76e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 632        |\n",
      "|    iterations           | 556        |\n",
      "|    time_elapsed         | 1800       |\n",
      "|    total_timesteps      | 1138688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01049768 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.18      |\n",
      "|    explained_variance   | 0.855      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 56.9       |\n",
      "|    n_updates            | 5550       |\n",
      "|    policy_gradient_loss | -0.000527  |\n",
      "|    std                  | 0.505      |\n",
      "|    value_loss           | 2.28e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1140000, episode_reward=-200291.00 +/- 2606.96\n",
      "Episode length: 1182.40 +/- 849.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.18e+03    |\n",
      "|    mean_reward          | -2e+05      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006389719 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 689         |\n",
      "|    n_updates            | 5560        |\n",
      "|    policy_gradient_loss | 0.000281    |\n",
      "|    std                  | 0.505       |\n",
      "|    value_loss           | 3.69e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 965       |\n",
      "|    ep_rew_mean     | -9.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 632       |\n",
      "|    iterations      | 557       |\n",
      "|    time_elapsed    | 1804      |\n",
      "|    total_timesteps | 1140736   |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 988           |\n",
      "|    ep_rew_mean          | -9.4e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 632           |\n",
      "|    iterations           | 558           |\n",
      "|    time_elapsed         | 1806          |\n",
      "|    total_timesteps      | 1142784       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072425505 |\n",
      "|    clip_fraction        | 0.000879      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.19         |\n",
      "|    explained_variance   | 0.202         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.52e+07      |\n",
      "|    n_updates            | 5570          |\n",
      "|    policy_gradient_loss | -0.0011       |\n",
      "|    std                  | 0.505         |\n",
      "|    value_loss           | 5.69e+07      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 995         |\n",
      "|    ep_rew_mean          | -9.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 1808        |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002360232 |\n",
      "|    clip_fraction        | 0.0061      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.216       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.79e+07    |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    std                  | 0.505       |\n",
      "|    value_loss           | 7.8e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1145000, episode_reward=-210098.59 +/- 3805.81\n",
      "Episode length: 1912.20 +/- 4.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.91e+03     |\n",
      "|    mean_reward          | -2.1e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1145000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054047164 |\n",
      "|    clip_fraction        | 0.0275       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.226        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61e+07     |\n",
      "|    n_updates            | 5590         |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    std                  | 0.505        |\n",
      "|    value_loss           | 3.67e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 997       |\n",
      "|    ep_rew_mean     | -9.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 560       |\n",
      "|    time_elapsed    | 1814      |\n",
      "|    total_timesteps | 1146880   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -9.01e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 632         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 1816        |\n",
      "|    total_timesteps      | 1148928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006851325 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.42e+07    |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    std                  | 0.505       |\n",
      "|    value_loss           | 3.64e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=-29324.93 +/- 88967.67\n",
      "Episode length: 1873.20 +/- 871.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.87e+03     |\n",
      "|    mean_reward          | -2.93e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1150000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023349521 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.248        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.08e+06     |\n",
      "|    n_updates            | 5610         |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    std                  | 0.503        |\n",
      "|    value_loss           | 1.85e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -8.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 562       |\n",
      "|    time_elapsed    | 1823      |\n",
      "|    total_timesteps | 1150976   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 999         |\n",
      "|    ep_rew_mean          | -8.75e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 1824        |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008486138 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.54e+06    |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.000187   |\n",
      "|    std                  | 0.502       |\n",
      "|    value_loss           | 1.12e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1155000, episode_reward=20733.60 +/- 2326.36\n",
      "Episode length: 2680.00 +/- 5.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.68e+03     |\n",
      "|    mean_reward          | 2.07e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1155000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019399283 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.157        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.21e+07     |\n",
      "|    n_updates            | 5630         |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.502        |\n",
      "|    value_loss           | 1.03e+08     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 998       |\n",
      "|    ep_rew_mean     | -8.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 564       |\n",
      "|    time_elapsed    | 1833      |\n",
      "|    total_timesteps | 1155072   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 995          |\n",
      "|    ep_rew_mean          | -8.76e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 565          |\n",
      "|    time_elapsed         | 1834         |\n",
      "|    total_timesteps      | 1157120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043471386 |\n",
      "|    clip_fraction        | 0.066        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.19        |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 548          |\n",
      "|    n_updates            | 5640         |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    std                  | 0.503        |\n",
      "|    value_loss           | 1.79e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 999         |\n",
      "|    ep_rew_mean          | -8.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 566         |\n",
      "|    time_elapsed         | 1836        |\n",
      "|    total_timesteps      | 1159168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004986093 |\n",
      "|    clip_fraction        | 0.0274      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.18       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 958         |\n",
      "|    n_updates            | 5650        |\n",
      "|    policy_gradient_loss | -0.00271    |\n",
      "|    std                  | 0.503       |\n",
      "|    value_loss           | 5.35e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=-27073.43 +/- 77039.36\n",
      "Episode length: 1450.80 +/- 664.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.45e+03     |\n",
      "|    mean_reward          | -2.71e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049547167 |\n",
      "|    clip_fraction        | 0.0407       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.18        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 787          |\n",
      "|    n_updates            | 5660         |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    std                  | 0.501        |\n",
      "|    value_loss           | 5.67e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 983       |\n",
      "|    ep_rew_mean     | -9.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 567       |\n",
      "|    time_elapsed    | 1841      |\n",
      "|    total_timesteps | 1161216   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 988          |\n",
      "|    ep_rew_mean          | -9.03e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 568          |\n",
      "|    time_elapsed         | 1843         |\n",
      "|    total_timesteps      | 1163264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026177042 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.17        |\n",
      "|    explained_variance   | 0.197        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.09e+07     |\n",
      "|    n_updates            | 5670         |\n",
      "|    policy_gradient_loss | -0.0011      |\n",
      "|    std                  | 0.501        |\n",
      "|    value_loss           | 9.28e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1165000, episode_reward=-69677.33 +/- 97678.35\n",
      "Episode length: 1206.60 +/- 890.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.21e+03    |\n",
      "|    mean_reward          | -6.97e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1165000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007813772 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.17       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.000863   |\n",
      "|    std                  | 0.502       |\n",
      "|    value_loss           | 2.65e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 992       |\n",
      "|    ep_rew_mean     | -8.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 569       |\n",
      "|    time_elapsed    | 1848      |\n",
      "|    total_timesteps | 1165312   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -8.73e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 630        |\n",
      "|    iterations           | 570        |\n",
      "|    time_elapsed         | 1850       |\n",
      "|    total_timesteps      | 1167360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00219939 |\n",
      "|    clip_fraction        | 0.0142     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.16      |\n",
      "|    explained_variance   | 0.19       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.69e+07   |\n",
      "|    n_updates            | 5690       |\n",
      "|    policy_gradient_loss | -0.00246   |\n",
      "|    std                  | 0.501      |\n",
      "|    value_loss           | 3.19e+07   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -8.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 1852        |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010721333 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    std                  | 0.499       |\n",
      "|    value_loss           | 615         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1170000, episode_reward=-65450.87 +/- 101489.32\n",
      "Episode length: 1290.60 +/- 957.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.29e+03     |\n",
      "|    mean_reward          | -6.55e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1170000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052270526 |\n",
      "|    clip_fraction        | 0.0477       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.14        |\n",
      "|    explained_variance   | 0.61         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+06     |\n",
      "|    n_updates            | 5710         |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    std                  | 0.499        |\n",
      "|    value_loss           | 8.26e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -8.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 572       |\n",
      "|    time_elapsed    | 1856      |\n",
      "|    total_timesteps | 1171456   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -8.42e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 573          |\n",
      "|    time_elapsed         | 1858         |\n",
      "|    total_timesteps      | 1173504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041335393 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.166        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.64e+07     |\n",
      "|    n_updates            | 5720         |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    std                  | 0.499        |\n",
      "|    value_loss           | 3.34e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1175000, episode_reward=-74613.40 +/- 112410.47\n",
      "Episode length: 1282.60 +/- 933.34\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.28e+03     |\n",
      "|    mean_reward          | -7.46e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1175000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050699455 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.14e+07     |\n",
      "|    n_updates            | 5730         |\n",
      "|    policy_gradient_loss | -0.00614     |\n",
      "|    std                  | 0.499        |\n",
      "|    value_loss           | 8.64e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -8.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 574       |\n",
      "|    time_elapsed    | 1863      |\n",
      "|    total_timesteps | 1175552   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -8.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 575          |\n",
      "|    time_elapsed         | 1865         |\n",
      "|    total_timesteps      | 1177600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048488267 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.14        |\n",
      "|    explained_variance   | 0.211        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.62e+06     |\n",
      "|    n_updates            | 5740         |\n",
      "|    policy_gradient_loss | -0.00762     |\n",
      "|    std                  | 0.501        |\n",
      "|    value_loss           | 3.64e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -8.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 576          |\n",
      "|    time_elapsed         | 1867         |\n",
      "|    total_timesteps      | 1179648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063875597 |\n",
      "|    clip_fraction        | 0.0427       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.14        |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 272          |\n",
      "|    n_updates            | 5750         |\n",
      "|    policy_gradient_loss | -0.00324     |\n",
      "|    std                  | 0.5          |\n",
      "|    value_loss           | 5.07e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=6722.22 +/- 1861.82\n",
      "Episode length: 2489.60 +/- 18.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.49e+03     |\n",
      "|    mean_reward          | 6.72e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1180000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063302484 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 229          |\n",
      "|    n_updates            | 5760         |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    std                  | 0.498        |\n",
      "|    value_loss           | 2.79e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -8.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 577       |\n",
      "|    time_elapsed    | 1874      |\n",
      "|    total_timesteps | 1181696   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -8.48e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 578         |\n",
      "|    time_elapsed         | 1876        |\n",
      "|    total_timesteps      | 1183744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005874131 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.203       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.66e+06    |\n",
      "|    n_updates            | 5770        |\n",
      "|    policy_gradient_loss | -0.00454    |\n",
      "|    std                  | 0.499       |\n",
      "|    value_loss           | 3.65e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1185000, episode_reward=11604.31 +/- 784.35\n",
      "Episode length: 2270.80 +/- 11.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.27e+03     |\n",
      "|    mean_reward          | 1.16e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1185000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042560017 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.4e+06      |\n",
      "|    n_updates            | 5780         |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    std                  | 0.501        |\n",
      "|    value_loss           | 3.84e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -8.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 579       |\n",
      "|    time_elapsed    | 1883      |\n",
      "|    total_timesteps | 1185792   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 982         |\n",
      "|    ep_rew_mean          | -9.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 1885        |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004813033 |\n",
      "|    clip_fraction        | 0.0279      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.14       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.25e+07    |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    std                  | 0.501       |\n",
      "|    value_loss           | 1.18e+08    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 979        |\n",
      "|    ep_rew_mean          | -9.17e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 630        |\n",
      "|    iterations           | 581        |\n",
      "|    time_elapsed         | 1887       |\n",
      "|    total_timesteps      | 1189888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00321653 |\n",
      "|    clip_fraction        | 0.0158     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.14      |\n",
      "|    explained_variance   | 0.258      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.37e+07   |\n",
      "|    n_updates            | 5800       |\n",
      "|    policy_gradient_loss | -0.00272   |\n",
      "|    std                  | 0.502      |\n",
      "|    value_loss           | 7.27e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1190000, episode_reward=-38983.01 +/- 103645.14\n",
      "Episode length: 1485.00 +/- 647.52\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.48e+03     |\n",
      "|    mean_reward          | -3.9e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1190000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067047244 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.14        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.37e+04     |\n",
      "|    n_updates            | 5810         |\n",
      "|    policy_gradient_loss | -0.000441    |\n",
      "|    std                  | 0.501        |\n",
      "|    value_loss           | 1.3e+04      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 978       |\n",
      "|    ep_rew_mean     | -9.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 582       |\n",
      "|    time_elapsed    | 1892      |\n",
      "|    total_timesteps | 1191936   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 963          |\n",
      "|    ep_rew_mean          | -9.27e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 583          |\n",
      "|    time_elapsed         | 1894         |\n",
      "|    total_timesteps      | 1193984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037808218 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+07     |\n",
      "|    n_updates            | 5820         |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.501        |\n",
      "|    value_loss           | 3.81e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1195000, episode_reward=-100114.65 +/- 141728.74\n",
      "Episode length: 1102.00 +/- 705.05\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.1e+03      |\n",
      "|    mean_reward          | -1e+05       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1195000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023351437 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.218        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.08e+07     |\n",
      "|    n_updates            | 5830         |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    std                  | 0.502        |\n",
      "|    value_loss           | 4.1e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 951       |\n",
      "|    ep_rew_mean     | -9.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 584       |\n",
      "|    time_elapsed    | 1899      |\n",
      "|    total_timesteps | 1196032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 915         |\n",
      "|    ep_rew_mean          | -9.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 1900        |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004183644 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.12       |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.2e+07     |\n",
      "|    n_updates            | 5840        |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    std                  | 0.501       |\n",
      "|    value_loss           | 4.31e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=-167974.48 +/- 146263.31\n",
      "Episode length: 792.60 +/- 638.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 793          |\n",
      "|    mean_reward          | -1.68e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038273642 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95e+07     |\n",
      "|    n_updates            | 5850         |\n",
      "|    policy_gradient_loss | -0.00518     |\n",
      "|    std                  | 0.502        |\n",
      "|    value_loss           | 7.29e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 904       |\n",
      "|    ep_rew_mean     | -9.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 586       |\n",
      "|    time_elapsed    | 1904      |\n",
      "|    total_timesteps | 1200128   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 911          |\n",
      "|    ep_rew_mean          | -1e+05       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 587          |\n",
      "|    time_elapsed         | 1906         |\n",
      "|    total_timesteps      | 1202176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030657996 |\n",
      "|    clip_fraction        | 0.0151       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.13        |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.22e+07     |\n",
      "|    n_updates            | 5860         |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    std                  | 0.501        |\n",
      "|    value_loss           | 1.29e+08     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 917          |\n",
      "|    ep_rew_mean          | -9.69e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 588          |\n",
      "|    time_elapsed         | 1908         |\n",
      "|    total_timesteps      | 1204224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074117966 |\n",
      "|    clip_fraction        | 0.04         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.12        |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.09e+05     |\n",
      "|    n_updates            | 5870         |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    std                  | 0.498        |\n",
      "|    value_loss           | 4.11e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1205000, episode_reward=-149721.24 +/- 203025.57\n",
      "Episode length: 1297.80 +/- 475.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.3e+03     |\n",
      "|    mean_reward          | -1.5e+05    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1205000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013469153 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    std                  | 0.496       |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 917       |\n",
      "|    ep_rew_mean     | -9.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 589       |\n",
      "|    time_elapsed    | 1913      |\n",
      "|    total_timesteps | 1206272   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 922          |\n",
      "|    ep_rew_mean          | -9.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 590          |\n",
      "|    time_elapsed         | 1915         |\n",
      "|    total_timesteps      | 1208320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018818434 |\n",
      "|    clip_fraction        | 0.0891       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.84e+06     |\n",
      "|    n_updates            | 5890         |\n",
      "|    policy_gradient_loss | 0.000727     |\n",
      "|    std                  | 0.497        |\n",
      "|    value_loss           | 1.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1210000, episode_reward=-59134.60 +/- 150160.75\n",
      "Episode length: 1794.20 +/- 406.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.79e+03    |\n",
      "|    mean_reward          | -5.91e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001784381 |\n",
      "|    clip_fraction        | 0.00933     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.19e+03    |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    std                  | 0.497       |\n",
      "|    value_loss           | 3.86e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 921       |\n",
      "|    ep_rew_mean     | -9.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 591       |\n",
      "|    time_elapsed    | 1921      |\n",
      "|    total_timesteps | 1210368   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 918        |\n",
      "|    ep_rew_mean          | -9.31e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 630        |\n",
      "|    iterations           | 592        |\n",
      "|    time_elapsed         | 1922       |\n",
      "|    total_timesteps      | 1212416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01067844 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.09      |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 117        |\n",
      "|    n_updates            | 5910       |\n",
      "|    policy_gradient_loss | -0.00541   |\n",
      "|    std                  | 0.498      |\n",
      "|    value_loss           | 7.44e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 908          |\n",
      "|    ep_rew_mean          | -9.66e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 593          |\n",
      "|    time_elapsed         | 1924         |\n",
      "|    total_timesteps      | 1214464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072622523 |\n",
      "|    clip_fraction        | 0.0699       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 513          |\n",
      "|    n_updates            | 5920         |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    std                  | 0.497        |\n",
      "|    value_loss           | 5.75e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1215000, episode_reward=-64795.61 +/- 156455.82\n",
      "Episode length: 1913.60 +/- 260.99\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.91e+03     |\n",
      "|    mean_reward          | -6.48e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1215000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037341607 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79e+07     |\n",
      "|    n_updates            | 5930         |\n",
      "|    policy_gradient_loss | -0.00423     |\n",
      "|    std                  | 0.497        |\n",
      "|    value_loss           | 4.33e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 917       |\n",
      "|    ep_rew_mean     | -9.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 594       |\n",
      "|    time_elapsed    | 1931      |\n",
      "|    total_timesteps | 1216512   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 922          |\n",
      "|    ep_rew_mean          | -9.45e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 595          |\n",
      "|    time_elapsed         | 1933         |\n",
      "|    total_timesteps      | 1218560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031247544 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.247        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.42e+07     |\n",
      "|    n_updates            | 5940         |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    std                  | 0.497        |\n",
      "|    value_loss           | 6.81e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=12849.88 +/- 200.79\n",
      "Episode length: 1366.40 +/- 8.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.37e+03    |\n",
      "|    mean_reward          | 1.28e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004163235 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.03e+07    |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    std                  | 0.497       |\n",
      "|    value_loss           | 4.68e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 934       |\n",
      "|    ep_rew_mean     | -9.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 596       |\n",
      "|    time_elapsed    | 1938      |\n",
      "|    total_timesteps | 1220608   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 923          |\n",
      "|    ep_rew_mean          | -9.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 597          |\n",
      "|    time_elapsed         | 1939         |\n",
      "|    total_timesteps      | 1222656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031848322 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+07     |\n",
      "|    n_updates            | 5960         |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    std                  | 0.496        |\n",
      "|    value_loss           | 4.79e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 899           |\n",
      "|    ep_rew_mean          | -9.67e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 630           |\n",
      "|    iterations           | 598           |\n",
      "|    time_elapsed         | 1941          |\n",
      "|    total_timesteps      | 1224704       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00016441896 |\n",
      "|    clip_fraction        | 0.000342      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -2.08         |\n",
      "|    explained_variance   | 0.232         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.68e+07      |\n",
      "|    n_updates            | 5970          |\n",
      "|    policy_gradient_loss | 0.00058       |\n",
      "|    std                  | 0.496         |\n",
      "|    value_loss           | 1.31e+08      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=1225000, episode_reward=-140543.72 +/- 182204.95\n",
      "Episode length: 972.60 +/- 436.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 973          |\n",
      "|    mean_reward          | -1.41e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1225000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027426824 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.09        |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+07     |\n",
      "|    n_updates            | 5980         |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    std                  | 0.498        |\n",
      "|    value_loss           | 1.96e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 884      |\n",
      "|    ep_rew_mean     | -9.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 630      |\n",
      "|    iterations      | 599      |\n",
      "|    time_elapsed    | 1945     |\n",
      "|    total_timesteps | 1226752  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 875          |\n",
      "|    ep_rew_mean          | -9.78e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 600          |\n",
      "|    time_elapsed         | 1947         |\n",
      "|    total_timesteps      | 1228800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017774965 |\n",
      "|    clip_fraction        | 0.00796      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.225        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.15e+07     |\n",
      "|    n_updates            | 5990         |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    std                  | 0.498        |\n",
      "|    value_loss           | 6.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=-67583.77 +/- 147312.76\n",
      "Episode length: 1035.80 +/- 335.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.04e+03     |\n",
      "|    mean_reward          | -6.76e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1230000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047504213 |\n",
      "|    clip_fraction        | 0.034        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.1         |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.79e+07     |\n",
      "|    n_updates            | 6000         |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    std                  | 0.499        |\n",
      "|    value_loss           | 4.42e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 849       |\n",
      "|    ep_rew_mean     | -1.02e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 601       |\n",
      "|    time_elapsed    | 1951      |\n",
      "|    total_timesteps | 1230848   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 836         |\n",
      "|    ep_rew_mean          | -1.01e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 1953        |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004439451 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.226       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.06e+07    |\n",
      "|    n_updates            | 6010        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    std                  | 0.499       |\n",
      "|    value_loss           | 1.36e+08    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 823         |\n",
      "|    ep_rew_mean          | -9.87e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 1955        |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010624992 |\n",
      "|    clip_fraction        | 0.0719      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.11       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.46e+03    |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    std                  | 0.499       |\n",
      "|    value_loss           | 3.22e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1235000, episode_reward=9303.33 +/- 4967.26\n",
      "Episode length: 1386.00 +/- 4.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.39e+03    |\n",
      "|    mean_reward          | 9.3e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1235000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009869062 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.1        |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 259         |\n",
      "|    n_updates            | 6030        |\n",
      "|    policy_gradient_loss | -0.00636    |\n",
      "|    std                  | 0.497       |\n",
      "|    value_loss           | 6.67e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 837       |\n",
      "|    ep_rew_mean     | -9.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 604       |\n",
      "|    time_elapsed    | 1960      |\n",
      "|    total_timesteps | 1236992   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 796         |\n",
      "|    ep_rew_mean          | -9.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 1962        |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007396371 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 428         |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    std                  | 0.495       |\n",
      "|    value_loss           | 3.73e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=-54431.09 +/- 130136.71\n",
      "Episode length: 1104.00 +/- 413.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.1e+03      |\n",
      "|    mean_reward          | -5.44e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041474523 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.08        |\n",
      "|    explained_variance   | 0.222        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.62e+07     |\n",
      "|    n_updates            | 6050         |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    std                  | 0.494        |\n",
      "|    value_loss           | 8.09e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 802       |\n",
      "|    ep_rew_mean     | -9.91e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 606       |\n",
      "|    time_elapsed    | 1967      |\n",
      "|    total_timesteps | 1241088   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 805         |\n",
      "|    ep_rew_mean          | -9.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 1968        |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004908791 |\n",
      "|    clip_fraction        | 0.0247      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.7e+06     |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    std                  | 0.493       |\n",
      "|    value_loss           | 4.49e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1245000, episode_reward=-42025.73 +/- 104641.01\n",
      "Episode length: 1111.20 +/- 455.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.11e+03    |\n",
      "|    mean_reward          | -4.2e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1245000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004776823 |\n",
      "|    clip_fraction        | 0.0358      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.08       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.14e+07    |\n",
      "|    n_updates            | 6070        |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 0.493       |\n",
      "|    value_loss           | 4.32e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 796       |\n",
      "|    ep_rew_mean     | -9.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 608       |\n",
      "|    time_elapsed    | 1973      |\n",
      "|    total_timesteps | 1245184   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 765         |\n",
      "|    ep_rew_mean          | -1.03e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 1975        |\n",
      "|    total_timesteps      | 1247232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010421583 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.07       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.61e+03    |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    std                  | 0.492       |\n",
      "|    value_loss           | 9.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 769          |\n",
      "|    ep_rew_mean          | -1.06e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 1976         |\n",
      "|    total_timesteps      | 1249280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051188236 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.07e+07     |\n",
      "|    n_updates            | 6090         |\n",
      "|    policy_gradient_loss | -0.00576     |\n",
      "|    std                  | 0.493        |\n",
      "|    value_loss           | 7.44e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=13624.43 +/- 3850.47\n",
      "Episode length: 1738.40 +/- 5.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.74e+03     |\n",
      "|    mean_reward          | 1.36e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1250000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057525793 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.64e+07     |\n",
      "|    n_updates            | 6100         |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    std                  | 0.493        |\n",
      "|    value_loss           | 1.62e+08     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 760      |\n",
      "|    ep_rew_mean     | -1.1e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 631      |\n",
      "|    iterations      | 611      |\n",
      "|    time_elapsed    | 1982     |\n",
      "|    total_timesteps | 1251328  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 759          |\n",
      "|    ep_rew_mean          | -1.1e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 612          |\n",
      "|    time_elapsed         | 1984         |\n",
      "|    total_timesteps      | 1253376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035502804 |\n",
      "|    clip_fraction        | 0.0236       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.07        |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+07     |\n",
      "|    n_updates            | 6110         |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    std                  | 0.493        |\n",
      "|    value_loss           | 6.72e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1255000, episode_reward=-61704.26 +/- 152404.65\n",
      "Episode length: 1654.60 +/- 429.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.65e+03    |\n",
      "|    mean_reward          | -6.17e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1255000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021637648 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.06       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 6120        |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    std                  | 0.492       |\n",
      "|    value_loss           | 3.38e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 744       |\n",
      "|    ep_rew_mean     | -1.15e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 613       |\n",
      "|    time_elapsed    | 1990      |\n",
      "|    total_timesteps | 1255424   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 741          |\n",
      "|    ep_rew_mean          | -1.16e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 614          |\n",
      "|    time_elapsed         | 1992         |\n",
      "|    total_timesteps      | 1257472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046085874 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.225        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.31e+07     |\n",
      "|    n_updates            | 6130         |\n",
      "|    policy_gradient_loss | -0.00479     |\n",
      "|    std                  | 0.492        |\n",
      "|    value_loss           | 9.97e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 732          |\n",
      "|    ep_rew_mean          | -1.21e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 615          |\n",
      "|    time_elapsed         | 1994         |\n",
      "|    total_timesteps      | 1259520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058783833 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.05        |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.23e+07     |\n",
      "|    n_updates            | 6140         |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    std                  | 0.491        |\n",
      "|    value_loss           | 4.6e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=10173.21 +/- 3417.59\n",
      "Episode length: 1385.20 +/- 8.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.39e+03    |\n",
      "|    mean_reward          | 1.02e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003907132 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.236       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.48e+07    |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.004      |\n",
      "|    std                  | 0.49        |\n",
      "|    value_loss           | 1.44e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 752       |\n",
      "|    ep_rew_mean     | -1.16e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 616       |\n",
      "|    time_elapsed    | 1999      |\n",
      "|    total_timesteps | 1261568   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 752         |\n",
      "|    ep_rew_mean          | -1.16e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 2001        |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010367303 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    std                  | 0.49        |\n",
      "|    value_loss           | 2.3e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1265000, episode_reward=-59077.73 +/- 153020.22\n",
      "Episode length: 1346.60 +/- 496.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.35e+03    |\n",
      "|    mean_reward          | -5.91e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1265000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003778439 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | 0.257       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.36e+07    |\n",
      "|    n_updates            | 6170        |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    std                  | 0.49        |\n",
      "|    value_loss           | 4.81e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 750       |\n",
      "|    ep_rew_mean     | -1.16e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 618       |\n",
      "|    time_elapsed    | 2006      |\n",
      "|    total_timesteps | 1265664   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 752         |\n",
      "|    ep_rew_mean          | -1.17e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 2008        |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008915007 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 179         |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    std                  | 0.49        |\n",
      "|    value_loss           | 626         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 754          |\n",
      "|    ep_rew_mean          | -1.17e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 620          |\n",
      "|    time_elapsed         | 2009         |\n",
      "|    total_timesteps      | 1269760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036818127 |\n",
      "|    clip_fraction        | 0.0818       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.251        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.97e+06     |\n",
      "|    n_updates            | 6190         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.489        |\n",
      "|    value_loss           | 9.55e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1270000, episode_reward=21703.86 +/- 37.76\n",
      "Episode length: 1985.20 +/- 1.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.99e+03    |\n",
      "|    mean_reward          | 2.17e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004649277 |\n",
      "|    clip_fraction        | 0.0187      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.249       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.67e+07    |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    std                  | 0.49        |\n",
      "|    value_loss           | 4.29e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 751       |\n",
      "|    ep_rew_mean     | -1.21e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 621       |\n",
      "|    time_elapsed    | 2016      |\n",
      "|    total_timesteps | 1271808   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 761          |\n",
      "|    ep_rew_mean          | -1.21e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 622          |\n",
      "|    time_elapsed         | 2018         |\n",
      "|    total_timesteps      | 1273856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053192144 |\n",
      "|    clip_fraction        | 0.0284       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.51e+07     |\n",
      "|    n_updates            | 6210         |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    std                  | 0.49         |\n",
      "|    value_loss           | 9.45e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1275000, episode_reward=-139848.28 +/- 196704.10\n",
      "Episode length: 1358.20 +/- 769.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.36e+03     |\n",
      "|    mean_reward          | -1.4e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1275000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035633554 |\n",
      "|    clip_fraction        | 0.0226       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.03        |\n",
      "|    explained_variance   | 0.249        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.59e+07     |\n",
      "|    n_updates            | 6220         |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    std                  | 0.491        |\n",
      "|    value_loss           | 4.77e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 774       |\n",
      "|    ep_rew_mean     | -1.18e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 623       |\n",
      "|    time_elapsed    | 2023      |\n",
      "|    total_timesteps | 1275904   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 783          |\n",
      "|    ep_rew_mean          | -1.2e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 624          |\n",
      "|    time_elapsed         | 2024         |\n",
      "|    total_timesteps      | 1277952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069116163 |\n",
      "|    clip_fraction        | 0.0833       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 415          |\n",
      "|    n_updates            | 6230         |\n",
      "|    policy_gradient_loss | -0.00646     |\n",
      "|    std                  | 0.491        |\n",
      "|    value_loss           | 1.47e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=-132305.23 +/- 182285.17\n",
      "Episode length: 1182.40 +/- 678.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.18e+03     |\n",
      "|    mean_reward          | -1.32e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039079105 |\n",
      "|    clip_fraction        | 0.0202       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.02        |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.5e+07      |\n",
      "|    n_updates            | 6240         |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    std                  | 0.491        |\n",
      "|    value_loss           | 5.3e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 798       |\n",
      "|    ep_rew_mean     | -1.16e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 625       |\n",
      "|    time_elapsed    | 2029      |\n",
      "|    total_timesteps | 1280000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 791         |\n",
      "|    ep_rew_mean          | -1.13e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 2031        |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005523477 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.64e+07    |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    std                  | 0.492       |\n",
      "|    value_loss           | 4.53e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 773          |\n",
      "|    ep_rew_mean          | -1.23e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 627          |\n",
      "|    time_elapsed         | 2033         |\n",
      "|    total_timesteps      | 1284096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109375045 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -2.03        |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 179          |\n",
      "|    n_updates            | 6260         |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.494        |\n",
      "|    value_loss           | 2.01e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1285000, episode_reward=-57161.32 +/- 154151.76\n",
      "Episode length: 2028.00 +/- 381.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.03e+03    |\n",
      "|    mean_reward          | -5.72e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1285000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006902169 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.03       |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.74e+07    |\n",
      "|    n_updates            | 6270        |\n",
      "|    policy_gradient_loss | -0.00779    |\n",
      "|    std                  | 0.494       |\n",
      "|    value_loss           | 1.54e+08    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 776       |\n",
      "|    ep_rew_mean     | -1.23e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 628       |\n",
      "|    time_elapsed    | 2039      |\n",
      "|    total_timesteps | 1286144   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 768         |\n",
      "|    ep_rew_mean          | -1.24e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 2041        |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007908107 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    std                  | 0.49        |\n",
      "|    value_loss           | 348         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1290000, episode_reward=19121.86 +/- 3258.47\n",
      "Episode length: 1797.20 +/- 10.30\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.8e+03      |\n",
      "|    mean_reward          | 1.91e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1290000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027311414 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.231        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.88e+07     |\n",
      "|    n_updates            | 6290         |\n",
      "|    policy_gradient_loss | -0.000557    |\n",
      "|    std                  | 0.49         |\n",
      "|    value_loss           | 7.38e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 776      |\n",
      "|    ep_rew_mean     | -1.3e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 630      |\n",
      "|    iterations      | 630      |\n",
      "|    time_elapsed    | 2047     |\n",
      "|    total_timesteps | 1290240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 767         |\n",
      "|    ep_rew_mean          | -1.33e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 2049        |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001884752 |\n",
      "|    clip_fraction        | 0.00225     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.71e+06    |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    std                  | 0.49        |\n",
      "|    value_loss           | 2.91e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 774          |\n",
      "|    ep_rew_mean          | -1.31e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 632          |\n",
      "|    time_elapsed         | 2051         |\n",
      "|    total_timesteps      | 1294336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.557801e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.18e+07     |\n",
      "|    n_updates            | 6310         |\n",
      "|    policy_gradient_loss | -0.000223    |\n",
      "|    std                  | 0.49         |\n",
      "|    value_loss           | 1.09e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1295000, episode_reward=-147823.12 +/- 205996.32\n",
      "Episode length: 1785.40 +/- 566.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.79e+03     |\n",
      "|    mean_reward          | -1.48e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1295000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012349652 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.241        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.74e+06     |\n",
      "|    n_updates            | 6320         |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    std                  | 0.49         |\n",
      "|    value_loss           | 2.71e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 782       |\n",
      "|    ep_rew_mean     | -1.33e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 633       |\n",
      "|    time_elapsed    | 2057      |\n",
      "|    total_timesteps | 1296384   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 796          |\n",
      "|    ep_rew_mean          | -1.37e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 634          |\n",
      "|    time_elapsed         | 2059         |\n",
      "|    total_timesteps      | 1298432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041055004 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.0474       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.29e+07     |\n",
      "|    n_updates            | 6330         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 0.49         |\n",
      "|    value_loss           | 9.34e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=15877.33 +/- 2048.79\n",
      "Episode length: 1524.80 +/- 6.46\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.52e+03     |\n",
      "|    mean_reward          | 1.59e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1300000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054012123 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.01e+03     |\n",
      "|    n_updates            | 6340         |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    std                  | 0.49         |\n",
      "|    value_loss           | 2.94e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 808       |\n",
      "|    ep_rew_mean     | -1.33e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 635       |\n",
      "|    time_elapsed    | 2064      |\n",
      "|    total_timesteps | 1300480   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 814          |\n",
      "|    ep_rew_mean          | -1.31e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 636          |\n",
      "|    time_elapsed         | 2066         |\n",
      "|    total_timesteps      | 1302528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052037826 |\n",
      "|    clip_fraction        | 0.0407       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.99        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.4e+04      |\n",
      "|    n_updates            | 6350         |\n",
      "|    policy_gradient_loss | -0.00495     |\n",
      "|    std                  | 0.489        |\n",
      "|    value_loss           | 1.83e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 831         |\n",
      "|    ep_rew_mean          | -1.34e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 2068        |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003912212 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | 0.219       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+07    |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    std                  | 0.489       |\n",
      "|    value_loss           | 6.41e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1305000, episode_reward=-220139.31 +/- 190465.43\n",
      "Episode length: 1804.20 +/- 489.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.8e+03      |\n",
      "|    mean_reward          | -2.2e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1305000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044620065 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.98        |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05e+04     |\n",
      "|    n_updates            | 6370         |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    std                  | 0.488        |\n",
      "|    value_loss           | 2.21e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 842       |\n",
      "|    ep_rew_mean     | -1.34e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 638       |\n",
      "|    time_elapsed    | 2074      |\n",
      "|    total_timesteps | 1306624   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 850          |\n",
      "|    ep_rew_mean          | -1.31e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 639          |\n",
      "|    time_elapsed         | 2076         |\n",
      "|    total_timesteps      | 1308672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045342715 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.91e+07     |\n",
      "|    n_updates            | 6380         |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    std                  | 0.488        |\n",
      "|    value_loss           | 4.94e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1310000, episode_reward=9745.31 +/- 1944.05\n",
      "Episode length: 1236.40 +/- 4.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.24e+03     |\n",
      "|    mean_reward          | 9.75e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1310000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031200869 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.251        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.98e+07     |\n",
      "|    n_updates            | 6390         |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    std                  | 0.486        |\n",
      "|    value_loss           | 4.57e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 870       |\n",
      "|    ep_rew_mean     | -1.32e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 640       |\n",
      "|    time_elapsed    | 2081      |\n",
      "|    total_timesteps | 1310720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 883         |\n",
      "|    ep_rew_mean          | -1.35e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 2082        |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005307707 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.281       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.61e+07    |\n",
      "|    n_updates            | 6400        |\n",
      "|    policy_gradient_loss | -0.00401    |\n",
      "|    std                  | 0.485       |\n",
      "|    value_loss           | 4.2e+07     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 891          |\n",
      "|    ep_rew_mean          | -1.43e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 642          |\n",
      "|    time_elapsed         | 2084         |\n",
      "|    total_timesteps      | 1314816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026362562 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.264        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+07     |\n",
      "|    n_updates            | 6410         |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    std                  | 0.485        |\n",
      "|    value_loss           | 4.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1315000, episode_reward=-69703.32 +/- 162261.31\n",
      "Episode length: 1480.60 +/- 280.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.48e+03    |\n",
      "|    mean_reward          | -6.97e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1315000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004069168 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.61e+07    |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    std                  | 0.486       |\n",
      "|    value_loss           | 4.86e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 902       |\n",
      "|    ep_rew_mean     | -1.41e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 643       |\n",
      "|    time_elapsed    | 2089      |\n",
      "|    total_timesteps | 1316864   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 911          |\n",
      "|    ep_rew_mean          | -1.38e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 644          |\n",
      "|    time_elapsed         | 2091         |\n",
      "|    total_timesteps      | 1318912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026287606 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.96        |\n",
      "|    explained_variance   | 0.22         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+07     |\n",
      "|    n_updates            | 6430         |\n",
      "|    policy_gradient_loss | -0.00381     |\n",
      "|    std                  | 0.485        |\n",
      "|    value_loss           | 3.6e+07      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1320000, episode_reward=-57399.14 +/- 139245.70\n",
      "Episode length: 1472.40 +/- 368.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.47e+03     |\n",
      "|    mean_reward          | -5.74e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047478825 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66e+06     |\n",
      "|    n_updates            | 6440         |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    std                  | 0.49         |\n",
      "|    value_loss           | 1.28e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 920       |\n",
      "|    ep_rew_mean     | -1.38e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 645       |\n",
      "|    time_elapsed    | 2097      |\n",
      "|    total_timesteps | 1320960   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 933         |\n",
      "|    ep_rew_mean          | -1.35e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 2098        |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012962126 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 209         |\n",
      "|    n_updates            | 6450        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    std                  | 0.488       |\n",
      "|    value_loss           | 482         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1325000, episode_reward=12757.18 +/- 2134.47\n",
      "Episode length: 1369.80 +/- 7.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.37e+03     |\n",
      "|    mean_reward          | 1.28e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1325000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073371637 |\n",
      "|    clip_fraction        | 0.073        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.97        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 317          |\n",
      "|    n_updates            | 6460         |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    std                  | 0.487        |\n",
      "|    value_loss           | 2.14e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 941       |\n",
      "|    ep_rew_mean     | -1.31e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 647       |\n",
      "|    time_elapsed    | 2103      |\n",
      "|    total_timesteps | 1325056   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 950        |\n",
      "|    ep_rew_mean          | -1.29e+05  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 630        |\n",
      "|    iterations           | 648        |\n",
      "|    time_elapsed         | 2105       |\n",
      "|    total_timesteps      | 1327104    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01367785 |\n",
      "|    clip_fraction        | 0.0936     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.94      |\n",
      "|    explained_variance   | 0.961      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 477        |\n",
      "|    n_updates            | 6470       |\n",
      "|    policy_gradient_loss | -0.00195   |\n",
      "|    std                  | 0.485      |\n",
      "|    value_loss           | 7.38e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 961         |\n",
      "|    ep_rew_mean          | -1.32e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 2107        |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004698781 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.51e+07    |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.00397    |\n",
      "|    std                  | 0.485       |\n",
      "|    value_loss           | 4.26e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=-57258.39 +/- 138868.81\n",
      "Episode length: 1520.60 +/- 401.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.52e+03    |\n",
      "|    mean_reward          | -5.73e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005545793 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 307         |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    std                  | 0.483       |\n",
      "|    value_loss           | 2.93e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 966       |\n",
      "|    ep_rew_mean     | -1.36e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 650       |\n",
      "|    time_elapsed    | 2113      |\n",
      "|    total_timesteps | 1331200   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 970       |\n",
      "|    ep_rew_mean          | -1.36e+05 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 630       |\n",
      "|    iterations           | 651       |\n",
      "|    time_elapsed         | 2114      |\n",
      "|    total_timesteps      | 1333248   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0040143 |\n",
      "|    clip_fraction        | 0.0353    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.92     |\n",
      "|    explained_variance   | 0.271     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.57e+07  |\n",
      "|    n_updates            | 6500      |\n",
      "|    policy_gradient_loss | -0.00491  |\n",
      "|    std                  | 0.483     |\n",
      "|    value_loss           | 4.36e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1335000, episode_reward=-56162.44 +/- 135802.90\n",
      "Episode length: 1641.40 +/- 429.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.64e+03    |\n",
      "|    mean_reward          | -5.62e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1335000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005975942 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.75e+05    |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    std                  | 0.484       |\n",
      "|    value_loss           | 8.04e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 979       |\n",
      "|    ep_rew_mean     | -1.39e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 652       |\n",
      "|    time_elapsed    | 2120      |\n",
      "|    total_timesteps | 1335296   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 995         |\n",
      "|    ep_rew_mean          | -1.39e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 2122        |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004563433 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.94       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.78e+07    |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.0021     |\n",
      "|    std                  | 0.485       |\n",
      "|    value_loss           | 6.18e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 989          |\n",
      "|    ep_rew_mean          | -1.44e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 654          |\n",
      "|    time_elapsed         | 2124         |\n",
      "|    total_timesteps      | 1339392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056178262 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.94        |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.8e+06      |\n",
      "|    n_updates            | 6530         |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    std                  | 0.484        |\n",
      "|    value_loss           | 1.4e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=12342.91 +/- 3095.98\n",
      "Episode length: 1252.20 +/- 3.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.25e+03    |\n",
      "|    mean_reward          | 1.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004096079 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.14e+07    |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    std                  | 0.485       |\n",
      "|    value_loss           | 8.28e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 999      |\n",
      "|    ep_rew_mean     | -1.4e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 630      |\n",
      "|    iterations      | 655      |\n",
      "|    time_elapsed    | 2128     |\n",
      "|    total_timesteps | 1341440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 999         |\n",
      "|    ep_rew_mean          | -1.4e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 2130        |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017527513 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.00404    |\n",
      "|    std                  | 0.485       |\n",
      "|    value_loss           | 548         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1345000, episode_reward=-59905.65 +/- 145697.54\n",
      "Episode length: 1586.00 +/- 426.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.59e+03    |\n",
      "|    mean_reward          | -5.99e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1345000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015452019 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.92       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    std                  | 0.481       |\n",
      "|    value_loss           | 326         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -1.41e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 657       |\n",
      "|    time_elapsed    | 2136      |\n",
      "|    total_timesteps | 1345536   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -1.41e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 658          |\n",
      "|    time_elapsed         | 2138         |\n",
      "|    total_timesteps      | 1347584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034029596 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.9         |\n",
      "|    explained_variance   | 0.28         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.12e+07     |\n",
      "|    n_updates            | 6570         |\n",
      "|    policy_gradient_loss | -0.00318     |\n",
      "|    std                  | 0.481        |\n",
      "|    value_loss           | 4.6e+07      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -1.39e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 2139        |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022361066 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.6        |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.00538    |\n",
      "|    std                  | 0.481       |\n",
      "|    value_loss           | 8.2e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=-64223.17 +/- 156199.44\n",
      "Episode length: 1184.80 +/- 364.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.18e+03    |\n",
      "|    mean_reward          | -6.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005915663 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.89       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.58e+06    |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    std                  | 0.482       |\n",
      "|    value_loss           | 4.08e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.03e+03  |\n",
      "|    ep_rew_mean     | -1.36e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 660       |\n",
      "|    time_elapsed    | 2144      |\n",
      "|    total_timesteps | 1351680   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -1.33e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 2146        |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011367003 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.88       |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    std                  | 0.479       |\n",
      "|    value_loss           | 5.76e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1355000, episode_reward=-128300.54 +/- 175124.56\n",
      "Episode length: 1888.80 +/- 488.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.89e+03     |\n",
      "|    mean_reward          | -1.28e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1355000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051536765 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.86        |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.52e+07     |\n",
      "|    n_updates            | 6610         |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    std                  | 0.478        |\n",
      "|    value_loss           | 4.7e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.05e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 662       |\n",
      "|    time_elapsed    | 2152      |\n",
      "|    total_timesteps | 1355776   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -1.27e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 2154        |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012121268 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.85       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74          |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    std                  | 0.478       |\n",
      "|    value_loss           | 6.13e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.06e+03     |\n",
      "|    ep_rew_mean          | -1.27e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 664          |\n",
      "|    time_elapsed         | 2156         |\n",
      "|    total_timesteps      | 1359872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031822235 |\n",
      "|    clip_fraction        | 0.0585       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | 0.18         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.2e+06      |\n",
      "|    n_updates            | 6630         |\n",
      "|    policy_gradient_loss | -0.000219    |\n",
      "|    std                  | 0.478        |\n",
      "|    value_loss           | 1.19e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=18780.12 +/- 1888.92\n",
      "Episode length: 1873.00 +/- 2.68\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.87e+03     |\n",
      "|    mean_reward          | 1.88e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032105083 |\n",
      "|    clip_fraction        | 0.0198       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.83        |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+07      |\n",
      "|    n_updates            | 6640         |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    std                  | 0.478        |\n",
      "|    value_loss           | 4.54e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.07e+03 |\n",
      "|    ep_rew_mean     | -1.3e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 629      |\n",
      "|    iterations      | 665      |\n",
      "|    time_elapsed    | 2162     |\n",
      "|    total_timesteps | 1361920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -1.3e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 2164        |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003965635 |\n",
      "|    clip_fraction        | 0.027       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.53e+07    |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    std                  | 0.478       |\n",
      "|    value_loss           | 4.39e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1365000, episode_reward=-59884.00 +/- 157588.22\n",
      "Episode length: 2183.40 +/- 601.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.18e+03    |\n",
      "|    mean_reward          | -5.99e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1365000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004913641 |\n",
      "|    clip_fraction        | 0.0128      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.83       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.15e+07    |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 0.478       |\n",
      "|    value_loss           | 9.14e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.08e+03 |\n",
      "|    ep_rew_mean     | -1.3e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 629      |\n",
      "|    iterations      | 667      |\n",
      "|    time_elapsed    | 2171     |\n",
      "|    total_timesteps | 1366016  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.08e+03   |\n",
      "|    ep_rew_mean          | -1.3e+05   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 629        |\n",
      "|    iterations           | 668        |\n",
      "|    time_elapsed         | 2173       |\n",
      "|    total_timesteps      | 1368064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00921436 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.83      |\n",
      "|    explained_variance   | 0.799      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 307        |\n",
      "|    n_updates            | 6670       |\n",
      "|    policy_gradient_loss | -0.00537   |\n",
      "|    std                  | 0.478      |\n",
      "|    value_loss           | 1.24e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1370000, episode_reward=-140947.21 +/- 191187.05\n",
      "Episode length: 1954.00 +/- 440.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.95e+03     |\n",
      "|    mean_reward          | -1.41e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1370000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024352423 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.26         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.98e+07     |\n",
      "|    n_updates            | 6680         |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    std                  | 0.477        |\n",
      "|    value_loss           | 4.86e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.1e+03   |\n",
      "|    ep_rew_mean     | -1.24e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 669       |\n",
      "|    time_elapsed    | 2179      |\n",
      "|    total_timesteps | 1370112   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -1.3e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 670         |\n",
      "|    time_elapsed         | 2181        |\n",
      "|    total_timesteps      | 1372160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023159161 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 6690        |\n",
      "|    policy_gradient_loss | -0.000322   |\n",
      "|    std                  | 0.478       |\n",
      "|    value_loss           | 1.63e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.07e+03     |\n",
      "|    ep_rew_mean          | -1.35e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 671          |\n",
      "|    time_elapsed         | 2183         |\n",
      "|    total_timesteps      | 1374208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043643704 |\n",
      "|    clip_fraction        | 0.049        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.243        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.96e+07     |\n",
      "|    n_updates            | 6700         |\n",
      "|    policy_gradient_loss | -0.000357    |\n",
      "|    std                  | 0.478        |\n",
      "|    value_loss           | 9.54e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1375000, episode_reward=-258307.99 +/- 67066.41\n",
      "Episode length: 477.20 +/- 409.41\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 477          |\n",
      "|    mean_reward          | -2.58e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1375000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005082088 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.72e+07     |\n",
      "|    n_updates            | 6710         |\n",
      "|    policy_gradient_loss | -0.000596    |\n",
      "|    std                  | 0.478        |\n",
      "|    value_loss           | 1.39e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -1.34e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 672       |\n",
      "|    time_elapsed    | 2186      |\n",
      "|    total_timesteps | 1376256   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | -1.37e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 673          |\n",
      "|    time_elapsed         | 2187         |\n",
      "|    total_timesteps      | 1378304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003885637 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.244        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.83e+07     |\n",
      "|    n_updates            | 6720         |\n",
      "|    policy_gradient_loss | -0.000693    |\n",
      "|    std                  | 0.478        |\n",
      "|    value_loss           | 5.12e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=-38407.05 +/- 121016.59\n",
      "Episode length: 1653.60 +/- 697.31\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.65e+03      |\n",
      "|    mean_reward          | -3.84e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 1380000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00077699765 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.82         |\n",
      "|    explained_variance   | 0.228         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.76e+07      |\n",
      "|    n_updates            | 6730          |\n",
      "|    policy_gradient_loss | -0.000918     |\n",
      "|    std                  | 0.478         |\n",
      "|    value_loss           | 1.33e+08      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.05e+03  |\n",
      "|    ep_rew_mean     | -1.36e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 674       |\n",
      "|    time_elapsed    | 2193      |\n",
      "|    total_timesteps | 1380352   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -1.38e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 675          |\n",
      "|    time_elapsed         | 2195         |\n",
      "|    total_timesteps      | 1382400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015632717 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.246        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.77e+07     |\n",
      "|    n_updates            | 6740         |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.478        |\n",
      "|    value_loss           | 4.07e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | -1.37e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 676          |\n",
      "|    time_elapsed         | 2197         |\n",
      "|    total_timesteps      | 1384448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011061054 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.23         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.9e+07      |\n",
      "|    n_updates            | 6750         |\n",
      "|    policy_gradient_loss | -0.00195     |\n",
      "|    std                  | 0.478        |\n",
      "|    value_loss           | 9.66e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1385000, episode_reward=26023.26 +/- 1837.28\n",
      "Episode length: 2568.60 +/- 6.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.57e+03     |\n",
      "|    mean_reward          | 2.6e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1385000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030416753 |\n",
      "|    clip_fraction        | 0.0143       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.186        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+07      |\n",
      "|    n_updates            | 6760         |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    std                  | 0.478        |\n",
      "|    value_loss           | 3.25e+07     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.04e+03 |\n",
      "|    ep_rew_mean     | -1.4e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 628      |\n",
      "|    iterations      | 677      |\n",
      "|    time_elapsed    | 2205     |\n",
      "|    total_timesteps | 1386496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -1.38e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 2206        |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003518613 |\n",
      "|    clip_fraction        | 0.015       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.86e+07    |\n",
      "|    n_updates            | 6770        |\n",
      "|    policy_gradient_loss | -0.00345    |\n",
      "|    std                  | 0.478       |\n",
      "|    value_loss           | 7.88e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=-85639.78 +/- 133130.83\n",
      "Episode length: 1626.60 +/- 1166.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.63e+03     |\n",
      "|    mean_reward          | -8.56e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1390000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017266286 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.82        |\n",
      "|    explained_variance   | 0.273        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.49e+07     |\n",
      "|    n_updates            | 6780         |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    std                  | 0.478        |\n",
      "|    value_loss           | 4.87e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.06e+03  |\n",
      "|    ep_rew_mean     | -1.35e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 679       |\n",
      "|    time_elapsed    | 2212      |\n",
      "|    total_timesteps | 1390592   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.06e+03  |\n",
      "|    ep_rew_mean          | -1.35e+05 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 628       |\n",
      "|    iterations           | 680       |\n",
      "|    time_elapsed         | 2214      |\n",
      "|    total_timesteps      | 1392640   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0080331 |\n",
      "|    clip_fraction        | 0.0788    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.82     |\n",
      "|    explained_variance   | 0.916     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.1e+03   |\n",
      "|    n_updates            | 6790      |\n",
      "|    policy_gradient_loss | -0.00984  |\n",
      "|    std                  | 0.477     |\n",
      "|    value_loss           | 1.5e+04   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -1.3e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 2216        |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007789507 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.8        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 6800        |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    std                  | 0.475       |\n",
      "|    value_loss           | 1.08e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1395000, episode_reward=-47091.80 +/- 121608.96\n",
      "Episode length: 1323.20 +/- 525.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.32e+03    |\n",
      "|    mean_reward          | -4.71e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1395000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003877375 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.78       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+07    |\n",
      "|    n_updates            | 6810        |\n",
      "|    policy_gradient_loss | -0.00777    |\n",
      "|    std                  | 0.474       |\n",
      "|    value_loss           | 3.6e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.05e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 682       |\n",
      "|    time_elapsed    | 2221      |\n",
      "|    total_timesteps | 1396736   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -1.23e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 2223        |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011759754 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.77       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.00629    |\n",
      "|    std                  | 0.471       |\n",
      "|    value_loss           | 495         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=-44430.07 +/- 115913.32\n",
      "Episode length: 1206.40 +/- 479.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.21e+03    |\n",
      "|    mean_reward          | -4.44e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008097249 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.75       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 631         |\n",
      "|    n_updates            | 6830        |\n",
      "|    policy_gradient_loss | -0.00754    |\n",
      "|    std                  | 0.47        |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -1.21e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 684       |\n",
      "|    time_elapsed    | 2227      |\n",
      "|    total_timesteps | 1400832   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.02e+03     |\n",
      "|    ep_rew_mean          | -1.24e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 685          |\n",
      "|    time_elapsed         | 2229         |\n",
      "|    total_timesteps      | 1402880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049432833 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.75        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 150          |\n",
      "|    n_updates            | 6840         |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    std                  | 0.469        |\n",
      "|    value_loss           | 6.38e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -1.19e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 686          |\n",
      "|    time_elapsed         | 2231         |\n",
      "|    total_timesteps      | 1404928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023966562 |\n",
      "|    clip_fraction        | 0.0149       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.226        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.54e+07     |\n",
      "|    n_updates            | 6850         |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    std                  | 0.469        |\n",
      "|    value_loss           | 1.57e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1405000, episode_reward=-71835.94 +/- 166566.23\n",
      "Episode length: 1095.40 +/- 185.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.1e+03     |\n",
      "|    mean_reward          | -7.18e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1405000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002989447 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.26e+03    |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.00465    |\n",
      "|    std                  | 0.469       |\n",
      "|    value_loss           | 7.21e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -1.17e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 687       |\n",
      "|    time_elapsed    | 2235      |\n",
      "|    total_timesteps | 1406976   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 991         |\n",
      "|    ep_rew_mean          | -1.14e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 2237        |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005284177 |\n",
      "|    clip_fraction        | 0.0423      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78e+07    |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    std                  | 0.471       |\n",
      "|    value_loss           | 2.51e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1410000, episode_reward=-136390.39 +/- 181081.30\n",
      "Episode length: 1538.60 +/- 550.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.54e+03     |\n",
      "|    mean_reward          | -1.36e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1410000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066724736 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.74        |\n",
      "|    explained_variance   | 0.899        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 159          |\n",
      "|    n_updates            | 6880         |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    std                  | 0.47         |\n",
      "|    value_loss           | 4.44e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 967       |\n",
      "|    ep_rew_mean     | -1.06e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 689       |\n",
      "|    time_elapsed    | 2243      |\n",
      "|    total_timesteps | 1411072   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 959          |\n",
      "|    ep_rew_mean          | -1.06e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 690          |\n",
      "|    time_elapsed         | 2245         |\n",
      "|    total_timesteps      | 1413120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050102035 |\n",
      "|    clip_fraction        | 0.0507       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.25e+07     |\n",
      "|    n_updates            | 6890         |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    std                  | 0.47         |\n",
      "|    value_loss           | 4.54e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1415000, episode_reward=-113061.02 +/- 149614.02\n",
      "Episode length: 740.20 +/- 383.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 740         |\n",
      "|    mean_reward          | -1.13e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1415000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004657423 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.74       |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.03e+07    |\n",
      "|    n_updates            | 6900        |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    std                  | 0.47        |\n",
      "|    value_loss           | 4.43e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 930       |\n",
      "|    ep_rew_mean     | -1.21e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 691       |\n",
      "|    time_elapsed    | 2248      |\n",
      "|    total_timesteps | 1415168   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 919          |\n",
      "|    ep_rew_mean          | -1.21e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 692          |\n",
      "|    time_elapsed         | 2250         |\n",
      "|    total_timesteps      | 1417216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012595417 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.73        |\n",
      "|    explained_variance   | 0.166        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.14e+07     |\n",
      "|    n_updates            | 6910         |\n",
      "|    policy_gradient_loss | -0.000714    |\n",
      "|    std                  | 0.469        |\n",
      "|    value_loss           | 1.66e+08     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 900         |\n",
      "|    ep_rew_mean          | -1.2e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 2252        |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014986023 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.58e+05    |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.0047     |\n",
      "|    std                  | 0.467       |\n",
      "|    value_loss           | 5.33e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=7976.91 +/- 5576.95\n",
      "Episode length: 1047.40 +/- 5.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.05e+03    |\n",
      "|    mean_reward          | 7.98e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004508045 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.9e+07     |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.466       |\n",
      "|    value_loss           | 2.89e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 898       |\n",
      "|    ep_rew_mean     | -1.16e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 694       |\n",
      "|    time_elapsed    | 2256      |\n",
      "|    total_timesteps | 1421312   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 876         |\n",
      "|    ep_rew_mean          | -1.15e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 2258        |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015563859 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.69       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    std                  | 0.466       |\n",
      "|    value_loss           | 1e+03       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1425000, episode_reward=-50941.49 +/- 124796.97\n",
      "Episode length: 824.20 +/- 281.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 824          |\n",
      "|    mean_reward          | -5.09e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1425000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031065494 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.76e+06     |\n",
      "|    n_updates            | 6950         |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    std                  | 0.465        |\n",
      "|    value_loss           | 3.75e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 864       |\n",
      "|    ep_rew_mean     | -1.12e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 696       |\n",
      "|    time_elapsed    | 2262      |\n",
      "|    total_timesteps | 1425408   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 855          |\n",
      "|    ep_rew_mean          | -1.12e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 697          |\n",
      "|    time_elapsed         | 2263         |\n",
      "|    total_timesteps      | 1427456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039758673 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.67        |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51e+07     |\n",
      "|    n_updates            | 6960         |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    std                  | 0.465        |\n",
      "|    value_loss           | 4.57e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 848          |\n",
      "|    ep_rew_mean          | -1.12e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 698          |\n",
      "|    time_elapsed         | 2265         |\n",
      "|    total_timesteps      | 1429504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045693708 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.68        |\n",
      "|    explained_variance   | 0.282        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+07     |\n",
      "|    n_updates            | 6970         |\n",
      "|    policy_gradient_loss | -0.00459     |\n",
      "|    std                  | 0.464        |\n",
      "|    value_loss           | 4.46e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1430000, episode_reward=-43200.08 +/- 108955.45\n",
      "Episode length: 875.00 +/- 342.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 875         |\n",
      "|    mean_reward          | -4.32e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022913057 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.834       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    std                  | 0.46        |\n",
      "|    value_loss           | 1.44e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 841       |\n",
      "|    ep_rew_mean     | -1.11e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 699       |\n",
      "|    time_elapsed    | 2269      |\n",
      "|    total_timesteps | 1431552   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 834          |\n",
      "|    ep_rew_mean          | -1.1e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 700          |\n",
      "|    time_elapsed         | 2271         |\n",
      "|    total_timesteps      | 1433600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055052266 |\n",
      "|    clip_fraction        | 0.0632       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+07     |\n",
      "|    n_updates            | 6990         |\n",
      "|    policy_gradient_loss | -0.00526     |\n",
      "|    std                  | 0.461        |\n",
      "|    value_loss           | 4.05e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1435000, episode_reward=-112475.28 +/- 152221.81\n",
      "Episode length: 748.60 +/- 394.47\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 749          |\n",
      "|    mean_reward          | -1.12e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1435000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047315573 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.254        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.11e+07     |\n",
      "|    n_updates            | 7000         |\n",
      "|    policy_gradient_loss | -0.00457     |\n",
      "|    std                  | 0.462        |\n",
      "|    value_loss           | 3.63e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 816       |\n",
      "|    ep_rew_mean     | -1.12e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 701       |\n",
      "|    time_elapsed    | 2275      |\n",
      "|    total_timesteps | 1435648   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 804          |\n",
      "|    ep_rew_mean          | -1.13e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 702          |\n",
      "|    time_elapsed         | 2276         |\n",
      "|    total_timesteps      | 1437696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041621584 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.276        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95e+07     |\n",
      "|    n_updates            | 7010         |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    std                  | 0.462        |\n",
      "|    value_loss           | 8.71e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 784          |\n",
      "|    ep_rew_mean          | -1.08e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 631          |\n",
      "|    iterations           | 703          |\n",
      "|    time_elapsed         | 2278         |\n",
      "|    total_timesteps      | 1439744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018006791 |\n",
      "|    clip_fraction        | 0.00269      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.225        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.55e+06     |\n",
      "|    n_updates            | 7020         |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.462        |\n",
      "|    value_loss           | 2.75e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=-45256.76 +/- 113052.79\n",
      "Episode length: 875.60 +/- 321.40\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 876           |\n",
      "|    mean_reward          | -4.53e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 1440000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00021067075 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.63         |\n",
      "|    explained_variance   | 0.235         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.52e+06      |\n",
      "|    n_updates            | 7030          |\n",
      "|    policy_gradient_loss | -0.000678     |\n",
      "|    std                  | 0.462         |\n",
      "|    value_loss           | 2.69e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 779       |\n",
      "|    ep_rew_mean     | -1.05e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 704       |\n",
      "|    time_elapsed    | 2282      |\n",
      "|    total_timesteps | 1441792   |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 744           |\n",
      "|    ep_rew_mean          | -1.09e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 632           |\n",
      "|    iterations           | 705           |\n",
      "|    time_elapsed         | 2284          |\n",
      "|    total_timesteps      | 1443840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00067047763 |\n",
      "|    clip_fraction        | 0.00239       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.63         |\n",
      "|    explained_variance   | 0.242         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.23e+07      |\n",
      "|    n_updates            | 7040          |\n",
      "|    policy_gradient_loss | -0.0048       |\n",
      "|    std                  | 0.462         |\n",
      "|    value_loss           | 2.52e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=1445000, episode_reward=8657.24 +/- 3833.16\n",
      "Episode length: 1012.00 +/- 4.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | 8.66e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1445000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012967109 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.41e+07     |\n",
      "|    n_updates            | 7050         |\n",
      "|    policy_gradient_loss | -0.000884    |\n",
      "|    std                  | 0.462        |\n",
      "|    value_loss           | 1.65e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 732       |\n",
      "|    ep_rew_mean     | -1.07e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 706       |\n",
      "|    time_elapsed    | 2288      |\n",
      "|    total_timesteps | 1445888   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 713          |\n",
      "|    ep_rew_mean          | -1.11e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 632          |\n",
      "|    iterations           | 707          |\n",
      "|    time_elapsed         | 2290         |\n",
      "|    total_timesteps      | 1447936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046601277 |\n",
      "|    clip_fraction        | 0.0363       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.269        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.57e+07     |\n",
      "|    n_updates            | 7060         |\n",
      "|    policy_gradient_loss | -0.00243     |\n",
      "|    std                  | 0.462        |\n",
      "|    value_loss           | 8.35e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 718           |\n",
      "|    ep_rew_mean          | -1.06e+05     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 632           |\n",
      "|    iterations           | 708           |\n",
      "|    time_elapsed         | 2292          |\n",
      "|    total_timesteps      | 1449984       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048746305 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.64         |\n",
      "|    explained_variance   | 0.242         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.32e+08      |\n",
      "|    n_updates            | 7070          |\n",
      "|    policy_gradient_loss | -0.000316     |\n",
      "|    std                  | 0.462         |\n",
      "|    value_loss           | 2.27e+08      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1450000, episode_reward=13009.19 +/- 155.96\n",
      "Episode length: 1008.60 +/- 6.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | 1.3e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1450000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025206234 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.229        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.8e+07      |\n",
      "|    n_updates            | 7080         |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 0.462        |\n",
      "|    value_loss           | 4.13e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 716       |\n",
      "|    ep_rew_mean     | -1.04e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 632       |\n",
      "|    iterations      | 709       |\n",
      "|    time_elapsed    | 2296      |\n",
      "|    total_timesteps | 1452032   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | -9.81e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 632          |\n",
      "|    iterations           | 710          |\n",
      "|    time_elapsed         | 2298         |\n",
      "|    total_timesteps      | 1454080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034965554 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.64        |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.56e+04     |\n",
      "|    n_updates            | 7090         |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    std                  | 0.462        |\n",
      "|    value_loss           | 4.63e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1455000, episode_reward=9966.99 +/- 2322.89\n",
      "Episode length: 848.80 +/- 2.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 849         |\n",
      "|    mean_reward          | 9.97e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1455000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006222106 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.06e+03    |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | -0.00659    |\n",
      "|    std                  | 0.462       |\n",
      "|    value_loss           | 2.07e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 698       |\n",
      "|    ep_rew_mean     | -9.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 632       |\n",
      "|    iterations      | 711       |\n",
      "|    time_elapsed    | 2302      |\n",
      "|    total_timesteps | 1456128   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 680          |\n",
      "|    ep_rew_mean          | -9.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 632          |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 2304         |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050960765 |\n",
      "|    clip_fraction        | 0.063        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+03     |\n",
      "|    n_updates            | 7110         |\n",
      "|    policy_gradient_loss | -0.00401     |\n",
      "|    std                  | 0.46         |\n",
      "|    value_loss           | 3.17e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=7909.86 +/- 2944.39\n",
      "Episode length: 749.80 +/- 4.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 750         |\n",
      "|    mean_reward          | 7.91e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003550628 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.26        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.95e+07    |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    std                  | 0.461       |\n",
      "|    value_loss           | 8.98e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 656       |\n",
      "|    ep_rew_mean     | -9.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 632       |\n",
      "|    iterations      | 713       |\n",
      "|    time_elapsed    | 2307      |\n",
      "|    total_timesteps | 1460224   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 612         |\n",
      "|    ep_rew_mean          | -1.04e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 2309        |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004224444 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.59e+07    |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | -0.00344    |\n",
      "|    std                  | 0.462       |\n",
      "|    value_loss           | 8.59e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 618          |\n",
      "|    ep_rew_mean          | -9.85e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 633          |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 2311         |\n",
      "|    total_timesteps      | 1464320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038814968 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.282        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.78e+07     |\n",
      "|    n_updates            | 7140         |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    std                  | 0.463        |\n",
      "|    value_loss           | 8.3e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1465000, episode_reward=-97721.52 +/- 130850.95\n",
      "Episode length: 545.80 +/- 282.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 546         |\n",
      "|    mean_reward          | -9.77e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1465000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003903204 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.256       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+07    |\n",
      "|    n_updates            | 7150        |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    std                  | 0.463       |\n",
      "|    value_loss           | 3.8e+07     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 612       |\n",
      "|    ep_rew_mean     | -9.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 716       |\n",
      "|    time_elapsed    | 2314      |\n",
      "|    total_timesteps | 1466368   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 584         |\n",
      "|    ep_rew_mean          | -1.03e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 633         |\n",
      "|    iterations           | 717         |\n",
      "|    time_elapsed         | 2316        |\n",
      "|    total_timesteps      | 1468416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004438633 |\n",
      "|    clip_fraction        | 0.0394      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.247       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.58e+07    |\n",
      "|    n_updates            | 7160        |\n",
      "|    policy_gradient_loss | -0.00672    |\n",
      "|    std                  | 0.463       |\n",
      "|    value_loss           | 6.79e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=10158.41 +/- 780.72\n",
      "Episode length: 778.40 +/- 5.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 778         |\n",
      "|    mean_reward          | 1.02e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005390942 |\n",
      "|    clip_fraction        | 0.0315      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.17e+07    |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    std                  | 0.464       |\n",
      "|    value_loss           | 8.02e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 582       |\n",
      "|    ep_rew_mean     | -9.93e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 718       |\n",
      "|    time_elapsed    | 2320      |\n",
      "|    total_timesteps | 1470464   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 577         |\n",
      "|    ep_rew_mean          | -9.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 2321        |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005143892 |\n",
      "|    clip_fraction        | 0.0314      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6e+07     |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    std                  | 0.463       |\n",
      "|    value_loss           | 4.3e+07     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 571          |\n",
      "|    ep_rew_mean          | -9.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 720          |\n",
      "|    time_elapsed         | 2323         |\n",
      "|    total_timesteps      | 1474560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042871265 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.62e+07     |\n",
      "|    n_updates            | 7190         |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    std                  | 0.463        |\n",
      "|    value_loss           | 1.25e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1475000, episode_reward=-47883.06 +/- 118837.64\n",
      "Episode length: 731.80 +/- 253.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 732          |\n",
      "|    mean_reward          | -4.79e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1475000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034293865 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.66        |\n",
      "|    explained_variance   | 0.277        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.7e+07      |\n",
      "|    n_updates            | 7200         |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    std                  | 0.463        |\n",
      "|    value_loss           | 7.56e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 564       |\n",
      "|    ep_rew_mean     | -9.61e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 721       |\n",
      "|    time_elapsed    | 2327      |\n",
      "|    total_timesteps | 1476608   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 563          |\n",
      "|    ep_rew_mean          | -9.61e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 634          |\n",
      "|    iterations           | 722          |\n",
      "|    time_elapsed         | 2329         |\n",
      "|    total_timesteps      | 1478656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104914615 |\n",
      "|    clip_fraction        | 0.147        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.65        |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 519          |\n",
      "|    n_updates            | 7210         |\n",
      "|    policy_gradient_loss | -0.00453     |\n",
      "|    std                  | 0.462        |\n",
      "|    value_loss           | 3.37e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=11490.69 +/- 3085.80\n",
      "Episode length: 1031.40 +/- 7.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.03e+03    |\n",
      "|    mean_reward          | 1.15e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009964161 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 280         |\n",
      "|    n_updates            | 7220        |\n",
      "|    policy_gradient_loss | -0.000358   |\n",
      "|    std                  | 0.461       |\n",
      "|    value_loss           | 6.84e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 563       |\n",
      "|    ep_rew_mean     | -9.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 723       |\n",
      "|    time_elapsed    | 2333      |\n",
      "|    total_timesteps | 1480704   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 559         |\n",
      "|    ep_rew_mean          | -9.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 2335        |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004836424 |\n",
      "|    clip_fraction        | 0.0331      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.252       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13e+07    |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    std                  | 0.461       |\n",
      "|    value_loss           | 4.08e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 553          |\n",
      "|    ep_rew_mean          | -1.03e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 725          |\n",
      "|    time_elapsed         | 2337         |\n",
      "|    total_timesteps      | 1484800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012513839 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.19e+07     |\n",
      "|    n_updates            | 7240         |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    std                  | 0.461        |\n",
      "|    value_loss           | 1.39e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1485000, episode_reward=11041.74 +/- 2270.45\n",
      "Episode length: 1061.40 +/- 4.50\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.06e+03      |\n",
      "|    mean_reward          | 1.1e+04       |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 1485000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00011899631 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.63         |\n",
      "|    explained_variance   | 0.23          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.88e+07      |\n",
      "|    n_updates            | 7250          |\n",
      "|    policy_gradient_loss | -0.000376     |\n",
      "|    std                  | 0.461         |\n",
      "|    value_loss           | 8.6e+07       |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 560       |\n",
      "|    ep_rew_mean     | -1.02e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 726       |\n",
      "|    time_elapsed    | 2341      |\n",
      "|    total_timesteps | 1486848   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 557          |\n",
      "|    ep_rew_mean          | -1.04e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 727          |\n",
      "|    time_elapsed         | 2343         |\n",
      "|    total_timesteps      | 1488896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008173081 |\n",
      "|    clip_fraction        | 0.00142      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.217        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.42e+04     |\n",
      "|    n_updates            | 7260         |\n",
      "|    policy_gradient_loss | -0.00202     |\n",
      "|    std                  | 0.461        |\n",
      "|    value_loss           | 2.77e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=7994.31 +/- 4822.98\n",
      "Episode length: 1074.80 +/- 6.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.07e+03     |\n",
      "|    mean_reward          | 7.99e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1490000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005033058 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.243        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.27e+07     |\n",
      "|    n_updates            | 7270         |\n",
      "|    policy_gradient_loss | -0.00123     |\n",
      "|    std                  | 0.461        |\n",
      "|    value_loss           | 7.02e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 558       |\n",
      "|    ep_rew_mean     | -1.04e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 728       |\n",
      "|    time_elapsed    | 2347      |\n",
      "|    total_timesteps | 1490944   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 566          |\n",
      "|    ep_rew_mean          | -9.89e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 729          |\n",
      "|    time_elapsed         | 2349         |\n",
      "|    total_timesteps      | 1492992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061097704 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.894        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.67e+03     |\n",
      "|    n_updates            | 7280         |\n",
      "|    policy_gradient_loss | -0.00765     |\n",
      "|    std                  | 0.461        |\n",
      "|    value_loss           | 2.78e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1495000, episode_reward=-49364.52 +/- 116009.84\n",
      "Episode length: 816.20 +/- 295.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 816          |\n",
      "|    mean_reward          | -4.94e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1495000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024462692 |\n",
      "|    clip_fraction        | 0.0156       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.224        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.91e+07     |\n",
      "|    n_updates            | 7290         |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    std                  | 0.46         |\n",
      "|    value_loss           | 3.85e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 560       |\n",
      "|    ep_rew_mean     | -1.02e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 730       |\n",
      "|    time_elapsed    | 2353      |\n",
      "|    total_timesteps | 1495040   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 560          |\n",
      "|    ep_rew_mean          | -1e+05       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 731          |\n",
      "|    time_elapsed         | 2355         |\n",
      "|    total_timesteps      | 1497088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027881195 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.63        |\n",
      "|    explained_variance   | 0.228        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+07     |\n",
      "|    n_updates            | 7300         |\n",
      "|    policy_gradient_loss | -0.00684     |\n",
      "|    std                  | 0.461        |\n",
      "|    value_loss           | 4.36e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 562         |\n",
      "|    ep_rew_mean          | -9.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 2356        |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009498768 |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 692         |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    std                  | 0.462       |\n",
      "|    value_loss           | 4.76e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1500000, episode_reward=9403.02 +/- 2179.38\n",
      "Episode length: 888.60 +/- 6.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 889         |\n",
      "|    mean_reward          | 9.4e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005133666 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.64       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.59e+07    |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    std                  | 0.462       |\n",
      "|    value_loss           | 4.54e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 571       |\n",
      "|    ep_rew_mean     | -9.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 733       |\n",
      "|    time_elapsed    | 2360      |\n",
      "|    total_timesteps | 1501184   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 578         |\n",
      "|    ep_rew_mean          | -9.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 2362        |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010611647 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.63       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    std                  | 0.46        |\n",
      "|    value_loss           | 2.42e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1505000, episode_reward=11037.88 +/- 2369.50\n",
      "Episode length: 984.40 +/- 5.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 984         |\n",
      "|    mean_reward          | 1.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1505000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007043084 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.89e+07    |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    std                  | 0.459       |\n",
      "|    value_loss           | 9.44e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 590       |\n",
      "|    ep_rew_mean     | -9.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 735       |\n",
      "|    time_elapsed    | 2366      |\n",
      "|    total_timesteps | 1505280   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 601        |\n",
      "|    ep_rew_mean          | -9.54e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 636        |\n",
      "|    iterations           | 736        |\n",
      "|    time_elapsed         | 2368       |\n",
      "|    total_timesteps      | 1507328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00506648 |\n",
      "|    clip_fraction        | 0.0432     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.61      |\n",
      "|    explained_variance   | 0.253      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.16e+07   |\n",
      "|    n_updates            | 7350       |\n",
      "|    policy_gradient_loss | -0.00668   |\n",
      "|    std                  | 0.459      |\n",
      "|    value_loss           | 5.1e+07    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 610          |\n",
      "|    ep_rew_mean          | -9.05e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 737          |\n",
      "|    time_elapsed         | 2370         |\n",
      "|    total_timesteps      | 1509376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061092684 |\n",
      "|    clip_fraction        | 0.0584       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.61        |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.3e+04      |\n",
      "|    n_updates            | 7360         |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    std                  | 0.459        |\n",
      "|    value_loss           | 9.53e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=8882.97 +/- 3192.39\n",
      "Episode length: 1024.00 +/- 5.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 8.88e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003109089 |\n",
      "|    clip_fraction        | 0.014       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.246       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.21e+07    |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    std                  | 0.459       |\n",
      "|    value_loss           | 6.58e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 610       |\n",
      "|    ep_rew_mean     | -9.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 636       |\n",
      "|    iterations      | 738       |\n",
      "|    time_elapsed    | 2374      |\n",
      "|    total_timesteps | 1511424   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 601          |\n",
      "|    ep_rew_mean          | -9.59e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 636          |\n",
      "|    iterations           | 739          |\n",
      "|    time_elapsed         | 2376         |\n",
      "|    total_timesteps      | 1513472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043802075 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.269        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.32e+07     |\n",
      "|    n_updates            | 7380         |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    std                  | 0.459        |\n",
      "|    value_loss           | 8.77e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1515000, episode_reward=-52125.42 +/- 123316.67\n",
      "Episode length: 854.40 +/- 299.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 854          |\n",
      "|    mean_reward          | -5.21e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1515000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019048576 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.261        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.83e+07     |\n",
      "|    n_updates            | 7390         |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    std                  | 0.459        |\n",
      "|    value_loss           | 7.67e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 603       |\n",
      "|    ep_rew_mean     | -9.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 636       |\n",
      "|    iterations      | 740       |\n",
      "|    time_elapsed    | 2380      |\n",
      "|    total_timesteps | 1515520   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 598          |\n",
      "|    ep_rew_mean          | -1.02e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 637          |\n",
      "|    iterations           | 741          |\n",
      "|    time_elapsed         | 2382         |\n",
      "|    total_timesteps      | 1517568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074374913 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+04     |\n",
      "|    n_updates            | 7400         |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    std                  | 0.459        |\n",
      "|    value_loss           | 5.55e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 609          |\n",
      "|    ep_rew_mean          | -9.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 637          |\n",
      "|    iterations           | 742          |\n",
      "|    time_elapsed         | 2384         |\n",
      "|    total_timesteps      | 1519616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046115224 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.62        |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.59e+07     |\n",
      "|    n_updates            | 7410         |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    std                  | 0.459        |\n",
      "|    value_loss           | 8.99e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=-46100.83 +/- 117567.38\n",
      "Episode length: 962.20 +/- 362.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 962         |\n",
      "|    mean_reward          | -4.61e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010185749 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 865         |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.00668    |\n",
      "|    std                  | 0.458       |\n",
      "|    value_loss           | 1.3e+04     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 626      |\n",
      "|    ep_rew_mean     | -9.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 637      |\n",
      "|    iterations      | 743      |\n",
      "|    time_elapsed    | 2388     |\n",
      "|    total_timesteps | 1521664  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 634        |\n",
      "|    ep_rew_mean          | -9.4e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 637        |\n",
      "|    iterations           | 744        |\n",
      "|    time_elapsed         | 2390       |\n",
      "|    total_timesteps      | 1523712    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00662829 |\n",
      "|    clip_fraction        | 0.0782     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.62      |\n",
      "|    explained_variance   | 0.3        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.07e+07   |\n",
      "|    n_updates            | 7430       |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    std                  | 0.458      |\n",
      "|    value_loss           | 5.05e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1525000, episode_reward=-95574.88 +/- 133336.97\n",
      "Episode length: 989.20 +/- 653.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 989         |\n",
      "|    mean_reward          | -9.56e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1525000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016506767 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 313         |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.455       |\n",
      "|    value_loss           | 1.49e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 641       |\n",
      "|    ep_rew_mean     | -9.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 637       |\n",
      "|    iterations      | 745       |\n",
      "|    time_elapsed    | 2394      |\n",
      "|    total_timesteps | 1525760   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 651          |\n",
      "|    ep_rew_mean          | -9.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 637          |\n",
      "|    iterations           | 746          |\n",
      "|    time_elapsed         | 2396         |\n",
      "|    total_timesteps      | 1527808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051361565 |\n",
      "|    clip_fraction        | 0.149        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.6         |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.74e+07     |\n",
      "|    n_updates            | 7450         |\n",
      "|    policy_gradient_loss | 0.000992     |\n",
      "|    std                  | 0.456        |\n",
      "|    value_loss           | 3.96e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 659         |\n",
      "|    ep_rew_mean          | -9.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 637         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 2397        |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012517688 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 259         |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    std                  | 0.452       |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=15725.25 +/- 2140.69\n",
      "Episode length: 1806.40 +/- 7.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.81e+03    |\n",
      "|    mean_reward          | 1.57e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004140936 |\n",
      "|    clip_fraction        | 0.0849      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.56e+07    |\n",
      "|    n_updates            | 7470        |\n",
      "|    policy_gradient_loss | 0.00268     |\n",
      "|    std                  | 0.452       |\n",
      "|    value_loss           | 7.58e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 669       |\n",
      "|    ep_rew_mean     | -9.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 637       |\n",
      "|    iterations      | 748       |\n",
      "|    time_elapsed    | 2404      |\n",
      "|    total_timesteps | 1531904   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 677          |\n",
      "|    ep_rew_mean          | -9.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 637          |\n",
      "|    iterations           | 749          |\n",
      "|    time_elapsed         | 2405         |\n",
      "|    total_timesteps      | 1533952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026794104 |\n",
      "|    clip_fraction        | 0.0114       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.99e+07     |\n",
      "|    n_updates            | 7480         |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.452        |\n",
      "|    value_loss           | 3.7e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1535000, episode_reward=-29962.71 +/- 94753.88\n",
      "Episode length: 1426.20 +/- 639.61\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.43e+03     |\n",
      "|    mean_reward          | -3e+04       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1535000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035514366 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.58        |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.65e+07     |\n",
      "|    n_updates            | 7490         |\n",
      "|    policy_gradient_loss | -0.00411     |\n",
      "|    std                  | 0.452        |\n",
      "|    value_loss           | 4.22e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 688       |\n",
      "|    ep_rew_mean     | -9.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 637       |\n",
      "|    iterations      | 750       |\n",
      "|    time_elapsed    | 2411      |\n",
      "|    total_timesteps | 1536000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 704         |\n",
      "|    ep_rew_mean          | -9.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 637         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 2412        |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018060114 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 89.9        |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | 0.00082     |\n",
      "|    std                  | 0.455       |\n",
      "|    value_loss           | 580         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=17219.56 +/- 1970.28\n",
      "Episode length: 1783.60 +/- 8.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.78e+03    |\n",
      "|    mean_reward          | 1.72e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014001665 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 7510        |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    std                  | 0.458       |\n",
      "|    value_loss           | 948         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 726       |\n",
      "|    ep_rew_mean     | -8.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 636       |\n",
      "|    iterations      | 752       |\n",
      "|    time_elapsed    | 2418      |\n",
      "|    total_timesteps | 1540096   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 739         |\n",
      "|    ep_rew_mean          | -8.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 637         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 2420        |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010335637 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    std                  | 0.453       |\n",
      "|    value_loss           | 369         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 740         |\n",
      "|    ep_rew_mean          | -9.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 637         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 2422        |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008101167 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 7530        |\n",
      "|    policy_gradient_loss | -0.00073    |\n",
      "|    std                  | 0.453       |\n",
      "|    value_loss           | 7.88e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1545000, episode_reward=22420.51 +/- 3830.27\n",
      "Episode length: 2200.20 +/- 6.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.2e+03     |\n",
      "|    mean_reward          | 2.24e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1545000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004239881 |\n",
      "|    clip_fraction        | 0.0453      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.245       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.37e+07    |\n",
      "|    n_updates            | 7540        |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    std                  | 0.453       |\n",
      "|    value_loss           | 9.91e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 743       |\n",
      "|    ep_rew_mean     | -9.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 636       |\n",
      "|    iterations      | 755       |\n",
      "|    time_elapsed    | 2429      |\n",
      "|    total_timesteps | 1546240   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 756         |\n",
      "|    ep_rew_mean          | -9.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 2431        |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004653272 |\n",
      "|    clip_fraction        | 0.0357      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.26e+06    |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.000632   |\n",
      "|    std                  | 0.453       |\n",
      "|    value_loss           | 3.19e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1550000, episode_reward=-57420.46 +/- 78551.74\n",
      "Episode length: 2375.20 +/- 1117.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.38e+03     |\n",
      "|    mean_reward          | -5.74e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1550000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046461434 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.53        |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.29e+07     |\n",
      "|    n_updates            | 7560         |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    std                  | 0.453        |\n",
      "|    value_loss           | 3.31e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 773       |\n",
      "|    ep_rew_mean     | -8.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 757       |\n",
      "|    time_elapsed    | 2438      |\n",
      "|    total_timesteps | 1550336   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 791         |\n",
      "|    ep_rew_mean          | -8.53e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 2440        |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009205189 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 7570        |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    std                  | 0.45        |\n",
      "|    value_loss           | 1.06e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 809         |\n",
      "|    ep_rew_mean          | -8.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 2442        |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002852936 |\n",
      "|    clip_fraction        | 0.0639      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.53e+04    |\n",
      "|    n_updates            | 7580        |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    std                  | 0.451       |\n",
      "|    value_loss           | 3.47e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1555000, episode_reward=-96864.25 +/- 114893.85\n",
      "Episode length: 1891.60 +/- 1396.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.89e+03    |\n",
      "|    mean_reward          | -9.69e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1555000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003716335 |\n",
      "|    clip_fraction        | 0.0234      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.19e+03    |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.000769   |\n",
      "|    std                  | 0.452       |\n",
      "|    value_loss           | 4.18e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 809       |\n",
      "|    ep_rew_mean     | -8.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 760       |\n",
      "|    time_elapsed    | 2448      |\n",
      "|    total_timesteps | 1556480   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 826         |\n",
      "|    ep_rew_mean          | -8.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 636         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 2450        |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004626274 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.75e+07    |\n",
      "|    n_updates            | 7600        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    std                  | 0.451       |\n",
      "|    value_loss           | 7.91e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=-23140.06 +/- 101317.16\n",
      "Episode length: 1898.60 +/- 869.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.9e+03      |\n",
      "|    mean_reward          | -2.31e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1560000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060599037 |\n",
      "|    clip_fraction        | 0.0499       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.52        |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 567          |\n",
      "|    n_updates            | 7610         |\n",
      "|    policy_gradient_loss | -0.000762    |\n",
      "|    std                  | 0.45         |\n",
      "|    value_loss           | 6.66e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 834       |\n",
      "|    ep_rew_mean     | -8.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 635       |\n",
      "|    iterations      | 762       |\n",
      "|    time_elapsed    | 2456      |\n",
      "|    total_timesteps | 1560576   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 846         |\n",
      "|    ep_rew_mean          | -8.75e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 2458        |\n",
      "|    total_timesteps      | 1562624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010570994 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 705         |\n",
      "|    n_updates            | 7620        |\n",
      "|    policy_gradient_loss | -0.000402   |\n",
      "|    std                  | 0.448       |\n",
      "|    value_loss           | 1.02e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 859         |\n",
      "|    ep_rew_mean          | -8.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 635         |\n",
      "|    iterations           | 764         |\n",
      "|    time_elapsed         | 2460        |\n",
      "|    total_timesteps      | 1564672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016827911 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 7630        |\n",
      "|    policy_gradient_loss | -0.00332    |\n",
      "|    std                  | 0.443       |\n",
      "|    value_loss           | 357         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1565000, episode_reward=-18543.39 +/- 97732.48\n",
      "Episode length: 2391.60 +/- 1125.32\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.39e+03     |\n",
      "|    mean_reward          | -1.85e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1565000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071196835 |\n",
      "|    clip_fraction        | 0.0881       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.58e+04     |\n",
      "|    n_updates            | 7640         |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    std                  | 0.444        |\n",
      "|    value_loss           | 1.21e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 865       |\n",
      "|    ep_rew_mean     | -8.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 634       |\n",
      "|    iterations      | 765       |\n",
      "|    time_elapsed    | 2467      |\n",
      "|    total_timesteps | 1566720   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 876          |\n",
      "|    ep_rew_mean          | -8.81e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 635          |\n",
      "|    iterations           | 766          |\n",
      "|    time_elapsed         | 2469         |\n",
      "|    total_timesteps      | 1568768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036536437 |\n",
      "|    clip_fraction        | 0.0688       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.95e+07     |\n",
      "|    n_updates            | 7650         |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    std                  | 0.444        |\n",
      "|    value_loss           | 6.41e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=32619.50 +/- 3006.44\n",
      "Episode length: 3636.00 +/- 2.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.64e+03     |\n",
      "|    mean_reward          | 3.26e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1570000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020452414 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.43        |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.47e+07     |\n",
      "|    n_updates            | 7660         |\n",
      "|    policy_gradient_loss | -0.00236     |\n",
      "|    std                  | 0.444        |\n",
      "|    value_loss           | 3.23e+07     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 876       |\n",
      "|    ep_rew_mean     | -8.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 633       |\n",
      "|    iterations      | 767       |\n",
      "|    time_elapsed    | 2480      |\n",
      "|    total_timesteps | 1570816   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 894        |\n",
      "|    ep_rew_mean          | -8.64e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 633        |\n",
      "|    iterations           | 768        |\n",
      "|    time_elapsed         | 2482       |\n",
      "|    total_timesteps      | 1572864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01142437 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.41      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 46.2       |\n",
      "|    n_updates            | 7670       |\n",
      "|    policy_gradient_loss | -0.00694   |\n",
      "|    std                  | 0.441      |\n",
      "|    value_loss           | 187        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 922         |\n",
      "|    ep_rew_mean          | -8.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 634         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 2483        |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013967184 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.779       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    std                  | 0.44        |\n",
      "|    value_loss           | 3.9e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1575000, episode_reward=-95794.72 +/- 2339.51\n",
      "Episode length: 2915.00 +/- 9.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.92e+03     |\n",
      "|    mean_reward          | -9.58e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1575000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066860924 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.242        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+07     |\n",
      "|    n_updates            | 7690         |\n",
      "|    policy_gradient_loss | 0.00977      |\n",
      "|    std                  | 0.44         |\n",
      "|    value_loss           | 4.75e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 938       |\n",
      "|    ep_rew_mean     | -8.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 632       |\n",
      "|    iterations      | 770       |\n",
      "|    time_elapsed    | 2492      |\n",
      "|    total_timesteps | 1576960   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 938          |\n",
      "|    ep_rew_mean          | -8.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 632          |\n",
      "|    iterations           | 771          |\n",
      "|    time_elapsed         | 2494         |\n",
      "|    total_timesteps      | 1579008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067839744 |\n",
      "|    clip_fraction        | 0.0294       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+04      |\n",
      "|    n_updates            | 7700         |\n",
      "|    policy_gradient_loss | -0.00767     |\n",
      "|    std                  | 0.44         |\n",
      "|    value_loss           | 3.97e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=27705.37 +/- 3785.14\n",
      "Episode length: 2670.20 +/- 6.24\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.67e+03     |\n",
      "|    mean_reward          | 2.77e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1580000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029438674 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 621          |\n",
      "|    n_updates            | 7710         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    std                  | 0.44         |\n",
      "|    value_loss           | 6.67e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 950       |\n",
      "|    ep_rew_mean     | -8.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 631       |\n",
      "|    iterations      | 772       |\n",
      "|    time_elapsed    | 2502      |\n",
      "|    total_timesteps | 1581056   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 963          |\n",
      "|    ep_rew_mean          | -8.21e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 632          |\n",
      "|    iterations           | 773          |\n",
      "|    time_elapsed         | 2504         |\n",
      "|    total_timesteps      | 1583104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026618578 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.272        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16e+07     |\n",
      "|    n_updates            | 7720         |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    std                  | 0.44         |\n",
      "|    value_loss           | 4.04e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1585000, episode_reward=-12966.37 +/- 92894.17\n",
      "Episode length: 2691.20 +/- 1280.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.69e+03     |\n",
      "|    mean_reward          | -1.3e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1585000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064845155 |\n",
      "|    clip_fraction        | 0.0484       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.38        |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 341          |\n",
      "|    n_updates            | 7730         |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    std                  | 0.44         |\n",
      "|    value_loss           | 1.79e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 976      |\n",
      "|    ep_rew_mean     | -8.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 630      |\n",
      "|    iterations      | 774      |\n",
      "|    time_elapsed    | 2512     |\n",
      "|    total_timesteps | 1585152  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 993         |\n",
      "|    ep_rew_mean          | -8.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 775         |\n",
      "|    time_elapsed         | 2514        |\n",
      "|    total_timesteps      | 1587200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008327249 |\n",
      "|    clip_fraction        | 0.0705      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 7740        |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    std                  | 0.441       |\n",
      "|    value_loss           | 670         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -7.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 2516        |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002916148 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55e+07    |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.442       |\n",
      "|    value_loss           | 3.1e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1590000, episode_reward=-291828.09 +/- 82406.31\n",
      "Episode length: 1671.80 +/- 1259.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.67e+03    |\n",
      "|    mean_reward          | -2.92e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010072837 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 357         |\n",
      "|    n_updates            | 7760        |\n",
      "|    policy_gradient_loss | -0.000349   |\n",
      "|    std                  | 0.441       |\n",
      "|    value_loss           | 9.46e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -7.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 777       |\n",
      "|    time_elapsed    | 2522      |\n",
      "|    total_timesteps | 1591296   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -7.92e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 631         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 2523        |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004118181 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.235       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+07    |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    std                  | 0.441       |\n",
      "|    value_loss           | 3.44e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1595000, episode_reward=-181879.52 +/- 14768.68\n",
      "Episode length: 2316.00 +/- 1089.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.32e+03     |\n",
      "|    mean_reward          | -1.82e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1595000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034713256 |\n",
      "|    clip_fraction        | 0.00889      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.17e+03     |\n",
      "|    n_updates            | 7780         |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    std                  | 0.441        |\n",
      "|    value_loss           | 2.03e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.05e+03 |\n",
      "|    ep_rew_mean     | -7.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 630      |\n",
      "|    iterations      | 779      |\n",
      "|    time_elapsed    | 2531     |\n",
      "|    total_timesteps | 1595392  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | -7.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 630          |\n",
      "|    iterations           | 780          |\n",
      "|    time_elapsed         | 2533         |\n",
      "|    total_timesteps      | 1597440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046887984 |\n",
      "|    clip_fraction        | 0.0367       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.36e+04     |\n",
      "|    n_updates            | 7790         |\n",
      "|    policy_gradient_loss | -0.000482    |\n",
      "|    std                  | 0.441        |\n",
      "|    value_loss           | 1.89e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -7.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 2535        |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008856676 |\n",
      "|    clip_fraction        | 0.0962      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 7800        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    std                  | 0.441       |\n",
      "|    value_loss           | 408         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=-301872.10 +/- 53678.96\n",
      "Episode length: 2155.60 +/- 1016.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.16e+03     |\n",
      "|    mean_reward          | -3.02e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047779754 |\n",
      "|    clip_fraction        | 0.056        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.3e+06      |\n",
      "|    n_updates            | 7810         |\n",
      "|    policy_gradient_loss | 0.00301      |\n",
      "|    std                  | 0.441        |\n",
      "|    value_loss           | 1.14e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.08e+03  |\n",
      "|    ep_rew_mean     | -7.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 630       |\n",
      "|    iterations      | 782       |\n",
      "|    time_elapsed    | 2541      |\n",
      "|    total_timesteps | 1601536   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -8.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 630         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 2543        |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008460803 |\n",
      "|    clip_fraction        | 0.0533      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.605       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+06    |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.00386    |\n",
      "|    std                  | 0.441       |\n",
      "|    value_loss           | 1.49e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1605000, episode_reward=-93735.93 +/- 3651.91\n",
      "Episode length: 2888.40 +/- 7.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.89e+03     |\n",
      "|    mean_reward          | -9.37e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1605000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042600227 |\n",
      "|    clip_fraction        | 0.0205       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+07     |\n",
      "|    n_updates            | 7830         |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    std                  | 0.441        |\n",
      "|    value_loss           | 4.79e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.11e+03  |\n",
      "|    ep_rew_mean     | -8.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 629       |\n",
      "|    iterations      | 784       |\n",
      "|    time_elapsed    | 2552      |\n",
      "|    total_timesteps | 1605632   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -8e+04       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 785          |\n",
      "|    time_elapsed         | 2554         |\n",
      "|    total_timesteps      | 1607680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029678033 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 976          |\n",
      "|    n_updates            | 7840         |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    std                  | 0.441        |\n",
      "|    value_loss           | 6.28e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -7.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 2556        |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010629626 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 325         |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | 0.00156     |\n",
      "|    std                  | 0.438       |\n",
      "|    value_loss           | 461         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=-117696.88 +/- 109.16\n",
      "Episode length: 1988.80 +/- 4.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.99e+03    |\n",
      "|    mean_reward          | -1.18e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011270142 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.1        |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | 0.000518    |\n",
      "|    std                  | 0.438       |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.16e+03  |\n",
      "|    ep_rew_mean     | -7.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 787       |\n",
      "|    time_elapsed    | 2562      |\n",
      "|    total_timesteps | 1611776   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -8.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 2564        |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006197194 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.243       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5e+07     |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | 0.00265     |\n",
      "|    std                  | 0.438       |\n",
      "|    value_loss           | 3.95e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1615000, episode_reward=-183399.71 +/- 10445.66\n",
      "Episode length: 1533.40 +/- 700.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.53e+03     |\n",
      "|    mean_reward          | -1.83e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1615000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024173234 |\n",
      "|    clip_fraction        | 0.00703      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.74e+07     |\n",
      "|    n_updates            | 7880         |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    std                  | 0.439        |\n",
      "|    value_loss           | 4.22e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -8.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 789       |\n",
      "|    time_elapsed    | 2569      |\n",
      "|    total_timesteps | 1615872   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.2e+03      |\n",
      "|    ep_rew_mean          | -8.36e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 790          |\n",
      "|    time_elapsed         | 2571         |\n",
      "|    total_timesteps      | 1617920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040574465 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.98e+07     |\n",
      "|    n_updates            | 7890         |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    std                  | 0.439        |\n",
      "|    value_loss           | 3.97e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | -8.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 791          |\n",
      "|    time_elapsed         | 2573         |\n",
      "|    total_timesteps      | 1619968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067653665 |\n",
      "|    clip_fraction        | 0.043        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 816          |\n",
      "|    n_updates            | 7900         |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    std                  | 0.438        |\n",
      "|    value_loss           | 2.87e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=-166140.91 +/- 17844.97\n",
      "Episode length: 1597.20 +/- 726.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -1.66e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036645845 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.47e+05    |\n",
      "|    n_updates            | 7910        |\n",
      "|    policy_gradient_loss | 0.00543     |\n",
      "|    std                  | 0.44        |\n",
      "|    value_loss           | 1.37e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.23e+03  |\n",
      "|    ep_rew_mean     | -8.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 792       |\n",
      "|    time_elapsed    | 2578      |\n",
      "|    total_timesteps | 1622016   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | -8.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 793          |\n",
      "|    time_elapsed         | 2580         |\n",
      "|    total_timesteps      | 1624064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034422532 |\n",
      "|    clip_fraction        | 0.254        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+07      |\n",
      "|    n_updates            | 7920         |\n",
      "|    policy_gradient_loss | 0.0146       |\n",
      "|    std                  | 0.441        |\n",
      "|    value_loss           | 1.72e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1625000, episode_reward=-160451.55 +/- 22695.62\n",
      "Episode length: 1561.40 +/- 711.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.56e+03     |\n",
      "|    mean_reward          | -1.6e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1625000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020414083 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.321        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.65e+05     |\n",
      "|    n_updates            | 7930         |\n",
      "|    policy_gradient_loss | 0.00098      |\n",
      "|    std                  | 0.44         |\n",
      "|    value_loss           | 1.36e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -8.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 794       |\n",
      "|    time_elapsed    | 2586      |\n",
      "|    total_timesteps | 1626112   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | -8.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 629         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 2588        |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004019074 |\n",
      "|    clip_fraction        | 0.0523      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.291       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.4e+06     |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | 0.000876    |\n",
      "|    std                  | 0.441       |\n",
      "|    value_loss           | 2.16e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=-185858.62 +/- 11516.70\n",
      "Episode length: 1647.60 +/- 749.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.65e+03    |\n",
      "|    mean_reward          | -1.86e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006081178 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.94e+06    |\n",
      "|    n_updates            | 7950        |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    std                  | 0.44        |\n",
      "|    value_loss           | 1.11e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.27e+03  |\n",
      "|    ep_rew_mean     | -8.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 796       |\n",
      "|    time_elapsed    | 2593      |\n",
      "|    total_timesteps | 1630208   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.28e+03     |\n",
      "|    ep_rew_mean          | -8.13e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 628          |\n",
      "|    iterations           | 797          |\n",
      "|    time_elapsed         | 2595         |\n",
      "|    total_timesteps      | 1632256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067292913 |\n",
      "|    clip_fraction        | 0.0934       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2e+03        |\n",
      "|    n_updates            | 7960         |\n",
      "|    policy_gradient_loss | -0.000326    |\n",
      "|    std                  | 0.44         |\n",
      "|    value_loss           | 2.75e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.29e+03     |\n",
      "|    ep_rew_mean          | -7.7e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 629          |\n",
      "|    iterations           | 798          |\n",
      "|    time_elapsed         | 2597         |\n",
      "|    total_timesteps      | 1634304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032959091 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.32        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 603          |\n",
      "|    n_updates            | 7970         |\n",
      "|    policy_gradient_loss | -0.00264     |\n",
      "|    std                  | 0.44         |\n",
      "|    value_loss           | 1.82e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1635000, episode_reward=-28633.21 +/- 98154.22\n",
      "Episode length: 2394.00 +/- 1113.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.39e+03    |\n",
      "|    mean_reward          | -2.86e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1635000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009534389 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.2        |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | 0.000671    |\n",
      "|    std                  | 0.44        |\n",
      "|    value_loss           | 1.15e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.31e+03  |\n",
      "|    ep_rew_mean     | -7.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 628       |\n",
      "|    iterations      | 799       |\n",
      "|    time_elapsed    | 2604      |\n",
      "|    total_timesteps | 1636352   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.31e+03   |\n",
      "|    ep_rew_mean          | -7.24e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 628        |\n",
      "|    iterations           | 800        |\n",
      "|    time_elapsed         | 2606       |\n",
      "|    total_timesteps      | 1638400    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00572781 |\n",
      "|    clip_fraction        | 0.0377     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 293        |\n",
      "|    n_updates            | 7990       |\n",
      "|    policy_gradient_loss | -0.00313   |\n",
      "|    std                  | 0.439      |\n",
      "|    value_loss           | 1.1e+04    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=-80398.92 +/- 122417.56\n",
      "Episode length: 1885.80 +/- 1408.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.89e+03    |\n",
      "|    mean_reward          | -8.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019889424 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.35e+03    |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    std                  | 0.439       |\n",
      "|    value_loss           | 1e+04       |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.32e+03  |\n",
      "|    ep_rew_mean     | -7.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 627       |\n",
      "|    iterations      | 801       |\n",
      "|    time_elapsed    | 2612      |\n",
      "|    total_timesteps | 1640448   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.33e+03     |\n",
      "|    ep_rew_mean          | -7.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 628          |\n",
      "|    iterations           | 802          |\n",
      "|    time_elapsed         | 2614         |\n",
      "|    total_timesteps      | 1642496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048387162 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.878        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 163          |\n",
      "|    n_updates            | 8010         |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    std                  | 0.439        |\n",
      "|    value_loss           | 5.25e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.35e+03     |\n",
      "|    ep_rew_mean          | -7.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 628          |\n",
      "|    iterations           | 803          |\n",
      "|    time_elapsed         | 2616         |\n",
      "|    total_timesteps      | 1644544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032091443 |\n",
      "|    clip_fraction        | 0.018        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.261        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05e+07     |\n",
      "|    n_updates            | 8020         |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    std                  | 0.439        |\n",
      "|    value_loss           | 3.44e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1645000, episode_reward=19189.64 +/- 2901.65\n",
      "Episode length: 2474.60 +/- 9.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.47e+03     |\n",
      "|    mean_reward          | 1.92e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1645000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040151533 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 988          |\n",
      "|    n_updates            | 8030         |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    std                  | 0.439        |\n",
      "|    value_loss           | 1.02e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.37e+03  |\n",
      "|    ep_rew_mean     | -6.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 627       |\n",
      "|    iterations      | 804       |\n",
      "|    time_elapsed    | 2624      |\n",
      "|    total_timesteps | 1646592   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | -6.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 627         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 2626        |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009279184 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    std                  | 0.438       |\n",
      "|    value_loss           | 8.7e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=8557.40 +/- 351.53\n",
      "Episode length: 2456.60 +/- 7.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.46e+03    |\n",
      "|    mean_reward          | 8.56e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006765268 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 317         |\n",
      "|    n_updates            | 8050        |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    std                  | 0.437       |\n",
      "|    value_loss           | 831         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.39e+03  |\n",
      "|    ep_rew_mean     | -6.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 626       |\n",
      "|    iterations      | 806       |\n",
      "|    time_elapsed    | 2633      |\n",
      "|    total_timesteps | 1650688   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | -6.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 627         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 2635        |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006442291 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.5        |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | 0.00297     |\n",
      "|    std                  | 0.437       |\n",
      "|    value_loss           | 4.68e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | -6.12e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 627         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 2637        |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016334053 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.75e+07    |\n",
      "|    n_updates            | 8070        |\n",
      "|    policy_gradient_loss | 0.00177     |\n",
      "|    std                  | 0.436       |\n",
      "|    value_loss           | 3.37e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1655000, episode_reward=12242.43 +/- 3687.81\n",
      "Episode length: 2488.00 +/- 10.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.49e+03    |\n",
      "|    mean_reward          | 1.22e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1655000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009186201 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 8080        |\n",
      "|    policy_gradient_loss | -0.00317    |\n",
      "|    std                  | 0.437       |\n",
      "|    value_loss           | 934         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.42e+03  |\n",
      "|    ep_rew_mean     | -6.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 626       |\n",
      "|    iterations      | 809       |\n",
      "|    time_elapsed    | 2645      |\n",
      "|    total_timesteps | 1656832   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -6.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 2646        |\n",
      "|    total_timesteps      | 1658880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013136547 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.7        |\n",
      "|    n_updates            | 8090        |\n",
      "|    policy_gradient_loss | -0.000662   |\n",
      "|    std                  | 0.437       |\n",
      "|    value_loss           | 485         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1660000, episode_reward=-193187.28 +/- 15949.16\n",
      "Episode length: 1650.20 +/- 749.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.65e+03     |\n",
      "|    mean_reward          | -1.93e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1660000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027255123 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.264        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.21e+07     |\n",
      "|    n_updates            | 8100         |\n",
      "|    policy_gradient_loss | 0.0033       |\n",
      "|    std                  | 0.437        |\n",
      "|    value_loss           | 4.06e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -6.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 626       |\n",
      "|    iterations      | 811       |\n",
      "|    time_elapsed    | 2652      |\n",
      "|    total_timesteps | 1660928   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | -6.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 2654        |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010688486 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+05    |\n",
      "|    n_updates            | 8110        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    std                  | 0.437       |\n",
      "|    value_loss           | 2.93e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1665000, episode_reward=-73434.01 +/- 120605.59\n",
      "Episode length: 1539.60 +/- 1132.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.54e+03    |\n",
      "|    mean_reward          | -7.34e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1665000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004977608 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 526         |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    std                  | 0.437       |\n",
      "|    value_loss           | 1.17e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -5.71e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 625       |\n",
      "|    iterations      | 813       |\n",
      "|    time_elapsed    | 2659      |\n",
      "|    total_timesteps | 1665024   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -5.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 2661        |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012983031 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 623         |\n",
      "|    n_updates            | 8130        |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    std                  | 0.438       |\n",
      "|    value_loss           | 1.06e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -5.94e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 2663        |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018902985 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 8140        |\n",
      "|    policy_gradient_loss | 0.00607     |\n",
      "|    std                  | 0.441       |\n",
      "|    value_loss           | 6.48e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1670000, episode_reward=20675.47 +/- 3029.21\n",
      "Episode length: 2355.40 +/- 6.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.36e+03     |\n",
      "|    mean_reward          | 2.07e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1670000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044790884 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.07e+07     |\n",
      "|    n_updates            | 8150         |\n",
      "|    policy_gradient_loss | -0.000988    |\n",
      "|    std                  | 0.441        |\n",
      "|    value_loss           | 3.7e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -5.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 625       |\n",
      "|    iterations      | 816       |\n",
      "|    time_elapsed    | 2670      |\n",
      "|    total_timesteps | 1671168   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -5.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 626         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 2672        |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008573409 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 8160        |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    std                  | 0.439       |\n",
      "|    value_loss           | 379         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1675000, episode_reward=30207.14 +/- 2397.88\n",
      "Episode length: 3019.40 +/- 8.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.02e+03    |\n",
      "|    mean_reward          | 3.02e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1675000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011997648 |\n",
      "|    clip_fraction        | 0.0929      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.21e+03    |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 0.439       |\n",
      "|    value_loss           | 5.2e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -5.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 624       |\n",
      "|    iterations      | 818       |\n",
      "|    time_elapsed    | 2681      |\n",
      "|    total_timesteps | 1675264   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -5.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 625         |\n",
      "|    iterations           | 819         |\n",
      "|    time_elapsed         | 2683        |\n",
      "|    total_timesteps      | 1677312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009138273 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 8180        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    std                  | 0.439       |\n",
      "|    value_loss           | 668         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -5.97e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 625          |\n",
      "|    iterations           | 820          |\n",
      "|    time_elapsed         | 2685         |\n",
      "|    total_timesteps      | 1679360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014405281 |\n",
      "|    clip_fraction        | 0.00181      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6e+07        |\n",
      "|    n_updates            | 8190         |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.439        |\n",
      "|    value_loss           | 9.49e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1680000, episode_reward=25483.19 +/- 2211.72\n",
      "Episode length: 2450.00 +/- 9.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.45e+03    |\n",
      "|    mean_reward          | 2.55e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003699587 |\n",
      "|    clip_fraction        | 0.0062      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.262       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.32e+06    |\n",
      "|    n_updates            | 8200        |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    std                  | 0.439       |\n",
      "|    value_loss           | 3.37e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -6.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 624       |\n",
      "|    iterations      | 821       |\n",
      "|    time_elapsed    | 2692      |\n",
      "|    total_timesteps | 1681408   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | -6.18e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 624          |\n",
      "|    iterations           | 822          |\n",
      "|    time_elapsed         | 2694         |\n",
      "|    total_timesteps      | 1683456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026779184 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.68e+07     |\n",
      "|    n_updates            | 8210         |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    std                  | 0.439        |\n",
      "|    value_loss           | 1.06e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1685000, episode_reward=24000.99 +/- 3903.10\n",
      "Episode length: 2481.20 +/- 6.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.48e+03     |\n",
      "|    mean_reward          | 2.4e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1685000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059800134 |\n",
      "|    clip_fraction        | 0.0562       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 461          |\n",
      "|    n_updates            | 8220         |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    std                  | 0.438        |\n",
      "|    value_loss           | 2.09e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -5.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 623       |\n",
      "|    iterations      | 823       |\n",
      "|    time_elapsed    | 2702      |\n",
      "|    total_timesteps | 1685504   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | -6.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 624         |\n",
      "|    iterations           | 824         |\n",
      "|    time_elapsed         | 2704        |\n",
      "|    total_timesteps      | 1687552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008947352 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.5        |\n",
      "|    n_updates            | 8230        |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    std                  | 0.439       |\n",
      "|    value_loss           | 4.51e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.51e+03   |\n",
      "|    ep_rew_mean          | -6.07e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 624        |\n",
      "|    iterations           | 825        |\n",
      "|    time_elapsed         | 2706       |\n",
      "|    total_timesteps      | 1689600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00378137 |\n",
      "|    clip_fraction        | 0.0269     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.282      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.51e+07   |\n",
      "|    n_updates            | 8240       |\n",
      "|    policy_gradient_loss | -0.00234   |\n",
      "|    std                  | 0.439      |\n",
      "|    value_loss           | 6.5e+07    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1690000, episode_reward=28549.15 +/- 14233.02\n",
      "Episode length: 3185.20 +/- 170.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.19e+03   |\n",
      "|    mean_reward          | 2.85e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1690000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03040342 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.24      |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 24.8       |\n",
      "|    n_updates            | 8250       |\n",
      "|    policy_gradient_loss | -0.000541  |\n",
      "|    std                  | 0.445      |\n",
      "|    value_loss           | 177        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -6.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 622       |\n",
      "|    iterations      | 826       |\n",
      "|    time_elapsed    | 2715      |\n",
      "|    total_timesteps | 1691648   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | -6.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 623          |\n",
      "|    iterations           | 827          |\n",
      "|    time_elapsed         | 2717         |\n",
      "|    total_timesteps      | 1693696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070582936 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.25        |\n",
      "|    explained_variance   | 0.269        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.28e+06     |\n",
      "|    n_updates            | 8260         |\n",
      "|    policy_gradient_loss | -0.0008      |\n",
      "|    std                  | 0.444        |\n",
      "|    value_loss           | 3.01e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1695000, episode_reward=35412.04 +/- 3760.04\n",
      "Episode length: 2964.00 +/- 12.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.96e+03    |\n",
      "|    mean_reward          | 3.54e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1695000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008949457 |\n",
      "|    clip_fraction        | 0.0981      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.36e+03    |\n",
      "|    n_updates            | 8270        |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    std                  | 0.443       |\n",
      "|    value_loss           | 6.85e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -6.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 622       |\n",
      "|    iterations      | 828       |\n",
      "|    time_elapsed    | 2726      |\n",
      "|    total_timesteps | 1695744   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -6.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 622         |\n",
      "|    iterations           | 829         |\n",
      "|    time_elapsed         | 2728        |\n",
      "|    total_timesteps      | 1697792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012221674 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.3        |\n",
      "|    n_updates            | 8280        |\n",
      "|    policy_gradient_loss | 0.000933    |\n",
      "|    std                  | 0.442       |\n",
      "|    value_loss           | 484         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -5.84e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 622         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 2729        |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021954887 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | 0.00237     |\n",
      "|    std                  | 0.437       |\n",
      "|    value_loss           | 287         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=-24662.76 +/- 95377.13\n",
      "Episode length: 1975.40 +/- 913.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.98e+03     |\n",
      "|    mean_reward          | -2.47e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1700000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037734676 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+07     |\n",
      "|    n_updates            | 8300         |\n",
      "|    policy_gradient_loss | 0.0012       |\n",
      "|    std                  | 0.437        |\n",
      "|    value_loss           | 3.5e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.55e+03  |\n",
      "|    ep_rew_mean     | -5.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 621       |\n",
      "|    iterations      | 831       |\n",
      "|    time_elapsed    | 2736      |\n",
      "|    total_timesteps | 1701888   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -5.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 622         |\n",
      "|    iterations           | 832         |\n",
      "|    time_elapsed         | 2738        |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017458223 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.5        |\n",
      "|    n_updates            | 8310        |\n",
      "|    policy_gradient_loss | 0.00218     |\n",
      "|    std                  | 0.438       |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1705000, episode_reward=27464.17 +/- 2381.47\n",
      "Episode length: 2389.80 +/- 7.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.39e+03    |\n",
      "|    mean_reward          | 2.75e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1705000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011282373 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 8320        |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    std                  | 0.44        |\n",
      "|    value_loss           | 5.16e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -5.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 621       |\n",
      "|    iterations      | 833       |\n",
      "|    time_elapsed    | 2745      |\n",
      "|    total_timesteps | 1705984   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -5.65e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 621         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 2747        |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009989141 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.7        |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    std                  | 0.443       |\n",
      "|    value_loss           | 363         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1710000, episode_reward=-72735.76 +/- 125273.74\n",
      "Episode length: 2165.60 +/- 1644.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.17e+03    |\n",
      "|    mean_reward          | -7.27e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005242034 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.33e+07    |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    std                  | 0.444       |\n",
      "|    value_loss           | 3.63e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -5.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 620       |\n",
      "|    iterations      | 835       |\n",
      "|    time_elapsed    | 2754      |\n",
      "|    total_timesteps | 1710080   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -5.43e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 621         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 2756        |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011453781 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.5        |\n",
      "|    n_updates            | 8350        |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    std                  | 0.441       |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -6.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 621         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 2758        |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012036856 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34e+04    |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    std                  | 0.438       |\n",
      "|    value_loss           | 2.92e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1715000, episode_reward=29655.90 +/- 3040.57\n",
      "Episode length: 2964.40 +/- 5.57\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 2.96e+03      |\n",
      "|    mean_reward          | 2.97e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 1715000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00048985775 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.22         |\n",
      "|    explained_variance   | 0.273         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.06e+08      |\n",
      "|    n_updates            | 8370          |\n",
      "|    policy_gradient_loss | 0.000303      |\n",
      "|    std                  | 0.438         |\n",
      "|    value_loss           | 2.08e+08      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -6.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 620       |\n",
      "|    iterations      | 838       |\n",
      "|    time_elapsed    | 2767      |\n",
      "|    total_timesteps | 1716224   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | -6.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 620          |\n",
      "|    iterations           | 839          |\n",
      "|    time_elapsed         | 2768         |\n",
      "|    total_timesteps      | 1718272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019502195 |\n",
      "|    clip_fraction        | 0.00518      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.806        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 862          |\n",
      "|    n_updates            | 8380         |\n",
      "|    policy_gradient_loss | -0.00107     |\n",
      "|    std                  | 0.438        |\n",
      "|    value_loss           | 9.61e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1720000, episode_reward=25202.52 +/- 4924.92\n",
      "Episode length: 2550.80 +/- 8.86\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.55e+03     |\n",
      "|    mean_reward          | 2.52e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047925655 |\n",
      "|    clip_fraction        | 0.0454       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 227          |\n",
      "|    n_updates            | 8390         |\n",
      "|    policy_gradient_loss | -0.0055      |\n",
      "|    std                  | 0.438        |\n",
      "|    value_loss           | 1.39e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -6.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 619       |\n",
      "|    iterations      | 840       |\n",
      "|    time_elapsed    | 2776      |\n",
      "|    total_timesteps | 1720320   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.55e+03   |\n",
      "|    ep_rew_mean          | -5.99e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 619        |\n",
      "|    iterations           | 841        |\n",
      "|    time_elapsed         | 2778       |\n",
      "|    total_timesteps      | 1722368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01455236 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 34.2       |\n",
      "|    n_updates            | 8400       |\n",
      "|    policy_gradient_loss | 0.0103     |\n",
      "|    std                  | 0.439      |\n",
      "|    value_loss           | 338        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -5.82e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 620         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 2780        |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011513397 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.1        |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | 0.00404     |\n",
      "|    std                  | 0.437       |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1725000, episode_reward=-71312.42 +/- 107637.52\n",
      "Episode length: 1219.60 +/- 885.57\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.22e+03   |\n",
      "|    mean_reward          | -7.13e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1725000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00434466 |\n",
      "|    clip_fraction        | 0.0837     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.89e+04   |\n",
      "|    n_updates            | 8420       |\n",
      "|    policy_gradient_loss | -0.00189   |\n",
      "|    std                  | 0.436      |\n",
      "|    value_loss           | 2.68e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -5.61e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 619       |\n",
      "|    iterations      | 843       |\n",
      "|    time_elapsed    | 2785      |\n",
      "|    total_timesteps | 1726464   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.55e+03   |\n",
      "|    ep_rew_mean          | -5.51e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 620        |\n",
      "|    iterations           | 844        |\n",
      "|    time_elapsed         | 2786       |\n",
      "|    total_timesteps      | 1728512    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02519098 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 40.5       |\n",
      "|    n_updates            | 8430       |\n",
      "|    policy_gradient_loss | 0.00261    |\n",
      "|    std                  | 0.43       |\n",
      "|    value_loss           | 5.61e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1730000, episode_reward=15500.47 +/- 3794.52\n",
      "Episode length: 2037.80 +/- 4.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.04e+03    |\n",
      "|    mean_reward          | 1.55e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007301622 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 233         |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.00693    |\n",
      "|    std                  | 0.43        |\n",
      "|    value_loss           | 1.03e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -5.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 619       |\n",
      "|    iterations      | 845       |\n",
      "|    time_elapsed    | 2793      |\n",
      "|    total_timesteps | 1730560   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -5.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 619         |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 2795        |\n",
      "|    total_timesteps      | 1732608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007629179 |\n",
      "|    clip_fraction        | 0.037       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.27        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+07    |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    std                  | 0.431       |\n",
      "|    value_loss           | 3.2e+07     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -5.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 620         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 2797        |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013998919 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 82.7        |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    std                  | 0.429       |\n",
      "|    value_loss           | 283         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1735000, episode_reward=25109.72 +/- 3063.92\n",
      "Episode length: 2662.40 +/- 9.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.66e+03    |\n",
      "|    mean_reward          | 2.51e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1735000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010407268 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.1        |\n",
      "|    n_updates            | 8470        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    std                  | 0.428       |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -5.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 619       |\n",
      "|    iterations      | 848       |\n",
      "|    time_elapsed    | 2805      |\n",
      "|    total_timesteps | 1736704   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -5.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 619         |\n",
      "|    iterations           | 849         |\n",
      "|    time_elapsed         | 2806        |\n",
      "|    total_timesteps      | 1738752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006110165 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 8480        |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    std                  | 0.428       |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1740000, episode_reward=23439.82 +/- 3345.65\n",
      "Episode length: 2887.20 +/- 17.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.89e+03     |\n",
      "|    mean_reward          | 2.34e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1740000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017643643 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.238        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.08e+07     |\n",
      "|    n_updates            | 8490         |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    std                  | 0.428        |\n",
      "|    value_loss           | 3.15e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -5.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 618       |\n",
      "|    iterations      | 850       |\n",
      "|    time_elapsed    | 2815      |\n",
      "|    total_timesteps | 1740800   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | -5.33e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 618          |\n",
      "|    iterations           | 851          |\n",
      "|    time_elapsed         | 2817         |\n",
      "|    total_timesteps      | 1742848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060823425 |\n",
      "|    clip_fraction        | 0.0265       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.97e+03     |\n",
      "|    n_updates            | 8500         |\n",
      "|    policy_gradient_loss | -0.0076      |\n",
      "|    std                  | 0.428        |\n",
      "|    value_loss           | 4.12e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | -5.16e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 618          |\n",
      "|    iterations           | 852          |\n",
      "|    time_elapsed         | 2819         |\n",
      "|    total_timesteps      | 1744896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038760058 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 293          |\n",
      "|    n_updates            | 8510         |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    std                  | 0.429        |\n",
      "|    value_loss           | 2.17e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1745000, episode_reward=10953.60 +/- 3135.48\n",
      "Episode length: 2717.80 +/- 9.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.72e+03    |\n",
      "|    mean_reward          | 1.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1745000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009023568 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.61e+03    |\n",
      "|    n_updates            | 8520        |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    std                  | 0.429       |\n",
      "|    value_loss           | 1.64e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -5.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 617       |\n",
      "|    iterations      | 853       |\n",
      "|    time_elapsed    | 2827      |\n",
      "|    total_timesteps | 1746944   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | -5.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 618          |\n",
      "|    iterations           | 854          |\n",
      "|    time_elapsed         | 2829         |\n",
      "|    total_timesteps      | 1748992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058371983 |\n",
      "|    clip_fraction        | 0.09         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 764          |\n",
      "|    n_updates            | 8530         |\n",
      "|    policy_gradient_loss | -0.000759    |\n",
      "|    std                  | 0.43         |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1750000, episode_reward=-21871.48 +/- 85676.98\n",
      "Episode length: 2030.40 +/- 955.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.03e+03    |\n",
      "|    mean_reward          | -2.19e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017744826 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 8540        |\n",
      "|    policy_gradient_loss | 0.000435    |\n",
      "|    std                  | 0.429       |\n",
      "|    value_loss           | 5.36e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -5.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 617       |\n",
      "|    iterations      | 855       |\n",
      "|    time_elapsed    | 2835      |\n",
      "|    total_timesteps | 1751040   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -5.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 856          |\n",
      "|    time_elapsed         | 2837         |\n",
      "|    total_timesteps      | 1753088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032163924 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.44e+06     |\n",
      "|    n_updates            | 8550         |\n",
      "|    policy_gradient_loss | -0.0037      |\n",
      "|    std                  | 0.429        |\n",
      "|    value_loss           | 3.28e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1755000, episode_reward=-58644.78 +/- 100302.29\n",
      "Episode length: 1536.00 +/- 1161.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.54e+03    |\n",
      "|    mean_reward          | -5.86e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1755000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016244937 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.9        |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.000679   |\n",
      "|    std                  | 0.429       |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -5.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 617       |\n",
      "|    iterations      | 857       |\n",
      "|    time_elapsed    | 2843      |\n",
      "|    total_timesteps | 1755136   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -5.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 617          |\n",
      "|    iterations           | 858          |\n",
      "|    time_elapsed         | 2844         |\n",
      "|    total_timesteps      | 1757184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0152427275 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 43.8         |\n",
      "|    n_updates            | 8570         |\n",
      "|    policy_gradient_loss | -5.67e-05    |\n",
      "|    std                  | 0.427        |\n",
      "|    value_loss           | 4.54e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.51e+03   |\n",
      "|    ep_rew_mean          | -5.04e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 617        |\n",
      "|    iterations           | 859        |\n",
      "|    time_elapsed         | 2846       |\n",
      "|    total_timesteps      | 1759232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01323407 |\n",
      "|    clip_fraction        | 0.047      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 143        |\n",
      "|    n_updates            | 8580       |\n",
      "|    policy_gradient_loss | -0.00224   |\n",
      "|    std                  | 0.427      |\n",
      "|    value_loss           | 1.97e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1760000, episode_reward=-22143.71 +/- 84889.78\n",
      "Episode length: 2523.20 +/- 1204.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.52e+03    |\n",
      "|    mean_reward          | -2.21e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004988049 |\n",
      "|    clip_fraction        | 0.0341      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 472         |\n",
      "|    n_updates            | 8590        |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    std                  | 0.427       |\n",
      "|    value_loss           | 4.92e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -5.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 617       |\n",
      "|    iterations      | 860       |\n",
      "|    time_elapsed    | 2854      |\n",
      "|    total_timesteps | 1761280   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | -5.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 617         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 2856        |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011481948 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.267       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.2e+06     |\n",
      "|    n_updates            | 8600        |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    std                  | 0.429       |\n",
      "|    value_loss           | 2.96e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1765000, episode_reward=17000.68 +/- 3863.53\n",
      "Episode length: 2475.40 +/- 12.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.48e+03    |\n",
      "|    mean_reward          | 1.7e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1765000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005071853 |\n",
      "|    clip_fraction        | 0.054       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    std                  | 0.428       |\n",
      "|    value_loss           | 775         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -4.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 862       |\n",
      "|    time_elapsed    | 2863      |\n",
      "|    total_timesteps | 1765376   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -4.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 2865        |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010259757 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.9        |\n",
      "|    n_updates            | 8620        |\n",
      "|    policy_gradient_loss | -0.000146   |\n",
      "|    std                  | 0.425       |\n",
      "|    value_loss           | 556         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.49e+03  |\n",
      "|    ep_rew_mean          | -4.53e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 617       |\n",
      "|    iterations           | 864       |\n",
      "|    time_elapsed         | 2867      |\n",
      "|    total_timesteps      | 1769472   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0125588 |\n",
      "|    clip_fraction        | 0.173     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.1      |\n",
      "|    explained_variance   | 0.997     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 43.4      |\n",
      "|    n_updates            | 8630      |\n",
      "|    policy_gradient_loss | 0.00361   |\n",
      "|    std                  | 0.424     |\n",
      "|    value_loss           | 266       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1770000, episode_reward=16767.62 +/- 4090.73\n",
      "Episode length: 2425.00 +/- 3.29\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.42e+03     |\n",
      "|    mean_reward          | 1.68e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1770000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065255403 |\n",
      "|    clip_fraction        | 0.0793       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 79.1         |\n",
      "|    n_updates            | 8640         |\n",
      "|    policy_gradient_loss | 0.00126      |\n",
      "|    std                  | 0.425        |\n",
      "|    value_loss           | 1.39e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -4.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 616       |\n",
      "|    iterations      | 865       |\n",
      "|    time_elapsed    | 2875      |\n",
      "|    total_timesteps | 1771520   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -4.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 2876        |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004589131 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 324         |\n",
      "|    n_updates            | 8650        |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    std                  | 0.425       |\n",
      "|    value_loss           | 1.76e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1775000, episode_reward=-126545.89 +/- 3670.32\n",
      "Episode length: 2201.40 +/- 17.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.2e+03     |\n",
      "|    mean_reward          | -1.27e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1775000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008834113 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.5        |\n",
      "|    n_updates            | 8660        |\n",
      "|    policy_gradient_loss | -0.000759   |\n",
      "|    std                  | 0.419       |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -4.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 615       |\n",
      "|    iterations      | 867       |\n",
      "|    time_elapsed    | 2883      |\n",
      "|    total_timesteps | 1775616   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -4.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 2885        |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013336431 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 393         |\n",
      "|    n_updates            | 8670        |\n",
      "|    policy_gradient_loss | -0.00909    |\n",
      "|    std                  | 0.419       |\n",
      "|    value_loss           | 5.42e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -4e+04      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 616         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 2887        |\n",
      "|    total_timesteps      | 1779712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012926122 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 8680        |\n",
      "|    policy_gradient_loss | 0.00639     |\n",
      "|    std                  | 0.422       |\n",
      "|    value_loss           | 179         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1780000, episode_reward=22298.80 +/- 2401.58\n",
      "Episode length: 2445.80 +/- 9.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.45e+03     |\n",
      "|    mean_reward          | 2.23e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1780000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078006024 |\n",
      "|    clip_fraction        | 0.0946       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 115          |\n",
      "|    n_updates            | 8690         |\n",
      "|    policy_gradient_loss | -0.00304     |\n",
      "|    std                  | 0.423        |\n",
      "|    value_loss           | 6.45e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.48e+03 |\n",
      "|    ep_rew_mean     | -4e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 615      |\n",
      "|    iterations      | 870      |\n",
      "|    time_elapsed    | 2895     |\n",
      "|    total_timesteps | 1781760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -4e+04      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 2897        |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013513322 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.9        |\n",
      "|    n_updates            | 8700        |\n",
      "|    policy_gradient_loss | 0.00606     |\n",
      "|    std                  | 0.424       |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1785000, episode_reward=-15994.89 +/- 84602.14\n",
      "Episode length: 2329.40 +/- 1109.76\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.33e+03   |\n",
      "|    mean_reward          | -1.6e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1785000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01088232 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 41.2       |\n",
      "|    n_updates            | 8710       |\n",
      "|    policy_gradient_loss | 0.00832    |\n",
      "|    std                  | 0.422      |\n",
      "|    value_loss           | 904        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -4.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 872       |\n",
      "|    time_elapsed    | 2904      |\n",
      "|    total_timesteps | 1785856   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | -4.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 615          |\n",
      "|    iterations           | 873          |\n",
      "|    time_elapsed         | 2906         |\n",
      "|    total_timesteps      | 1787904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036109143 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.05        |\n",
      "|    explained_variance   | 0.318        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.78e+04     |\n",
      "|    n_updates            | 8720         |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    std                  | 0.422        |\n",
      "|    value_loss           | 5.61e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | -4.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 2908        |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009185664 |\n",
      "|    clip_fraction        | 0.0971      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.9        |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    std                  | 0.42        |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1790000, episode_reward=-22245.28 +/- 78739.51\n",
      "Episode length: 1867.40 +/- 879.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.87e+03    |\n",
      "|    mean_reward          | -2.22e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010865968 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.3        |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    std                  | 0.42        |\n",
      "|    value_loss           | 459         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -4.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 875       |\n",
      "|    time_elapsed    | 2914      |\n",
      "|    total_timesteps | 1792000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -3.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 615         |\n",
      "|    iterations           | 876         |\n",
      "|    time_elapsed         | 2916        |\n",
      "|    total_timesteps      | 1794048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006553001 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.34e+03    |\n",
      "|    n_updates            | 8750        |\n",
      "|    policy_gradient_loss | 0.00319     |\n",
      "|    std                  | 0.421       |\n",
      "|    value_loss           | 6.09e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1795000, episode_reward=21002.37 +/- 3026.61\n",
      "Episode length: 2474.40 +/- 9.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.47e+03    |\n",
      "|    mean_reward          | 2.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1795000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012215163 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.8        |\n",
      "|    n_updates            | 8760        |\n",
      "|    policy_gradient_loss | 0.0003      |\n",
      "|    std                  | 0.421       |\n",
      "|    value_loss           | 285         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -3.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 614       |\n",
      "|    iterations      | 877       |\n",
      "|    time_elapsed    | 2923      |\n",
      "|    total_timesteps | 1796096   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | -3.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 614         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 2925        |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006626852 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.261       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.52e+06    |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    std                  | 0.421       |\n",
      "|    value_loss           | 2.81e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=19656.74 +/- 4534.51\n",
      "Episode length: 2476.20 +/- 5.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.48e+03    |\n",
      "|    mean_reward          | 1.97e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007974805 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.3        |\n",
      "|    n_updates            | 8780        |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    std                  | 0.421       |\n",
      "|    value_loss           | 479         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -3.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 879       |\n",
      "|    time_elapsed    | 2933      |\n",
      "|    total_timesteps | 1800192   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -3.97e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 614          |\n",
      "|    iterations           | 880          |\n",
      "|    time_elapsed         | 2935         |\n",
      "|    total_timesteps      | 1802240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0128692575 |\n",
      "|    clip_fraction        | 0.0697       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 57.5         |\n",
      "|    n_updates            | 8790         |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 0.42         |\n",
      "|    value_loss           | 209          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | -4.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 614          |\n",
      "|    iterations           | 881          |\n",
      "|    time_elapsed         | 2937         |\n",
      "|    total_timesteps      | 1804288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067609907 |\n",
      "|    clip_fraction        | 0.0937       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 64.4         |\n",
      "|    n_updates            | 8800         |\n",
      "|    policy_gradient_loss | -2.53e-05    |\n",
      "|    std                  | 0.42         |\n",
      "|    value_loss           | 7.35e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1805000, episode_reward=-19838.54 +/- 81221.53\n",
      "Episode length: 2077.60 +/- 982.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.08e+03    |\n",
      "|    mean_reward          | -1.98e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1805000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007953931 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55e+07    |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -8.62e-05   |\n",
      "|    std                  | 0.42        |\n",
      "|    value_loss           | 2.18e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -3.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 613       |\n",
      "|    iterations      | 882       |\n",
      "|    time_elapsed    | 2943      |\n",
      "|    total_timesteps | 1806336   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -3.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 613         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 2945        |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012540523 |\n",
      "|    clip_fraction        | 0.0629      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+03    |\n",
      "|    n_updates            | 8820        |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    std                  | 0.419       |\n",
      "|    value_loss           | 1.9e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1810000, episode_reward=23608.39 +/- 2910.25\n",
      "Episode length: 2680.00 +/- 11.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.68e+03     |\n",
      "|    mean_reward          | 2.36e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1810000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073131192 |\n",
      "|    clip_fraction        | 0.0979       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1           |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 70.4         |\n",
      "|    n_updates            | 8830         |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    std                  | 0.42         |\n",
      "|    value_loss           | 309          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.55e+03  |\n",
      "|    ep_rew_mean     | -3.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 884       |\n",
      "|    time_elapsed    | 2953      |\n",
      "|    total_timesteps | 1810432   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | -4.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 885          |\n",
      "|    time_elapsed         | 2955         |\n",
      "|    total_timesteps      | 1812480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086446665 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.991       |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 104          |\n",
      "|    n_updates            | 8840         |\n",
      "|    policy_gradient_loss | -0.012       |\n",
      "|    std                  | 0.419        |\n",
      "|    value_loss           | 342          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | -3.83e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 613          |\n",
      "|    iterations           | 886          |\n",
      "|    time_elapsed         | 2957         |\n",
      "|    total_timesteps      | 1814528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036597704 |\n",
      "|    clip_fraction        | 0.0807       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.984       |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11e+07     |\n",
      "|    n_updates            | 8850         |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    std                  | 0.418        |\n",
      "|    value_loss           | 3.05e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1815000, episode_reward=-13114.17 +/- 82011.50\n",
      "Episode length: 2620.80 +/- 1256.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.62e+03    |\n",
      "|    mean_reward          | -1.31e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1815000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005867607 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.975      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.7        |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    std                  | 0.416       |\n",
      "|    value_loss           | 609         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -4.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 887       |\n",
      "|    time_elapsed    | 2965      |\n",
      "|    total_timesteps | 1816576   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | -4.15e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 888          |\n",
      "|    time_elapsed         | 2967         |\n",
      "|    total_timesteps      | 1818624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026454981 |\n",
      "|    clip_fraction        | 0.0317       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.966       |\n",
      "|    explained_variance   | 0.221        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.52e+07     |\n",
      "|    n_updates            | 8870         |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    std                  | 0.417        |\n",
      "|    value_loss           | 3.39e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1820000, episode_reward=-145459.58 +/- 14006.40\n",
      "Episode length: 1709.60 +/- 801.46\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.71e+03     |\n",
      "|    mean_reward          | -1.45e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1820000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004741151 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.968       |\n",
      "|    explained_variance   | 0.257        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.63e+06     |\n",
      "|    n_updates            | 8880         |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    std                  | 0.417        |\n",
      "|    value_loss           | 2.36e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.55e+03  |\n",
      "|    ep_rew_mean     | -4.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 889       |\n",
      "|    time_elapsed    | 2973      |\n",
      "|    total_timesteps | 1820672   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -4.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 890         |\n",
      "|    time_elapsed         | 2975        |\n",
      "|    total_timesteps      | 1822720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002546125 |\n",
      "|    clip_fraction        | 0.0107      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.968      |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.91e+07    |\n",
      "|    n_updates            | 8890        |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.417       |\n",
      "|    value_loss           | 3.66e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | -4.55e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 612          |\n",
      "|    iterations           | 891          |\n",
      "|    time_elapsed         | 2976         |\n",
      "|    total_timesteps      | 1824768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040648673 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.968       |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+03     |\n",
      "|    n_updates            | 8900         |\n",
      "|    policy_gradient_loss | -0.000713    |\n",
      "|    std                  | 0.417        |\n",
      "|    value_loss           | 2.02e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1825000, episode_reward=-11729.59 +/- 75646.46\n",
      "Episode length: 2362.00 +/- 1130.55\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.36e+03     |\n",
      "|    mean_reward          | -1.17e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1825000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030108155 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.969       |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.51e+07     |\n",
      "|    n_updates            | 8910         |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    std                  | 0.417        |\n",
      "|    value_loss           | 4.02e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -4.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 612       |\n",
      "|    iterations      | 892       |\n",
      "|    time_elapsed    | 2984      |\n",
      "|    total_timesteps | 1826816   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -4.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 612         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 2986        |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006855925 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.968      |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.77e+05    |\n",
      "|    n_updates            | 8920        |\n",
      "|    policy_gradient_loss | 0.000424    |\n",
      "|    std                  | 0.415       |\n",
      "|    value_loss           | 2.08e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1830000, episode_reward=23766.52 +/- 4321.99\n",
      "Episode length: 2760.80 +/- 9.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.76e+03     |\n",
      "|    mean_reward          | 2.38e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1830000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053654136 |\n",
      "|    clip_fraction        | 0.0785       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.963       |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.91e+06     |\n",
      "|    n_updates            | 8930         |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    std                  | 0.415        |\n",
      "|    value_loss           | 1.46e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -4.71e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 611       |\n",
      "|    iterations      | 894       |\n",
      "|    time_elapsed    | 2994      |\n",
      "|    total_timesteps | 1830912   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.57e+03     |\n",
      "|    ep_rew_mean          | -4.73e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 611          |\n",
      "|    iterations           | 895          |\n",
      "|    time_elapsed         | 2996         |\n",
      "|    total_timesteps      | 1832960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014313936 |\n",
      "|    clip_fraction        | 0.0127       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.964       |\n",
      "|    explained_variance   | 0.251        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.65e+06     |\n",
      "|    n_updates            | 8940         |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    std                  | 0.415        |\n",
      "|    value_loss           | 3.15e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1835000, episode_reward=26585.78 +/- 3502.47\n",
      "Episode length: 3123.80 +/- 18.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.12e+03     |\n",
      "|    mean_reward          | 2.66e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1835000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075837215 |\n",
      "|    clip_fraction        | 0.0616       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.963       |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 244          |\n",
      "|    n_updates            | 8950         |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    std                  | 0.415        |\n",
      "|    value_loss           | 1.96e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.59e+03  |\n",
      "|    ep_rew_mean     | -4.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 896       |\n",
      "|    time_elapsed    | 3005      |\n",
      "|    total_timesteps | 1835008   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | -4.49e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 3007        |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006958742 |\n",
      "|    clip_fraction        | 0.0609      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.961      |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 389         |\n",
      "|    n_updates            | 8960        |\n",
      "|    policy_gradient_loss | -0.000773   |\n",
      "|    std                  | 0.415       |\n",
      "|    value_loss           | 8.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -4.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 611         |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 3009        |\n",
      "|    total_timesteps      | 1839104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008567868 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.952      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | 0.000233    |\n",
      "|    std                  | 0.413       |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=-141627.72 +/- 23673.71\n",
      "Episode length: 906.20 +/- 993.93\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 906        |\n",
      "|    mean_reward          | -1.42e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1840000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00517631 |\n",
      "|    clip_fraction        | 0.0663     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.941     |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 94.8       |\n",
      "|    n_updates            | 8980       |\n",
      "|    policy_gradient_loss | 0.00331    |\n",
      "|    std                  | 0.413      |\n",
      "|    value_loss           | 1.28e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.62e+03 |\n",
      "|    ep_rew_mean     | -4.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 611      |\n",
      "|    iterations      | 899      |\n",
      "|    time_elapsed    | 3013     |\n",
      "|    total_timesteps | 1841152  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | -4.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 611          |\n",
      "|    iterations           | 900          |\n",
      "|    time_elapsed         | 3014         |\n",
      "|    total_timesteps      | 1843200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061060684 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.936       |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.23e+06     |\n",
      "|    n_updates            | 8990         |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.413        |\n",
      "|    value_loss           | 1.15e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1845000, episode_reward=23598.96 +/- 3098.70\n",
      "Episode length: 2791.80 +/- 5.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.79e+03     |\n",
      "|    mean_reward          | 2.36e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1845000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055649234 |\n",
      "|    clip_fraction        | 0.0447       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.935       |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 186          |\n",
      "|    n_updates            | 9000         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    std                  | 0.412        |\n",
      "|    value_loss           | 7.46e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -4.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 901       |\n",
      "|    time_elapsed    | 3023      |\n",
      "|    total_timesteps | 1845248   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.65e+03     |\n",
      "|    ep_rew_mean          | -4.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 610          |\n",
      "|    iterations           | 902          |\n",
      "|    time_elapsed         | 3025         |\n",
      "|    total_timesteps      | 1847296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031879323 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.933       |\n",
      "|    explained_variance   | 0.268        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 517          |\n",
      "|    n_updates            | 9010         |\n",
      "|    policy_gradient_loss | -0.00696     |\n",
      "|    std                  | 0.412        |\n",
      "|    value_loss           | 2.65e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -3.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 903         |\n",
      "|    time_elapsed         | 3026        |\n",
      "|    total_timesteps      | 1849344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007942043 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | 0.299       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+05    |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    std                  | 0.412       |\n",
      "|    value_loss           | 1.74e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1850000, episode_reward=22170.56 +/- 4696.64\n",
      "Episode length: 2532.80 +/- 11.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.53e+03     |\n",
      "|    mean_reward          | 2.22e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1850000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069230422 |\n",
      "|    clip_fraction        | 0.0361       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.935       |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 9030         |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    std                  | 0.412        |\n",
      "|    value_loss           | 1.33e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -3.71e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 610       |\n",
      "|    iterations      | 904       |\n",
      "|    time_elapsed    | 3034      |\n",
      "|    total_timesteps | 1851392   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.68e+03   |\n",
      "|    ep_rew_mean          | -3.71e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 610        |\n",
      "|    iterations           | 905        |\n",
      "|    time_elapsed         | 3036       |\n",
      "|    total_timesteps      | 1853440    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04114324 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.934     |\n",
      "|    explained_variance   | 0.272      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.42e+06   |\n",
      "|    n_updates            | 9040       |\n",
      "|    policy_gradient_loss | -0.00439   |\n",
      "|    std                  | 0.412      |\n",
      "|    value_loss           | 2.44e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1855000, episode_reward=21281.42 +/- 3887.69\n",
      "Episode length: 2169.20 +/- 11.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.17e+03     |\n",
      "|    mean_reward          | 2.13e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1855000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0080919005 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.928       |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 392          |\n",
      "|    n_updates            | 9050         |\n",
      "|    policy_gradient_loss | -0.000946    |\n",
      "|    std                  | 0.413        |\n",
      "|    value_loss           | 352          |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -3.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 609       |\n",
      "|    iterations      | 906       |\n",
      "|    time_elapsed    | 3043      |\n",
      "|    total_timesteps | 1855488   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -3.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 609         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 3045        |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015981197 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.915      |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+07    |\n",
      "|    n_updates            | 9060        |\n",
      "|    policy_gradient_loss | 0.00689     |\n",
      "|    std                  | 0.411       |\n",
      "|    value_loss           | 2.7e+07     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -3.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 610         |\n",
      "|    iterations           | 908         |\n",
      "|    time_elapsed         | 3047        |\n",
      "|    total_timesteps      | 1859584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012932969 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.912      |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | 0.00519     |\n",
      "|    std                  | 0.412       |\n",
      "|    value_loss           | 1.4e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1860000, episode_reward=-11918.24 +/- 61302.26\n",
      "Episode length: 1957.40 +/- 941.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.96e+03    |\n",
      "|    mean_reward          | -1.19e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016471762 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.904      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 9080        |\n",
      "|    policy_gradient_loss | 0.00369     |\n",
      "|    std                  | 0.409       |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -3.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 609       |\n",
      "|    iterations      | 909       |\n",
      "|    time_elapsed    | 3053      |\n",
      "|    total_timesteps | 1861632   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.72e+03   |\n",
      "|    ep_rew_mean          | -3.25e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 609        |\n",
      "|    iterations           | 910        |\n",
      "|    time_elapsed         | 3055       |\n",
      "|    total_timesteps      | 1863680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02134601 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.885     |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 27         |\n",
      "|    n_updates            | 9090       |\n",
      "|    policy_gradient_loss | 0.00345    |\n",
      "|    std                  | 0.408      |\n",
      "|    value_loss           | 151        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1865000, episode_reward=-11042.75 +/- 62565.64\n",
      "Episode length: 2217.20 +/- 1071.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.22e+03    |\n",
      "|    mean_reward          | -1.1e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1865000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004684155 |\n",
      "|    clip_fraction        | 0.0825      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.407       |\n",
      "|    value_loss           | 931         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -3.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 609       |\n",
      "|    iterations      | 911       |\n",
      "|    time_elapsed    | 3062      |\n",
      "|    total_timesteps | 1865728   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -3.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 609         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 3064        |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006140914 |\n",
      "|    clip_fraction        | 0.0519      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.872      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.8        |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    std                  | 0.407       |\n",
      "|    value_loss           | 591         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | -3.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 609         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 3065        |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008201101 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.867      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.00476    |\n",
      "|    std                  | 0.406       |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1870000, episode_reward=-10521.34 +/- 62834.05\n",
      "Episode length: 1930.60 +/- 923.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.93e+03     |\n",
      "|    mean_reward          | -1.05e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1870000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065844674 |\n",
      "|    clip_fraction        | 0.0898       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.859       |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 38.1         |\n",
      "|    n_updates            | 9130         |\n",
      "|    policy_gradient_loss | -0.00161     |\n",
      "|    std                  | 0.406        |\n",
      "|    value_loss           | 593          |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 609       |\n",
      "|    iterations      | 914       |\n",
      "|    time_elapsed    | 3072      |\n",
      "|    total_timesteps | 1871872   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.75e+03     |\n",
      "|    ep_rew_mean          | -3.03e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 609          |\n",
      "|    iterations           | 915          |\n",
      "|    time_elapsed         | 3074         |\n",
      "|    total_timesteps      | 1873920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059604626 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.858       |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.3         |\n",
      "|    n_updates            | 9140         |\n",
      "|    policy_gradient_loss | 0.00151      |\n",
      "|    std                  | 0.407        |\n",
      "|    value_loss           | 7.31e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1875000, episode_reward=-11711.74 +/- 60378.28\n",
      "Episode length: 1937.60 +/- 932.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.94e+03    |\n",
      "|    mean_reward          | -1.17e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1875000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005692873 |\n",
      "|    clip_fraction        | 0.0638      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.858      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 171         |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.00108    |\n",
      "|    std                  | 0.407       |\n",
      "|    value_loss           | 2.38e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -3.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 608       |\n",
      "|    iterations      | 916       |\n",
      "|    time_elapsed    | 3080      |\n",
      "|    total_timesteps | 1875968   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.74e+03  |\n",
      "|    ep_rew_mean          | -3.29e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 609       |\n",
      "|    iterations           | 917       |\n",
      "|    time_elapsed         | 3082      |\n",
      "|    total_timesteps      | 1878016   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0420543 |\n",
      "|    clip_fraction        | 0.136     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.861    |\n",
      "|    explained_variance   | 0.988     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.48e+04  |\n",
      "|    n_updates            | 9160      |\n",
      "|    policy_gradient_loss | 0.00065   |\n",
      "|    std                  | 0.407     |\n",
      "|    value_loss           | 6.34e+03  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1880000, episode_reward=-13497.36 +/- 60555.05\n",
      "Episode length: 2026.80 +/- 975.92\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.03e+03     |\n",
      "|    mean_reward          | -1.35e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027593877 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.863       |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79e+07     |\n",
      "|    n_updates            | 9170         |\n",
      "|    policy_gradient_loss | -0.000509    |\n",
      "|    std                  | 0.407        |\n",
      "|    value_loss           | 3.68e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.74e+03  |\n",
      "|    ep_rew_mean     | -3.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 608       |\n",
      "|    iterations      | 918       |\n",
      "|    time_elapsed    | 3088      |\n",
      "|    total_timesteps | 1880064   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.72e+03     |\n",
      "|    ep_rew_mean          | -3.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 608          |\n",
      "|    iterations           | 919          |\n",
      "|    time_elapsed         | 3090         |\n",
      "|    total_timesteps      | 1882112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056034485 |\n",
      "|    clip_fraction        | 0.0298       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.863       |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 938          |\n",
      "|    n_updates            | 9180         |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    std                  | 0.407        |\n",
      "|    value_loss           | 4.02e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.72e+03     |\n",
      "|    ep_rew_mean          | -3.09e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 609          |\n",
      "|    iterations           | 920          |\n",
      "|    time_elapsed         | 3092         |\n",
      "|    total_timesteps      | 1884160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047525344 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.866       |\n",
      "|    explained_variance   | 0.25         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3e+07        |\n",
      "|    n_updates            | 9190         |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    std                  | 0.408        |\n",
      "|    value_loss           | 4.5e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1885000, episode_reward=19721.99 +/- 898.33\n",
      "Episode length: 2463.20 +/- 11.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.46e+03     |\n",
      "|    mean_reward          | 1.97e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1885000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079870485 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.861       |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 48.7         |\n",
      "|    n_updates            | 9200         |\n",
      "|    policy_gradient_loss | -0.00514     |\n",
      "|    std                  | 0.406        |\n",
      "|    value_loss           | 1.22e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -3.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 608       |\n",
      "|    iterations      | 921       |\n",
      "|    time_elapsed    | 3100      |\n",
      "|    total_timesteps | 1886208   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | -2.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 608         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 3102        |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009129005 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.825      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.3        |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | 0.00261     |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1890000, episode_reward=20193.13 +/- 189.17\n",
      "Episode length: 2294.20 +/- 9.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.29e+03    |\n",
      "|    mean_reward          | 2.02e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004908615 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.807      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.78e+06    |\n",
      "|    n_updates            | 9220        |\n",
      "|    policy_gradient_loss | 0.000188    |\n",
      "|    std                  | 0.403       |\n",
      "|    value_loss           | 2.21e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.76e+03  |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 607       |\n",
      "|    iterations      | 923       |\n",
      "|    time_elapsed    | 3109      |\n",
      "|    total_timesteps | 1890304   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.78e+03   |\n",
      "|    ep_rew_mean          | -2.41e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 608        |\n",
      "|    iterations           | 924        |\n",
      "|    time_elapsed         | 3111       |\n",
      "|    total_timesteps      | 1892352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00955626 |\n",
      "|    clip_fraction        | 0.0571     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.812     |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 61.9       |\n",
      "|    n_updates            | 9230       |\n",
      "|    policy_gradient_loss | -0.00173   |\n",
      "|    std                  | 0.403      |\n",
      "|    value_loss           | 541        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -2.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 608         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 3112        |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011198035 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.8        |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    std                  | 0.403       |\n",
      "|    value_loss           | 552         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1895000, episode_reward=22402.84 +/- 3127.02\n",
      "Episode length: 2737.20 +/- 10.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.74e+03     |\n",
      "|    mean_reward          | 2.24e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1895000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014744385 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.807       |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.37e+07     |\n",
      "|    n_updates            | 9250         |\n",
      "|    policy_gradient_loss | 0.000328     |\n",
      "|    std                  | 0.403        |\n",
      "|    value_loss           | 4.3e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -2.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 607       |\n",
      "|    iterations      | 926       |\n",
      "|    time_elapsed    | 3121      |\n",
      "|    total_timesteps | 1896448   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -2.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 927         |\n",
      "|    time_elapsed         | 3122        |\n",
      "|    total_timesteps      | 1898496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007267872 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.806      |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.82e+03    |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 1.31e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1900000, episode_reward=17622.19 +/- 3369.05\n",
      "Episode length: 2452.60 +/- 8.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.45e+03    |\n",
      "|    mean_reward          | 1.76e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011174807 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.805      |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 9270        |\n",
      "|    policy_gradient_loss | -0.0013     |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 773         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.8e+03   |\n",
      "|    ep_rew_mean     | -2.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 607       |\n",
      "|    iterations      | 928       |\n",
      "|    time_elapsed    | 3130      |\n",
      "|    total_timesteps | 1900544   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.8e+03     |\n",
      "|    ep_rew_mean          | -2.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 3132        |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009434158 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.801      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.7        |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | 0.00115     |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | -2.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 607         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 3134        |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011717716 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 330         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1905000, episode_reward=19027.86 +/- 3554.08\n",
      "Episode length: 2730.60 +/- 9.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.73e+03    |\n",
      "|    mean_reward          | 1.9e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1905000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007755743 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.792      |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.61e+04    |\n",
      "|    n_updates            | 9300        |\n",
      "|    policy_gradient_loss | 0.00038     |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 8.26e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.81e+03  |\n",
      "|    ep_rew_mean     | -2.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 606       |\n",
      "|    iterations      | 931       |\n",
      "|    time_elapsed    | 3142      |\n",
      "|    total_timesteps | 1906688   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.81e+03     |\n",
      "|    ep_rew_mean          | -2.58e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 607          |\n",
      "|    iterations           | 932          |\n",
      "|    time_elapsed         | 3144         |\n",
      "|    total_timesteps      | 1908736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074175256 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.788       |\n",
      "|    explained_variance   | 0.243        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.87e+06     |\n",
      "|    n_updates            | 9310         |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    std                  | 0.403        |\n",
      "|    value_loss           | 2.17e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1910000, episode_reward=-10484.84 +/- 62884.22\n",
      "Episode length: 2098.20 +/- 1010.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.1e+03     |\n",
      "|    mean_reward          | -1.05e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008839138 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.783      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.9        |\n",
      "|    n_updates            | 9320        |\n",
      "|    policy_gradient_loss | -0.00102    |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 349         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.82e+03  |\n",
      "|    ep_rew_mean     | -2.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 606       |\n",
      "|    iterations      | 933       |\n",
      "|    time_elapsed    | 3150      |\n",
      "|    total_timesteps | 1910784   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.83e+03   |\n",
      "|    ep_rew_mean          | -2.57e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 606        |\n",
      "|    iterations           | 934        |\n",
      "|    time_elapsed         | 3152       |\n",
      "|    total_timesteps      | 1912832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02285282 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.774     |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.6e+04    |\n",
      "|    n_updates            | 9330       |\n",
      "|    policy_gradient_loss | 0.00291    |\n",
      "|    std                  | 0.403      |\n",
      "|    value_loss           | 5.6e+03    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.84e+03     |\n",
      "|    ep_rew_mean          | -2.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 607          |\n",
      "|    iterations           | 935          |\n",
      "|    time_elapsed         | 3154         |\n",
      "|    total_timesteps      | 1914880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0098356595 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.773       |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.19e+04     |\n",
      "|    n_updates            | 9340         |\n",
      "|    policy_gradient_loss | -0.000634    |\n",
      "|    std                  | 0.403        |\n",
      "|    value_loss           | 1.25e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1915000, episode_reward=8167.89 +/- 4644.47\n",
      "Episode length: 3195.20 +/- 8.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.2e+03     |\n",
      "|    mean_reward          | 8.17e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1915000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013713102 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.763      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 9350        |\n",
      "|    policy_gradient_loss | 0.000266    |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 334         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.85e+03 |\n",
      "|    ep_rew_mean     | -2.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 605      |\n",
      "|    iterations      | 936      |\n",
      "|    time_elapsed    | 3164     |\n",
      "|    total_timesteps | 1916928  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.86e+03    |\n",
      "|    ep_rew_mean          | -2.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 606         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 3165        |\n",
      "|    total_timesteps      | 1918976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014409799 |\n",
      "|    clip_fraction        | 0.0571      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.751      |\n",
      "|    explained_variance   | 0.23        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.84e+06    |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    std                  | 0.401       |\n",
      "|    value_loss           | 2.23e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=21195.25 +/- 3116.08\n",
      "Episode length: 2593.00 +/- 10.77\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.59e+03   |\n",
      "|    mean_reward          | 2.12e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1920000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02532861 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.75      |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 47.2       |\n",
      "|    n_updates            | 9370       |\n",
      "|    policy_gradient_loss | 0.00542    |\n",
      "|    std                  | 0.401      |\n",
      "|    value_loss           | 974        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.86e+03 |\n",
      "|    ep_rew_mean     | -2.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 605      |\n",
      "|    iterations      | 938      |\n",
      "|    time_elapsed    | 3173     |\n",
      "|    total_timesteps | 1921024  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.84e+03    |\n",
      "|    ep_rew_mean          | -2.65e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 605         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 3175        |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020762082 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.746      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -2.59e-05   |\n",
      "|    std                  | 0.4         |\n",
      "|    value_loss           | 234         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1925000, episode_reward=18594.04 +/- 3401.47\n",
      "Episode length: 2283.80 +/- 5.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.28e+03     |\n",
      "|    mean_reward          | 1.86e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1925000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036955257 |\n",
      "|    clip_fraction        | 0.0548       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.739       |\n",
      "|    explained_variance   | 0.282        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17e+07     |\n",
      "|    n_updates            | 9390         |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 2.09e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.85e+03  |\n",
      "|    ep_rew_mean     | -2.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 604       |\n",
      "|    iterations      | 940       |\n",
      "|    time_elapsed    | 3182      |\n",
      "|    total_timesteps | 1925120   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -2.49e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 605         |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 3184        |\n",
      "|    total_timesteps      | 1927168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022194525 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.741      |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 9400        |\n",
      "|    policy_gradient_loss | 0.00815     |\n",
      "|    std                  | 0.4         |\n",
      "|    value_loss           | 6.41e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -2.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 605         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 3186        |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030333271 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.738      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.4        |\n",
      "|    n_updates            | 9410        |\n",
      "|    policy_gradient_loss | 0.00206     |\n",
      "|    std                  | 0.399       |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1930000, episode_reward=19913.10 +/- 3917.90\n",
      "Episode length: 2381.60 +/- 7.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.38e+03    |\n",
      "|    mean_reward          | 1.99e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012075017 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.733      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 9420        |\n",
      "|    policy_gradient_loss | 0.00234     |\n",
      "|    std                  | 0.398       |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.86e+03  |\n",
      "|    ep_rew_mean     | -2.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 604       |\n",
      "|    iterations      | 943       |\n",
      "|    time_elapsed    | 3194      |\n",
      "|    total_timesteps | 1931264   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.86e+03     |\n",
      "|    ep_rew_mean          | -2.45e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 604          |\n",
      "|    iterations           | 944          |\n",
      "|    time_elapsed         | 3195         |\n",
      "|    total_timesteps      | 1933312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075048897 |\n",
      "|    clip_fraction        | 0.0833       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.717       |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 260          |\n",
      "|    n_updates            | 9430         |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    std                  | 0.397        |\n",
      "|    value_loss           | 6.33e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1935000, episode_reward=-9608.64 +/- 62530.19\n",
      "Episode length: 1935.00 +/- 931.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.94e+03    |\n",
      "|    mean_reward          | -9.61e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1935000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014264027 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.709      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 9440        |\n",
      "|    policy_gradient_loss | 0.00415     |\n",
      "|    std                  | 0.396       |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.86e+03  |\n",
      "|    ep_rew_mean     | -2.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 604       |\n",
      "|    iterations      | 945       |\n",
      "|    time_elapsed    | 3202      |\n",
      "|    total_timesteps | 1935360   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.86e+03    |\n",
      "|    ep_rew_mean          | -2.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 3204        |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012610674 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.699      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.7        |\n",
      "|    n_updates            | 9450        |\n",
      "|    policy_gradient_loss | -8.59e-05   |\n",
      "|    std                  | 0.395       |\n",
      "|    value_loss           | 599         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.88e+03     |\n",
      "|    ep_rew_mean          | -2.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 604          |\n",
      "|    iterations           | 947          |\n",
      "|    time_elapsed         | 3205         |\n",
      "|    total_timesteps      | 1939456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043724133 |\n",
      "|    clip_fraction        | 0.0826       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.693       |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 146          |\n",
      "|    n_updates            | 9460         |\n",
      "|    policy_gradient_loss | -0.00046     |\n",
      "|    std                  | 0.395        |\n",
      "|    value_loss           | 1.27e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1940000, episode_reward=-16856.76 +/- 60443.52\n",
      "Episode length: 2018.20 +/- 971.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | -1.69e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007834979 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.697      |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 393         |\n",
      "|    n_updates            | 9470        |\n",
      "|    policy_gradient_loss | 0.000409    |\n",
      "|    std                  | 0.396       |\n",
      "|    value_loss           | 866         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -2.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 604       |\n",
      "|    iterations      | 948       |\n",
      "|    time_elapsed    | 3212      |\n",
      "|    total_timesteps | 1941504   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.88e+03    |\n",
      "|    ep_rew_mean          | -2.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 3214        |\n",
      "|    total_timesteps      | 1943552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052421123 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.704      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | 0.00775     |\n",
      "|    std                  | 0.397       |\n",
      "|    value_loss           | 399         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1945000, episode_reward=7738.99 +/- 18691.51\n",
      "Episode length: 2120.80 +/- 31.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.12e+03    |\n",
      "|    mean_reward          | 7.74e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1945000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020667128 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.717      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | 0.00893     |\n",
      "|    std                  | 0.4         |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.87e+03  |\n",
      "|    ep_rew_mean     | -2.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 950       |\n",
      "|    time_elapsed    | 3221      |\n",
      "|    total_timesteps | 1945600   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.87e+03     |\n",
      "|    ep_rew_mean          | -2.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 604          |\n",
      "|    iterations           | 951          |\n",
      "|    time_elapsed         | 3223         |\n",
      "|    total_timesteps      | 1947648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064592985 |\n",
      "|    clip_fraction        | 0.124        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.732       |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.76e+04     |\n",
      "|    n_updates            | 9500         |\n",
      "|    policy_gradient_loss | -0.00535     |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 4.7e+06      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.88e+03     |\n",
      "|    ep_rew_mean          | -2.13e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 604          |\n",
      "|    iterations           | 952          |\n",
      "|    time_elapsed         | 3224         |\n",
      "|    total_timesteps      | 1949696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069994368 |\n",
      "|    clip_fraction        | 0.0528       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.731       |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33e+05     |\n",
      "|    n_updates            | 9510         |\n",
      "|    policy_gradient_loss | -0.00539     |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 1.54e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1950000, episode_reward=-66436.03 +/- 31758.90\n",
      "Episode length: 1553.60 +/- 739.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.55e+03     |\n",
      "|    mean_reward          | -6.64e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1950000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037858998 |\n",
      "|    clip_fraction        | 0.0319       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.727       |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.94e+06     |\n",
      "|    n_updates            | 9520         |\n",
      "|    policy_gradient_loss | -0.000437    |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 6.05e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -2.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 604       |\n",
      "|    iterations      | 953       |\n",
      "|    time_elapsed    | 3230      |\n",
      "|    total_timesteps | 1951744   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.88e+03    |\n",
      "|    ep_rew_mean          | -2.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 3232        |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006812093 |\n",
      "|    clip_fraction        | 0.0594      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.728      |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    std                  | 0.4         |\n",
      "|    value_loss           | 1.33e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1955000, episode_reward=-14737.14 +/- 57583.76\n",
      "Episode length: 1911.00 +/- 918.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.91e+03     |\n",
      "|    mean_reward          | -1.47e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1955000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044690296 |\n",
      "|    clip_fraction        | 0.0454       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.728       |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 406          |\n",
      "|    n_updates            | 9540         |\n",
      "|    policy_gradient_loss | -0.005       |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 1.83e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -2.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 955       |\n",
      "|    time_elapsed    | 3238      |\n",
      "|    total_timesteps | 1955840   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.89e+03    |\n",
      "|    ep_rew_mean          | -2.19e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 604         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 3240        |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019140229 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.726      |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79.4        |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | 0.00101     |\n",
      "|    std                  | 0.4         |\n",
      "|    value_loss           | 8.1e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.89e+03   |\n",
      "|    ep_rew_mean          | -2.19e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 604        |\n",
      "|    iterations           | 957        |\n",
      "|    time_elapsed         | 3242       |\n",
      "|    total_timesteps      | 1959936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01148799 |\n",
      "|    clip_fraction        | 0.066      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.719     |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.04e+06   |\n",
      "|    n_updates            | 9560       |\n",
      "|    policy_gradient_loss | -0.00283   |\n",
      "|    std                  | 0.4        |\n",
      "|    value_loss           | 5.81e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1960000, episode_reward=-18949.77 +/- 55927.36\n",
      "Episode length: 1900.20 +/- 909.16\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.9e+03      |\n",
      "|    mean_reward          | -1.89e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028691706 |\n",
      "|    clip_fraction        | 0.019        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.719       |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 512          |\n",
      "|    n_updates            | 9570         |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 7.17e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -2.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 958       |\n",
      "|    time_elapsed    | 3248      |\n",
      "|    total_timesteps | 1961984   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.88e+03     |\n",
      "|    ep_rew_mean          | -2.36e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 604          |\n",
      "|    iterations           | 959          |\n",
      "|    time_elapsed         | 3250         |\n",
      "|    total_timesteps      | 1964032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011347327 |\n",
      "|    clip_fraction        | 0.00854      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.719       |\n",
      "|    explained_variance   | 0.265        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+06     |\n",
      "|    n_updates            | 9580         |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 2.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1965000, episode_reward=5546.65 +/- 4701.04\n",
      "Episode length: 2399.20 +/- 8.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.4e+03      |\n",
      "|    mean_reward          | 5.55e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1965000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059281588 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.718       |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.01e+03     |\n",
      "|    n_updates            | 9590         |\n",
      "|    policy_gradient_loss | -0.00668     |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 7.42e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -2.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 960       |\n",
      "|    time_elapsed    | 3257      |\n",
      "|    total_timesteps | 1966080   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.88e+03    |\n",
      "|    ep_rew_mean          | -2.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 3259        |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009409105 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.716      |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.51e+03    |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    std                  | 0.4         |\n",
      "|    value_loss           | 1.03e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1970000, episode_reward=-17406.23 +/- 60508.09\n",
      "Episode length: 1658.20 +/- 791.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.66e+03    |\n",
      "|    mean_reward          | -1.74e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002553762 |\n",
      "|    clip_fraction        | 0.0106      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.717      |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.05e+06    |\n",
      "|    n_updates            | 9610        |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    std                  | 0.4         |\n",
      "|    value_loss           | 1.86e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.86e+03  |\n",
      "|    ep_rew_mean     | -2.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 962       |\n",
      "|    time_elapsed    | 3265      |\n",
      "|    total_timesteps | 1970176   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.85e+03     |\n",
      "|    ep_rew_mean          | -2.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 603          |\n",
      "|    iterations           | 963          |\n",
      "|    time_elapsed         | 3267         |\n",
      "|    total_timesteps      | 1972224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031619389 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.714       |\n",
      "|    explained_variance   | 0.877        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.71e+03     |\n",
      "|    n_updates            | 9620         |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    std                  | 0.399        |\n",
      "|    value_loss           | 6.34e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.85e+03     |\n",
      "|    ep_rew_mean          | -2.52e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 603          |\n",
      "|    iterations           | 964          |\n",
      "|    time_elapsed         | 3268         |\n",
      "|    total_timesteps      | 1974272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062011583 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.706       |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 453          |\n",
      "|    n_updates            | 9630         |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    std                  | 0.399        |\n",
      "|    value_loss           | 1.16e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1975000, episode_reward=8314.27 +/- 4061.27\n",
      "Episode length: 2078.60 +/- 9.18\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.08e+03     |\n",
      "|    mean_reward          | 8.31e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1975000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042669484 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.7         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 280          |\n",
      "|    n_updates            | 9640         |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 6.66e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.81e+03  |\n",
      "|    ep_rew_mean     | -2.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 965       |\n",
      "|    time_elapsed    | 3275      |\n",
      "|    total_timesteps | 1976320   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.83e+03   |\n",
      "|    ep_rew_mean          | -2.5e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 603        |\n",
      "|    iterations           | 966        |\n",
      "|    time_elapsed         | 3277       |\n",
      "|    total_timesteps      | 1978368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00261279 |\n",
      "|    clip_fraction        | 0.0248     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.697     |\n",
      "|    explained_variance   | 0.277      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.51e+07   |\n",
      "|    n_updates            | 9650       |\n",
      "|    policy_gradient_loss | -0.00163   |\n",
      "|    std                  | 0.399      |\n",
      "|    value_loss           | 2.1e+07    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1980000, episode_reward=-15179.35 +/- 59855.39\n",
      "Episode length: 1533.80 +/- 728.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.53e+03    |\n",
      "|    mean_reward          | -1.52e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015226839 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.692      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 298         |\n",
      "|    n_updates            | 9660        |\n",
      "|    policy_gradient_loss | 0.00934     |\n",
      "|    std                  | 0.399       |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.82e+03  |\n",
      "|    ep_rew_mean     | -2.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 967       |\n",
      "|    time_elapsed    | 3283      |\n",
      "|    total_timesteps | 1980416   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | -2.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 3284        |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008145256 |\n",
      "|    clip_fraction        | 0.0664      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 213         |\n",
      "|    n_updates            | 9670        |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    std                  | 0.398       |\n",
      "|    value_loss           | 633         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.8e+03      |\n",
      "|    ep_rew_mean          | -2.39e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 603          |\n",
      "|    iterations           | 969          |\n",
      "|    time_elapsed         | 3286         |\n",
      "|    total_timesteps      | 1984512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057392633 |\n",
      "|    clip_fraction        | 0.0945       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.673       |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 129          |\n",
      "|    n_updates            | 9680         |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    std                  | 0.397        |\n",
      "|    value_loss           | 456          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1985000, episode_reward=-14523.78 +/- 60518.78\n",
      "Episode length: 1343.80 +/- 632.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.34e+03    |\n",
      "|    mean_reward          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1985000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004931993 |\n",
      "|    clip_fraction        | 0.0957      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.663      |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.3        |\n",
      "|    n_updates            | 9690        |\n",
      "|    policy_gradient_loss | 0.00039     |\n",
      "|    std                  | 0.396       |\n",
      "|    value_loss           | 1.3e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.78e+03  |\n",
      "|    ep_rew_mean     | -2.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 970       |\n",
      "|    time_elapsed    | 3291      |\n",
      "|    total_timesteps | 1986560   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | -2.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 3293        |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010149352 |\n",
      "|    clip_fraction        | 0.0822      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.659      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    std                  | 0.396       |\n",
      "|    value_loss           | 6.56e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1990000, episode_reward=13960.74 +/- 3743.37\n",
      "Episode length: 1728.60 +/- 11.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.73e+03    |\n",
      "|    mean_reward          | 1.4e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1990000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010401723 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.658      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53          |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | 0.00335     |\n",
      "|    std                  | 0.399       |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.77e+03  |\n",
      "|    ep_rew_mean     | -2.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 972       |\n",
      "|    time_elapsed    | 3299      |\n",
      "|    total_timesteps | 1990656   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | -2.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 3301        |\n",
      "|    total_timesteps      | 1992704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010627349 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.66       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98          |\n",
      "|    n_updates            | 9720        |\n",
      "|    policy_gradient_loss | 0.000668    |\n",
      "|    std                  | 0.399       |\n",
      "|    value_loss           | 761         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | -1.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 3303        |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014111381 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.642      |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.8        |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.000787   |\n",
      "|    std                  | 0.398       |\n",
      "|    value_loss           | 2e+04       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1995000, episode_reward=17359.07 +/- 4396.06\n",
      "Episode length: 1598.80 +/- 8.26\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.6e+03    |\n",
      "|    mean_reward          | 1.74e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1995000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01597004 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.617     |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 77.3       |\n",
      "|    n_updates            | 9740       |\n",
      "|    policy_gradient_loss | -0.00159   |\n",
      "|    std                  | 0.398      |\n",
      "|    value_loss           | 212        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -1.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 975       |\n",
      "|    time_elapsed    | 3308      |\n",
      "|    total_timesteps | 1996800   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 3310        |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014797509 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.621      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.1        |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | 0.00424     |\n",
      "|    std                  | 0.4         |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2000000, episode_reward=21426.82 +/- 3327.93\n",
      "Episode length: 1642.60 +/- 9.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.64e+03     |\n",
      "|    mean_reward          | 2.14e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066875475 |\n",
      "|    clip_fraction        | 0.0775       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.626       |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+04     |\n",
      "|    n_updates            | 9760         |\n",
      "|    policy_gradient_loss | 0.000504     |\n",
      "|    std                  | 0.4          |\n",
      "|    value_loss           | 8.42e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.73e+03 |\n",
      "|    ep_rew_mean     | -1.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 603      |\n",
      "|    iterations      | 977      |\n",
      "|    time_elapsed    | 3316     |\n",
      "|    total_timesteps | 2000896  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.73e+03   |\n",
      "|    ep_rew_mean          | -1.38e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 603        |\n",
      "|    iterations           | 978        |\n",
      "|    time_elapsed         | 3318       |\n",
      "|    total_timesteps      | 2002944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08547214 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.628     |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14.7       |\n",
      "|    n_updates            | 9770       |\n",
      "|    policy_gradient_loss | 0.0126     |\n",
      "|    std                  | 0.401      |\n",
      "|    value_loss           | 599        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | -1.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 3320        |\n",
      "|    total_timesteps      | 2004992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007524608 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.618      |\n",
      "|    explained_variance   | 0.286       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.13e+06    |\n",
      "|    n_updates            | 9780        |\n",
      "|    policy_gradient_loss | -0.000379   |\n",
      "|    std                  | 0.401       |\n",
      "|    value_loss           | 1.38e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2005000, episode_reward=-71212.14 +/- 52416.21\n",
      "Episode length: 1522.40 +/- 1178.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.52e+03    |\n",
      "|    mean_reward          | -7.12e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2005000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009863969 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.619      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -2.39e-05   |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 354         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -1.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 603       |\n",
      "|    iterations      | 980       |\n",
      "|    time_elapsed    | 3325      |\n",
      "|    total_timesteps | 2007040   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -1.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 603         |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 3327        |\n",
      "|    total_timesteps      | 2009088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008350786 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.623      |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+07    |\n",
      "|    n_updates            | 9800        |\n",
      "|    policy_gradient_loss | 0.00328     |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 3.34e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2010000, episode_reward=-85966.24 +/- 25206.35\n",
      "Episode length: 1692.40 +/- 807.74\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.69e+03     |\n",
      "|    mean_reward          | -8.6e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2010000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011643609 |\n",
      "|    clip_fraction        | 9.77e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+07     |\n",
      "|    n_updates            | 9810         |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    std                  | 0.402        |\n",
      "|    value_loss           | 3.47e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.69e+03 |\n",
      "|    ep_rew_mean     | -1.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 603      |\n",
      "|    iterations      | 982      |\n",
      "|    time_elapsed    | 3333     |\n",
      "|    total_timesteps | 2011136  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.68e+03     |\n",
      "|    ep_rew_mean          | -1.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 603          |\n",
      "|    iterations           | 983          |\n",
      "|    time_elapsed         | 3334         |\n",
      "|    total_timesteps      | 2013184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018660825 |\n",
      "|    clip_fraction        | 0.00234      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.623       |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.46e+07     |\n",
      "|    n_updates            | 9820         |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    std                  | 0.402        |\n",
      "|    value_loss           | 5.39e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2015000, episode_reward=34209.88 +/- 2394.89\n",
      "Episode length: 2706.80 +/- 9.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.71e+03     |\n",
      "|    mean_reward          | 3.42e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2015000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023089864 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.308        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.64e+05     |\n",
      "|    n_updates            | 9830         |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    std                  | 0.402        |\n",
      "|    value_loss           | 2.34e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.7e+03  |\n",
      "|    ep_rew_mean     | -1.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 602      |\n",
      "|    iterations      | 984      |\n",
      "|    time_elapsed    | 3343     |\n",
      "|    total_timesteps | 2015232  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -1.78e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 603          |\n",
      "|    iterations           | 985          |\n",
      "|    time_elapsed         | 3344         |\n",
      "|    total_timesteps      | 2017280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022309534 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.625       |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.65e+07     |\n",
      "|    n_updates            | 9840         |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    std                  | 0.402        |\n",
      "|    value_loss           | 2.6e+07      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -1.77e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 603          |\n",
      "|    iterations           | 986          |\n",
      "|    time_elapsed         | 3346         |\n",
      "|    total_timesteps      | 2019328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022403058 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.625       |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.56e+03     |\n",
      "|    n_updates            | 9850         |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    std                  | 0.402        |\n",
      "|    value_loss           | 2.8e+04      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2020000, episode_reward=-46592.90 +/- 3211.58\n",
      "Episode length: 2280.00 +/- 10.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.28e+03     |\n",
      "|    mean_reward          | -4.66e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2020000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065057585 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 378          |\n",
      "|    n_updates            | 9860         |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    std                  | 0.402        |\n",
      "|    value_loss           | 1.1e+04      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 602       |\n",
      "|    iterations      | 987       |\n",
      "|    time_elapsed    | 3353      |\n",
      "|    total_timesteps | 2021376   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.71e+03     |\n",
      "|    ep_rew_mean          | -1.74e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 602          |\n",
      "|    iterations           | 988          |\n",
      "|    time_elapsed         | 3355         |\n",
      "|    total_timesteps      | 2023424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044786553 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.625       |\n",
      "|    explained_variance   | 0.426        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.74e+06     |\n",
      "|    n_updates            | 9870         |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    std                  | 0.402        |\n",
      "|    value_loss           | 6.55e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2025000, episode_reward=32173.34 +/- 4984.28\n",
      "Episode length: 2679.80 +/- 12.46\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.68e+03     |\n",
      "|    mean_reward          | 3.22e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2025000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020885356 |\n",
      "|    clip_fraction        | 0.00786      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.57e+06     |\n",
      "|    n_updates            | 9880         |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    std                  | 0.402        |\n",
      "|    value_loss           | 1.57e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 602       |\n",
      "|    iterations      | 989       |\n",
      "|    time_elapsed    | 3363      |\n",
      "|    total_timesteps | 2025472   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 3365        |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008767027 |\n",
      "|    clip_fraction        | 0.0515      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.626      |\n",
      "|    explained_variance   | 0.268       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+07     |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 2.07e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -1.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 602          |\n",
      "|    iterations           | 991          |\n",
      "|    time_elapsed         | 3367         |\n",
      "|    total_timesteps      | 2029568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036200443 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.626       |\n",
      "|    explained_variance   | 0.478        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.24e+06     |\n",
      "|    n_updates            | 9900         |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    std                  | 0.402        |\n",
      "|    value_loss           | 5.06e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2030000, episode_reward=24557.37 +/- 4120.81\n",
      "Episode length: 2331.80 +/- 12.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.33e+03     |\n",
      "|    mean_reward          | 2.46e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2030000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035865603 |\n",
      "|    clip_fraction        | 0.0101       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.624       |\n",
      "|    explained_variance   | 0.256        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.4e+07      |\n",
      "|    n_updates            | 9910         |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    std                  | 0.402        |\n",
      "|    value_loss           | 3.26e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.93e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 601       |\n",
      "|    iterations      | 992       |\n",
      "|    time_elapsed    | 3374      |\n",
      "|    total_timesteps | 2031616   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 993         |\n",
      "|    time_elapsed         | 3376        |\n",
      "|    total_timesteps      | 2033664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014513101 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.625      |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 682         |\n",
      "|    n_updates            | 9920        |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    std                  | 0.402       |\n",
      "|    value_loss           | 3.39e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2035000, episode_reward=-12135.33 +/- 67995.79\n",
      "Episode length: 1683.20 +/- 800.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.68e+03    |\n",
      "|    mean_reward          | -1.21e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2035000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011997392 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.611      |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.24e+04    |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    std                  | 0.399       |\n",
      "|    value_loss           | 7.09e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.93e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 601       |\n",
      "|    iterations      | 994       |\n",
      "|    time_elapsed    | 3382      |\n",
      "|    total_timesteps | 2035712   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 995         |\n",
      "|    time_elapsed         | 3384        |\n",
      "|    total_timesteps      | 2037760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011398285 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.583      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.8        |\n",
      "|    n_updates            | 9940        |\n",
      "|    policy_gradient_loss | 0.000786    |\n",
      "|    std                  | 0.398       |\n",
      "|    value_loss           | 707         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 3386        |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008302447 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.577      |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.7        |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.000851   |\n",
      "|    std                  | 0.4         |\n",
      "|    value_loss           | 6.95e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2040000, episode_reward=22630.09 +/- 3836.55\n",
      "Episode length: 1988.40 +/- 8.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.99e+03    |\n",
      "|    mean_reward          | 2.26e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008982083 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.567      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 9960        |\n",
      "|    policy_gradient_loss | -0.000736   |\n",
      "|    std                  | 0.398       |\n",
      "|    value_loss           | 448         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -1.91e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 601       |\n",
      "|    iterations      | 997       |\n",
      "|    time_elapsed    | 3392      |\n",
      "|    total_timesteps | 2041856   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -1.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 602         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 3394        |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012675224 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.558      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | 0.0011      |\n",
      "|    std                  | 0.398       |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2045000, episode_reward=17641.21 +/- 3615.23\n",
      "Episode length: 1919.60 +/- 7.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.92e+03    |\n",
      "|    mean_reward          | 1.76e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2045000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011343615 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.55       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.4        |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | 0.00337     |\n",
      "|    std                  | 0.397       |\n",
      "|    value_loss           | 384         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -1.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 601       |\n",
      "|    iterations      | 999       |\n",
      "|    time_elapsed    | 3400      |\n",
      "|    total_timesteps | 2045952   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -1.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 601         |\n",
      "|    iterations           | 1000        |\n",
      "|    time_elapsed         | 3402        |\n",
      "|    total_timesteps      | 2048000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015911086 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.517      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.8        |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | 0.00604     |\n",
      "|    std                  | 0.395       |\n",
      "|    value_loss           | 90.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2050000, episode_reward=26495.27 +/- 804.34\n",
      "Episode length: 2306.60 +/- 7.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.31e+03    |\n",
      "|    mean_reward          | 2.65e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014697781 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.488      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    std                  | 0.392       |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.67e+03  |\n",
      "|    ep_rew_mean     | -1.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 601       |\n",
      "|    iterations      | 1001      |\n",
      "|    time_elapsed    | 3410      |\n",
      "|    total_timesteps | 2050048   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 601         |\n",
      "|    iterations           | 1002        |\n",
      "|    time_elapsed         | 3411        |\n",
      "|    total_timesteps      | 2052096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007171678 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.476      |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.4        |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    std                  | 0.392       |\n",
      "|    value_loss           | 8.19e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 601         |\n",
      "|    iterations           | 1003        |\n",
      "|    time_elapsed         | 3413        |\n",
      "|    total_timesteps      | 2054144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011416184 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.47       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 10020       |\n",
      "|    policy_gradient_loss | -0.00645    |\n",
      "|    std                  | 0.39        |\n",
      "|    value_loss           | 6.14e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2055000, episode_reward=25452.43 +/- 4035.38\n",
      "Episode length: 2872.80 +/- 6.85\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.87e+03   |\n",
      "|    mean_reward          | 2.55e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2055000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00975195 |\n",
      "|    clip_fraction        | 0.0997     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.455     |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 37.2       |\n",
      "|    n_updates            | 10030      |\n",
      "|    policy_gradient_loss | -0.000701  |\n",
      "|    std                  | 0.389      |\n",
      "|    value_loss           | 192        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.71e+03  |\n",
      "|    ep_rew_mean     | -1.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 600       |\n",
      "|    iterations      | 1004      |\n",
      "|    time_elapsed    | 3422      |\n",
      "|    total_timesteps | 2056192   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 601         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 3424        |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007962425 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.449      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.1        |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    std                  | 0.389       |\n",
      "|    value_loss           | 244         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2060000, episode_reward=11391.32 +/- 136.15\n",
      "Episode length: 3115.40 +/- 6.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.12e+03    |\n",
      "|    mean_reward          | 1.14e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016379528 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.443      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    std                  | 0.388       |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -1.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 600       |\n",
      "|    iterations      | 1006      |\n",
      "|    time_elapsed    | 3433      |\n",
      "|    total_timesteps | 2060288   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -1.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 600         |\n",
      "|    iterations           | 1007        |\n",
      "|    time_elapsed         | 3435        |\n",
      "|    total_timesteps      | 2062336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009767329 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.441      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.7        |\n",
      "|    n_updates            | 10060       |\n",
      "|    policy_gradient_loss | 0.000314    |\n",
      "|    std                  | 0.388       |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 600         |\n",
      "|    iterations           | 1008        |\n",
      "|    time_elapsed         | 3436        |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009722572 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.438      |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 10070       |\n",
      "|    policy_gradient_loss | 0.00145     |\n",
      "|    std                  | 0.386       |\n",
      "|    value_loss           | 6.92e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2065000, episode_reward=11639.42 +/- 3993.48\n",
      "Episode length: 3199.40 +/- 10.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.2e+03      |\n",
      "|    mean_reward          | 1.16e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2065000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026089265 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.433       |\n",
      "|    explained_variance   | 0.235        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.28e+07     |\n",
      "|    n_updates            | 10080        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    std                  | 0.386        |\n",
      "|    value_loss           | 2.47e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -1.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 599       |\n",
      "|    iterations      | 1009      |\n",
      "|    time_elapsed    | 3446      |\n",
      "|    total_timesteps | 2066432   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -1.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 599         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 3448        |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008344207 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.432      |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.58e+03    |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.0074     |\n",
      "|    std                  | 0.386       |\n",
      "|    value_loss           | 1.42e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2070000, episode_reward=-18141.81 +/- 59691.75\n",
      "Episode length: 2467.20 +/- 1196.63\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.47e+03     |\n",
      "|    mean_reward          | -1.81e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2070000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069202427 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.434       |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.68e+06     |\n",
      "|    n_updates            | 10100        |\n",
      "|    policy_gradient_loss | -0.00548     |\n",
      "|    std                  | 0.387        |\n",
      "|    value_loss           | 1.78e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 599       |\n",
      "|    iterations      | 1011      |\n",
      "|    time_elapsed    | 3455      |\n",
      "|    total_timesteps | 2070528   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 599         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 3457        |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010924391 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.4        |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    std                  | 0.388       |\n",
      "|    value_loss           | 2.64e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.67e+03     |\n",
      "|    ep_rew_mean          | -1.3e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 599          |\n",
      "|    iterations           | 1013         |\n",
      "|    time_elapsed         | 3459         |\n",
      "|    total_timesteps      | 2074624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057561817 |\n",
      "|    clip_fraction        | 0.0678       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.437       |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 203          |\n",
      "|    n_updates            | 10120        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    std                  | 0.388        |\n",
      "|    value_loss           | 6.35e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2075000, episode_reward=12373.74 +/- 3420.59\n",
      "Episode length: 2965.60 +/- 3.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.97e+03     |\n",
      "|    mean_reward          | 1.24e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2075000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038978627 |\n",
      "|    clip_fraction        | 0.0213       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.436       |\n",
      "|    explained_variance   | 0.271        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 71.3         |\n",
      "|    n_updates            | 10130        |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    std                  | 0.388        |\n",
      "|    value_loss           | 2.12e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 598       |\n",
      "|    iterations      | 1014      |\n",
      "|    time_elapsed    | 3468      |\n",
      "|    total_timesteps | 2076672   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 599         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 3470        |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013717787 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.44       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    std                  | 0.389       |\n",
      "|    value_loss           | 1.97e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2080000, episode_reward=11400.76 +/- 3923.66\n",
      "Episode length: 2701.60 +/- 5.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.7e+03      |\n",
      "|    mean_reward          | 1.14e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025127148 |\n",
      "|    clip_fraction        | 0.0176       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.439       |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+04      |\n",
      "|    n_updates            | 10150        |\n",
      "|    policy_gradient_loss | -0.000868    |\n",
      "|    std                  | 0.389        |\n",
      "|    value_loss           | 4.73e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 598       |\n",
      "|    iterations      | 1016      |\n",
      "|    time_elapsed    | 3478      |\n",
      "|    total_timesteps | 2080768   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -1.25e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 598          |\n",
      "|    iterations           | 1017         |\n",
      "|    time_elapsed         | 3479         |\n",
      "|    total_timesteps      | 2082816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048762145 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.19e+05     |\n",
      "|    n_updates            | 10160        |\n",
      "|    policy_gradient_loss | -0.00142     |\n",
      "|    std                  | 0.389        |\n",
      "|    value_loss           | 6.85e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -1.25e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 598          |\n",
      "|    iterations           | 1018         |\n",
      "|    time_elapsed         | 3481         |\n",
      "|    total_timesteps      | 2084864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048006955 |\n",
      "|    clip_fraction        | 0.0476       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.44        |\n",
      "|    explained_variance   | 0.895        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.62e+05     |\n",
      "|    n_updates            | 10170        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    std                  | 0.389        |\n",
      "|    value_loss           | 4.44e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2085000, episode_reward=8743.81 +/- 4419.45\n",
      "Episode length: 2714.40 +/- 9.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.71e+03    |\n",
      "|    mean_reward          | 8.74e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2085000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015333569 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.437      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.74e+03    |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | 0.00206     |\n",
      "|    std                  | 0.389       |\n",
      "|    value_loss           | 1.92e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.7e+03  |\n",
      "|    ep_rew_mean     | -1.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 597      |\n",
      "|    iterations      | 1019     |\n",
      "|    time_elapsed    | 3489     |\n",
      "|    total_timesteps | 2086912  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -1.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 598         |\n",
      "|    iterations           | 1020        |\n",
      "|    time_elapsed         | 3491        |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024139851 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.415      |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | 0.00201     |\n",
      "|    std                  | 0.386       |\n",
      "|    value_loss           | 6.17e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2090000, episode_reward=-11951.93 +/- 61844.38\n",
      "Episode length: 2154.80 +/- 1040.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.15e+03     |\n",
      "|    mean_reward          | -1.2e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2090000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056596263 |\n",
      "|    clip_fraction        | 0.172        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.405       |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 51.6         |\n",
      "|    n_updates            | 10200        |\n",
      "|    policy_gradient_loss | 0.0025       |\n",
      "|    std                  | 0.386        |\n",
      "|    value_loss           | 1.08e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 597       |\n",
      "|    iterations      | 1021      |\n",
      "|    time_elapsed    | 3498      |\n",
      "|    total_timesteps | 2091008   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -1.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 597         |\n",
      "|    iterations           | 1022        |\n",
      "|    time_elapsed         | 3500        |\n",
      "|    total_timesteps      | 2093056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010565117 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.407      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.386       |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2095000, episode_reward=10764.46 +/- 4290.19\n",
      "Episode length: 2909.20 +/- 13.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.91e+03    |\n",
      "|    mean_reward          | 1.08e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2095000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015126822 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.413      |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.6        |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    std                  | 0.387       |\n",
      "|    value_loss           | 6.85e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -9.64e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 597       |\n",
      "|    iterations      | 1023      |\n",
      "|    time_elapsed    | 3509      |\n",
      "|    total_timesteps | 2095104   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | -9.57e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 597          |\n",
      "|    iterations           | 1024         |\n",
      "|    time_elapsed         | 3510         |\n",
      "|    total_timesteps      | 2097152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033913474 |\n",
      "|    clip_fraction        | 0.0606       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.424       |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 479          |\n",
      "|    n_updates            | 10230        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    std                  | 0.388        |\n",
      "|    value_loss           | 923          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | -9.76e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 597          |\n",
      "|    iterations           | 1025         |\n",
      "|    time_elapsed         | 3512         |\n",
      "|    total_timesteps      | 2099200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037888722 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.429       |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 10240        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    std                  | 0.389        |\n",
      "|    value_loss           | 8.53e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2100000, episode_reward=-20460.25 +/- 57625.89\n",
      "Episode length: 2497.80 +/- 1212.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.5e+03     |\n",
      "|    mean_reward          | -2.05e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006330372 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.43       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.36e+04    |\n",
      "|    n_updates            | 10250       |\n",
      "|    policy_gradient_loss | -0.000529   |\n",
      "|    std                  | 0.389       |\n",
      "|    value_loss           | 1.1e+05     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.74e+03 |\n",
      "|    ep_rew_mean     | -1e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 596      |\n",
      "|    iterations      | 1026     |\n",
      "|    time_elapsed    | 3520     |\n",
      "|    total_timesteps | 2101248  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.71e+03     |\n",
      "|    ep_rew_mean          | -1.25e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 597          |\n",
      "|    iterations           | 1027         |\n",
      "|    time_elapsed         | 3522         |\n",
      "|    total_timesteps      | 2103296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036380053 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.58e+04     |\n",
      "|    n_updates            | 10260        |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    std                  | 0.389        |\n",
      "|    value_loss           | 1.29e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2105000, episode_reward=-20048.63 +/- 58195.61\n",
      "Episode length: 2482.20 +/- 1204.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.48e+03    |\n",
      "|    mean_reward          | -2e+04      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2105000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002338037 |\n",
      "|    clip_fraction        | 0.00977     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.432      |\n",
      "|    explained_variance   | 0.269       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.33e+07    |\n",
      "|    n_updates            | 10270       |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    std                  | 0.389       |\n",
      "|    value_loss           | 3.74e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.71e+03  |\n",
      "|    ep_rew_mean     | -1.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 596       |\n",
      "|    iterations      | 1028      |\n",
      "|    time_elapsed    | 3529      |\n",
      "|    total_timesteps | 2105344   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -1.36e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 596          |\n",
      "|    iterations           | 1029         |\n",
      "|    time_elapsed         | 3531         |\n",
      "|    total_timesteps      | 2107392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027777446 |\n",
      "|    clip_fraction        | 0.00615      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.431       |\n",
      "|    explained_variance   | 0.934        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.48e+04     |\n",
      "|    n_updates            | 10280        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    std                  | 0.389        |\n",
      "|    value_loss           | 1.92e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -1.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 1030        |\n",
      "|    time_elapsed         | 3533        |\n",
      "|    total_timesteps      | 2109440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006182238 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.432      |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+07    |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    std                  | 0.39        |\n",
      "|    value_loss           | 1.53e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2110000, episode_reward=-11932.68 +/- 1593.97\n",
      "Episode length: 2487.20 +/- 4.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.49e+03     |\n",
      "|    mean_reward          | -1.19e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2110000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095249545 |\n",
      "|    clip_fraction        | 0.0667       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.435       |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.5e+06      |\n",
      "|    n_updates            | 10300        |\n",
      "|    policy_gradient_loss | -0.000802    |\n",
      "|    std                  | 0.39         |\n",
      "|    value_loss           | 6.59e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 596       |\n",
      "|    iterations      | 1031      |\n",
      "|    time_elapsed    | 3541      |\n",
      "|    total_timesteps | 2111488   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -1.45e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 596          |\n",
      "|    iterations           | 1032         |\n",
      "|    time_elapsed         | 3543         |\n",
      "|    total_timesteps      | 2113536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052871006 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 397          |\n",
      "|    n_updates            | 10310        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    std                  | 0.39         |\n",
      "|    value_loss           | 2.55e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2115000, episode_reward=-41379.55 +/- 10749.15\n",
      "Episode length: 2463.40 +/- 30.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.46e+03     |\n",
      "|    mean_reward          | -4.14e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2115000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033799503 |\n",
      "|    clip_fraction        | 0.0444       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.432       |\n",
      "|    explained_variance   | 0.548        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 533          |\n",
      "|    n_updates            | 10320        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    std                  | 0.39         |\n",
      "|    value_loss           | 3.34e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 595       |\n",
      "|    iterations      | 1033      |\n",
      "|    time_elapsed    | 3550      |\n",
      "|    total_timesteps | 2115584   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 1034        |\n",
      "|    time_elapsed         | 3552        |\n",
      "|    total_timesteps      | 2117632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018636676 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.436      |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 10330       |\n",
      "|    policy_gradient_loss | 0.00888     |\n",
      "|    std                  | 0.388       |\n",
      "|    value_loss           | 308         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.34e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 3554        |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015040511 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.439      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.9        |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | 0.0063      |\n",
      "|    std                  | 0.388       |\n",
      "|    value_loss           | 531         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2120000, episode_reward=10925.33 +/- 4980.84\n",
      "Episode length: 2015.80 +/- 11.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | 1.09e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010498962 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.443      |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 418         |\n",
      "|    n_updates            | 10350       |\n",
      "|    policy_gradient_loss | 0.00396     |\n",
      "|    std                  | 0.389       |\n",
      "|    value_loss           | 6.92e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 595       |\n",
      "|    iterations      | 1036      |\n",
      "|    time_elapsed    | 3560      |\n",
      "|    total_timesteps | 2121728   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -1.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 3562        |\n",
      "|    total_timesteps      | 2123776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016147336 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.447      |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 207         |\n",
      "|    n_updates            | 10360       |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    std                  | 0.39        |\n",
      "|    value_loss           | 7.62e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2125000, episode_reward=14550.30 +/- 3402.67\n",
      "Episode length: 1830.00 +/- 8.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.83e+03     |\n",
      "|    mean_reward          | 1.46e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2125000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077920714 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.449       |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 85.9         |\n",
      "|    n_updates            | 10370        |\n",
      "|    policy_gradient_loss | 0.000197     |\n",
      "|    std                  | 0.391        |\n",
      "|    value_loss           | 8.87e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.68e+03 |\n",
      "|    ep_rew_mean     | -1.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 595      |\n",
      "|    iterations      | 1038     |\n",
      "|    time_elapsed    | 3568     |\n",
      "|    total_timesteps | 2125824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -1.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 1039        |\n",
      "|    time_elapsed         | 3570        |\n",
      "|    total_timesteps      | 2127872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036658797 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.434      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 10380       |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    std                  | 0.387       |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.67e+03     |\n",
      "|    ep_rew_mean          | -1.13e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 596          |\n",
      "|    iterations           | 1040         |\n",
      "|    time_elapsed         | 3572         |\n",
      "|    total_timesteps      | 2129920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146593135 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.416       |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 19           |\n",
      "|    n_updates            | 10390        |\n",
      "|    policy_gradient_loss | 0.00429      |\n",
      "|    std                  | 0.387        |\n",
      "|    value_loss           | 120          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2130000, episode_reward=-13221.24 +/- 57982.18\n",
      "Episode length: 1666.40 +/- 796.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.67e+03    |\n",
      "|    mean_reward          | -1.32e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009808965 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.415      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.73e+04    |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | 0.00102     |\n",
      "|    std                  | 0.387       |\n",
      "|    value_loss           | 6.38e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.67e+03  |\n",
      "|    ep_rew_mean     | -1.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 595       |\n",
      "|    iterations      | 1041      |\n",
      "|    time_elapsed    | 3578      |\n",
      "|    total_timesteps | 2131968   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -1.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 596         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 3580        |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011886508 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.404      |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78          |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    std                  | 0.386       |\n",
      "|    value_loss           | 6.41e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2135000, episode_reward=-22242.68 +/- 3549.27\n",
      "Episode length: 2456.40 +/- 5.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.46e+03    |\n",
      "|    mean_reward          | -2.22e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2135000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008840809 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.389      |\n",
      "|    explained_variance   | 0.29        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.45e+06    |\n",
      "|    n_updates            | 10420       |\n",
      "|    policy_gradient_loss | 0.00712     |\n",
      "|    std                  | 0.385       |\n",
      "|    value_loss           | 2.12e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.67e+03  |\n",
      "|    ep_rew_mean     | -1.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 595       |\n",
      "|    iterations      | 1043      |\n",
      "|    time_elapsed    | 3587      |\n",
      "|    total_timesteps | 2136064   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -1.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 3589        |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022188067 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.384      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.4        |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    std                  | 0.384       |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2140000, episode_reward=-6997.84 +/- 4441.20\n",
      "Episode length: 2488.80 +/- 6.55\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.49e+03     |\n",
      "|    mean_reward          | -7e+03       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2140000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039241873 |\n",
      "|    clip_fraction        | 0.0543       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.38        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 10440        |\n",
      "|    policy_gradient_loss | -0.000712    |\n",
      "|    std                  | 0.384        |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.68e+03 |\n",
      "|    ep_rew_mean     | -1.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 594      |\n",
      "|    iterations      | 1045     |\n",
      "|    time_elapsed    | 3597     |\n",
      "|    total_timesteps | 2140160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -1.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 1046        |\n",
      "|    time_elapsed         | 3599        |\n",
      "|    total_timesteps      | 2142208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008337778 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.379      |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 10450       |\n",
      "|    policy_gradient_loss | -0.0056     |\n",
      "|    std                  | 0.384       |\n",
      "|    value_loss           | 7.78e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -1.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 1047        |\n",
      "|    time_elapsed         | 3600        |\n",
      "|    total_timesteps      | 2144256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009242145 |\n",
      "|    clip_fraction        | 0.0807      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.381      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.45e+06    |\n",
      "|    n_updates            | 10460       |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    std                  | 0.384       |\n",
      "|    value_loss           | 2.18e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2145000, episode_reward=-5496.08 +/- 2457.02\n",
      "Episode length: 2447.20 +/- 5.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.45e+03    |\n",
      "|    mean_reward          | -5.5e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2145000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003401631 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.385      |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    std                  | 0.384       |\n",
      "|    value_loss           | 7.13e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 594       |\n",
      "|    iterations      | 1048      |\n",
      "|    time_elapsed    | 3608      |\n",
      "|    total_timesteps | 2146304   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.68e+03     |\n",
      "|    ep_rew_mean          | -1.27e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 595          |\n",
      "|    iterations           | 1049         |\n",
      "|    time_elapsed         | 3610         |\n",
      "|    total_timesteps      | 2148352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028233652 |\n",
      "|    clip_fraction        | 0.0085       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.386       |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 105          |\n",
      "|    n_updates            | 10480        |\n",
      "|    policy_gradient_loss | -0.000377    |\n",
      "|    std                  | 0.384        |\n",
      "|    value_loss           | 1.87e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2150000, episode_reward=-32823.64 +/- 55084.47\n",
      "Episode length: 1983.20 +/- 952.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.98e+03     |\n",
      "|    mean_reward          | -3.28e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2150000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048780343 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.387       |\n",
      "|    explained_variance   | 0.267        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69e+07     |\n",
      "|    n_updates            | 10490        |\n",
      "|    policy_gradient_loss | -0.00556     |\n",
      "|    std                  | 0.384        |\n",
      "|    value_loss           | 2.48e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -1.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 594       |\n",
      "|    iterations      | 1050      |\n",
      "|    time_elapsed    | 3616      |\n",
      "|    total_timesteps | 2150400   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -1.27e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 1051         |\n",
      "|    time_elapsed         | 3618         |\n",
      "|    total_timesteps      | 2152448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089272745 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.383       |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 236          |\n",
      "|    n_updates            | 10500        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    std                  | 0.384        |\n",
      "|    value_loss           | 474          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 595         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 3620        |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012314368 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.372      |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.000819   |\n",
      "|    std                  | 0.384       |\n",
      "|    value_loss           | 7.26e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2155000, episode_reward=2599.68 +/- 4961.96\n",
      "Episode length: 2608.20 +/- 13.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.61e+03    |\n",
      "|    mean_reward          | 2.6e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2155000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011673542 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.359      |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 209         |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    std                  | 0.382       |\n",
      "|    value_loss           | 769         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 594       |\n",
      "|    iterations      | 1053      |\n",
      "|    time_elapsed    | 3628      |\n",
      "|    total_timesteps | 2156544   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.27e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 594         |\n",
      "|    iterations           | 1054        |\n",
      "|    time_elapsed         | 3630        |\n",
      "|    total_timesteps      | 2158592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016365383 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.344      |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.000541   |\n",
      "|    std                  | 0.38        |\n",
      "|    value_loss           | 1.04e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2160000, episode_reward=5789.40 +/- 4183.43\n",
      "Episode length: 2689.40 +/- 3.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.69e+03    |\n",
      "|    mean_reward          | 5.79e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007873805 |\n",
      "|    clip_fraction        | 0.074       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.332      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.8        |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | 0.00131     |\n",
      "|    std                  | 0.38        |\n",
      "|    value_loss           | 527         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -1.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 593       |\n",
      "|    iterations      | 1055      |\n",
      "|    time_elapsed    | 3638      |\n",
      "|    total_timesteps | 2160640   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | -1.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 1056         |\n",
      "|    time_elapsed         | 3640         |\n",
      "|    total_timesteps      | 2162688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067585763 |\n",
      "|    clip_fraction        | 0.0728       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.329       |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 70.2         |\n",
      "|    n_updates            | 10550        |\n",
      "|    policy_gradient_loss | -5.97e-05    |\n",
      "|    std                  | 0.38         |\n",
      "|    value_loss           | 878          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -1.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 594          |\n",
      "|    iterations           | 1057         |\n",
      "|    time_elapsed         | 3642         |\n",
      "|    total_timesteps      | 2164736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041706245 |\n",
      "|    clip_fraction        | 0.0316       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.325       |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.66e+05     |\n",
      "|    n_updates            | 10560        |\n",
      "|    policy_gradient_loss | 0.000716     |\n",
      "|    std                  | 0.38         |\n",
      "|    value_loss           | 1.46e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2165000, episode_reward=-11791.23 +/- 4224.74\n",
      "Episode length: 2676.00 +/- 7.21\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.68e+03   |\n",
      "|    mean_reward          | -1.18e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2165000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02019982 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.327     |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 20.4       |\n",
      "|    n_updates            | 10570      |\n",
      "|    policy_gradient_loss | 0.00527    |\n",
      "|    std                  | 0.381      |\n",
      "|    value_loss           | 290        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.74e+03  |\n",
      "|    ep_rew_mean     | -1.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 593       |\n",
      "|    iterations      | 1058      |\n",
      "|    time_elapsed    | 3650      |\n",
      "|    total_timesteps | 2166784   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -1.46e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 593          |\n",
      "|    iterations           | 1059         |\n",
      "|    time_elapsed         | 3652         |\n",
      "|    total_timesteps      | 2168832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076071573 |\n",
      "|    clip_fraction        | 0.0803       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.328       |\n",
      "|    explained_variance   | 0.271        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.52e+07     |\n",
      "|    n_updates            | 10580        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    std                  | 0.382        |\n",
      "|    value_loss           | 2.26e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2170000, episode_reward=11246.33 +/- 3831.74\n",
      "Episode length: 2869.60 +/- 10.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.87e+03    |\n",
      "|    mean_reward          | 1.12e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013252988 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.317      |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 10590       |\n",
      "|    policy_gradient_loss | 0.00719     |\n",
      "|    std                  | 0.381       |\n",
      "|    value_loss           | 72          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -1.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 593       |\n",
      "|    iterations      | 1060      |\n",
      "|    time_elapsed    | 3660      |\n",
      "|    total_timesteps | 2170880   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -1.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 593          |\n",
      "|    iterations           | 1061         |\n",
      "|    time_elapsed         | 3662         |\n",
      "|    total_timesteps      | 2172928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023409044 |\n",
      "|    clip_fraction        | 0.0747       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.302       |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.28e+06     |\n",
      "|    n_updates            | 10600        |\n",
      "|    policy_gradient_loss | 0.000814     |\n",
      "|    std                  | 0.381        |\n",
      "|    value_loss           | 2.38e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | -1.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 593         |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 3664        |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014998991 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.302      |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 10610       |\n",
      "|    policy_gradient_loss | -0.000519   |\n",
      "|    std                  | 0.381       |\n",
      "|    value_loss           | 468         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2175000, episode_reward=10509.31 +/- 2677.87\n",
      "Episode length: 2912.60 +/- 11.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.91e+03    |\n",
      "|    mean_reward          | 1.05e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2175000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009041427 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.297      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 10620       |\n",
      "|    policy_gradient_loss | 0.00747     |\n",
      "|    std                  | 0.381       |\n",
      "|    value_loss           | 220         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -1.61e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 592       |\n",
      "|    iterations      | 1063      |\n",
      "|    time_elapsed    | 3673      |\n",
      "|    total_timesteps | 2177024   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | -1.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 592         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 3675        |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008405572 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.299      |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.4        |\n",
      "|    n_updates            | 10630       |\n",
      "|    policy_gradient_loss | 5.72e-06    |\n",
      "|    std                  | 0.383       |\n",
      "|    value_loss           | 7.44e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2180000, episode_reward=-18851.37 +/- 63608.94\n",
      "Episode length: 2612.60 +/- 1266.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.61e+03    |\n",
      "|    mean_reward          | -1.89e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003020024 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.308      |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.72e+06    |\n",
      "|    n_updates            | 10640       |\n",
      "|    policy_gradient_loss | -0.00146    |\n",
      "|    std                  | 0.383       |\n",
      "|    value_loss           | 5.51e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.71e+03  |\n",
      "|    ep_rew_mean     | -1.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 592       |\n",
      "|    iterations      | 1065      |\n",
      "|    time_elapsed    | 3683      |\n",
      "|    total_timesteps | 2181120   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 1066         |\n",
      "|    time_elapsed         | 3684         |\n",
      "|    total_timesteps      | 2183168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024768813 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.308       |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.92e+07     |\n",
      "|    n_updates            | 10650        |\n",
      "|    policy_gradient_loss | -0.00531     |\n",
      "|    std                  | 0.383        |\n",
      "|    value_loss           | 5.05e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2185000, episode_reward=11024.57 +/- 3698.71\n",
      "Episode length: 3170.20 +/- 11.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.17e+03    |\n",
      "|    mean_reward          | 1.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2185000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004130474 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.309      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+04    |\n",
      "|    n_updates            | 10660       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    std                  | 0.383       |\n",
      "|    value_loss           | 8.64e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.74e+03 |\n",
      "|    ep_rew_mean     | -1.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 591      |\n",
      "|    iterations      | 1067     |\n",
      "|    time_elapsed    | 3694     |\n",
      "|    total_timesteps | 2185216  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | -1.61e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 591          |\n",
      "|    iterations           | 1068         |\n",
      "|    time_elapsed         | 3696         |\n",
      "|    total_timesteps      | 2187264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029705479 |\n",
      "|    clip_fraction        | 0.00947      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.309       |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.22e+07     |\n",
      "|    n_updates            | 10670        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    std                  | 0.383        |\n",
      "|    value_loss           | 2.56e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 592          |\n",
      "|    iterations           | 1069         |\n",
      "|    time_elapsed         | 3697         |\n",
      "|    total_timesteps      | 2189312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024318858 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.31        |\n",
      "|    explained_variance   | 0.266        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.07e+07     |\n",
      "|    n_updates            | 10680        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    std                  | 0.383        |\n",
      "|    value_loss           | 2.32e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2190000, episode_reward=8375.65 +/- 2125.98\n",
      "Episode length: 2956.60 +/- 16.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.96e+03     |\n",
      "|    mean_reward          | 8.38e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2190000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021073888 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.311       |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.93e+07     |\n",
      "|    n_updates            | 10690        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    std                  | 0.383        |\n",
      "|    value_loss           | 2.57e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -1.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 591       |\n",
      "|    iterations      | 1070      |\n",
      "|    time_elapsed    | 3706      |\n",
      "|    total_timesteps | 2191360   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.72e+03     |\n",
      "|    ep_rew_mean          | -1.58e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 591          |\n",
      "|    iterations           | 1071         |\n",
      "|    time_elapsed         | 3708         |\n",
      "|    total_timesteps      | 2193408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039914483 |\n",
      "|    clip_fraction        | 0.0345       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.311       |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+04     |\n",
      "|    n_updates            | 10700        |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    std                  | 0.383        |\n",
      "|    value_loss           | 4.83e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2195000, episode_reward=-8556.92 +/- 2931.14\n",
      "Episode length: 2907.20 +/- 9.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.91e+03     |\n",
      "|    mean_reward          | -8.56e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2195000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062733847 |\n",
      "|    clip_fraction        | 0.0451       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.311       |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.19e+03     |\n",
      "|    n_updates            | 10710        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    std                  | 0.383        |\n",
      "|    value_loss           | 2.68e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.72e+03 |\n",
      "|    ep_rew_mean     | -1.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 590      |\n",
      "|    iterations      | 1072     |\n",
      "|    time_elapsed    | 3717     |\n",
      "|    total_timesteps | 2195456  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | -1.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 3719        |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009778641 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.293      |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 10720       |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    std                  | 0.381       |\n",
      "|    value_loss           | 2.26e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | -1.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 591         |\n",
      "|    iterations           | 1074        |\n",
      "|    time_elapsed         | 3720        |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016579755 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.273      |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 10730       |\n",
      "|    policy_gradient_loss | -0.00226    |\n",
      "|    std                  | 0.38        |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2200000, episode_reward=5132.17 +/- 2161.69\n",
      "Episode length: 2658.60 +/- 12.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.66e+03    |\n",
      "|    mean_reward          | 5.13e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010671046 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.276      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 82.3        |\n",
      "|    n_updates            | 10740       |\n",
      "|    policy_gradient_loss | 5.42e-05    |\n",
      "|    std                  | 0.38        |\n",
      "|    value_loss           | 879         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.75e+03 |\n",
      "|    ep_rew_mean     | -1.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 590      |\n",
      "|    iterations      | 1075     |\n",
      "|    time_elapsed    | 3728     |\n",
      "|    total_timesteps | 2201600  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.75e+03   |\n",
      "|    ep_rew_mean          | -1.31e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 590        |\n",
      "|    iterations           | 1076       |\n",
      "|    time_elapsed         | 3730       |\n",
      "|    total_timesteps      | 2203648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01363966 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.277     |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 516        |\n",
      "|    n_updates            | 10750      |\n",
      "|    policy_gradient_loss | 0.00221    |\n",
      "|    std                  | 0.381      |\n",
      "|    value_loss           | 1.96e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2205000, episode_reward=-116444.75 +/- 18393.41\n",
      "Episode length: 2305.00 +/- 1112.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.30e+03    |\n",
      "|    mean_reward          | -1.16e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2205000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018261025 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.268      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.8        |\n",
      "|    n_updates            | 10760       |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    std                  | 0.379       |\n",
      "|    value_loss           | 460         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.76e+03  |\n",
      "|    ep_rew_mean     | -1.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 590       |\n",
      "|    iterations      | 1077      |\n",
      "|    time_elapsed    | 3738      |\n",
      "|    total_timesteps | 2205696   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.76e+03   |\n",
      "|    ep_rew_mean          | -1.13e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 590        |\n",
      "|    iterations           | 1078       |\n",
      "|    time_elapsed         | 3739       |\n",
      "|    total_timesteps      | 2207744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03366632 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.261     |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 34.8       |\n",
      "|    n_updates            | 10770      |\n",
      "|    policy_gradient_loss | 0.00466    |\n",
      "|    std                  | 0.378      |\n",
      "|    value_loss           | 358        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | -1.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 1079        |\n",
      "|    time_elapsed         | 3741        |\n",
      "|    total_timesteps      | 2209792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021010052 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.251      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 10780       |\n",
      "|    policy_gradient_loss | 0.00458     |\n",
      "|    std                  | 0.377       |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2210000, episode_reward=17610.38 +/- 4105.12\n",
      "Episode length: 1742.00 +/- 13.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.74e+03    |\n",
      "|    mean_reward          | 1.76e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021221459 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.216      |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.9        |\n",
      "|    n_updates            | 10790       |\n",
      "|    policy_gradient_loss | -0.00656    |\n",
      "|    std                  | 0.372       |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -1.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 590       |\n",
      "|    iterations      | 1080      |\n",
      "|    time_elapsed    | 3747      |\n",
      "|    total_timesteps | 2211840   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | -1.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 1081        |\n",
      "|    time_elapsed         | 3749        |\n",
      "|    total_timesteps      | 2213888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014427072 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.185      |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 70.8        |\n",
      "|    n_updates            | 10800       |\n",
      "|    policy_gradient_loss | -0.000624   |\n",
      "|    std                  | 0.37        |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2215000, episode_reward=21575.71 +/- 3181.12\n",
      "Episode length: 2017.40 +/- 9.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | 2.16e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2215000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039117746 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.168      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 10810       |\n",
      "|    policy_gradient_loss | 0.00543     |\n",
      "|    std                  | 0.369       |\n",
      "|    value_loss           | 574         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.74e+03  |\n",
      "|    ep_rew_mean     | -1.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 589       |\n",
      "|    iterations      | 1082      |\n",
      "|    time_elapsed    | 3756      |\n",
      "|    total_timesteps | 2215936   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | -1.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 590         |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 3758        |\n",
      "|    total_timesteps      | 2217984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011474064 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.139      |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 10820       |\n",
      "|    policy_gradient_loss | 0.00238     |\n",
      "|    std                  | 0.366       |\n",
      "|    value_loss           | 346         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2220000, episode_reward=21917.53 +/- 3080.11\n",
      "Episode length: 1962.00 +/- 6.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.96e+03    |\n",
      "|    mean_reward          | 2.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015257961 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.119      |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 10830       |\n",
      "|    policy_gradient_loss | 0.00042     |\n",
      "|    std                  | 0.365       |\n",
      "|    value_loss           | 9.46e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -1.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 589       |\n",
      "|    iterations      | 1084      |\n",
      "|    time_elapsed    | 3764      |\n",
      "|    total_timesteps | 2220032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | -1.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 3766        |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020909082 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.106      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78.5        |\n",
      "|    n_updates            | 10840       |\n",
      "|    policy_gradient_loss | -0.00633    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.71e+03     |\n",
      "|    ep_rew_mean          | -1.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 590          |\n",
      "|    iterations           | 1086         |\n",
      "|    time_elapsed         | 3768         |\n",
      "|    total_timesteps      | 2224128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030572643 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0944      |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.45e+06     |\n",
      "|    n_updates            | 10850        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 2.41e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2225000, episode_reward=9901.32 +/- 1976.02\n",
      "Episode length: 2676.80 +/- 2.32\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.68e+03     |\n",
      "|    mean_reward          | 9.9e+03      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2225000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054443916 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0935      |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 76.6         |\n",
      "|    n_updates            | 10860        |\n",
      "|    policy_gradient_loss | 0.000386     |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 1.64e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.71e+03  |\n",
      "|    ep_rew_mean     | -1.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 589       |\n",
      "|    iterations      | 1087      |\n",
      "|    time_elapsed    | 3776      |\n",
      "|    total_timesteps | 2226176   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.7e+03    |\n",
      "|    ep_rew_mean          | -1.49e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 589        |\n",
      "|    iterations           | 1088       |\n",
      "|    time_elapsed         | 3777       |\n",
      "|    total_timesteps      | 2228224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08729036 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0872    |\n",
      "|    explained_variance   | 0.919      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.9       |\n",
      "|    n_updates            | 10870      |\n",
      "|    policy_gradient_loss | 0.00919    |\n",
      "|    std                  | 0.363      |\n",
      "|    value_loss           | 1.14e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2230000, episode_reward=24954.96 +/- 2278.19\n",
      "Episode length: 2068.80 +/- 10.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.07e+03    |\n",
      "|    mean_reward          | 2.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009263088 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.082      |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.5        |\n",
      "|    n_updates            | 10880       |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 7.57e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 589       |\n",
      "|    iterations      | 1089      |\n",
      "|    time_elapsed    | 3784      |\n",
      "|    total_timesteps | 2230272   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -1.49e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 1090        |\n",
      "|    time_elapsed         | 3786        |\n",
      "|    total_timesteps      | 2232320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025037758 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0829     |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 10890       |\n",
      "|    policy_gradient_loss | -0.00458    |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -1.49e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 589         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 3788        |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019036027 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0645     |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.6        |\n",
      "|    n_updates            | 10900       |\n",
      "|    policy_gradient_loss | 0.00369     |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 162         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2235000, episode_reward=17355.66 +/- 230.93\n",
      "Episode length: 2919.40 +/- 7.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.92e+03     |\n",
      "|    mean_reward          | 1.74e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2235000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094317375 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0553      |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.3         |\n",
      "|    n_updates            | 10910        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 7.76e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -1.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 589       |\n",
      "|    iterations      | 1092      |\n",
      "|    time_elapsed    | 3796      |\n",
      "|    total_timesteps | 2236416   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.71e+03     |\n",
      "|    ep_rew_mean          | -1.39e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 589          |\n",
      "|    iterations           | 1093         |\n",
      "|    time_elapsed         | 3798         |\n",
      "|    total_timesteps      | 2238464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050754994 |\n",
      "|    clip_fraction        | 0.0643       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.058       |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.11e+04     |\n",
      "|    n_updates            | 10920        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 1.75e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2240000, episode_reward=16396.37 +/- 4054.01\n",
      "Episode length: 2996.00 +/- 14.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3e+03       |\n",
      "|    mean_reward          | 1.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011411972 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0563     |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.1        |\n",
      "|    n_updates            | 10930       |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 1.08e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -1.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 588       |\n",
      "|    iterations      | 1094      |\n",
      "|    time_elapsed    | 3807      |\n",
      "|    total_timesteps | 2240512   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.69e+03     |\n",
      "|    ep_rew_mean          | -1.61e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 588          |\n",
      "|    iterations           | 1095         |\n",
      "|    time_elapsed         | 3809         |\n",
      "|    total_timesteps      | 2242560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036112613 |\n",
      "|    clip_fraction        | 0.00679      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0536      |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.98e+07     |\n",
      "|    n_updates            | 10940        |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 3.71e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.71e+03     |\n",
      "|    ep_rew_mean          | -1.55e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 588          |\n",
      "|    iterations           | 1096         |\n",
      "|    time_elapsed         | 3811         |\n",
      "|    total_timesteps      | 2244608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031493441 |\n",
      "|    clip_fraction        | 0.00757      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.054       |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+07     |\n",
      "|    n_updates            | 10950        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 1.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2245000, episode_reward=17388.45 +/- 4163.92\n",
      "Episode length: 1931.40 +/- 10.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.93e+03    |\n",
      "|    mean_reward          | 1.74e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2245000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017263316 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0568     |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.33e+06    |\n",
      "|    n_updates            | 10960       |\n",
      "|    policy_gradient_loss | 0.000794    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 1.44e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 588       |\n",
      "|    iterations      | 1097      |\n",
      "|    time_elapsed    | 3817      |\n",
      "|    total_timesteps | 2246656   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 1098        |\n",
      "|    time_elapsed         | 3819        |\n",
      "|    total_timesteps      | 2248704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007287644 |\n",
      "|    clip_fraction        | 0.0625      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0587     |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 397         |\n",
      "|    n_updates            | 10970       |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2250000, episode_reward=23799.10 +/- 278.52\n",
      "Episode length: 1811.20 +/- 11.16\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.81e+03     |\n",
      "|    mean_reward          | 2.38e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2250000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045039314 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.055       |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 316          |\n",
      "|    n_updates            | 10980        |\n",
      "|    policy_gradient_loss | 0.000271     |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 2.59e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -1.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 588       |\n",
      "|    iterations      | 1099      |\n",
      "|    time_elapsed    | 3825      |\n",
      "|    total_timesteps | 2250752   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -1.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 1100        |\n",
      "|    time_elapsed         | 3827        |\n",
      "|    total_timesteps      | 2252800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025149446 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0482     |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.5        |\n",
      "|    n_updates            | 10990       |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 1.08e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -1.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 3829        |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009449946 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0431     |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 11000       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 1e+03       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2255000, episode_reward=18328.10 +/- 3654.43\n",
      "Episode length: 2967.60 +/- 14.18\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.97e+03     |\n",
      "|    mean_reward          | 1.83e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2255000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065192496 |\n",
      "|    clip_fraction        | 0.0677       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0466      |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 254          |\n",
      "|    n_updates            | 11010        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 1.22e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -1.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 588       |\n",
      "|    iterations      | 1102      |\n",
      "|    time_elapsed    | 3837      |\n",
      "|    total_timesteps | 2256896   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 588         |\n",
      "|    iterations           | 1103        |\n",
      "|    time_elapsed         | 3839        |\n",
      "|    total_timesteps      | 2258944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008004891 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.051      |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 770         |\n",
      "|    n_updates            | 11020       |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 3.03e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2260000, episode_reward=19777.88 +/- 1772.79\n",
      "Episode length: 3503.20 +/- 8.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.5e+03     |\n",
      "|    mean_reward          | 1.98e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028434593 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.045      |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 11030       |\n",
      "|    policy_gradient_loss | 0.00483     |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 2e+04       |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 587       |\n",
      "|    iterations      | 1104      |\n",
      "|    time_elapsed    | 3849      |\n",
      "|    total_timesteps | 2260992   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.48e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 3851        |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007755796 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0396     |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 205         |\n",
      "|    n_updates            | 11040       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 6.39e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2265000, episode_reward=-11818.49 +/- 58782.71\n",
      "Episode length: 2888.40 +/- 1403.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.89e+03     |\n",
      "|    mean_reward          | -1.18e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2265000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028888937 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0363      |\n",
      "|    explained_variance   | 0.95         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.88e+04     |\n",
      "|    n_updates            | 11050        |\n",
      "|    policy_gradient_loss | -0.000588    |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 2.11e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 586       |\n",
      "|    iterations      | 1106      |\n",
      "|    time_elapsed    | 3860      |\n",
      "|    total_timesteps | 2265088   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -1.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 587          |\n",
      "|    iterations           | 1107         |\n",
      "|    time_elapsed         | 3862         |\n",
      "|    total_timesteps      | 2267136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076067396 |\n",
      "|    clip_fraction        | 0.0925       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0334      |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 459          |\n",
      "|    n_updates            | 11060        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 1.42e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -1.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 587         |\n",
      "|    iterations           | 1108        |\n",
      "|    time_elapsed         | 3863        |\n",
      "|    total_timesteps      | 2269184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014073294 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0335     |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.98e+05    |\n",
      "|    n_updates            | 11070       |\n",
      "|    policy_gradient_loss | 9.45e-05    |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 1.93e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2270000, episode_reward=-17346.74 +/- 56096.87\n",
      "Episode length: 3278.40 +/- 1600.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.28e+03    |\n",
      "|    mean_reward          | -1.73e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005050012 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0363     |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.5e+04     |\n",
      "|    n_updates            | 11080       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 1.25e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.71e+03  |\n",
      "|    ep_rew_mean     | -1.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 586       |\n",
      "|    iterations      | 1109      |\n",
      "|    time_elapsed    | 3873      |\n",
      "|    total_timesteps | 2271232   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.72e+03   |\n",
      "|    ep_rew_mean          | -1.61e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 586        |\n",
      "|    iterations           | 1110       |\n",
      "|    time_elapsed         | 3875       |\n",
      "|    total_timesteps      | 2273280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06465608 |\n",
      "|    clip_fraction        | 0.442      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.026     |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 129        |\n",
      "|    n_updates            | 11090      |\n",
      "|    policy_gradient_loss | 0.0473     |\n",
      "|    std                  | 0.361      |\n",
      "|    value_loss           | 700        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2275000, episode_reward=24472.35 +/- 4517.05\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 2.45e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2275000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067272605 |\n",
      "|    clip_fraction        | 0.0714       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.019       |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.07e+05     |\n",
      "|    n_updates            | 11100        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 1.28e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -1.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 585       |\n",
      "|    iterations      | 1111      |\n",
      "|    time_elapsed    | 3888      |\n",
      "|    total_timesteps | 2275328   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 585          |\n",
      "|    iterations           | 1112         |\n",
      "|    time_elapsed         | 3890         |\n",
      "|    total_timesteps      | 2277376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035033822 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0192      |\n",
      "|    explained_variance   | 0.289        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.48e+07     |\n",
      "|    n_updates            | 11110        |\n",
      "|    policy_gradient_loss | 0.00695      |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 2.37e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.73e+03      |\n",
      "|    ep_rew_mean          | -1.62e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 585           |\n",
      "|    iterations           | 1113          |\n",
      "|    time_elapsed         | 3892          |\n",
      "|    total_timesteps      | 2279424       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026427465 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0194       |\n",
      "|    explained_variance   | 0.3           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.01e+07      |\n",
      "|    n_updates            | 11120         |\n",
      "|    policy_gradient_loss | -0.00157      |\n",
      "|    std                  | 0.362         |\n",
      "|    value_loss           | 2.43e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=2280000, episode_reward=18031.08 +/- 1912.06\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 1.8e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2280000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056934906 |\n",
      "|    clip_fraction        | 0.0459       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0194      |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.35e+03     |\n",
      "|    n_updates            | 11130        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 2.16e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -1.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 584       |\n",
      "|    iterations      | 1114      |\n",
      "|    time_elapsed    | 3906      |\n",
      "|    total_timesteps | 2281472   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.76e+03     |\n",
      "|    ep_rew_mean          | -1.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 584          |\n",
      "|    iterations           | 1115         |\n",
      "|    time_elapsed         | 3907         |\n",
      "|    total_timesteps      | 2283520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040896656 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0195      |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.3e+05      |\n",
      "|    n_updates            | 11140        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 9.74e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2285000, episode_reward=16008.91 +/- 170.10\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 1.6e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2285000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034363696 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0197      |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.78e+05     |\n",
      "|    n_updates            | 11150        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 6.13e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.76e+03 |\n",
      "|    ep_rew_mean     | -1.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 582      |\n",
      "|    iterations      | 1116     |\n",
      "|    time_elapsed    | 3921     |\n",
      "|    total_timesteps | 2285568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.78e+03    |\n",
      "|    ep_rew_mean          | -1.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 3923        |\n",
      "|    total_timesteps      | 2287616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008868864 |\n",
      "|    clip_fraction        | 0.0646      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0198     |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.35e+03    |\n",
      "|    n_updates            | 11160       |\n",
      "|    policy_gradient_loss | -0.00742    |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 7.11e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.78e+03    |\n",
      "|    ep_rew_mean          | -1.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 583         |\n",
      "|    iterations           | 1118        |\n",
      "|    time_elapsed         | 3925        |\n",
      "|    total_timesteps      | 2289664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002184299 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0197     |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 11170       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 1.19e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2290000, episode_reward=-311.95 +/- 4662.20\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | -312         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2290000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075392537 |\n",
      "|    clip_fraction        | 0.0576       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0185      |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.87e+03     |\n",
      "|    n_updates            | 11180        |\n",
      "|    policy_gradient_loss | -0.00554     |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 7.65e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -1.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 581       |\n",
      "|    iterations      | 1119      |\n",
      "|    time_elapsed    | 3938      |\n",
      "|    total_timesteps | 2291712   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.8e+03     |\n",
      "|    ep_rew_mean          | -1.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 582         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 3940        |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013942536 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0146     |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+05    |\n",
      "|    n_updates            | 11190       |\n",
      "|    policy_gradient_loss | 0.00947     |\n",
      "|    std                  | 0.361       |\n",
      "|    value_loss           | 5.84e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2295000, episode_reward=13983.23 +/- 5660.92\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 1.4e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2295000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055017476 |\n",
      "|    clip_fraction        | 0.0727       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.00921     |\n",
      "|    explained_variance   | 0.524        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.21e+05     |\n",
      "|    n_updates            | 11200        |\n",
      "|    policy_gradient_loss | -0.00254     |\n",
      "|    std                  | 0.361        |\n",
      "|    value_loss           | 3.99e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.81e+03  |\n",
      "|    ep_rew_mean     | -1.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 580       |\n",
      "|    iterations      | 1121      |\n",
      "|    time_elapsed    | 3953      |\n",
      "|    total_timesteps | 2295808   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | -1.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 580         |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 3955        |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005238529 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00842    |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 11210       |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 4.44e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | -1.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 581         |\n",
      "|    iterations           | 1123        |\n",
      "|    time_elapsed         | 3957        |\n",
      "|    total_timesteps      | 2299904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012258105 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00508    |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 11220       |\n",
      "|    policy_gradient_loss | 0.00288     |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 622         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2300000, episode_reward=-124906.86 +/- 1208.34\n",
      "Episode length: 4196.60 +/- 14.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.2e+03     |\n",
      "|    mean_reward          | -1.25e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004915246 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00222    |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.27e+04    |\n",
      "|    n_updates            | 11230       |\n",
      "|    policy_gradient_loss | 0.00067     |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 7.37e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.83e+03  |\n",
      "|    ep_rew_mean     | -1.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 579       |\n",
      "|    iterations      | 1124      |\n",
      "|    time_elapsed    | 3969      |\n",
      "|    total_timesteps | 2301952   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -1.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 580         |\n",
      "|    iterations           | 1125        |\n",
      "|    time_elapsed         | 3971        |\n",
      "|    total_timesteps      | 2304000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010010756 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.00305    |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 540         |\n",
      "|    n_updates            | 11240       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 2.39e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2305000, episode_reward=-71148.62 +/- 3100.95\n",
      "Episode length: 4019.80 +/- 16.27\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.02e+03   |\n",
      "|    mean_reward          | -7.11e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2305000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01680668 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00951   |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.46e+04   |\n",
      "|    n_updates            | 11250      |\n",
      "|    policy_gradient_loss | 0.0098     |\n",
      "|    std                  | 0.361      |\n",
      "|    value_loss           | 8.52e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.87e+03  |\n",
      "|    ep_rew_mean     | -1.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 579       |\n",
      "|    iterations      | 1126      |\n",
      "|    time_elapsed    | 3982      |\n",
      "|    total_timesteps | 2306048   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.87e+03     |\n",
      "|    ep_rew_mean          | -1.65e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 579          |\n",
      "|    iterations           | 1127         |\n",
      "|    time_elapsed         | 3984         |\n",
      "|    total_timesteps      | 2308096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038275912 |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.017       |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58e+05     |\n",
      "|    n_updates            | 11260        |\n",
      "|    policy_gradient_loss | -0.000531    |\n",
      "|    std                  | 0.361        |\n",
      "|    value_loss           | 2.86e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2310000, episode_reward=-49948.42 +/- 4731.86\n",
      "Episode length: 2975.00 +/- 19.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.98e+03     |\n",
      "|    mean_reward          | -4.99e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2310000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053584003 |\n",
      "|    clip_fraction        | 0.0703       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0171      |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+05     |\n",
      "|    n_updates            | 11270        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    std                  | 0.361        |\n",
      "|    value_loss           | 2.34e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -1.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 578       |\n",
      "|    iterations      | 1128      |\n",
      "|    time_elapsed    | 3993      |\n",
      "|    total_timesteps | 2310144   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.88e+03    |\n",
      "|    ep_rew_mean          | -1.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 578         |\n",
      "|    iterations           | 1129        |\n",
      "|    time_elapsed         | 3995        |\n",
      "|    total_timesteps      | 2312192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040854793 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0195     |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.8        |\n",
      "|    n_updates            | 11280       |\n",
      "|    policy_gradient_loss | 0.00445     |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 9.14e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.88e+03   |\n",
      "|    ep_rew_mean          | -1.64e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 579        |\n",
      "|    iterations           | 1130       |\n",
      "|    time_elapsed         | 3996       |\n",
      "|    total_timesteps      | 2314240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04364623 |\n",
      "|    clip_fraction        | 0.498      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0281    |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 11290      |\n",
      "|    policy_gradient_loss | 0.0695     |\n",
      "|    std                  | 0.361      |\n",
      "|    value_loss           | 185        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2315000, episode_reward=-85150.82 +/- 3206.43\n",
      "Episode length: 4047.60 +/- 16.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.05e+03     |\n",
      "|    mean_reward          | -8.52e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2315000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049928795 |\n",
      "|    clip_fraction        | 0.0957       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0311      |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.65e+04     |\n",
      "|    n_updates            | 11300        |\n",
      "|    policy_gradient_loss | 0.000507     |\n",
      "|    std                  | 0.361        |\n",
      "|    value_loss           | 2.03e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -1.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 577       |\n",
      "|    iterations      | 1131      |\n",
      "|    time_elapsed    | 4008      |\n",
      "|    total_timesteps | 2316288   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | -1.66e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 578         |\n",
      "|    iterations           | 1132        |\n",
      "|    time_elapsed         | 4009        |\n",
      "|    total_timesteps      | 2318336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018956043 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0312     |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+05    |\n",
      "|    n_updates            | 11310       |\n",
      "|    policy_gradient_loss | 0.0183      |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 1.87e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2320000, episode_reward=-24685.43 +/- 3379.91\n",
      "Episode length: 2823.20 +/- 7.55\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.82e+03   |\n",
      "|    mean_reward          | -2.47e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2320000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01176798 |\n",
      "|    clip_fraction        | 0.0937     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.029     |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 714        |\n",
      "|    n_updates            | 11320      |\n",
      "|    policy_gradient_loss | -0.00138   |\n",
      "|    std                  | 0.36       |\n",
      "|    value_loss           | 590        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.9e+03   |\n",
      "|    ep_rew_mean     | -1.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 577       |\n",
      "|    iterations      | 1133      |\n",
      "|    time_elapsed    | 4018      |\n",
      "|    total_timesteps | 2320384   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.91e+03    |\n",
      "|    ep_rew_mean          | -1.72e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 577         |\n",
      "|    iterations           | 1134        |\n",
      "|    time_elapsed         | 4020        |\n",
      "|    total_timesteps      | 2322432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009014888 |\n",
      "|    clip_fraction        | 0.0961      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0248     |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+07    |\n",
      "|    n_updates            | 11330       |\n",
      "|    policy_gradient_loss | 0.000642    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 9.36e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.91e+03     |\n",
      "|    ep_rew_mean          | -1.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 577          |\n",
      "|    iterations           | 1135         |\n",
      "|    time_elapsed         | 4022         |\n",
      "|    total_timesteps      | 2324480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012388766 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0243      |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.31e+04     |\n",
      "|    n_updates            | 11340        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    std                  | 0.36         |\n",
      "|    value_loss           | 6.4e+04      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2325000, episode_reward=20758.23 +/- 5648.43\n",
      "Episode length: 2359.40 +/- 12.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.36e+03     |\n",
      "|    mean_reward          | 2.08e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2325000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0099955145 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0274      |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 88.5         |\n",
      "|    n_updates            | 11350        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.359        |\n",
      "|    value_loss           | 377          |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -1.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 577       |\n",
      "|    iterations      | 1136      |\n",
      "|    time_elapsed    | 4029      |\n",
      "|    total_timesteps | 2326528   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.93e+03   |\n",
      "|    ep_rew_mean          | -1.56e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 577        |\n",
      "|    iterations           | 1137       |\n",
      "|    time_elapsed         | 4031       |\n",
      "|    total_timesteps      | 2328576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00916216 |\n",
      "|    clip_fraction        | 0.0891     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0363    |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.4       |\n",
      "|    n_updates            | 11360      |\n",
      "|    policy_gradient_loss | -0.000769  |\n",
      "|    std                  | 0.36       |\n",
      "|    value_loss           | 1.09e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2330000, episode_reward=-86978.21 +/- 4468.71\n",
      "Episode length: 3056.20 +/- 12.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.06e+03    |\n",
      "|    mean_reward          | -8.7e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.116445065 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0451     |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 11370       |\n",
      "|    policy_gradient_loss | 0.0233      |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -1.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 576       |\n",
      "|    iterations      | 1138      |\n",
      "|    time_elapsed    | 4040      |\n",
      "|    total_timesteps | 2330624   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -1.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 577         |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 4042        |\n",
      "|    total_timesteps      | 2332672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004836983 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0481     |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 329         |\n",
      "|    n_updates            | 11380       |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.93e+03   |\n",
      "|    ep_rew_mean          | -1.71e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 577        |\n",
      "|    iterations           | 1140       |\n",
      "|    time_elapsed         | 4043       |\n",
      "|    total_timesteps      | 2334720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00738482 |\n",
      "|    clip_fraction        | 0.03       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0492    |\n",
      "|    explained_variance   | 0.81       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.57e+05   |\n",
      "|    n_updates            | 11390      |\n",
      "|    policy_gradient_loss | -0.00217   |\n",
      "|    std                  | 0.361      |\n",
      "|    value_loss           | 1.09e+06   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2335000, episode_reward=-83660.95 +/- 3820.86\n",
      "Episode length: 3198.40 +/- 16.74\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.2e+03      |\n",
      "|    mean_reward          | -8.37e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2335000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013727488 |\n",
      "|    clip_fraction        | 0.00835      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0532      |\n",
      "|    explained_variance   | 0.237        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.76e+07     |\n",
      "|    n_updates            | 11400        |\n",
      "|    policy_gradient_loss | -0.00467     |\n",
      "|    std                  | 0.361        |\n",
      "|    value_loss           | 4.04e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -1.71e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 576       |\n",
      "|    iterations      | 1141      |\n",
      "|    time_elapsed    | 4053      |\n",
      "|    total_timesteps | 2336768   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -1.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 576         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 4054        |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008156103 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0534     |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16e+05    |\n",
      "|    n_updates            | 11410       |\n",
      "|    policy_gradient_loss | -0.00203    |\n",
      "|    std                  | 0.361       |\n",
      "|    value_loss           | 4.9e+05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2340000, episode_reward=-83902.91 +/- 5052.19\n",
      "Episode length: 3044.40 +/- 12.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.04e+03    |\n",
      "|    mean_reward          | -8.39e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012302378 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0612     |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.86e+05    |\n",
      "|    n_updates            | 11420       |\n",
      "|    policy_gradient_loss | 0.00439     |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 1.49e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.91e+03  |\n",
      "|    ep_rew_mean     | -2.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 576       |\n",
      "|    iterations      | 1143      |\n",
      "|    time_elapsed    | 4063      |\n",
      "|    total_timesteps | 2340864   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.91e+03    |\n",
      "|    ep_rew_mean          | -2.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 576         |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 4065        |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035683148 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0675     |\n",
      "|    explained_variance   | 0.251       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.58e+07    |\n",
      "|    n_updates            | 11430       |\n",
      "|    policy_gradient_loss | 0.0136      |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 6.66e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.92e+03    |\n",
      "|    ep_rew_mean          | -2.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 576         |\n",
      "|    iterations           | 1145        |\n",
      "|    time_elapsed         | 4067        |\n",
      "|    total_timesteps      | 2344960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011968613 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0697     |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8e+05     |\n",
      "|    n_updates            | 11440       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 3.43e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2345000, episode_reward=-63086.90 +/- 4278.83\n",
      "Episode length: 3480.80 +/- 11.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.48e+03     |\n",
      "|    mean_reward          | -6.31e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2345000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050607985 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0752      |\n",
      "|    explained_variance   | 0.918        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.92e+03     |\n",
      "|    n_updates            | 11450        |\n",
      "|    policy_gradient_loss | -1.96e-05    |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 1.3e+04      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.92e+03  |\n",
      "|    ep_rew_mean     | -2.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 575       |\n",
      "|    iterations      | 1146      |\n",
      "|    time_elapsed    | 4077      |\n",
      "|    total_timesteps | 2347008   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.93e+03   |\n",
      "|    ep_rew_mean          | -2.3e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 575        |\n",
      "|    iterations           | 1147       |\n",
      "|    time_elapsed         | 4079       |\n",
      "|    total_timesteps      | 2349056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01116634 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.072     |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 180        |\n",
      "|    n_updates            | 11460      |\n",
      "|    policy_gradient_loss | -0.00647   |\n",
      "|    std                  | 0.362      |\n",
      "|    value_loss           | 969        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2350000, episode_reward=-71786.07 +/- 3463.62\n",
      "Episode length: 3427.80 +/- 9.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.43e+03     |\n",
      "|    mean_reward          | -7.18e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2350000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081851315 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0668      |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69e+06     |\n",
      "|    n_updates            | 11470        |\n",
      "|    policy_gradient_loss | 0.00276      |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 3.84e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -2.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 574       |\n",
      "|    iterations      | 1148      |\n",
      "|    time_elapsed    | 4089      |\n",
      "|    total_timesteps | 2351104   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -2.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 575         |\n",
      "|    iterations           | 1149        |\n",
      "|    time_elapsed         | 4090        |\n",
      "|    total_timesteps      | 2353152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008489573 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0697     |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.42e+04    |\n",
      "|    n_updates            | 11480       |\n",
      "|    policy_gradient_loss | -0.00068    |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 9.39e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2355000, episode_reward=-134380.68 +/- 2789.27\n",
      "Episode length: 4080.00 +/- 17.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.08e+03    |\n",
      "|    mean_reward          | -1.34e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2355000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014018241 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0722     |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.91e+03    |\n",
      "|    n_updates            | 11490       |\n",
      "|    policy_gradient_loss | 0.00149     |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 9.81e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -2.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 574       |\n",
      "|    iterations      | 1150      |\n",
      "|    time_elapsed    | 4102      |\n",
      "|    total_timesteps | 2355200   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -2.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 574         |\n",
      "|    iterations           | 1151        |\n",
      "|    time_elapsed         | 4104        |\n",
      "|    total_timesteps      | 2357248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018598828 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0774     |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.74e+05    |\n",
      "|    n_updates            | 11500       |\n",
      "|    policy_gradient_loss | 0.0174      |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 7.51e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -2.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 574         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 4106        |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006860514 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0768     |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.74e+06    |\n",
      "|    n_updates            | 11510       |\n",
      "|    policy_gradient_loss | 0.00096     |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 8.75e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2360000, episode_reward=-77371.76 +/- 2036.42\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | -7.74e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063155484 |\n",
      "|    clip_fraction        | 0.0558       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0765      |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 235          |\n",
      "|    n_updates            | 11520        |\n",
      "|    policy_gradient_loss | -0.00371     |\n",
      "|    std                  | 0.363        |\n",
      "|    value_loss           | 1.38e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -2.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 573       |\n",
      "|    iterations      | 1153      |\n",
      "|    time_elapsed    | 4119      |\n",
      "|    total_timesteps | 2361344   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.93e+03     |\n",
      "|    ep_rew_mean          | -2.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 573          |\n",
      "|    iterations           | 1154         |\n",
      "|    time_elapsed         | 4121         |\n",
      "|    total_timesteps      | 2363392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059018973 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0758      |\n",
      "|    explained_variance   | 0.586        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.26e+05     |\n",
      "|    n_updates            | 11530        |\n",
      "|    policy_gradient_loss | -0.00428     |\n",
      "|    std                  | 0.363        |\n",
      "|    value_loss           | 1.33e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2365000, episode_reward=-61094.54 +/- 31780.81\n",
      "Episode length: 4014.40 +/- 1971.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.01e+03     |\n",
      "|    mean_reward          | -6.11e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2365000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014849433 |\n",
      "|    clip_fraction        | 0.00332      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0764      |\n",
      "|    explained_variance   | 0.258        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.11e+06     |\n",
      "|    n_updates            | 11540        |\n",
      "|    policy_gradient_loss | -0.0021      |\n",
      "|    std                  | 0.363        |\n",
      "|    value_loss           | 7.36e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.96e+03  |\n",
      "|    ep_rew_mean     | -2.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 572       |\n",
      "|    iterations      | 1155      |\n",
      "|    time_elapsed    | 4132      |\n",
      "|    total_timesteps | 2365440   |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.96e+03      |\n",
      "|    ep_rew_mean          | -2.72e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 572           |\n",
      "|    iterations           | 1156          |\n",
      "|    time_elapsed         | 4134          |\n",
      "|    total_timesteps      | 2367488       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00070952874 |\n",
      "|    clip_fraction        | 0.000195      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0768       |\n",
      "|    explained_variance   | 0.916         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.73e+05      |\n",
      "|    n_updates            | 11550         |\n",
      "|    policy_gradient_loss | 1.68e-05      |\n",
      "|    std                  | 0.363         |\n",
      "|    value_loss           | 5.96e+05      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.97e+03     |\n",
      "|    ep_rew_mean          | -2.86e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 572          |\n",
      "|    iterations           | 1157         |\n",
      "|    time_elapsed         | 4136         |\n",
      "|    total_timesteps      | 2369536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064717047 |\n",
      "|    clip_fraction        | 0.0504       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0773      |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 763          |\n",
      "|    n_updates            | 11560        |\n",
      "|    policy_gradient_loss | -0.00564     |\n",
      "|    std                  | 0.363        |\n",
      "|    value_loss           | 3.13e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2370000, episode_reward=-65083.87 +/- 4148.17\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | -6.51e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006728798 |\n",
      "|    clip_fraction        | 0.0641      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0828     |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+06    |\n",
      "|    n_updates            | 11570       |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 2.55e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.97e+03  |\n",
      "|    ep_rew_mean     | -2.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 571       |\n",
      "|    iterations      | 1158      |\n",
      "|    time_elapsed    | 4149      |\n",
      "|    total_timesteps | 2371584   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -3.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 571         |\n",
      "|    iterations           | 1159        |\n",
      "|    time_elapsed         | 4151        |\n",
      "|    total_timesteps      | 2373632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009789801 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0906     |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 740         |\n",
      "|    n_updates            | 11580       |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 3.46e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2375000, episode_reward=-54778.42 +/- 4543.50\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 5e+03         |\n",
      "|    mean_reward          | -5.48e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 2375000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00018381953 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.0905       |\n",
      "|    explained_variance   | 0.283         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.31e+07      |\n",
      "|    n_updates            | 11590         |\n",
      "|    policy_gradient_loss | -2.74e-05     |\n",
      "|    std                  | 0.364         |\n",
      "|    value_loss           | 6.36e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.96e+03  |\n",
      "|    ep_rew_mean     | -3.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 570       |\n",
      "|    iterations      | 1160      |\n",
      "|    time_elapsed    | 4165      |\n",
      "|    total_timesteps | 2375680   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.96e+03    |\n",
      "|    ep_rew_mean          | -3.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 570         |\n",
      "|    iterations           | 1161        |\n",
      "|    time_elapsed         | 4166        |\n",
      "|    total_timesteps      | 2377728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017710999 |\n",
      "|    clip_fraction        | 0.0671      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0905     |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.93e+06    |\n",
      "|    n_updates            | 11600       |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 1.29e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.98e+03     |\n",
      "|    ep_rew_mean          | -2.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 570          |\n",
      "|    iterations           | 1162         |\n",
      "|    time_elapsed         | 4168         |\n",
      "|    total_timesteps      | 2379776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072064456 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0891      |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.83e+04     |\n",
      "|    n_updates            | 11610        |\n",
      "|    policy_gradient_loss | -0.000649    |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 1.23e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2380000, episode_reward=-80232.38 +/- 3926.92\n",
      "Episode length: 3126.80 +/- 8.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.13e+03     |\n",
      "|    mean_reward          | -8.02e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2380000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024690987 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0888      |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.72e+07     |\n",
      "|    n_updates            | 11620        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 1.74e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.97e+03  |\n",
      "|    ep_rew_mean     | -2.91e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 570       |\n",
      "|    iterations      | 1163      |\n",
      "|    time_elapsed    | 4177      |\n",
      "|    total_timesteps | 2381824   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.97e+03     |\n",
      "|    ep_rew_mean          | -2.91e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 570          |\n",
      "|    iterations           | 1164         |\n",
      "|    time_elapsed         | 4179         |\n",
      "|    total_timesteps      | 2383872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036511165 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.089       |\n",
      "|    explained_variance   | 0.24         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.99e+07     |\n",
      "|    n_updates            | 11630        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    std                  | 0.364        |\n",
      "|    value_loss           | 2.45e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2385000, episode_reward=-61655.88 +/- 6024.60\n",
      "Episode length: 3076.60 +/- 19.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.08e+03    |\n",
      "|    mean_reward          | -6.17e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2385000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006302763 |\n",
      "|    clip_fraction        | 0.0529      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0888     |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 846         |\n",
      "|    n_updates            | 11640       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 5.51e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.97e+03  |\n",
      "|    ep_rew_mean     | -2.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 569       |\n",
      "|    iterations      | 1165      |\n",
      "|    time_elapsed    | 4188      |\n",
      "|    total_timesteps | 2385920   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.97e+03     |\n",
      "|    ep_rew_mean          | -2.96e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 569          |\n",
      "|    iterations           | 1166         |\n",
      "|    time_elapsed         | 4190         |\n",
      "|    total_timesteps      | 2387968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013494032 |\n",
      "|    clip_fraction        | 0.00439      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0882      |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.08e+06     |\n",
      "|    n_updates            | 11650        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    std                  | 0.363        |\n",
      "|    value_loss           | 2.08e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2390000, episode_reward=-56934.44 +/- 34158.66\n",
      "Episode length: 2348.40 +/- 1137.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.35e+03    |\n",
      "|    mean_reward          | -5.69e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004102734 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0869     |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.36e+06    |\n",
      "|    n_updates            | 11660       |\n",
      "|    policy_gradient_loss | -0.000755   |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 1.75e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.97e+03  |\n",
      "|    ep_rew_mean     | -2.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 569       |\n",
      "|    iterations      | 1167      |\n",
      "|    time_elapsed    | 4197      |\n",
      "|    total_timesteps | 2390016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.96e+03    |\n",
      "|    ep_rew_mean          | -3.12e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 1168        |\n",
      "|    time_elapsed         | 4199        |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004376975 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0868     |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.58e+03    |\n",
      "|    n_updates            | 11670       |\n",
      "|    policy_gradient_loss | -0.00278    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 2.71e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.96e+03    |\n",
      "|    ep_rew_mean          | -3.12e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 1169        |\n",
      "|    time_elapsed         | 4201        |\n",
      "|    total_timesteps      | 2394112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008858037 |\n",
      "|    clip_fraction        | 0.0388      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0888     |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.33e+06    |\n",
      "|    n_updates            | 11680       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 2.77e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2395000, episode_reward=-2616.79 +/- 4371.51\n",
      "Episode length: 2649.60 +/- 12.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.65e+03    |\n",
      "|    mean_reward          | -2.62e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2395000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006159113 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0897     |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.84e+03    |\n",
      "|    n_updates            | 11690       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    std                  | 0.364       |\n",
      "|    value_loss           | 8.79e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.96e+03  |\n",
      "|    ep_rew_mean     | -3.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 569       |\n",
      "|    iterations      | 1170      |\n",
      "|    time_elapsed    | 4209      |\n",
      "|    total_timesteps | 2396160   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -3.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 1171        |\n",
      "|    time_elapsed         | 4211        |\n",
      "|    total_timesteps      | 2398208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008655496 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0864     |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.16e+03    |\n",
      "|    n_updates            | 11700       |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 4.3e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=21297.47 +/- 5580.12\n",
      "Episode length: 2349.80 +/- 5.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.35e+03    |\n",
      "|    mean_reward          | 2.13e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016702957 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0732     |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 329         |\n",
      "|    n_updates            | 11710       |\n",
      "|    policy_gradient_loss | 0.00279     |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 740         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -3.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 568       |\n",
      "|    iterations      | 1172      |\n",
      "|    time_elapsed    | 4218      |\n",
      "|    total_timesteps | 2400256   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -3.12e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 4220        |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010882432 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0612     |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 219         |\n",
      "|    n_updates            | 11720       |\n",
      "|    policy_gradient_loss | 0.0025      |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 955         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -3.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 1174        |\n",
      "|    time_elapsed         | 4222        |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018371727 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0587     |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 330         |\n",
      "|    n_updates            | 11730       |\n",
      "|    policy_gradient_loss | -0.000632   |\n",
      "|    std                  | 0.365       |\n",
      "|    value_loss           | 1.2e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2405000, episode_reward=20518.92 +/- 4677.38\n",
      "Episode length: 1910.80 +/- 5.38\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.91e+03   |\n",
      "|    mean_reward          | 2.05e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2405000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03763841 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0537    |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 78.5       |\n",
      "|    n_updates            | 11740      |\n",
      "|    policy_gradient_loss | 0.00436    |\n",
      "|    std                  | 0.363      |\n",
      "|    value_loss           | 1.09e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -3.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 569       |\n",
      "|    iterations      | 1175      |\n",
      "|    time_elapsed    | 4228      |\n",
      "|    total_timesteps | 2406400   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.94e+03  |\n",
      "|    ep_rew_mean          | -3.24e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 569       |\n",
      "|    iterations           | 1176      |\n",
      "|    time_elapsed         | 4230      |\n",
      "|    total_timesteps      | 2408448   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0652218 |\n",
      "|    clip_fraction        | 0.475     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.0422   |\n",
      "|    explained_variance   | 0.27      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.89e+06  |\n",
      "|    n_updates            | 11750     |\n",
      "|    policy_gradient_loss | 0.0238    |\n",
      "|    std                  | 0.362     |\n",
      "|    value_loss           | 1.71e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2410000, episode_reward=19770.85 +/- 2559.11\n",
      "Episode length: 1624.40 +/- 6.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.62e+03    |\n",
      "|    mean_reward          | 1.98e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009163704 |\n",
      "|    clip_fraction        | 0.0628      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.045      |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 892         |\n",
      "|    n_updates            | 11760       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 3.37e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -3.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 569       |\n",
      "|    iterations      | 1177      |\n",
      "|    time_elapsed    | 4235      |\n",
      "|    total_timesteps | 2410496   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.91e+03     |\n",
      "|    ep_rew_mean          | -3.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 569          |\n",
      "|    iterations           | 1178         |\n",
      "|    time_elapsed         | 4237         |\n",
      "|    total_timesteps      | 2412544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020526517 |\n",
      "|    clip_fraction        | 0.00542      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0481      |\n",
      "|    explained_variance   | 0.275        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.56e+06     |\n",
      "|    n_updates            | 11770        |\n",
      "|    policy_gradient_loss | -0.0057      |\n",
      "|    std                  | 0.362        |\n",
      "|    value_loss           | 2.47e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.92e+03     |\n",
      "|    ep_rew_mean          | -3.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 569          |\n",
      "|    iterations           | 1179         |\n",
      "|    time_elapsed         | 4239         |\n",
      "|    total_timesteps      | 2414592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039889924 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0485      |\n",
      "|    explained_variance   | 0.284        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+05     |\n",
      "|    n_updates            | 11780        |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    std                  | 0.363        |\n",
      "|    value_loss           | 2.06e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2415000, episode_reward=11792.92 +/- 2068.00\n",
      "Episode length: 1528.40 +/- 4.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.53e+03     |\n",
      "|    mean_reward          | 1.18e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2415000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064576585 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0495      |\n",
      "|    explained_variance   | 0.847        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.88e+03     |\n",
      "|    n_updates            | 11790        |\n",
      "|    policy_gradient_loss | -0.00395     |\n",
      "|    std                  | 0.363        |\n",
      "|    value_loss           | 4.35e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -3.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 569       |\n",
      "|    iterations      | 1180      |\n",
      "|    time_elapsed    | 4245      |\n",
      "|    total_timesteps | 2416640   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.93e+03    |\n",
      "|    ep_rew_mean          | -3.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 1181        |\n",
      "|    time_elapsed         | 4246        |\n",
      "|    total_timesteps      | 2418688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017776102 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0477     |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 11800       |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    std                  | 0.362       |\n",
      "|    value_loss           | 639         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2420000, episode_reward=17341.79 +/- 4925.09\n",
      "Episode length: 1886.40 +/- 8.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.89e+03    |\n",
      "|    mean_reward          | 1.73e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010599276 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.042      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 149         |\n",
      "|    n_updates            | 11810       |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    std                  | 0.361       |\n",
      "|    value_loss           | 640         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.92e+03  |\n",
      "|    ep_rew_mean     | -3.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 569       |\n",
      "|    iterations      | 1182      |\n",
      "|    time_elapsed    | 4253      |\n",
      "|    total_timesteps | 2420736   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.92e+03   |\n",
      "|    ep_rew_mean          | -3.24e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 569        |\n",
      "|    iterations           | 1183       |\n",
      "|    time_elapsed         | 4255       |\n",
      "|    total_timesteps      | 2422784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01382575 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0337    |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 79.9       |\n",
      "|    n_updates            | 11820      |\n",
      "|    policy_gradient_loss | 0.00301    |\n",
      "|    std                  | 0.358      |\n",
      "|    value_loss           | 8.29e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.91e+03    |\n",
      "|    ep_rew_mean          | -3.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 569         |\n",
      "|    iterations           | 1184        |\n",
      "|    time_elapsed         | 4256        |\n",
      "|    total_timesteps      | 2424832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010098711 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.032      |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.4        |\n",
      "|    n_updates            | 11830       |\n",
      "|    policy_gradient_loss | 0.000585    |\n",
      "|    std                  | 0.359       |\n",
      "|    value_loss           | 1.94e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2425000, episode_reward=-77780.11 +/- 2905.74\n",
      "Episode length: 3902.20 +/- 9.99\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.9e+03    |\n",
      "|    mean_reward          | -7.78e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2425000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03371981 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0357    |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 46.2       |\n",
      "|    n_updates            | 11840      |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    std                  | 0.361      |\n",
      "|    value_loss           | 8.44e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -3.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 568       |\n",
      "|    iterations      | 1185      |\n",
      "|    time_elapsed    | 4267      |\n",
      "|    total_timesteps | 2426880   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.89e+03    |\n",
      "|    ep_rew_mean          | -3.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 1186        |\n",
      "|    time_elapsed         | 4269        |\n",
      "|    total_timesteps      | 2428928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007133686 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0379     |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+07    |\n",
      "|    n_updates            | 11850       |\n",
      "|    policy_gradient_loss | -0.0033     |\n",
      "|    std                  | 0.361       |\n",
      "|    value_loss           | 1.8e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2430000, episode_reward=-36315.08 +/- 4406.25\n",
      "Episode length: 3734.40 +/- 7.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.73e+03   |\n",
      "|    mean_reward          | -3.63e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2430000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00987689 |\n",
      "|    clip_fraction        | 0.0974     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0364    |\n",
      "|    explained_variance   | 0.725      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 84.4       |\n",
      "|    n_updates            | 11860      |\n",
      "|    policy_gradient_loss | -0.00305   |\n",
      "|    std                  | 0.36       |\n",
      "|    value_loss           | 4.24e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -3.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 567       |\n",
      "|    iterations      | 1187      |\n",
      "|    time_elapsed    | 4280      |\n",
      "|    total_timesteps | 2430976   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.89e+03    |\n",
      "|    ep_rew_mean          | -3.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 568         |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 4282        |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002963352 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0327     |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.43e+06    |\n",
      "|    n_updates            | 11870       |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 1.01e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2435000, episode_reward=-99993.44 +/- 4451.91\n",
      "Episode length: 4132.20 +/- 19.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.13e+03    |\n",
      "|    mean_reward          | -1e+05      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2435000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009403191 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0336     |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 938         |\n",
      "|    n_updates            | 11880       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 4.25e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.91e+03  |\n",
      "|    ep_rew_mean     | -2.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 567       |\n",
      "|    iterations      | 1189      |\n",
      "|    time_elapsed    | 4293      |\n",
      "|    total_timesteps | 2435072   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.89e+03   |\n",
      "|    ep_rew_mean          | -3.14e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 567        |\n",
      "|    iterations           | 1190       |\n",
      "|    time_elapsed         | 4295       |\n",
      "|    total_timesteps      | 2437120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00861343 |\n",
      "|    clip_fraction        | 0.0646     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0355    |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.33e+03   |\n",
      "|    n_updates            | 11890      |\n",
      "|    policy_gradient_loss | -0.000257  |\n",
      "|    std                  | 0.36       |\n",
      "|    value_loss           | 2.59e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | -3.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 1191        |\n",
      "|    time_elapsed         | 4297        |\n",
      "|    total_timesteps      | 2439168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007506861 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0428     |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.25e+06    |\n",
      "|    n_updates            | 11900       |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    std                  | 0.361       |\n",
      "|    value_loss           | 1.83e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2440000, episode_reward=-56208.44 +/- 3307.59\n",
      "Episode length: 2853.60 +/- 12.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.85e+03    |\n",
      "|    mean_reward          | -5.62e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005635784 |\n",
      "|    clip_fraction        | 0.0307      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0532     |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.22e+05    |\n",
      "|    n_updates            | 11910       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    std                  | 0.361       |\n",
      "|    value_loss           | 1.54e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.9e+03   |\n",
      "|    ep_rew_mean     | -3.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 566       |\n",
      "|    iterations      | 1192      |\n",
      "|    time_elapsed    | 4306      |\n",
      "|    total_timesteps | 2441216   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.91e+03     |\n",
      "|    ep_rew_mean          | -3.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 567          |\n",
      "|    iterations           | 1193         |\n",
      "|    time_elapsed         | 4308         |\n",
      "|    total_timesteps      | 2443264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045806607 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0493      |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 70.4         |\n",
      "|    n_updates            | 11920        |\n",
      "|    policy_gradient_loss | 0.00209      |\n",
      "|    std                  | 0.361        |\n",
      "|    value_loss           | 346          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2445000, episode_reward=-28731.35 +/- 3003.89\n",
      "Episode length: 2699.00 +/- 9.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.7e+03      |\n",
      "|    mean_reward          | -2.87e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2445000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053384406 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0463      |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.73e+03     |\n",
      "|    n_updates            | 11930        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    std                  | 0.361        |\n",
      "|    value_loss           | 2.19e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -3.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 566       |\n",
      "|    iterations      | 1194      |\n",
      "|    time_elapsed    | 4316      |\n",
      "|    total_timesteps | 2445312   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.87e+03   |\n",
      "|    ep_rew_mean          | -3.3e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 566        |\n",
      "|    iterations           | 1195       |\n",
      "|    time_elapsed         | 4318       |\n",
      "|    total_timesteps      | 2447360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13194567 |\n",
      "|    clip_fraction        | 0.181      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0476    |\n",
      "|    explained_variance   | 0.309      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.86e+06   |\n",
      "|    n_updates            | 11940      |\n",
      "|    policy_gradient_loss | 0.0068     |\n",
      "|    std                  | 0.36       |\n",
      "|    value_loss           | 2e+07      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.83e+03   |\n",
      "|    ep_rew_mean          | -3.18e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 566        |\n",
      "|    iterations           | 1196       |\n",
      "|    time_elapsed         | 4320       |\n",
      "|    total_timesteps      | 2449408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01624054 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.0411    |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 152        |\n",
      "|    n_updates            | 11950      |\n",
      "|    policy_gradient_loss | 0.0038     |\n",
      "|    std                  | 0.358      |\n",
      "|    value_loss           | 315        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2450000, episode_reward=-14941.15 +/- 62679.79\n",
      "Episode length: 1292.80 +/- 608.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.29e+03    |\n",
      "|    mean_reward          | -1.49e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017725877 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0369     |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 83.7        |\n",
      "|    n_updates            | 11960       |\n",
      "|    policy_gradient_loss | 0.000143    |\n",
      "|    std                  | 0.359       |\n",
      "|    value_loss           | 660         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.81e+03  |\n",
      "|    ep_rew_mean     | -3.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 566       |\n",
      "|    iterations      | 1197      |\n",
      "|    time_elapsed    | 4324      |\n",
      "|    total_timesteps | 2451456   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.78e+03    |\n",
      "|    ep_rew_mean          | -2.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 1198        |\n",
      "|    time_elapsed         | 4326        |\n",
      "|    total_timesteps      | 2453504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013302011 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0459     |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.4        |\n",
      "|    n_updates            | 11970       |\n",
      "|    policy_gradient_loss | 0.00855     |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 149         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2455000, episode_reward=-13688.58 +/- 67904.28\n",
      "Episode length: 1306.80 +/- 611.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.31e+03     |\n",
      "|    mean_reward          | -1.37e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2455000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067892433 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.0484      |\n",
      "|    explained_variance   | 0.884        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 417          |\n",
      "|    n_updates            | 11980        |\n",
      "|    policy_gradient_loss | -0.00134     |\n",
      "|    std                  | 0.36         |\n",
      "|    value_loss           | 5.74e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -2.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 566       |\n",
      "|    iterations      | 1199      |\n",
      "|    time_elapsed    | 4331      |\n",
      "|    total_timesteps | 2455552   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -2.92e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 1200        |\n",
      "|    time_elapsed         | 4333        |\n",
      "|    total_timesteps      | 2457600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018679943 |\n",
      "|    clip_fraction        | 0.0776      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0496     |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 301         |\n",
      "|    n_updates            | 11990       |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 2.26e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -2.9e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 1201        |\n",
      "|    time_elapsed         | 4335        |\n",
      "|    total_timesteps      | 2459648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016604982 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.05       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 454         |\n",
      "|    n_updates            | 12000       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.361       |\n",
      "|    value_loss           | 8.31e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2460000, episode_reward=12532.54 +/- 4421.58\n",
      "Episode length: 1325.00 +/- 8.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.32e+03    |\n",
      "|    mean_reward          | 1.25e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022162031 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0485     |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63          |\n",
      "|    n_updates            | 12010       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.361       |\n",
      "|    value_loss           | 342         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -2.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 567       |\n",
      "|    iterations      | 1202      |\n",
      "|    time_elapsed    | 4340      |\n",
      "|    total_timesteps | 2461696   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -2.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 4342        |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016281169 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0499     |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 263         |\n",
      "|    n_updates            | 12020       |\n",
      "|    policy_gradient_loss | -0.00702    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 7.22e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2465000, episode_reward=16620.30 +/- 5379.19\n",
      "Episode length: 1533.00 +/- 6.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.53e+03    |\n",
      "|    mean_reward          | 1.66e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2465000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006777675 |\n",
      "|    clip_fraction        | 0.0525      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0451     |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 12030       |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 1.02e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.62e+03  |\n",
      "|    ep_rew_mean     | -2.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 567       |\n",
      "|    iterations      | 1204      |\n",
      "|    time_elapsed    | 4347      |\n",
      "|    total_timesteps | 2465792   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | -2.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 1205        |\n",
      "|    time_elapsed         | 4349        |\n",
      "|    total_timesteps      | 2467840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010337443 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0431     |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 12040       |\n",
      "|    policy_gradient_loss | -0.00435    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 2.29e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | -2.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 1206        |\n",
      "|    time_elapsed         | 4351        |\n",
      "|    total_timesteps      | 2469888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024066344 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0541     |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80.9        |\n",
      "|    n_updates            | 12050       |\n",
      "|    policy_gradient_loss | 0.00335     |\n",
      "|    std                  | 0.363       |\n",
      "|    value_loss           | 7.5e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2470000, episode_reward=-45086.87 +/- 47868.06\n",
      "Episode length: 3072.80 +/- 1498.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.07e+03    |\n",
      "|    mean_reward          | -4.51e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019885117 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0488     |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.2        |\n",
      "|    n_updates            | 12060       |\n",
      "|    policy_gradient_loss | 0.00325     |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 83.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.57e+03 |\n",
      "|    ep_rew_mean     | -2.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 566      |\n",
      "|    iterations      | 1207     |\n",
      "|    time_elapsed    | 4360     |\n",
      "|    total_timesteps | 2471936  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -2.91e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 567         |\n",
      "|    iterations           | 1208        |\n",
      "|    time_elapsed         | 4362        |\n",
      "|    total_timesteps      | 2473984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010027681 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0271     |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.31e+06    |\n",
      "|    n_updates            | 12070       |\n",
      "|    policy_gradient_loss | 0.00647     |\n",
      "|    std                  | 0.359       |\n",
      "|    value_loss           | 2.19e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2475000, episode_reward=6656.56 +/- 4846.67\n",
      "Episode length: 2405.20 +/- 10.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.41e+03    |\n",
      "|    mean_reward          | 6.66e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2475000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008468101 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0271     |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.08e+04    |\n",
      "|    n_updates            | 12080       |\n",
      "|    policy_gradient_loss | -0.00937    |\n",
      "|    std                  | 0.36        |\n",
      "|    value_loss           | 4.03e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.55e+03  |\n",
      "|    ep_rew_mean     | -2.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 566       |\n",
      "|    iterations      | 1209      |\n",
      "|    time_elapsed    | 4369      |\n",
      "|    total_timesteps | 2476032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -2.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 1210        |\n",
      "|    time_elapsed         | 4371        |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006796627 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0262     |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.68e+03    |\n",
      "|    n_updates            | 12090       |\n",
      "|    policy_gradient_loss | -0.00965    |\n",
      "|    std                  | 0.359       |\n",
      "|    value_loss           | 2.14e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2480000, episode_reward=-9505.02 +/- 250.75\n",
      "Episode length: 2684.20 +/- 10.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.68e+03    |\n",
      "|    mean_reward          | -9.51e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011764806 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0225     |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 302         |\n",
      "|    n_updates            | 12100       |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    std                  | 0.359       |\n",
      "|    value_loss           | 2.09e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -2.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 566       |\n",
      "|    iterations      | 1211      |\n",
      "|    time_elapsed    | 4379      |\n",
      "|    total_timesteps | 2480128   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -2.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 1212        |\n",
      "|    time_elapsed         | 4381        |\n",
      "|    total_timesteps      | 2482176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012123977 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.0132     |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.1        |\n",
      "|    n_updates            | 12110       |\n",
      "|    policy_gradient_loss | 0.00378     |\n",
      "|    std                  | 0.359       |\n",
      "|    value_loss           | 9.01e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.51e+03   |\n",
      "|    ep_rew_mean          | -2.81e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 566        |\n",
      "|    iterations           | 1213       |\n",
      "|    time_elapsed         | 4383       |\n",
      "|    total_timesteps      | 2484224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01383928 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.00646   |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 35.4       |\n",
      "|    n_updates            | 12120      |\n",
      "|    policy_gradient_loss | 0.00363    |\n",
      "|    std                  | 0.358      |\n",
      "|    value_loss           | 7.55e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2485000, episode_reward=-29968.96 +/- 64244.56\n",
      "Episode length: 2173.40 +/- 1041.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.17e+03    |\n",
      "|    mean_reward          | -3e+04      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2485000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020132588 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0111      |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.14e+04    |\n",
      "|    n_updates            | 12130       |\n",
      "|    policy_gradient_loss | 0.00458     |\n",
      "|    std                  | 0.356       |\n",
      "|    value_loss           | 1.06e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -2.93e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 566       |\n",
      "|    iterations      | 1214      |\n",
      "|    time_elapsed    | 4389      |\n",
      "|    total_timesteps | 2486272   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | -2.77e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 566          |\n",
      "|    iterations           | 1215         |\n",
      "|    time_elapsed         | 4391         |\n",
      "|    total_timesteps      | 2488320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039375946 |\n",
      "|    clip_fraction        | 0.0474       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.0307       |\n",
      "|    explained_variance   | 0.262        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.2e+07      |\n",
      "|    n_updates            | 12140        |\n",
      "|    policy_gradient_loss | -0.0032      |\n",
      "|    std                  | 0.356        |\n",
      "|    value_loss           | 7.74e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2490000, episode_reward=4195.48 +/- 3259.51\n",
      "Episode length: 2663.00 +/- 8.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.66e+03    |\n",
      "|    mean_reward          | 4.2e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018704647 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0279      |\n",
      "|    explained_variance   | 0.628       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+04     |\n",
      "|    n_updates            | 12150       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.356       |\n",
      "|    value_loss           | 9.81e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -2.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 566       |\n",
      "|    iterations      | 1216      |\n",
      "|    time_elapsed    | 4399      |\n",
      "|    total_timesteps | 2490368   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | -2.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 4401        |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012017251 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0283      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.79e+03    |\n",
      "|    n_updates            | 12160       |\n",
      "|    policy_gradient_loss | 0.00345     |\n",
      "|    std                  | 0.356       |\n",
      "|    value_loss           | 5.15e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | -2.52e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 566          |\n",
      "|    iterations           | 1218         |\n",
      "|    time_elapsed         | 4403         |\n",
      "|    total_timesteps      | 2494464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034150986 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.0255       |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 738          |\n",
      "|    n_updates            | 12170        |\n",
      "|    policy_gradient_loss | 0.00046      |\n",
      "|    std                  | 0.356        |\n",
      "|    value_loss           | 1.18e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2495000, episode_reward=-27357.99 +/- 56460.07\n",
      "Episode length: 2123.20 +/- 1017.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.12e+03     |\n",
      "|    mean_reward          | -2.74e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2495000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018954054 |\n",
      "|    clip_fraction        | 0.00591      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.0249       |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.11e+05     |\n",
      "|    n_updates            | 12180        |\n",
      "|    policy_gradient_loss | -0.000624    |\n",
      "|    std                  | 0.356        |\n",
      "|    value_loss           | 2.37e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -2.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 566       |\n",
      "|    iterations      | 1219      |\n",
      "|    time_elapsed    | 4410      |\n",
      "|    total_timesteps | 2496512   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -2.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 566         |\n",
      "|    iterations           | 1220        |\n",
      "|    time_elapsed         | 4412        |\n",
      "|    total_timesteps      | 2498560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009126929 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0277      |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 794         |\n",
      "|    n_updates            | 12190       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    std                  | 0.356       |\n",
      "|    value_loss           | 4.68e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2500000, episode_reward=4210.27 +/- 3493.74\n",
      "Episode length: 2690.20 +/- 9.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.69e+03    |\n",
      "|    mean_reward          | 4.21e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015702808 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0371      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.2        |\n",
      "|    n_updates            | 12200       |\n",
      "|    policy_gradient_loss | 0.000823    |\n",
      "|    std                  | 0.354       |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -2.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 565       |\n",
      "|    iterations      | 1221      |\n",
      "|    time_elapsed    | 4420      |\n",
      "|    total_timesteps | 2500608   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | -2.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 1222        |\n",
      "|    time_elapsed         | 4422        |\n",
      "|    total_timesteps      | 2502656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034548502 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0558      |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 12210       |\n",
      "|    policy_gradient_loss | 0.00362     |\n",
      "|    std                  | 0.352       |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | -1.94e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 566          |\n",
      "|    iterations           | 1223         |\n",
      "|    time_elapsed         | 4424         |\n",
      "|    total_timesteps      | 2504704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139033515 |\n",
      "|    clip_fraction        | 0.231        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.0825       |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 59.9         |\n",
      "|    n_updates            | 12220        |\n",
      "|    policy_gradient_loss | -0.00553     |\n",
      "|    std                  | 0.351        |\n",
      "|    value_loss           | 7.56e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2505000, episode_reward=4272.01 +/- 3163.25\n",
      "Episode length: 2411.00 +/- 3.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.41e+03    |\n",
      "|    mean_reward          | 4.27e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2505000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013096819 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0957      |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 12230       |\n",
      "|    policy_gradient_loss | 0.000619    |\n",
      "|    std                  | 0.352       |\n",
      "|    value_loss           | 1.91e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -1.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 565       |\n",
      "|    iterations      | 1224      |\n",
      "|    time_elapsed    | 4431      |\n",
      "|    total_timesteps | 2506752   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -1.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 1225        |\n",
      "|    time_elapsed         | 4433        |\n",
      "|    total_timesteps      | 2508800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006773218 |\n",
      "|    clip_fraction        | 0.0323      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.0917      |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.42e+03    |\n",
      "|    n_updates            | 12240       |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    std                  | 0.352       |\n",
      "|    value_loss           | 2.78e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2510000, episode_reward=10718.90 +/- 172.06\n",
      "Episode length: 2448.20 +/- 7.05\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.45e+03     |\n",
      "|    mean_reward          | 1.07e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2510000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043443735 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.0919       |\n",
      "|    explained_variance   | 0.698        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.21e+05     |\n",
      "|    n_updates            | 12250        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    std                  | 0.352        |\n",
      "|    value_loss           | 4.7e+05      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -1.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 565       |\n",
      "|    iterations      | 1226      |\n",
      "|    time_elapsed    | 4441      |\n",
      "|    total_timesteps | 2510848   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.43e+03  |\n",
      "|    ep_rew_mean          | -1.55e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 565       |\n",
      "|    iterations           | 1227      |\n",
      "|    time_elapsed         | 4442      |\n",
      "|    total_timesteps      | 2512896   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0195831 |\n",
      "|    clip_fraction        | 0.205     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0.113     |\n",
      "|    explained_variance   | 0.999     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 26.7      |\n",
      "|    n_updates            | 12260     |\n",
      "|    policy_gradient_loss | -0.00522  |\n",
      "|    std                  | 0.349     |\n",
      "|    value_loss           | 83.3      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | -1.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 1228        |\n",
      "|    time_elapsed         | 4444        |\n",
      "|    total_timesteps      | 2514944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005565944 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.13        |\n",
      "|    explained_variance   | 0.332       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.12e+06    |\n",
      "|    n_updates            | 12270       |\n",
      "|    policy_gradient_loss | -0.000669   |\n",
      "|    std                  | 0.349       |\n",
      "|    value_loss           | 3.47e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2515000, episode_reward=2396.56 +/- 3894.69\n",
      "Episode length: 2589.00 +/- 14.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.59e+03     |\n",
      "|    mean_reward          | 2.4e+03      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2515000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065351864 |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.13         |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.58e+03     |\n",
      "|    n_updates            | 12280        |\n",
      "|    policy_gradient_loss | -0.00924     |\n",
      "|    std                  | 0.349        |\n",
      "|    value_loss           | 2.62e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -1.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 565       |\n",
      "|    iterations      | 1229      |\n",
      "|    time_elapsed    | 4452      |\n",
      "|    total_timesteps | 2516992   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | -1.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 565          |\n",
      "|    iterations           | 1230         |\n",
      "|    time_elapsed         | 4454         |\n",
      "|    total_timesteps      | 2519040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063133487 |\n",
      "|    clip_fraction        | 0.0727       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.134        |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+04     |\n",
      "|    n_updates            | 12290        |\n",
      "|    policy_gradient_loss | -0.000731    |\n",
      "|    std                  | 0.349        |\n",
      "|    value_loss           | 1.08e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2520000, episode_reward=6827.55 +/- 1663.86\n",
      "Episode length: 2714.80 +/- 7.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.71e+03    |\n",
      "|    mean_reward          | 6.83e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009538311 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.144       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94          |\n",
      "|    n_updates            | 12300       |\n",
      "|    policy_gradient_loss | -0.00393    |\n",
      "|    std                  | 0.347       |\n",
      "|    value_loss           | 368         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -1.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 564       |\n",
      "|    iterations      | 1231      |\n",
      "|    time_elapsed    | 4462      |\n",
      "|    total_timesteps | 2521088   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -1.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 1232        |\n",
      "|    time_elapsed         | 4464        |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021574762 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.173       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.2        |\n",
      "|    n_updates            | 12310       |\n",
      "|    policy_gradient_loss | 0.0066      |\n",
      "|    std                  | 0.344       |\n",
      "|    value_loss           | 220         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2525000, episode_reward=7227.47 +/- 3760.34\n",
      "Episode length: 2512.20 +/- 7.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.51e+03    |\n",
      "|    mean_reward          | 7.23e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2525000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021503706 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.198       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 12320       |\n",
      "|    policy_gradient_loss | 0.000637    |\n",
      "|    std                  | 0.342       |\n",
      "|    value_loss           | 1.9e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -9.25e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 564       |\n",
      "|    iterations      | 1233      |\n",
      "|    time_elapsed    | 4472      |\n",
      "|    total_timesteps | 2525184   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | -7.65e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 1234        |\n",
      "|    time_elapsed         | 4474        |\n",
      "|    total_timesteps      | 2527232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014671134 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.198       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.2        |\n",
      "|    n_updates            | 12330       |\n",
      "|    policy_gradient_loss | 0.00561     |\n",
      "|    std                  | 0.342       |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -7.51e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 565         |\n",
      "|    iterations           | 1235        |\n",
      "|    time_elapsed         | 4475        |\n",
      "|    total_timesteps      | 2529280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021638801 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.198       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 12340       |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    std                  | 0.342       |\n",
      "|    value_loss           | 9.16e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2530000, episode_reward=1998.68 +/- 2840.10\n",
      "Episode length: 2508.60 +/- 8.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.51e+03    |\n",
      "|    mean_reward          | 2e+03       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040220086 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.238       |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.52        |\n",
      "|    n_updates            | 12350       |\n",
      "|    policy_gradient_loss | 0.000945    |\n",
      "|    std                  | 0.336       |\n",
      "|    value_loss           | 32.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -6.36e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 564       |\n",
      "|    iterations      | 1236      |\n",
      "|    time_elapsed    | 4483      |\n",
      "|    total_timesteps | 2531328   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.45e+03     |\n",
      "|    ep_rew_mean          | -5.97e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 564          |\n",
      "|    iterations           | 1237         |\n",
      "|    time_elapsed         | 4485         |\n",
      "|    total_timesteps      | 2533376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065799765 |\n",
      "|    clip_fraction        | 0.357        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.259        |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 12360        |\n",
      "|    policy_gradient_loss | 0.034        |\n",
      "|    std                  | 0.336        |\n",
      "|    value_loss           | 1.05e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2535000, episode_reward=7217.13 +/- 146.27\n",
      "Episode length: 2558.00 +/- 5.40\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.56e+03   |\n",
      "|    mean_reward          | 7.22e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2535000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00463517 |\n",
      "|    clip_fraction        | 0.0764     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.26       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.8       |\n",
      "|    n_updates            | 12370      |\n",
      "|    policy_gradient_loss | -0.00042   |\n",
      "|    std                  | 0.335      |\n",
      "|    value_loss           | 273        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -4.62e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 564       |\n",
      "|    iterations      | 1238      |\n",
      "|    time_elapsed    | 4493      |\n",
      "|    total_timesteps | 2535424   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | -4.45e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 1239        |\n",
      "|    time_elapsed         | 4495        |\n",
      "|    total_timesteps      | 2537472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021676105 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.26        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.2        |\n",
      "|    n_updates            | 12380       |\n",
      "|    policy_gradient_loss | 0.0031      |\n",
      "|    std                  | 0.336       |\n",
      "|    value_loss           | 1.03e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -2.88e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 1240        |\n",
      "|    time_elapsed         | 4497        |\n",
      "|    total_timesteps      | 2539520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016618537 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.272       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 12390       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    std                  | 0.335       |\n",
      "|    value_loss           | 78.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2540000, episode_reward=3304.37 +/- 3728.54\n",
      "Episode length: 2591.20 +/- 8.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.59e+03    |\n",
      "|    mean_reward          | 3.3e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025088442 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.312       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 12400       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    std                  | 0.332       |\n",
      "|    value_loss           | 9.1e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -2.92e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 564       |\n",
      "|    iterations      | 1241      |\n",
      "|    time_elapsed    | 4504      |\n",
      "|    total_timesteps | 2541568   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -2.96e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 1242        |\n",
      "|    time_elapsed         | 4506        |\n",
      "|    total_timesteps      | 2543616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011788396 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.336       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.7        |\n",
      "|    n_updates            | 12410       |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    std                  | 0.332       |\n",
      "|    value_loss           | 2.22e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2545000, episode_reward=4228.94 +/- 3976.38\n",
      "Episode length: 2613.60 +/- 6.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.61e+03    |\n",
      "|    mean_reward          | 4.23e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2545000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025654959 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.346       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79.6        |\n",
      "|    n_updates            | 12420       |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    std                  | 0.331       |\n",
      "|    value_loss           | 311         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -2.97e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 563       |\n",
      "|    iterations      | 1243      |\n",
      "|    time_elapsed    | 4514      |\n",
      "|    total_timesteps | 2545664   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -3.01e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 4516        |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017328065 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.373       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 12430       |\n",
      "|    policy_gradient_loss | -0.00684    |\n",
      "|    std                  | 0.329       |\n",
      "|    value_loss           | 70.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -3.04e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 564         |\n",
      "|    iterations           | 1245        |\n",
      "|    time_elapsed         | 4518        |\n",
      "|    total_timesteps      | 2549760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008604355 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.398       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 12440       |\n",
      "|    policy_gradient_loss | -0.000457   |\n",
      "|    std                  | 0.328       |\n",
      "|    value_loss           | 252         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2550000, episode_reward=-2665.23 +/- 6041.49\n",
      "Episode length: 2545.80 +/- 15.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.55e+03    |\n",
      "|    mean_reward          | -2.67e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010523818 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.411       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94          |\n",
      "|    n_updates            | 12450       |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    std                  | 0.327       |\n",
      "|    value_loss           | 475         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -4.29e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 563       |\n",
      "|    iterations      | 1246      |\n",
      "|    time_elapsed    | 4526      |\n",
      "|    total_timesteps | 2551808   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | -4.36e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 564          |\n",
      "|    iterations           | 1247         |\n",
      "|    time_elapsed         | 4527         |\n",
      "|    total_timesteps      | 2553856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003379557 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.416        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.51e+07     |\n",
      "|    n_updates            | 12460        |\n",
      "|    policy_gradient_loss | -0.00106     |\n",
      "|    std                  | 0.327        |\n",
      "|    value_loss           | 4.01e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2555000, episode_reward=994.60 +/- 3827.82\n",
      "Episode length: 2503.60 +/- 3.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.5e+03      |\n",
      "|    mean_reward          | 995          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2555000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030348918 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.416        |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.33e+03     |\n",
      "|    n_updates            | 12470        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    std                  | 0.327        |\n",
      "|    value_loss           | 9.82e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -5.46e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 563       |\n",
      "|    iterations      | 1248      |\n",
      "|    time_elapsed    | 4535      |\n",
      "|    total_timesteps | 2555904   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | -5.46e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 563          |\n",
      "|    iterations           | 1249         |\n",
      "|    time_elapsed         | 4537         |\n",
      "|    total_timesteps      | 2557952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035647906 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.416        |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.75e+06     |\n",
      "|    n_updates            | 12480        |\n",
      "|    policy_gradient_loss | -0.0036      |\n",
      "|    std                  | 0.327        |\n",
      "|    value_loss           | 1.99e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2560000, episode_reward=7849.23 +/- 260.77\n",
      "Episode length: 2455.00 +/- 9.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.46e+03    |\n",
      "|    mean_reward          | 7.85e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006946954 |\n",
      "|    clip_fraction        | 0.0489      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.416       |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.16e+04    |\n",
      "|    n_updates            | 12490       |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    std                  | 0.327       |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -4.09e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 563       |\n",
      "|    iterations      | 1250      |\n",
      "|    time_elapsed    | 4545      |\n",
      "|    total_timesteps | 2560000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -3.97e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 1251        |\n",
      "|    time_elapsed         | 4546        |\n",
      "|    total_timesteps      | 2562048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005002967 |\n",
      "|    clip_fraction        | 0.0238      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.417       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 654         |\n",
      "|    n_updates            | 12500       |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    std                  | 0.327       |\n",
      "|    value_loss           | 5.62e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | -4.03e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 563          |\n",
      "|    iterations           | 1252         |\n",
      "|    time_elapsed         | 4548         |\n",
      "|    total_timesteps      | 2564096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038226459 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.419        |\n",
      "|    explained_variance   | 0.239        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.09e+06     |\n",
      "|    n_updates            | 12510        |\n",
      "|    policy_gradient_loss | -0.00217     |\n",
      "|    std                  | 0.327        |\n",
      "|    value_loss           | 1.8e+07      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2565000, episode_reward=5334.95 +/- 4428.91\n",
      "Episode length: 2382.20 +/- 8.42\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.38e+03   |\n",
      "|    mean_reward          | 5.33e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2565000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00865064 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.418      |\n",
      "|    explained_variance   | 0.89       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.35e+03   |\n",
      "|    n_updates            | 12520      |\n",
      "|    policy_gradient_loss | -0.00439   |\n",
      "|    std                  | 0.327      |\n",
      "|    value_loss           | 8.65e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -4.07e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 563       |\n",
      "|    iterations      | 1253      |\n",
      "|    time_elapsed    | 4556      |\n",
      "|    total_timesteps | 2566144   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -4.13e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 563          |\n",
      "|    iterations           | 1254         |\n",
      "|    time_elapsed         | 4557         |\n",
      "|    total_timesteps      | 2568192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082313325 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.417        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 262          |\n",
      "|    n_updates            | 12530        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    std                  | 0.328        |\n",
      "|    value_loss           | 1.41e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2570000, episode_reward=8155.34 +/- 4613.96\n",
      "Episode length: 2409.00 +/- 5.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.41e+03    |\n",
      "|    mean_reward          | 8.16e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011110725 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.428       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.5        |\n",
      "|    n_updates            | 12540       |\n",
      "|    policy_gradient_loss | -0.00173    |\n",
      "|    std                  | 0.326       |\n",
      "|    value_loss           | 886         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -4.16e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1255      |\n",
      "|    time_elapsed    | 4565      |\n",
      "|    total_timesteps | 2570240   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -4.14e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 1256        |\n",
      "|    time_elapsed         | 4567        |\n",
      "|    total_timesteps      | 2572288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008067721 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.44        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.2        |\n",
      "|    n_updates            | 12550       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    std                  | 0.326       |\n",
      "|    value_loss           | 897         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -4.17e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 1257        |\n",
      "|    time_elapsed         | 4569        |\n",
      "|    total_timesteps      | 2574336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010406589 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.446       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.93e+05    |\n",
      "|    n_updates            | 12560       |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    std                  | 0.326       |\n",
      "|    value_loss           | 4e+04       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2575000, episode_reward=12671.29 +/- 5435.98\n",
      "Episode length: 2367.60 +/- 10.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.37e+03     |\n",
      "|    mean_reward          | 1.27e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2575000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121607045 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.461        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23.1         |\n",
      "|    n_updates            | 12570        |\n",
      "|    policy_gradient_loss | -0.000837    |\n",
      "|    std                  | 0.324        |\n",
      "|    value_loss           | 1.11e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -4.23e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1258      |\n",
      "|    time_elapsed    | 4576      |\n",
      "|    total_timesteps | 2576384   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -4.11e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 1259        |\n",
      "|    time_elapsed         | 4578        |\n",
      "|    total_timesteps      | 2578432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025956549 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.474       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 12580       |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    std                  | 0.326       |\n",
      "|    value_loss           | 281         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2580000, episode_reward=21000.74 +/- 2408.50\n",
      "Episode length: 1949.40 +/- 5.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.95e+03    |\n",
      "|    mean_reward          | 2.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015208883 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.475       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.6        |\n",
      "|    n_updates            | 12590       |\n",
      "|    policy_gradient_loss | 0.00239     |\n",
      "|    std                  | 0.323       |\n",
      "|    value_loss           | 240         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -4.09e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1260      |\n",
      "|    time_elapsed    | 4584      |\n",
      "|    total_timesteps | 2580480   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -2.69e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 4586        |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013326575 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.495       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 12600       |\n",
      "|    policy_gradient_loss | -0.000299   |\n",
      "|    std                  | 0.323       |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -2.61e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 563         |\n",
      "|    iterations           | 1262        |\n",
      "|    time_elapsed         | 4588        |\n",
      "|    total_timesteps      | 2584576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014490543 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.504       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 12610       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    std                  | 0.325       |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2585000, episode_reward=14822.36 +/- 4249.19\n",
      "Episode length: 2925.60 +/- 10.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.93e+03    |\n",
      "|    mean_reward          | 1.48e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2585000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017542094 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.511       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 12620       |\n",
      "|    policy_gradient_loss | -0.00251    |\n",
      "|    std                  | 0.324       |\n",
      "|    value_loss           | 1.12e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.55e+03  |\n",
      "|    ep_rew_mean     | -1.89e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1263      |\n",
      "|    time_elapsed    | 4597      |\n",
      "|    total_timesteps | 2586624   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -3.1e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1264        |\n",
      "|    time_elapsed         | 4599        |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018932782 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.538       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 12630       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    std                  | 0.322       |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2590000, episode_reward=-19918.31 +/- 77017.41\n",
      "Episode length: 2523.60 +/- 1207.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.52e+03    |\n",
      "|    mean_reward          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.103440985 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.553       |\n",
      "|    explained_variance   | 0.301       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.1e+05     |\n",
      "|    n_updates            | 12640       |\n",
      "|    policy_gradient_loss | -0.00175    |\n",
      "|    std                  | 0.322       |\n",
      "|    value_loss           | 1.71e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -3.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1265      |\n",
      "|    time_elapsed    | 4606      |\n",
      "|    total_timesteps | 2590720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -3.05e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1266        |\n",
      "|    time_elapsed         | 4608        |\n",
      "|    total_timesteps      | 2592768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011011674 |\n",
      "|    clip_fraction        | 0.0952      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.552       |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52e+07    |\n",
      "|    n_updates            | 12650       |\n",
      "|    policy_gradient_loss | -0.000244   |\n",
      "|    std                  | 0.321       |\n",
      "|    value_loss           | 2.48e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -3.01e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1267        |\n",
      "|    time_elapsed         | 4610        |\n",
      "|    total_timesteps      | 2594816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015473525 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.55        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 12660       |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    std                  | 0.322       |\n",
      "|    value_loss           | 347         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2595000, episode_reward=16262.26 +/- 2662.82\n",
      "Episode length: 3652.80 +/- 6.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.65e+03    |\n",
      "|    mean_reward          | 1.63e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2595000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011557462 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.552       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 12670       |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    std                  | 0.321       |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -2.91e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1268      |\n",
      "|    time_elapsed    | 4621      |\n",
      "|    total_timesteps | 2596864   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -3.58e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1269        |\n",
      "|    time_elapsed         | 4622        |\n",
      "|    total_timesteps      | 2598912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024833342 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.557       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.5        |\n",
      "|    n_updates            | 12680       |\n",
      "|    policy_gradient_loss | 0.00521     |\n",
      "|    std                  | 0.322       |\n",
      "|    value_loss           | 74.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2600000, episode_reward=-22032.88 +/- 81156.73\n",
      "Episode length: 3066.20 +/- 1472.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.07e+03    |\n",
      "|    mean_reward          | -2.2e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006687399 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.555       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.81e+07    |\n",
      "|    n_updates            | 12690       |\n",
      "|    policy_gradient_loss | 0.00122     |\n",
      "|    std                  | 0.322       |\n",
      "|    value_loss           | 3.73e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -3.58e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1270      |\n",
      "|    time_elapsed    | 4631      |\n",
      "|    total_timesteps | 2600960   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -3.64e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1271        |\n",
      "|    time_elapsed         | 4633        |\n",
      "|    total_timesteps      | 2603008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007872198 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.555       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.23e+03    |\n",
      "|    n_updates            | 12700       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 0.321       |\n",
      "|    value_loss           | 3.99e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2605000, episode_reward=-64091.36 +/- 98857.94\n",
      "Episode length: 2168.80 +/- 1676.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.17e+03    |\n",
      "|    mean_reward          | -6.41e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2605000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005230144 |\n",
      "|    clip_fraction        | 0.0193      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.556       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 919         |\n",
      "|    n_updates            | 12710       |\n",
      "|    policy_gradient_loss | -0.00354    |\n",
      "|    std                  | 0.321       |\n",
      "|    value_loss           | 6.06e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -3.57e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1272      |\n",
      "|    time_elapsed    | 4640      |\n",
      "|    total_timesteps | 2605056   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | -3.57e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 561          |\n",
      "|    iterations           | 1273         |\n",
      "|    time_elapsed         | 4642         |\n",
      "|    total_timesteps      | 2607104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051899673 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.558        |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 796          |\n",
      "|    n_updates            | 12720        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    std                  | 0.321        |\n",
      "|    value_loss           | 3.84e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -3.56e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1274        |\n",
      "|    time_elapsed         | 4644        |\n",
      "|    total_timesteps      | 2609152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007548414 |\n",
      "|    clip_fraction        | 0.0886      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.562       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 564         |\n",
      "|    n_updates            | 12730       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    std                  | 0.32        |\n",
      "|    value_loss           | 3.89e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2610000, episode_reward=14329.79 +/- 3845.04\n",
      "Episode length: 3365.20 +/- 5.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.37e+03    |\n",
      "|    mean_reward          | 1.43e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011527977 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.567       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 315         |\n",
      "|    n_updates            | 12740       |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    std                  | 0.32        |\n",
      "|    value_loss           | 1.08e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -3.55e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1275      |\n",
      "|    time_elapsed    | 4654      |\n",
      "|    total_timesteps | 2611200   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -3.49e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1276        |\n",
      "|    time_elapsed         | 4655        |\n",
      "|    total_timesteps      | 2613248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008770576 |\n",
      "|    clip_fraction        | 0.0797      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.569       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 12750       |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    std                  | 0.32        |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2615000, episode_reward=-66796.37 +/- 103192.43\n",
      "Episode length: 2057.20 +/- 1578.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.06e+03    |\n",
      "|    mean_reward          | -6.68e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2615000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009550432 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.568       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 12760       |\n",
      "|    policy_gradient_loss | 0.0033      |\n",
      "|    std                  | 0.319       |\n",
      "|    value_loss           | 1.45e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -7.53e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1277      |\n",
      "|    time_elapsed    | 4662      |\n",
      "|    total_timesteps | 2615296   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | -7.48e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 561          |\n",
      "|    iterations           | 1278         |\n",
      "|    time_elapsed         | 4664         |\n",
      "|    total_timesteps      | 2617344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041063773 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.571        |\n",
      "|    explained_variance   | 0.286        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.58e+07     |\n",
      "|    n_updates            | 12770        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.319        |\n",
      "|    value_loss           | 8.48e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | -9.43e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 561          |\n",
      "|    iterations           | 1279         |\n",
      "|    time_elapsed         | 4666         |\n",
      "|    total_timesteps      | 2619392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127894245 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.572        |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 132          |\n",
      "|    n_updates            | 12780        |\n",
      "|    policy_gradient_loss | -0.000136    |\n",
      "|    std                  | 0.318        |\n",
      "|    value_loss           | 504          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2620000, episode_reward=-68410.83 +/- 100126.52\n",
      "Episode length: 3331.60 +/- 23.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.33e+03    |\n",
      "|    mean_reward          | -6.84e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025544092 |\n",
      "|    clip_fraction        | 0.0721      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.575       |\n",
      "|    explained_variance   | 0.283       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.53e+07    |\n",
      "|    n_updates            | 12790       |\n",
      "|    policy_gradient_loss | 0.00701     |\n",
      "|    std                  | 0.318       |\n",
      "|    value_loss           | 3.13e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.59e+03  |\n",
      "|    ep_rew_mean     | -1.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1280      |\n",
      "|    time_elapsed    | 4675      |\n",
      "|    total_timesteps | 2621440   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | -1.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1281         |\n",
      "|    time_elapsed         | 4677         |\n",
      "|    total_timesteps      | 2623488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006419255 |\n",
      "|    clip_fraction        | 0.00298      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.573        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.23e+06     |\n",
      "|    n_updates            | 12800        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 0.318        |\n",
      "|    value_loss           | 1.91e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2625000, episode_reward=-30698.65 +/- 76199.08\n",
      "Episode length: 2501.60 +/- 1195.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.5e+03     |\n",
      "|    mean_reward          | -3.07e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2625000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005795464 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.573       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.33e+03    |\n",
      "|    n_updates            | 12810       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    std                  | 0.318       |\n",
      "|    value_loss           | 3.76e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.59e+03  |\n",
      "|    ep_rew_mean     | -1.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1282      |\n",
      "|    time_elapsed    | 4685      |\n",
      "|    total_timesteps | 2625536   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | -1.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1283         |\n",
      "|    time_elapsed         | 4687         |\n",
      "|    total_timesteps      | 2627584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032981662 |\n",
      "|    clip_fraction        | 0.00928      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.572        |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.77e+07     |\n",
      "|    n_updates            | 12820        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    std                  | 0.318        |\n",
      "|    value_loss           | 2.91e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | -1.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1284         |\n",
      "|    time_elapsed         | 4689         |\n",
      "|    total_timesteps      | 2629632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070014703 |\n",
      "|    clip_fraction        | 0.0722       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.572        |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.08e+03     |\n",
      "|    n_updates            | 12830        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    std                  | 0.318        |\n",
      "|    value_loss           | 5.78e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2630000, episode_reward=14675.23 +/- 3889.58\n",
      "Episode length: 2325.00 +/- 4.20\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 2.32e+03 |\n",
      "|    mean_reward          | 1.47e+04 |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 2630000  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.019737 |\n",
      "|    clip_fraction        | 0.176    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 0.571    |\n",
      "|    explained_variance   | 0.996    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 52.3     |\n",
      "|    n_updates            | 12840    |\n",
      "|    policy_gradient_loss | 0.00627  |\n",
      "|    std                  | 0.319    |\n",
      "|    value_loss           | 350      |\n",
      "--------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.61e+03  |\n",
      "|    ep_rew_mean     | -1.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1285      |\n",
      "|    time_elapsed    | 4696      |\n",
      "|    total_timesteps | 2631680   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -1.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1286        |\n",
      "|    time_elapsed         | 4698        |\n",
      "|    total_timesteps      | 2633728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014824885 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.576       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.2        |\n",
      "|    n_updates            | 12850       |\n",
      "|    policy_gradient_loss | 0.00778     |\n",
      "|    std                  | 0.318       |\n",
      "|    value_loss           | 230         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2635000, episode_reward=3496.76 +/- 1005.20\n",
      "Episode length: 3144.40 +/- 11.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.14e+03    |\n",
      "|    mean_reward          | 3.5e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2635000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019000012 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.584       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 12860       |\n",
      "|    policy_gradient_loss | 0.00331     |\n",
      "|    std                  | 0.317       |\n",
      "|    value_loss           | 964         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.62e+03  |\n",
      "|    ep_rew_mean     | -1.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1287      |\n",
      "|    time_elapsed    | 4707      |\n",
      "|    total_timesteps | 2635776   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | -1.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1288        |\n",
      "|    time_elapsed         | 4709        |\n",
      "|    total_timesteps      | 2637824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011573954 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.586       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 12870       |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    std                  | 0.317       |\n",
      "|    value_loss           | 9.92e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -1.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 4711        |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011277207 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.596       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.3        |\n",
      "|    n_updates            | 12880       |\n",
      "|    policy_gradient_loss | 0.00255     |\n",
      "|    std                  | 0.316       |\n",
      "|    value_loss           | 715         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2640000, episode_reward=-76979.25 +/- 107791.56\n",
      "Episode length: 1491.00 +/- 1105.96\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.49e+03   |\n",
      "|    mean_reward          | -7.7e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2640000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03853485 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.599      |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.2       |\n",
      "|    n_updates            | 12890      |\n",
      "|    policy_gradient_loss | 0.00625    |\n",
      "|    std                  | 0.316      |\n",
      "|    value_loss           | 249        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.65e+03 |\n",
      "|    ep_rew_mean     | -1.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 560      |\n",
      "|    iterations      | 1290     |\n",
      "|    time_elapsed    | 4716     |\n",
      "|    total_timesteps | 2641920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.66e+03    |\n",
      "|    ep_rew_mean          | -1.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1291        |\n",
      "|    time_elapsed         | 4718        |\n",
      "|    total_timesteps      | 2643968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014733465 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.603       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 12900       |\n",
      "|    policy_gradient_loss | -0.000747   |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 236         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2645000, episode_reward=-41166.34 +/- 83720.88\n",
      "Episode length: 2216.40 +/- 1037.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.22e+03    |\n",
      "|    mean_reward          | -4.12e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2645000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012950953 |\n",
      "|    clip_fraction        | 0.421       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.614       |\n",
      "|    explained_variance   | 0.381       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+06    |\n",
      "|    n_updates            | 12910       |\n",
      "|    policy_gradient_loss | 0.0195      |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 4e+06       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -1.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1292      |\n",
      "|    time_elapsed    | 4725      |\n",
      "|    total_timesteps | 2646016   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.67e+03     |\n",
      "|    ep_rew_mean          | -1.18e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1293         |\n",
      "|    time_elapsed         | 4727         |\n",
      "|    total_timesteps      | 2648064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074912924 |\n",
      "|    clip_fraction        | 0.0573       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.614        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 712          |\n",
      "|    n_updates            | 12920        |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    std                  | 0.315        |\n",
      "|    value_loss           | 1.97e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2650000, episode_reward=6145.63 +/- 4848.06\n",
      "Episode length: 2261.60 +/- 1.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.26e+03    |\n",
      "|    mean_reward          | 6.15e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005680641 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.611       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 779         |\n",
      "|    n_updates            | 12930       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 519         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -1.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1294      |\n",
      "|    time_elapsed    | 4734      |\n",
      "|    total_timesteps | 2650112   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -1.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1295        |\n",
      "|    time_elapsed         | 4736        |\n",
      "|    total_timesteps      | 2652160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014236619 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.605       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.15e+03    |\n",
      "|    n_updates            | 12940       |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    std                  | 0.316       |\n",
      "|    value_loss           | 3.52e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.67e+03     |\n",
      "|    ep_rew_mean          | -1.41e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1296         |\n",
      "|    time_elapsed         | 4737         |\n",
      "|    total_timesteps      | 2654208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069725933 |\n",
      "|    clip_fraction        | 0.0906       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.603        |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 150          |\n",
      "|    n_updates            | 12950        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    std                  | 0.316        |\n",
      "|    value_loss           | 512          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2655000, episode_reward=8272.43 +/- 3778.10\n",
      "Episode length: 2030.80 +/- 5.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.03e+03     |\n",
      "|    mean_reward          | 8.27e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2655000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051729577 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.607        |\n",
      "|    explained_variance   | 0.297        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.6e+06      |\n",
      "|    n_updates            | 12960        |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    std                  | 0.315        |\n",
      "|    value_loss           | 3.16e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1297      |\n",
      "|    time_elapsed    | 4744      |\n",
      "|    total_timesteps | 2656256   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -9.05e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1298        |\n",
      "|    time_elapsed         | 4746        |\n",
      "|    total_timesteps      | 2658304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013587279 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.612       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.88e+04    |\n",
      "|    n_updates            | 12970       |\n",
      "|    policy_gradient_loss | 0.00154     |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 2.99e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2660000, episode_reward=-28798.89 +/- 83366.00\n",
      "Episode length: 1629.80 +/- 754.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.63e+03    |\n",
      "|    mean_reward          | -2.88e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010139039 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.615       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 70.1        |\n",
      "|    n_updates            | 12980       |\n",
      "|    policy_gradient_loss | -0.000938   |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -9.07e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1299      |\n",
      "|    time_elapsed    | 4751      |\n",
      "|    total_timesteps | 2660352   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -9.01e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1300        |\n",
      "|    time_elapsed         | 4753        |\n",
      "|    total_timesteps      | 2662400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018098231 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.632       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 12990       |\n",
      "|    policy_gradient_loss | 0.00234     |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 239         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.72e+03   |\n",
      "|    ep_rew_mean          | -8.69e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 560        |\n",
      "|    iterations           | 1301       |\n",
      "|    time_elapsed         | 4755       |\n",
      "|    total_timesteps      | 2664448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09688142 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.643      |\n",
      "|    explained_variance   | 0.834      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 166        |\n",
      "|    n_updates            | 13000      |\n",
      "|    policy_gradient_loss | 0.00497    |\n",
      "|    std                  | 0.315      |\n",
      "|    value_loss           | 1.68e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2665000, episode_reward=-50958.02 +/- 84302.73\n",
      "Episode length: 1337.60 +/- 1021.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.34e+03    |\n",
      "|    mean_reward          | -5.1e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2665000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013633642 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.631       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 13010       |\n",
      "|    policy_gradient_loss | -0.000888   |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 313         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -9.21e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1302      |\n",
      "|    time_elapsed    | 4760      |\n",
      "|    total_timesteps | 2666496   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | -9.13e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1303        |\n",
      "|    time_elapsed         | 4762        |\n",
      "|    total_timesteps      | 2668544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009299714 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.634       |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.14e+06    |\n",
      "|    n_updates            | 13020       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 1.57e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2670000, episode_reward=15338.45 +/- 3862.35\n",
      "Episode length: 2108.60 +/- 4.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.11e+03    |\n",
      "|    mean_reward          | 1.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015499829 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.634       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 13030       |\n",
      "|    policy_gradient_loss | 0.00206     |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -9.03e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1304      |\n",
      "|    time_elapsed    | 4769      |\n",
      "|    total_timesteps | 2670592   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | -9.1e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1305        |\n",
      "|    time_elapsed         | 4770        |\n",
      "|    total_timesteps      | 2672640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011548023 |\n",
      "|    clip_fraction        | 0.0663      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.637       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 13040       |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 2.95e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -9.15e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1306         |\n",
      "|    time_elapsed         | 4772         |\n",
      "|    total_timesteps      | 2674688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037590556 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.635        |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 13050        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    std                  | 0.314        |\n",
      "|    value_loss           | 1.18e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2675000, episode_reward=16051.82 +/- 2433.55\n",
      "Episode length: 2256.40 +/- 6.92\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.26e+03   |\n",
      "|    mean_reward          | 1.61e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2675000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19240737 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.634      |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 27.9       |\n",
      "|    n_updates            | 13060      |\n",
      "|    policy_gradient_loss | 0.00592    |\n",
      "|    std                  | 0.315      |\n",
      "|    value_loss           | 9.61e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.74e+03  |\n",
      "|    ep_rew_mean     | -1.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1307      |\n",
      "|    time_elapsed    | 4779      |\n",
      "|    total_timesteps | 2676736   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | -1.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1308        |\n",
      "|    time_elapsed         | 4781        |\n",
      "|    total_timesteps      | 2678784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.122292966 |\n",
      "|    clip_fraction        | 0.604       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.64        |\n",
      "|    explained_variance   | 0.279       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.92e+05    |\n",
      "|    n_updates            | 13070       |\n",
      "|    policy_gradient_loss | 0.0388      |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 1.79e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2680000, episode_reward=18292.95 +/- 148.88\n",
      "Episode length: 2048.20 +/- 6.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.05e+03     |\n",
      "|    mean_reward          | 1.83e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2680000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006803235 |\n",
      "|    clip_fraction        | 0.000879     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.641        |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.24e+07     |\n",
      "|    n_updates            | 13080        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    std                  | 0.314        |\n",
      "|    value_loss           | 2.09e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.73e+03 |\n",
      "|    ep_rew_mean     | -1.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 559      |\n",
      "|    iterations      | 1309     |\n",
      "|    time_elapsed    | 4788     |\n",
      "|    total_timesteps | 2680832  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1310        |\n",
      "|    time_elapsed         | 4790        |\n",
      "|    total_timesteps      | 2682880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004893072 |\n",
      "|    clip_fraction        | 0.0167      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.641       |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.43e+06    |\n",
      "|    n_updates            | 13090       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 1.9e+07     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -1.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1311         |\n",
      "|    time_elapsed         | 4791         |\n",
      "|    total_timesteps      | 2684928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028913827 |\n",
      "|    clip_fraction        | 0.00845      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.641        |\n",
      "|    explained_variance   | 0.269        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.69e+06     |\n",
      "|    n_updates            | 13100        |\n",
      "|    policy_gradient_loss | -0.0023      |\n",
      "|    std                  | 0.314        |\n",
      "|    value_loss           | 3.05e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2685000, episode_reward=14294.57 +/- 2888.36\n",
      "Episode length: 1988.20 +/- 11.30\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.99e+03     |\n",
      "|    mean_reward          | 1.43e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2685000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017189342 |\n",
      "|    clip_fraction        | 0.00156      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.642        |\n",
      "|    explained_variance   | 0.312        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.87e+07     |\n",
      "|    n_updates            | 13110        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    std                  | 0.314        |\n",
      "|    value_loss           | 4.67e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1312      |\n",
      "|    time_elapsed    | 4798      |\n",
      "|    total_timesteps | 2686976   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.71e+03     |\n",
      "|    ep_rew_mean          | -1.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1313         |\n",
      "|    time_elapsed         | 4800         |\n",
      "|    total_timesteps      | 2689024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043354686 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.642        |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.62e+03     |\n",
      "|    n_updates            | 13120        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.314        |\n",
      "|    value_loss           | 3.77e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2690000, episode_reward=15420.43 +/- 2881.74\n",
      "Episode length: 1923.80 +/- 13.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.92e+03     |\n",
      "|    mean_reward          | 1.54e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2690000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055486867 |\n",
      "|    clip_fraction        | 0.0483       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.645        |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 825          |\n",
      "|    n_updates            | 13130        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.314        |\n",
      "|    value_loss           | 6.44e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1314      |\n",
      "|    time_elapsed    | 4806      |\n",
      "|    total_timesteps | 2691072   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -1.82e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1315         |\n",
      "|    time_elapsed         | 4808         |\n",
      "|    total_timesteps      | 2693120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040562497 |\n",
      "|    clip_fraction        | 0.0334       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.646        |\n",
      "|    explained_variance   | 0.252        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.6e+07      |\n",
      "|    n_updates            | 13140        |\n",
      "|    policy_gradient_loss | -0.00424     |\n",
      "|    std                  | 0.314        |\n",
      "|    value_loss           | 3.13e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2695000, episode_reward=-57520.48 +/- 91569.32\n",
      "Episode length: 1221.00 +/- 911.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.22e+03    |\n",
      "|    mean_reward          | -5.75e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2695000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007817662 |\n",
      "|    clip_fraction        | 0.0604      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.646       |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.57e+05    |\n",
      "|    n_updates            | 13150       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 1.4e+05     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.71e+03  |\n",
      "|    ep_rew_mean     | -1.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1316      |\n",
      "|    time_elapsed    | 4813      |\n",
      "|    total_timesteps | 2695168   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1317        |\n",
      "|    time_elapsed         | 4814        |\n",
      "|    total_timesteps      | 2697216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010715925 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.648       |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 13160       |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 1.97e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1318        |\n",
      "|    time_elapsed         | 4816        |\n",
      "|    total_timesteps      | 2699264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006891617 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.646       |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.1e+03     |\n",
      "|    n_updates            | 13170       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 1.18e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2700000, episode_reward=14420.16 +/- 3800.37\n",
      "Episode length: 1825.60 +/- 7.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.83e+03     |\n",
      "|    mean_reward          | 1.44e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2700000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068945736 |\n",
      "|    clip_fraction        | 0.056        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.644        |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 82.3         |\n",
      "|    n_updates            | 13180        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    std                  | 0.314        |\n",
      "|    value_loss           | 1.1e+04      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -2.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1319      |\n",
      "|    time_elapsed    | 4822      |\n",
      "|    total_timesteps | 2701312   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -2.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1320        |\n",
      "|    time_elapsed         | 4824        |\n",
      "|    total_timesteps      | 2703360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010224521 |\n",
      "|    clip_fraction        | 0.0425      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.645       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14e+07    |\n",
      "|    n_updates            | 13190       |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 3.21e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2705000, episode_reward=16263.84 +/- 2336.43\n",
      "Episode length: 1827.00 +/- 9.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.83e+03    |\n",
      "|    mean_reward          | 1.63e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2705000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004151319 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.644       |\n",
      "|    explained_variance   | 0.282       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.57e+06    |\n",
      "|    n_updates            | 13200       |\n",
      "|    policy_gradient_loss | -0.00275    |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 3.27e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.67e+03  |\n",
      "|    ep_rew_mean     | -2.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1321      |\n",
      "|    time_elapsed    | 4830      |\n",
      "|    total_timesteps | 2705408   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -2.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1322        |\n",
      "|    time_elapsed         | 4832        |\n",
      "|    total_timesteps      | 2707456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006048735 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.644       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 760         |\n",
      "|    n_updates            | 13210       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -2.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1323        |\n",
      "|    time_elapsed         | 4834        |\n",
      "|    total_timesteps      | 2709504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007722181 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.646       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 245         |\n",
      "|    n_updates            | 13220       |\n",
      "|    policy_gradient_loss | -0.0015     |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 734         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2710000, episode_reward=17536.78 +/- 3128.04\n",
      "Episode length: 1777.80 +/- 3.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.78e+03    |\n",
      "|    mean_reward          | 1.75e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009857023 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.652       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.87e+04    |\n",
      "|    n_updates            | 13230       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    std                  | 0.313       |\n",
      "|    value_loss           | 6.61e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -2.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1324      |\n",
      "|    time_elapsed    | 4840      |\n",
      "|    total_timesteps | 2711552   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.66e+03   |\n",
      "|    ep_rew_mean          | -2.33e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 560        |\n",
      "|    iterations           | 1325       |\n",
      "|    time_elapsed         | 4842       |\n",
      "|    total_timesteps      | 2713600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01440678 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.657      |\n",
      "|    explained_variance   | 0.833      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 180        |\n",
      "|    n_updates            | 13240      |\n",
      "|    policy_gradient_loss | -0.00567   |\n",
      "|    std                  | 0.313      |\n",
      "|    value_loss           | 6.7e+04    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2715000, episode_reward=17440.66 +/- 4561.73\n",
      "Episode length: 1804.20 +/- 9.41\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.8e+03      |\n",
      "|    mean_reward          | 1.74e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2715000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036032647 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.659        |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 276          |\n",
      "|    n_updates            | 13250        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    std                  | 0.313        |\n",
      "|    value_loss           | 2.04e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -2.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1326      |\n",
      "|    time_elapsed    | 4848      |\n",
      "|    total_timesteps | 2715648   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -2.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 4850        |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010968825 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.665       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 255         |\n",
      "|    n_updates            | 13260       |\n",
      "|    policy_gradient_loss | -0.0022     |\n",
      "|    std                  | 0.312       |\n",
      "|    value_loss           | 568         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -2.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1328        |\n",
      "|    time_elapsed         | 4852        |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012440842 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.673       |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 13270       |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    std                  | 0.312       |\n",
      "|    value_loss           | 1.04e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2720000, episode_reward=21974.56 +/- 2498.69\n",
      "Episode length: 2108.00 +/- 7.01\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.11e+03     |\n",
      "|    mean_reward          | 2.2e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066511477 |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.674        |\n",
      "|    explained_variance   | 0.281        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.01e+07     |\n",
      "|    n_updates            | 13280        |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    std                  | 0.312        |\n",
      "|    value_loss           | 1.9e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.67e+03  |\n",
      "|    ep_rew_mean     | -2.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1329      |\n",
      "|    time_elapsed    | 4859      |\n",
      "|    total_timesteps | 2721792   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -2.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1330        |\n",
      "|    time_elapsed         | 4860        |\n",
      "|    total_timesteps      | 2723840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004204273 |\n",
      "|    clip_fraction        | 0.0384      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.674       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.64e+03    |\n",
      "|    n_updates            | 13290       |\n",
      "|    policy_gradient_loss | -0.00655    |\n",
      "|    std                  | 0.312       |\n",
      "|    value_loss           | 3.97e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2725000, episode_reward=21236.85 +/- 3929.37\n",
      "Episode length: 2066.80 +/- 5.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.07e+03     |\n",
      "|    mean_reward          | 2.12e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2725000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063449247 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.676        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+03     |\n",
      "|    n_updates            | 13300        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    std                  | 0.312        |\n",
      "|    value_loss           | 2.43e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -2.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1331      |\n",
      "|    time_elapsed    | 4867      |\n",
      "|    total_timesteps | 2725888   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -2.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1332        |\n",
      "|    time_elapsed         | 4869        |\n",
      "|    total_timesteps      | 2727936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004349472 |\n",
      "|    clip_fraction        | 0.0403      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.677       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 926         |\n",
      "|    n_updates            | 13310       |\n",
      "|    policy_gradient_loss | -0.00635    |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 2.11e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -2.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1333        |\n",
      "|    time_elapsed         | 4871        |\n",
      "|    total_timesteps      | 2729984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008051094 |\n",
      "|    clip_fraction        | 0.0506      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.679       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 796         |\n",
      "|    n_updates            | 13320       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 2.32e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2730000, episode_reward=14677.76 +/- 4878.77\n",
      "Episode length: 1862.40 +/- 11.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.86e+03    |\n",
      "|    mean_reward          | 1.47e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007768601 |\n",
      "|    clip_fraction        | 0.0533      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.681       |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 377         |\n",
      "|    n_updates            | 13330       |\n",
      "|    policy_gradient_loss | -0.0011     |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 1.53e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1334      |\n",
      "|    time_elapsed    | 4877      |\n",
      "|    total_timesteps | 2732032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1335        |\n",
      "|    time_elapsed         | 4879        |\n",
      "|    total_timesteps      | 2734080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004589683 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.685       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 13340       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2735000, episode_reward=17827.35 +/- 2980.52\n",
      "Episode length: 1798.80 +/- 8.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.8e+03     |\n",
      "|    mean_reward          | 1.78e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2735000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009933696 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.69        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 294         |\n",
      "|    n_updates            | 13350       |\n",
      "|    policy_gradient_loss | -0.000271   |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 3.14e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1336      |\n",
      "|    time_elapsed    | 4885      |\n",
      "|    total_timesteps | 2736128   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 4887        |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016342428 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.697       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 89.7        |\n",
      "|    n_updates            | 13360       |\n",
      "|    policy_gradient_loss | 0.00642     |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 583         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2740000, episode_reward=12293.92 +/- 3581.56\n",
      "Episode length: 1720.40 +/- 10.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.72e+03    |\n",
      "|    mean_reward          | 1.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028677367 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.702       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 13370       |\n",
      "|    policy_gradient_loss | 0.00508     |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 321         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1338      |\n",
      "|    time_elapsed    | 4893      |\n",
      "|    total_timesteps | 2740224   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -1.96e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1339        |\n",
      "|    time_elapsed         | 4894        |\n",
      "|    total_timesteps      | 2742272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013455268 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.705       |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 13380       |\n",
      "|    policy_gradient_loss | -0.000975   |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 1.92e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.68e+03   |\n",
      "|    ep_rew_mean          | -1.96e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 560        |\n",
      "|    iterations           | 1340       |\n",
      "|    time_elapsed         | 4896       |\n",
      "|    total_timesteps      | 2744320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01831289 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.71       |\n",
      "|    explained_variance   | 0.967      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.7e+04    |\n",
      "|    n_updates            | 13390      |\n",
      "|    policy_gradient_loss | -0.00332   |\n",
      "|    std                  | 0.311      |\n",
      "|    value_loss           | 2.04e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2745000, episode_reward=13075.51 +/- 127.16\n",
      "Episode length: 1943.40 +/- 5.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.94e+03   |\n",
      "|    mean_reward          | 1.31e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2745000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20599699 |\n",
      "|    clip_fraction        | 0.463      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.714      |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 18.5       |\n",
      "|    n_updates            | 13400      |\n",
      "|    policy_gradient_loss | 0.0387     |\n",
      "|    std                  | 0.311      |\n",
      "|    value_loss           | 9.43e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -1.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1341      |\n",
      "|    time_elapsed    | 4903      |\n",
      "|    total_timesteps | 2746368   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1342        |\n",
      "|    time_elapsed         | 4905        |\n",
      "|    total_timesteps      | 2748416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011910361 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.72        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 13410       |\n",
      "|    policy_gradient_loss | 0.00248     |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 1.05e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2750000, episode_reward=9822.99 +/- 194.86\n",
      "Episode length: 1951.60 +/- 8.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.95e+03     |\n",
      "|    mean_reward          | 9.82e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2750000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042174403 |\n",
      "|    clip_fraction        | 0.0626       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.714        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 117          |\n",
      "|    n_updates            | 13420        |\n",
      "|    policy_gradient_loss | -9.67e-05    |\n",
      "|    std                  | 0.311        |\n",
      "|    value_loss           | 1.65e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.68e+03 |\n",
      "|    ep_rew_mean     | -2e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 560      |\n",
      "|    iterations      | 1343     |\n",
      "|    time_elapsed    | 4911     |\n",
      "|    total_timesteps | 2750464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -2.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1344        |\n",
      "|    time_elapsed         | 4913        |\n",
      "|    total_timesteps      | 2752512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004449307 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.712       |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 244         |\n",
      "|    n_updates            | 13430       |\n",
      "|    policy_gradient_loss | -0.000478   |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 2.92e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -2.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1345        |\n",
      "|    time_elapsed         | 4915        |\n",
      "|    total_timesteps      | 2754560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017518653 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.714       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 13440       |\n",
      "|    policy_gradient_loss | 0.00352     |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 328         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2755000, episode_reward=8951.94 +/- 3734.64\n",
      "Episode length: 2244.40 +/- 4.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.24e+03    |\n",
      "|    mean_reward          | 8.95e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2755000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010859524 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.715       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.9        |\n",
      "|    n_updates            | 13450       |\n",
      "|    policy_gradient_loss | 0.00161     |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -2.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1346      |\n",
      "|    time_elapsed    | 4922      |\n",
      "|    total_timesteps | 2756608   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.7e+03    |\n",
      "|    ep_rew_mean          | -1.9e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 560        |\n",
      "|    iterations           | 1347       |\n",
      "|    time_elapsed         | 4924       |\n",
      "|    total_timesteps      | 2758656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02227814 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.734      |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.6       |\n",
      "|    n_updates            | 13460      |\n",
      "|    policy_gradient_loss | 0.00953    |\n",
      "|    std                  | 0.306      |\n",
      "|    value_loss           | 59.7       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2760000, episode_reward=-2842.62 +/- 2983.32\n",
      "Episode length: 2669.60 +/- 5.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.67e+03    |\n",
      "|    mean_reward          | -2.84e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009297673 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.742       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 13470       |\n",
      "|    policy_gradient_loss | -0.00703    |\n",
      "|    std                  | 0.308       |\n",
      "|    value_loss           | 5.57e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1348      |\n",
      "|    time_elapsed    | 4932      |\n",
      "|    total_timesteps | 2760704   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -1.75e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1349        |\n",
      "|    time_elapsed         | 4934        |\n",
      "|    total_timesteps      | 2762752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008040069 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.733       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.6        |\n",
      "|    n_updates            | 13480       |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.308       |\n",
      "|    value_loss           | 784         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.73e+03   |\n",
      "|    ep_rew_mean          | -1.76e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 560        |\n",
      "|    iterations           | 1350       |\n",
      "|    time_elapsed         | 4936       |\n",
      "|    total_timesteps      | 2764800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01696234 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.733      |\n",
      "|    explained_variance   | 0.983      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.3       |\n",
      "|    n_updates            | 13490      |\n",
      "|    policy_gradient_loss | 0.00423    |\n",
      "|    std                  | 0.308      |\n",
      "|    value_loss           | 1.44e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2765000, episode_reward=1425.95 +/- 3205.54\n",
      "Episode length: 2473.40 +/- 8.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.47e+03   |\n",
      "|    mean_reward          | 1.43e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2765000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00637109 |\n",
      "|    clip_fraction        | 0.0925     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.726      |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 36.3       |\n",
      "|    n_updates            | 13500      |\n",
      "|    policy_gradient_loss | 0.00181    |\n",
      "|    std                  | 0.309      |\n",
      "|    value_loss           | 1.19e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -1.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1351      |\n",
      "|    time_elapsed    | 4943      |\n",
      "|    total_timesteps | 2766848   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -1.82e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1352        |\n",
      "|    time_elapsed         | 4945        |\n",
      "|    total_timesteps      | 2768896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014878885 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.717       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 13510       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.309       |\n",
      "|    value_loss           | 893         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2770000, episode_reward=170.72 +/- 1538.13\n",
      "Episode length: 2396.00 +/- 4.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.4e+03     |\n",
      "|    mean_reward          | 171         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007895647 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.716       |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 181         |\n",
      "|    n_updates            | 13520       |\n",
      "|    policy_gradient_loss | -0.000564   |\n",
      "|    std                  | 0.309       |\n",
      "|    value_loss           | 7.89e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -1.71e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1353      |\n",
      "|    time_elapsed    | 4953      |\n",
      "|    total_timesteps | 2770944   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 559          |\n",
      "|    iterations           | 1354         |\n",
      "|    time_elapsed         | 4954         |\n",
      "|    total_timesteps      | 2772992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072846496 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.715        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 360          |\n",
      "|    n_updates            | 13530        |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    std                  | 0.309        |\n",
      "|    value_loss           | 8.4e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2775000, episode_reward=1518.80 +/- 2966.87\n",
      "Episode length: 2434.80 +/- 5.88\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.43e+03   |\n",
      "|    mean_reward          | 1.52e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2775000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02321212 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.716      |\n",
      "|    explained_variance   | 0.857      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 654        |\n",
      "|    n_updates            | 13540      |\n",
      "|    policy_gradient_loss | -0.000229  |\n",
      "|    std                  | 0.309      |\n",
      "|    value_loss           | 1.57e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -1.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1355      |\n",
      "|    time_elapsed    | 4962      |\n",
      "|    total_timesteps | 2775040   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -1.66e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 4964        |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015871916 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.713       |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.24e+05    |\n",
      "|    n_updates            | 13550       |\n",
      "|    policy_gradient_loss | -0.000412   |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 8.34e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1357        |\n",
      "|    time_elapsed         | 4966        |\n",
      "|    total_timesteps      | 2779136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048041187 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.712       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 13560       |\n",
      "|    policy_gradient_loss | 0.00213     |\n",
      "|    std                  | 0.309       |\n",
      "|    value_loss           | 7.79e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2780000, episode_reward=-28847.57 +/- 73502.39\n",
      "Episode length: 1712.60 +/- 800.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.71e+03    |\n",
      "|    mean_reward          | -2.88e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006726473 |\n",
      "|    clip_fraction        | 0.0539      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.714       |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 13570       |\n",
      "|    policy_gradient_loss | -0.000177   |\n",
      "|    std                  | 0.309       |\n",
      "|    value_loss           | 1.25e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.7e+03  |\n",
      "|    ep_rew_mean     | -1.7e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 559      |\n",
      "|    iterations      | 1358     |\n",
      "|    time_elapsed    | 4972     |\n",
      "|    total_timesteps | 2781184  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.69e+03   |\n",
      "|    ep_rew_mean          | -1.72e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 559        |\n",
      "|    iterations           | 1359       |\n",
      "|    time_elapsed         | 4974       |\n",
      "|    total_timesteps      | 2783232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02656303 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.712      |\n",
      "|    explained_variance   | 0.624      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.89e+06   |\n",
      "|    n_updates            | 13580      |\n",
      "|    policy_gradient_loss | 0.00259    |\n",
      "|    std                  | 0.31       |\n",
      "|    value_loss           | 1.44e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2785000, episode_reward=6301.19 +/- 3998.42\n",
      "Episode length: 2012.20 +/- 8.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.01e+03    |\n",
      "|    mean_reward          | 6.3e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2785000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008636112 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.71        |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.52e+07    |\n",
      "|    n_updates            | 13590       |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 3.15e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1360      |\n",
      "|    time_elapsed    | 4980      |\n",
      "|    total_timesteps | 2785280   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -1.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1361        |\n",
      "|    time_elapsed         | 4982        |\n",
      "|    total_timesteps      | 2787328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012824722 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.711       |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 352         |\n",
      "|    n_updates            | 13600       |\n",
      "|    policy_gradient_loss | 0.00675     |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 654         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1362        |\n",
      "|    time_elapsed         | 4984        |\n",
      "|    total_timesteps      | 2789376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017085705 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.708       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.7        |\n",
      "|    n_updates            | 13610       |\n",
      "|    policy_gradient_loss | -0.001      |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 1.16e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2790000, episode_reward=10711.88 +/- 4669.60\n",
      "Episode length: 1999.00 +/- 7.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | 1.07e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010280605 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.707       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 13620       |\n",
      "|    policy_gradient_loss | 0.00297     |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 344         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.71e+03  |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1363      |\n",
      "|    time_elapsed    | 4990      |\n",
      "|    total_timesteps | 2791424   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1364        |\n",
      "|    time_elapsed         | 4992        |\n",
      "|    total_timesteps      | 2793472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010918584 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.708       |\n",
      "|    explained_variance   | 0.664       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.51e+03    |\n",
      "|    n_updates            | 13630       |\n",
      "|    policy_gradient_loss | -0.000216   |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 1.82e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2795000, episode_reward=9958.27 +/- 3297.37\n",
      "Episode length: 1994.80 +/- 5.64\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.99e+03     |\n",
      "|    mean_reward          | 9.96e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2795000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040697763 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.704        |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.83e+06     |\n",
      "|    n_updates            | 13640        |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    std                  | 0.311        |\n",
      "|    value_loss           | 3.21e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1365      |\n",
      "|    time_elapsed    | 4999      |\n",
      "|    total_timesteps | 2795520   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -1.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 5001        |\n",
      "|    total_timesteps      | 2797568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011940435 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.71        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.1        |\n",
      "|    n_updates            | 13650       |\n",
      "|    policy_gradient_loss | 0.00279     |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 321         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -1.49e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1367        |\n",
      "|    time_elapsed         | 5003        |\n",
      "|    total_timesteps      | 2799616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015415698 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.724       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 13660       |\n",
      "|    policy_gradient_loss | 0.0023      |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2800000, episode_reward=8416.42 +/- 4953.95\n",
      "Episode length: 1606.80 +/- 8.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.61e+03    |\n",
      "|    mean_reward          | 8.42e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009507125 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.73        |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2e+07       |\n",
      "|    n_updates            | 13670       |\n",
      "|    policy_gradient_loss | -0.00303    |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 4.81e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -1.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1368      |\n",
      "|    time_elapsed    | 5008      |\n",
      "|    total_timesteps | 2801664   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.64e+03     |\n",
      "|    ep_rew_mean          | -1.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 559          |\n",
      "|    iterations           | 1369         |\n",
      "|    time_elapsed         | 5010         |\n",
      "|    total_timesteps      | 2803712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056366134 |\n",
      "|    clip_fraction        | 0.146        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.709        |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 13680        |\n",
      "|    policy_gradient_loss | 0.00803      |\n",
      "|    std                  | 0.314        |\n",
      "|    value_loss           | 356          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2805000, episode_reward=11945.97 +/- 4159.29\n",
      "Episode length: 1408.60 +/- 15.63\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.41e+03     |\n",
      "|    mean_reward          | 1.19e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2805000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050388067 |\n",
      "|    clip_fraction        | 0.0953       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.689        |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 91.3         |\n",
      "|    n_updates            | 13690        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    std                  | 0.315        |\n",
      "|    value_loss           | 9.76e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -1.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1370      |\n",
      "|    time_elapsed    | 5015      |\n",
      "|    total_timesteps | 2805760   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -1.42e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1371        |\n",
      "|    time_elapsed         | 5017        |\n",
      "|    total_timesteps      | 2807808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009950792 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.686       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 13700       |\n",
      "|    policy_gradient_loss | 0.00746     |\n",
      "|    std                  | 0.316       |\n",
      "|    value_loss           | 8.52e+03    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | -1.42e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 559          |\n",
      "|    iterations           | 1372         |\n",
      "|    time_elapsed         | 5019         |\n",
      "|    total_timesteps      | 2809856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078514395 |\n",
      "|    clip_fraction        | 0.0668       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.689        |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 108          |\n",
      "|    n_updates            | 13710        |\n",
      "|    policy_gradient_loss | 5.48e-05     |\n",
      "|    std                  | 0.315        |\n",
      "|    value_loss           | 1.24e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2810000, episode_reward=8080.36 +/- 4803.47\n",
      "Episode length: 1539.60 +/- 10.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.54e+03    |\n",
      "|    mean_reward          | 8.08e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007299705 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.692       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 13720       |\n",
      "|    policy_gradient_loss | 0.00209     |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 378         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.6e+03  |\n",
      "|    ep_rew_mean     | -1.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 559      |\n",
      "|    iterations      | 1373     |\n",
      "|    time_elapsed    | 5024     |\n",
      "|    total_timesteps | 2811904  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -1.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1374        |\n",
      "|    time_elapsed         | 5026        |\n",
      "|    total_timesteps      | 2813952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009695152 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.695       |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 302         |\n",
      "|    n_updates            | 13730       |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 1.19e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2815000, episode_reward=11949.52 +/- 6650.25\n",
      "Episode length: 1565.20 +/- 6.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.57e+03    |\n",
      "|    mean_reward          | 1.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2815000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013936373 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.697       |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80.1        |\n",
      "|    n_updates            | 13740       |\n",
      "|    policy_gradient_loss | 0.00192     |\n",
      "|    std                  | 0.315       |\n",
      "|    value_loss           | 351         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.61e+03  |\n",
      "|    ep_rew_mean     | -1.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1375      |\n",
      "|    time_elapsed    | 5032      |\n",
      "|    total_timesteps | 2816000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | -1.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1376        |\n",
      "|    time_elapsed         | 5034        |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012043762 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.703       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.31e+05    |\n",
      "|    n_updates            | 13750       |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2820000, episode_reward=13578.43 +/- 6358.41\n",
      "Episode length: 1546.80 +/- 10.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.55e+03    |\n",
      "|    mean_reward          | 1.36e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012021953 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.71        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 222         |\n",
      "|    n_updates            | 13760       |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 8.74e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.59e+03  |\n",
      "|    ep_rew_mean     | -1.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1377      |\n",
      "|    time_elapsed    | 5039      |\n",
      "|    total_timesteps | 2820096   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | -1.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 5041        |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018680692 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.704       |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 13770       |\n",
      "|    policy_gradient_loss | 0.014       |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 433         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -1.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1379        |\n",
      "|    time_elapsed         | 5043        |\n",
      "|    total_timesteps      | 2824192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020901434 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.709       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 13780       |\n",
      "|    policy_gradient_loss | 0.0038      |\n",
      "|    std                  | 0.314       |\n",
      "|    value_loss           | 213         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2825000, episode_reward=13822.55 +/- 4527.92\n",
      "Episode length: 1436.40 +/- 12.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.44e+03    |\n",
      "|    mean_reward          | 1.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2825000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015037145 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.731       |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 13790       |\n",
      "|    policy_gradient_loss | 0.00467     |\n",
      "|    std                  | 0.312       |\n",
      "|    value_loss           | 56.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -1.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1380      |\n",
      "|    time_elapsed    | 5048      |\n",
      "|    total_timesteps | 2826240   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -1.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1381        |\n",
      "|    time_elapsed         | 5050        |\n",
      "|    total_timesteps      | 2828288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016420549 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.746       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.6        |\n",
      "|    n_updates            | 13800       |\n",
      "|    policy_gradient_loss | 0.00151     |\n",
      "|    std                  | 0.312       |\n",
      "|    value_loss           | 1.03e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2830000, episode_reward=-97341.86 +/- 89198.65\n",
      "Episode length: 641.60 +/- 657.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 642         |\n",
      "|    mean_reward          | -9.73e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037133757 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.756       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.76        |\n",
      "|    n_updates            | 13810       |\n",
      "|    policy_gradient_loss | 0.00619     |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 3.34e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -1.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1382      |\n",
      "|    time_elapsed    | 5053      |\n",
      "|    total_timesteps | 2830336   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | -1.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1383         |\n",
      "|    time_elapsed         | 5055         |\n",
      "|    total_timesteps      | 2832384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071370443 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.766        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 60.1         |\n",
      "|    n_updates            | 13820        |\n",
      "|    policy_gradient_loss | 0.00257      |\n",
      "|    std                  | 0.311        |\n",
      "|    value_loss           | 3.36e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -8.99e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1384        |\n",
      "|    time_elapsed         | 5057        |\n",
      "|    total_timesteps      | 2834432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010343681 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.761       |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.51e+07    |\n",
      "|    n_updates            | 13830       |\n",
      "|    policy_gradient_loss | 0.00144     |\n",
      "|    std                  | 0.311       |\n",
      "|    value_loss           | 2.38e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2835000, episode_reward=-56759.31 +/- 85559.79\n",
      "Episode length: 938.60 +/- 686.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 939         |\n",
      "|    mean_reward          | -5.68e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2835000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022431672 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.762       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.1        |\n",
      "|    n_updates            | 13840       |\n",
      "|    policy_gradient_loss | 0.00586     |\n",
      "|    std                  | 0.31        |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -6.97e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1385      |\n",
      "|    time_elapsed    | 5061      |\n",
      "|    total_timesteps | 2836480   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | -5.85e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1386         |\n",
      "|    time_elapsed         | 5063         |\n",
      "|    total_timesteps      | 2838528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057627913 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.767        |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 162          |\n",
      "|    n_updates            | 13850        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    std                  | 0.31         |\n",
      "|    value_loss           | 1.29e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2840000, episode_reward=-50340.26 +/- 88603.99\n",
      "Episode length: 1047.40 +/- 775.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.05e+03    |\n",
      "|    mean_reward          | -5.03e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012067845 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.774       |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.8        |\n",
      "|    n_updates            | 13860       |\n",
      "|    policy_gradient_loss | 0.00469     |\n",
      "|    std                  | 0.309       |\n",
      "|    value_loss           | 3.86e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.55e+03  |\n",
      "|    ep_rew_mean     | -4.27e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1387      |\n",
      "|    time_elapsed    | 5067      |\n",
      "|    total_timesteps | 2840576   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -5.99e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1388        |\n",
      "|    time_elapsed         | 5069        |\n",
      "|    total_timesteps      | 2842624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011466428 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.777       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 13870       |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    std                  | 0.308       |\n",
      "|    value_loss           | 1.93e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | -5.82e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1389         |\n",
      "|    time_elapsed         | 5071         |\n",
      "|    total_timesteps      | 2844672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061811614 |\n",
      "|    clip_fraction        | 0.0593       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.782        |\n",
      "|    explained_variance   | 0.32         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+07     |\n",
      "|    n_updates            | 13880        |\n",
      "|    policy_gradient_loss | -0.000877    |\n",
      "|    std                  | 0.308        |\n",
      "|    value_loss           | 2.31e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2845000, episode_reward=-10899.40 +/- 68082.97\n",
      "Episode length: 1376.20 +/- 645.66\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.38e+03   |\n",
      "|    mean_reward          | -1.09e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2845000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06114064 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.782      |\n",
      "|    explained_variance   | 0.325      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.83e+07   |\n",
      "|    n_updates            | 13890      |\n",
      "|    policy_gradient_loss | 0.0127     |\n",
      "|    std                  | 0.308      |\n",
      "|    value_loss           | 2.3e+07    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -7.06e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1390      |\n",
      "|    time_elapsed    | 5076      |\n",
      "|    total_timesteps | 2846720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -7.98e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1391        |\n",
      "|    time_elapsed         | 5077        |\n",
      "|    total_timesteps      | 2848768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015636377 |\n",
      "|    clip_fraction        | 0.0935      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.781       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.13e+07    |\n",
      "|    n_updates            | 13900       |\n",
      "|    policy_gradient_loss | 0.00839     |\n",
      "|    std                  | 0.308       |\n",
      "|    value_loss           | 2.25e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2850000, episode_reward=16625.38 +/- 6374.95\n",
      "Episode length: 1656.80 +/- 13.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.66e+03     |\n",
      "|    mean_reward          | 1.66e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2850000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028309557 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.782        |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.16e+07     |\n",
      "|    n_updates            | 13910        |\n",
      "|    policy_gradient_loss | -0.00439     |\n",
      "|    std                  | 0.308        |\n",
      "|    value_loss           | 1.85e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.49e+03 |\n",
      "|    ep_rew_mean     | -8.2e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 560      |\n",
      "|    iterations      | 1392     |\n",
      "|    time_elapsed    | 5083     |\n",
      "|    total_timesteps | 2850816  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | -6.09e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 560          |\n",
      "|    iterations           | 1393         |\n",
      "|    time_elapsed         | 5085         |\n",
      "|    total_timesteps      | 2852864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002667614 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.782        |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.42e+07     |\n",
      "|    n_updates            | 13920        |\n",
      "|    policy_gradient_loss | 0.000307     |\n",
      "|    std                  | 0.308        |\n",
      "|    value_loss           | 3.66e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.49e+03      |\n",
      "|    ep_rew_mean          | -7.03e+03     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 561           |\n",
      "|    iterations           | 1394          |\n",
      "|    time_elapsed         | 5087          |\n",
      "|    total_timesteps      | 2854912       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028762038 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 0.782         |\n",
      "|    explained_variance   | 0.392         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.77e+05      |\n",
      "|    n_updates            | 13930         |\n",
      "|    policy_gradient_loss | -0.000879     |\n",
      "|    std                  | 0.308         |\n",
      "|    value_loss           | 3.01e+06      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=2855000, episode_reward=18032.49 +/- 7770.29\n",
      "Episode length: 1605.80 +/- 23.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.61e+03    |\n",
      "|    mean_reward          | 1.8e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2855000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004335818 |\n",
      "|    clip_fraction        | 0.0333      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.782       |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.39e+06    |\n",
      "|    n_updates            | 13940       |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    std                  | 0.308       |\n",
      "|    value_loss           | 9.52e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -6.96e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1395      |\n",
      "|    time_elapsed    | 5092      |\n",
      "|    total_timesteps | 2856960   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.49e+03     |\n",
      "|    ep_rew_mean          | -6.78e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 561          |\n",
      "|    iterations           | 1396         |\n",
      "|    time_elapsed         | 5094         |\n",
      "|    total_timesteps      | 2859008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056362236 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.782        |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 621          |\n",
      "|    n_updates            | 13950        |\n",
      "|    policy_gradient_loss | -0.00269     |\n",
      "|    std                  | 0.309        |\n",
      "|    value_loss           | 2.3e+03      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2860000, episode_reward=17647.92 +/- 7171.15\n",
      "Episode length: 1500.00 +/- 5.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.5e+03     |\n",
      "|    mean_reward          | 1.76e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011492722 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.786       |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+03    |\n",
      "|    n_updates            | 13960       |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    std                  | 0.308       |\n",
      "|    value_loss           | 3.05e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -6.64e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1397      |\n",
      "|    time_elapsed    | 5100      |\n",
      "|    total_timesteps | 2861056   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.46e+03   |\n",
      "|    ep_rew_mean          | -8.08e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 561        |\n",
      "|    iterations           | 1398       |\n",
      "|    time_elapsed         | 5101       |\n",
      "|    total_timesteps      | 2863104    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07535743 |\n",
      "|    clip_fraction        | 0.345      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.807      |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19.5       |\n",
      "|    n_updates            | 13970      |\n",
      "|    policy_gradient_loss | 0.0111     |\n",
      "|    std                  | 0.305      |\n",
      "|    value_loss           | 1.04e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2865000, episode_reward=-45221.10 +/- 84472.45\n",
      "Episode length: 1003.20 +/- 742.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+03       |\n",
      "|    mean_reward          | -4.52e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2865000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020430502 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.832       |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.06e+06    |\n",
      "|    n_updates            | 13980       |\n",
      "|    policy_gradient_loss | 0.00545     |\n",
      "|    std                  | 0.305       |\n",
      "|    value_loss           | 2.06e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -6.87e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1399      |\n",
      "|    time_elapsed    | 5106      |\n",
      "|    total_timesteps | 2865152   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | -6.85e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1400        |\n",
      "|    time_elapsed         | 5107        |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015135509 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.84        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.6        |\n",
      "|    n_updates            | 13990       |\n",
      "|    policy_gradient_loss | 0.00699     |\n",
      "|    std                  | 0.305       |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | -6.84e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1401        |\n",
      "|    time_elapsed         | 5109        |\n",
      "|    total_timesteps      | 2869248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015550943 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.86        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.5        |\n",
      "|    n_updates            | 14000       |\n",
      "|    policy_gradient_loss | 0.00511     |\n",
      "|    std                  | 0.305       |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2870000, episode_reward=-16391.39 +/- 70384.59\n",
      "Episode length: 1450.40 +/- 679.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.45e+03    |\n",
      "|    mean_reward          | -1.64e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010354254 |\n",
      "|    clip_fraction        | 0.0903      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.87        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 14010       |\n",
      "|    policy_gradient_loss | -0.00415    |\n",
      "|    std                  | 0.304       |\n",
      "|    value_loss           | 709         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -6.74e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1402      |\n",
      "|    time_elapsed    | 5115      |\n",
      "|    total_timesteps | 2871296   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.44e+03   |\n",
      "|    ep_rew_mean          | -6.62e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 561        |\n",
      "|    iterations           | 1403       |\n",
      "|    time_elapsed         | 5116       |\n",
      "|    total_timesteps      | 2873344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01583153 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.873      |\n",
      "|    explained_variance   | 0.828      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 105        |\n",
      "|    n_updates            | 14020      |\n",
      "|    policy_gradient_loss | -0.00341   |\n",
      "|    std                  | 0.304      |\n",
      "|    value_loss           | 5.18e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2875000, episode_reward=26414.46 +/- 1754.21\n",
      "Episode length: 1813.80 +/- 9.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.81e+03    |\n",
      "|    mean_reward          | 2.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2875000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018041411 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.882       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 14030       |\n",
      "|    policy_gradient_loss | 0.000117    |\n",
      "|    std                  | 0.3         |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -6.57e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1404      |\n",
      "|    time_elapsed    | 5122      |\n",
      "|    total_timesteps | 2875392   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -6.48e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1405        |\n",
      "|    time_elapsed         | 5124        |\n",
      "|    total_timesteps      | 2877440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023169043 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.877       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.5        |\n",
      "|    n_updates            | 14040       |\n",
      "|    policy_gradient_loss | 0.0046      |\n",
      "|    std                  | 0.302       |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | -8.74e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1406        |\n",
      "|    time_elapsed         | 5126        |\n",
      "|    total_timesteps      | 2879488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014693126 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.868       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.3        |\n",
      "|    n_updates            | 14050       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    std                  | 0.301       |\n",
      "|    value_loss           | 278         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2880000, episode_reward=-10725.50 +/- 66904.24\n",
      "Episode length: 1595.40 +/- 752.55\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6e+03      |\n",
      "|    mean_reward          | -1.07e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054175793 |\n",
      "|    clip_fraction        | 0.106        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.876        |\n",
      "|    explained_variance   | 0.333        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.68e+07     |\n",
      "|    n_updates            | 14060        |\n",
      "|    policy_gradient_loss | 0.00114      |\n",
      "|    std                  | 0.301        |\n",
      "|    value_loss           | 3.18e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.42e+03  |\n",
      "|    ep_rew_mean     | -8.68e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1407      |\n",
      "|    time_elapsed    | 5132      |\n",
      "|    total_timesteps | 2881536   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.42e+03     |\n",
      "|    ep_rew_mean          | -9.39e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 561          |\n",
      "|    iterations           | 1408         |\n",
      "|    time_elapsed         | 5133         |\n",
      "|    total_timesteps      | 2883584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069648884 |\n",
      "|    clip_fraction        | 0.0976       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.877        |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 153          |\n",
      "|    n_updates            | 14070        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    std                  | 0.3          |\n",
      "|    value_loss           | 1.14e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2885000, episode_reward=-13032.35 +/- 68446.98\n",
      "Episode length: 1454.20 +/- 682.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.45e+03    |\n",
      "|    mean_reward          | -1.3e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2885000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004233869 |\n",
      "|    clip_fraction        | 0.0407      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.879       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+05    |\n",
      "|    n_updates            | 14080       |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    std                  | 0.3         |\n",
      "|    value_loss           | 1.19e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.4e+03   |\n",
      "|    ep_rew_mean     | -1.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1409      |\n",
      "|    time_elapsed    | 5139      |\n",
      "|    total_timesteps | 2885632   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.4e+03      |\n",
      "|    ep_rew_mean          | -1.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 561          |\n",
      "|    iterations           | 1410         |\n",
      "|    time_elapsed         | 5141         |\n",
      "|    total_timesteps      | 2887680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022886053 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.878        |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.53e+07     |\n",
      "|    n_updates            | 14090        |\n",
      "|    policy_gradient_loss | -0.00895     |\n",
      "|    std                  | 0.3          |\n",
      "|    value_loss           | 4.27e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | -1.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1411        |\n",
      "|    time_elapsed         | 5142        |\n",
      "|    total_timesteps      | 2889728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011714604 |\n",
      "|    clip_fraction        | 0.0153      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.878       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.58e+06    |\n",
      "|    n_updates            | 14100       |\n",
      "|    policy_gradient_loss | 0.000591    |\n",
      "|    std                  | 0.3         |\n",
      "|    value_loss           | 1.48e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2890000, episode_reward=-16286.22 +/- 69015.34\n",
      "Episode length: 1474.40 +/- 692.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.47e+03     |\n",
      "|    mean_reward          | -1.63e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2890000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055610156 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.878        |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11e+07     |\n",
      "|    n_updates            | 14110        |\n",
      "|    policy_gradient_loss | -8.31e-05    |\n",
      "|    std                  | 0.3          |\n",
      "|    value_loss           | 2.21e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.38e+03  |\n",
      "|    ep_rew_mean     | -1.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1412      |\n",
      "|    time_elapsed    | 5148      |\n",
      "|    total_timesteps | 2891776   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.38e+03     |\n",
      "|    ep_rew_mean          | -1.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 561          |\n",
      "|    iterations           | 1413         |\n",
      "|    time_elapsed         | 5149         |\n",
      "|    total_timesteps      | 2893824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041709724 |\n",
      "|    clip_fraction        | 0.0299       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 0.88         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.74e+03     |\n",
      "|    n_updates            | 14120        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    std                  | 0.3          |\n",
      "|    value_loss           | 1.39e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2895000, episode_reward=-18448.12 +/- 68944.52\n",
      "Episode length: 1450.20 +/- 676.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.45e+03    |\n",
      "|    mean_reward          | -1.84e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2895000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008051635 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.88        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.46e+03    |\n",
      "|    n_updates            | 14130       |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    std                  | 0.3         |\n",
      "|    value_loss           | 2.59e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.37e+03  |\n",
      "|    ep_rew_mean     | -1.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1414      |\n",
      "|    time_elapsed    | 5155      |\n",
      "|    total_timesteps | 2895872   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | -1.48e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1415        |\n",
      "|    time_elapsed         | 5157        |\n",
      "|    total_timesteps      | 2897920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009610716 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.883       |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 14140       |\n",
      "|    policy_gradient_loss | 0.00185     |\n",
      "|    std                  | 0.299       |\n",
      "|    value_loss           | 462         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | -1.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 5158        |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028247263 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.88        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.5        |\n",
      "|    n_updates            | 14150       |\n",
      "|    policy_gradient_loss | 0.00759     |\n",
      "|    std                  | 0.3         |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2900000, episode_reward=20382.06 +/- 4509.84\n",
      "Episode length: 1679.80 +/- 14.61\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.68e+03   |\n",
      "|    mean_reward          | 2.04e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2900000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20033522 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.874      |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.95e+06   |\n",
      "|    n_updates            | 14160      |\n",
      "|    policy_gradient_loss | 0.0127     |\n",
      "|    std                  | 0.3        |\n",
      "|    value_loss           | 2.42e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -1.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1417      |\n",
      "|    time_elapsed    | 5164      |\n",
      "|    total_timesteps | 2902016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | -1.61e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1418        |\n",
      "|    time_elapsed         | 5166        |\n",
      "|    total_timesteps      | 2904064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009554464 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.872       |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 14170       |\n",
      "|    policy_gradient_loss | 0.00711     |\n",
      "|    std                  | 0.3         |\n",
      "|    value_loss           | 2.63e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2905000, episode_reward=18458.65 +/- 6622.58\n",
      "Episode length: 1615.40 +/- 13.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.62e+03    |\n",
      "|    mean_reward          | 1.85e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2905000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015666714 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.865       |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38          |\n",
      "|    n_updates            | 14180       |\n",
      "|    policy_gradient_loss | 0.00431     |\n",
      "|    std                  | 0.3         |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | -1.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 561      |\n",
      "|    iterations      | 1419     |\n",
      "|    time_elapsed    | 5172     |\n",
      "|    total_timesteps | 2906112  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | -1.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1420        |\n",
      "|    time_elapsed         | 5173        |\n",
      "|    total_timesteps      | 2908160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042440094 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.858       |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66          |\n",
      "|    n_updates            | 14190       |\n",
      "|    policy_gradient_loss | 0.0152      |\n",
      "|    std                  | 0.301       |\n",
      "|    value_loss           | 5.98e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2910000, episode_reward=16491.49 +/- 5941.19\n",
      "Episode length: 1543.80 +/- 9.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.54e+03    |\n",
      "|    mean_reward          | 1.65e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011331592 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.858       |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 70.7        |\n",
      "|    n_updates            | 14200       |\n",
      "|    policy_gradient_loss | 0.00522     |\n",
      "|    std                  | 0.302       |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.32e+03  |\n",
      "|    ep_rew_mean     | -1.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1421      |\n",
      "|    time_elapsed    | 5179      |\n",
      "|    total_timesteps | 2910208   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | -1.66e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1422        |\n",
      "|    time_elapsed         | 5181        |\n",
      "|    total_timesteps      | 2912256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005593961 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.851       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+07    |\n",
      "|    n_updates            | 14210       |\n",
      "|    policy_gradient_loss | 0.00173     |\n",
      "|    std                  | 0.302       |\n",
      "|    value_loss           | 2.11e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | -1.65e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1423        |\n",
      "|    time_elapsed         | 5183        |\n",
      "|    total_timesteps      | 2914304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017131925 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.853       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 14220       |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    std                  | 0.301       |\n",
      "|    value_loss           | 1.07e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2915000, episode_reward=15286.52 +/- 5140.44\n",
      "Episode length: 1560.00 +/- 13.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.56e+03    |\n",
      "|    mean_reward          | 1.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2915000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006533599 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.86        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96          |\n",
      "|    n_updates            | 14230       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    std                  | 0.301       |\n",
      "|    value_loss           | 3.41e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.31e+03  |\n",
      "|    ep_rew_mean     | -1.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1424      |\n",
      "|    time_elapsed    | 5188      |\n",
      "|    total_timesteps | 2916352   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.31e+03  |\n",
      "|    ep_rew_mean          | -1.57e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 562       |\n",
      "|    iterations           | 1425      |\n",
      "|    time_elapsed         | 5190      |\n",
      "|    total_timesteps      | 2918400   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0993337 |\n",
      "|    clip_fraction        | 0.142     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 0.85      |\n",
      "|    explained_variance   | 0.347     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.67e+06  |\n",
      "|    n_updates            | 14240     |\n",
      "|    policy_gradient_loss | 0.0151    |\n",
      "|    std                  | 0.303     |\n",
      "|    value_loss           | 1.78e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2920000, episode_reward=14284.01 +/- 5763.05\n",
      "Episode length: 1419.80 +/- 11.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.42e+03    |\n",
      "|    mean_reward          | 1.43e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029842222 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.824       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.31e+05    |\n",
      "|    n_updates            | 14250       |\n",
      "|    policy_gradient_loss | 0.0105      |\n",
      "|    std                  | 0.304       |\n",
      "|    value_loss           | 1.93e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.3e+03   |\n",
      "|    ep_rew_mean     | -1.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1426      |\n",
      "|    time_elapsed    | 5195      |\n",
      "|    total_timesteps | 2920448   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.3e+03     |\n",
      "|    ep_rew_mean          | -1.49e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1427        |\n",
      "|    time_elapsed         | 5197        |\n",
      "|    total_timesteps      | 2922496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006321541 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.82        |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8e+03       |\n",
      "|    n_updates            | 14260       |\n",
      "|    policy_gradient_loss | -0.00101    |\n",
      "|    std                  | 0.304       |\n",
      "|    value_loss           | 1.01e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.31e+03   |\n",
      "|    ep_rew_mean          | -1.34e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 562        |\n",
      "|    iterations           | 1428       |\n",
      "|    time_elapsed         | 5199       |\n",
      "|    total_timesteps      | 2924544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05453674 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.823      |\n",
      "|    explained_variance   | 0.932      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14.9       |\n",
      "|    n_updates            | 14270      |\n",
      "|    policy_gradient_loss | 0.00559    |\n",
      "|    std                  | 0.305      |\n",
      "|    value_loss           | 3.51e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2925000, episode_reward=17190.39 +/- 8210.54\n",
      "Episode length: 1514.60 +/- 24.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.51e+03    |\n",
      "|    mean_reward          | 1.72e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2925000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008730408 |\n",
      "|    clip_fraction        | 0.0598      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.825       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 297         |\n",
      "|    n_updates            | 14280       |\n",
      "|    policy_gradient_loss | 0.00139     |\n",
      "|    std                  | 0.305       |\n",
      "|    value_loss           | 1.63e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.31e+03  |\n",
      "|    ep_rew_mean     | -1.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1429      |\n",
      "|    time_elapsed    | 5204      |\n",
      "|    total_timesteps | 2926592   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.31e+03    |\n",
      "|    ep_rew_mean          | -1.34e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1430        |\n",
      "|    time_elapsed         | 5206        |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027287547 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.832       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 14290       |\n",
      "|    policy_gradient_loss | 0.00631     |\n",
      "|    std                  | 0.304       |\n",
      "|    value_loss           | 60.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2930000, episode_reward=19973.52 +/- 2250.99\n",
      "Episode length: 1471.40 +/- 9.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.47e+03    |\n",
      "|    mean_reward          | 2e+04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026267491 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.837       |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 14300       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    std                  | 0.304       |\n",
      "|    value_loss           | 1.08e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.32e+03  |\n",
      "|    ep_rew_mean     | -1.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1431      |\n",
      "|    time_elapsed    | 5211      |\n",
      "|    total_timesteps | 2930688   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | -1.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1432        |\n",
      "|    time_elapsed         | 5213        |\n",
      "|    total_timesteps      | 2932736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031717278 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.825       |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 14310       |\n",
      "|    policy_gradient_loss | 0.00488     |\n",
      "|    std                  | 0.306       |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.33e+03    |\n",
      "|    ep_rew_mean          | -9.77e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1433        |\n",
      "|    time_elapsed         | 5215        |\n",
      "|    total_timesteps      | 2934784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022535887 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.822       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 14320       |\n",
      "|    policy_gradient_loss | 0.00572     |\n",
      "|    std                  | 0.305       |\n",
      "|    value_loss           | 96.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2935000, episode_reward=20501.78 +/- 6659.15\n",
      "Episode length: 1533.00 +/- 20.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.53e+03    |\n",
      "|    mean_reward          | 2.05e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2935000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011159892 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.838       |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14          |\n",
      "|    n_updates            | 14330       |\n",
      "|    policy_gradient_loss | 0.00178     |\n",
      "|    std                  | 0.303       |\n",
      "|    value_loss           | 70.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -9.71e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1434      |\n",
      "|    time_elapsed    | 5220      |\n",
      "|    total_timesteps | 2936832   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | -9.5e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1435        |\n",
      "|    time_elapsed         | 5222        |\n",
      "|    total_timesteps      | 2938880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030526921 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.863       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 14340       |\n",
      "|    policy_gradient_loss | 0.00208     |\n",
      "|    std                  | 0.303       |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2940000, episode_reward=22439.21 +/- 1546.71\n",
      "Episode length: 1499.60 +/- 3.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.5e+03     |\n",
      "|    mean_reward          | 2.24e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017030463 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.883       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.1         |\n",
      "|    n_updates            | 14350       |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    std                  | 0.301       |\n",
      "|    value_loss           | 70.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -9.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1436      |\n",
      "|    time_elapsed    | 5228      |\n",
      "|    total_timesteps | 2940928   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | -9.41e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1437        |\n",
      "|    time_elapsed         | 5229        |\n",
      "|    total_timesteps      | 2942976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026235951 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.906       |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 14360       |\n",
      "|    policy_gradient_loss | 0.00299     |\n",
      "|    std                  | 0.3         |\n",
      "|    value_loss           | 1.06e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2945000, episode_reward=19286.97 +/- 4793.31\n",
      "Episode length: 1596.80 +/- 20.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | 1.93e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2945000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013889887 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.9         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 14370       |\n",
      "|    policy_gradient_loss | 0.000908    |\n",
      "|    std                  | 0.301       |\n",
      "|    value_loss           | 76.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -9.35e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1438      |\n",
      "|    time_elapsed    | 5235      |\n",
      "|    total_timesteps | 2945024   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.34e+03   |\n",
      "|    ep_rew_mean          | -9.28e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 562        |\n",
      "|    iterations           | 1439       |\n",
      "|    time_elapsed         | 5237       |\n",
      "|    total_timesteps      | 2947072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03279712 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 0.901      |\n",
      "|    explained_variance   | 0.873      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14.7       |\n",
      "|    n_updates            | 14380      |\n",
      "|    policy_gradient_loss | 0.00481    |\n",
      "|    std                  | 0.301      |\n",
      "|    value_loss           | 9.2e+04    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | -9.31e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 5239        |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017774932 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.916       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.96        |\n",
      "|    n_updates            | 14390       |\n",
      "|    policy_gradient_loss | 0.00488     |\n",
      "|    std                  | 0.298       |\n",
      "|    value_loss           | 3.33e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2950000, episode_reward=26053.84 +/- 3531.39\n",
      "Episode length: 1819.80 +/- 9.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.82e+03    |\n",
      "|    mean_reward          | 2.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011166198 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.939       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 14400       |\n",
      "|    policy_gradient_loss | 0.00575     |\n",
      "|    std                  | 0.296       |\n",
      "|    value_loss           | 1.92e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.35e+03  |\n",
      "|    ep_rew_mean     | -9.19e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1441      |\n",
      "|    time_elapsed    | 5245      |\n",
      "|    total_timesteps | 2951168   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | -9.11e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1442        |\n",
      "|    time_elapsed         | 5246        |\n",
      "|    total_timesteps      | 2953216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023011584 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.954       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 14410       |\n",
      "|    policy_gradient_loss | 0.000346    |\n",
      "|    std                  | 0.295       |\n",
      "|    value_loss           | 99.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2955000, episode_reward=18570.00 +/- 7823.61\n",
      "Episode length: 1812.20 +/- 20.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.81e+03    |\n",
      "|    mean_reward          | 1.86e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2955000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006947886 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.963       |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.77        |\n",
      "|    n_updates            | 14420       |\n",
      "|    policy_gradient_loss | 0.00376     |\n",
      "|    std                  | 0.295       |\n",
      "|    value_loss           | 8.87e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.35e+03  |\n",
      "|    ep_rew_mean     | -9.04e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1443      |\n",
      "|    time_elapsed    | 5253      |\n",
      "|    total_timesteps | 2955264   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | -8.94e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1444        |\n",
      "|    time_elapsed         | 5254        |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051664703 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.978       |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.3        |\n",
      "|    n_updates            | 14430       |\n",
      "|    policy_gradient_loss | 0.016       |\n",
      "|    std                  | 0.295       |\n",
      "|    value_loss           | 36.9        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | -9.01e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1445        |\n",
      "|    time_elapsed         | 5256        |\n",
      "|    total_timesteps      | 2959360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022268847 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.992       |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.18        |\n",
      "|    n_updates            | 14440       |\n",
      "|    policy_gradient_loss | 0.00635     |\n",
      "|    std                  | 0.294       |\n",
      "|    value_loss           | 2e+05       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2960000, episode_reward=33410.59 +/- 207.76\n",
      "Episode length: 2159.20 +/- 9.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.16e+03    |\n",
      "|    mean_reward          | 3.34e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010049595 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 0.996       |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.2        |\n",
      "|    n_updates            | 14450       |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    std                  | 0.293       |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.37e+03  |\n",
      "|    ep_rew_mean     | -8.92e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1446      |\n",
      "|    time_elapsed    | 5263      |\n",
      "|    total_timesteps | 2961408   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | -8.79e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1447        |\n",
      "|    time_elapsed         | 5265        |\n",
      "|    total_timesteps      | 2963456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018267313 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.01        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.02        |\n",
      "|    n_updates            | 14460       |\n",
      "|    policy_gradient_loss | 0.000795    |\n",
      "|    std                  | 0.292       |\n",
      "|    value_loss           | 8.91e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2965000, episode_reward=33831.99 +/- 6056.50\n",
      "Episode length: 2554.00 +/- 21.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.55e+03    |\n",
      "|    mean_reward          | 3.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2965000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016618297 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.02        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.1        |\n",
      "|    n_updates            | 14470       |\n",
      "|    policy_gradient_loss | 0.00751     |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 1.93e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.39e+03  |\n",
      "|    ep_rew_mean     | -8.69e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 562       |\n",
      "|    iterations      | 1448      |\n",
      "|    time_elapsed    | 5273      |\n",
      "|    total_timesteps | 2965504   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | -8.53e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1449        |\n",
      "|    time_elapsed         | 5275        |\n",
      "|    total_timesteps      | 2967552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005556715 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.04        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 398         |\n",
      "|    n_updates            | 14480       |\n",
      "|    policy_gradient_loss | 0.00538     |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 654         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.4e+03      |\n",
      "|    ep_rew_mean          | -8.53e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 562          |\n",
      "|    iterations           | 1450         |\n",
      "|    time_elapsed         | 5277         |\n",
      "|    total_timesteps      | 2969600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047419826 |\n",
      "|    clip_fraction        | 0.0594       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.04         |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 82.7         |\n",
      "|    n_updates            | 14490        |\n",
      "|    policy_gradient_loss | -0.00616     |\n",
      "|    std                  | 0.29         |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2970000, episode_reward=31391.00 +/- 6889.56\n",
      "Episode length: 4051.40 +/- 6.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.05e+03    |\n",
      "|    mean_reward          | 3.14e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029317591 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.05        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.92        |\n",
      "|    n_updates            | 14500       |\n",
      "|    policy_gradient_loss | 0.0076      |\n",
      "|    std                  | 0.289       |\n",
      "|    value_loss           | 35          |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.42e+03  |\n",
      "|    ep_rew_mean     | -8.24e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1451      |\n",
      "|    time_elapsed    | 5288      |\n",
      "|    total_timesteps | 2971648   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -7.92e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 562         |\n",
      "|    iterations           | 1452        |\n",
      "|    time_elapsed         | 5290        |\n",
      "|    total_timesteps      | 2973696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005921373 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.06        |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 358         |\n",
      "|    n_updates            | 14510       |\n",
      "|    policy_gradient_loss | 0.0178      |\n",
      "|    std                  | 0.289       |\n",
      "|    value_loss           | 3.95e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2975000, episode_reward=24294.50 +/- 4040.09\n",
      "Episode length: 4953.60 +/- 15.96\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.95e+03   |\n",
      "|    mean_reward          | 2.43e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2975000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00631718 |\n",
      "|    clip_fraction        | 0.0753     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.06       |\n",
      "|    explained_variance   | 0.895      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 313        |\n",
      "|    n_updates            | 14520      |\n",
      "|    policy_gradient_loss | -0.00462   |\n",
      "|    std                  | 0.289      |\n",
      "|    value_loss           | 2.13e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -7.92e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 561       |\n",
      "|    iterations      | 1453      |\n",
      "|    time_elapsed    | 5303      |\n",
      "|    total_timesteps | 2975744   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | -7.67e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 561         |\n",
      "|    iterations           | 1454        |\n",
      "|    time_elapsed         | 5305        |\n",
      "|    total_timesteps      | 2977792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007855228 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.06        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 14530       |\n",
      "|    policy_gradient_loss | 0.000377    |\n",
      "|    std                  | 0.289       |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | -7.67e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 561        |\n",
      "|    iterations           | 1455       |\n",
      "|    time_elapsed         | 5307       |\n",
      "|    total_timesteps      | 2979840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00892251 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.06       |\n",
      "|    explained_variance   | 0.754      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 598        |\n",
      "|    n_updates            | 14540      |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    std                  | 0.29       |\n",
      "|    value_loss           | 1.41e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2980000, episode_reward=67258.78 +/- 4276.89\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.73e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006541671 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.06        |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 361         |\n",
      "|    n_updates            | 14550       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 914         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -5.79e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 560       |\n",
      "|    iterations      | 1456      |\n",
      "|    time_elapsed    | 5321      |\n",
      "|    total_timesteps | 2981888   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -5.79e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 560         |\n",
      "|    iterations           | 1457        |\n",
      "|    time_elapsed         | 5322        |\n",
      "|    total_timesteps      | 2983936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009793371 |\n",
      "|    clip_fraction        | 0.0769      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.06        |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 14560       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 1.19e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2985000, episode_reward=-15522.86 +/- 3406.11\n",
      "Episode length: 4655.20 +/- 15.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.66e+03    |\n",
      "|    mean_reward          | -1.55e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2985000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014207795 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.06        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 82.7        |\n",
      "|    n_updates            | 14570       |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -6.31e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 559       |\n",
      "|    iterations      | 1458      |\n",
      "|    time_elapsed    | 5335      |\n",
      "|    total_timesteps | 2985984   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -6.19e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1459        |\n",
      "|    time_elapsed         | 5337        |\n",
      "|    total_timesteps      | 2988032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008882117 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.05        |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+04    |\n",
      "|    n_updates            | 14580       |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 1.22e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2990000, episode_reward=69385.79 +/- 8609.23\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.94e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2990000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006847038 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.05        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.11e+05    |\n",
      "|    n_updates            | 14590       |\n",
      "|    policy_gradient_loss | -0.00291    |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 5.31e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -6.19e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 558       |\n",
      "|    iterations      | 1460      |\n",
      "|    time_elapsed    | 5351      |\n",
      "|    total_timesteps | 2990080   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -5.79e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 1461        |\n",
      "|    time_elapsed         | 5352        |\n",
      "|    total_timesteps      | 2992128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014822045 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.05        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.7        |\n",
      "|    n_updates            | 14600       |\n",
      "|    policy_gradient_loss | 3.79e-06    |\n",
      "|    std                  | 0.291       |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -5.85e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1462        |\n",
      "|    time_elapsed         | 5354        |\n",
      "|    total_timesteps      | 2994176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011290142 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.05        |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 232         |\n",
      "|    n_updates            | 14610       |\n",
      "|    policy_gradient_loss | 0.00219     |\n",
      "|    std                  | 0.291       |\n",
      "|    value_loss           | 9.16e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2995000, episode_reward=19182.21 +/- 4017.82\n",
      "Episode length: 1542.80 +/- 21.22\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.54e+03  |\n",
      "|    mean_reward          | 1.92e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 2995000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.8492811 |\n",
      "|    clip_fraction        | 0.697     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.06      |\n",
      "|    explained_variance   | 0.942     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 10.2      |\n",
      "|    n_updates            | 14620     |\n",
      "|    policy_gradient_loss | 0.114     |\n",
      "|    std                  | 0.29      |\n",
      "|    value_loss           | 8.99e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -5.77e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 558       |\n",
      "|    iterations      | 1463      |\n",
      "|    time_elapsed    | 5360      |\n",
      "|    total_timesteps | 2996224   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -5.63e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1464        |\n",
      "|    time_elapsed         | 5362        |\n",
      "|    total_timesteps      | 2998272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070140034 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.06        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 311         |\n",
      "|    n_updates            | 14630       |\n",
      "|    policy_gradient_loss | 0.0156      |\n",
      "|    std                  | 0.291       |\n",
      "|    value_loss           | 395         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3000000, episode_reward=19191.82 +/- 6184.53\n",
      "Episode length: 1576.00 +/- 15.07\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.58e+03     |\n",
      "|    mean_reward          | 1.92e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0125744315 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.05         |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 154          |\n",
      "|    n_updates            | 14640        |\n",
      "|    policy_gradient_loss | 6.66e-05     |\n",
      "|    std                  | 0.292        |\n",
      "|    value_loss           | 2.02e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -3.93e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 558       |\n",
      "|    iterations      | 1465      |\n",
      "|    time_elapsed    | 5367      |\n",
      "|    total_timesteps | 3000320   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -2.23e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1466        |\n",
      "|    time_elapsed         | 5369        |\n",
      "|    total_timesteps      | 3002368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013213687 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.05        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 410         |\n",
      "|    n_updates            | 14650       |\n",
      "|    policy_gradient_loss | 0.00331     |\n",
      "|    std                  | 0.291       |\n",
      "|    value_loss           | 362         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -2.26e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1467        |\n",
      "|    time_elapsed         | 5371        |\n",
      "|    total_timesteps      | 3004416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008696083 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.05        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 276         |\n",
      "|    n_updates            | 14660       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    std                  | 0.292       |\n",
      "|    value_loss           | 581         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3005000, episode_reward=17812.63 +/- 7031.93\n",
      "Episode length: 1622.80 +/- 14.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.62e+03    |\n",
      "|    mean_reward          | 1.78e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3005000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009103127 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.05        |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 14670       |\n",
      "|    policy_gradient_loss | 0.0031      |\n",
      "|    std                  | 0.292       |\n",
      "|    value_loss           | 2.77e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.59e+03 |\n",
      "|    ep_rew_mean     | -759     |\n",
      "| time/              |          |\n",
      "|    fps             | 559      |\n",
      "|    iterations      | 1468     |\n",
      "|    time_elapsed    | 5376     |\n",
      "|    total_timesteps | 3006464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -919        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1469        |\n",
      "|    time_elapsed         | 5378        |\n",
      "|    total_timesteps      | 3008512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017189654 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.06        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 14680       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 1.93e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3010000, episode_reward=-702.21 +/- 51788.68\n",
      "Episode length: 1428.60 +/- 680.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.43e+03    |\n",
      "|    mean_reward          | -702        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006847052 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.07        |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.06e+07    |\n",
      "|    n_updates            | 14690       |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 1.94e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.6e+03  |\n",
      "|    ep_rew_mean     | 1.25e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 559      |\n",
      "|    iterations      | 1470     |\n",
      "|    time_elapsed    | 5384     |\n",
      "|    total_timesteps | 3010560  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | 1.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1471        |\n",
      "|    time_elapsed         | 5385        |\n",
      "|    total_timesteps      | 3012608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027676515 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.07        |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 376         |\n",
      "|    n_updates            | 14700       |\n",
      "|    policy_gradient_loss | 0.00203     |\n",
      "|    std                  | 0.291       |\n",
      "|    value_loss           | 3.06e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.61e+03   |\n",
      "|    ep_rew_mean          | 2.47e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 559        |\n",
      "|    iterations           | 1472       |\n",
      "|    time_elapsed         | 5387       |\n",
      "|    total_timesteps      | 3014656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02433429 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.08       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 50.7       |\n",
      "|    n_updates            | 14710      |\n",
      "|    policy_gradient_loss | 0.000424   |\n",
      "|    std                  | 0.289      |\n",
      "|    value_loss           | 191        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3015000, episode_reward=25192.76 +/- 7816.27\n",
      "Episode length: 2638.80 +/- 40.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.64e+03    |\n",
      "|    mean_reward          | 2.52e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3015000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023795627 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.1         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 14720       |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    std                  | 0.289       |\n",
      "|    value_loss           | 164         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.61e+03 |\n",
      "|    ep_rew_mean     | 2.49e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 559      |\n",
      "|    iterations      | 1473     |\n",
      "|    time_elapsed    | 5395     |\n",
      "|    total_timesteps | 3016704  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | 2.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1474        |\n",
      "|    time_elapsed         | 5397        |\n",
      "|    total_timesteps      | 3018752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022062587 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.1         |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 14730       |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 1.1e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3020000, episode_reward=28610.50 +/- 2683.44\n",
      "Episode length: 2764.40 +/- 17.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.76e+03    |\n",
      "|    mean_reward          | 2.86e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008416334 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.11        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.2        |\n",
      "|    n_updates            | 14740       |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    std                  | 0.289       |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.62e+03 |\n",
      "|    ep_rew_mean     | 2.54e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 558      |\n",
      "|    iterations      | 1475     |\n",
      "|    time_elapsed    | 5405     |\n",
      "|    total_timesteps | 3020800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 2.47e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 1476        |\n",
      "|    time_elapsed         | 5407        |\n",
      "|    total_timesteps      | 3022848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043201543 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.12        |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18          |\n",
      "|    n_updates            | 14750       |\n",
      "|    policy_gradient_loss | 0.00638     |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 9.17e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.63e+03  |\n",
      "|    ep_rew_mean          | 2.79e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 559       |\n",
      "|    iterations           | 1477      |\n",
      "|    time_elapsed         | 5409      |\n",
      "|    total_timesteps      | 3024896   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0714217 |\n",
      "|    clip_fraction        | 0.25      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.12      |\n",
      "|    explained_variance   | 0.867     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 46.1      |\n",
      "|    n_updates            | 14760     |\n",
      "|    policy_gradient_loss | 0.0116    |\n",
      "|    std                  | 0.289     |\n",
      "|    value_loss           | 1.03e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3025000, episode_reward=-30172.54 +/- 67171.39\n",
      "Episode length: 1253.00 +/- 962.09\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.25e+03  |\n",
      "|    mean_reward          | -3.02e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3025000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0865452 |\n",
      "|    clip_fraction        | 0.228     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.12      |\n",
      "|    explained_variance   | 0.352     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.79e+04  |\n",
      "|    n_updates            | 14770     |\n",
      "|    policy_gradient_loss | -0.00353  |\n",
      "|    std                  | 0.289     |\n",
      "|    value_loss           | 1.11e+07  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.63e+03 |\n",
      "|    ep_rew_mean     | 2.84e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 559      |\n",
      "|    iterations      | 1478     |\n",
      "|    time_elapsed    | 5414     |\n",
      "|    total_timesteps | 3026944  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | 2.91e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 559         |\n",
      "|    iterations           | 1479        |\n",
      "|    time_elapsed         | 5416        |\n",
      "|    total_timesteps      | 3028992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032110587 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.13        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.1        |\n",
      "|    n_updates            | 14780       |\n",
      "|    policy_gradient_loss | 0.00156     |\n",
      "|    std                  | 0.29        |\n",
      "|    value_loss           | 81.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3030000, episode_reward=16109.14 +/- 8302.82\n",
      "Episode length: 3084.60 +/- 26.03\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.08e+03   |\n",
      "|    mean_reward          | 1.61e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3030000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15455934 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.13       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.2       |\n",
      "|    n_updates            | 14790      |\n",
      "|    policy_gradient_loss | 0.0068     |\n",
      "|    std                  | 0.288      |\n",
      "|    value_loss           | 61.6       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.64e+03 |\n",
      "|    ep_rew_mean     | 2.91e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 558      |\n",
      "|    iterations      | 1480     |\n",
      "|    time_elapsed    | 5425     |\n",
      "|    total_timesteps | 3031040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | 2.89e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 1481        |\n",
      "|    time_elapsed         | 5427        |\n",
      "|    total_timesteps      | 3033088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019585975 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.3        |\n",
      "|    n_updates            | 14800       |\n",
      "|    policy_gradient_loss | 0.00558     |\n",
      "|    std                  | 0.288       |\n",
      "|    value_loss           | 389         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3035000, episode_reward=13083.42 +/- 7998.66\n",
      "Episode length: 3730.80 +/- 23.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.73e+03    |\n",
      "|    mean_reward          | 1.31e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3035000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018147217 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 14810       |\n",
      "|    policy_gradient_loss | 0.00828     |\n",
      "|    std                  | 0.289       |\n",
      "|    value_loss           | 1.91e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.64e+03 |\n",
      "|    ep_rew_mean     | 1.6e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 558      |\n",
      "|    iterations      | 1482     |\n",
      "|    time_elapsed    | 5437     |\n",
      "|    total_timesteps | 3035136  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | 1.85e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 1483        |\n",
      "|    time_elapsed         | 5439        |\n",
      "|    total_timesteps      | 3037184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.060387913 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.359       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.63e+06    |\n",
      "|    n_updates            | 14820       |\n",
      "|    policy_gradient_loss | 0.00442     |\n",
      "|    std                  | 0.288       |\n",
      "|    value_loss           | 1.59e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | 1.85e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 558         |\n",
      "|    iterations           | 1484        |\n",
      "|    time_elapsed         | 5441        |\n",
      "|    total_timesteps      | 3039232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008004328 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.15        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.2        |\n",
      "|    n_updates            | 14830       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    std                  | 0.288       |\n",
      "|    value_loss           | 1.13e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3040000, episode_reward=10658.95 +/- 4527.75\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 1.07e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009539602 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 14840       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    std                  | 0.287       |\n",
      "|    value_loss           | 331         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.67e+03 |\n",
      "|    ep_rew_mean     | 1.96e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 557      |\n",
      "|    iterations      | 1485     |\n",
      "|    time_elapsed    | 5454     |\n",
      "|    total_timesteps | 3041280  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.67e+03   |\n",
      "|    ep_rew_mean          | 1.96e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 557        |\n",
      "|    iterations           | 1486       |\n",
      "|    time_elapsed         | 5456       |\n",
      "|    total_timesteps      | 3043328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36232585 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.16       |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 37.9       |\n",
      "|    n_updates            | 14850      |\n",
      "|    policy_gradient_loss | 0.0225     |\n",
      "|    std                  | 0.287      |\n",
      "|    value_loss           | 3.38e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3045000, episode_reward=35298.98 +/- 6481.60\n",
      "Episode length: 2686.20 +/- 24.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.69e+03    |\n",
      "|    mean_reward          | 3.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3045000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082062066 |\n",
      "|    clip_fraction        | 0.487       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.16        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 14860       |\n",
      "|    policy_gradient_loss | 0.0336      |\n",
      "|    std                  | 0.286       |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.68e+03 |\n",
      "|    ep_rew_mean     | 2.05e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 557      |\n",
      "|    iterations      | 1487     |\n",
      "|    time_elapsed    | 5465     |\n",
      "|    total_timesteps | 3045376  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | 2.88e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 557         |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 5466        |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.084364444 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.18        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 14870       |\n",
      "|    policy_gradient_loss | 0.0068      |\n",
      "|    std                  | 0.285       |\n",
      "|    value_loss           | 526         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | 4.65e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 557         |\n",
      "|    iterations           | 1489        |\n",
      "|    time_elapsed         | 5468        |\n",
      "|    total_timesteps      | 3049472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017602887 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.19        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 14880       |\n",
      "|    policy_gradient_loss | 0.00208     |\n",
      "|    std                  | 0.283       |\n",
      "|    value_loss           | 108         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3050000, episode_reward=36401.78 +/- 631.16\n",
      "Episode length: 2339.60 +/- 28.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.34e+03    |\n",
      "|    mean_reward          | 3.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026203468 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.2         |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.81        |\n",
      "|    n_updates            | 14890       |\n",
      "|    policy_gradient_loss | 0.0123      |\n",
      "|    std                  | 0.282       |\n",
      "|    value_loss           | 41.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.7e+03  |\n",
      "|    ep_rew_mean     | 4.83e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 557      |\n",
      "|    iterations      | 1490     |\n",
      "|    time_elapsed    | 5476     |\n",
      "|    total_timesteps | 3051520  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.67e+03   |\n",
      "|    ep_rew_mean          | 3.43e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 557        |\n",
      "|    iterations           | 1491       |\n",
      "|    time_elapsed         | 5477       |\n",
      "|    total_timesteps      | 3053568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09083924 |\n",
      "|    clip_fraction        | 0.345      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.21       |\n",
      "|    explained_variance   | 0.77       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 28         |\n",
      "|    n_updates            | 14900      |\n",
      "|    policy_gradient_loss | 0.00582    |\n",
      "|    std                  | 0.283      |\n",
      "|    value_loss           | 1.41e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3055000, episode_reward=29888.39 +/- 6436.88\n",
      "Episode length: 2467.60 +/- 27.17\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.47e+03     |\n",
      "|    mean_reward          | 2.99e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3055000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039885542 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.21         |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17e+07     |\n",
      "|    n_updates            | 14910        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    std                  | 0.283        |\n",
      "|    value_loss           | 2.36e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.69e+03 |\n",
      "|    ep_rew_mean     | 5.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 557      |\n",
      "|    iterations      | 1492     |\n",
      "|    time_elapsed    | 5485     |\n",
      "|    total_timesteps | 3055616  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.71e+03     |\n",
      "|    ep_rew_mean          | 6.97e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 557          |\n",
      "|    iterations           | 1493         |\n",
      "|    time_elapsed         | 5487         |\n",
      "|    total_timesteps      | 3057664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065537067 |\n",
      "|    clip_fraction        | 0.0605       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.22         |\n",
      "|    explained_variance   | 0.876        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.06e+03     |\n",
      "|    n_updates            | 14920        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    std                  | 0.283        |\n",
      "|    value_loss           | 1.33e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | 8.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 557         |\n",
      "|    iterations           | 1494        |\n",
      "|    time_elapsed         | 5489        |\n",
      "|    total_timesteps      | 3059712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013200742 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.22        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.1        |\n",
      "|    n_updates            | 14930       |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    std                  | 0.283       |\n",
      "|    value_loss           | 608         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3060000, episode_reward=32098.60 +/- 5826.73\n",
      "Episode length: 2542.20 +/- 30.14\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.54e+03  |\n",
      "|    mean_reward          | 3.21e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3060000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0157925 |\n",
      "|    clip_fraction        | 0.221     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.22      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 16.7      |\n",
      "|    n_updates            | 14940     |\n",
      "|    policy_gradient_loss | 0.0196    |\n",
      "|    std                  | 0.281     |\n",
      "|    value_loss           | 93.1      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.73e+03 |\n",
      "|    ep_rew_mean     | 8.16e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 556      |\n",
      "|    iterations      | 1495     |\n",
      "|    time_elapsed    | 5496     |\n",
      "|    total_timesteps | 3061760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | 9.97e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 557         |\n",
      "|    iterations           | 1496        |\n",
      "|    time_elapsed         | 5498        |\n",
      "|    total_timesteps      | 3063808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018189559 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.24        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 14950       |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    std                  | 0.28        |\n",
      "|    value_loss           | 269         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3065000, episode_reward=37325.30 +/- 2447.32\n",
      "Episode length: 2982.00 +/- 22.45\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.98e+03   |\n",
      "|    mean_reward          | 3.73e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3065000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12430693 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.26       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.13       |\n",
      "|    n_updates            | 14960      |\n",
      "|    policy_gradient_loss | 0.0223     |\n",
      "|    std                  | 0.279      |\n",
      "|    value_loss           | 40.9       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.75e+03 |\n",
      "|    ep_rew_mean     | 1.1e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 556      |\n",
      "|    iterations      | 1497     |\n",
      "|    time_elapsed    | 5507     |\n",
      "|    total_timesteps | 3065856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | 1.11e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 1498        |\n",
      "|    time_elapsed         | 5509        |\n",
      "|    total_timesteps      | 3067904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016528115 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.27        |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.7        |\n",
      "|    n_updates            | 14970       |\n",
      "|    policy_gradient_loss | 0.00355     |\n",
      "|    std                  | 0.278       |\n",
      "|    value_loss           | 3.63e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | 9.78e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 557         |\n",
      "|    iterations           | 1499        |\n",
      "|    time_elapsed         | 5511        |\n",
      "|    total_timesteps      | 3069952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037991624 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.29        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 14980       |\n",
      "|    policy_gradient_loss | 0.00368     |\n",
      "|    std                  | 0.278       |\n",
      "|    value_loss           | 3.48e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3070000, episode_reward=-4868.53 +/- 52271.64\n",
      "Episode length: 2967.40 +/- 1445.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.97e+03    |\n",
      "|    mean_reward          | -4.87e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.117450505 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.29        |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.52e+06    |\n",
      "|    n_updates            | 14990       |\n",
      "|    policy_gradient_loss | -0.00895    |\n",
      "|    std                  | 0.278       |\n",
      "|    value_loss           | 1.08e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.75e+03 |\n",
      "|    ep_rew_mean     | 9.84e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 556      |\n",
      "|    iterations      | 1500     |\n",
      "|    time_elapsed    | 5520     |\n",
      "|    total_timesteps | 3072000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | 1e+04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 1501        |\n",
      "|    time_elapsed         | 5521        |\n",
      "|    total_timesteps      | 3074048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025396656 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.3         |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.8        |\n",
      "|    n_updates            | 15000       |\n",
      "|    policy_gradient_loss | 0.00539     |\n",
      "|    std                  | 0.277       |\n",
      "|    value_loss           | 121         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3075000, episode_reward=20923.89 +/- 7425.40\n",
      "Episode length: 3546.60 +/- 44.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.55e+03    |\n",
      "|    mean_reward          | 2.09e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3075000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008458659 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.3         |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80.4        |\n",
      "|    n_updates            | 15010       |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    std                  | 0.276       |\n",
      "|    value_loss           | 304         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.76e+03 |\n",
      "|    ep_rew_mean     | 1.02e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 556      |\n",
      "|    iterations      | 1502     |\n",
      "|    time_elapsed    | 5532     |\n",
      "|    total_timesteps | 3076096  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.79e+03   |\n",
      "|    ep_rew_mean          | 1.21e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 556        |\n",
      "|    iterations           | 1503       |\n",
      "|    time_elapsed         | 5533       |\n",
      "|    total_timesteps      | 3078144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02557387 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.3        |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 22.1       |\n",
      "|    n_updates            | 15020      |\n",
      "|    policy_gradient_loss | 0.00979    |\n",
      "|    std                  | 0.276      |\n",
      "|    value_loss           | 118        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3080000, episode_reward=-5597.63 +/- 52662.09\n",
      "Episode length: 2926.80 +/- 1425.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.93e+03    |\n",
      "|    mean_reward          | -5.6e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014568808 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.3         |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 15030       |\n",
      "|    policy_gradient_loss | -0.000128   |\n",
      "|    std                  | 0.277       |\n",
      "|    value_loss           | 1.3e+04     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.79e+03 |\n",
      "|    ep_rew_mean     | 1.21e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 555      |\n",
      "|    iterations      | 1504     |\n",
      "|    time_elapsed    | 5542     |\n",
      "|    total_timesteps | 3080192  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.8e+03     |\n",
      "|    ep_rew_mean          | 1.23e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 555         |\n",
      "|    iterations           | 1505        |\n",
      "|    time_elapsed         | 5544        |\n",
      "|    total_timesteps      | 3082240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020555751 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.31        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.4        |\n",
      "|    n_updates            | 15040       |\n",
      "|    policy_gradient_loss | 0.0271      |\n",
      "|    std                  | 0.276       |\n",
      "|    value_loss           | 54.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.82e+03    |\n",
      "|    ep_rew_mean          | 1.26e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 556         |\n",
      "|    iterations           | 1506        |\n",
      "|    time_elapsed         | 5546        |\n",
      "|    total_timesteps      | 3084288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005353693 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.31        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 257         |\n",
      "|    n_updates            | 15050       |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    std                  | 0.277       |\n",
      "|    value_loss           | 6.56e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3085000, episode_reward=-21816.76 +/- 4887.34\n",
      "Episode length: 4839.20 +/- 28.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.84e+03    |\n",
      "|    mean_reward          | -2.18e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3085000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009849071 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.31        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.1        |\n",
      "|    n_updates            | 15060       |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    std                  | 0.276       |\n",
      "|    value_loss           | 286         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.82e+03 |\n",
      "|    ep_rew_mean     | 1.26e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 555      |\n",
      "|    iterations      | 1507     |\n",
      "|    time_elapsed    | 5559     |\n",
      "|    total_timesteps | 3086336  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.83e+03   |\n",
      "|    ep_rew_mean          | 1.27e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 555        |\n",
      "|    iterations           | 1508       |\n",
      "|    time_elapsed         | 5561       |\n",
      "|    total_timesteps      | 3088384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06245747 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.33       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.66       |\n",
      "|    n_updates            | 15070      |\n",
      "|    policy_gradient_loss | 0.0187     |\n",
      "|    std                  | 0.275      |\n",
      "|    value_loss           | 29.6       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3090000, episode_reward=-34972.70 +/- 34737.67\n",
      "Episode length: 3732.60 +/- 1831.96\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.73e+03     |\n",
      "|    mean_reward          | -3.5e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3090000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060410476 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.32         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 42.3         |\n",
      "|    n_updates            | 15080        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    std                  | 0.275        |\n",
      "|    value_loss           | 1.15e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.83e+03 |\n",
      "|    ep_rew_mean     | 1.17e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 554      |\n",
      "|    iterations      | 1509     |\n",
      "|    time_elapsed    | 5571     |\n",
      "|    total_timesteps | 3090432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | 1.17e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 554         |\n",
      "|    iterations           | 1510        |\n",
      "|    time_elapsed         | 5573        |\n",
      "|    total_timesteps      | 3092480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008228002 |\n",
      "|    clip_fraction        | 0.0418      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.33        |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.12e+06    |\n",
      "|    n_updates            | 15090       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    std                  | 0.275       |\n",
      "|    value_loss           | 1.39e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | 1.2e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 555         |\n",
      "|    iterations           | 1511        |\n",
      "|    time_elapsed         | 5575        |\n",
      "|    total_timesteps      | 3094528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035088945 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.34        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.6        |\n",
      "|    n_updates            | 15100       |\n",
      "|    policy_gradient_loss | 0.00969     |\n",
      "|    std                  | 0.274       |\n",
      "|    value_loss           | 44.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3095000, episode_reward=-20842.92 +/- 42782.13\n",
      "Episode length: 3073.60 +/- 1501.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.07e+03    |\n",
      "|    mean_reward          | -2.08e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3095000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007826245 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.35        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 15110       |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    std                  | 0.274       |\n",
      "|    value_loss           | 220         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.87e+03 |\n",
      "|    ep_rew_mean     | 1.33e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 554      |\n",
      "|    iterations      | 1512     |\n",
      "|    time_elapsed    | 5584     |\n",
      "|    total_timesteps | 3096576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.87e+03    |\n",
      "|    ep_rew_mean          | 1.33e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 554         |\n",
      "|    iterations           | 1513        |\n",
      "|    time_elapsed         | 5586        |\n",
      "|    total_timesteps      | 3098624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008770021 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.36        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 15120       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    std                  | 0.273       |\n",
      "|    value_loss           | 1.14e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3100000, episode_reward=-19894.72 +/- 42967.13\n",
      "Episode length: 3471.20 +/- 1701.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.47e+03    |\n",
      "|    mean_reward          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034235105 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.37        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4           |\n",
      "|    n_updates            | 15130       |\n",
      "|    policy_gradient_loss | 0.00942     |\n",
      "|    std                  | 0.274       |\n",
      "|    value_loss           | 17.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.88e+03 |\n",
      "|    ep_rew_mean     | 1.36e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 554      |\n",
      "|    iterations      | 1514     |\n",
      "|    time_elapsed    | 5596     |\n",
      "|    total_timesteps | 3100672  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.88e+03    |\n",
      "|    ep_rew_mean          | 1.28e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 554         |\n",
      "|    iterations           | 1515        |\n",
      "|    time_elapsed         | 5598        |\n",
      "|    total_timesteps      | 3102720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011188474 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.38        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.7        |\n",
      "|    n_updates            | 15140       |\n",
      "|    policy_gradient_loss | 0.00913     |\n",
      "|    std                  | 0.273       |\n",
      "|    value_loss           | 92.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.89e+03   |\n",
      "|    ep_rew_mean          | 1.21e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 554        |\n",
      "|    iterations           | 1516       |\n",
      "|    time_elapsed         | 5600       |\n",
      "|    total_timesteps      | 3104768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04951629 |\n",
      "|    clip_fraction        | 0.0905     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.38       |\n",
      "|    explained_variance   | 0.39       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.39e+06   |\n",
      "|    n_updates            | 15150      |\n",
      "|    policy_gradient_loss | 0.00564    |\n",
      "|    std                  | 0.273      |\n",
      "|    value_loss           | 1.03e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3105000, episode_reward=-50873.62 +/- 34514.07\n",
      "Episode length: 4015.40 +/- 1969.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.02e+03     |\n",
      "|    mean_reward          | -5.09e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3105000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006883474 |\n",
      "|    clip_fraction        | 0.00415      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.38         |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+07     |\n",
      "|    n_updates            | 15160        |\n",
      "|    policy_gradient_loss | -0.00186     |\n",
      "|    std                  | 0.273        |\n",
      "|    value_loss           | 3.58e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.89e+03 |\n",
      "|    ep_rew_mean     | 1.21e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 553      |\n",
      "|    iterations      | 1517     |\n",
      "|    time_elapsed    | 5611     |\n",
      "|    total_timesteps | 3106816  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.9e+03    |\n",
      "|    ep_rew_mean          | 1.22e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 553        |\n",
      "|    iterations           | 1518       |\n",
      "|    time_elapsed         | 5613       |\n",
      "|    total_timesteps      | 3108864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00419247 |\n",
      "|    clip_fraction        | 0.0137     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.38       |\n",
      "|    explained_variance   | 0.887      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.02e+04   |\n",
      "|    n_updates            | 15170      |\n",
      "|    policy_gradient_loss | -0.00489   |\n",
      "|    std                  | 0.273      |\n",
      "|    value_loss           | 5.68e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3110000, episode_reward=-52820.22 +/- 35468.51\n",
      "Episode length: 4015.80 +/- 1968.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.02e+03    |\n",
      "|    mean_reward          | -5.28e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004780216 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.38        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 15180       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    std                  | 0.273       |\n",
      "|    value_loss           | 1.32e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.92e+03 |\n",
      "|    ep_rew_mean     | 1.25e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 553      |\n",
      "|    iterations      | 1519     |\n",
      "|    time_elapsed    | 5624     |\n",
      "|    total_timesteps | 3110912  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.93e+03     |\n",
      "|    ep_rew_mean          | 1.25e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 553          |\n",
      "|    iterations           | 1520         |\n",
      "|    time_elapsed         | 5626         |\n",
      "|    total_timesteps      | 3112960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060505476 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.38         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 229          |\n",
      "|    n_updates            | 15190        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    std                  | 0.273        |\n",
      "|    value_loss           | 2.78e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3115000, episode_reward=-35162.69 +/- 5911.04\n",
      "Episode length: 4694.60 +/- 17.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.69e+03    |\n",
      "|    mean_reward          | -3.52e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3115000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004638546 |\n",
      "|    clip_fraction        | 0.0164      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.38        |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.18e+05    |\n",
      "|    n_updates            | 15200       |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    std                  | 0.273       |\n",
      "|    value_loss           | 1.94e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.93e+03 |\n",
      "|    ep_rew_mean     | 1.25e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 552      |\n",
      "|    iterations      | 1521     |\n",
      "|    time_elapsed    | 5638     |\n",
      "|    total_timesteps | 3115008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | 1.27e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 552         |\n",
      "|    iterations           | 1522        |\n",
      "|    time_elapsed         | 5640        |\n",
      "|    total_timesteps      | 3117056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008719152 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.38        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 489         |\n",
      "|    n_updates            | 15210       |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    std                  | 0.273       |\n",
      "|    value_loss           | 3.23e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | 1.3e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 552         |\n",
      "|    iterations           | 1523        |\n",
      "|    time_elapsed         | 5642        |\n",
      "|    total_timesteps      | 3119104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005880325 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.38        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 15220       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    std                  | 0.273       |\n",
      "|    value_loss           | 3.11e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3120000, episode_reward=-36866.60 +/- 42569.46\n",
      "Episode length: 3444.60 +/- 1682.52\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.44e+03     |\n",
      "|    mean_reward          | -3.69e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042575113 |\n",
      "|    clip_fraction        | 0.0187       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.38         |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 149          |\n",
      "|    n_updates            | 15230        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    std                  | 0.273        |\n",
      "|    value_loss           | 2.95e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.96e+03 |\n",
      "|    ep_rew_mean     | 1.33e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 552      |\n",
      "|    iterations      | 1524     |\n",
      "|    time_elapsed    | 5652     |\n",
      "|    total_timesteps | 3121152  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.96e+03   |\n",
      "|    ep_rew_mean          | 1.21e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 552        |\n",
      "|    iterations           | 1525       |\n",
      "|    time_elapsed         | 5654       |\n",
      "|    total_timesteps      | 3123200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00642345 |\n",
      "|    clip_fraction        | 0.052      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.38       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 230        |\n",
      "|    n_updates            | 15240      |\n",
      "|    policy_gradient_loss | -0.00433   |\n",
      "|    std                  | 0.273      |\n",
      "|    value_loss           | 1.83e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3125000, episode_reward=3857.16 +/- 327.71\n",
      "Episode length: 4162.80 +/- 14.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.16e+03    |\n",
      "|    mean_reward          | 3.86e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3125000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010463202 |\n",
      "|    clip_fraction        | 0.0879      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.38        |\n",
      "|    explained_variance   | 0.328       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.14e+06    |\n",
      "|    n_updates            | 15250       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    std                  | 0.273       |\n",
      "|    value_loss           | 1.83e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.96e+03 |\n",
      "|    ep_rew_mean     | 1.21e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 551      |\n",
      "|    iterations      | 1526     |\n",
      "|    time_elapsed    | 5666     |\n",
      "|    total_timesteps | 3125248  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.97e+03   |\n",
      "|    ep_rew_mean          | 1.23e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 551        |\n",
      "|    iterations           | 1527       |\n",
      "|    time_elapsed         | 5667       |\n",
      "|    total_timesteps      | 3127296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03279513 |\n",
      "|    clip_fraction        | 0.304      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.39       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13         |\n",
      "|    n_updates            | 15260      |\n",
      "|    policy_gradient_loss | 0.0174     |\n",
      "|    std                  | 0.272      |\n",
      "|    value_loss           | 118        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.98e+03     |\n",
      "|    ep_rew_mean          | 1.25e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 551          |\n",
      "|    iterations           | 1528         |\n",
      "|    time_elapsed         | 5669         |\n",
      "|    total_timesteps      | 3129344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048554465 |\n",
      "|    clip_fraction        | 0.0915       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.41         |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 207          |\n",
      "|    n_updates            | 15270        |\n",
      "|    policy_gradient_loss | 0.00145      |\n",
      "|    std                  | 0.272        |\n",
      "|    value_loss           | 1.07e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3130000, episode_reward=6967.07 +/- 7427.69\n",
      "Episode length: 4034.80 +/- 28.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.03e+03    |\n",
      "|    mean_reward          | 6.97e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020273644 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.42        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.9        |\n",
      "|    n_updates            | 15280       |\n",
      "|    policy_gradient_loss | 0.00728     |\n",
      "|    std                  | 0.269       |\n",
      "|    value_loss           | 163         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.99e+03 |\n",
      "|    ep_rew_mean     | 1.26e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 551      |\n",
      "|    iterations      | 1529     |\n",
      "|    time_elapsed    | 5680     |\n",
      "|    total_timesteps | 3131392  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | 1.28e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 1530        |\n",
      "|    time_elapsed         | 5682        |\n",
      "|    total_timesteps      | 3133440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012200387 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.44        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 15290       |\n",
      "|    policy_gradient_loss | 0.00736     |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 195         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3135000, episode_reward=-8308.92 +/- 6146.06\n",
      "Episode length: 4135.60 +/- 14.72\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.14e+03   |\n",
      "|    mean_reward          | -8.31e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3135000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00903571 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.45       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 25         |\n",
      "|    n_updates            | 15300      |\n",
      "|    policy_gradient_loss | 0.00318    |\n",
      "|    std                  | 0.267      |\n",
      "|    value_loss           | 245        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.01e+03 |\n",
      "|    ep_rew_mean     | 1.29e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 550      |\n",
      "|    iterations      | 1531     |\n",
      "|    time_elapsed    | 5694     |\n",
      "|    total_timesteps | 3135488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | 1.3e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 1532        |\n",
      "|    time_elapsed         | 5696        |\n",
      "|    total_timesteps      | 3137536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021340935 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.45        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 15310       |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 60.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.02e+03   |\n",
      "|    ep_rew_mean          | 1.3e+04    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 551        |\n",
      "|    iterations           | 1533       |\n",
      "|    time_elapsed         | 5697       |\n",
      "|    total_timesteps      | 3139584    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04703716 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.46       |\n",
      "|    explained_variance   | 0.93       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.68e+04   |\n",
      "|    n_updates            | 15320      |\n",
      "|    policy_gradient_loss | 0.00562    |\n",
      "|    std                  | 0.268      |\n",
      "|    value_loss           | 1.14e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3140000, episode_reward=6658.41 +/- 5558.58\n",
      "Episode length: 3711.40 +/- 11.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.71e+03    |\n",
      "|    mean_reward          | 6.66e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016488863 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.47        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.1         |\n",
      "|    n_updates            | 15330       |\n",
      "|    policy_gradient_loss | 0.00566     |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 29.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.03e+03 |\n",
      "|    ep_rew_mean     | 1.31e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 550      |\n",
      "|    iterations      | 1534     |\n",
      "|    time_elapsed    | 5708     |\n",
      "|    total_timesteps | 3141632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | 1.19e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 1535        |\n",
      "|    time_elapsed         | 5710        |\n",
      "|    total_timesteps      | 3143680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011410017 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.48        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 15340       |\n",
      "|    policy_gradient_loss | 0.0013      |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 300         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3145000, episode_reward=-27994.52 +/- 57443.08\n",
      "Episode length: 3465.60 +/- 1693.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.47e+03   |\n",
      "|    mean_reward          | -2.8e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3145000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16374144 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.48       |\n",
      "|    explained_variance   | 0.398      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.81e+06   |\n",
      "|    n_updates            | 15350      |\n",
      "|    policy_gradient_loss | 0.0102     |\n",
      "|    std                  | 0.268      |\n",
      "|    value_loss           | 1.29e+07   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.03e+03 |\n",
      "|    ep_rew_mean     | 1.2e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 549      |\n",
      "|    iterations      | 1536     |\n",
      "|    time_elapsed    | 5720     |\n",
      "|    total_timesteps | 3145728  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.04e+03    |\n",
      "|    ep_rew_mean          | 1.21e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 1537        |\n",
      "|    time_elapsed         | 5722        |\n",
      "|    total_timesteps      | 3147776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009545544 |\n",
      "|    clip_fraction        | 0.0634      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.48        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.4        |\n",
      "|    n_updates            | 15360       |\n",
      "|    policy_gradient_loss | 5.03e-05    |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.05e+03    |\n",
      "|    ep_rew_mean          | 1.22e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 1538        |\n",
      "|    time_elapsed         | 5723        |\n",
      "|    total_timesteps      | 3149824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022281326 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.49        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.21        |\n",
      "|    n_updates            | 15370       |\n",
      "|    policy_gradient_loss | -0.000663   |\n",
      "|    std                  | 0.267       |\n",
      "|    value_loss           | 1.45e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3150000, episode_reward=-54983.67 +/- 67664.13\n",
      "Episode length: 3030.80 +/- 2411.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.03e+03    |\n",
      "|    mean_reward          | -5.5e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029677305 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.49        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 15380       |\n",
      "|    policy_gradient_loss | 0.00863     |\n",
      "|    std                  | 0.268       |\n",
      "|    value_loss           | 103         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.06e+03 |\n",
      "|    ep_rew_mean     | 1.24e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 549      |\n",
      "|    iterations      | 1539     |\n",
      "|    time_elapsed    | 5732     |\n",
      "|    total_timesteps | 3151872  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.03e+03   |\n",
      "|    ep_rew_mean          | 9.79e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 549        |\n",
      "|    iterations           | 1540       |\n",
      "|    time_elapsed         | 5734       |\n",
      "|    total_timesteps      | 3153920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08826067 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.49       |\n",
      "|    explained_variance   | 0.326      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.55e+06   |\n",
      "|    n_updates            | 15390      |\n",
      "|    policy_gradient_loss | 0.0182     |\n",
      "|    std                  | 0.268      |\n",
      "|    value_loss           | 1.95e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3155000, episode_reward=-7848.81 +/- 7364.05\n",
      "Episode length: 4201.00 +/- 32.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.2e+03    |\n",
      "|    mean_reward          | -7.85e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3155000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23491469 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.48       |\n",
      "|    explained_variance   | 0.353      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.97e+06   |\n",
      "|    n_updates            | 15400      |\n",
      "|    policy_gradient_loss | 0.00336    |\n",
      "|    std                  | 0.267      |\n",
      "|    value_loss           | 1.29e+07   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.03e+03 |\n",
      "|    ep_rew_mean     | 9.86e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 549      |\n",
      "|    iterations      | 1541     |\n",
      "|    time_elapsed    | 5746     |\n",
      "|    total_timesteps | 3155968  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.03e+03    |\n",
      "|    ep_rew_mean          | 9.92e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 549         |\n",
      "|    iterations           | 1542        |\n",
      "|    time_elapsed         | 5748        |\n",
      "|    total_timesteps      | 3158016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056124806 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.5         |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21          |\n",
      "|    n_updates            | 15410       |\n",
      "|    policy_gradient_loss | 0.0197      |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 1.18e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3160000, episode_reward=-160477.23 +/- 29214.45\n",
      "Episode length: 4013.60 +/- 1972.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.01e+03     |\n",
      "|    mean_reward          | -1.6e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0149411885 |\n",
      "|    clip_fraction        | 0.221        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.51         |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 12.2         |\n",
      "|    n_updates            | 15420        |\n",
      "|    policy_gradient_loss | 0.00727      |\n",
      "|    std                  | 0.265        |\n",
      "|    value_loss           | 57.5         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.02e+03 |\n",
      "|    ep_rew_mean     | 8.77e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 548      |\n",
      "|    iterations      | 1543     |\n",
      "|    time_elapsed    | 5759     |\n",
      "|    total_timesteps | 3160064  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.02e+03   |\n",
      "|    ep_rew_mean          | 8.92e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 548        |\n",
      "|    iterations           | 1544       |\n",
      "|    time_elapsed         | 5761       |\n",
      "|    total_timesteps      | 3162112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14885904 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.52       |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.42e+06   |\n",
      "|    n_updates            | 15430      |\n",
      "|    policy_gradient_loss | 0.0135     |\n",
      "|    std                  | 0.266      |\n",
      "|    value_loss           | 1.12e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.02e+03   |\n",
      "|    ep_rew_mean          | 7.97e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 549        |\n",
      "|    iterations           | 1545       |\n",
      "|    time_elapsed         | 5763       |\n",
      "|    total_timesteps      | 3164160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06630774 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.51       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.9       |\n",
      "|    n_updates            | 15440      |\n",
      "|    policy_gradient_loss | 0.0109     |\n",
      "|    std                  | 0.266      |\n",
      "|    value_loss           | 48.6       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3165000, episode_reward=-138867.55 +/- 21796.46\n",
      "Episode length: 3996.00 +/- 1965.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4e+03       |\n",
      "|    mean_reward          | -1.39e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3165000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017017525 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.51        |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.87e+06    |\n",
      "|    n_updates            | 15450       |\n",
      "|    policy_gradient_loss | 0.00132     |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 1.32e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.02e+03 |\n",
      "|    ep_rew_mean     | 7.97e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 548      |\n",
      "|    iterations      | 1546     |\n",
      "|    time_elapsed    | 5774     |\n",
      "|    total_timesteps | 3166208  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.02e+03     |\n",
      "|    ep_rew_mean          | 8.06e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 1547         |\n",
      "|    time_elapsed         | 5775         |\n",
      "|    total_timesteps      | 3168256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044535086 |\n",
      "|    clip_fraction        | 0.00664      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.51         |\n",
      "|    explained_variance   | 0.69         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.46e+04     |\n",
      "|    n_updates            | 15460        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.266        |\n",
      "|    value_loss           | 6.16e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3170000, episode_reward=-146280.84 +/- 26624.34\n",
      "Episode length: 3888.80 +/- 1913.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.89e+03     |\n",
      "|    mean_reward          | -1.46e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3170000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074987477 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.51         |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.97e+03     |\n",
      "|    n_updates            | 15470        |\n",
      "|    policy_gradient_loss | -0.0108      |\n",
      "|    std                  | 0.266        |\n",
      "|    value_loss           | 9.53e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.01e+03 |\n",
      "|    ep_rew_mean     | 8.05e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 547      |\n",
      "|    iterations      | 1548     |\n",
      "|    time_elapsed    | 5786     |\n",
      "|    total_timesteps | 3170304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 7.83e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 548         |\n",
      "|    iterations           | 1549        |\n",
      "|    time_elapsed         | 5788        |\n",
      "|    total_timesteps      | 3172352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014870107 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.51        |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.59e+03    |\n",
      "|    n_updates            | 15480       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    std                  | 0.265       |\n",
      "|    value_loss           | 3.18e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2e+03      |\n",
      "|    ep_rew_mean          | 7.57e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 548        |\n",
      "|    iterations           | 1550       |\n",
      "|    time_elapsed         | 5790       |\n",
      "|    total_timesteps      | 3174400    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00982805 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.52       |\n",
      "|    explained_variance   | 0.689      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 43.9       |\n",
      "|    n_updates            | 15490      |\n",
      "|    policy_gradient_loss | -0.00887   |\n",
      "|    std                  | 0.265      |\n",
      "|    value_loss           | 2.56e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3175000, episode_reward=-84884.36 +/- 8879.43\n",
      "Episode length: 3024.40 +/- 2419.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.02e+03    |\n",
      "|    mean_reward          | -8.49e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3175000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017465806 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.52        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.9        |\n",
      "|    n_updates            | 15500       |\n",
      "|    policy_gradient_loss | 0.00227     |\n",
      "|    std                  | 0.264       |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.99e+03 |\n",
      "|    ep_rew_mean     | 7.46e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 547      |\n",
      "|    iterations      | 1551     |\n",
      "|    time_elapsed    | 5799     |\n",
      "|    total_timesteps | 3176448  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | 7.42e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 1552        |\n",
      "|    time_elapsed         | 5801        |\n",
      "|    total_timesteps      | 3178496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015056069 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.2        |\n",
      "|    n_updates            | 15510       |\n",
      "|    policy_gradient_loss | 0.00248     |\n",
      "|    std                  | 0.264       |\n",
      "|    value_loss           | 243         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3180000, episode_reward=1994.01 +/- 48620.11\n",
      "Episode length: 4011.60 +/- 1976.80\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.01e+03   |\n",
      "|    mean_reward          | 1.99e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3180000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20064151 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.52       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.3       |\n",
      "|    n_updates            | 15520      |\n",
      "|    policy_gradient_loss | 0.022      |\n",
      "|    std                  | 0.266      |\n",
      "|    value_loss           | 177        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.97e+03 |\n",
      "|    ep_rew_mean     | 7.42e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 547      |\n",
      "|    iterations      | 1553     |\n",
      "|    time_elapsed    | 5812     |\n",
      "|    total_timesteps | 3180544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | 8.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 1554        |\n",
      "|    time_elapsed         | 5814        |\n",
      "|    total_timesteps      | 3182592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015289624 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.52        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 15530       |\n",
      "|    policy_gradient_loss | -0.00228    |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 228         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | 8.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 1555        |\n",
      "|    time_elapsed         | 5816        |\n",
      "|    total_timesteps      | 3184640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019818414 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33          |\n",
      "|    n_updates            | 15540       |\n",
      "|    policy_gradient_loss | 0.00514     |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 229         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3185000, episode_reward=29813.10 +/- 64531.72\n",
      "Episode length: 4013.00 +/- 1974.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.01e+03    |\n",
      "|    mean_reward          | 2.98e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3185000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009795725 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 15550       |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 249         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.93e+03 |\n",
      "|    ep_rew_mean     | 5.71e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 546      |\n",
      "|    iterations      | 1556     |\n",
      "|    time_elapsed    | 5827     |\n",
      "|    total_timesteps | 3186688  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.93e+03     |\n",
      "|    ep_rew_mean          | 5.71e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 1557         |\n",
      "|    time_elapsed         | 5829         |\n",
      "|    total_timesteps      | 3188736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043631904 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.53         |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.88e+06     |\n",
      "|    n_updates            | 15560        |\n",
      "|    policy_gradient_loss | -0.00523     |\n",
      "|    std                  | 0.266        |\n",
      "|    value_loss           | 2.58e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3190000, episode_reward=3916.67 +/- 77759.82\n",
      "Episode length: 3025.20 +/- 2418.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.03e+03    |\n",
      "|    mean_reward          | 3.92e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026366558 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 89.2        |\n",
      "|    n_updates            | 15570       |\n",
      "|    policy_gradient_loss | 0.00139     |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 231         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.95e+03 |\n",
      "|    ep_rew_mean     | 6.14e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 546      |\n",
      "|    iterations      | 1558     |\n",
      "|    time_elapsed    | 5837     |\n",
      "|    total_timesteps | 3190784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | 6.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 1559        |\n",
      "|    time_elapsed         | 5839        |\n",
      "|    total_timesteps      | 3192832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015041878 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.53        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 359         |\n",
      "|    n_updates            | 15580       |\n",
      "|    policy_gradient_loss | -0.000626   |\n",
      "|    std                  | 0.265       |\n",
      "|    value_loss           | 515         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.98e+03    |\n",
      "|    ep_rew_mean          | 6.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 1560        |\n",
      "|    time_elapsed         | 5841        |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024066275 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.54        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.7        |\n",
      "|    n_updates            | 15590       |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    std                  | 0.265       |\n",
      "|    value_loss           | 74.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3195000, episode_reward=36294.99 +/- 64320.09\n",
      "Episode length: 4012.00 +/- 1976.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.01e+03    |\n",
      "|    mean_reward          | 3.63e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3195000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.065968364 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.55        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 15600       |\n",
      "|    policy_gradient_loss | 0.00779     |\n",
      "|    std                  | 0.265       |\n",
      "|    value_loss           | 318         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.98e+03 |\n",
      "|    ep_rew_mean     | 6.48e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 546      |\n",
      "|    iterations      | 1561     |\n",
      "|    time_elapsed    | 5852     |\n",
      "|    total_timesteps | 3196928  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.01e+03   |\n",
      "|    ep_rew_mean          | 7.07e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 546        |\n",
      "|    iterations           | 1562       |\n",
      "|    time_elapsed         | 5854       |\n",
      "|    total_timesteps      | 3198976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06106188 |\n",
      "|    clip_fraction        | 0.291      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.55       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.5       |\n",
      "|    n_updates            | 15610      |\n",
      "|    policy_gradient_loss | -0.00351   |\n",
      "|    std                  | 0.265      |\n",
      "|    value_loss           | 130        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3200000, episode_reward=7131.41 +/- 83962.75\n",
      "Episode length: 3025.60 +/- 2418.14\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.03e+03     |\n",
      "|    mean_reward          | 7.13e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062991707 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.55         |\n",
      "|    explained_variance   | 0.435        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 15620        |\n",
      "|    policy_gradient_loss | -0.00563     |\n",
      "|    std                  | 0.265        |\n",
      "|    value_loss           | 6.49e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.01e+03 |\n",
      "|    ep_rew_mean     | 7.07e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 545      |\n",
      "|    iterations      | 1563     |\n",
      "|    time_elapsed    | 5863     |\n",
      "|    total_timesteps | 3201024  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | 7.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 1564        |\n",
      "|    time_elapsed         | 5865        |\n",
      "|    total_timesteps      | 3203072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024611287 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.54        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 15630       |\n",
      "|    policy_gradient_loss | 0.0052      |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3205000, episode_reward=86733.63 +/- 3201.67\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.67e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3205000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017257899 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.54        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 15640       |\n",
      "|    policy_gradient_loss | 0.01        |\n",
      "|    std                  | 0.267       |\n",
      "|    value_loss           | 298         |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.05e+03 |\n",
      "|    ep_rew_mean     | 7.48e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 545      |\n",
      "|    iterations      | 1565     |\n",
      "|    time_elapsed    | 5878     |\n",
      "|    total_timesteps | 3205120  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.05e+03    |\n",
      "|    ep_rew_mean          | 7.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 1566        |\n",
      "|    time_elapsed         | 5880        |\n",
      "|    total_timesteps      | 3207168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009039672 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.54        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.79e+03    |\n",
      "|    n_updates            | 15650       |\n",
      "|    policy_gradient_loss | 0.0034      |\n",
      "|    std                  | 0.266       |\n",
      "|    value_loss           | 5.68e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | 8.1e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 1567        |\n",
      "|    time_elapsed         | 5882        |\n",
      "|    total_timesteps      | 3209216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025113324 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.55        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 15660       |\n",
      "|    policy_gradient_loss | 0.00868     |\n",
      "|    std                  | 0.265       |\n",
      "|    value_loss           | 94.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3210000, episode_reward=79114.52 +/- 8225.26\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 7.91e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3210000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076343794 |\n",
      "|    clip_fraction        | 0.0986       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.56         |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.22e+04     |\n",
      "|    n_updates            | 15670        |\n",
      "|    policy_gradient_loss | -0.000862    |\n",
      "|    std                  | 0.265        |\n",
      "|    value_loss           | 4.03e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.08e+03 |\n",
      "|    ep_rew_mean     | 8.1e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 544      |\n",
      "|    iterations      | 1568     |\n",
      "|    time_elapsed    | 5896     |\n",
      "|    total_timesteps | 3211264  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.08e+03   |\n",
      "|    ep_rew_mean          | 5.33e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 544        |\n",
      "|    iterations           | 1569       |\n",
      "|    time_elapsed         | 5898       |\n",
      "|    total_timesteps      | 3213312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08899013 |\n",
      "|    clip_fraction        | 0.4        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.59       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 10.6       |\n",
      "|    n_updates            | 15680      |\n",
      "|    policy_gradient_loss | 0.0195     |\n",
      "|    std                  | 0.263      |\n",
      "|    value_loss           | 28.5       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3215000, episode_reward=20043.15 +/- 93639.47\n",
      "Episode length: 3024.20 +/- 2419.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.02e+03    |\n",
      "|    mean_reward          | 2e+04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3215000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029322496 |\n",
      "|    clip_fraction        | 0.347       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.61        |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32e+07    |\n",
      "|    n_updates            | 15690       |\n",
      "|    policy_gradient_loss | 0.0162      |\n",
      "|    std                  | 0.263       |\n",
      "|    value_loss           | 4.19e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.08e+03 |\n",
      "|    ep_rew_mean     | 5.33e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 544      |\n",
      "|    iterations      | 1570     |\n",
      "|    time_elapsed    | 5906     |\n",
      "|    total_timesteps | 3215360  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | 5.33e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 1571        |\n",
      "|    time_elapsed         | 5908        |\n",
      "|    total_timesteps      | 3217408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021507733 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.62        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 15700       |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    std                  | 0.26        |\n",
      "|    value_loss           | 376         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.12e+03   |\n",
      "|    ep_rew_mean          | 6.14e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 544        |\n",
      "|    iterations           | 1572       |\n",
      "|    time_elapsed         | 5910       |\n",
      "|    total_timesteps      | 3219456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01805876 |\n",
      "|    clip_fraction        | 0.332      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.64       |\n",
      "|    explained_variance   | 0.625      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 20.6       |\n",
      "|    n_updates            | 15710      |\n",
      "|    policy_gradient_loss | 0.0144     |\n",
      "|    std                  | 0.259      |\n",
      "|    value_loss           | 103        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3220000, episode_reward=92374.67 +/- 5871.28\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 9.24e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010106423 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.65        |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 966         |\n",
      "|    n_updates            | 15720       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.259       |\n",
      "|    value_loss           | 2.25e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.12e+03 |\n",
      "|    ep_rew_mean     | 6.14e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 543      |\n",
      "|    iterations      | 1573     |\n",
      "|    time_elapsed    | 5924     |\n",
      "|    total_timesteps | 3221504  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.15e+03   |\n",
      "|    ep_rew_mean          | 7.07e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 543        |\n",
      "|    iterations           | 1574       |\n",
      "|    time_elapsed         | 5926       |\n",
      "|    total_timesteps      | 3223552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04971609 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.64       |\n",
      "|    explained_variance   | 0.921      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.3        |\n",
      "|    n_updates            | 15730      |\n",
      "|    policy_gradient_loss | 0.0322     |\n",
      "|    std                  | 0.26       |\n",
      "|    value_loss           | 47.1       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3225000, episode_reward=83158.87 +/- 4907.20\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.32e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3225000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008204356 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.63        |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.36e+06    |\n",
      "|    n_updates            | 15740       |\n",
      "|    policy_gradient_loss | 0.000657    |\n",
      "|    std                  | 0.26        |\n",
      "|    value_loss           | 1.16e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.15e+03 |\n",
      "|    ep_rew_mean     | 7.07e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 543      |\n",
      "|    iterations      | 1575     |\n",
      "|    time_elapsed    | 5939     |\n",
      "|    total_timesteps | 3225600  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.15e+03    |\n",
      "|    ep_rew_mean          | 7.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 543         |\n",
      "|    iterations           | 1576        |\n",
      "|    time_elapsed         | 5941        |\n",
      "|    total_timesteps      | 3227648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061612032 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.66        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 15750       |\n",
      "|    policy_gradient_loss | 0.00673     |\n",
      "|    std                  | 0.258       |\n",
      "|    value_loss           | 52.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.18e+03   |\n",
      "|    ep_rew_mean          | 7.82e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 543        |\n",
      "|    iterations           | 1577       |\n",
      "|    time_elapsed         | 5943       |\n",
      "|    total_timesteps      | 3229696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09184505 |\n",
      "|    clip_fraction        | 0.43       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.7        |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.93       |\n",
      "|    n_updates            | 15760      |\n",
      "|    policy_gradient_loss | 0.0226     |\n",
      "|    std                  | 0.257      |\n",
      "|    value_loss           | 35.6       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3230000, episode_reward=90376.10 +/- 5324.23\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 9.04e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3230000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017121047 |\n",
      "|    clip_fraction        | 0.0581       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.7          |\n",
      "|    explained_variance   | 0.662        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.42e+04     |\n",
      "|    n_updates            | 15770        |\n",
      "|    policy_gradient_loss | 0.00619      |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 9.51e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.18e+03 |\n",
      "|    ep_rew_mean     | 7.82e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 542      |\n",
      "|    iterations      | 1578     |\n",
      "|    time_elapsed    | 5957     |\n",
      "|    total_timesteps | 3231744  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.21e+03    |\n",
      "|    ep_rew_mean          | 8.59e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 1579        |\n",
      "|    time_elapsed         | 5958        |\n",
      "|    total_timesteps      | 3233792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037695266 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.68        |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.64        |\n",
      "|    n_updates            | 15780       |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    std                  | 0.261       |\n",
      "|    value_loss           | 16.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3235000, episode_reward=92023.40 +/- 4722.68\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 9.2e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3235000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003841919 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.66        |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.69e+03    |\n",
      "|    n_updates            | 15790       |\n",
      "|    policy_gradient_loss | 0.00335     |\n",
      "|    std                  | 0.261       |\n",
      "|    value_loss           | 1.04e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.21e+03 |\n",
      "|    ep_rew_mean     | 8.59e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 541      |\n",
      "|    iterations      | 1580     |\n",
      "|    time_elapsed    | 5972     |\n",
      "|    total_timesteps | 3235840  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.23e+03   |\n",
      "|    ep_rew_mean          | 7.81e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 541        |\n",
      "|    iterations           | 1581       |\n",
      "|    time_elapsed         | 5974       |\n",
      "|    total_timesteps      | 3237888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03244251 |\n",
      "|    clip_fraction        | 0.398      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.67       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.33       |\n",
      "|    n_updates            | 15800      |\n",
      "|    policy_gradient_loss | 0.0117     |\n",
      "|    std                  | 0.261      |\n",
      "|    value_loss           | 28.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.23e+03    |\n",
      "|    ep_rew_mean          | 7.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 1582        |\n",
      "|    time_elapsed         | 5976        |\n",
      "|    total_timesteps      | 3239936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011190719 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.67        |\n",
      "|    explained_variance   | 0.293       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.91e+06    |\n",
      "|    n_updates            | 15810       |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    std                  | 0.261       |\n",
      "|    value_loss           | 1.54e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3240000, episode_reward=-21839.73 +/- 6361.79\n",
      "Episode length: 4155.20 +/- 22.59\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 4.16e+03      |\n",
      "|    mean_reward          | -2.18e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 3240000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00045277254 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.67          |\n",
      "|    explained_variance   | 0.733         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.48e+05      |\n",
      "|    n_updates            | 15820         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    std                  | 0.261         |\n",
      "|    value_loss           | 3.57e+05      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.25e+03 |\n",
      "|    ep_rew_mean     | 7.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 541      |\n",
      "|    iterations      | 1583     |\n",
      "|    time_elapsed    | 5987     |\n",
      "|    total_timesteps | 3241984  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.27e+03     |\n",
      "|    ep_rew_mean          | 6.81e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 1584         |\n",
      "|    time_elapsed         | 5989         |\n",
      "|    total_timesteps      | 3244032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029835366 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.67         |\n",
      "|    explained_variance   | 0.409        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.5e+05      |\n",
      "|    n_updates            | 15830        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    std                  | 0.261        |\n",
      "|    value_loss           | 1.48e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3245000, episode_reward=-11792.65 +/- 5225.21\n",
      "Episode length: 4711.00 +/- 22.79\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 4.71e+03      |\n",
      "|    mean_reward          | -1.18e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 3245000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00024239375 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.67          |\n",
      "|    explained_variance   | 0.405         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.34e+06      |\n",
      "|    n_updates            | 15840         |\n",
      "|    policy_gradient_loss | -0.00126      |\n",
      "|    std                  | 0.261         |\n",
      "|    value_loss           | 1.41e+07      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.27e+03 |\n",
      "|    ep_rew_mean     | 6.81e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 540      |\n",
      "|    iterations      | 1585     |\n",
      "|    time_elapsed    | 6002     |\n",
      "|    total_timesteps | 3246080  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.27e+03    |\n",
      "|    ep_rew_mean          | 6.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 540         |\n",
      "|    iterations           | 1586        |\n",
      "|    time_elapsed         | 6004        |\n",
      "|    total_timesteps      | 3248128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027358277 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.69        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 15850       |\n",
      "|    policy_gradient_loss | 0.0225      |\n",
      "|    std                  | 0.261       |\n",
      "|    value_loss           | 24.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3250000, episode_reward=91925.60 +/- 7429.11\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 9.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012918395 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.7         |\n",
      "|    explained_variance   | 0.585       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 15860       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    std                  | 0.26        |\n",
      "|    value_loss           | 3.14e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 7.49e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 540      |\n",
      "|    iterations      | 1587     |\n",
      "|    time_elapsed    | 6017     |\n",
      "|    total_timesteps | 3250176  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.3e+03      |\n",
      "|    ep_rew_mean          | 7.49e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 1588         |\n",
      "|    time_elapsed         | 6019         |\n",
      "|    total_timesteps      | 3252224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049781622 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.7          |\n",
      "|    explained_variance   | 0.875        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+03     |\n",
      "|    n_updates            | 15870        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    std                  | 0.26         |\n",
      "|    value_loss           | 4.89e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.33e+03   |\n",
      "|    ep_rew_mean          | 8.3e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 540        |\n",
      "|    iterations           | 1589       |\n",
      "|    time_elapsed         | 6021       |\n",
      "|    total_timesteps      | 3254272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02945298 |\n",
      "|    clip_fraction        | 0.294      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.72       |\n",
      "|    explained_variance   | 0.95       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.04       |\n",
      "|    n_updates            | 15880      |\n",
      "|    policy_gradient_loss | 0.0184     |\n",
      "|    std                  | 0.257      |\n",
      "|    value_loss           | 25.7       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3255000, episode_reward=91650.21 +/- 5375.62\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 9.17e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3255000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048538516 |\n",
      "|    clip_fraction        | 0.2          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.74         |\n",
      "|    explained_variance   | 0.628        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.54e+03     |\n",
      "|    n_updates            | 15890        |\n",
      "|    policy_gradient_loss | -0.000641    |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 3.01e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.33e+03 |\n",
      "|    ep_rew_mean     | 8.3e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 539      |\n",
      "|    iterations      | 1590     |\n",
      "|    time_elapsed    | 6034     |\n",
      "|    total_timesteps | 3256320  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.33e+03   |\n",
      "|    ep_rew_mean          | 8.3e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 539        |\n",
      "|    iterations           | 1591       |\n",
      "|    time_elapsed         | 6036       |\n",
      "|    total_timesteps      | 3258368    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08426613 |\n",
      "|    clip_fraction        | 0.383      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.74       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.3        |\n",
      "|    n_updates            | 15900      |\n",
      "|    policy_gradient_loss | 0.0111     |\n",
      "|    std                  | 0.256      |\n",
      "|    value_loss           | 17.2       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3260000, episode_reward=92872.44 +/- 3140.20\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 9.29e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048981056 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 15910       |\n",
      "|    policy_gradient_loss | 0.00992     |\n",
      "|    std                  | 0.257       |\n",
      "|    value_loss           | 46          |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.36e+03 |\n",
      "|    ep_rew_mean     | 8.82e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 538      |\n",
      "|    iterations      | 1592     |\n",
      "|    time_elapsed    | 6050     |\n",
      "|    total_timesteps | 3260416  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.36e+03     |\n",
      "|    ep_rew_mean          | 8.82e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 539          |\n",
      "|    iterations           | 1593         |\n",
      "|    time_elapsed         | 6052         |\n",
      "|    total_timesteps      | 3262464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050425585 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.581        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 429          |\n",
      "|    n_updates            | 15920        |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 7.2e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | 9.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 1594        |\n",
      "|    time_elapsed         | 6053        |\n",
      "|    total_timesteps      | 3264512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009109584 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.55e+03    |\n",
      "|    n_updates            | 15930       |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    std                  | 0.257       |\n",
      "|    value_loss           | 6.69e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3265000, episode_reward=91162.82 +/- 4578.31\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 9.12e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3265000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021111225 |\n",
      "|    clip_fraction        | 0.00425      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.299        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 788          |\n",
      "|    n_updates            | 15940        |\n",
      "|    policy_gradient_loss | -0.00219     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 1.58e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.39e+03 |\n",
      "|    ep_rew_mean     | 9.45e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 538      |\n",
      "|    iterations      | 1595     |\n",
      "|    time_elapsed    | 6067     |\n",
      "|    total_timesteps | 3266560  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.39e+03   |\n",
      "|    ep_rew_mean          | 9.45e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 538        |\n",
      "|    iterations           | 1596       |\n",
      "|    time_elapsed         | 6069       |\n",
      "|    total_timesteps      | 3268608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02990025 |\n",
      "|    clip_fraction        | 0.264      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.74       |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 15950      |\n",
      "|    policy_gradient_loss | -0.00107   |\n",
      "|    std                  | 0.255      |\n",
      "|    value_loss           | 68.9       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3270000, episode_reward=8851.84 +/- 98829.14\n",
      "Episode length: 3025.00 +/- 2418.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.02e+03     |\n",
      "|    mean_reward          | 8.85e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3270000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050934358 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.75         |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 91.4         |\n",
      "|    n_updates            | 15960        |\n",
      "|    policy_gradient_loss | 0.00208      |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 747          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.42e+03 |\n",
      "|    ep_rew_mean     | 1.01e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 538      |\n",
      "|    iterations      | 1597     |\n",
      "|    time_elapsed    | 6078     |\n",
      "|    total_timesteps | 3270656  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.42e+03     |\n",
      "|    ep_rew_mean          | 1.01e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 1598         |\n",
      "|    time_elapsed         | 6079         |\n",
      "|    total_timesteps      | 3272704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075775324 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.48e+05     |\n",
      "|    n_updates            | 15970        |\n",
      "|    policy_gradient_loss | 0.00275      |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 1.2e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.41e+03     |\n",
      "|    ep_rew_mean          | 7.79e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 1599         |\n",
      "|    time_elapsed         | 6081         |\n",
      "|    total_timesteps      | 3274752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085028475 |\n",
      "|    clip_fraction        | 0.0417       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 164          |\n",
      "|    n_updates            | 15980        |\n",
      "|    policy_gradient_loss | 0.00112      |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 445          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3275000, episode_reward=84919.56 +/- 7778.00\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 8.49e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3275000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052911905 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.77e+07     |\n",
      "|    n_updates            | 15990        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 2.98e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.41e+03 |\n",
      "|    ep_rew_mean     | 7.79e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 1600     |\n",
      "|    time_elapsed    | 6095     |\n",
      "|    total_timesteps | 3276800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.45e+03    |\n",
      "|    ep_rew_mean          | 9.71e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 537         |\n",
      "|    iterations           | 1601        |\n",
      "|    time_elapsed         | 6097        |\n",
      "|    total_timesteps      | 3278848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014998144 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | 0.00551     |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 32          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3280000, episode_reward=41988.42 +/- 75135.05\n",
      "Episode length: 4011.60 +/- 1976.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.01e+03    |\n",
      "|    mean_reward          | 4.2e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005851847 |\n",
      "|    clip_fraction        | 0.0204      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.3        |\n",
      "|    n_updates            | 16010       |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 9.81e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.45e+03 |\n",
      "|    ep_rew_mean     | 9.71e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 537      |\n",
      "|    iterations      | 1602     |\n",
      "|    time_elapsed    | 6108     |\n",
      "|    total_timesteps | 3280896  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.46e+03   |\n",
      "|    ep_rew_mean          | 9.75e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 537        |\n",
      "|    iterations           | 1603       |\n",
      "|    time_elapsed         | 6110       |\n",
      "|    total_timesteps      | 3282944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04377272 |\n",
      "|    clip_fraction        | 0.333      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.79       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 10.3       |\n",
      "|    n_updates            | 16020      |\n",
      "|    policy_gradient_loss | 0.00374    |\n",
      "|    std                  | 0.253      |\n",
      "|    value_loss           | 27         |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.46e+03    |\n",
      "|    ep_rew_mean          | 9.75e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 537         |\n",
      "|    iterations           | 1604        |\n",
      "|    time_elapsed         | 6111        |\n",
      "|    total_timesteps      | 3284992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007774151 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 16030       |\n",
      "|    policy_gradient_loss | 0.00254     |\n",
      "|    std                  | 0.252       |\n",
      "|    value_loss           | 265         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3285000, episode_reward=35164.03 +/- 5279.72\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 3.52e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3285000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020539787 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.47        |\n",
      "|    n_updates            | 16040       |\n",
      "|    policy_gradient_loss | 0.00157     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 26.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.47e+03 |\n",
      "|    ep_rew_mean     | 9.94e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 1605     |\n",
      "|    time_elapsed    | 6125     |\n",
      "|    total_timesteps | 3287040  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.47e+03     |\n",
      "|    ep_rew_mean          | 9.94e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 536          |\n",
      "|    iterations           | 1606         |\n",
      "|    time_elapsed         | 6127         |\n",
      "|    total_timesteps      | 3289088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075124027 |\n",
      "|    clip_fraction        | 0.0588       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 145          |\n",
      "|    n_updates            | 16050        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    std                  | 0.251        |\n",
      "|    value_loss           | 1.43e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3290000, episode_reward=43014.58 +/- 7136.01\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 4.3e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3290000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070163184 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28.8         |\n",
      "|    n_updates            | 16060        |\n",
      "|    policy_gradient_loss | 0.00104      |\n",
      "|    std                  | 0.25         |\n",
      "|    value_loss           | 111          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.48e+03 |\n",
      "|    ep_rew_mean     | 1.01e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 1607     |\n",
      "|    time_elapsed    | 6140     |\n",
      "|    total_timesteps | 3291136  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.47e+03     |\n",
      "|    ep_rew_mean          | 8.94e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 536          |\n",
      "|    iterations           | 1608         |\n",
      "|    time_elapsed         | 6142         |\n",
      "|    total_timesteps      | 3293184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072219865 |\n",
      "|    clip_fraction        | 0.0536       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.86         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.1         |\n",
      "|    n_updates            | 16070        |\n",
      "|    policy_gradient_loss | -0.00115     |\n",
      "|    std                  | 0.25         |\n",
      "|    value_loss           | 1.01e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3295000, episode_reward=41238.78 +/- 4789.16\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 4.12e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3295000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03050207 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.85       |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.22e+06   |\n",
      "|    n_updates            | 16080      |\n",
      "|    policy_gradient_loss | 0.00202    |\n",
      "|    std                  | 0.25       |\n",
      "|    value_loss           | 1.27e+07   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.47e+03 |\n",
      "|    ep_rew_mean     | 8.94e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 535      |\n",
      "|    iterations      | 1609     |\n",
      "|    time_elapsed    | 6156     |\n",
      "|    total_timesteps | 3295232  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.48e+03    |\n",
      "|    ep_rew_mean          | 9.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 1610        |\n",
      "|    time_elapsed         | 6157        |\n",
      "|    total_timesteps      | 3297280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030631624 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 16090       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 59.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+03    |\n",
      "|    ep_rew_mean          | 9.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 1611        |\n",
      "|    time_elapsed         | 6159        |\n",
      "|    total_timesteps      | 3299328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008230802 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 16100       |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 3.31e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3300000, episode_reward=13626.74 +/- 3444.15\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 1.36e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026207976 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.4        |\n",
      "|    n_updates            | 16110       |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 8.97e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.49e+03 |\n",
      "|    ep_rew_mean     | 9.07e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 534      |\n",
      "|    iterations      | 1612     |\n",
      "|    time_elapsed    | 6173     |\n",
      "|    total_timesteps | 3301376  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.51e+03   |\n",
      "|    ep_rew_mean          | 9.19e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 534        |\n",
      "|    iterations           | 1613       |\n",
      "|    time_elapsed         | 6175       |\n",
      "|    total_timesteps      | 3303424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26314378 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.84       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.39       |\n",
      "|    n_updates            | 16120      |\n",
      "|    policy_gradient_loss | 0.0281     |\n",
      "|    std                  | 0.251      |\n",
      "|    value_loss           | 15.9       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3305000, episode_reward=30633.47 +/- 5876.71\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 3.06e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3305000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014398254 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 16130       |\n",
      "|    policy_gradient_loss | 0.0792      |\n",
      "|    std                  | 0.252       |\n",
      "|    value_loss           | 465         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.51e+03 |\n",
      "|    ep_rew_mean     | 9.19e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 534      |\n",
      "|    iterations      | 1614     |\n",
      "|    time_elapsed    | 6188     |\n",
      "|    total_timesteps | 3305472  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54e+03    |\n",
      "|    ep_rew_mean          | 1.06e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 534         |\n",
      "|    iterations           | 1615        |\n",
      "|    time_elapsed         | 6190        |\n",
      "|    total_timesteps      | 3307520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037890755 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15          |\n",
      "|    n_updates            | 16140       |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 33.1        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54e+03    |\n",
      "|    ep_rew_mean          | 1.06e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 534         |\n",
      "|    iterations           | 1616        |\n",
      "|    time_elapsed         | 6192        |\n",
      "|    total_timesteps      | 3309568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006433705 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 16150       |\n",
      "|    policy_gradient_loss | 0.00107     |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 167         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3310000, episode_reward=37191.70 +/- 4977.56\n",
      "Episode length: 4081.80 +/- 17.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.08e+03    |\n",
      "|    mean_reward          | 3.72e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013511459 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 70.3        |\n",
      "|    n_updates            | 16160       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 175         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.58e+03 |\n",
      "|    ep_rew_mean     | 1.2e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 533      |\n",
      "|    iterations      | 1617     |\n",
      "|    time_elapsed    | 6203     |\n",
      "|    total_timesteps | 3311616  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.59e+03  |\n",
      "|    ep_rew_mean          | 1.21e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 533       |\n",
      "|    iterations           | 1618      |\n",
      "|    time_elapsed         | 6205      |\n",
      "|    total_timesteps      | 3313664   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3452689 |\n",
      "|    clip_fraction        | 0.254     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.84      |\n",
      "|    explained_variance   | 0.932     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 21.3      |\n",
      "|    n_updates            | 16170     |\n",
      "|    policy_gradient_loss | -0.00607  |\n",
      "|    std                  | 0.251     |\n",
      "|    value_loss           | 1.23e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3315000, episode_reward=41247.79 +/- 3895.55\n",
      "Episode length: 3152.20 +/- 34.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.15e+03    |\n",
      "|    mean_reward          | 4.12e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3315000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016135056 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 16180       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    std                  | 0.252       |\n",
      "|    value_loss           | 99.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.59e+03 |\n",
      "|    ep_rew_mean     | 1.22e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 533      |\n",
      "|    iterations      | 1619     |\n",
      "|    time_elapsed    | 6215     |\n",
      "|    total_timesteps | 3315712  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.59e+03    |\n",
      "|    ep_rew_mean          | 1.22e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 533         |\n",
      "|    iterations           | 1620        |\n",
      "|    time_elapsed         | 6216        |\n",
      "|    total_timesteps      | 3317760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009704797 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.808       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 16190       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 5.89e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.6e+03    |\n",
      "|    ep_rew_mean          | 1.21e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 533        |\n",
      "|    iterations           | 1621       |\n",
      "|    time_elapsed         | 6218       |\n",
      "|    total_timesteps      | 3319808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06920746 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.84       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.9        |\n",
      "|    n_updates            | 16200      |\n",
      "|    policy_gradient_loss | 0.0128     |\n",
      "|    std                  | 0.253      |\n",
      "|    value_loss           | 22         |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3320000, episode_reward=31971.69 +/- 4239.87\n",
      "Episode length: 4646.20 +/- 11.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.65e+03    |\n",
      "|    mean_reward          | 3.2e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014589718 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 204         |\n",
      "|    n_updates            | 16210       |\n",
      "|    policy_gradient_loss | 0.0412      |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 764         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.6e+03  |\n",
      "|    ep_rew_mean     | 1.21e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 533      |\n",
      "|    iterations      | 1622     |\n",
      "|    time_elapsed    | 6231     |\n",
      "|    total_timesteps | 3321856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.6e+03     |\n",
      "|    ep_rew_mean          | 1.21e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 533         |\n",
      "|    iterations           | 1623        |\n",
      "|    time_elapsed         | 6233        |\n",
      "|    total_timesteps      | 3323904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017549932 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.4        |\n",
      "|    n_updates            | 16220       |\n",
      "|    policy_gradient_loss | 0.00286     |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3325000, episode_reward=33718.69 +/- 4954.41\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 3.37e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3325000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012923422 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.6        |\n",
      "|    n_updates            | 16230       |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 235         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.62e+03 |\n",
      "|    ep_rew_mean     | 1.22e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 532      |\n",
      "|    iterations      | 1624     |\n",
      "|    time_elapsed    | 6247     |\n",
      "|    total_timesteps | 3325952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.62e+03    |\n",
      "|    ep_rew_mean          | 1.22e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 532         |\n",
      "|    iterations           | 1625        |\n",
      "|    time_elapsed         | 6248        |\n",
      "|    total_timesteps      | 3328000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004636436 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 16240       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 2.2e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3330000, episode_reward=38128.36 +/- 5048.06\n",
      "Episode length: 3764.20 +/- 24.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.76e+03    |\n",
      "|    mean_reward          | 3.81e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018126506 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.9        |\n",
      "|    n_updates            | 16250       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.62e+03 |\n",
      "|    ep_rew_mean     | 1.22e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 531      |\n",
      "|    iterations      | 1626     |\n",
      "|    time_elapsed    | 6259     |\n",
      "|    total_timesteps | 3330048  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.62e+03   |\n",
      "|    ep_rew_mean          | 1.22e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 532        |\n",
      "|    iterations           | 1627       |\n",
      "|    time_elapsed         | 6261       |\n",
      "|    total_timesteps      | 3332096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03233401 |\n",
      "|    clip_fraction        | 0.328      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.84       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.95       |\n",
      "|    n_updates            | 16260      |\n",
      "|    policy_gradient_loss | 0.00392    |\n",
      "|    std                  | 0.254      |\n",
      "|    value_loss           | 24.1       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.66e+03    |\n",
      "|    ep_rew_mean          | 1.37e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 532         |\n",
      "|    iterations           | 1628        |\n",
      "|    time_elapsed         | 6263        |\n",
      "|    total_timesteps      | 3334144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053336177 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | 0.0286      |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3335000, episode_reward=43316.81 +/- 6924.75\n",
      "Episode length: 4293.40 +/- 28.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.29e+03    |\n",
      "|    mean_reward          | 4.33e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3335000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013303431 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71          |\n",
      "|    n_updates            | 16280       |\n",
      "|    policy_gradient_loss | -0.00419    |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 867         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.65e+03 |\n",
      "|    ep_rew_mean     | 1.26e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 531      |\n",
      "|    iterations      | 1629     |\n",
      "|    time_elapsed    | 6275     |\n",
      "|    total_timesteps | 3336192  |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2.65e+03      |\n",
      "|    ep_rew_mean          | 1.26e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 531           |\n",
      "|    iterations           | 1630          |\n",
      "|    time_elapsed         | 6277          |\n",
      "|    total_timesteps      | 3338240       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00030396867 |\n",
      "|    clip_fraction        | 0.0019        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.85          |\n",
      "|    explained_variance   | 0.3           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 8.05e+06      |\n",
      "|    n_updates            | 16290         |\n",
      "|    policy_gradient_loss | -0.00174      |\n",
      "|    std                  | 0.254         |\n",
      "|    value_loss           | 1.61e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=3340000, episode_reward=42502.47 +/- 6121.52\n",
      "Episode length: 4747.00 +/- 19.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.75e+03    |\n",
      "|    mean_reward          | 4.25e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006578432 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+04    |\n",
      "|    n_updates            | 16300       |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 4.73e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.66e+03 |\n",
      "|    ep_rew_mean     | 1.26e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 531      |\n",
      "|    iterations      | 1631     |\n",
      "|    time_elapsed    | 6290     |\n",
      "|    total_timesteps | 3340288  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.66e+03    |\n",
      "|    ep_rew_mean          | 1.26e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 1632        |\n",
      "|    time_elapsed         | 6291        |\n",
      "|    total_timesteps      | 3342336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015814036 |\n",
      "|    clip_fraction        | 0.0802      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 254         |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | -0.00554    |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 5.64e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.66e+03     |\n",
      "|    ep_rew_mean          | 1.26e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 531          |\n",
      "|    iterations           | 1633         |\n",
      "|    time_elapsed         | 6293         |\n",
      "|    total_timesteps      | 3344384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083896555 |\n",
      "|    clip_fraction        | 0.0698       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.872        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 65.6         |\n",
      "|    n_updates            | 16320        |\n",
      "|    policy_gradient_loss | -0.0073      |\n",
      "|    std                  | 0.254        |\n",
      "|    value_loss           | 1.92e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3345000, episode_reward=39142.73 +/- 5714.47\n",
      "Episode length: 3967.00 +/- 31.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.97e+03    |\n",
      "|    mean_reward          | 3.91e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3345000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010361327 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 16330       |\n",
      "|    policy_gradient_loss | -0.000319   |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 409         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.67e+03 |\n",
      "|    ep_rew_mean     | 1.25e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 530      |\n",
      "|    iterations      | 1634     |\n",
      "|    time_elapsed    | 6304     |\n",
      "|    total_timesteps | 3346432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.67e+03    |\n",
      "|    ep_rew_mean          | 1.27e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1635        |\n",
      "|    time_elapsed         | 6306        |\n",
      "|    total_timesteps      | 3348480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021234427 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46          |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | 0.00423     |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 356         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3350000, episode_reward=42000.99 +/- 5952.66\n",
      "Episode length: 4206.00 +/- 15.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.21e+03    |\n",
      "|    mean_reward          | 4.2e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009579653 |\n",
      "|    clip_fraction        | 0.0768      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.87        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 16350       |\n",
      "|    policy_gradient_loss | -0.000658   |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 2.01e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.67e+03 |\n",
      "|    ep_rew_mean     | 1.27e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 530      |\n",
      "|    iterations      | 1636     |\n",
      "|    time_elapsed    | 6318     |\n",
      "|    total_timesteps | 3350528  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.67e+03   |\n",
      "|    ep_rew_mean          | 1.27e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 530        |\n",
      "|    iterations           | 1637       |\n",
      "|    time_elapsed         | 6320       |\n",
      "|    total_timesteps      | 3352576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03731734 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.86       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16.1       |\n",
      "|    n_updates            | 16360      |\n",
      "|    policy_gradient_loss | 0.0104     |\n",
      "|    std                  | 0.254      |\n",
      "|    value_loss           | 79.9       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.67e+03    |\n",
      "|    ep_rew_mean          | 1.28e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1638        |\n",
      "|    time_elapsed         | 6322        |\n",
      "|    total_timesteps      | 3354624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022232387 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | 0.00426     |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3355000, episode_reward=39785.60 +/- 5671.01\n",
      "Episode length: 3384.80 +/- 20.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.38e+03    |\n",
      "|    mean_reward          | 3.98e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3355000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018993333 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.87        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.8        |\n",
      "|    n_updates            | 16380       |\n",
      "|    policy_gradient_loss | 0.000804    |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 253         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.66e+03 |\n",
      "|    ep_rew_mean     | 1.28e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 530      |\n",
      "|    iterations      | 1639     |\n",
      "|    time_elapsed    | 6332     |\n",
      "|    total_timesteps | 3356672  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.66e+03    |\n",
      "|    ep_rew_mean          | 1.28e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1640        |\n",
      "|    time_elapsed         | 6333        |\n",
      "|    total_timesteps      | 3358720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014722474 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.87        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 16390       |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 99.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3360000, episode_reward=43897.87 +/- 5608.52\n",
      "Episode length: 4125.00 +/- 19.57\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.12e+03   |\n",
      "|    mean_reward          | 4.39e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3360000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03781332 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.87       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.3       |\n",
      "|    n_updates            | 16400      |\n",
      "|    policy_gradient_loss | 0.00996    |\n",
      "|    std                  | 0.256      |\n",
      "|    value_loss           | 47.4       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | 1.43e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 529      |\n",
      "|    iterations      | 1641     |\n",
      "|    time_elapsed    | 6345     |\n",
      "|    total_timesteps | 3360768  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.69e+03     |\n",
      "|    ep_rew_mean          | 1.42e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 529          |\n",
      "|    iterations           | 1642         |\n",
      "|    time_elapsed         | 6347         |\n",
      "|    total_timesteps      | 3362816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117884595 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.87         |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+05     |\n",
      "|    n_updates            | 16410        |\n",
      "|    policy_gradient_loss | 0.00332      |\n",
      "|    std                  | 0.256        |\n",
      "|    value_loss           | 1.37e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | 1.42e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1643        |\n",
      "|    time_elapsed         | 6349        |\n",
      "|    total_timesteps      | 3364864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020522628 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.88        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.9        |\n",
      "|    n_updates            | 16420       |\n",
      "|    policy_gradient_loss | 0.00471     |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 83.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3365000, episode_reward=50385.94 +/- 4293.49\n",
      "Episode length: 4967.60 +/- 17.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.97e+03    |\n",
      "|    mean_reward          | 5.04e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3365000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019457413 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 16430       |\n",
      "|    policy_gradient_loss | 0.0147      |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 43.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.7e+03  |\n",
      "|    ep_rew_mean     | 1.44e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 529      |\n",
      "|    iterations      | 1644     |\n",
      "|    time_elapsed    | 6362     |\n",
      "|    total_timesteps | 3366912  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.7e+03     |\n",
      "|    ep_rew_mean          | 1.44e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1645        |\n",
      "|    time_elapsed         | 6364        |\n",
      "|    total_timesteps      | 3368960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010385961 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.7        |\n",
      "|    n_updates            | 16440       |\n",
      "|    policy_gradient_loss | 0.000756    |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 431         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3370000, episode_reward=59360.90 +/- 521.60\n",
      "Episode length: 4401.40 +/- 22.41\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 4.4e+03   |\n",
      "|    mean_reward          | 5.94e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3370000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0486299 |\n",
      "|    clip_fraction        | 0.166     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.89      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 13.2      |\n",
      "|    n_updates            | 16450     |\n",
      "|    policy_gradient_loss | 0.00304   |\n",
      "|    std                  | 0.254     |\n",
      "|    value_loss           | 64.8      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.7e+03  |\n",
      "|    ep_rew_mean     | 1.46e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 528      |\n",
      "|    iterations      | 1646     |\n",
      "|    time_elapsed    | 6376     |\n",
      "|    total_timesteps | 3371008  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.7e+03    |\n",
      "|    ep_rew_mean          | 1.45e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 528        |\n",
      "|    iterations           | 1647       |\n",
      "|    time_elapsed         | 6378       |\n",
      "|    total_timesteps      | 3373056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24902646 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.91       |\n",
      "|    explained_variance   | 0.881      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.56       |\n",
      "|    n_updates            | 16460      |\n",
      "|    policy_gradient_loss | -6.34e-06  |\n",
      "|    std                  | 0.253      |\n",
      "|    value_loss           | 3.27e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3375000, episode_reward=35543.61 +/- 5513.98\n",
      "Episode length: 3204.60 +/- 28.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.2e+03     |\n",
      "|    mean_reward          | 3.55e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3375000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018119978 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.93        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.2        |\n",
      "|    n_updates            | 16470       |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 1.01e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.73e+03 |\n",
      "|    ep_rew_mean     | 1.58e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 528      |\n",
      "|    iterations      | 1648     |\n",
      "|    time_elapsed    | 6387     |\n",
      "|    total_timesteps | 3375104  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.73e+03    |\n",
      "|    ep_rew_mean          | 1.58e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1649        |\n",
      "|    time_elapsed         | 6389        |\n",
      "|    total_timesteps      | 3377152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007672025 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.93        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | -0.00608    |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 3.59e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.74e+03    |\n",
      "|    ep_rew_mean          | 1.69e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1650        |\n",
      "|    time_elapsed         | 6391        |\n",
      "|    total_timesteps      | 3379200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036257844 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 16490       |\n",
      "|    policy_gradient_loss | 0.00746     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 44.1        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3380000, episode_reward=34798.44 +/- 4369.24\n",
      "Episode length: 3017.00 +/- 16.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.02e+03     |\n",
      "|    mean_reward          | 3.48e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3380000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083893165 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.96         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30.6         |\n",
      "|    n_updates            | 16500        |\n",
      "|    policy_gradient_loss | 0.00641      |\n",
      "|    std                  | 0.25         |\n",
      "|    value_loss           | 1.94e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.76e+03 |\n",
      "|    ep_rew_mean     | 1.82e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 528      |\n",
      "|    iterations      | 1651     |\n",
      "|    time_elapsed    | 6400     |\n",
      "|    total_timesteps | 3381248  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.76e+03   |\n",
      "|    ep_rew_mean          | 1.82e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 528        |\n",
      "|    iterations           | 1652       |\n",
      "|    time_elapsed         | 6402       |\n",
      "|    total_timesteps      | 3383296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00897036 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.96       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.03e+04   |\n",
      "|    n_updates            | 16510      |\n",
      "|    policy_gradient_loss | -0.00419   |\n",
      "|    std                  | 0.25       |\n",
      "|    value_loss           | 1.22e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3385000, episode_reward=37641.50 +/- 3118.82\n",
      "Episode length: 2894.20 +/- 9.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.89e+03    |\n",
      "|    mean_reward          | 3.76e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3385000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029859293 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.21        |\n",
      "|    n_updates            | 16520       |\n",
      "|    policy_gradient_loss | 0.0075      |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 13.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.72e+03 |\n",
      "|    ep_rew_mean     | 1.54e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 528      |\n",
      "|    iterations      | 1653     |\n",
      "|    time_elapsed    | 6410     |\n",
      "|    total_timesteps | 3385344  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.72e+03   |\n",
      "|    ep_rew_mean          | 1.54e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 528        |\n",
      "|    iterations           | 1654       |\n",
      "|    time_elapsed         | 6412       |\n",
      "|    total_timesteps      | 3387392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02498385 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.98       |\n",
      "|    explained_variance   | 0.315      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.4e+07    |\n",
      "|    n_updates            | 16530      |\n",
      "|    policy_gradient_loss | 0.00378    |\n",
      "|    std                  | 0.25       |\n",
      "|    value_loss           | 4.14e+07   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.73e+03    |\n",
      "|    ep_rew_mean          | 1.54e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1655        |\n",
      "|    time_elapsed         | 6414        |\n",
      "|    total_timesteps      | 3389440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007814368 |\n",
      "|    clip_fraction        | 0.0401      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.35e+03    |\n",
      "|    n_updates            | 16540       |\n",
      "|    policy_gradient_loss | -0.00761    |\n",
      "|    std                  | 0.249       |\n",
      "|    value_loss           | 3.71e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3390000, episode_reward=-38867.16 +/- 82034.93\n",
      "Episode length: 2606.00 +/- 2059.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.61e+03    |\n",
      "|    mean_reward          | -3.89e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007565031 |\n",
      "|    clip_fraction        | 0.0689      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 16550       |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    std                  | 0.249       |\n",
      "|    value_loss           | 2.02e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.7e+03  |\n",
      "|    ep_rew_mean     | 1.37e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 528      |\n",
      "|    iterations      | 1656     |\n",
      "|    time_elapsed    | 6422     |\n",
      "|    total_timesteps | 3391488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.7e+03     |\n",
      "|    ep_rew_mean          | 1.37e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1657        |\n",
      "|    time_elapsed         | 6424        |\n",
      "|    total_timesteps      | 3393536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013781894 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.298       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+07    |\n",
      "|    n_updates            | 16560       |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    std                  | 0.249       |\n",
      "|    value_loss           | 2.2e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3395000, episode_reward=33794.27 +/- 7112.61\n",
      "Episode length: 3254.00 +/- 19.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.25e+03    |\n",
      "|    mean_reward          | 3.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3395000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010716728 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.98        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 16570       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    std                  | 0.249       |\n",
      "|    value_loss           | 383         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 1.36e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 527      |\n",
      "|    iterations      | 1658     |\n",
      "|    time_elapsed    | 6433     |\n",
      "|    total_timesteps | 3395584  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.74e+03    |\n",
      "|    ep_rew_mean          | 1.53e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 1659        |\n",
      "|    time_elapsed         | 6435        |\n",
      "|    total_timesteps      | 3397632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031678732 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 16580       |\n",
      "|    policy_gradient_loss | 0.00735     |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.74e+03    |\n",
      "|    ep_rew_mean          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1660        |\n",
      "|    time_elapsed         | 6437        |\n",
      "|    total_timesteps      | 3399680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011811305 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 16590       |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 6.4e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3400000, episode_reward=34462.71 +/- 6745.60\n",
      "Episode length: 2989.20 +/- 15.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.99e+03    |\n",
      "|    mean_reward          | 3.45e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025619436 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.1        |\n",
      "|    n_updates            | 16600       |\n",
      "|    policy_gradient_loss | 0.0183      |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 1.28e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.74e+03 |\n",
      "|    ep_rew_mean     | 1.52e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 527      |\n",
      "|    iterations      | 1661     |\n",
      "|    time_elapsed    | 6446     |\n",
      "|    total_timesteps | 3401728  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.74e+03   |\n",
      "|    ep_rew_mean          | 1.51e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 527        |\n",
      "|    iterations           | 1662       |\n",
      "|    time_elapsed         | 6448       |\n",
      "|    total_timesteps      | 3403776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07728645 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.96       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 16610      |\n",
      "|    policy_gradient_loss | 0.00635    |\n",
      "|    std                  | 0.251      |\n",
      "|    value_loss           | 55.2       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3405000, episode_reward=34643.18 +/- 790.91\n",
      "Episode length: 4989.60 +/- 17.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.99e+03    |\n",
      "|    mean_reward          | 3.46e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3405000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018455638 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.3        |\n",
      "|    n_updates            | 16620       |\n",
      "|    policy_gradient_loss | 0.0082      |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 3.48e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.74e+03 |\n",
      "|    ep_rew_mean     | 1.5e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 527      |\n",
      "|    iterations      | 1663     |\n",
      "|    time_elapsed    | 6461     |\n",
      "|    total_timesteps | 3405824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.75e+03    |\n",
      "|    ep_rew_mean          | 1.5e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 1664        |\n",
      "|    time_elapsed         | 6463        |\n",
      "|    total_timesteps      | 3407872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017312083 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.96        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 16630       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.75e+03     |\n",
      "|    ep_rew_mean          | 1.5e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 527          |\n",
      "|    iterations           | 1665         |\n",
      "|    time_elapsed         | 6465         |\n",
      "|    total_timesteps      | 3409920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097424565 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.97         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 16640        |\n",
      "|    policy_gradient_loss | 0.00135      |\n",
      "|    std                  | 0.251        |\n",
      "|    value_loss           | 167          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3410000, episode_reward=28219.64 +/- 611.75\n",
      "Episode length: 4950.80 +/- 43.61\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.95e+03   |\n",
      "|    mean_reward          | 2.82e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3410000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02879899 |\n",
      "|    clip_fraction        | 0.258      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.98       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.5       |\n",
      "|    n_updates            | 16650      |\n",
      "|    policy_gradient_loss | 0.0051     |\n",
      "|    std                  | 0.251      |\n",
      "|    value_loss           | 30.8       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.76e+03 |\n",
      "|    ep_rew_mean     | 1.5e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 526      |\n",
      "|    iterations      | 1666     |\n",
      "|    time_elapsed    | 6479     |\n",
      "|    total_timesteps | 3411968  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | 1.5e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1667        |\n",
      "|    time_elapsed         | 6481        |\n",
      "|    total_timesteps      | 3414016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026200553 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 16660       |\n",
      "|    policy_gradient_loss | 0.00398     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 569         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3415000, episode_reward=31689.62 +/- 2439.61\n",
      "Episode length: 3131.00 +/- 10.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.13e+03   |\n",
      "|    mean_reward          | 3.17e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3415000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01334925 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.99       |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.7        |\n",
      "|    n_updates            | 16670      |\n",
      "|    policy_gradient_loss | -0.000352  |\n",
      "|    std                  | 0.249      |\n",
      "|    value_loss           | 30.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.77e+03 |\n",
      "|    ep_rew_mean     | 1.5e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 526      |\n",
      "|    iterations      | 1668     |\n",
      "|    time_elapsed    | 6490     |\n",
      "|    total_timesteps | 3416064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.77e+03    |\n",
      "|    ep_rew_mean          | 1.51e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1669        |\n",
      "|    time_elapsed         | 6492        |\n",
      "|    total_timesteps      | 3418112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012762714 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.4        |\n",
      "|    n_updates            | 16680       |\n",
      "|    policy_gradient_loss | -0.00853    |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3420000, episode_reward=26733.00 +/- 4888.07\n",
      "Episode length: 2608.80 +/- 20.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.61e+03     |\n",
      "|    mean_reward          | 2.67e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3420000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136697665 |\n",
      "|    clip_fraction        | 0.18         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2            |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.9         |\n",
      "|    n_updates            | 16690        |\n",
      "|    policy_gradient_loss | -0.000404    |\n",
      "|    std                  | 0.249        |\n",
      "|    value_loss           | 103          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.78e+03 |\n",
      "|    ep_rew_mean     | 1.51e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 526      |\n",
      "|    iterations      | 1670     |\n",
      "|    time_elapsed    | 6500     |\n",
      "|    total_timesteps | 3420160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.78e+03    |\n",
      "|    ep_rew_mean          | 1.51e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1671        |\n",
      "|    time_elapsed         | 6501        |\n",
      "|    total_timesteps      | 3422208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030737925 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 16700       |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 1.35e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.8e+03     |\n",
      "|    ep_rew_mean          | 1.63e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1672        |\n",
      "|    time_elapsed         | 6503        |\n",
      "|    total_timesteps      | 3424256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058170877 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.39        |\n",
      "|    n_updates            | 16710       |\n",
      "|    policy_gradient_loss | -0.000133   |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 36          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3425000, episode_reward=26353.33 +/- 6946.31\n",
      "Episode length: 3122.60 +/- 16.06\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.12e+03   |\n",
      "|    mean_reward          | 2.64e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3425000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01489209 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 31.8       |\n",
      "|    n_updates            | 16720      |\n",
      "|    policy_gradient_loss | 0.00365    |\n",
      "|    std                  | 0.247      |\n",
      "|    value_loss           | 120        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.8e+03  |\n",
      "|    ep_rew_mean     | 1.65e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 526      |\n",
      "|    iterations      | 1673     |\n",
      "|    time_elapsed    | 6512     |\n",
      "|    total_timesteps | 3426304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.81e+03    |\n",
      "|    ep_rew_mean          | 1.63e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1674        |\n",
      "|    time_elapsed         | 6514        |\n",
      "|    total_timesteps      | 3428352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030718524 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16e+05    |\n",
      "|    n_updates            | 16730       |\n",
      "|    policy_gradient_loss | 0.0156      |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 3.29e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3430000, episode_reward=30358.66 +/- 5292.71\n",
      "Episode length: 3381.20 +/- 8.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.38e+03    |\n",
      "|    mean_reward          | 3.04e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047745742 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.1        |\n",
      "|    n_updates            | 16740       |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 48          |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.81e+03 |\n",
      "|    ep_rew_mean     | 1.64e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1675     |\n",
      "|    time_elapsed    | 6524     |\n",
      "|    total_timesteps | 3430400  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.81e+03    |\n",
      "|    ep_rew_mean          | 1.64e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1676        |\n",
      "|    time_elapsed         | 6526        |\n",
      "|    total_timesteps      | 3432448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015053727 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.51        |\n",
      "|    n_updates            | 16750       |\n",
      "|    policy_gradient_loss | 0.00724     |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 34.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.81e+03    |\n",
      "|    ep_rew_mean          | 1.64e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1677        |\n",
      "|    time_elapsed         | 6528        |\n",
      "|    total_timesteps      | 3434496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029140973 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.4         |\n",
      "|    n_updates            | 16760       |\n",
      "|    policy_gradient_loss | 0.0175      |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 21.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3435000, episode_reward=20192.76 +/- 3784.44\n",
      "Episode length: 4159.80 +/- 12.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.16e+03    |\n",
      "|    mean_reward          | 2.02e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3435000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031537615 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 16770       |\n",
      "|    policy_gradient_loss | 0.0062      |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 1.33e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.84e+03 |\n",
      "|    ep_rew_mean     | 1.78e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1678     |\n",
      "|    time_elapsed    | 6539     |\n",
      "|    total_timesteps | 3436544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.84e+03    |\n",
      "|    ep_rew_mean          | 1.78e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1679        |\n",
      "|    time_elapsed         | 6541        |\n",
      "|    total_timesteps      | 3438592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012294863 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 16780       |\n",
      "|    policy_gradient_loss | 0.00152     |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3440000, episode_reward=27860.41 +/- 4043.67\n",
      "Episode length: 2798.60 +/- 16.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.8e+03     |\n",
      "|    mean_reward          | 2.79e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019327872 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.8        |\n",
      "|    n_updates            | 16790       |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 67          |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.87e+03 |\n",
      "|    ep_rew_mean     | 1.91e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1680     |\n",
      "|    time_elapsed    | 6549     |\n",
      "|    total_timesteps | 3440640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.87e+03    |\n",
      "|    ep_rew_mean          | 1.9e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1681        |\n",
      "|    time_elapsed         | 6551        |\n",
      "|    total_timesteps      | 3442688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041964196 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.02        |\n",
      "|    n_updates            | 16800       |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 1.25e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.87e+03    |\n",
      "|    ep_rew_mean          | 1.89e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1682        |\n",
      "|    time_elapsed         | 6553        |\n",
      "|    total_timesteps      | 3444736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026785063 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | 0.0151      |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 1.39e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3445000, episode_reward=25788.34 +/- 3012.84\n",
      "Episode length: 2266.60 +/- 10.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.27e+03    |\n",
      "|    mean_reward          | 2.58e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3445000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014355864 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.8        |\n",
      "|    n_updates            | 16820       |\n",
      "|    policy_gradient_loss | 0.00399     |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 262         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.87e+03 |\n",
      "|    ep_rew_mean     | 1.88e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1683     |\n",
      "|    time_elapsed    | 6560     |\n",
      "|    total_timesteps | 3446784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.89e+03    |\n",
      "|    ep_rew_mean          | 1.86e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1684        |\n",
      "|    time_elapsed         | 6562        |\n",
      "|    total_timesteps      | 3448832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022147622 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.9        |\n",
      "|    n_updates            | 16830       |\n",
      "|    policy_gradient_loss | 0.0062      |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 5.56e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3450000, episode_reward=22841.83 +/- 5201.34\n",
      "Episode length: 2265.00 +/- 14.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.26e+03     |\n",
      "|    mean_reward          | 2.28e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3450000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029367944 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+07     |\n",
      "|    n_updates            | 16840        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    std                  | 0.248        |\n",
      "|    value_loss           | 2.44e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.89e+03 |\n",
      "|    ep_rew_mean     | 1.86e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1685     |\n",
      "|    time_elapsed    | 6569     |\n",
      "|    total_timesteps | 3450880  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.89e+03     |\n",
      "|    ep_rew_mean          | 1.85e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 1686         |\n",
      "|    time_elapsed         | 6571         |\n",
      "|    total_timesteps      | 3452928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013998114 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+04     |\n",
      "|    n_updates            | 16850        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    std                  | 0.248        |\n",
      "|    value_loss           | 5.84e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.9e+03      |\n",
      "|    ep_rew_mean          | 1.94e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 1687         |\n",
      "|    time_elapsed         | 6573         |\n",
      "|    total_timesteps      | 3454976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029711623 |\n",
      "|    clip_fraction        | 0.00391      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.27e+03     |\n",
      "|    n_updates            | 16860        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    std                  | 0.248        |\n",
      "|    value_loss           | 3.34e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3455000, episode_reward=23258.01 +/- 4387.39\n",
      "Episode length: 2195.20 +/- 4.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.2e+03     |\n",
      "|    mean_reward          | 2.33e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3455000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005302202 |\n",
      "|    clip_fraction        | 0.0319      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 702         |\n",
      "|    n_updates            | 16870       |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 8.22e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.9e+03  |\n",
      "|    ep_rew_mean     | 1.93e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1688     |\n",
      "|    time_elapsed    | 6580     |\n",
      "|    total_timesteps | 3457024  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.89e+03     |\n",
      "|    ep_rew_mean          | 1.91e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 1689         |\n",
      "|    time_elapsed         | 6582         |\n",
      "|    total_timesteps      | 3459072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022211983 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 881          |\n",
      "|    n_updates            | 16880        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.248        |\n",
      "|    value_loss           | 3.59e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3460000, episode_reward=20325.24 +/- 6762.46\n",
      "Episode length: 2087.20 +/- 11.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.09e+03     |\n",
      "|    mean_reward          | 2.03e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3460000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041609276 |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 403          |\n",
      "|    n_updates            | 16890        |\n",
      "|    policy_gradient_loss | -0.000773    |\n",
      "|    std                  | 0.248        |\n",
      "|    value_loss           | 1.33e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.89e+03 |\n",
      "|    ep_rew_mean     | 1.91e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1690     |\n",
      "|    time_elapsed    | 6588     |\n",
      "|    total_timesteps | 3461120  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.89e+03    |\n",
      "|    ep_rew_mean          | 1.92e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1691        |\n",
      "|    time_elapsed         | 6590        |\n",
      "|    total_timesteps      | 3463168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006117264 |\n",
      "|    clip_fraction        | 0.0533      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 254         |\n",
      "|    n_updates            | 16900       |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 3.42e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3465000, episode_reward=25195.89 +/- 2942.54\n",
      "Episode length: 2092.40 +/- 12.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.09e+03    |\n",
      "|    mean_reward          | 2.52e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3465000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013102187 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 16910       |\n",
      "|    policy_gradient_loss | 0.000744    |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 576         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.89e+03 |\n",
      "|    ep_rew_mean     | 1.91e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1692     |\n",
      "|    time_elapsed    | 6597     |\n",
      "|    total_timesteps | 3465216  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.89e+03     |\n",
      "|    ep_rew_mean          | 1.9e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 1693         |\n",
      "|    time_elapsed         | 6599         |\n",
      "|    total_timesteps      | 3467264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074958582 |\n",
      "|    clip_fraction        | 0.072        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.08         |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 143          |\n",
      "|    n_updates            | 16920        |\n",
      "|    policy_gradient_loss | -0.000999    |\n",
      "|    std                  | 0.247        |\n",
      "|    value_loss           | 1.08e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.87e+03   |\n",
      "|    ep_rew_mean          | 1.88e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 525        |\n",
      "|    iterations           | 1694       |\n",
      "|    time_elapsed         | 6601       |\n",
      "|    total_timesteps      | 3469312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01244344 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.09       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 93.9       |\n",
      "|    n_updates            | 16930      |\n",
      "|    policy_gradient_loss | 0.00659    |\n",
      "|    std                  | 0.246      |\n",
      "|    value_loss           | 264        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3470000, episode_reward=27956.75 +/- 3717.17\n",
      "Episode length: 2278.20 +/- 11.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.28e+03    |\n",
      "|    mean_reward          | 2.8e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015116859 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.1         |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 16940       |\n",
      "|    policy_gradient_loss | 0.000568    |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 2.09e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.84e+03 |\n",
      "|    ep_rew_mean     | 1.85e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1695     |\n",
      "|    time_elapsed    | 6608     |\n",
      "|    total_timesteps | 3471360  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.87e+03    |\n",
      "|    ep_rew_mean          | 1.98e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1696        |\n",
      "|    time_elapsed         | 6610        |\n",
      "|    total_timesteps      | 3473408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030585214 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.11        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29          |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | 0.0137      |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 99.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3475000, episode_reward=31278.08 +/- 4746.15\n",
      "Episode length: 2892.60 +/- 7.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.89e+03    |\n",
      "|    mean_reward          | 3.13e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3475000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023720436 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.12        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 16960       |\n",
      "|    policy_gradient_loss | 0.00245     |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 1.97e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.87e+03 |\n",
      "|    ep_rew_mean     | 1.98e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1697     |\n",
      "|    time_elapsed    | 6618     |\n",
      "|    total_timesteps | 3475456  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.9e+03     |\n",
      "|    ep_rew_mean          | 2.11e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1698        |\n",
      "|    time_elapsed         | 6620        |\n",
      "|    total_timesteps      | 3477504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022142649 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.12        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 16970       |\n",
      "|    policy_gradient_loss | 0.00867     |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 98          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.88e+03    |\n",
      "|    ep_rew_mean          | 1.96e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1699        |\n",
      "|    time_elapsed         | 6622        |\n",
      "|    total_timesteps      | 3479552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024420237 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.13        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 16980       |\n",
      "|    policy_gradient_loss | 0.0183      |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3480000, episode_reward=31506.05 +/- 3470.98\n",
      "Episode length: 2757.60 +/- 9.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.76e+03     |\n",
      "|    mean_reward          | 3.15e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034141522 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.13         |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.7e+06      |\n",
      "|    n_updates            | 16990        |\n",
      "|    policy_gradient_loss | 0.000591     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 1.82e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.83e+03 |\n",
      "|    ep_rew_mean     | 1.65e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 525      |\n",
      "|    iterations      | 1700     |\n",
      "|    time_elapsed    | 6630     |\n",
      "|    total_timesteps | 3481600  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.8e+03      |\n",
      "|    ep_rew_mean          | 1.5e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 1701         |\n",
      "|    time_elapsed         | 6632         |\n",
      "|    total_timesteps      | 3483648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004242942 |\n",
      "|    clip_fraction        | 0.00684      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.13         |\n",
      "|    explained_variance   | 0.296        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.8e+07      |\n",
      "|    n_updates            | 17000        |\n",
      "|    policy_gradient_loss | 0.00105      |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 3.8e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3485000, episode_reward=29969.59 +/- 4100.06\n",
      "Episode length: 2775.60 +/- 8.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.78e+03     |\n",
      "|    mean_reward          | 3e+04        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3485000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030453894 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.13         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.3e+07      |\n",
      "|    n_updates            | 17010        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 2.02e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.76e+03 |\n",
      "|    ep_rew_mean     | 1.33e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1702     |\n",
      "|    time_elapsed    | 6640     |\n",
      "|    total_timesteps | 3485696  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | 1.33e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1703        |\n",
      "|    time_elapsed         | 6642        |\n",
      "|    total_timesteps      | 3487744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030104037 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.13        |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.01e+06    |\n",
      "|    n_updates            | 17020       |\n",
      "|    policy_gradient_loss | 0.0551      |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.01e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.76e+03     |\n",
      "|    ep_rew_mean          | 1.41e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 1704         |\n",
      "|    time_elapsed         | 6644         |\n",
      "|    total_timesteps      | 3489792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046798633 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.13         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.49e+04     |\n",
      "|    n_updates            | 17030        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 1.06e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3490000, episode_reward=29180.84 +/- 3823.96\n",
      "Episode length: 2668.00 +/- 5.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.67e+03     |\n",
      "|    mean_reward          | 2.92e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3490000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029178404 |\n",
      "|    clip_fraction        | 0.0103       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.13         |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.04e+03     |\n",
      "|    n_updates            | 17040        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 2e+04        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.77e+03 |\n",
      "|    ep_rew_mean     | 1.52e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1705     |\n",
      "|    time_elapsed    | 6652     |\n",
      "|    total_timesteps | 3491840  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.8e+03     |\n",
      "|    ep_rew_mean          | 1.64e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1706        |\n",
      "|    time_elapsed         | 6654        |\n",
      "|    total_timesteps      | 3493888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003821748 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.13        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+03    |\n",
      "|    n_updates            | 17050       |\n",
      "|    policy_gradient_loss | -0.00482    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 2.97e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3495000, episode_reward=24766.43 +/- 4882.33\n",
      "Episode length: 2600.60 +/- 8.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.6e+03      |\n",
      "|    mean_reward          | 2.48e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3495000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059121987 |\n",
      "|    clip_fraction        | 0.0627       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.13         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.54e+04     |\n",
      "|    n_updates            | 17060        |\n",
      "|    policy_gradient_loss | -0.00876     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 2.65e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.77e+03 |\n",
      "|    ep_rew_mean     | 1.56e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1707     |\n",
      "|    time_elapsed    | 6662     |\n",
      "|    total_timesteps | 3495936  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.74e+03     |\n",
      "|    ep_rew_mean          | 1.5e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 524          |\n",
      "|    iterations           | 1708         |\n",
      "|    time_elapsed         | 6664         |\n",
      "|    total_timesteps      | 3497984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075101582 |\n",
      "|    clip_fraction        | 0.0637       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.13         |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 562          |\n",
      "|    n_updates            | 17070        |\n",
      "|    policy_gradient_loss | -0.00695     |\n",
      "|    std                  | 0.241        |\n",
      "|    value_loss           | 1.26e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3500000, episode_reward=24490.25 +/- 5909.21\n",
      "Episode length: 2480.40 +/- 13.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.48e+03    |\n",
      "|    mean_reward          | 2.45e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008915985 |\n",
      "|    clip_fraction        | 0.0845      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.14        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 537         |\n",
      "|    n_updates            | 17080       |\n",
      "|    policy_gradient_loss | -0.00219    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.77e+03 |\n",
      "|    ep_rew_mean     | 1.62e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1709     |\n",
      "|    time_elapsed    | 6671     |\n",
      "|    total_timesteps | 3500032  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.77e+03   |\n",
      "|    ep_rew_mean          | 1.62e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 524        |\n",
      "|    iterations           | 1710       |\n",
      "|    time_elapsed         | 6673       |\n",
      "|    total_timesteps      | 3502080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00756787 |\n",
      "|    clip_fraction        | 0.0807     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.14       |\n",
      "|    explained_variance   | 0.968      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.23e+03   |\n",
      "|    n_updates            | 17090      |\n",
      "|    policy_gradient_loss | -0.00312   |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 1.66e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.74e+03   |\n",
      "|    ep_rew_mean          | 1.56e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 524        |\n",
      "|    iterations           | 1711       |\n",
      "|    time_elapsed         | 6675       |\n",
      "|    total_timesteps      | 3504128    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06415154 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.14       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 41.4       |\n",
      "|    n_updates            | 17100      |\n",
      "|    policy_gradient_loss | 0.0108     |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 327        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3505000, episode_reward=21483.01 +/- 2978.95\n",
      "Episode length: 2016.60 +/- 12.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | 2.15e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3505000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012174251 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.15        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.41e+04    |\n",
      "|    n_updates            | 17110       |\n",
      "|    policy_gradient_loss | 0.00704     |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 3.31e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | 1.56e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1712     |\n",
      "|    time_elapsed    | 6682     |\n",
      "|    total_timesteps | 3506176  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.68e+03    |\n",
      "|    ep_rew_mean          | 1.6e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 1713        |\n",
      "|    time_elapsed         | 6683        |\n",
      "|    total_timesteps      | 3508224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015070641 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.15        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.46e+05    |\n",
      "|    n_updates            | 17120       |\n",
      "|    policy_gradient_loss | 0.00342     |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 3.48e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3510000, episode_reward=23385.21 +/- 3687.96\n",
      "Episode length: 1906.00 +/- 7.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.91e+03    |\n",
      "|    mean_reward          | 2.34e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043645162 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.15        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 17130       |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.66e+03 |\n",
      "|    ep_rew_mean     | 1.65e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1714     |\n",
      "|    time_elapsed    | 6690     |\n",
      "|    total_timesteps | 3510272  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.62e+03  |\n",
      "|    ep_rew_mean          | 1.58e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 524       |\n",
      "|    iterations           | 1715      |\n",
      "|    time_elapsed         | 6692      |\n",
      "|    total_timesteps      | 3512320   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2614721 |\n",
      "|    clip_fraction        | 0.364     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.15      |\n",
      "|    explained_variance   | 0.963     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 26.3      |\n",
      "|    n_updates            | 17140     |\n",
      "|    policy_gradient_loss | 0.0298    |\n",
      "|    std                  | 0.242     |\n",
      "|    value_loss           | 9.79e+03  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.59e+03  |\n",
      "|    ep_rew_mean          | 1.51e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 525       |\n",
      "|    iterations           | 1716      |\n",
      "|    time_elapsed         | 6693      |\n",
      "|    total_timesteps      | 3514368   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1081945 |\n",
      "|    clip_fraction        | 0.346     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.15      |\n",
      "|    explained_variance   | 0.999     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 12.5      |\n",
      "|    n_updates            | 17150     |\n",
      "|    policy_gradient_loss | 0.0126    |\n",
      "|    std                  | 0.241     |\n",
      "|    value_loss           | 40.8      |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3515000, episode_reward=27110.74 +/- 247.75\n",
      "Episode length: 2224.60 +/- 11.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.22e+03    |\n",
      "|    mean_reward          | 2.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3515000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007185232 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.16        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.4        |\n",
      "|    n_updates            | 17160       |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    std                  | 0.241       |\n",
      "|    value_loss           | 1.27e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.57e+03 |\n",
      "|    ep_rew_mean     | 1.45e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1717     |\n",
      "|    time_elapsed    | 6701     |\n",
      "|    total_timesteps | 3516416  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54e+03    |\n",
      "|    ep_rew_mean          | 1.38e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 1718        |\n",
      "|    time_elapsed         | 6702        |\n",
      "|    total_timesteps      | 3518464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016567634 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.16        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.43        |\n",
      "|    n_updates            | 17170       |\n",
      "|    policy_gradient_loss | 0.00755     |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 1.38e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3520000, episode_reward=22725.23 +/- 4589.79\n",
      "Episode length: 2193.00 +/- 13.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.19e+03    |\n",
      "|    mean_reward          | 2.27e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010519151 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36          |\n",
      "|    n_updates            | 17180       |\n",
      "|    policy_gradient_loss | 0.0115      |\n",
      "|    std                  | 0.239       |\n",
      "|    value_loss           | 9.96e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.56e+03 |\n",
      "|    ep_rew_mean     | 1.51e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1719     |\n",
      "|    time_elapsed    | 6709     |\n",
      "|    total_timesteps | 3520512  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 1.43e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 1720        |\n",
      "|    time_elapsed         | 6711        |\n",
      "|    total_timesteps      | 3522560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014989396 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 17190       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    std                  | 0.238       |\n",
      "|    value_loss           | 8.2e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.5e+03    |\n",
      "|    ep_rew_mean          | 1.38e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 524        |\n",
      "|    iterations           | 1721       |\n",
      "|    time_elapsed         | 6713       |\n",
      "|    total_timesteps      | 3524608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02325803 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.18       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.5       |\n",
      "|    n_updates            | 17200      |\n",
      "|    policy_gradient_loss | 0.00416    |\n",
      "|    std                  | 0.239      |\n",
      "|    value_loss           | 96.6       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3525000, episode_reward=28310.64 +/- 1584.91\n",
      "Episode length: 2649.80 +/- 6.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.65e+03    |\n",
      "|    mean_reward          | 2.83e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3525000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010429723 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73          |\n",
      "|    n_updates            | 17210       |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    std                  | 0.239       |\n",
      "|    value_loss           | 1.99e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.53e+03 |\n",
      "|    ep_rew_mean     | 1.51e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1722     |\n",
      "|    time_elapsed    | 6721     |\n",
      "|    total_timesteps | 3526656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 1.51e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 1723        |\n",
      "|    time_elapsed         | 6723        |\n",
      "|    total_timesteps      | 3528704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024541382 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.7        |\n",
      "|    n_updates            | 17220       |\n",
      "|    policy_gradient_loss | 0.00114     |\n",
      "|    std                  | 0.238       |\n",
      "|    value_loss           | 144         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3530000, episode_reward=30133.41 +/- 4082.22\n",
      "Episode length: 3020.20 +/- 5.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.02e+03    |\n",
      "|    mean_reward          | 3.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047078997 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.33        |\n",
      "|    n_updates            | 17230       |\n",
      "|    policy_gradient_loss | 0.0233      |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 40          |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.55e+03 |\n",
      "|    ep_rew_mean     | 1.65e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1724     |\n",
      "|    time_elapsed    | 6732     |\n",
      "|    total_timesteps | 3530752  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.55e+03    |\n",
      "|    ep_rew_mean          | 1.65e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 1725        |\n",
      "|    time_elapsed         | 6734        |\n",
      "|    total_timesteps      | 3532800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005828377 |\n",
      "|    clip_fraction        | 0.0875      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.3        |\n",
      "|    n_updates            | 17240       |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.54e+03     |\n",
      "|    ep_rew_mean          | 1.61e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 524          |\n",
      "|    iterations           | 1726         |\n",
      "|    time_elapsed         | 6736         |\n",
      "|    total_timesteps      | 3534848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143785775 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 30           |\n",
      "|    n_updates            | 17250        |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 110          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3535000, episode_reward=46579.76 +/- 4549.95\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 5e+03     |\n",
      "|    mean_reward          | 4.66e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3535000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7537555 |\n",
      "|    clip_fraction        | 0.321     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.23      |\n",
      "|    explained_variance   | 0.996     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.48      |\n",
      "|    n_updates            | 17260     |\n",
      "|    policy_gradient_loss | 0.0167    |\n",
      "|    std                  | 0.237     |\n",
      "|    value_loss           | 75.4      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 1.61e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1727     |\n",
      "|    time_elapsed    | 6749     |\n",
      "|    total_timesteps | 3536896  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.56e+03     |\n",
      "|    ep_rew_mean          | 1.62e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 524          |\n",
      "|    iterations           | 1728         |\n",
      "|    time_elapsed         | 6751         |\n",
      "|    total_timesteps      | 3538944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064696968 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.59         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 76.3         |\n",
      "|    n_updates            | 17270        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    std                  | 0.237        |\n",
      "|    value_loss           | 232          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3540000, episode_reward=526.34 +/- 85689.46\n",
      "Episode length: 4021.20 +/- 1957.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.02e+03     |\n",
      "|    mean_reward          | 526          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3540000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068641137 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 122          |\n",
      "|    n_updates            | 17280        |\n",
      "|    policy_gradient_loss | 0.0014       |\n",
      "|    std                  | 0.237        |\n",
      "|    value_loss           | 1.69e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.56e+03 |\n",
      "|    ep_rew_mean     | 1.62e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 523      |\n",
      "|    iterations      | 1729     |\n",
      "|    time_elapsed    | 6762     |\n",
      "|    total_timesteps | 3540992  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.56e+03    |\n",
      "|    ep_rew_mean          | 1.61e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 1730        |\n",
      "|    time_elapsed         | 6764        |\n",
      "|    total_timesteps      | 3543040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011417607 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25          |\n",
      "|    n_updates            | 17290       |\n",
      "|    policy_gradient_loss | 0.0283      |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 77.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3545000, episode_reward=31854.43 +/- 4974.95\n",
      "Episode length: 4341.00 +/- 19.52\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 4.34e+03  |\n",
      "|    mean_reward          | 3.19e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3545000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0102592 |\n",
      "|    clip_fraction        | 0.169     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.23      |\n",
      "|    explained_variance   | 0.796     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.17e+03  |\n",
      "|    n_updates            | 17300     |\n",
      "|    policy_gradient_loss | 0.00054   |\n",
      "|    std                  | 0.236     |\n",
      "|    value_loss           | 1.2e+05   |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.56e+03 |\n",
      "|    ep_rew_mean     | 1.61e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 523      |\n",
      "|    iterations      | 1731     |\n",
      "|    time_elapsed    | 6776     |\n",
      "|    total_timesteps | 3545088  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.56e+03    |\n",
      "|    ep_rew_mean          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 1732        |\n",
      "|    time_elapsed         | 6778        |\n",
      "|    total_timesteps      | 3547136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009519927 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.8        |\n",
      "|    n_updates            | 17310       |\n",
      "|    policy_gradient_loss | 0.00975     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 96.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.56e+03    |\n",
      "|    ep_rew_mean          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 1733        |\n",
      "|    time_elapsed         | 6780        |\n",
      "|    total_timesteps      | 3549184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010332903 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.65e+05    |\n",
      "|    n_updates            | 17320       |\n",
      "|    policy_gradient_loss | 0.00659     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 6.72e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3550000, episode_reward=-23988.40 +/- 73598.91\n",
      "Episode length: 3382.80 +/- 1638.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.38e+03    |\n",
      "|    mean_reward          | -2.4e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010989565 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 17330       |\n",
      "|    policy_gradient_loss | 0.00486     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.57e+03 |\n",
      "|    ep_rew_mean     | 1.43e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 523      |\n",
      "|    iterations      | 1734     |\n",
      "|    time_elapsed    | 6790     |\n",
      "|    total_timesteps | 3551232  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.57e+03     |\n",
      "|    ep_rew_mean          | 1.43e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 523          |\n",
      "|    iterations           | 1735         |\n",
      "|    time_elapsed         | 6791         |\n",
      "|    total_timesteps      | 3553280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086153615 |\n",
      "|    clip_fraction        | 0.0636       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.24         |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+07     |\n",
      "|    n_updates            | 17340        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 2.88e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3555000, episode_reward=7748.51 +/- 3099.08\n",
      "Episode length: 4320.40 +/- 13.02\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.32e+03   |\n",
      "|    mean_reward          | 7.75e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3555000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01385219 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.24       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 48.2       |\n",
      "|    n_updates            | 17350      |\n",
      "|    policy_gradient_loss | 0.00352    |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 242        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.57e+03 |\n",
      "|    ep_rew_mean     | 1.41e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 522      |\n",
      "|    iterations      | 1736     |\n",
      "|    time_elapsed    | 6803     |\n",
      "|    total_timesteps | 3555328  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.58e+03    |\n",
      "|    ep_rew_mean          | 1.41e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 1737        |\n",
      "|    time_elapsed         | 6805        |\n",
      "|    total_timesteps      | 3557376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014511703 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 17360       |\n",
      "|    policy_gradient_loss | 0.0208      |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 328         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.58e+03    |\n",
      "|    ep_rew_mean          | 1.41e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 1738        |\n",
      "|    time_elapsed         | 6807        |\n",
      "|    total_timesteps      | 3559424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014555372 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.9        |\n",
      "|    n_updates            | 17370       |\n",
      "|    policy_gradient_loss | -0.00578    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 294         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3560000, episode_reward=51025.12 +/- 4025.17\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 5.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055758666 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.6        |\n",
      "|    n_updates            | 17380       |\n",
      "|    policy_gradient_loss | 0.0234      |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 100         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.57e+03 |\n",
      "|    ep_rew_mean     | 1.41e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 522      |\n",
      "|    iterations      | 1739     |\n",
      "|    time_elapsed    | 6821     |\n",
      "|    total_timesteps | 3561472  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.57e+03     |\n",
      "|    ep_rew_mean          | 1.41e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 522          |\n",
      "|    iterations           | 1740         |\n",
      "|    time_elapsed         | 6822         |\n",
      "|    total_timesteps      | 3563520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034228906 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 94.1         |\n",
      "|    n_updates            | 17390        |\n",
      "|    policy_gradient_loss | 0.00425      |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 3.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3565000, episode_reward=49209.10 +/- 4608.04\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 4.92e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3565000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023571225 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.8        |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | 0.00109     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 1.18e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 521      |\n",
      "|    iterations      | 1741     |\n",
      "|    time_elapsed    | 6836     |\n",
      "|    total_timesteps | 3565568  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.54e+03     |\n",
      "|    ep_rew_mean          | 1.18e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 1742         |\n",
      "|    time_elapsed         | 6838         |\n",
      "|    total_timesteps      | 3567616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056495443 |\n",
      "|    clip_fraction        | 0.0609       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.292        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.71e+07     |\n",
      "|    n_updates            | 17410        |\n",
      "|    policy_gradient_loss | -0.00546     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 3.11e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 9.97e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1743        |\n",
      "|    time_elapsed         | 6840        |\n",
      "|    total_timesteps      | 3569664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008878195 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.551       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.46e+03    |\n",
      "|    n_updates            | 17420       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.23e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3570000, episode_reward=50295.24 +/- 3604.79\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 5.03e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3570000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017378378 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.83e+05     |\n",
      "|    n_updates            | 17430        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 2.35e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.53e+03 |\n",
      "|    ep_rew_mean     | 9.97e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 521      |\n",
      "|    iterations      | 1744     |\n",
      "|    time_elapsed    | 6853     |\n",
      "|    total_timesteps | 3571712  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54e+03    |\n",
      "|    ep_rew_mean          | 1e+04       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1745        |\n",
      "|    time_elapsed         | 6855        |\n",
      "|    total_timesteps      | 3573760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024237894 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 17440       |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 655         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3575000, episode_reward=53173.41 +/- 3269.92\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 5.32e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3575000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097129755 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.11e+03     |\n",
      "|    n_updates            | 17450        |\n",
      "|    policy_gradient_loss | -0.00678     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 4.74e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 1e+04    |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 1746     |\n",
      "|    time_elapsed    | 6869     |\n",
      "|    total_timesteps | 3575808  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.55e+03   |\n",
      "|    ep_rew_mean          | 9.99e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 520        |\n",
      "|    iterations           | 1747       |\n",
      "|    time_elapsed         | 6871       |\n",
      "|    total_timesteps      | 3577856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01692795 |\n",
      "|    clip_fraction        | 0.237      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.24       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 67.3       |\n",
      "|    n_updates            | 17460      |\n",
      "|    policy_gradient_loss | 0.00396    |\n",
      "|    std                  | 0.235      |\n",
      "|    value_loss           | 314        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54e+03    |\n",
      "|    ep_rew_mean          | 9.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1748        |\n",
      "|    time_elapsed         | 6872        |\n",
      "|    total_timesteps      | 3579904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020778812 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 17470       |\n",
      "|    policy_gradient_loss | 0.00299     |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 1.14e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3580000, episode_reward=27240.90 +/- 4621.75\n",
      "Episode length: 2782.40 +/- 13.28\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.78e+03     |\n",
      "|    mean_reward          | 2.72e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3580000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073648416 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.24         |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 155          |\n",
      "|    n_updates            | 17480        |\n",
      "|    policy_gradient_loss | -0.00169     |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 1.41e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 9.67e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 1749     |\n",
      "|    time_elapsed    | 6881     |\n",
      "|    total_timesteps | 3581952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54e+03    |\n",
      "|    ep_rew_mean          | 9.67e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1750        |\n",
      "|    time_elapsed         | 6883        |\n",
      "|    total_timesteps      | 3584000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019456381 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 17490       |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 1.5e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3585000, episode_reward=-19892.58 +/- 76884.02\n",
      "Episode length: 1910.80 +/- 902.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.91e+03    |\n",
      "|    mean_reward          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3585000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019293608 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.8        |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 109         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 7.72e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 1751     |\n",
      "|    time_elapsed    | 6889     |\n",
      "|    total_timesteps | 3586048  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 7.47e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1752        |\n",
      "|    time_elapsed         | 6891        |\n",
      "|    total_timesteps      | 3588096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006973275 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.224       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8e+07     |\n",
      "|    n_updates            | 17510       |\n",
      "|    policy_gradient_loss | 0.00373     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 3.44e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3590000, episode_reward=7382.82 +/- 4151.73\n",
      "Episode length: 2435.40 +/- 16.33\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.44e+03   |\n",
      "|    mean_reward          | 7.38e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3590000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00550462 |\n",
      "|    clip_fraction        | 0.0597     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.25       |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.97e+04   |\n",
      "|    n_updates            | 17520      |\n",
      "|    policy_gradient_loss | -0.00572   |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 5.33e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 8.39e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 1753     |\n",
      "|    time_elapsed    | 6898     |\n",
      "|    total_timesteps | 3590144  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 8.23e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1754        |\n",
      "|    time_elapsed         | 6900        |\n",
      "|    total_timesteps      | 3592192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003850175 |\n",
      "|    clip_fraction        | 0.0378      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.39e+03    |\n",
      "|    n_updates            | 17530       |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.68e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 8.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1755        |\n",
      "|    time_elapsed         | 6902        |\n",
      "|    total_timesteps      | 3594240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011517177 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 139         |\n",
      "|    n_updates            | 17540       |\n",
      "|    policy_gradient_loss | 0.00343     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.75e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3595000, episode_reward=17436.25 +/- 2092.98\n",
      "Episode length: 2269.60 +/- 12.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.27e+03    |\n",
      "|    mean_reward          | 1.74e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3595000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012017922 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 774         |\n",
      "|    n_updates            | 17550       |\n",
      "|    policy_gradient_loss | 0.00222     |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 1.41e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.51e+03 |\n",
      "|    ep_rew_mean     | 7.88e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 1756     |\n",
      "|    time_elapsed    | 6909     |\n",
      "|    total_timesteps | 3596288  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.51e+03   |\n",
      "|    ep_rew_mean          | 7.88e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 520        |\n",
      "|    iterations           | 1757       |\n",
      "|    time_elapsed         | 6911       |\n",
      "|    total_timesteps      | 3598336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39355785 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.24       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 49.9       |\n",
      "|    n_updates            | 17560      |\n",
      "|    policy_gradient_loss | 0.0218     |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 1.26e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3600000, episode_reward=26650.76 +/- 4442.72\n",
      "Episode length: 3289.60 +/- 17.76\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.29e+03   |\n",
      "|    mean_reward          | 2.67e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3600000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04705479 |\n",
      "|    clip_fraction        | 0.296      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.23       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 17570      |\n",
      "|    policy_gradient_loss | 0.0184     |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 80.1       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.51e+03 |\n",
      "|    ep_rew_mean     | 7.72e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 1758     |\n",
      "|    time_elapsed    | 6921     |\n",
      "|    total_timesteps | 3600384  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.51e+03  |\n",
      "|    ep_rew_mean          | 7.54e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 520       |\n",
      "|    iterations           | 1759      |\n",
      "|    time_elapsed         | 6923      |\n",
      "|    total_timesteps      | 3602432   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.8336351 |\n",
      "|    clip_fraction        | 0.254     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.22      |\n",
      "|    explained_variance   | 0.951     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 306       |\n",
      "|    n_updates            | 17580     |\n",
      "|    policy_gradient_loss | 0.00264   |\n",
      "|    std                  | 0.236     |\n",
      "|    value_loss           | 1.06e+04  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.51e+03     |\n",
      "|    ep_rew_mean          | 7.54e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 1760         |\n",
      "|    time_elapsed         | 6924         |\n",
      "|    total_timesteps      | 3604480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066526644 |\n",
      "|    clip_fraction        | 0.0815       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.819        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.81e+03     |\n",
      "|    n_updates            | 17590        |\n",
      "|    policy_gradient_loss | -0.00568     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 7.6e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3605000, episode_reward=28138.53 +/- 2206.91\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 2.81e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3605000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056682546 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.8        |\n",
      "|    n_updates            | 17600       |\n",
      "|    policy_gradient_loss | 0.00939     |\n",
      "|    std                  | 0.237       |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.52e+03 |\n",
      "|    ep_rew_mean     | 7.36e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 519      |\n",
      "|    iterations      | 1761     |\n",
      "|    time_elapsed    | 6938     |\n",
      "|    total_timesteps | 3606528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.52e+03    |\n",
      "|    ep_rew_mean          | 7.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 1762        |\n",
      "|    time_elapsed         | 6940        |\n",
      "|    total_timesteps      | 3608576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008662529 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 450         |\n",
      "|    n_updates            | 17610       |\n",
      "|    policy_gradient_loss | 0.00782     |\n",
      "|    std                  | 0.237       |\n",
      "|    value_loss           | 2.19e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3610000, episode_reward=19583.98 +/- 4999.22\n",
      "Episode length: 4808.80 +/- 20.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.81e+03    |\n",
      "|    mean_reward          | 1.96e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029228441 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 17620       |\n",
      "|    policy_gradient_loss | 0.0136      |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 74          |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 7.31e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 519      |\n",
      "|    iterations      | 1763     |\n",
      "|    time_elapsed    | 6953     |\n",
      "|    total_timesteps | 3610624  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54e+03    |\n",
      "|    ep_rew_mean          | 7.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 1764        |\n",
      "|    time_elapsed         | 6955        |\n",
      "|    total_timesteps      | 3612672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011504008 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.03e+04    |\n",
      "|    n_updates            | 17630       |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.48e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.52e+03    |\n",
      "|    ep_rew_mean          | 5.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 1765        |\n",
      "|    time_elapsed         | 6957        |\n",
      "|    total_timesteps      | 3614720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023866769 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13          |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | 0.00747     |\n",
      "|    std                  | 0.237       |\n",
      "|    value_loss           | 34.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3615000, episode_reward=-15107.16 +/- 75635.13\n",
      "Episode length: 3637.20 +/- 1783.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.64e+03     |\n",
      "|    mean_reward          | -1.51e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3615000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032595722 |\n",
      "|    clip_fraction        | 0.332        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.263        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.5e+06      |\n",
      "|    n_updates            | 17650        |\n",
      "|    policy_gradient_loss | 0.0102       |\n",
      "|    std                  | 0.237        |\n",
      "|    value_loss           | 2.7e+07      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.52e+03 |\n",
      "|    ep_rew_mean     | 5.14e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 519      |\n",
      "|    iterations      | 1766     |\n",
      "|    time_elapsed    | 6967     |\n",
      "|    total_timesteps | 3616768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.52e+03    |\n",
      "|    ep_rew_mean          | 5.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 1767        |\n",
      "|    time_elapsed         | 6969        |\n",
      "|    total_timesteps      | 3618816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024148475 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.4        |\n",
      "|    n_updates            | 17660       |\n",
      "|    policy_gradient_loss | 0.0178      |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 85          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3620000, episode_reward=32621.64 +/- 2804.72\n",
      "Episode length: 2839.00 +/- 16.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.84e+03    |\n",
      "|    mean_reward          | 3.26e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010262504 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 425         |\n",
      "|    n_updates            | 17670       |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.53e+03 |\n",
      "|    ep_rew_mean     | 4.74e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 518      |\n",
      "|    iterations      | 1768     |\n",
      "|    time_elapsed    | 6977     |\n",
      "|    total_timesteps | 3620864  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 4.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 1769        |\n",
      "|    time_elapsed         | 6979        |\n",
      "|    total_timesteps      | 3622912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002551873 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 17680       |\n",
      "|    policy_gradient_loss | 0.000974    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 4.52e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 1770        |\n",
      "|    time_elapsed         | 6981        |\n",
      "|    total_timesteps      | 3624960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006061704 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 17690       |\n",
      "|    policy_gradient_loss | 5.49e-05    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.59e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3625000, episode_reward=24633.68 +/- 5512.70\n",
      "Episode length: 2886.40 +/- 20.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.89e+03     |\n",
      "|    mean_reward          | 2.46e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3625000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074334648 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.916        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 194          |\n",
      "|    n_updates            | 17700        |\n",
      "|    policy_gradient_loss | -0.00416     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 2.59e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.53e+03 |\n",
      "|    ep_rew_mean     | 4.52e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 518      |\n",
      "|    iterations      | 1771     |\n",
      "|    time_elapsed    | 6989     |\n",
      "|    total_timesteps | 3627008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 4.45e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 1772        |\n",
      "|    time_elapsed         | 6991        |\n",
      "|    total_timesteps      | 3629056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020441454 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.5         |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | 0.00431     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 39.7        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3630000, episode_reward=24003.15 +/- 5594.85\n",
      "Episode length: 2463.40 +/- 12.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.46e+03    |\n",
      "|    mean_reward          | 2.4e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031582728 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.94        |\n",
      "|    n_updates            | 17720       |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.52e+03 |\n",
      "|    ep_rew_mean     | 4.47e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 518      |\n",
      "|    iterations      | 1773     |\n",
      "|    time_elapsed    | 6999     |\n",
      "|    total_timesteps | 3631104  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.52e+03    |\n",
      "|    ep_rew_mean          | 4.43e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1774        |\n",
      "|    time_elapsed         | 7001        |\n",
      "|    total_timesteps      | 3633152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008067178 |\n",
      "|    clip_fraction        | 0.0959      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 17730       |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 483         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3635000, episode_reward=-8693.93 +/- 79485.26\n",
      "Episode length: 2054.00 +/- 975.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.05e+03    |\n",
      "|    mean_reward          | -8.69e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3635000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051294968 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.2        |\n",
      "|    n_updates            | 17740       |\n",
      "|    policy_gradient_loss | 0.0394      |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 2.04e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.52e+03 |\n",
      "|    ep_rew_mean     | 4.43e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 518      |\n",
      "|    iterations      | 1775     |\n",
      "|    time_elapsed    | 7007     |\n",
      "|    total_timesteps | 3635200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.52e+03    |\n",
      "|    ep_rew_mean          | 4.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1776        |\n",
      "|    time_elapsed         | 7009        |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033561684 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.78        |\n",
      "|    n_updates            | 17750       |\n",
      "|    policy_gradient_loss | 0.0111      |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.54e+03     |\n",
      "|    ep_rew_mean          | 5.65e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 519          |\n",
      "|    iterations           | 1777         |\n",
      "|    time_elapsed         | 7011         |\n",
      "|    total_timesteps      | 3639296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047115833 |\n",
      "|    clip_fraction        | 0.129        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.26         |\n",
      "|    explained_variance   | 0.972        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 38           |\n",
      "|    n_updates            | 17760        |\n",
      "|    policy_gradient_loss | 0.00612      |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 1.31e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3640000, episode_reward=26879.53 +/- 3887.56\n",
      "Episode length: 2432.40 +/- 16.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.43e+03    |\n",
      "|    mean_reward          | 2.69e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018152265 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.73        |\n",
      "|    n_updates            | 17770       |\n",
      "|    policy_gradient_loss | 0.0132      |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.56e+03 |\n",
      "|    ep_rew_mean     | 7.24e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 518      |\n",
      "|    iterations      | 1778     |\n",
      "|    time_elapsed    | 7019     |\n",
      "|    total_timesteps | 3641344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.55e+03    |\n",
      "|    ep_rew_mean          | 7.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1779        |\n",
      "|    time_elapsed         | 7020        |\n",
      "|    total_timesteps      | 3643392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025300264 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.7        |\n",
      "|    n_updates            | 17780       |\n",
      "|    policy_gradient_loss | 0.00958     |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 3.28e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3645000, episode_reward=29968.47 +/- 4242.47\n",
      "Episode length: 2287.00 +/- 16.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.29e+03    |\n",
      "|    mean_reward          | 3e+04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3645000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043914065 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.8        |\n",
      "|    n_updates            | 17790       |\n",
      "|    policy_gradient_loss | 0.0178      |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 7.02e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 518      |\n",
      "|    iterations      | 1780     |\n",
      "|    time_elapsed    | 7028     |\n",
      "|    total_timesteps | 3645440  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.56e+03     |\n",
      "|    ep_rew_mean          | 8.74e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 518          |\n",
      "|    iterations           | 1781         |\n",
      "|    time_elapsed         | 7030         |\n",
      "|    total_timesteps      | 3647488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135663375 |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.22         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 28.9         |\n",
      "|    n_updates            | 17800        |\n",
      "|    policy_gradient_loss | 0.00355      |\n",
      "|    std                  | 0.237        |\n",
      "|    value_loss           | 140          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.56e+03    |\n",
      "|    ep_rew_mean          | 8.74e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1782        |\n",
      "|    time_elapsed         | 7031        |\n",
      "|    total_timesteps      | 3649536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017697664 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 17810       |\n",
      "|    policy_gradient_loss | 0.0117      |\n",
      "|    std                  | 0.237       |\n",
      "|    value_loss           | 73.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3650000, episode_reward=36986.45 +/- 3850.45\n",
      "Episode length: 2680.40 +/- 13.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.68e+03     |\n",
      "|    mean_reward          | 3.7e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3650000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072720293 |\n",
      "|    clip_fraction        | 0.175        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.21         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.5         |\n",
      "|    n_updates            | 17820        |\n",
      "|    policy_gradient_loss | 0.0118       |\n",
      "|    std                  | 0.237        |\n",
      "|    value_loss           | 125          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.56e+03 |\n",
      "|    ep_rew_mean     | 8.75e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 518      |\n",
      "|    iterations      | 1783     |\n",
      "|    time_elapsed    | 7040     |\n",
      "|    total_timesteps | 3651584  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.56e+03   |\n",
      "|    ep_rew_mean          | 8.54e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 518        |\n",
      "|    iterations           | 1784       |\n",
      "|    time_elapsed         | 7041       |\n",
      "|    total_timesteps      | 3653632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02383412 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.22       |\n",
      "|    explained_variance   | 0.948      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.1       |\n",
      "|    n_updates            | 17830      |\n",
      "|    policy_gradient_loss | 0.0296     |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 1.33e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3655000, episode_reward=434.97 +/- 4654.12\n",
      "Episode length: 3505.60 +/- 12.08\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.51e+03     |\n",
      "|    mean_reward          | 435          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3655000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032397066 |\n",
      "|    clip_fraction        | 0.0531       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.23         |\n",
      "|    explained_variance   | 0.65         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+03     |\n",
      "|    n_updates            | 17840        |\n",
      "|    policy_gradient_loss | 0.000558     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 2.8e+05      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.56e+03 |\n",
      "|    ep_rew_mean     | 8.54e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 518      |\n",
      "|    iterations      | 1785     |\n",
      "|    time_elapsed    | 7051     |\n",
      "|    total_timesteps | 3655680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57e+03    |\n",
      "|    ep_rew_mean          | 8.69e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1786        |\n",
      "|    time_elapsed         | 7053        |\n",
      "|    total_timesteps      | 3657728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022743562 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 17850       |\n",
      "|    policy_gradient_loss | 0.00501     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 80.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57e+03    |\n",
      "|    ep_rew_mean          | 8.83e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1787        |\n",
      "|    time_elapsed         | 7055        |\n",
      "|    total_timesteps      | 3659776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015462993 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 318         |\n",
      "|    n_updates            | 17860       |\n",
      "|    policy_gradient_loss | 0.00412     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 410         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3660000, episode_reward=44981.34 +/- 3762.28\n",
      "Episode length: 3464.40 +/- 16.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.46e+03    |\n",
      "|    mean_reward          | 4.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018467229 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 17870       |\n",
      "|    policy_gradient_loss | 0.000391    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 1.28e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.57e+03 |\n",
      "|    ep_rew_mean     | 8.83e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 518      |\n",
      "|    iterations      | 1788     |\n",
      "|    time_elapsed    | 7065     |\n",
      "|    total_timesteps | 3661824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57e+03    |\n",
      "|    ep_rew_mean          | 8.77e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1789        |\n",
      "|    time_elapsed         | 7067        |\n",
      "|    total_timesteps      | 3663872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021049723 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.81        |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | 0.0197      |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 33.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3665000, episode_reward=41568.21 +/- 2881.77\n",
      "Episode length: 3280.40 +/- 14.61\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.28e+03     |\n",
      "|    mean_reward          | 4.16e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3665000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085192565 |\n",
      "|    clip_fraction        | 0.078        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.24         |\n",
      "|    explained_variance   | 0.623        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86e+03     |\n",
      "|    n_updates            | 17890        |\n",
      "|    policy_gradient_loss | 0.0044       |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 7.44e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.58e+03 |\n",
      "|    ep_rew_mean     | 8.7e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 517      |\n",
      "|    iterations      | 1790     |\n",
      "|    time_elapsed    | 7077     |\n",
      "|    total_timesteps | 3665920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.58e+03    |\n",
      "|    ep_rew_mean          | 8.7e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1791        |\n",
      "|    time_elapsed         | 7078        |\n",
      "|    total_timesteps      | 3667968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010033322 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.17e+04    |\n",
      "|    n_updates            | 17900       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 1.25e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3670000, episode_reward=36995.91 +/- 3874.65\n",
      "Episode length: 2803.20 +/- 7.88\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.8e+03    |\n",
      "|    mean_reward          | 3.7e+04    |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3670000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03367217 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.25       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.73       |\n",
      "|    n_updates            | 17910      |\n",
      "|    policy_gradient_loss | 0.0105     |\n",
      "|    std                  | 0.234      |\n",
      "|    value_loss           | 18.1       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.57e+03 |\n",
      "|    ep_rew_mean     | 8.76e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 517      |\n",
      "|    iterations      | 1792     |\n",
      "|    time_elapsed    | 7087     |\n",
      "|    total_timesteps | 3670016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57e+03    |\n",
      "|    ep_rew_mean          | 8.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 517         |\n",
      "|    iterations           | 1793        |\n",
      "|    time_elapsed         | 7089        |\n",
      "|    total_timesteps      | 3672064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015934767 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.8         |\n",
      "|    n_updates            | 17920       |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 35.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57e+03    |\n",
      "|    ep_rew_mean          | 8.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1794        |\n",
      "|    time_elapsed         | 7091        |\n",
      "|    total_timesteps      | 3674112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006641395 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 17930       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 1.32e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3675000, episode_reward=24834.43 +/- 5102.61\n",
      "Episode length: 3310.80 +/- 38.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.31e+03    |\n",
      "|    mean_reward          | 2.48e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3675000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010482129 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 17940       |\n",
      "|    policy_gradient_loss | 0.0105      |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 79.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.57e+03 |\n",
      "|    ep_rew_mean     | 8.44e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 517      |\n",
      "|    iterations      | 1795     |\n",
      "|    time_elapsed    | 7100     |\n",
      "|    total_timesteps | 3676160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57e+03    |\n",
      "|    ep_rew_mean          | 8.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 517         |\n",
      "|    iterations           | 1796        |\n",
      "|    time_elapsed         | 7102        |\n",
      "|    total_timesteps      | 3678208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011857764 |\n",
      "|    clip_fraction        | 0.0528      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.06e+06    |\n",
      "|    n_updates            | 17950       |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 3.17e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3680000, episode_reward=13824.78 +/- 2585.64\n",
      "Episode length: 3197.40 +/- 16.68\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.2e+03    |\n",
      "|    mean_reward          | 1.38e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3680000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02126925 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.25       |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 52         |\n",
      "|    n_updates            | 17960      |\n",
      "|    policy_gradient_loss | -0.00449   |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 3.27e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.57e+03 |\n",
      "|    ep_rew_mean     | 8.49e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 517      |\n",
      "|    iterations      | 1797     |\n",
      "|    time_elapsed    | 7112     |\n",
      "|    total_timesteps | 3680256  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.58e+03     |\n",
      "|    ep_rew_mean          | 8.39e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 517          |\n",
      "|    iterations           | 1798         |\n",
      "|    time_elapsed         | 7113         |\n",
      "|    total_timesteps      | 3682304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053965803 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.24         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 59           |\n",
      "|    n_updates            | 17970        |\n",
      "|    policy_gradient_loss | -0.000751    |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 2.22e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.58e+03   |\n",
      "|    ep_rew_mean          | 8.4e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 517        |\n",
      "|    iterations           | 1799       |\n",
      "|    time_elapsed         | 7115       |\n",
      "|    total_timesteps      | 3684352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14401534 |\n",
      "|    clip_fraction        | 0.43       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.25       |\n",
      "|    explained_variance   | 0.748      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.04e+04   |\n",
      "|    n_updates            | 17980      |\n",
      "|    policy_gradient_loss | 0.0375     |\n",
      "|    std                  | 0.235      |\n",
      "|    value_loss           | 1.85e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3685000, episode_reward=34905.35 +/- 1290.10\n",
      "Episode length: 4915.00 +/- 58.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.92e+03    |\n",
      "|    mean_reward          | 3.49e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3685000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056933846 |\n",
      "|    clip_fraction        | 0.487       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.27        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+03    |\n",
      "|    n_updates            | 17990       |\n",
      "|    policy_gradient_loss | 0.0259      |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 4.68e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.59e+03 |\n",
      "|    ep_rew_mean     | 8.53e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 517      |\n",
      "|    iterations      | 1800     |\n",
      "|    time_elapsed    | 7129     |\n",
      "|    total_timesteps | 3686400  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.59e+03    |\n",
      "|    ep_rew_mean          | 8.53e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 517         |\n",
      "|    iterations           | 1801        |\n",
      "|    time_elapsed         | 7131        |\n",
      "|    total_timesteps      | 3688448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004619963 |\n",
      "|    clip_fraction        | 0.0226      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.27        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 206         |\n",
      "|    n_updates            | 18000       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 1.51e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3690000, episode_reward=37890.99 +/- 3584.17\n",
      "Episode length: 3246.20 +/- 19.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.25e+03    |\n",
      "|    mean_reward          | 3.79e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3690000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043816373 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.28        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.85        |\n",
      "|    n_updates            | 18010       |\n",
      "|    policy_gradient_loss | 0.0164      |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 24.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.59e+03 |\n",
      "|    ep_rew_mean     | 8.62e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 516      |\n",
      "|    iterations      | 1802     |\n",
      "|    time_elapsed    | 7140     |\n",
      "|    total_timesteps | 3690496  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.59e+03     |\n",
      "|    ep_rew_mean          | 8.62e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 516          |\n",
      "|    iterations           | 1803         |\n",
      "|    time_elapsed         | 7142         |\n",
      "|    total_timesteps      | 3692544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035589645 |\n",
      "|    clip_fraction        | 0.0947       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.29         |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.03e+03     |\n",
      "|    n_updates            | 18020        |\n",
      "|    policy_gradient_loss | 0.000458     |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 3.62e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.6e+03      |\n",
      "|    ep_rew_mean          | 8.68e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 517          |\n",
      "|    iterations           | 1804         |\n",
      "|    time_elapsed         | 7144         |\n",
      "|    total_timesteps      | 3694592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078381505 |\n",
      "|    clip_fraction        | 0.0699       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.29         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 36.3         |\n",
      "|    n_updates            | 18030        |\n",
      "|    policy_gradient_loss | -0.00429     |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 200          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3695000, episode_reward=-147.30 +/- 74030.88\n",
      "Episode length: 2630.80 +/- 1269.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.63e+03     |\n",
      "|    mean_reward          | -147         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3695000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018401649 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.29         |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.09e+04     |\n",
      "|    n_updates            | 18040        |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 3.74e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.61e+03 |\n",
      "|    ep_rew_mean     | 8.83e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 516      |\n",
      "|    iterations      | 1805     |\n",
      "|    time_elapsed    | 7152     |\n",
      "|    total_timesteps | 3696640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.61e+03    |\n",
      "|    ep_rew_mean          | 8.83e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 1806        |\n",
      "|    time_elapsed         | 7154        |\n",
      "|    total_timesteps      | 3698688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006821003 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.29        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.3        |\n",
      "|    n_updates            | 18050       |\n",
      "|    policy_gradient_loss | 0.0003      |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 3.36e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3700000, episode_reward=-39670.74 +/- 54005.32\n",
      "Episode length: 2583.00 +/- 1245.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.58e+03    |\n",
      "|    mean_reward          | -3.97e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010554534 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.3         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.44        |\n",
      "|    n_updates            | 18060       |\n",
      "|    policy_gradient_loss | 0.0021      |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 26.2        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.61e+03 |\n",
      "|    ep_rew_mean     | 8.46e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 516      |\n",
      "|    iterations      | 1807     |\n",
      "|    time_elapsed    | 7162     |\n",
      "|    total_timesteps | 3700736  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.61e+03     |\n",
      "|    ep_rew_mean          | 8.5e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 516          |\n",
      "|    iterations           | 1808         |\n",
      "|    time_elapsed         | 7163         |\n",
      "|    total_timesteps      | 3702784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040016957 |\n",
      "|    clip_fraction        | 0.0675       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.31         |\n",
      "|    explained_variance   | 0.544        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.95e+05     |\n",
      "|    n_updates            | 18070        |\n",
      "|    policy_gradient_loss | 0.000709     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 3e+06        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.61e+03     |\n",
      "|    ep_rew_mean          | 8.5e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 517          |\n",
      "|    iterations           | 1809         |\n",
      "|    time_elapsed         | 7165         |\n",
      "|    total_timesteps      | 3704832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057170754 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.31         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 135          |\n",
      "|    n_updates            | 18080        |\n",
      "|    policy_gradient_loss | 0.000339     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 2.67e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3705000, episode_reward=42957.21 +/- 3294.00\n",
      "Episode length: 3465.80 +/- 42.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.47e+03    |\n",
      "|    mean_reward          | 4.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3705000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027791195 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.34        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.2        |\n",
      "|    n_updates            | 18090       |\n",
      "|    policy_gradient_loss | 0.00599     |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 28.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.62e+03 |\n",
      "|    ep_rew_mean     | 8.64e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 516      |\n",
      "|    iterations      | 1810     |\n",
      "|    time_elapsed    | 7175     |\n",
      "|    total_timesteps | 3706880  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.63e+03     |\n",
      "|    ep_rew_mean          | 8.77e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 516          |\n",
      "|    iterations           | 1811         |\n",
      "|    time_elapsed         | 7177         |\n",
      "|    total_timesteps      | 3708928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041816975 |\n",
      "|    clip_fraction        | 0.0535       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.36         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 38.1         |\n",
      "|    n_updates            | 18100        |\n",
      "|    policy_gradient_loss | 0.00229      |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 979          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3710000, episode_reward=35445.40 +/- 3405.61\n",
      "Episode length: 3554.00 +/- 41.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.55e+03    |\n",
      "|    mean_reward          | 3.54e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008763874 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.36        |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.49e+05    |\n",
      "|    n_updates            | 18110       |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 8.77e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.63e+03 |\n",
      "|    ep_rew_mean     | 8.77e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 516      |\n",
      "|    iterations      | 1812     |\n",
      "|    time_elapsed    | 7187     |\n",
      "|    total_timesteps | 3710976  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.65e+03   |\n",
      "|    ep_rew_mean          | 1.02e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 516        |\n",
      "|    iterations           | 1813       |\n",
      "|    time_elapsed         | 7189       |\n",
      "|    total_timesteps      | 3713024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03753549 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.36       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.44       |\n",
      "|    n_updates            | 18120      |\n",
      "|    policy_gradient_loss | 0.0164     |\n",
      "|    std                  | 0.23       |\n",
      "|    value_loss           | 27.5       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3715000, episode_reward=37236.66 +/- 1523.16\n",
      "Episode length: 3373.60 +/- 87.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.37e+03    |\n",
      "|    mean_reward          | 3.72e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3715000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011202365 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.38        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 18130       |\n",
      "|    policy_gradient_loss | 0.00754     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 2.15e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.65e+03 |\n",
      "|    ep_rew_mean     | 1.02e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 516      |\n",
      "|    iterations      | 1814     |\n",
      "|    time_elapsed    | 7199     |\n",
      "|    total_timesteps | 3715072  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.67e+03   |\n",
      "|    ep_rew_mean          | 1.03e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 516        |\n",
      "|    iterations           | 1815       |\n",
      "|    time_elapsed         | 7201       |\n",
      "|    total_timesteps      | 3717120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04243382 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.37       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.7       |\n",
      "|    n_updates            | 18140      |\n",
      "|    policy_gradient_loss | 0.00806    |\n",
      "|    std                  | 0.231      |\n",
      "|    value_loss           | 161        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.67e+03     |\n",
      "|    ep_rew_mean          | 1.04e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 516          |\n",
      "|    iterations           | 1816         |\n",
      "|    time_elapsed         | 7202         |\n",
      "|    total_timesteps      | 3719168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059577664 |\n",
      "|    clip_fraction        | 0.0789       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.35         |\n",
      "|    explained_variance   | 0.992        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 293          |\n",
      "|    n_updates            | 18150        |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    std                  | 0.232        |\n",
      "|    value_loss           | 4.2e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3720000, episode_reward=779.40 +/- 56014.72\n",
      "Episode length: 2594.60 +/- 1062.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.59e+03    |\n",
      "|    mean_reward          | 779         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012352996 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.35        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 18160       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 1.45e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.67e+03 |\n",
      "|    ep_rew_mean     | 1.04e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 516      |\n",
      "|    iterations      | 1817     |\n",
      "|    time_elapsed    | 7210     |\n",
      "|    total_timesteps | 3721216  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.67e+03    |\n",
      "|    ep_rew_mean          | 1.05e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 1818        |\n",
      "|    time_elapsed         | 7212        |\n",
      "|    total_timesteps      | 3723264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027915558 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.35        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.14        |\n",
      "|    n_updates            | 18170       |\n",
      "|    policy_gradient_loss | 0.00933     |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 44.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3725000, episode_reward=35631.81 +/- 3765.50\n",
      "Episode length: 3172.80 +/- 38.18\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 3.17e+03  |\n",
      "|    mean_reward          | 3.56e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3725000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0225038 |\n",
      "|    clip_fraction        | 0.388     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.36      |\n",
      "|    explained_variance   | 0.658     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.63e+04  |\n",
      "|    n_updates            | 18180     |\n",
      "|    policy_gradient_loss | 0.00556   |\n",
      "|    std                  | 0.231     |\n",
      "|    value_loss           | 2e+05     |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.68e+03 |\n",
      "|    ep_rew_mean     | 1.04e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 515      |\n",
      "|    iterations      | 1819     |\n",
      "|    time_elapsed    | 7221     |\n",
      "|    total_timesteps | 3725312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | 1.05e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 1820        |\n",
      "|    time_elapsed         | 7223        |\n",
      "|    total_timesteps      | 3727360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020838115 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.36        |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.7        |\n",
      "|    n_updates            | 18190       |\n",
      "|    policy_gradient_loss | 0.00117     |\n",
      "|    std                  | 0.23        |\n",
      "|    value_loss           | 5.49e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | 1.05e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 1821        |\n",
      "|    time_elapsed         | 7225        |\n",
      "|    total_timesteps      | 3729408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008051321 |\n",
      "|    clip_fraction        | 0.0951      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.37        |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.42e+03    |\n",
      "|    n_updates            | 18200       |\n",
      "|    policy_gradient_loss | 0.00878     |\n",
      "|    std                  | 0.23        |\n",
      "|    value_loss           | 4.93e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3730000, episode_reward=32620.85 +/- 3430.23\n",
      "Episode length: 2989.00 +/- 24.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.99e+03     |\n",
      "|    mean_reward          | 3.26e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3730000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065863207 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.37         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 58           |\n",
      "|    n_updates            | 18210        |\n",
      "|    policy_gradient_loss | -0.00289     |\n",
      "|    std                  | 0.23         |\n",
      "|    value_loss           | 351          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | 1.05e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 515      |\n",
      "|    iterations      | 1822     |\n",
      "|    time_elapsed    | 7234     |\n",
      "|    total_timesteps | 3731456  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.68e+03    |\n",
      "|    ep_rew_mean          | 9.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 1823        |\n",
      "|    time_elapsed         | 7236        |\n",
      "|    total_timesteps      | 3733504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019862134 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.37        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 18220       |\n",
      "|    policy_gradient_loss | 0.0101      |\n",
      "|    std                  | 0.23        |\n",
      "|    value_loss           | 64.1        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3735000, episode_reward=36956.22 +/- 11625.16\n",
      "Episode length: 4229.60 +/- 328.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.23e+03    |\n",
      "|    mean_reward          | 3.7e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3735000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062529065 |\n",
      "|    clip_fraction        | 0.475       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.38        |\n",
      "|    explained_variance   | 0.287       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+07    |\n",
      "|    n_updates            | 18230       |\n",
      "|    policy_gradient_loss | 0.015       |\n",
      "|    std                  | 0.23        |\n",
      "|    value_loss           | 1.8e+07     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | 9.54e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 515      |\n",
      "|    iterations      | 1824     |\n",
      "|    time_elapsed    | 7247     |\n",
      "|    total_timesteps | 3735552  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | 9.54e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 1825        |\n",
      "|    time_elapsed         | 7249        |\n",
      "|    total_timesteps      | 3737600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009504138 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.39        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 235         |\n",
      "|    n_updates            | 18240       |\n",
      "|    policy_gradient_loss | -0.00575    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 5.69e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.7e+03      |\n",
      "|    ep_rew_mean          | 9.55e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 515          |\n",
      "|    iterations           | 1826         |\n",
      "|    time_elapsed         | 7251         |\n",
      "|    total_timesteps      | 3739648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133229755 |\n",
      "|    clip_fraction        | 0.211        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.4          |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 63.4         |\n",
      "|    n_updates            | 18250        |\n",
      "|    policy_gradient_loss | 0.0023       |\n",
      "|    std                  | 0.228        |\n",
      "|    value_loss           | 248          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3740000, episode_reward=-1404.18 +/- 20218.75\n",
      "Episode length: 2921.00 +/- 117.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.92e+03     |\n",
      "|    mean_reward          | -1.4e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3740000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052010166 |\n",
      "|    clip_fraction        | 0.0684       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.4          |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+05      |\n",
      "|    n_updates            | 18260        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    std                  | 0.228        |\n",
      "|    value_loss           | 1.35e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 9.53e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 515      |\n",
      "|    iterations      | 1827     |\n",
      "|    time_elapsed    | 7260     |\n",
      "|    total_timesteps | 3741696  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.71e+03    |\n",
      "|    ep_rew_mean          | 9.53e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 1828        |\n",
      "|    time_elapsed         | 7262        |\n",
      "|    total_timesteps      | 3743744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012070045 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.4         |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 18270       |\n",
      "|    policy_gradient_loss | -0.000278   |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 277         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3745000, episode_reward=28329.67 +/- 3543.10\n",
      "Episode length: 3091.80 +/- 9.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.09e+03    |\n",
      "|    mean_reward          | 2.83e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3745000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011841058 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.41        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.8        |\n",
      "|    n_updates            | 18280       |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 96.2        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 9.47e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 515      |\n",
      "|    iterations      | 1829     |\n",
      "|    time_elapsed    | 7271     |\n",
      "|    total_timesteps | 3745792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.71e+03    |\n",
      "|    ep_rew_mean          | 9.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 1830        |\n",
      "|    time_elapsed         | 7273        |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023095336 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.43        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 18290       |\n",
      "|    policy_gradient_loss | 0.0231      |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 161         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.72e+03    |\n",
      "|    ep_rew_mean          | 1.07e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 1831        |\n",
      "|    time_elapsed         | 7274        |\n",
      "|    total_timesteps      | 3749888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012720037 |\n",
      "|    clip_fraction        | 0.0936      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.43        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 18300       |\n",
      "|    policy_gradient_loss | 0.000115    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3750000, episode_reward=32663.75 +/- 5937.45\n",
      "Episode length: 3145.60 +/- 18.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.15e+03    |\n",
      "|    mean_reward          | 3.27e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009603177 |\n",
      "|    clip_fraction        | 0.0866      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.43        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 18310       |\n",
      "|    policy_gradient_loss | -0.00225    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 3.29e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | 1.01e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 515      |\n",
      "|    iterations      | 1832     |\n",
      "|    time_elapsed    | 7284     |\n",
      "|    total_timesteps | 3751936  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.7e+03      |\n",
      "|    ep_rew_mean          | 1.14e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 515          |\n",
      "|    iterations           | 1833         |\n",
      "|    time_elapsed         | 7285         |\n",
      "|    total_timesteps      | 3753984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005625516 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.43         |\n",
      "|    explained_variance   | 0.303        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.32e+07     |\n",
      "|    n_updates            | 18320        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    std                  | 0.228        |\n",
      "|    value_loss           | 3.77e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3755000, episode_reward=16303.39 +/- 8247.22\n",
      "Episode length: 2991.80 +/- 65.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.99e+03    |\n",
      "|    mean_reward          | 1.63e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3755000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011376139 |\n",
      "|    clip_fraction        | 0.0852      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.43        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 18330       |\n",
      "|    policy_gradient_loss | -0.0039     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.42e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 1.24e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 514      |\n",
      "|    iterations      | 1834     |\n",
      "|    time_elapsed    | 7294     |\n",
      "|    total_timesteps | 3756032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.71e+03    |\n",
      "|    ep_rew_mean          | 1.24e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 1835        |\n",
      "|    time_elapsed         | 7296        |\n",
      "|    total_timesteps      | 3758080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008408692 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.43        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.1        |\n",
      "|    n_updates            | 18340       |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 494         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3760000, episode_reward=31868.86 +/- 5909.00\n",
      "Episode length: 3133.40 +/- 43.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.13e+03    |\n",
      "|    mean_reward          | 3.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047291536 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.45        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.1        |\n",
      "|    n_updates            | 18350       |\n",
      "|    policy_gradient_loss | 0.0136      |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 73.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 1.24e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 514      |\n",
      "|    iterations      | 1836     |\n",
      "|    time_elapsed    | 7305     |\n",
      "|    total_timesteps | 3760128  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.71e+03    |\n",
      "|    ep_rew_mean          | 1.24e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1837        |\n",
      "|    time_elapsed         | 7307        |\n",
      "|    total_timesteps      | 3762176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010497564 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.47        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 18360       |\n",
      "|    policy_gradient_loss | 0.0145      |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.18e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.71e+03    |\n",
      "|    ep_rew_mean          | 1.24e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1838        |\n",
      "|    time_elapsed         | 7309        |\n",
      "|    total_timesteps      | 3764224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008853793 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.47        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.9        |\n",
      "|    n_updates            | 18370       |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 258         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3765000, episode_reward=34701.91 +/- 4883.54\n",
      "Episode length: 4241.40 +/- 27.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.24e+03    |\n",
      "|    mean_reward          | 3.47e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3765000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011568449 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.48        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19          |\n",
      "|    n_updates            | 18380       |\n",
      "|    policy_gradient_loss | 0.0129      |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 75          |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 1.25e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 514      |\n",
      "|    iterations      | 1839     |\n",
      "|    time_elapsed    | 7321     |\n",
      "|    total_timesteps | 3766272  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.73e+03    |\n",
      "|    ep_rew_mean          | 1.26e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1840        |\n",
      "|    time_elapsed         | 7322        |\n",
      "|    total_timesteps      | 3768320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020728434 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 18390       |\n",
      "|    policy_gradient_loss | 0.00952     |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 1.22e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3770000, episode_reward=34975.98 +/- 295.68\n",
      "Episode length: 4205.60 +/- 13.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.21e+03    |\n",
      "|    mean_reward          | 3.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006695142 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.6        |\n",
      "|    n_updates            | 18400       |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 1.38e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.73e+03 |\n",
      "|    ep_rew_mean     | 1.26e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 514      |\n",
      "|    iterations      | 1841     |\n",
      "|    time_elapsed    | 7334     |\n",
      "|    total_timesteps | 3770368  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.74e+03    |\n",
      "|    ep_rew_mean          | 1.26e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1842        |\n",
      "|    time_elapsed         | 7336        |\n",
      "|    total_timesteps      | 3772416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025843704 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.48        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 18410       |\n",
      "|    policy_gradient_loss | 0.0251      |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 35.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.74e+03    |\n",
      "|    ep_rew_mean          | 1.26e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1843        |\n",
      "|    time_elapsed         | 7338        |\n",
      "|    total_timesteps      | 3774464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011229097 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.48        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 18420       |\n",
      "|    policy_gradient_loss | -0.000487   |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3775000, episode_reward=-5959.08 +/- 61704.50\n",
      "Episode length: 2528.40 +/- 1220.73\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.53e+03  |\n",
      "|    mean_reward          | -5.96e+03 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3775000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0164531 |\n",
      "|    clip_fraction        | 0.134     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.48      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 31.9      |\n",
      "|    n_updates            | 18430     |\n",
      "|    policy_gradient_loss | -0.00162  |\n",
      "|    std                  | 0.227     |\n",
      "|    value_loss           | 125       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.74e+03 |\n",
      "|    ep_rew_mean     | 1.26e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 514      |\n",
      "|    iterations      | 1844     |\n",
      "|    time_elapsed    | 7345     |\n",
      "|    total_timesteps | 3776512  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.74e+03    |\n",
      "|    ep_rew_mean          | 1.27e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1845        |\n",
      "|    time_elapsed         | 7347        |\n",
      "|    total_timesteps      | 3778560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023162808 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.48        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.58        |\n",
      "|    n_updates            | 18440       |\n",
      "|    policy_gradient_loss | 0.00746     |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 56.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3780000, episode_reward=22698.16 +/- 4060.57\n",
      "Episode length: 2041.40 +/- 14.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.04e+03    |\n",
      "|    mean_reward          | 2.27e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035257712 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.9        |\n",
      "|    n_updates            | 18450       |\n",
      "|    policy_gradient_loss | 0.00795     |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.74e+03 |\n",
      "|    ep_rew_mean     | 1.27e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 514      |\n",
      "|    iterations      | 1846     |\n",
      "|    time_elapsed    | 7354     |\n",
      "|    total_timesteps | 3780608  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.74e+03   |\n",
      "|    ep_rew_mean          | 1.27e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 514        |\n",
      "|    iterations           | 1847       |\n",
      "|    time_elapsed         | 7356       |\n",
      "|    total_timesteps      | 3782656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12236312 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.5        |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19.6       |\n",
      "|    n_updates            | 18460      |\n",
      "|    policy_gradient_loss | 0.0113     |\n",
      "|    std                  | 0.225      |\n",
      "|    value_loss           | 224        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.75e+03    |\n",
      "|    ep_rew_mean          | 1.29e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1848        |\n",
      "|    time_elapsed         | 7358        |\n",
      "|    total_timesteps      | 3784704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029447991 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 18470       |\n",
      "|    policy_gradient_loss | 0.00542     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 52.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3785000, episode_reward=28506.13 +/- 2358.74\n",
      "Episode length: 3360.80 +/- 9.41\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.36e+03   |\n",
      "|    mean_reward          | 2.85e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3785000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04127024 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.47       |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.2       |\n",
      "|    n_updates            | 18480      |\n",
      "|    policy_gradient_loss | 0.0147     |\n",
      "|    std                  | 0.227      |\n",
      "|    value_loss           | 49         |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.75e+03 |\n",
      "|    ep_rew_mean     | 1.29e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1849     |\n",
      "|    time_elapsed    | 7367     |\n",
      "|    total_timesteps | 3786752  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | 1.28e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1850        |\n",
      "|    time_elapsed         | 7369        |\n",
      "|    total_timesteps      | 3788800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033686638 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.14        |\n",
      "|    n_updates            | 18490       |\n",
      "|    policy_gradient_loss | 0.0069      |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 1.99e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3790000, episode_reward=-6060.02 +/- 69369.45\n",
      "Episode length: 2443.40 +/- 1176.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.44e+03    |\n",
      "|    mean_reward          | -6.06e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017886711 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.5         |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.1         |\n",
      "|    n_updates            | 18500       |\n",
      "|    policy_gradient_loss | 0.00131     |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 34.8        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.76e+03 |\n",
      "|    ep_rew_mean     | 1.28e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1851     |\n",
      "|    time_elapsed    | 7377     |\n",
      "|    total_timesteps | 3790848  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.77e+03    |\n",
      "|    ep_rew_mean          | 1.29e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1852        |\n",
      "|    time_elapsed         | 7378        |\n",
      "|    total_timesteps      | 3792896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008777482 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.5         |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.9        |\n",
      "|    n_updates            | 18510       |\n",
      "|    policy_gradient_loss | 0.00206     |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 518         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.77e+03    |\n",
      "|    ep_rew_mean          | 1.3e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1853        |\n",
      "|    time_elapsed         | 7380        |\n",
      "|    total_timesteps      | 3794944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020253602 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.5         |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.7        |\n",
      "|    n_updates            | 18520       |\n",
      "|    policy_gradient_loss | 0.00606     |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 169         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3795000, episode_reward=24851.53 +/- 4426.38\n",
      "Episode length: 2603.00 +/- 20.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.6e+03     |\n",
      "|    mean_reward          | 2.49e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3795000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015711745 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.51        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.17        |\n",
      "|    n_updates            | 18530       |\n",
      "|    policy_gradient_loss | 0.00859     |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.77e+03 |\n",
      "|    ep_rew_mean     | 1.31e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1854     |\n",
      "|    time_elapsed    | 7388     |\n",
      "|    total_timesteps | 3796992  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.77e+03   |\n",
      "|    ep_rew_mean          | 1.32e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 514        |\n",
      "|    iterations           | 1855       |\n",
      "|    time_elapsed         | 7390       |\n",
      "|    total_timesteps      | 3799040    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09987573 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.52       |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.82       |\n",
      "|    n_updates            | 18540      |\n",
      "|    policy_gradient_loss | 0.00367    |\n",
      "|    std                  | 0.224      |\n",
      "|    value_loss           | 28.6       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3800000, episode_reward=26149.23 +/- 3093.38\n",
      "Episode length: 2705.80 +/- 7.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.71e+03    |\n",
      "|    mean_reward          | 2.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005446488 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.53        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 18550       |\n",
      "|    policy_gradient_loss | -0.00113    |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 1.56e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.77e+03 |\n",
      "|    ep_rew_mean     | 1.32e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1856     |\n",
      "|    time_elapsed    | 7398     |\n",
      "|    total_timesteps | 3801088  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.77e+03   |\n",
      "|    ep_rew_mean          | 1.31e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 513        |\n",
      "|    iterations           | 1857       |\n",
      "|    time_elapsed         | 7400       |\n",
      "|    total_timesteps      | 3803136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03848857 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.53       |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.8       |\n",
      "|    n_updates            | 18560      |\n",
      "|    policy_gradient_loss | 0.0107     |\n",
      "|    std                  | 0.223      |\n",
      "|    value_loss           | 29.6       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3805000, episode_reward=21609.79 +/- 3703.13\n",
      "Episode length: 2534.20 +/- 15.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.53e+03   |\n",
      "|    mean_reward          | 2.16e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3805000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01160149 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.54       |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 97.6       |\n",
      "|    n_updates            | 18570      |\n",
      "|    policy_gradient_loss | -0.000324  |\n",
      "|    std                  | 0.222      |\n",
      "|    value_loss           | 3.26e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.77e+03 |\n",
      "|    ep_rew_mean     | 1.31e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1858     |\n",
      "|    time_elapsed    | 7408     |\n",
      "|    total_timesteps | 3805184  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.76e+03   |\n",
      "|    ep_rew_mean          | 1.31e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 513        |\n",
      "|    iterations           | 1859       |\n",
      "|    time_elapsed         | 7410       |\n",
      "|    total_timesteps      | 3807232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16114505 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.55       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.32       |\n",
      "|    n_updates            | 18580      |\n",
      "|    policy_gradient_loss | 0.0151     |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 26.5       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.75e+03    |\n",
      "|    ep_rew_mean          | 1.3e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 1860        |\n",
      "|    time_elapsed         | 7412        |\n",
      "|    total_timesteps      | 3809280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022321545 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.57        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.84        |\n",
      "|    n_updates            | 18590       |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 55.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3810000, episode_reward=-3215.46 +/- 68304.69\n",
      "Episode length: 2089.40 +/- 1001.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.09e+03    |\n",
      "|    mean_reward          | -3.22e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013287094 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.57        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 18600       |\n",
      "|    policy_gradient_loss | 0.00821     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 78.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.73e+03 |\n",
      "|    ep_rew_mean     | 1.29e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1861     |\n",
      "|    time_elapsed    | 7418     |\n",
      "|    total_timesteps | 3811328  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.71e+03    |\n",
      "|    ep_rew_mean          | 1.24e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 1862        |\n",
      "|    time_elapsed         | 7420        |\n",
      "|    total_timesteps      | 3813376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016331317 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.12        |\n",
      "|    n_updates            | 18610       |\n",
      "|    policy_gradient_loss | 0.0035      |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 3.25e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3815000, episode_reward=28372.35 +/- 3798.58\n",
      "Episode length: 2443.40 +/- 5.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.44e+03    |\n",
      "|    mean_reward          | 2.84e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3815000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007931823 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16e+05    |\n",
      "|    n_updates            | 18620       |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 1.13e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 1.24e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1863     |\n",
      "|    time_elapsed    | 7428     |\n",
      "|    total_timesteps | 3815424  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | 1.32e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 1864        |\n",
      "|    time_elapsed         | 7430        |\n",
      "|    total_timesteps      | 3817472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008400439 |\n",
      "|    clip_fraction        | 0.0359      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 18630       |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 1.07e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.68e+03     |\n",
      "|    ep_rew_mean          | 1.31e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 1865         |\n",
      "|    time_elapsed         | 7431         |\n",
      "|    total_timesteps      | 3819520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022440092 |\n",
      "|    clip_fraction        | 0.00645      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.56         |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 332          |\n",
      "|    n_updates            | 18640        |\n",
      "|    policy_gradient_loss | -0.003       |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 1.44e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3820000, episode_reward=39935.02 +/- 253.47\n",
      "Episode length: 2944.00 +/- 13.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.94e+03    |\n",
      "|    mean_reward          | 3.99e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008661495 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 159         |\n",
      "|    n_updates            | 18650       |\n",
      "|    policy_gradient_loss | 0.00452     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 908         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 1.51e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1866     |\n",
      "|    time_elapsed    | 7440     |\n",
      "|    total_timesteps | 3821568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.7e+03     |\n",
      "|    ep_rew_mean          | 1.51e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 1867        |\n",
      "|    time_elapsed         | 7442        |\n",
      "|    total_timesteps      | 3823616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002414235 |\n",
      "|    clip_fraction        | 0.0141      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 18660       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 9.57e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3825000, episode_reward=36854.51 +/- 5337.89\n",
      "Episode length: 3237.20 +/- 23.28\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.24e+03     |\n",
      "|    mean_reward          | 3.69e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3825000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038615055 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.56         |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 500          |\n",
      "|    n_updates            | 18670        |\n",
      "|    policy_gradient_loss | -0.00421     |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 1.51e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.7e+03  |\n",
      "|    ep_rew_mean     | 1.51e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1868     |\n",
      "|    time_elapsed    | 7452     |\n",
      "|    total_timesteps | 3825664  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.7e+03     |\n",
      "|    ep_rew_mean          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 1869        |\n",
      "|    time_elapsed         | 7453        |\n",
      "|    total_timesteps      | 3827712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027095854 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.76        |\n",
      "|    n_updates            | 18680       |\n",
      "|    policy_gradient_loss | 0.00483     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 64.5        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.68e+03     |\n",
      "|    ep_rew_mean          | 1.52e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 1870         |\n",
      "|    time_elapsed         | 7455         |\n",
      "|    total_timesteps      | 3829760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037122287 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.55         |\n",
      "|    explained_variance   | 0.893        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 400          |\n",
      "|    n_updates            | 18690        |\n",
      "|    policy_gradient_loss | 0.00286      |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 2.6e+04      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3830000, episode_reward=47427.10 +/- 3882.63\n",
      "Episode length: 3462.00 +/- 27.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.46e+03    |\n",
      "|    mean_reward          | 4.74e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008866385 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.03e+03    |\n",
      "|    n_updates            | 18700       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 2.56e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.68e+03 |\n",
      "|    ep_rew_mean     | 1.41e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1871     |\n",
      "|    time_elapsed    | 7465     |\n",
      "|    total_timesteps | 3831808  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.68e+03     |\n",
      "|    ep_rew_mean          | 1.41e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 1872         |\n",
      "|    time_elapsed         | 7467         |\n",
      "|    total_timesteps      | 3833856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025249282 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.56         |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.48e+06     |\n",
      "|    n_updates            | 18710        |\n",
      "|    policy_gradient_loss | -0.000569    |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 1.68e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3835000, episode_reward=35734.53 +/- 3027.42\n",
      "Episode length: 3253.00 +/- 20.90\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.25e+03    |\n",
      "|    mean_reward          | 3.57e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3835000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055448286 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.39        |\n",
      "|    n_updates            | 18720       |\n",
      "|    policy_gradient_loss | 0.00993     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 170         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.7e+03  |\n",
      "|    ep_rew_mean     | 1.53e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1873     |\n",
      "|    time_elapsed    | 7477     |\n",
      "|    total_timesteps | 3835904  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.69e+03   |\n",
      "|    ep_rew_mean          | 1.45e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 513        |\n",
      "|    iterations           | 1874       |\n",
      "|    time_elapsed         | 7478       |\n",
      "|    total_timesteps      | 3837952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06348497 |\n",
      "|    clip_fraction        | 0.51       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.55       |\n",
      "|    explained_variance   | 0.421      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.11e+07   |\n",
      "|    n_updates            | 18730      |\n",
      "|    policy_gradient_loss | 0.0257     |\n",
      "|    std                  | 0.222      |\n",
      "|    value_loss           | 1.16e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3840000, episode_reward=46402.32 +/- 4765.07\n",
      "Episode length: 3296.20 +/- 7.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.3e+03     |\n",
      "|    mean_reward          | 4.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015665488 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 484         |\n",
      "|    n_updates            | 18740       |\n",
      "|    policy_gradient_loss | 0.0039      |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.2e+07     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.72e+03 |\n",
      "|    ep_rew_mean     | 1.62e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1875     |\n",
      "|    time_elapsed    | 7488     |\n",
      "|    total_timesteps | 3840000  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.72e+03    |\n",
      "|    ep_rew_mean          | 1.62e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1876        |\n",
      "|    time_elapsed         | 7490        |\n",
      "|    total_timesteps      | 3842048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009934317 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 18750       |\n",
      "|    policy_gradient_loss | -0.00055    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 957         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.7e+03     |\n",
      "|    ep_rew_mean          | 1.61e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 1877        |\n",
      "|    time_elapsed         | 7492        |\n",
      "|    total_timesteps      | 3844096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063749656 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.54        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 18760       |\n",
      "|    policy_gradient_loss | 0.0296      |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 25.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3845000, episode_reward=-6255.37 +/- 5164.04\n",
      "Episode length: 3040.00 +/- 19.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.04e+03    |\n",
      "|    mean_reward          | -6.26e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3845000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016386878 |\n",
      "|    clip_fraction        | 0.414       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.53        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 578         |\n",
      "|    n_updates            | 18770       |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 2.76e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | 1.49e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1878     |\n",
      "|    time_elapsed    | 7501     |\n",
      "|    total_timesteps | 3846144  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.69e+03     |\n",
      "|    ep_rew_mean          | 1.49e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1879         |\n",
      "|    time_elapsed         | 7503         |\n",
      "|    total_timesteps      | 3848192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.860764e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.53         |\n",
      "|    explained_variance   | 0.353        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.11e+06     |\n",
      "|    n_updates            | 18780        |\n",
      "|    policy_gradient_loss | -6.15e-05    |\n",
      "|    std                  | 0.223        |\n",
      "|    value_loss           | 2.26e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3850000, episode_reward=3072.12 +/- 3054.43\n",
      "Episode length: 3014.40 +/- 14.32\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.01e+03     |\n",
      "|    mean_reward          | 3.07e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3850000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024476757 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.53         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04e+05     |\n",
      "|    n_updates            | 18790        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    std                  | 0.223        |\n",
      "|    value_loss           | 3.05e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | 1.43e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1880     |\n",
      "|    time_elapsed    | 7511     |\n",
      "|    total_timesteps | 3850240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | 1.38e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1881        |\n",
      "|    time_elapsed         | 7513        |\n",
      "|    total_timesteps      | 3852288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043012433 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.53        |\n",
      "|    explained_variance   | 0.684       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 18800       |\n",
      "|    policy_gradient_loss | 0.00782     |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 3.21e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | 1.48e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1882        |\n",
      "|    time_elapsed         | 7515        |\n",
      "|    total_timesteps      | 3854336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007649882 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+07    |\n",
      "|    n_updates            | 18810       |\n",
      "|    policy_gradient_loss | 1.96e-05    |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 9.46e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3855000, episode_reward=1173.04 +/- 172.82\n",
      "Episode length: 3223.60 +/- 8.11\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.22e+03   |\n",
      "|    mean_reward          | 1.17e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3855000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01079108 |\n",
      "|    clip_fraction        | 0.0685     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.55       |\n",
      "|    explained_variance   | 0.399      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5e+06      |\n",
      "|    n_updates            | 18820      |\n",
      "|    policy_gradient_loss | 0.00518    |\n",
      "|    std                  | 0.223      |\n",
      "|    value_loss           | 1.66e+07   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | 1.5e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1883     |\n",
      "|    time_elapsed    | 7525     |\n",
      "|    total_timesteps | 3856384  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | 1.5e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1884        |\n",
      "|    time_elapsed         | 7526        |\n",
      "|    total_timesteps      | 3858432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011188942 |\n",
      "|    clip_fraction        | 0.0674      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 18830       |\n",
      "|    policy_gradient_loss | -0.00177    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 971         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3860000, episode_reward=-111646.43 +/- 5190.98\n",
      "Episode length: 3224.40 +/- 19.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.22e+03    |\n",
      "|    mean_reward          | -1.12e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011716289 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 18840       |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.7e+03  |\n",
      "|    ep_rew_mean     | 1.45e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1885     |\n",
      "|    time_elapsed    | 7536     |\n",
      "|    total_timesteps | 3860480  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.7e+03      |\n",
      "|    ep_rew_mean          | 1.39e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1886         |\n",
      "|    time_elapsed         | 7538         |\n",
      "|    total_timesteps      | 3862528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049387626 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.55         |\n",
      "|    explained_variance   | 0.492        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.51e+03     |\n",
      "|    n_updates            | 18850        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    std                  | 0.222        |\n",
      "|    value_loss           | 8.32e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.7e+03     |\n",
      "|    ep_rew_mean          | 1.39e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1887        |\n",
      "|    time_elapsed         | 7539        |\n",
      "|    total_timesteps      | 3864576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004783206 |\n",
      "|    clip_fraction        | 0.0321      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.61e+06    |\n",
      "|    n_updates            | 18860       |\n",
      "|    policy_gradient_loss | -0.00917    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.11e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3865000, episode_reward=-15415.74 +/- 9549.87\n",
      "Episode length: 3253.20 +/- 30.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.25e+03    |\n",
      "|    mean_reward          | -1.54e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3865000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007505804 |\n",
      "|    clip_fraction        | 0.0348      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.26e+07    |\n",
      "|    n_updates            | 18870       |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.52e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 1.3e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1888     |\n",
      "|    time_elapsed    | 7549     |\n",
      "|    total_timesteps | 3866624  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.71e+03   |\n",
      "|    ep_rew_mean          | 1.33e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 512        |\n",
      "|    iterations           | 1889       |\n",
      "|    time_elapsed         | 7551       |\n",
      "|    total_timesteps      | 3868672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09130951 |\n",
      "|    clip_fraction        | 0.473      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.56       |\n",
      "|    explained_variance   | 0.656      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16.2       |\n",
      "|    n_updates            | 18880      |\n",
      "|    policy_gradient_loss | 0.0268     |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 4.52e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3870000, episode_reward=36032.76 +/- 1488.81\n",
      "Episode length: 2429.00 +/- 19.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.43e+03    |\n",
      "|    mean_reward          | 3.6e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012316205 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.58        |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2e+05       |\n",
      "|    n_updates            | 18890       |\n",
      "|    policy_gradient_loss | -0.000485   |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 5.42e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 1.33e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1890     |\n",
      "|    time_elapsed    | 7558     |\n",
      "|    total_timesteps | 3870720  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.69e+03     |\n",
      "|    ep_rew_mean          | 1.34e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1891         |\n",
      "|    time_elapsed         | 7560         |\n",
      "|    total_timesteps      | 3872768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071298652 |\n",
      "|    clip_fraction        | 0.0576       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.3         |\n",
      "|    n_updates            | 18900        |\n",
      "|    policy_gradient_loss | -0.000296    |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 238          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.68e+03     |\n",
      "|    ep_rew_mean          | 1.34e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1892         |\n",
      "|    time_elapsed         | 7562         |\n",
      "|    total_timesteps      | 3874816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0140797235 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.89         |\n",
      "|    n_updates            | 18910        |\n",
      "|    policy_gradient_loss | 0.000877     |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 2.01e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3875000, episode_reward=22956.61 +/- 1458.46\n",
      "Episode length: 2380.40 +/- 16.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.38e+03    |\n",
      "|    mean_reward          | 2.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3875000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006570476 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 672         |\n",
      "|    n_updates            | 18920       |\n",
      "|    policy_gradient_loss | -0.000534   |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 4.88e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.66e+03 |\n",
      "|    ep_rew_mean     | 1.34e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1893     |\n",
      "|    time_elapsed    | 7569     |\n",
      "|    total_timesteps | 3876864  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.66e+03     |\n",
      "|    ep_rew_mean          | 1.34e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1894         |\n",
      "|    time_elapsed         | 7571         |\n",
      "|    total_timesteps      | 3878912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042096693 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 82.9         |\n",
      "|    n_updates            | 18930        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 2.14e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3880000, episode_reward=27821.39 +/- 5056.45\n",
      "Episode length: 2290.40 +/- 19.90\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.29e+03    |\n",
      "|    mean_reward          | 2.78e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004909727 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 192         |\n",
      "|    n_updates            | 18940       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.64e+03 |\n",
      "|    ep_rew_mean     | 1.33e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1895     |\n",
      "|    time_elapsed    | 7579     |\n",
      "|    total_timesteps | 3880960  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.66e+03    |\n",
      "|    ep_rew_mean          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1896        |\n",
      "|    time_elapsed         | 7580        |\n",
      "|    total_timesteps      | 3883008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015727546 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26          |\n",
      "|    n_updates            | 18950       |\n",
      "|    policy_gradient_loss | 0.00899     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 1.46e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3885000, episode_reward=26497.17 +/- 2853.33\n",
      "Episode length: 2125.00 +/- 19.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.12e+03    |\n",
      "|    mean_reward          | 2.65e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3885000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036549643 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.58        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.1        |\n",
      "|    n_updates            | 18960       |\n",
      "|    policy_gradient_loss | 0.00567     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 2.01e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.64e+03 |\n",
      "|    ep_rew_mean     | 1.52e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1897     |\n",
      "|    time_elapsed    | 7587     |\n",
      "|    total_timesteps | 3885056  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.63e+03    |\n",
      "|    ep_rew_mean          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1898        |\n",
      "|    time_elapsed         | 7589        |\n",
      "|    total_timesteps      | 3887104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018109228 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.79        |\n",
      "|    n_updates            | 18970       |\n",
      "|    policy_gradient_loss | 0.0169      |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 33.5        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.62e+03    |\n",
      "|    ep_rew_mean          | 1.51e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1899        |\n",
      "|    time_elapsed         | 7591        |\n",
      "|    total_timesteps      | 3889152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017639745 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11          |\n",
      "|    n_updates            | 18980       |\n",
      "|    policy_gradient_loss | 0.00754     |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 1.47e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3890000, episode_reward=24679.45 +/- 4127.90\n",
      "Episode length: 2403.40 +/- 24.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.4e+03     |\n",
      "|    mean_reward          | 2.47e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025050277 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.6        |\n",
      "|    n_updates            | 18990       |\n",
      "|    policy_gradient_loss | 0.00146     |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 3.25e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.6e+03  |\n",
      "|    ep_rew_mean     | 1.27e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1900     |\n",
      "|    time_elapsed    | 7598     |\n",
      "|    total_timesteps | 3891200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.6e+03     |\n",
      "|    ep_rew_mean          | 1.14e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1901        |\n",
      "|    time_elapsed         | 7600        |\n",
      "|    total_timesteps      | 3893248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009749286 |\n",
      "|    clip_fraction        | 0.0828      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.1e+07     |\n",
      "|    n_updates            | 19000       |\n",
      "|    policy_gradient_loss | 0.0236      |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 3.75e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3895000, episode_reward=28613.97 +/- 3078.52\n",
      "Episode length: 2348.60 +/- 16.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.35e+03     |\n",
      "|    mean_reward          | 2.86e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3895000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010483591 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.03e+07     |\n",
      "|    n_updates            | 19010        |\n",
      "|    policy_gradient_loss | -0.00276     |\n",
      "|    std                  | 0.223        |\n",
      "|    value_loss           | 2.26e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.57e+03 |\n",
      "|    ep_rew_mean     | 8.11e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1902     |\n",
      "|    time_elapsed    | 7608     |\n",
      "|    total_timesteps | 3895296  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.56e+03    |\n",
      "|    ep_rew_mean          | 6.6e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1903        |\n",
      "|    time_elapsed         | 7610        |\n",
      "|    total_timesteps      | 3897344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001158154 |\n",
      "|    clip_fraction        | 0.00669     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.02e+07    |\n",
      "|    n_updates            | 19020       |\n",
      "|    policy_gradient_loss | -0.00449    |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 5.91e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.54e+03     |\n",
      "|    ep_rew_mean          | 3.46e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1904         |\n",
      "|    time_elapsed         | 7611         |\n",
      "|    total_timesteps      | 3899392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027944688 |\n",
      "|    clip_fraction        | 0.0117       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.49e+07     |\n",
      "|    n_updates            | 19030        |\n",
      "|    policy_gradient_loss | -0.00667     |\n",
      "|    std                  | 0.223        |\n",
      "|    value_loss           | 2.66e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3900000, episode_reward=24309.33 +/- 4597.82\n",
      "Episode length: 2502.80 +/- 43.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.5e+03      |\n",
      "|    mean_reward          | 2.43e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3900000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011018419 |\n",
      "|    clip_fraction        | 0.0064       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.95e+07     |\n",
      "|    n_updates            | 19040        |\n",
      "|    policy_gradient_loss | -0.00277     |\n",
      "|    std                  | 0.223        |\n",
      "|    value_loss           | 5.5e+07      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 3.46e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1905     |\n",
      "|    time_elapsed    | 7619     |\n",
      "|    total_timesteps | 3901440  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.54e+03     |\n",
      "|    ep_rew_mean          | 1.75e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1906         |\n",
      "|    time_elapsed         | 7621         |\n",
      "|    total_timesteps      | 3903488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027196058 |\n",
      "|    clip_fraction        | 0.00347      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+04     |\n",
      "|    n_updates            | 19050        |\n",
      "|    policy_gradient_loss | -0.00223     |\n",
      "|    std                  | 0.223        |\n",
      "|    value_loss           | 1.08e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3905000, episode_reward=30245.59 +/- 4520.22\n",
      "Episode length: 2630.20 +/- 22.99\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.63e+03     |\n",
      "|    mean_reward          | 3.02e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3905000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012795132 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.89e+06     |\n",
      "|    n_updates            | 19060        |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    std                  | 0.223        |\n",
      "|    value_loss           | 2.67e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 1.75e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1907     |\n",
      "|    time_elapsed    | 7629     |\n",
      "|    total_timesteps | 3905536  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.54e+03     |\n",
      "|    ep_rew_mean          | 1.73e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1908         |\n",
      "|    time_elapsed         | 7631         |\n",
      "|    total_timesteps      | 3907584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042298874 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.01e+03     |\n",
      "|    n_updates            | 19070        |\n",
      "|    policy_gradient_loss | -0.00654     |\n",
      "|    std                  | 0.223        |\n",
      "|    value_loss           | 2.54e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.52e+03     |\n",
      "|    ep_rew_mean          | 1.68e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1909         |\n",
      "|    time_elapsed         | 7633         |\n",
      "|    total_timesteps      | 3909632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064657223 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+03     |\n",
      "|    n_updates            | 19080        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    std                  | 0.223        |\n",
      "|    value_loss           | 5.28e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3910000, episode_reward=35092.24 +/- 3919.98\n",
      "Episode length: 3150.60 +/- 15.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.15e+03     |\n",
      "|    mean_reward          | 3.51e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3910000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065645464 |\n",
      "|    clip_fraction        | 0.0489       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 260          |\n",
      "|    n_updates            | 19090        |\n",
      "|    policy_gradient_loss | -0.00191     |\n",
      "|    std                  | 0.223        |\n",
      "|    value_loss           | 5.82e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.52e+03 |\n",
      "|    ep_rew_mean     | 1.27e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1910     |\n",
      "|    time_elapsed    | 7642     |\n",
      "|    total_timesteps | 3911680  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.52e+03   |\n",
      "|    ep_rew_mean          | 1.27e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 511        |\n",
      "|    iterations           | 1911       |\n",
      "|    time_elapsed         | 7644       |\n",
      "|    total_timesteps      | 3913728    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00508269 |\n",
      "|    clip_fraction        | 0.0363     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.59       |\n",
      "|    explained_variance   | 0.765      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.31e+04   |\n",
      "|    n_updates            | 19100      |\n",
      "|    policy_gradient_loss | -0.00553   |\n",
      "|    std                  | 0.223      |\n",
      "|    value_loss           | 4.54e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3915000, episode_reward=29124.70 +/- 5162.75\n",
      "Episode length: 2799.40 +/- 16.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.8e+03     |\n",
      "|    mean_reward          | 2.91e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3915000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008360447 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.6         |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.6        |\n",
      "|    n_updates            | 19110       |\n",
      "|    policy_gradient_loss | 0.003       |\n",
      "|    std                  | 0.224       |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.52e+03 |\n",
      "|    ep_rew_mean     | 1.43e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1912     |\n",
      "|    time_elapsed    | 7652     |\n",
      "|    total_timesteps | 3915776  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.51e+03    |\n",
      "|    ep_rew_mean          | 1.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1913        |\n",
      "|    time_elapsed         | 7654        |\n",
      "|    total_timesteps      | 3917824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015326716 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.61        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.7        |\n",
      "|    n_updates            | 19120       |\n",
      "|    policy_gradient_loss | 0.000942    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 899         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.5e+03     |\n",
      "|    ep_rew_mean          | 1.41e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1914        |\n",
      "|    time_elapsed         | 7656        |\n",
      "|    total_timesteps      | 3919872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005627253 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.64        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 325         |\n",
      "|    n_updates            | 19130       |\n",
      "|    policy_gradient_loss | -0.000575   |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 776         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3920000, episode_reward=33031.68 +/- 1135.20\n",
      "Episode length: 2404.80 +/- 24.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.4e+03     |\n",
      "|    mean_reward          | 3.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010689156 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.65        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.3        |\n",
      "|    n_updates            | 19140       |\n",
      "|    policy_gradient_loss | 0.00459     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1.41e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.49e+03 |\n",
      "|    ep_rew_mean     | 1.27e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1915     |\n",
      "|    time_elapsed    | 7663     |\n",
      "|    total_timesteps | 3921920  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.49e+03   |\n",
      "|    ep_rew_mean          | 1.55e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 511        |\n",
      "|    iterations           | 1916       |\n",
      "|    time_elapsed         | 7665       |\n",
      "|    total_timesteps      | 3923968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01393966 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.66       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 39.1       |\n",
      "|    n_updates            | 19150      |\n",
      "|    policy_gradient_loss | 0.00222    |\n",
      "|    std                  | 0.22       |\n",
      "|    value_loss           | 1.51e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3925000, episode_reward=35577.48 +/- 4203.64\n",
      "Episode length: 2573.00 +/- 26.93\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.57e+03  |\n",
      "|    mean_reward          | 3.56e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3925000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0083581 |\n",
      "|    clip_fraction        | 0.143     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.65      |\n",
      "|    explained_variance   | 0.996     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 36        |\n",
      "|    n_updates            | 19160     |\n",
      "|    policy_gradient_loss | 0.00105   |\n",
      "|    std                  | 0.219     |\n",
      "|    value_loss           | 270       |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.48e+03 |\n",
      "|    ep_rew_mean     | 1.54e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1917     |\n",
      "|    time_elapsed    | 7673     |\n",
      "|    total_timesteps | 3926016  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.48e+03    |\n",
      "|    ep_rew_mean          | 1.54e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1918        |\n",
      "|    time_elapsed         | 7675        |\n",
      "|    total_timesteps      | 3928064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009935606 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.66        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 19170       |\n",
      "|    policy_gradient_loss | 0.000481    |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3930000, episode_reward=32909.20 +/- 4770.32\n",
      "Episode length: 2568.60 +/- 59.13\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.57e+03   |\n",
      "|    mean_reward          | 3.29e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3930000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01149886 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.66       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19         |\n",
      "|    n_updates            | 19180      |\n",
      "|    policy_gradient_loss | 0.00185    |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 125        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.48e+03 |\n",
      "|    ep_rew_mean     | 1.24e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1919     |\n",
      "|    time_elapsed    | 7683     |\n",
      "|    total_timesteps | 3930112  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.48e+03   |\n",
      "|    ep_rew_mean          | 1.25e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 511        |\n",
      "|    iterations           | 1920       |\n",
      "|    time_elapsed         | 7685       |\n",
      "|    total_timesteps      | 3932160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09069845 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.66       |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 101        |\n",
      "|    n_updates            | 19190      |\n",
      "|    policy_gradient_loss | 0.0021     |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 6.17e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.47e+03   |\n",
      "|    ep_rew_mean          | 1.31e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 511        |\n",
      "|    iterations           | 1921       |\n",
      "|    time_elapsed         | 7687       |\n",
      "|    total_timesteps      | 3934208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01067541 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.66       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.6       |\n",
      "|    n_updates            | 19200      |\n",
      "|    policy_gradient_loss | 0.00805    |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 127        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3935000, episode_reward=38246.97 +/- 3608.91\n",
      "Episode length: 2640.00 +/- 26.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.64e+03    |\n",
      "|    mean_reward          | 3.82e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3935000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012910698 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.66        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 194         |\n",
      "|    n_updates            | 19210       |\n",
      "|    policy_gradient_loss | -0.000839   |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 424         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.46e+03 |\n",
      "|    ep_rew_mean     | 1.27e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1922     |\n",
      "|    time_elapsed    | 7695     |\n",
      "|    total_timesteps | 3936256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.45e+03    |\n",
      "|    ep_rew_mean          | 1.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1923        |\n",
      "|    time_elapsed         | 7696        |\n",
      "|    total_timesteps      | 3938304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020536596 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.66        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.7        |\n",
      "|    n_updates            | 19220       |\n",
      "|    policy_gradient_loss | -0.00042    |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 3.28e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3940000, episode_reward=32766.01 +/- 5127.71\n",
      "Episode length: 2927.60 +/- 21.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.93e+03    |\n",
      "|    mean_reward          | 3.28e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019495022 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.67        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.9        |\n",
      "|    n_updates            | 19230       |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 136         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.45e+03 |\n",
      "|    ep_rew_mean     | 1.14e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1924     |\n",
      "|    time_elapsed    | 7705     |\n",
      "|    total_timesteps | 3940352  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | 1.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1925        |\n",
      "|    time_elapsed         | 7707        |\n",
      "|    total_timesteps      | 3942400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014940794 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.68        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 19240       |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 63.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.43e+03   |\n",
      "|    ep_rew_mean          | 1.66e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 511        |\n",
      "|    iterations           | 1926       |\n",
      "|    time_elapsed         | 7709       |\n",
      "|    total_timesteps      | 3944448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16744277 |\n",
      "|    clip_fraction        | 0.358      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.69       |\n",
      "|    explained_variance   | 0.926      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 10.7       |\n",
      "|    n_updates            | 19250      |\n",
      "|    policy_gradient_loss | 0.0169     |\n",
      "|    std                  | 0.216      |\n",
      "|    value_loss           | 1.37e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3945000, episode_reward=-28635.55 +/- 76319.91\n",
      "Episode length: 2881.40 +/- 1548.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.88e+03    |\n",
      "|    mean_reward          | -2.86e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3945000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029305093 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.7         |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66          |\n",
      "|    n_updates            | 19260       |\n",
      "|    policy_gradient_loss | 0.00735     |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 333         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.43e+03 |\n",
      "|    ep_rew_mean     | 448      |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1927     |\n",
      "|    time_elapsed    | 7717     |\n",
      "|    total_timesteps | 3946496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.43e+03    |\n",
      "|    ep_rew_mean          | -625        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1928        |\n",
      "|    time_elapsed         | 7719        |\n",
      "|    total_timesteps      | 3948544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007835095 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.7         |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1e+06       |\n",
      "|    n_updates            | 19270       |\n",
      "|    policy_gradient_loss | 0.00232     |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 2.5e+06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3950000, episode_reward=42717.02 +/- 965.77\n",
      "Episode length: 2961.60 +/- 45.46\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.96e+03     |\n",
      "|    mean_reward          | 4.27e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3950000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010574553 |\n",
      "|    clip_fraction        | 0.00547      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.7          |\n",
      "|    explained_variance   | 0.308        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+07     |\n",
      "|    n_updates            | 19280        |\n",
      "|    policy_gradient_loss | 0.00118      |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 1.9e+07      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.43e+03 |\n",
      "|    ep_rew_mean     | -625     |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1929     |\n",
      "|    time_elapsed    | 7728     |\n",
      "|    total_timesteps | 3950592  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.43e+03    |\n",
      "|    ep_rew_mean          | -564        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1930        |\n",
      "|    time_elapsed         | 7730        |\n",
      "|    total_timesteps      | 3952640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052486368 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.7         |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 19290       |\n",
      "|    policy_gradient_loss | 0.00456     |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 404         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.41e+03     |\n",
      "|    ep_rew_mean          | -1.77e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 511          |\n",
      "|    iterations           | 1931         |\n",
      "|    time_elapsed         | 7732         |\n",
      "|    total_timesteps      | 3954688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058370726 |\n",
      "|    clip_fraction        | 0.262        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.7          |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.59e+03     |\n",
      "|    n_updates            | 19300        |\n",
      "|    policy_gradient_loss | 0.021        |\n",
      "|    std                  | 0.216        |\n",
      "|    value_loss           | 4.39e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3955000, episode_reward=43769.50 +/- 4685.52\n",
      "Episode length: 3564.80 +/- 429.03\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.56e+03   |\n",
      "|    mean_reward          | 4.38e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3955000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02284643 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.7        |\n",
      "|    explained_variance   | 0.898      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.63e+05   |\n",
      "|    n_updates            | 19310      |\n",
      "|    policy_gradient_loss | 0.00564    |\n",
      "|    std                  | 0.216      |\n",
      "|    value_loss           | 1.71e+06   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -3.21e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 511       |\n",
      "|    iterations      | 1932      |\n",
      "|    time_elapsed    | 7742      |\n",
      "|    total_timesteps | 3956736   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.39e+03  |\n",
      "|    ep_rew_mean          | -3.25e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 511       |\n",
      "|    iterations           | 1933      |\n",
      "|    time_elapsed         | 7744      |\n",
      "|    total_timesteps      | 3958784   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.9058993 |\n",
      "|    clip_fraction        | 0.364     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.7       |\n",
      "|    explained_variance   | 0.884     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.15e+06  |\n",
      "|    n_updates            | 19320     |\n",
      "|    policy_gradient_loss | -0.0257   |\n",
      "|    std                  | 0.216     |\n",
      "|    value_loss           | 2.27e+06  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3960000, episode_reward=41066.73 +/- 3843.68\n",
      "Episode length: 2905.20 +/- 421.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.91e+03    |\n",
      "|    mean_reward          | 4.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010055285 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.1        |\n",
      "|    n_updates            | 19330       |\n",
      "|    policy_gradient_loss | 0.00426     |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 435         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -3.13e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1934      |\n",
      "|    time_elapsed    | 7752      |\n",
      "|    total_timesteps | 3960832   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.39e+03   |\n",
      "|    ep_rew_mean          | -3.13e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 511        |\n",
      "|    iterations           | 1935       |\n",
      "|    time_elapsed         | 7754       |\n",
      "|    total_timesteps      | 3962880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03991861 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.71       |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.5       |\n",
      "|    n_updates            | 19340      |\n",
      "|    policy_gradient_loss | 0.0179     |\n",
      "|    std                  | 0.216      |\n",
      "|    value_loss           | 1.45e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -2.93e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1936        |\n",
      "|    time_elapsed         | 7756        |\n",
      "|    total_timesteps      | 3964928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032266594 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.73        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.27        |\n",
      "|    n_updates            | 19350       |\n",
      "|    policy_gradient_loss | 0.026       |\n",
      "|    std                  | 0.215       |\n",
      "|    value_loss           | 23.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3965000, episode_reward=31925.85 +/- 17425.48\n",
      "Episode length: 3220.80 +/- 89.13\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.22e+03   |\n",
      "|    mean_reward          | 3.19e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3965000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12091147 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.74       |\n",
      "|    explained_variance   | 0.895      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 27.1       |\n",
      "|    n_updates            | 19360      |\n",
      "|    policy_gradient_loss | 0.000172   |\n",
      "|    std                  | 0.214      |\n",
      "|    value_loss           | 1.56e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -2.77e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1937      |\n",
      "|    time_elapsed    | 7765      |\n",
      "|    total_timesteps | 3966976   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.39e+03   |\n",
      "|    ep_rew_mean          | -2.77e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 510        |\n",
      "|    iterations           | 1938       |\n",
      "|    time_elapsed         | 7767       |\n",
      "|    total_timesteps      | 3969024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04065381 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.74       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 69         |\n",
      "|    n_updates            | 19370      |\n",
      "|    policy_gradient_loss | 0.00756    |\n",
      "|    std                  | 0.214      |\n",
      "|    value_loss           | 163        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3970000, episode_reward=42135.16 +/- 3433.88\n",
      "Episode length: 3155.80 +/- 6.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.16e+03    |\n",
      "|    mean_reward          | 4.21e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014693569 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.5        |\n",
      "|    n_updates            | 19380       |\n",
      "|    policy_gradient_loss | 0.00287     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 77.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -2.51e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1939      |\n",
      "|    time_elapsed    | 7777      |\n",
      "|    total_timesteps | 3971072   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | -2.47e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1940        |\n",
      "|    time_elapsed         | 7778        |\n",
      "|    total_timesteps      | 3973120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004267784 |\n",
      "|    clip_fraction        | 0.059       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 618         |\n",
      "|    n_updates            | 19390       |\n",
      "|    policy_gradient_loss | -0.000891   |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 7.93e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3975000, episode_reward=45170.16 +/- 3080.12\n",
      "Episode length: 3197.40 +/- 38.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.2e+03     |\n",
      "|    mean_reward          | 4.52e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3975000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019973788 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 83.6        |\n",
      "|    n_updates            | 19400       |\n",
      "|    policy_gradient_loss | 0.0035      |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 923         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.42e+03  |\n",
      "|    ep_rew_mean     | -1.16e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1941      |\n",
      "|    time_elapsed    | 7788      |\n",
      "|    total_timesteps | 3975168   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.42e+03   |\n",
      "|    ep_rew_mean          | -1.02e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 510        |\n",
      "|    iterations           | 1942       |\n",
      "|    time_elapsed         | 7790       |\n",
      "|    total_timesteps      | 3977216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06665911 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.74       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.9       |\n",
      "|    n_updates            | 19410      |\n",
      "|    policy_gradient_loss | 0.000774   |\n",
      "|    std                  | 0.215      |\n",
      "|    value_loss           | 154        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.42e+03     |\n",
      "|    ep_rew_mean          | -1.02e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 1943         |\n",
      "|    time_elapsed         | 7791         |\n",
      "|    total_timesteps      | 3979264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072757257 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.997        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 68.1         |\n",
      "|    n_updates            | 19420        |\n",
      "|    policy_gradient_loss | -0.00655     |\n",
      "|    std                  | 0.214        |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3980000, episode_reward=43295.57 +/- 334.79\n",
      "Episode length: 2923.80 +/- 12.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.92e+03    |\n",
      "|    mean_reward          | 4.33e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032781057 |\n",
      "|    clip_fraction        | 0.393       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.1        |\n",
      "|    n_updates            | 19430       |\n",
      "|    policy_gradient_loss | 0.0234      |\n",
      "|    std                  | 0.214       |\n",
      "|    value_loss           | 28.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.41e+03 |\n",
      "|    ep_rew_mean     | -915     |\n",
      "| time/              |          |\n",
      "|    fps             | 510      |\n",
      "|    iterations      | 1944     |\n",
      "|    time_elapsed    | 7800     |\n",
      "|    total_timesteps | 3981312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+03    |\n",
      "|    ep_rew_mean          | -848        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1945        |\n",
      "|    time_elapsed         | 7802        |\n",
      "|    total_timesteps      | 3983360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015436563 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+04    |\n",
      "|    n_updates            | 19440       |\n",
      "|    policy_gradient_loss | 0.00137     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 2.02e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3985000, episode_reward=-30389.13 +/- 62709.73\n",
      "Episode length: 3364.60 +/- 65.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.36e+03    |\n",
      "|    mean_reward          | -3.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3985000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017710632 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 19450       |\n",
      "|    policy_gradient_loss | 0.00157     |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.41e+03 |\n",
      "|    ep_rew_mean     | -703     |\n",
      "| time/              |          |\n",
      "|    fps             | 510      |\n",
      "|    iterations      | 1946     |\n",
      "|    time_elapsed    | 7812     |\n",
      "|    total_timesteps | 3985408  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.37e+03     |\n",
      "|    ep_rew_mean          | -3.11e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 1947         |\n",
      "|    time_elapsed         | 7814         |\n",
      "|    total_timesteps      | 3987456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066360123 |\n",
      "|    clip_fraction        | 0.0814       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27.6         |\n",
      "|    n_updates            | 19460        |\n",
      "|    policy_gradient_loss | 0.0011       |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 91.2         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.37e+03     |\n",
      "|    ep_rew_mean          | -3.11e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 1948         |\n",
      "|    time_elapsed         | 7815         |\n",
      "|    total_timesteps      | 3989504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037046387 |\n",
      "|    clip_fraction        | 0.00972      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.304        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.4e+06      |\n",
      "|    n_updates            | 19470        |\n",
      "|    policy_gradient_loss | -0.000388    |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 3.02e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3990000, episode_reward=33728.68 +/- 3581.09\n",
      "Episode length: 2818.60 +/- 180.10\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.82e+03   |\n",
      "|    mean_reward          | 3.37e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3990000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00523143 |\n",
      "|    clip_fraction        | 0.0162     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.78       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.47e+03   |\n",
      "|    n_updates            | 19480      |\n",
      "|    policy_gradient_loss | -0.00378   |\n",
      "|    std                  | 0.212      |\n",
      "|    value_loss           | 8.57e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.39e+03 |\n",
      "|    ep_rew_mean     | -1.6e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 510      |\n",
      "|    iterations      | 1949     |\n",
      "|    time_elapsed    | 7824     |\n",
      "|    total_timesteps | 3991552  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.42e+03     |\n",
      "|    ep_rew_mean          | -18          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 1950         |\n",
      "|    time_elapsed         | 7826         |\n",
      "|    total_timesteps      | 3993600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051194234 |\n",
      "|    clip_fraction        | 0.0191       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+04      |\n",
      "|    n_updates            | 19490        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    std                  | 0.212        |\n",
      "|    value_loss           | 5.58e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3995000, episode_reward=35805.50 +/- 3019.83\n",
      "Episode length: 3205.80 +/- 35.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.21e+03    |\n",
      "|    mean_reward          | 3.58e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3995000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004650852 |\n",
      "|    clip_fraction        | 0.0219      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.36e+03    |\n",
      "|    n_updates            | 19500       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 1.77e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.41e+03 |\n",
      "|    ep_rew_mean     | -8.2     |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1951     |\n",
      "|    time_elapsed    | 7835     |\n",
      "|    total_timesteps | 3995648  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+03    |\n",
      "|    ep_rew_mean          | 30.4        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1952        |\n",
      "|    time_elapsed         | 7837        |\n",
      "|    total_timesteps      | 3997696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005962951 |\n",
      "|    clip_fraction        | 0.0255      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 963         |\n",
      "|    n_updates            | 19510       |\n",
      "|    policy_gradient_loss | -0.00464    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 4.11e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+03    |\n",
      "|    ep_rew_mean          | 120         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1953        |\n",
      "|    time_elapsed         | 7839        |\n",
      "|    total_timesteps      | 3999744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009668968 |\n",
      "|    clip_fraction        | 0.038       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 19520       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.51e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4000000, episode_reward=33649.06 +/- 1605.38\n",
      "Episode length: 2724.40 +/- 214.28\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.72e+03     |\n",
      "|    mean_reward          | 3.36e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047011403 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 549          |\n",
      "|    n_updates            | 19530        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.64e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.41e+03 |\n",
      "|    ep_rew_mean     | 120      |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1954     |\n",
      "|    time_elapsed    | 7847     |\n",
      "|    total_timesteps | 4001792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | -848        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1955        |\n",
      "|    time_elapsed         | 7849        |\n",
      "|    total_timesteps      | 4003840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052290883 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 193         |\n",
      "|    n_updates            | 19540       |\n",
      "|    policy_gradient_loss | 0.0257      |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 651         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4005000, episode_reward=8476.18 +/- 52795.94\n",
      "Episode length: 2587.80 +/- 366.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.59e+03    |\n",
      "|    mean_reward          | 8.48e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4005000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011807026 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+06    |\n",
      "|    n_updates            | 19550       |\n",
      "|    policy_gradient_loss | 0.00385     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.99e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.41e+03  |\n",
      "|    ep_rew_mean     | -2.03e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1956      |\n",
      "|    time_elapsed    | 7857      |\n",
      "|    total_timesteps | 4005888   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -2.14e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1957        |\n",
      "|    time_elapsed         | 7858        |\n",
      "|    total_timesteps      | 4007936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015226331 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.5e+05     |\n",
      "|    n_updates            | 19560       |\n",
      "|    policy_gradient_loss | 7.15e-07    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.06e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -2.14e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1958        |\n",
      "|    time_elapsed         | 7860        |\n",
      "|    total_timesteps      | 4009984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006276373 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.64e+03    |\n",
      "|    n_updates            | 19570       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 2.59e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4010000, episode_reward=-41429.76 +/- 66964.63\n",
      "Episode length: 2386.80 +/- 731.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.39e+03    |\n",
      "|    mean_reward          | -4.14e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009284284 |\n",
      "|    clip_fraction        | 0.0656      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 19580       |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 3.39e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -1.98e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1959      |\n",
      "|    time_elapsed    | 7868      |\n",
      "|    total_timesteps | 4012032   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.39e+03     |\n",
      "|    ep_rew_mean          | -1.94e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 1960         |\n",
      "|    time_elapsed         | 7870         |\n",
      "|    total_timesteps      | 4014080      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057739704 |\n",
      "|    clip_fraction        | 0.0451       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 220          |\n",
      "|    n_updates            | 19590        |\n",
      "|    policy_gradient_loss | -0.00312     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 2.87e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4015000, episode_reward=35230.86 +/- 6212.27\n",
      "Episode length: 3256.60 +/- 78.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.26e+03     |\n",
      "|    mean_reward          | 3.52e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4015000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091563985 |\n",
      "|    clip_fraction        | 0.0716       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 156          |\n",
      "|    n_updates            | 19600        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.44e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -1.86e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1961      |\n",
      "|    time_elapsed    | 7879      |\n",
      "|    total_timesteps | 4016128   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -1.86e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1962        |\n",
      "|    time_elapsed         | 7881        |\n",
      "|    total_timesteps      | 4018176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009338995 |\n",
      "|    clip_fraction        | 0.091       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.4        |\n",
      "|    n_updates            | 19610       |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.74e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4020000, episode_reward=5165.74 +/- 54694.72\n",
      "Episode length: 3192.20 +/- 618.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.19e+03    |\n",
      "|    mean_reward          | 5.17e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010954245 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.07e+05    |\n",
      "|    n_updates            | 19620       |\n",
      "|    policy_gradient_loss | 0.00342     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.09e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.37e+03  |\n",
      "|    ep_rew_mean     | -3.33e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1963      |\n",
      "|    time_elapsed    | 7890      |\n",
      "|    total_timesteps | 4020224   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.37e+03    |\n",
      "|    ep_rew_mean          | -3.33e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1964        |\n",
      "|    time_elapsed         | 7892        |\n",
      "|    total_timesteps      | 4022272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004053084 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.44e+05    |\n",
      "|    n_updates            | 19630       |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.17e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | -3.14e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1965        |\n",
      "|    time_elapsed         | 7894        |\n",
      "|    total_timesteps      | 4024320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011368781 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 577         |\n",
      "|    n_updates            | 19640       |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.65e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4025000, episode_reward=16448.91 +/- 57684.57\n",
      "Episode length: 3335.80 +/- 793.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.34e+03    |\n",
      "|    mean_reward          | 1.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4025000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009246664 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+04    |\n",
      "|    n_updates            | 19650       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.65e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.38e+03  |\n",
      "|    ep_rew_mean     | -3.14e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1966      |\n",
      "|    time_elapsed    | 7904      |\n",
      "|    total_timesteps | 4026368   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -2.77e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1967        |\n",
      "|    time_elapsed         | 7905        |\n",
      "|    total_timesteps      | 4028416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013588237 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 366         |\n",
      "|    n_updates            | 19660       |\n",
      "|    policy_gradient_loss | 0.00505     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.87e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4030000, episode_reward=41512.59 +/- 5618.72\n",
      "Episode length: 3252.80 +/- 307.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.25e+03    |\n",
      "|    mean_reward          | 4.15e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011758638 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 19670       |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.06e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.38e+03  |\n",
      "|    ep_rew_mean     | -3.15e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1968      |\n",
      "|    time_elapsed    | 7915      |\n",
      "|    total_timesteps | 4030464   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | -3.15e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1969        |\n",
      "|    time_elapsed         | 7917        |\n",
      "|    total_timesteps      | 4032512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004109813 |\n",
      "|    clip_fraction        | 0.046       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.74e+06    |\n",
      "|    n_updates            | 19680       |\n",
      "|    policy_gradient_loss | -0.00249    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.6e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.38e+03   |\n",
      "|    ep_rew_mean          | -3.13e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 509        |\n",
      "|    iterations           | 1970       |\n",
      "|    time_elapsed         | 7918       |\n",
      "|    total_timesteps      | 4034560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01115346 |\n",
      "|    clip_fraction        | 0.122      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.78       |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 416        |\n",
      "|    n_updates            | 19690      |\n",
      "|    policy_gradient_loss | -0.0043    |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 4.56e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4035000, episode_reward=32905.87 +/- 2019.40\n",
      "Episode length: 2589.40 +/- 68.39\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.59e+03   |\n",
      "|    mean_reward          | 3.29e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4035000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01136763 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 740        |\n",
      "|    n_updates            | 19700      |\n",
      "|    policy_gradient_loss | -0.00031   |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.96e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -3.07e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1971      |\n",
      "|    time_elapsed    | 7926      |\n",
      "|    total_timesteps | 4036608   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -2.98e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1972        |\n",
      "|    time_elapsed         | 7928        |\n",
      "|    total_timesteps      | 4038656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011386372 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 231         |\n",
      "|    n_updates            | 19710       |\n",
      "|    policy_gradient_loss | -0.00215    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.06e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4040000, episode_reward=-1902.45 +/- 45265.75\n",
      "Episode length: 2075.00 +/- 831.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.08e+03    |\n",
      "|    mean_reward          | -1.9e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016416539 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 19720       |\n",
      "|    policy_gradient_loss | 0.000156    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -2.98e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1973      |\n",
      "|    time_elapsed    | 7935      |\n",
      "|    total_timesteps | 4040704   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | -2.72e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1974        |\n",
      "|    time_elapsed         | 7937        |\n",
      "|    total_timesteps      | 4042752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027966615 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 521         |\n",
      "|    n_updates            | 19730       |\n",
      "|    policy_gradient_loss | 0.00186     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.37e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.4e+03    |\n",
      "|    ep_rew_mean          | -2.61e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 509        |\n",
      "|    iterations           | 1975       |\n",
      "|    time_elapsed         | 7939       |\n",
      "|    total_timesteps      | 4044800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01676378 |\n",
      "|    clip_fraction        | 0.163      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 245        |\n",
      "|    n_updates            | 19740      |\n",
      "|    policy_gradient_loss | 0.00143    |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.22e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4045000, episode_reward=29586.99 +/- 963.77\n",
      "Episode length: 2616.60 +/- 166.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.62e+03    |\n",
      "|    mean_reward          | 2.96e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4045000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016734157 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.04e+03    |\n",
      "|    n_updates            | 19750       |\n",
      "|    policy_gradient_loss | -0.000578   |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.5e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -2.69e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1976      |\n",
      "|    time_elapsed    | 7947      |\n",
      "|    total_timesteps | 4046848   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | -2.69e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1977        |\n",
      "|    time_elapsed         | 7948        |\n",
      "|    total_timesteps      | 4048896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018089477 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 19760       |\n",
      "|    policy_gradient_loss | 0.00144     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 594         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4050000, episode_reward=-10917.24 +/- 26910.90\n",
      "Episode length: 909.80 +/- 868.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 910         |\n",
      "|    mean_reward          | -1.09e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018600289 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.8        |\n",
      "|    n_updates            | 19770       |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 367         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -3.57e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1978      |\n",
      "|    time_elapsed    | 7952      |\n",
      "|    total_timesteps | 4050944   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.39e+03   |\n",
      "|    ep_rew_mean          | -3.21e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 509        |\n",
      "|    iterations           | 1979       |\n",
      "|    time_elapsed         | 7954       |\n",
      "|    total_timesteps      | 4052992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07106335 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.306      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.31e+05   |\n",
      "|    n_updates            | 19780      |\n",
      "|    policy_gradient_loss | 0.0228     |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 7.1e+06    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4055000, episode_reward=-14638.33 +/- 23868.84\n",
      "Episode length: 578.40 +/- 157.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 578         |\n",
      "|    mean_reward          | -1.46e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4055000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012043099 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 215         |\n",
      "|    n_updates            | 19790       |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 888         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.29e+03 |\n",
      "|    ep_rew_mean     | -4.8e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1980     |\n",
      "|    time_elapsed    | 7957     |\n",
      "|    total_timesteps | 4055040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.27e+03    |\n",
      "|    ep_rew_mean          | -5.33e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1981        |\n",
      "|    time_elapsed         | 7959        |\n",
      "|    total_timesteps      | 4057088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012921253 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.93e+06    |\n",
      "|    n_updates            | 19800       |\n",
      "|    policy_gradient_loss | -0.00489    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 3.58e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.28e+03    |\n",
      "|    ep_rew_mean          | -5.08e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1982        |\n",
      "|    time_elapsed         | 7961        |\n",
      "|    total_timesteps      | 4059136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008838881 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.82e+05    |\n",
      "|    n_updates            | 19810       |\n",
      "|    policy_gradient_loss | -0.00696    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 7.66e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4060000, episode_reward=-38727.05 +/- 35076.99\n",
      "Episode length: 719.80 +/- 513.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 720          |\n",
      "|    mean_reward          | -3.87e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4060000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051528886 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+07     |\n",
      "|    n_updates            | 19820        |\n",
      "|    policy_gradient_loss | -0.00446     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.21e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.18e+03  |\n",
      "|    ep_rew_mean     | -6.56e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1983      |\n",
      "|    time_elapsed    | 7965      |\n",
      "|    total_timesteps | 4061184   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.1e+03     |\n",
      "|    ep_rew_mean          | -4.64e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1984        |\n",
      "|    time_elapsed         | 7966        |\n",
      "|    total_timesteps      | 4063232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006647419 |\n",
      "|    clip_fraction        | 0.0354      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+07    |\n",
      "|    n_updates            | 19830       |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.49e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4065000, episode_reward=-14860.48 +/- 31981.69\n",
      "Episode length: 467.00 +/- 37.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 467          |\n",
      "|    mean_reward          | -1.49e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4065000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067441273 |\n",
      "|    clip_fraction        | 0.0524       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.571        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+06     |\n",
      "|    n_updates            | 19840        |\n",
      "|    policy_gradient_loss | -0.00656     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 4.83e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.98e+03  |\n",
      "|    ep_rew_mean     | -6.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1985      |\n",
      "|    time_elapsed    | 7969      |\n",
      "|    total_timesteps | 4065280   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.86e+03     |\n",
      "|    ep_rew_mean          | -1.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 1986         |\n",
      "|    time_elapsed         | 7971         |\n",
      "|    total_timesteps      | 4067328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053821583 |\n",
      "|    clip_fraction        | 0.0561       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.27e+06     |\n",
      "|    n_updates            | 19850        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.66e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.84e+03     |\n",
      "|    ep_rew_mean          | -1.1e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 1987         |\n",
      "|    time_elapsed         | 7973         |\n",
      "|    total_timesteps      | 4069376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016371263 |\n",
      "|    clip_fraction        | 0.0181       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+07      |\n",
      "|    n_updates            | 19860        |\n",
      "|    policy_gradient_loss | -0.00212     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.49e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4070000, episode_reward=-900.55 +/- 15819.95\n",
      "Episode length: 481.00 +/- 72.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 481          |\n",
      "|    mean_reward          | -901         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4070000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050272434 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.54e+04     |\n",
      "|    n_updates            | 19870        |\n",
      "|    policy_gradient_loss | -0.00473     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.51e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.81e+03  |\n",
      "|    ep_rew_mean     | -1.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1988      |\n",
      "|    time_elapsed    | 7976      |\n",
      "|    total_timesteps | 4071424   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | -9.75e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1989        |\n",
      "|    time_elapsed         | 7978        |\n",
      "|    total_timesteps      | 4073472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004051322 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8e+05       |\n",
      "|    n_updates            | 19880       |\n",
      "|    policy_gradient_loss | 0.00274     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.5e+06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4075000, episode_reward=126.28 +/- 6310.29\n",
      "Episode length: 470.80 +/- 13.06\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 471      |\n",
      "|    mean_reward          | 126      |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 4075000  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 2.208867 |\n",
      "|    clip_fraction        | 0.204    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 2.77     |\n",
      "|    explained_variance   | 0.888    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 3.58e+05 |\n",
      "|    n_updates            | 19890    |\n",
      "|    policy_gradient_loss | 0.0188   |\n",
      "|    std                  | 0.208    |\n",
      "|    value_loss           | 1.34e+06 |\n",
      "--------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.78e+03  |\n",
      "|    ep_rew_mean     | -5.36e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1990      |\n",
      "|    time_elapsed    | 7981      |\n",
      "|    total_timesteps | 4075520   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | -2.98e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 1991         |\n",
      "|    time_elapsed         | 7983         |\n",
      "|    total_timesteps      | 4077568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028230161 |\n",
      "|    clip_fraction        | 0.0276       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.45e+06     |\n",
      "|    n_updates            | 19900        |\n",
      "|    policy_gradient_loss | -0.000179    |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.47e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.72e+03   |\n",
      "|    ep_rew_mean          | -3.07e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 510        |\n",
      "|    iterations           | 1992       |\n",
      "|    time_elapsed         | 7984       |\n",
      "|    total_timesteps      | 4079616    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01171992 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.89e+03   |\n",
      "|    n_updates            | 19910      |\n",
      "|    policy_gradient_loss | -0.00381   |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 7.34e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4080000, episode_reward=-18517.65 +/- 44273.58\n",
      "Episode length: 525.00 +/- 64.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 525         |\n",
      "|    mean_reward          | -1.85e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011056557 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+04    |\n",
      "|    n_updates            | 19920       |\n",
      "|    policy_gradient_loss | -0.000832   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.73e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -4.56e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1993      |\n",
      "|    time_elapsed    | 7987      |\n",
      "|    total_timesteps | 4081664   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -5.19e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1994        |\n",
      "|    time_elapsed         | 7989        |\n",
      "|    total_timesteps      | 4083712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006185959 |\n",
      "|    clip_fraction        | 0.0601      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.81e+05    |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | 0.000455    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 8.99e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4085000, episode_reward=-45095.47 +/- 61146.77\n",
      "Episode length: 1408.20 +/- 1012.17\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.41e+03   |\n",
      "|    mean_reward          | -4.51e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4085000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02919282 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.04e+05   |\n",
      "|    n_updates            | 19940      |\n",
      "|    policy_gradient_loss | 0.00333    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 2.28e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -7.48e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 511       |\n",
      "|    iterations      | 1995      |\n",
      "|    time_elapsed    | 7994      |\n",
      "|    total_timesteps | 4085760   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -7.45e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1996        |\n",
      "|    time_elapsed         | 7996        |\n",
      "|    total_timesteps      | 4087808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017405007 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.26e+06    |\n",
      "|    n_updates            | 19950       |\n",
      "|    policy_gradient_loss | -0.000834   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.43e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | -7.78e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1997        |\n",
      "|    time_elapsed         | 7998        |\n",
      "|    total_timesteps      | 4089856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008393856 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.572       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.28e+03    |\n",
      "|    n_updates            | 19960       |\n",
      "|    policy_gradient_loss | 0.00072     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.13e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4090000, episode_reward=-10886.59 +/- 34161.67\n",
      "Episode length: 790.20 +/- 581.08\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 790        |\n",
      "|    mean_reward          | -1.09e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4090000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06931095 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.887      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 345        |\n",
      "|    n_updates            | 19970      |\n",
      "|    policy_gradient_loss | 0.00229    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 3.27e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | -8.2e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1998     |\n",
      "|    time_elapsed    | 8002     |\n",
      "|    total_timesteps | 4091904  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | -7.13e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1999        |\n",
      "|    time_elapsed         | 8004        |\n",
      "|    total_timesteps      | 4093952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019616468 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.43e+03    |\n",
      "|    n_updates            | 19980       |\n",
      "|    policy_gradient_loss | -0.000902   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 7.39e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4095000, episode_reward=97.97 +/- 5875.87\n",
      "Episode length: 482.40 +/- 18.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 482         |\n",
      "|    mean_reward          | 98          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4095000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019605229 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.38e+03    |\n",
      "|    n_updates            | 19990       |\n",
      "|    policy_gradient_loss | -0.000936   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.24e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.4e+03   |\n",
      "|    ep_rew_mean     | -5.42e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 511       |\n",
      "|    iterations      | 2000      |\n",
      "|    time_elapsed    | 8007      |\n",
      "|    total_timesteps | 4096000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | -8.13e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 2001        |\n",
      "|    time_elapsed         | 8008        |\n",
      "|    total_timesteps      | 4098048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027991427 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.75e+03    |\n",
      "|    n_updates            | 20000       |\n",
      "|    policy_gradient_loss | 0.00815     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 5.14e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4100000, episode_reward=1420.20 +/- 8598.08\n",
      "Episode length: 576.40 +/- 214.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 576         |\n",
      "|    mean_reward          | 1.42e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012949575 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+07    |\n",
      "|    n_updates            | 20010       |\n",
      "|    policy_gradient_loss | 0.00287     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.64e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -1.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 511       |\n",
      "|    iterations      | 2002      |\n",
      "|    time_elapsed    | 8012      |\n",
      "|    total_timesteps | 4100096   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.23e+03     |\n",
      "|    ep_rew_mean          | -1.09e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 511          |\n",
      "|    iterations           | 2003         |\n",
      "|    time_elapsed         | 8013         |\n",
      "|    total_timesteps      | 4102144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069956044 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.37e+06     |\n",
      "|    n_updates            | 20020        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 1.45e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.18e+03     |\n",
      "|    ep_rew_mean          | -1.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 2004         |\n",
      "|    time_elapsed         | 8015         |\n",
      "|    total_timesteps      | 4104192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0119272685 |\n",
      "|    clip_fraction        | 0.0974       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.87e+03     |\n",
      "|    n_updates            | 20030        |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.77e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4105000, episode_reward=-2752.38 +/- 13709.15\n",
      "Episode length: 405.60 +/- 69.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 406         |\n",
      "|    mean_reward          | -2.75e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4105000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012304965 |\n",
      "|    clip_fraction        | 0.0841      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.63e+05    |\n",
      "|    n_updates            | 20040       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 4.55e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -1.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 512       |\n",
      "|    iterations      | 2005      |\n",
      "|    time_elapsed    | 8018      |\n",
      "|    total_timesteps | 4106240   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.05e+03    |\n",
      "|    ep_rew_mean          | -1.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 2006        |\n",
      "|    time_elapsed         | 8020        |\n",
      "|    total_timesteps      | 4108288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036254928 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 20050       |\n",
      "|    policy_gradient_loss | 0.00211     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 6.1e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4110000, episode_reward=-14057.65 +/- 28764.31\n",
      "Episode length: 510.20 +/- 61.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 510         |\n",
      "|    mean_reward          | -1.41e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004677646 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.34e+04    |\n",
      "|    n_updates            | 20060       |\n",
      "|    policy_gradient_loss | 0.000681    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 4.68e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 994       |\n",
      "|    ep_rew_mean     | -1.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 512       |\n",
      "|    iterations      | 2007      |\n",
      "|    time_elapsed    | 8023      |\n",
      "|    total_timesteps | 4110336   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 966         |\n",
      "|    ep_rew_mean          | -1.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 2008        |\n",
      "|    time_elapsed         | 8025        |\n",
      "|    total_timesteps      | 4112384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011759887 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.56e+04    |\n",
      "|    n_updates            | 20070       |\n",
      "|    policy_gradient_loss | -0.00494    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.49e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 880         |\n",
      "|    ep_rew_mean          | -1.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 2009        |\n",
      "|    time_elapsed         | 8027        |\n",
      "|    total_timesteps      | 4114432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010165388 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.462       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.73e+05    |\n",
      "|    n_updates            | 20080       |\n",
      "|    policy_gradient_loss | 0.00803     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.91e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4115000, episode_reward=-20406.00 +/- 55073.25\n",
      "Episode length: 383.00 +/- 163.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 383          |\n",
      "|    mean_reward          | -2.04e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4115000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034761399 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.47e+07     |\n",
      "|    n_updates            | 20090        |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.62e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 864       |\n",
      "|    ep_rew_mean     | -1.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 512       |\n",
      "|    iterations      | 2010      |\n",
      "|    time_elapsed    | 8029      |\n",
      "|    total_timesteps | 4116480   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 826        |\n",
      "|    ep_rew_mean          | -1.66e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 512        |\n",
      "|    iterations           | 2011       |\n",
      "|    time_elapsed         | 8031       |\n",
      "|    total_timesteps      | 4118528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02871991 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.78       |\n",
      "|    explained_variance   | 0.865      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.95e+05   |\n",
      "|    n_updates            | 20100      |\n",
      "|    policy_gradient_loss | 0.0138     |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 1.83e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4120000, episode_reward=-32422.36 +/- 64946.22\n",
      "Episode length: 1229.80 +/- 1148.08\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.23e+03   |\n",
      "|    mean_reward          | -3.24e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4120000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02319868 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.78       |\n",
      "|    explained_variance   | 0.819      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.88e+03   |\n",
      "|    n_updates            | 20110      |\n",
      "|    policy_gradient_loss | 0.00263    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 1.09e+05   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 763       |\n",
      "|    ep_rew_mean     | -1.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 512       |\n",
      "|    iterations      | 2012      |\n",
      "|    time_elapsed    | 8036      |\n",
      "|    total_timesteps | 4120576   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 718         |\n",
      "|    ep_rew_mean          | -1.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 2013        |\n",
      "|    time_elapsed         | 8038        |\n",
      "|    total_timesteps      | 4122624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009613588 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.58e+03    |\n",
      "|    n_updates            | 20120       |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 4.36e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 715         |\n",
      "|    ep_rew_mean          | -1.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 2014        |\n",
      "|    time_elapsed         | 8040        |\n",
      "|    total_timesteps      | 4124672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016458133 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 749         |\n",
      "|    n_updates            | 20130       |\n",
      "|    policy_gradient_loss | 0.00932     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.26e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4125000, episode_reward=-20597.40 +/- 57511.64\n",
      "Episode length: 381.80 +/- 162.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 382         |\n",
      "|    mean_reward          | -2.06e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4125000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028141575 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.77e+05    |\n",
      "|    n_updates            | 20140       |\n",
      "|    policy_gradient_loss | 0.0115      |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.6e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 725       |\n",
      "|    ep_rew_mean     | -1.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 513       |\n",
      "|    iterations      | 2015      |\n",
      "|    time_elapsed    | 8042      |\n",
      "|    total_timesteps | 4126720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 692         |\n",
      "|    ep_rew_mean          | -1.94e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 2016        |\n",
      "|    time_elapsed         | 8044        |\n",
      "|    total_timesteps      | 4128768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011581432 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5e+03       |\n",
      "|    n_updates            | 20150       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 7.91e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4130000, episode_reward=3386.94 +/- 4569.81\n",
      "Episode length: 503.60 +/- 46.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 504          |\n",
      "|    mean_reward          | 3.39e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4130000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052281683 |\n",
      "|    clip_fraction        | 0.0951       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.99e+06     |\n",
      "|    n_updates            | 20160        |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.43e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 699       |\n",
      "|    ep_rew_mean     | -1.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 513       |\n",
      "|    iterations      | 2017      |\n",
      "|    time_elapsed    | 8047      |\n",
      "|    total_timesteps | 4130816   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 699          |\n",
      "|    ep_rew_mean          | -1.89e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 2018         |\n",
      "|    time_elapsed         | 8049         |\n",
      "|    total_timesteps      | 4132864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048386073 |\n",
      "|    clip_fraction        | 0.0808       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.91e+03     |\n",
      "|    n_updates            | 20170        |\n",
      "|    policy_gradient_loss | 0.0107       |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.81e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 730         |\n",
      "|    ep_rew_mean          | -1.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 2019        |\n",
      "|    time_elapsed         | 8051        |\n",
      "|    total_timesteps      | 4134912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026146732 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 988         |\n",
      "|    n_updates            | 20180       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.74e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4135000, episode_reward=19809.26 +/- 11502.80\n",
      "Episode length: 2564.00 +/- 594.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.56e+03    |\n",
      "|    mean_reward          | 1.98e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4135000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031145906 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 300         |\n",
      "|    n_updates            | 20190       |\n",
      "|    policy_gradient_loss | 0.00284     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 2.99e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 743       |\n",
      "|    ep_rew_mean     | -1.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 513       |\n",
      "|    iterations      | 2020      |\n",
      "|    time_elapsed    | 8059      |\n",
      "|    total_timesteps | 4136960   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 757         |\n",
      "|    ep_rew_mean          | -1.84e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 2021        |\n",
      "|    time_elapsed         | 8060        |\n",
      "|    total_timesteps      | 4139008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012022736 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+03    |\n",
      "|    n_updates            | 20200       |\n",
      "|    policy_gradient_loss | -0.000268   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 2.9e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4140000, episode_reward=-10389.44 +/- 38536.58\n",
      "Episode length: 1249.80 +/- 881.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.25e+03    |\n",
      "|    mean_reward          | -1.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034545347 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.93e+06    |\n",
      "|    n_updates            | 20210       |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 2.56e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 757       |\n",
      "|    ep_rew_mean     | -1.84e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 513       |\n",
      "|    iterations      | 2022      |\n",
      "|    time_elapsed    | 8065      |\n",
      "|    total_timesteps | 4141056   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 777        |\n",
      "|    ep_rew_mean          | -1.81e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 513        |\n",
      "|    iterations           | 2023       |\n",
      "|    time_elapsed         | 8067       |\n",
      "|    total_timesteps      | 4143104    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06747359 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.919      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 123        |\n",
      "|    n_updates            | 20220      |\n",
      "|    policy_gradient_loss | 0.0176     |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 933        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4145000, episode_reward=-12804.47 +/- 34348.69\n",
      "Episode length: 611.00 +/- 512.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 611         |\n",
      "|    mean_reward          | -1.28e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4145000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005123113 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.31e+05    |\n",
      "|    n_updates            | 20230       |\n",
      "|    policy_gradient_loss | 6.19e-05    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 2.83e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 810       |\n",
      "|    ep_rew_mean     | -1.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 513       |\n",
      "|    iterations      | 2024      |\n",
      "|    time_elapsed    | 8070      |\n",
      "|    total_timesteps | 4145152   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 813        |\n",
      "|    ep_rew_mean          | -1.54e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 513        |\n",
      "|    iterations           | 2025       |\n",
      "|    time_elapsed         | 8072       |\n",
      "|    total_timesteps      | 4147200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01232725 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 165        |\n",
      "|    n_updates            | 20240      |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 906        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 817          |\n",
      "|    ep_rew_mean          | -1.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 2026         |\n",
      "|    time_elapsed         | 8074         |\n",
      "|    total_timesteps      | 4149248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059393947 |\n",
      "|    clip_fraction        | 0.0529       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+04     |\n",
      "|    n_updates            | 20250        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 2.46e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4150000, episode_reward=2526.58 +/- 9478.44\n",
      "Episode length: 441.80 +/- 65.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 442         |\n",
      "|    mean_reward          | 2.53e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004915905 |\n",
      "|    clip_fraction        | 0.0493      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.52e+06    |\n",
      "|    n_updates            | 20260       |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.42e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 799       |\n",
      "|    ep_rew_mean     | -1.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 513       |\n",
      "|    iterations      | 2027      |\n",
      "|    time_elapsed    | 8077      |\n",
      "|    total_timesteps | 4151296   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 785         |\n",
      "|    ep_rew_mean          | -1.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 2028        |\n",
      "|    time_elapsed         | 8079        |\n",
      "|    total_timesteps      | 4153344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012023019 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.41e+06    |\n",
      "|    n_updates            | 20270       |\n",
      "|    policy_gradient_loss | -8.74e-05   |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.18e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4155000, episode_reward=-1772.67 +/- 11031.35\n",
      "Episode length: 406.20 +/- 32.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 406         |\n",
      "|    mean_reward          | -1.77e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4155000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016161062 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.33e+06    |\n",
      "|    n_updates            | 20280       |\n",
      "|    policy_gradient_loss | -0.000266   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.04e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 805       |\n",
      "|    ep_rew_mean     | -1.61e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 514       |\n",
      "|    iterations      | 2029      |\n",
      "|    time_elapsed    | 8081      |\n",
      "|    total_timesteps | 4155392   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 799         |\n",
      "|    ep_rew_mean          | -1.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 2030        |\n",
      "|    time_elapsed         | 8083        |\n",
      "|    total_timesteps      | 4157440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026010107 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.87e+05    |\n",
      "|    n_updates            | 20290       |\n",
      "|    policy_gradient_loss | -0.000297   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.66e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 790         |\n",
      "|    ep_rew_mean          | -1.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 2031        |\n",
      "|    time_elapsed         | 8085        |\n",
      "|    total_timesteps      | 4159488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010801538 |\n",
      "|    clip_fraction        | 0.0884      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.04e+03    |\n",
      "|    n_updates            | 20300       |\n",
      "|    policy_gradient_loss | -0.000863   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.1e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4160000, episode_reward=-22247.93 +/- 50836.34\n",
      "Episode length: 334.20 +/- 136.90\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 334         |\n",
      "|    mean_reward          | -2.22e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007820314 |\n",
      "|    clip_fraction        | 0.0713      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.65        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.43e+04    |\n",
      "|    n_updates            | 20310       |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 8.94e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 764       |\n",
      "|    ep_rew_mean     | -1.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 514       |\n",
      "|    iterations      | 2032      |\n",
      "|    time_elapsed    | 8088      |\n",
      "|    total_timesteps | 4161536   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 735          |\n",
      "|    ep_rew_mean          | -1.63e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 514          |\n",
      "|    iterations           | 2033         |\n",
      "|    time_elapsed         | 8089         |\n",
      "|    total_timesteps      | 4163584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0103600845 |\n",
      "|    clip_fraction        | 0.0612       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.91e+06     |\n",
      "|    n_updates            | 20320        |\n",
      "|    policy_gradient_loss | 0.0018       |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.5e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4165000, episode_reward=-13946.06 +/- 31229.09\n",
      "Episode length: 486.80 +/- 147.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 487          |\n",
      "|    mean_reward          | -1.39e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4165000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034028685 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.5e+07      |\n",
      "|    n_updates            | 20330        |\n",
      "|    policy_gradient_loss | -0.000487    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.27e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 719       |\n",
      "|    ep_rew_mean     | -1.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 514       |\n",
      "|    iterations      | 2034      |\n",
      "|    time_elapsed    | 8092      |\n",
      "|    total_timesteps | 4165632   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 702          |\n",
      "|    ep_rew_mean          | -2.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 514          |\n",
      "|    iterations           | 2035         |\n",
      "|    time_elapsed         | 8094         |\n",
      "|    total_timesteps      | 4167680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051038987 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.77e+06     |\n",
      "|    n_updates            | 20340        |\n",
      "|    policy_gradient_loss | -0.00634     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.46e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 704          |\n",
      "|    ep_rew_mean          | -1.95e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 515          |\n",
      "|    iterations           | 2036         |\n",
      "|    time_elapsed         | 8096         |\n",
      "|    total_timesteps      | 4169728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052408613 |\n",
      "|    clip_fraction        | 0.0375       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.59e+06     |\n",
      "|    n_updates            | 20350        |\n",
      "|    policy_gradient_loss | -0.00657     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.77e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4170000, episode_reward=-12944.57 +/- 35560.04\n",
      "Episode length: 427.60 +/- 62.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 428          |\n",
      "|    mean_reward          | -1.29e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4170000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034000222 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+07     |\n",
      "|    n_updates            | 20360        |\n",
      "|    policy_gradient_loss | -0.00341     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.71e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 687       |\n",
      "|    ep_rew_mean     | -2.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 515       |\n",
      "|    iterations      | 2037      |\n",
      "|    time_elapsed    | 8099      |\n",
      "|    total_timesteps | 4171776   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 679         |\n",
      "|    ep_rew_mean          | -2.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 2038        |\n",
      "|    time_elapsed         | 8101        |\n",
      "|    total_timesteps      | 4173824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007153395 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.33e+06    |\n",
      "|    n_updates            | 20370       |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.27e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4175000, episode_reward=-3616.50 +/- 22187.03\n",
      "Episode length: 442.00 +/- 70.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 442          |\n",
      "|    mean_reward          | -3.62e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4175000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063791894 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.97e+07     |\n",
      "|    n_updates            | 20380        |\n",
      "|    policy_gradient_loss | -0.000895    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.8e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 686       |\n",
      "|    ep_rew_mean     | -2.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 515       |\n",
      "|    iterations      | 2039      |\n",
      "|    time_elapsed    | 8104      |\n",
      "|    total_timesteps | 4175872   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 680          |\n",
      "|    ep_rew_mean          | -2.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 515          |\n",
      "|    iterations           | 2040         |\n",
      "|    time_elapsed         | 8105         |\n",
      "|    total_timesteps      | 4177920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059812665 |\n",
      "|    clip_fraction        | 0.0433       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.514        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.31e+06     |\n",
      "|    n_updates            | 20390        |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.89e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 669        |\n",
      "|    ep_rew_mean          | -2.24e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 515        |\n",
      "|    iterations           | 2041       |\n",
      "|    time_elapsed         | 8107       |\n",
      "|    total_timesteps      | 4179968    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01167452 |\n",
      "|    clip_fraction        | 0.0973     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.76       |\n",
      "|    explained_variance   | 0.408      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.71e+07   |\n",
      "|    n_updates            | 20400      |\n",
      "|    policy_gradient_loss | 0.00507    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 2.03e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4180000, episode_reward=-16639.15 +/- 33477.06\n",
      "Episode length: 439.00 +/- 81.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 439         |\n",
      "|    mean_reward          | -1.66e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009259218 |\n",
      "|    clip_fraction        | 0.0577      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29e+04    |\n",
      "|    n_updates            | 20410       |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.83e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 653       |\n",
      "|    ep_rew_mean     | -2.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 515       |\n",
      "|    iterations      | 2042      |\n",
      "|    time_elapsed    | 8110      |\n",
      "|    total_timesteps | 4182016   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 641          |\n",
      "|    ep_rew_mean          | -2.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 515          |\n",
      "|    iterations           | 2043         |\n",
      "|    time_elapsed         | 8112         |\n",
      "|    total_timesteps      | 4184064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057093105 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.77e+07     |\n",
      "|    n_updates            | 20420        |\n",
      "|    policy_gradient_loss | -0.00156     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 6.33e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4185000, episode_reward=5268.58 +/- 3271.30\n",
      "Episode length: 386.80 +/- 14.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 387         |\n",
      "|    mean_reward          | 5.27e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4185000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008138286 |\n",
      "|    clip_fraction        | 0.0628      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.65e+07    |\n",
      "|    n_updates            | 20430       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.87e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 645       |\n",
      "|    ep_rew_mean     | -2.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 515       |\n",
      "|    iterations      | 2044      |\n",
      "|    time_elapsed    | 8115      |\n",
      "|    total_timesteps | 4186112   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 621         |\n",
      "|    ep_rew_mean          | -2.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 2045        |\n",
      "|    time_elapsed         | 8116        |\n",
      "|    total_timesteps      | 4188160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009819826 |\n",
      "|    clip_fraction        | 0.0779      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.91e+06    |\n",
      "|    n_updates            | 20440       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.08e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4190000, episode_reward=51.17 +/- 6396.35\n",
      "Episode length: 430.00 +/- 89.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 430         |\n",
      "|    mean_reward          | 51.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018299747 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.37e+04    |\n",
      "|    n_updates            | 20450       |\n",
      "|    policy_gradient_loss | 0.00325     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.35e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 620       |\n",
      "|    ep_rew_mean     | -2.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 516       |\n",
      "|    iterations      | 2046      |\n",
      "|    time_elapsed    | 8119      |\n",
      "|    total_timesteps | 4190208   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 546          |\n",
      "|    ep_rew_mean          | -2.82e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 516          |\n",
      "|    iterations           | 2047         |\n",
      "|    time_elapsed         | 8121         |\n",
      "|    total_timesteps      | 4192256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074280957 |\n",
      "|    clip_fraction        | 0.0649       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.336        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.92e+07     |\n",
      "|    n_updates            | 20460        |\n",
      "|    policy_gradient_loss | -0.00316     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.49e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 494         |\n",
      "|    ep_rew_mean          | -3.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 2048        |\n",
      "|    time_elapsed         | 8123        |\n",
      "|    total_timesteps      | 4194304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004583993 |\n",
      "|    clip_fraction        | 0.0424      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.13e+05    |\n",
      "|    n_updates            | 20470       |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.11e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4195000, episode_reward=-20302.17 +/- 47569.27\n",
      "Episode length: 343.60 +/- 151.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 344         |\n",
      "|    mean_reward          | -2.03e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4195000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007876257 |\n",
      "|    clip_fraction        | 0.0676      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.62e+06    |\n",
      "|    n_updates            | 20480       |\n",
      "|    policy_gradient_loss | -0.000158   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.65e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 494       |\n",
      "|    ep_rew_mean     | -3.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 516       |\n",
      "|    iterations      | 2049      |\n",
      "|    time_elapsed    | 8125      |\n",
      "|    total_timesteps | 4196352   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 508         |\n",
      "|    ep_rew_mean          | -3.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 2050        |\n",
      "|    time_elapsed         | 8127        |\n",
      "|    total_timesteps      | 4198400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016917482 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.11e+03    |\n",
      "|    n_updates            | 20490       |\n",
      "|    policy_gradient_loss | 0.00315     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 4.04e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4200000, episode_reward=-67217.30 +/- 60103.25\n",
      "Episode length: 185.00 +/- 135.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 185         |\n",
      "|    mean_reward          | -6.72e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008899922 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8e+05     |\n",
      "|    n_updates            | 20500       |\n",
      "|    policy_gradient_loss | -0.00127    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 5.21e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 513       |\n",
      "|    ep_rew_mean     | -3.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 516       |\n",
      "|    iterations      | 2051      |\n",
      "|    time_elapsed    | 8130      |\n",
      "|    total_timesteps | 4200448   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 524         |\n",
      "|    ep_rew_mean          | -2.91e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 2052        |\n",
      "|    time_elapsed         | 8131        |\n",
      "|    total_timesteps      | 4202496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008932313 |\n",
      "|    clip_fraction        | 0.0675      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.9e+07     |\n",
      "|    n_updates            | 20510       |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.97e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 523         |\n",
      "|    ep_rew_mean          | -2.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 2053        |\n",
      "|    time_elapsed         | 8133        |\n",
      "|    total_timesteps      | 4204544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009447259 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.7e+03     |\n",
      "|    n_updates            | 20520       |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 5.67e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4205000, episode_reward=-18834.24 +/- 43816.44\n",
      "Episode length: 485.40 +/- 264.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 485         |\n",
      "|    mean_reward          | -1.88e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4205000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016971223 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73e+03    |\n",
      "|    n_updates            | 20530       |\n",
      "|    policy_gradient_loss | 0.00128     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.81e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 504       |\n",
      "|    ep_rew_mean     | -2.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 516       |\n",
      "|    iterations      | 2054      |\n",
      "|    time_elapsed    | 8136      |\n",
      "|    total_timesteps | 4206592   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 500         |\n",
      "|    ep_rew_mean          | -2.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 517         |\n",
      "|    iterations           | 2055        |\n",
      "|    time_elapsed         | 8138        |\n",
      "|    total_timesteps      | 4208640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022203516 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8e+03     |\n",
      "|    n_updates            | 20540       |\n",
      "|    policy_gradient_loss | 0.00343     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.7e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4210000, episode_reward=5567.31 +/- 2420.49\n",
      "Episode length: 468.20 +/- 184.77\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 468        |\n",
      "|    mean_reward          | 5.57e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4210000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31698626 |\n",
      "|    clip_fraction        | 0.403      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.75       |\n",
      "|    explained_variance   | 0.385      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.32e+06   |\n",
      "|    n_updates            | 20550      |\n",
      "|    policy_gradient_loss | 0.0384     |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.38e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 496       |\n",
      "|    ep_rew_mean     | -2.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 517       |\n",
      "|    iterations      | 2056      |\n",
      "|    time_elapsed    | 8141      |\n",
      "|    total_timesteps | 4210688   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 495         |\n",
      "|    ep_rew_mean          | -2.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 517         |\n",
      "|    iterations           | 2057        |\n",
      "|    time_elapsed         | 8143        |\n",
      "|    total_timesteps      | 4212736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004552128 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13e+06    |\n",
      "|    n_updates            | 20560       |\n",
      "|    policy_gradient_loss | -0.00348    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.17e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 496        |\n",
      "|    ep_rew_mean          | -2.73e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 517        |\n",
      "|    iterations           | 2058       |\n",
      "|    time_elapsed         | 8145       |\n",
      "|    total_timesteps      | 4214784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01824679 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.75       |\n",
      "|    explained_variance   | 0.371      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.22e+07   |\n",
      "|    n_updates            | 20570      |\n",
      "|    policy_gradient_loss | 0.00903    |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.43e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4215000, episode_reward=-10634.96 +/- 21171.71\n",
      "Episode length: 460.40 +/- 31.08\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 460          |\n",
      "|    mean_reward          | -1.06e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4215000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033170981 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.34e+07     |\n",
      "|    n_updates            | 20580        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.43e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 498       |\n",
      "|    ep_rew_mean     | -2.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 517       |\n",
      "|    iterations      | 2059      |\n",
      "|    time_elapsed    | 8147      |\n",
      "|    total_timesteps | 4216832   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 510          |\n",
      "|    ep_rew_mean          | -2.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 517          |\n",
      "|    iterations           | 2060         |\n",
      "|    time_elapsed         | 8149         |\n",
      "|    total_timesteps      | 4218880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034903204 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.13e+05     |\n",
      "|    n_updates            | 20590        |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 7.75e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4220000, episode_reward=-8734.08 +/- 24718.44\n",
      "Episode length: 527.00 +/- 108.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 527         |\n",
      "|    mean_reward          | -8.73e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010476749 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.77e+04    |\n",
      "|    n_updates            | 20600       |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 7.61e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 505       |\n",
      "|    ep_rew_mean     | -2.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 517       |\n",
      "|    iterations      | 2061      |\n",
      "|    time_elapsed    | 8152      |\n",
      "|    total_timesteps | 4220928   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 510       |\n",
      "|    ep_rew_mean          | -2.46e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 517       |\n",
      "|    iterations           | 2062      |\n",
      "|    time_elapsed         | 8154      |\n",
      "|    total_timesteps      | 4222976   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.003933  |\n",
      "|    clip_fraction        | 0.0351    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.76      |\n",
      "|    explained_variance   | 0.437     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.17e+06  |\n",
      "|    n_updates            | 20610     |\n",
      "|    policy_gradient_loss | -0.00306  |\n",
      "|    std                  | 0.21      |\n",
      "|    value_loss           | 1.37e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4225000, episode_reward=-32934.68 +/- 49857.51\n",
      "Episode length: 359.00 +/- 150.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 359         |\n",
      "|    mean_reward          | -3.29e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4225000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009478912 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.6e+06     |\n",
      "|    n_updates            | 20620       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.65e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 514       |\n",
      "|    ep_rew_mean     | -2.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 517       |\n",
      "|    iterations      | 2063      |\n",
      "|    time_elapsed    | 8157      |\n",
      "|    total_timesteps | 4225024   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 499          |\n",
      "|    ep_rew_mean          | -2.55e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 518          |\n",
      "|    iterations           | 2064         |\n",
      "|    time_elapsed         | 8159         |\n",
      "|    total_timesteps      | 4227072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068753916 |\n",
      "|    clip_fraction        | 0.0819       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.45e+06     |\n",
      "|    n_updates            | 20630        |\n",
      "|    policy_gradient_loss | -0.00705     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 8.01e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 503         |\n",
      "|    ep_rew_mean          | -2.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 2065        |\n",
      "|    time_elapsed         | 8161        |\n",
      "|    total_timesteps      | 4229120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006022211 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+07    |\n",
      "|    n_updates            | 20640       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.29e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4230000, episode_reward=3276.27 +/- 3316.47\n",
      "Episode length: 570.80 +/- 234.14\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 571          |\n",
      "|    mean_reward          | 3.28e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4230000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043199416 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.89e+06     |\n",
      "|    n_updates            | 20650        |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.88e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 494       |\n",
      "|    ep_rew_mean     | -2.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 518       |\n",
      "|    iterations      | 2066      |\n",
      "|    time_elapsed    | 8164      |\n",
      "|    total_timesteps | 4231168   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 500          |\n",
      "|    ep_rew_mean          | -2.34e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 518          |\n",
      "|    iterations           | 2067         |\n",
      "|    time_elapsed         | 8166         |\n",
      "|    total_timesteps      | 4233216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036811768 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.1e+07      |\n",
      "|    n_updates            | 20660        |\n",
      "|    policy_gradient_loss | -0.00197     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.86e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4235000, episode_reward=691.55 +/- 12148.44\n",
      "Episode length: 425.80 +/- 73.17\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 426          |\n",
      "|    mean_reward          | 692          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4235000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065153902 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.421        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.52e+06     |\n",
      "|    n_updates            | 20670        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.89e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 502       |\n",
      "|    ep_rew_mean     | -2.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 518       |\n",
      "|    iterations      | 2068      |\n",
      "|    time_elapsed    | 8168      |\n",
      "|    total_timesteps | 4235264   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 496         |\n",
      "|    ep_rew_mean          | -2.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 2069        |\n",
      "|    time_elapsed         | 8170        |\n",
      "|    total_timesteps      | 4237312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013565574 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+05    |\n",
      "|    n_updates            | 20680       |\n",
      "|    policy_gradient_loss | 0.00233     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.25e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 493        |\n",
      "|    ep_rew_mean          | -2.33e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 518        |\n",
      "|    iterations           | 2070       |\n",
      "|    time_elapsed         | 8172       |\n",
      "|    total_timesteps      | 4239360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00627473 |\n",
      "|    clip_fraction        | 0.0737     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.75       |\n",
      "|    explained_variance   | 0.392      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.14e+07   |\n",
      "|    n_updates            | 20690      |\n",
      "|    policy_gradient_loss | 0.00081    |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.44e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4240000, episode_reward=3084.55 +/- 4930.29\n",
      "Episode length: 461.00 +/- 44.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 461          |\n",
      "|    mean_reward          | 3.08e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044921963 |\n",
      "|    clip_fraction        | 0.0434       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.23e+06     |\n",
      "|    n_updates            | 20700        |\n",
      "|    policy_gradient_loss | -0.00397     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.17e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 496       |\n",
      "|    ep_rew_mean     | -2.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 518       |\n",
      "|    iterations      | 2071      |\n",
      "|    time_elapsed    | 8175      |\n",
      "|    total_timesteps | 4241408   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 506          |\n",
      "|    ep_rew_mean          | -2.11e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 518          |\n",
      "|    iterations           | 2072         |\n",
      "|    time_elapsed         | 8177         |\n",
      "|    total_timesteps      | 4243456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040811393 |\n",
      "|    clip_fraction        | 0.0326       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.52e+06     |\n",
      "|    n_updates            | 20710        |\n",
      "|    policy_gradient_loss | -0.00311     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.76e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4245000, episode_reward=5597.02 +/- 4548.73\n",
      "Episode length: 453.40 +/- 50.93\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 453          |\n",
      "|    mean_reward          | 5.6e+03      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4245000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049812635 |\n",
      "|    clip_fraction        | 0.0486       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+07     |\n",
      "|    n_updates            | 20720        |\n",
      "|    policy_gradient_loss | -0.00662     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.74e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 499       |\n",
      "|    ep_rew_mean     | -2.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 518       |\n",
      "|    iterations      | 2073      |\n",
      "|    time_elapsed    | 8180      |\n",
      "|    total_timesteps | 4245504   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 479          |\n",
      "|    ep_rew_mean          | -2.23e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 519          |\n",
      "|    iterations           | 2074         |\n",
      "|    time_elapsed         | 8182         |\n",
      "|    total_timesteps      | 4247552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089664385 |\n",
      "|    clip_fraction        | 0.0646       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.39e+06     |\n",
      "|    n_updates            | 20730        |\n",
      "|    policy_gradient_loss | 0.0049       |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.32e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 458          |\n",
      "|    ep_rew_mean          | -2.52e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 519          |\n",
      "|    iterations           | 2075         |\n",
      "|    time_elapsed         | 8183         |\n",
      "|    total_timesteps      | 4249600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043767635 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+07     |\n",
      "|    n_updates            | 20740        |\n",
      "|    policy_gradient_loss | -0.000433    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.94e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4250000, episode_reward=2188.41 +/- 5249.60\n",
      "Episode length: 524.60 +/- 234.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 525          |\n",
      "|    mean_reward          | 2.19e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4250000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057091396 |\n",
      "|    clip_fraction        | 0.0521       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.39e+07     |\n",
      "|    n_updates            | 20750        |\n",
      "|    policy_gradient_loss | -0.00697     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.08e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 446       |\n",
      "|    ep_rew_mean     | -2.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 519       |\n",
      "|    iterations      | 2076      |\n",
      "|    time_elapsed    | 8186      |\n",
      "|    total_timesteps | 4251648   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 445         |\n",
      "|    ep_rew_mean          | -2.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 2077        |\n",
      "|    time_elapsed         | 8188        |\n",
      "|    total_timesteps      | 4253696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005403933 |\n",
      "|    clip_fraction        | 0.0367      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.88e+06    |\n",
      "|    n_updates            | 20760       |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.78e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4255000, episode_reward=-17580.74 +/- 45055.49\n",
      "Episode length: 333.80 +/- 132.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 334          |\n",
      "|    mean_reward          | -1.76e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4255000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053090514 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.5e+05      |\n",
      "|    n_updates            | 20770        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.06e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 442       |\n",
      "|    ep_rew_mean     | -2.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 519       |\n",
      "|    iterations      | 2078      |\n",
      "|    time_elapsed    | 8191      |\n",
      "|    total_timesteps | 4255744   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 440         |\n",
      "|    ep_rew_mean          | -2.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 2079        |\n",
      "|    time_elapsed         | 8193        |\n",
      "|    total_timesteps      | 4257792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006289407 |\n",
      "|    clip_fraction        | 0.0481      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+07    |\n",
      "|    n_updates            | 20780       |\n",
      "|    policy_gradient_loss | 0.00079     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.36e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 439          |\n",
      "|    ep_rew_mean          | -2.8e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 519          |\n",
      "|    iterations           | 2080         |\n",
      "|    time_elapsed         | 8195         |\n",
      "|    total_timesteps      | 4259840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027405673 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+07     |\n",
      "|    n_updates            | 20790        |\n",
      "|    policy_gradient_loss | -0.0045      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4260000, episode_reward=4620.50 +/- 4061.77\n",
      "Episode length: 398.60 +/- 41.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 399         |\n",
      "|    mean_reward          | 4.62e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008277323 |\n",
      "|    clip_fraction        | 0.0543      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.33e+07    |\n",
      "|    n_updates            | 20800       |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.05e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 428       |\n",
      "|    ep_rew_mean     | -2.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 519       |\n",
      "|    iterations      | 2081      |\n",
      "|    time_elapsed    | 8197      |\n",
      "|    total_timesteps | 4261888   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 431         |\n",
      "|    ep_rew_mean          | -2.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 2082        |\n",
      "|    time_elapsed         | 8199        |\n",
      "|    total_timesteps      | 4263936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.071135804 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.33e+06    |\n",
      "|    n_updates            | 20810       |\n",
      "|    policy_gradient_loss | 0.0124      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.56e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4265000, episode_reward=2458.25 +/- 4001.54\n",
      "Episode length: 430.80 +/- 58.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 431         |\n",
      "|    mean_reward          | 2.46e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4265000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013200921 |\n",
      "|    clip_fraction        | 0.0581      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.04e+06    |\n",
      "|    n_updates            | 20820       |\n",
      "|    policy_gradient_loss | -0.00162    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.8e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 423       |\n",
      "|    ep_rew_mean     | -2.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 2083      |\n",
      "|    time_elapsed    | 8202      |\n",
      "|    total_timesteps | 4265984   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 410          |\n",
      "|    ep_rew_mean          | -2.69e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 2084         |\n",
      "|    time_elapsed         | 8204         |\n",
      "|    total_timesteps      | 4268032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060905395 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.68         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.05e+05     |\n",
      "|    n_updates            | 20830        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.27e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4270000, episode_reward=4925.48 +/- 3290.59\n",
      "Episode length: 367.20 +/- 20.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 367         |\n",
      "|    mean_reward          | 4.93e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004499455 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.48e+05    |\n",
      "|    n_updates            | 20840       |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.77e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 408       |\n",
      "|    ep_rew_mean     | -2.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 2085      |\n",
      "|    time_elapsed    | 8206      |\n",
      "|    total_timesteps | 4270080   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 414          |\n",
      "|    ep_rew_mean          | -2.71e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 2086         |\n",
      "|    time_elapsed         | 8208         |\n",
      "|    total_timesteps      | 4272128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037133312 |\n",
      "|    clip_fraction        | 0.0145       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21e+07     |\n",
      "|    n_updates            | 20850        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.78e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 420          |\n",
      "|    ep_rew_mean          | -2.73e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 2087         |\n",
      "|    time_elapsed         | 8210         |\n",
      "|    total_timesteps      | 4274176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065623345 |\n",
      "|    clip_fraction        | 0.0388       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+07     |\n",
      "|    n_updates            | 20860        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.26e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4275000, episode_reward=6185.93 +/- 983.25\n",
      "Episode length: 370.20 +/- 16.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 370          |\n",
      "|    mean_reward          | 6.19e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4275000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067503816 |\n",
      "|    clip_fraction        | 0.0918       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.417        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.12e+06     |\n",
      "|    n_updates            | 20870        |\n",
      "|    policy_gradient_loss | -0.000252    |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.1e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 421       |\n",
      "|    ep_rew_mean     | -2.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 2088      |\n",
      "|    time_elapsed    | 8213      |\n",
      "|    total_timesteps | 4276224   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 418         |\n",
      "|    ep_rew_mean          | -2.66e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 2089        |\n",
      "|    time_elapsed         | 8215        |\n",
      "|    total_timesteps      | 4278272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011784503 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.842       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.84e+03    |\n",
      "|    n_updates            | 20880       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 8.34e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4280000, episode_reward=3653.46 +/- 4067.19\n",
      "Episode length: 403.00 +/- 46.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 403         |\n",
      "|    mean_reward          | 3.65e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002899092 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38e+04    |\n",
      "|    n_updates            | 20890       |\n",
      "|    policy_gradient_loss | 1.69e-05    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.3e+07     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 416      |\n",
      "|    ep_rew_mean     | -2.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 520      |\n",
      "|    iterations      | 2090     |\n",
      "|    time_elapsed    | 8217     |\n",
      "|    total_timesteps | 4280320  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 418          |\n",
      "|    ep_rew_mean          | -2.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 2091         |\n",
      "|    time_elapsed         | 8219         |\n",
      "|    total_timesteps      | 4282368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040834174 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.354        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.98e+06     |\n",
      "|    n_updates            | 20900        |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.98e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 418         |\n",
      "|    ep_rew_mean          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 2092        |\n",
      "|    time_elapsed         | 8221        |\n",
      "|    total_timesteps      | 4284416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010792701 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.639       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.02e+04    |\n",
      "|    n_updates            | 20910       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.82e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4285000, episode_reward=-13712.08 +/- 36138.67\n",
      "Episode length: 402.20 +/- 47.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 402         |\n",
      "|    mean_reward          | -1.37e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4285000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008517409 |\n",
      "|    clip_fraction        | 0.0551      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02e+06    |\n",
      "|    n_updates            | 20920       |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.85e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 409       |\n",
      "|    ep_rew_mean     | -2.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 2093      |\n",
      "|    time_elapsed    | 8224      |\n",
      "|    total_timesteps | 4286464   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 417          |\n",
      "|    ep_rew_mean          | -2.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 2094         |\n",
      "|    time_elapsed         | 8226         |\n",
      "|    total_timesteps      | 4288512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048129233 |\n",
      "|    clip_fraction        | 0.0263       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.33e+06     |\n",
      "|    n_updates            | 20930        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.15e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4290000, episode_reward=5608.88 +/- 2409.21\n",
      "Episode length: 379.80 +/- 5.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 380         |\n",
      "|    mean_reward          | 5.61e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003243152 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.96e+05    |\n",
      "|    n_updates            | 20940       |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.49e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 420       |\n",
      "|    ep_rew_mean     | -2.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 2095      |\n",
      "|    time_elapsed    | 8228      |\n",
      "|    total_timesteps | 4290560   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 430         |\n",
      "|    ep_rew_mean          | -2.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 2096        |\n",
      "|    time_elapsed         | 8230        |\n",
      "|    total_timesteps      | 4292608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005767243 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.24e+06    |\n",
      "|    n_updates            | 20950       |\n",
      "|    policy_gradient_loss | -0.00204    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 7.61e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 436        |\n",
      "|    ep_rew_mean          | -2.47e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 521        |\n",
      "|    iterations           | 2097       |\n",
      "|    time_elapsed         | 8232       |\n",
      "|    total_timesteps      | 4294656    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01988379 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.76       |\n",
      "|    explained_variance   | 0.475      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.12e+06   |\n",
      "|    n_updates            | 20960      |\n",
      "|    policy_gradient_loss | 0.00467    |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.47e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4295000, episode_reward=-13116.31 +/- 31713.36\n",
      "Episode length: 389.80 +/- 42.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 390          |\n",
      "|    mean_reward          | -1.31e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4295000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052713794 |\n",
      "|    clip_fraction        | 0.0503       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.414        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.89e+07     |\n",
      "|    n_updates            | 20970        |\n",
      "|    policy_gradient_loss | -0.00508     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.26e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 438       |\n",
      "|    ep_rew_mean     | -2.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 2098      |\n",
      "|    time_elapsed    | 8235      |\n",
      "|    total_timesteps | 4296704   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 440         |\n",
      "|    ep_rew_mean          | -2.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 2099        |\n",
      "|    time_elapsed         | 8237        |\n",
      "|    total_timesteps      | 4298752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017645601 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.8e+03     |\n",
      "|    n_updates            | 20980       |\n",
      "|    policy_gradient_loss | 0.0079      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.85e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4300000, episode_reward=5708.54 +/- 2270.84\n",
      "Episode length: 385.20 +/- 4.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 385         |\n",
      "|    mean_reward          | 5.71e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016492743 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.569       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+05     |\n",
      "|    n_updates            | 20990       |\n",
      "|    policy_gradient_loss | 0.00193     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.62e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 443       |\n",
      "|    ep_rew_mean     | -2.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 2100      |\n",
      "|    time_elapsed    | 8239      |\n",
      "|    total_timesteps | 4300800   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 449         |\n",
      "|    ep_rew_mean          | -2.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 2101        |\n",
      "|    time_elapsed         | 8241        |\n",
      "|    total_timesteps      | 4302848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012932785 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.08e+03    |\n",
      "|    n_updates            | 21000       |\n",
      "|    policy_gradient_loss | -0.00624    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.53e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 447          |\n",
      "|    ep_rew_mean          | -2.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 522          |\n",
      "|    iterations           | 2102         |\n",
      "|    time_elapsed         | 8243         |\n",
      "|    total_timesteps      | 4304896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045345137 |\n",
      "|    clip_fraction        | 0.0358       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.9e+06      |\n",
      "|    n_updates            | 21010        |\n",
      "|    policy_gradient_loss | -0.00566     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 6.77e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4305000, episode_reward=-4743.22 +/- 22917.90\n",
      "Episode length: 398.80 +/- 51.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 399          |\n",
      "|    mean_reward          | -4.74e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4305000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023396001 |\n",
      "|    clip_fraction        | 0.00869      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.374        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.85e+06     |\n",
      "|    n_updates            | 21020        |\n",
      "|    policy_gradient_loss | -0.00154     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.34e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 446       |\n",
      "|    ep_rew_mean     | -2.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 522       |\n",
      "|    iterations      | 2103      |\n",
      "|    time_elapsed    | 8246      |\n",
      "|    total_timesteps | 4306944   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 452          |\n",
      "|    ep_rew_mean          | -2.05e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 522          |\n",
      "|    iterations           | 2104         |\n",
      "|    time_elapsed         | 8248         |\n",
      "|    total_timesteps      | 4308992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054820306 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.58e+06     |\n",
      "|    n_updates            | 21030        |\n",
      "|    policy_gradient_loss | -0.0107      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.32e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4310000, episode_reward=-43858.14 +/- 47143.31\n",
      "Episode length: 314.60 +/- 125.46\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 315          |\n",
      "|    mean_reward          | -4.39e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4310000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036014104 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.526        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+06     |\n",
      "|    n_updates            | 21040        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 5.18e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 446       |\n",
      "|    ep_rew_mean     | -2.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 522       |\n",
      "|    iterations      | 2105      |\n",
      "|    time_elapsed    | 8250      |\n",
      "|    total_timesteps | 4311040   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 449         |\n",
      "|    ep_rew_mean          | -2.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 2106        |\n",
      "|    time_elapsed         | 8252        |\n",
      "|    total_timesteps      | 4313088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004114708 |\n",
      "|    clip_fraction        | 0.0288      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.89e+07    |\n",
      "|    n_updates            | 21050       |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.99e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4315000, episode_reward=3781.09 +/- 5244.37\n",
      "Episode length: 385.60 +/- 3.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 386         |\n",
      "|    mean_reward          | 3.78e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4315000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005478838 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14e+05    |\n",
      "|    n_updates            | 21060       |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.3e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 451       |\n",
      "|    ep_rew_mean     | -2.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 522       |\n",
      "|    iterations      | 2107      |\n",
      "|    time_elapsed    | 8255      |\n",
      "|    total_timesteps | 4315136   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 459          |\n",
      "|    ep_rew_mean          | -2.23e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 522          |\n",
      "|    iterations           | 2108         |\n",
      "|    time_elapsed         | 8257         |\n",
      "|    total_timesteps      | 4317184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072061163 |\n",
      "|    clip_fraction        | 0.0567       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.771        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.71e+04     |\n",
      "|    n_updates            | 21070        |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 8.82e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 454          |\n",
      "|    ep_rew_mean          | -2.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 522          |\n",
      "|    iterations           | 2109         |\n",
      "|    time_elapsed         | 8258         |\n",
      "|    total_timesteps      | 4319232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117790215 |\n",
      "|    clip_fraction        | 0.0869       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16e+06     |\n",
      "|    n_updates            | 21080        |\n",
      "|    policy_gradient_loss | 0.000825     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.36e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4320000, episode_reward=5325.63 +/- 1946.32\n",
      "Episode length: 383.00 +/- 6.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 383          |\n",
      "|    mean_reward          | 5.33e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040550455 |\n",
      "|    clip_fraction        | 0.0269       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.542        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.95e+04     |\n",
      "|    n_updates            | 21090        |\n",
      "|    policy_gradient_loss | -0.00237     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4e+06        |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 442      |\n",
      "|    ep_rew_mean     | -2.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 523      |\n",
      "|    iterations      | 2110     |\n",
      "|    time_elapsed    | 8261     |\n",
      "|    total_timesteps | 4321280  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 440         |\n",
      "|    ep_rew_mean          | -2.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 2111        |\n",
      "|    time_elapsed         | 8263        |\n",
      "|    total_timesteps      | 4323328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010129912 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.12e+07    |\n",
      "|    n_updates            | 21100       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.74e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4325000, episode_reward=-21622.34 +/- 35705.02\n",
      "Episode length: 419.00 +/- 68.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 419         |\n",
      "|    mean_reward          | -2.16e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4325000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008081414 |\n",
      "|    clip_fraction        | 0.0537      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73e+07    |\n",
      "|    n_updates            | 21110       |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 5.89e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 440       |\n",
      "|    ep_rew_mean     | -2.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 523       |\n",
      "|    iterations      | 2112      |\n",
      "|    time_elapsed    | 8266      |\n",
      "|    total_timesteps | 4325376   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 430          |\n",
      "|    ep_rew_mean          | -2.87e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 523          |\n",
      "|    iterations           | 2113         |\n",
      "|    time_elapsed         | 8268         |\n",
      "|    total_timesteps      | 4327424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061194724 |\n",
      "|    clip_fraction        | 0.046        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+07     |\n",
      "|    n_updates            | 21120        |\n",
      "|    policy_gradient_loss | -0.00172     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.48e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 430         |\n",
      "|    ep_rew_mean          | -2.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 2114        |\n",
      "|    time_elapsed         | 8269        |\n",
      "|    total_timesteps      | 4329472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002395858 |\n",
      "|    clip_fraction        | 0.0235      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.71e+07    |\n",
      "|    n_updates            | 21130       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.21e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4330000, episode_reward=-4544.60 +/- 18631.40\n",
      "Episode length: 377.60 +/- 16.03\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 378          |\n",
      "|    mean_reward          | -4.54e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4330000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066374363 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02e+07     |\n",
      "|    n_updates            | 21140        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.42e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 429       |\n",
      "|    ep_rew_mean     | -2.84e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 523       |\n",
      "|    iterations      | 2115      |\n",
      "|    time_elapsed    | 8272      |\n",
      "|    total_timesteps | 4331520   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 412         |\n",
      "|    ep_rew_mean          | -3.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 2116        |\n",
      "|    time_elapsed         | 8274        |\n",
      "|    total_timesteps      | 4333568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010207918 |\n",
      "|    clip_fraction        | 0.0386      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.66e+06    |\n",
      "|    n_updates            | 21150       |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 7.36e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4335000, episode_reward=909.45 +/- 6617.89\n",
      "Episode length: 379.00 +/- 41.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 379          |\n",
      "|    mean_reward          | 909          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4335000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031817448 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.57e+07     |\n",
      "|    n_updates            | 21160        |\n",
      "|    policy_gradient_loss | -0.00194     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.77e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 418       |\n",
      "|    ep_rew_mean     | -2.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 523       |\n",
      "|    iterations      | 2117      |\n",
      "|    time_elapsed    | 8277      |\n",
      "|    total_timesteps | 4335616   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 409         |\n",
      "|    ep_rew_mean          | -3.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 2118        |\n",
      "|    time_elapsed         | 8278        |\n",
      "|    total_timesteps      | 4337664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010259767 |\n",
      "|    clip_fraction        | 0.0708      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+07    |\n",
      "|    n_updates            | 21170       |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.54e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 410          |\n",
      "|    ep_rew_mean          | -3.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 524          |\n",
      "|    iterations           | 2119         |\n",
      "|    time_elapsed         | 8280         |\n",
      "|    total_timesteps      | 4339712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043576304 |\n",
      "|    clip_fraction        | 0.0561       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+07     |\n",
      "|    n_updates            | 21180        |\n",
      "|    policy_gradient_loss | 0.00152      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.05e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4340000, episode_reward=-15058.22 +/- 42668.79\n",
      "Episode length: 291.80 +/- 113.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 292         |\n",
      "|    mean_reward          | -1.51e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008810436 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.611       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38e+04    |\n",
      "|    n_updates            | 21190       |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.04e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 410       |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 524       |\n",
      "|    iterations      | 2120      |\n",
      "|    time_elapsed    | 8283      |\n",
      "|    total_timesteps | 4341760   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 404          |\n",
      "|    ep_rew_mean          | -3.25e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 524          |\n",
      "|    iterations           | 2121         |\n",
      "|    time_elapsed         | 8285         |\n",
      "|    total_timesteps      | 4343808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055773323 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+07     |\n",
      "|    n_updates            | 21200        |\n",
      "|    policy_gradient_loss | 0.00153      |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.87e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4345000, episode_reward=-18682.68 +/- 44830.03\n",
      "Episode length: 385.40 +/- 184.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 385         |\n",
      "|    mean_reward          | -1.87e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4345000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006708862 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.78e+06    |\n",
      "|    n_updates            | 21210       |\n",
      "|    policy_gradient_loss | -0.00131    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.32e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 409       |\n",
      "|    ep_rew_mean     | -3.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 524       |\n",
      "|    iterations      | 2122      |\n",
      "|    time_elapsed    | 8287      |\n",
      "|    total_timesteps | 4345856   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 419         |\n",
      "|    ep_rew_mean          | -3.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 2123        |\n",
      "|    time_elapsed         | 8289        |\n",
      "|    total_timesteps      | 4347904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005923479 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.476       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.5e+06     |\n",
      "|    n_updates            | 21220       |\n",
      "|    policy_gradient_loss | -0.00406    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 9.47e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 414        |\n",
      "|    ep_rew_mean          | -3.21e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 524        |\n",
      "|    iterations           | 2124       |\n",
      "|    time_elapsed         | 8291       |\n",
      "|    total_timesteps      | 4349952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01866231 |\n",
      "|    clip_fraction        | 0.0854     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.75       |\n",
      "|    explained_variance   | 0.912      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.04e+05   |\n",
      "|    n_updates            | 21230      |\n",
      "|    policy_gradient_loss | -0.00244   |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 2.71e+05   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4350000, episode_reward=-16824.24 +/- 43730.08\n",
      "Episode length: 351.00 +/- 168.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 351         |\n",
      "|    mean_reward          | -1.68e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009604875 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.484       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+06    |\n",
      "|    n_updates            | 21240       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.57e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 422       |\n",
      "|    ep_rew_mean     | -3.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 524       |\n",
      "|    iterations      | 2125      |\n",
      "|    time_elapsed    | 8294      |\n",
      "|    total_timesteps | 4352000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 430         |\n",
      "|    ep_rew_mean          | -2.84e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 2126        |\n",
      "|    time_elapsed         | 8296        |\n",
      "|    total_timesteps      | 4354048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027560426 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+06    |\n",
      "|    n_updates            | 21250       |\n",
      "|    policy_gradient_loss | -0.000953   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 9.78e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4355000, episode_reward=5752.88 +/- 1493.93\n",
      "Episode length: 364.00 +/- 15.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 364          |\n",
      "|    mean_reward          | 5.75e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4355000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069496837 |\n",
      "|    clip_fraction        | 0.0681       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.29e+03     |\n",
      "|    n_updates            | 21260        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 5.01e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 426       |\n",
      "|    ep_rew_mean     | -2.93e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 524       |\n",
      "|    iterations      | 2127      |\n",
      "|    time_elapsed    | 8298      |\n",
      "|    total_timesteps | 4356096   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 418          |\n",
      "|    ep_rew_mean          | -2.89e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 2128         |\n",
      "|    time_elapsed         | 8300         |\n",
      "|    total_timesteps      | 4358144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061427685 |\n",
      "|    clip_fraction        | 0.0685       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79e+07     |\n",
      "|    n_updates            | 21270        |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 4.15e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4360000, episode_reward=-36530.46 +/- 52891.30\n",
      "Episode length: 248.80 +/- 149.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 249         |\n",
      "|    mean_reward          | -3.65e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005233634 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.671       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.55e+03    |\n",
      "|    n_updates            | 21280       |\n",
      "|    policy_gradient_loss | -0.000756   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 7.76e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 425       |\n",
      "|    ep_rew_mean     | -2.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 525       |\n",
      "|    iterations      | 2129      |\n",
      "|    time_elapsed    | 8303      |\n",
      "|    total_timesteps | 4360192   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 433         |\n",
      "|    ep_rew_mean          | -2.66e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 2130        |\n",
      "|    time_elapsed         | 8304        |\n",
      "|    total_timesteps      | 4362240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012384102 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.98e+03    |\n",
      "|    n_updates            | 21290       |\n",
      "|    policy_gradient_loss | -0.00165    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 7.58e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 438         |\n",
      "|    ep_rew_mean          | -2.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 2131        |\n",
      "|    time_elapsed         | 8306        |\n",
      "|    total_timesteps      | 4364288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017673973 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 879         |\n",
      "|    n_updates            | 21300       |\n",
      "|    policy_gradient_loss | 0.000174    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.68e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4365000, episode_reward=4194.11 +/- 2844.96\n",
      "Episode length: 362.40 +/- 21.04\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 362        |\n",
      "|    mean_reward          | 4.19e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4365000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01011426 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.76       |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.57e+07   |\n",
      "|    n_updates            | 21310      |\n",
      "|    policy_gradient_loss | 0.00182    |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.37e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 437       |\n",
      "|    ep_rew_mean     | -2.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 525       |\n",
      "|    iterations      | 2132      |\n",
      "|    time_elapsed    | 8309      |\n",
      "|    total_timesteps | 4366336   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 456          |\n",
      "|    ep_rew_mean          | -2.56e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 525          |\n",
      "|    iterations           | 2133         |\n",
      "|    time_elapsed         | 8311         |\n",
      "|    total_timesteps      | 4368384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078049144 |\n",
      "|    clip_fraction        | 0.0387       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.587        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.23e+06     |\n",
      "|    n_updates            | 21320        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 3.29e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4370000, episode_reward=-16620.25 +/- 40167.42\n",
      "Episode length: 397.60 +/- 241.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 398         |\n",
      "|    mean_reward          | -1.66e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005168779 |\n",
      "|    clip_fraction        | 0.0412      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.07e+06    |\n",
      "|    n_updates            | 21330       |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.5e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 466       |\n",
      "|    ep_rew_mean     | -2.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 525       |\n",
      "|    iterations      | 2134      |\n",
      "|    time_elapsed    | 8314      |\n",
      "|    total_timesteps | 4370432   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 470         |\n",
      "|    ep_rew_mean          | -2.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 2135        |\n",
      "|    time_elapsed         | 8315        |\n",
      "|    total_timesteps      | 4372480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009659166 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+07    |\n",
      "|    n_updates            | 21340       |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.14e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 477         |\n",
      "|    ep_rew_mean          | -2.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 2136        |\n",
      "|    time_elapsed         | 8317        |\n",
      "|    total_timesteps      | 4374528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009189471 |\n",
      "|    clip_fraction        | 0.0748      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13e+07    |\n",
      "|    n_updates            | 21350       |\n",
      "|    policy_gradient_loss | -0.00255    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.18e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4375000, episode_reward=-1193.38 +/- 10462.61\n",
      "Episode length: 465.60 +/- 230.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 466         |\n",
      "|    mean_reward          | -1.19e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4375000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014127801 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.58e+03    |\n",
      "|    n_updates            | 21360       |\n",
      "|    policy_gradient_loss | 0.0059      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 9.42e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 487       |\n",
      "|    ep_rew_mean     | -2.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 525       |\n",
      "|    iterations      | 2137      |\n",
      "|    time_elapsed    | 8320      |\n",
      "|    total_timesteps | 4376576   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 497         |\n",
      "|    ep_rew_mean          | -2.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 2138        |\n",
      "|    time_elapsed         | 8322        |\n",
      "|    total_timesteps      | 4378624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011250032 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.635       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55e+04    |\n",
      "|    n_updates            | 21370       |\n",
      "|    policy_gradient_loss | 0.000942    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.62e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4380000, episode_reward=-45217.68 +/- 41138.53\n",
      "Episode length: 377.20 +/- 88.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 377         |\n",
      "|    mean_reward          | -4.52e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007207243 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.02e+06    |\n",
      "|    n_updates            | 21380       |\n",
      "|    policy_gradient_loss | -0.000823   |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.44e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 491       |\n",
      "|    ep_rew_mean     | -2.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 526       |\n",
      "|    iterations      | 2139      |\n",
      "|    time_elapsed    | 8325      |\n",
      "|    total_timesteps | 4380672   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 496          |\n",
      "|    ep_rew_mean          | -2e+04       |\n",
      "| time/                   |              |\n",
      "|    fps                  | 526          |\n",
      "|    iterations           | 2140         |\n",
      "|    time_elapsed         | 8327         |\n",
      "|    total_timesteps      | 4382720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068468032 |\n",
      "|    clip_fraction        | 0.03         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.73e+06     |\n",
      "|    n_updates            | 21390        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 1.4e+07      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 499         |\n",
      "|    ep_rew_mean          | -2e+04      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 2141        |\n",
      "|    time_elapsed         | 8328        |\n",
      "|    total_timesteps      | 4384768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005003428 |\n",
      "|    clip_fraction        | 0.0383      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.14e+06    |\n",
      "|    n_updates            | 21400       |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.7e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4385000, episode_reward=-48196.48 +/- 47725.61\n",
      "Episode length: 311.80 +/- 219.08\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 312          |\n",
      "|    mean_reward          | -4.82e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4385000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041307537 |\n",
      "|    clip_fraction        | 0.0223       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+07     |\n",
      "|    n_updates            | 21410        |\n",
      "|    policy_gradient_loss | -0.00271     |\n",
      "|    std                  | 0.21         |\n",
      "|    value_loss           | 2.19e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 499       |\n",
      "|    ep_rew_mean     | -1.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 526       |\n",
      "|    iterations      | 2142      |\n",
      "|    time_elapsed    | 8331      |\n",
      "|    total_timesteps | 4386816   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 502         |\n",
      "|    ep_rew_mean          | -2.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 2143        |\n",
      "|    time_elapsed         | 8333        |\n",
      "|    total_timesteps      | 4388864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.072805665 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.01e+06    |\n",
      "|    n_updates            | 21420       |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.14e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4390000, episode_reward=4704.53 +/- 2329.13\n",
      "Episode length: 435.40 +/- 74.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 435         |\n",
      "|    mean_reward          | 4.7e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010121448 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.88e+06    |\n",
      "|    n_updates            | 21430       |\n",
      "|    policy_gradient_loss | 0.000687    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.41e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 515       |\n",
      "|    ep_rew_mean     | -2.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 526       |\n",
      "|    iterations      | 2144      |\n",
      "|    time_elapsed    | 8336      |\n",
      "|    total_timesteps | 4390912   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 515        |\n",
      "|    ep_rew_mean          | -2.12e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 526        |\n",
      "|    iterations           | 2145       |\n",
      "|    time_elapsed         | 8337       |\n",
      "|    total_timesteps      | 4392960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04382529 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.76       |\n",
      "|    explained_variance   | 0.319      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.28e+06   |\n",
      "|    n_updates            | 21440      |\n",
      "|    policy_gradient_loss | -0.000224  |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 1.58e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4395000, episode_reward=-42279.90 +/- 47487.28\n",
      "Episode length: 323.00 +/- 221.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 323         |\n",
      "|    mean_reward          | -4.23e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4395000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013726776 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+03    |\n",
      "|    n_updates            | 21450       |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 8.15e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 530       |\n",
      "|    ep_rew_mean     | -2.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 526       |\n",
      "|    iterations      | 2146      |\n",
      "|    time_elapsed    | 8340      |\n",
      "|    total_timesteps | 4395008   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 542         |\n",
      "|    ep_rew_mean          | -2.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 2147        |\n",
      "|    time_elapsed         | 8342        |\n",
      "|    total_timesteps      | 4397056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002335553 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.78e+07    |\n",
      "|    n_updates            | 21460       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.16e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 551         |\n",
      "|    ep_rew_mean          | -2.27e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 2148        |\n",
      "|    time_elapsed         | 8344        |\n",
      "|    total_timesteps      | 4399104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009643884 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.39e+07    |\n",
      "|    n_updates            | 21470       |\n",
      "|    policy_gradient_loss | 0.000716    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.74e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4400000, episode_reward=-33385.54 +/- 50054.86\n",
      "Episode length: 308.40 +/- 214.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 308         |\n",
      "|    mean_reward          | -3.34e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005916314 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.98e+04    |\n",
      "|    n_updates            | 21480       |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.9e+05     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 562       |\n",
      "|    ep_rew_mean     | -2.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 527       |\n",
      "|    iterations      | 2149      |\n",
      "|    time_elapsed    | 8346      |\n",
      "|    total_timesteps | 4401152   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 562        |\n",
      "|    ep_rew_mean          | -2.29e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 527        |\n",
      "|    iterations           | 2150       |\n",
      "|    time_elapsed         | 8348       |\n",
      "|    total_timesteps      | 4403200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02588015 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.76       |\n",
      "|    explained_variance   | 0.924      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.17e+05   |\n",
      "|    n_updates            | 21490      |\n",
      "|    policy_gradient_loss | 0.0225     |\n",
      "|    std                  | 0.21       |\n",
      "|    value_loss           | 7.26e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4405000, episode_reward=-24230.48 +/- 40640.57\n",
      "Episode length: 330.40 +/- 159.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 330         |\n",
      "|    mean_reward          | -2.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4405000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014465302 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 21500       |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 6.03e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 569       |\n",
      "|    ep_rew_mean     | -2.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 527       |\n",
      "|    iterations      | 2151      |\n",
      "|    time_elapsed    | 8351      |\n",
      "|    total_timesteps | 4405248   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 567         |\n",
      "|    ep_rew_mean          | -2.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 2152        |\n",
      "|    time_elapsed         | 8353        |\n",
      "|    total_timesteps      | 4407296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004852968 |\n",
      "|    clip_fraction        | 0.0338      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32e+07    |\n",
      "|    n_updates            | 21510       |\n",
      "|    policy_gradient_loss | -0.00586    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.41e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 552         |\n",
      "|    ep_rew_mean          | -2.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 2153        |\n",
      "|    time_elapsed         | 8354        |\n",
      "|    total_timesteps      | 4409344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005474001 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.36e+07    |\n",
      "|    n_updates            | 21520       |\n",
      "|    policy_gradient_loss | -0.00387    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 4.32e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4410000, episode_reward=-1204.75 +/- 7022.22\n",
      "Episode length: 365.80 +/- 29.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 366         |\n",
      "|    mean_reward          | -1.2e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005871715 |\n",
      "|    clip_fraction        | 0.0356      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+07    |\n",
      "|    n_updates            | 21530       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.78e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 560       |\n",
      "|    ep_rew_mean     | -2.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 527       |\n",
      "|    iterations      | 2154      |\n",
      "|    time_elapsed    | 8357      |\n",
      "|    total_timesteps | 4411392   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 560         |\n",
      "|    ep_rew_mean          | -2.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 2155        |\n",
      "|    time_elapsed         | 8359        |\n",
      "|    total_timesteps      | 4413440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009534217 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.03e+04    |\n",
      "|    n_updates            | 21540       |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 3.78e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4415000, episode_reward=-39121.95 +/- 45808.21\n",
      "Episode length: 234.80 +/- 143.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 235         |\n",
      "|    mean_reward          | -3.91e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4415000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030470274 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 21550       |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 6.62e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 596      |\n",
      "|    ep_rew_mean     | -2.7e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 528      |\n",
      "|    iterations      | 2156     |\n",
      "|    time_elapsed    | 8361     |\n",
      "|    total_timesteps | 4415488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 590         |\n",
      "|    ep_rew_mean          | -2.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 2157        |\n",
      "|    time_elapsed         | 8363        |\n",
      "|    total_timesteps      | 4417536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006882822 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05e+03    |\n",
      "|    n_updates            | 21560       |\n",
      "|    policy_gradient_loss | 0.000883    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 3.91e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 572       |\n",
      "|    ep_rew_mean          | -2.89e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 528       |\n",
      "|    iterations           | 2158      |\n",
      "|    time_elapsed         | 8365      |\n",
      "|    total_timesteps      | 4419584   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0123489 |\n",
      "|    clip_fraction        | 0.0766    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.77      |\n",
      "|    explained_variance   | 0.414     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.23e+07  |\n",
      "|    n_updates            | 21570     |\n",
      "|    policy_gradient_loss | -0.00581  |\n",
      "|    std                  | 0.209     |\n",
      "|    value_loss           | 1.83e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4420000, episode_reward=-12666.52 +/- 30163.67\n",
      "Episode length: 380.00 +/- 71.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 380         |\n",
      "|    mean_reward          | -1.27e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008749675 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.77e+06    |\n",
      "|    n_updates            | 21580       |\n",
      "|    policy_gradient_loss | -0.00416    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.23e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 576       |\n",
      "|    ep_rew_mean     | -3.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 528       |\n",
      "|    iterations      | 2159      |\n",
      "|    time_elapsed    | 8368      |\n",
      "|    total_timesteps | 4421632   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 554         |\n",
      "|    ep_rew_mean          | -3.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 2160        |\n",
      "|    time_elapsed         | 8370        |\n",
      "|    total_timesteps      | 4423680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010345028 |\n",
      "|    clip_fraction        | 0.0716      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+07    |\n",
      "|    n_updates            | 21590       |\n",
      "|    policy_gradient_loss | -0.000849   |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.13e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4425000, episode_reward=-17450.43 +/- 40240.23\n",
      "Episode length: 331.20 +/- 147.99\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 331          |\n",
      "|    mean_reward          | -1.75e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4425000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049640504 |\n",
      "|    clip_fraction        | 0.0541       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.55e+07     |\n",
      "|    n_updates            | 21600        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 4.86e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 541       |\n",
      "|    ep_rew_mean     | -3.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 528       |\n",
      "|    iterations      | 2161      |\n",
      "|    time_elapsed    | 8372      |\n",
      "|    total_timesteps | 4425728   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 538         |\n",
      "|    ep_rew_mean          | -3.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 2162        |\n",
      "|    time_elapsed         | 8374        |\n",
      "|    total_timesteps      | 4427776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009600275 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.05e+03    |\n",
      "|    n_updates            | 21610       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 4.4e+04     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 520       |\n",
      "|    ep_rew_mean          | -3.22e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 528       |\n",
      "|    iterations           | 2163      |\n",
      "|    time_elapsed         | 8376      |\n",
      "|    total_timesteps      | 4429824   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0083765 |\n",
      "|    clip_fraction        | 0.0683    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.76      |\n",
      "|    explained_variance   | 0.431     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.2e+06   |\n",
      "|    n_updates            | 21620     |\n",
      "|    policy_gradient_loss | -0.00395  |\n",
      "|    std                  | 0.209     |\n",
      "|    value_loss           | 1.44e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4430000, episode_reward=-21168.38 +/- 31328.02\n",
      "Episode length: 526.20 +/- 474.14\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 526       |\n",
      "|    mean_reward          | -2.12e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4430000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2957704 |\n",
      "|    clip_fraction        | 0.258     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.76      |\n",
      "|    explained_variance   | 0.41      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.39e+06  |\n",
      "|    n_updates            | 21630     |\n",
      "|    policy_gradient_loss | 0.0117    |\n",
      "|    std                  | 0.209     |\n",
      "|    value_loss           | 1.14e+07  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 533       |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 528       |\n",
      "|    iterations      | 2164      |\n",
      "|    time_elapsed    | 8379      |\n",
      "|    total_timesteps | 4431872   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 551         |\n",
      "|    ep_rew_mean          | -3.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 2165        |\n",
      "|    time_elapsed         | 8381        |\n",
      "|    total_timesteps      | 4433920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017180763 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.19e+03    |\n",
      "|    n_updates            | 21640       |\n",
      "|    policy_gradient_loss | 0.00593     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.75e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4435000, episode_reward=-20423.77 +/- 34053.39\n",
      "Episode length: 597.60 +/- 670.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 598          |\n",
      "|    mean_reward          | -2.04e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4435000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029986042 |\n",
      "|    clip_fraction        | 0.0763       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.99e+06     |\n",
      "|    n_updates            | 21650        |\n",
      "|    policy_gradient_loss | 9.98e-05     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.35e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 540      |\n",
      "|    ep_rew_mean     | -3.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 529      |\n",
      "|    iterations      | 2166     |\n",
      "|    time_elapsed    | 8384     |\n",
      "|    total_timesteps | 4435968  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 545          |\n",
      "|    ep_rew_mean          | -3.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 529          |\n",
      "|    iterations           | 2167         |\n",
      "|    time_elapsed         | 8386         |\n",
      "|    total_timesteps      | 4438016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062676184 |\n",
      "|    clip_fraction        | 0.0473       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+07     |\n",
      "|    n_updates            | 21660        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 4.03e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4440000, episode_reward=-49259.94 +/- 34162.79\n",
      "Episode length: 1019.40 +/- 1074.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | -4.93e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013298791 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.421       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.09e+06    |\n",
      "|    n_updates            | 21670       |\n",
      "|    policy_gradient_loss | 0.000764    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 3.64e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 522      |\n",
      "|    ep_rew_mean     | -3.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 529      |\n",
      "|    iterations      | 2168     |\n",
      "|    time_elapsed    | 8390     |\n",
      "|    total_timesteps | 4440064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 510         |\n",
      "|    ep_rew_mean          | -3.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 2169        |\n",
      "|    time_elapsed         | 8392        |\n",
      "|    total_timesteps      | 4442112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005204983 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.56e+07    |\n",
      "|    n_updates            | 21680       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 4.98e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 507          |\n",
      "|    ep_rew_mean          | -3.58e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 529          |\n",
      "|    iterations           | 2170         |\n",
      "|    time_elapsed         | 8394         |\n",
      "|    total_timesteps      | 4444160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034994693 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.48e+06     |\n",
      "|    n_updates            | 21690        |\n",
      "|    policy_gradient_loss | 4.63e-05     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 8.92e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4445000, episode_reward=-36378.98 +/- 45115.32\n",
      "Episode length: 1214.40 +/- 1318.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.21e+03    |\n",
      "|    mean_reward          | -3.64e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4445000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011216965 |\n",
      "|    clip_fraction        | 0.0764      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.23e+06    |\n",
      "|    n_updates            | 21700       |\n",
      "|    policy_gradient_loss | -0.0012     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 5.7e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 510       |\n",
      "|    ep_rew_mean     | -3.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2171      |\n",
      "|    time_elapsed    | 8398      |\n",
      "|    total_timesteps | 4446208   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 2172        |\n",
      "|    time_elapsed         | 8400        |\n",
      "|    total_timesteps      | 4448256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005823753 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.41e+06    |\n",
      "|    n_updates            | 21710       |\n",
      "|    policy_gradient_loss | -0.0016     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 7.66e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4450000, episode_reward=23971.77 +/- 14424.09\n",
      "Episode length: 2529.60 +/- 1767.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.53e+03    |\n",
      "|    mean_reward          | 2.4e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024665248 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+07    |\n",
      "|    n_updates            | 21720       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 8.57e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 537       |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2173      |\n",
      "|    time_elapsed    | 8408      |\n",
      "|    total_timesteps | 4450304   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 537         |\n",
      "|    ep_rew_mean          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 2174        |\n",
      "|    time_elapsed         | 8410        |\n",
      "|    total_timesteps      | 4452352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009681713 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.57e+03    |\n",
      "|    n_updates            | 21730       |\n",
      "|    policy_gradient_loss | -0.000757   |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 6.84e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 559         |\n",
      "|    ep_rew_mean          | -3.43e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 2175        |\n",
      "|    time_elapsed         | 8411        |\n",
      "|    total_timesteps      | 4454400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013518872 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 567         |\n",
      "|    n_updates            | 21740       |\n",
      "|    policy_gradient_loss | 0.00653     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4455000, episode_reward=-26722.25 +/- 50458.59\n",
      "Episode length: 1642.40 +/- 1762.25\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.64e+03   |\n",
      "|    mean_reward          | -2.67e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4455000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08778316 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.441      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.31e+05   |\n",
      "|    n_updates            | 21750      |\n",
      "|    policy_gradient_loss | 0.00816    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 7.05e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 519       |\n",
      "|    ep_rew_mean     | -3.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2176      |\n",
      "|    time_elapsed    | 8417      |\n",
      "|    total_timesteps | 4456448   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 517         |\n",
      "|    ep_rew_mean          | -3.43e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 2177        |\n",
      "|    time_elapsed         | 8419        |\n",
      "|    total_timesteps      | 4458496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009081868 |\n",
      "|    clip_fraction        | 0.0431      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05e+07    |\n",
      "|    n_updates            | 21760       |\n",
      "|    policy_gradient_loss | -0.00243    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.32e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4460000, episode_reward=-58858.13 +/- 44670.77\n",
      "Episode length: 765.40 +/- 1423.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 765         |\n",
      "|    mean_reward          | -5.89e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003956939 |\n",
      "|    clip_fraction        | 0.0265      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.58e+07    |\n",
      "|    n_updates            | 21770       |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 3.74e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 532       |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2178      |\n",
      "|    time_elapsed    | 8423      |\n",
      "|    total_timesteps | 4460544   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 535          |\n",
      "|    ep_rew_mean          | -3.23e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 529          |\n",
      "|    iterations           | 2179         |\n",
      "|    time_elapsed         | 8424         |\n",
      "|    total_timesteps      | 4462592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0084907785 |\n",
      "|    clip_fraction        | 0.0655       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.736        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.45e+03     |\n",
      "|    n_updates            | 21780        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 4e+04        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 558         |\n",
      "|    ep_rew_mean          | -3.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 2180        |\n",
      "|    time_elapsed         | 8426        |\n",
      "|    total_timesteps      | 4464640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.070240214 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.83e+06    |\n",
      "|    n_updates            | 21790       |\n",
      "|    policy_gradient_loss | 0.00161     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.19e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4465000, episode_reward=-21144.70 +/- 48544.59\n",
      "Episode length: 1579.80 +/- 1247.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.58e+03    |\n",
      "|    mean_reward          | -2.11e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4465000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016090471 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.08e+03    |\n",
      "|    n_updates            | 21800       |\n",
      "|    policy_gradient_loss | -0.000228   |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.31e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 584       |\n",
      "|    ep_rew_mean     | -3.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2181      |\n",
      "|    time_elapsed    | 8432      |\n",
      "|    total_timesteps | 4466688   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 584          |\n",
      "|    ep_rew_mean          | -3.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 529          |\n",
      "|    iterations           | 2182         |\n",
      "|    time_elapsed         | 8434         |\n",
      "|    total_timesteps      | 4468736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030398944 |\n",
      "|    clip_fraction        | 0.0585       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.212        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.77e+06     |\n",
      "|    n_updates            | 21810        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.52e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4470000, episode_reward=-19937.57 +/- 49707.65\n",
      "Episode length: 1573.20 +/- 1244.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.57e+03    |\n",
      "|    mean_reward          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050649554 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.518       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 898         |\n",
      "|    n_updates            | 21820       |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 3.32e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 605       |\n",
      "|    ep_rew_mean     | -3.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2183      |\n",
      "|    time_elapsed    | 8439      |\n",
      "|    total_timesteps | 4470784   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 618          |\n",
      "|    ep_rew_mean          | -3.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 529          |\n",
      "|    iterations           | 2184         |\n",
      "|    time_elapsed         | 8441         |\n",
      "|    total_timesteps      | 4472832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077873557 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.32e+06     |\n",
      "|    n_updates            | 21830        |\n",
      "|    policy_gradient_loss | 0.00619      |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.51e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 635          |\n",
      "|    ep_rew_mean          | -3.25e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 529          |\n",
      "|    iterations           | 2185         |\n",
      "|    time_elapsed         | 8443         |\n",
      "|    total_timesteps      | 4474880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056676324 |\n",
      "|    clip_fraction        | 0.081        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.43e+06     |\n",
      "|    n_updates            | 21840        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.02e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4475000, episode_reward=-16486.44 +/- 48735.23\n",
      "Episode length: 1569.00 +/- 1240.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.57e+03    |\n",
      "|    mean_reward          | -1.65e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4475000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015997067 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.09e+04    |\n",
      "|    n_updates            | 21850       |\n",
      "|    policy_gradient_loss | -4.54e-05   |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.85e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 647       |\n",
      "|    ep_rew_mean     | -3.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2186      |\n",
      "|    time_elapsed    | 8449      |\n",
      "|    total_timesteps | 4476928   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 625        |\n",
      "|    ep_rew_mean          | -3.45e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 530        |\n",
      "|    iterations           | 2187       |\n",
      "|    time_elapsed         | 8450       |\n",
      "|    total_timesteps      | 4478976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12922776 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.543      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.68e+06   |\n",
      "|    n_updates            | 21860      |\n",
      "|    policy_gradient_loss | 0.00753    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 6.78e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4480000, episode_reward=17022.96 +/- 5782.08\n",
      "Episode length: 2332.60 +/- 563.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.33e+03    |\n",
      "|    mean_reward          | 1.7e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010891305 |\n",
      "|    clip_fraction        | 0.083       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.66e+06    |\n",
      "|    n_updates            | 21870       |\n",
      "|    policy_gradient_loss | -0.0063     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.01e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 649       |\n",
      "|    ep_rew_mean     | -3.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2188      |\n",
      "|    time_elapsed    | 8458      |\n",
      "|    total_timesteps | 4481024   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 649         |\n",
      "|    ep_rew_mean          | -3.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 2189        |\n",
      "|    time_elapsed         | 8460        |\n",
      "|    total_timesteps      | 4483072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006262587 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02e+03    |\n",
      "|    n_updates            | 21880       |\n",
      "|    policy_gradient_loss | -0.000682   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.81e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4485000, episode_reward=-57063.74 +/- 38739.21\n",
      "Episode length: 598.80 +/- 1095.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 599         |\n",
      "|    mean_reward          | -5.71e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4485000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011918796 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 21890       |\n",
      "|    policy_gradient_loss | 0.000498    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 2.91e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 676       |\n",
      "|    ep_rew_mean     | -3.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2190      |\n",
      "|    time_elapsed    | 8463      |\n",
      "|    total_timesteps | 4485120   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 691          |\n",
      "|    ep_rew_mean          | -3.4e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 2191         |\n",
      "|    time_elapsed         | 8465         |\n",
      "|    total_timesteps      | 4487168      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042180405 |\n",
      "|    clip_fraction        | 0.0636       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.53e+03     |\n",
      "|    n_updates            | 21900        |\n",
      "|    policy_gradient_loss | -0.00239     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 3.66e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 705        |\n",
      "|    ep_rew_mean          | -3.38e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 530        |\n",
      "|    iterations           | 2192       |\n",
      "|    time_elapsed         | 8467       |\n",
      "|    total_timesteps      | 4489216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02187196 |\n",
      "|    clip_fraction        | 0.115      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.78       |\n",
      "|    explained_variance   | 0.486      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.17e+07   |\n",
      "|    n_updates            | 21910      |\n",
      "|    policy_gradient_loss | 0.00078    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 1.3e+07    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4490000, episode_reward=18387.37 +/- 1143.97\n",
      "Episode length: 2697.60 +/- 50.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.7e+03     |\n",
      "|    mean_reward          | 1.84e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014036683 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.85e+05    |\n",
      "|    n_updates            | 21920       |\n",
      "|    policy_gradient_loss | 0.0015      |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.27e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 708      |\n",
      "|    ep_rew_mean     | -3.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 529      |\n",
      "|    iterations      | 2193     |\n",
      "|    time_elapsed    | 8475     |\n",
      "|    total_timesteps | 4491264  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 720          |\n",
      "|    ep_rew_mean          | -3.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 2194         |\n",
      "|    time_elapsed         | 8477         |\n",
      "|    total_timesteps      | 4493312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043829577 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.68e+06     |\n",
      "|    n_updates            | 21930        |\n",
      "|    policy_gradient_loss | -0.000201    |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.1e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4495000, episode_reward=-20393.03 +/- 46304.66\n",
      "Episode length: 1686.20 +/- 1335.82\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.69e+03     |\n",
      "|    mean_reward          | -2.04e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4495000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046716016 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.407        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.84e+06     |\n",
      "|    n_updates            | 21940        |\n",
      "|    policy_gradient_loss | -0.000974    |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.61e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 718       |\n",
      "|    ep_rew_mean     | -3.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2195      |\n",
      "|    time_elapsed    | 8482      |\n",
      "|    total_timesteps | 4495360   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 736         |\n",
      "|    ep_rew_mean          | -3.61e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 2196        |\n",
      "|    time_elapsed         | 8484        |\n",
      "|    total_timesteps      | 4497408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007546705 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+06    |\n",
      "|    n_updates            | 21950       |\n",
      "|    policy_gradient_loss | 0.00931     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 5.9e+06     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 758          |\n",
      "|    ep_rew_mean          | -3.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 2197         |\n",
      "|    time_elapsed         | 8486         |\n",
      "|    total_timesteps      | 4499456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046977326 |\n",
      "|    clip_fraction        | 0.0488       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.87e+05     |\n",
      "|    n_updates            | 21960        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.13e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4500000, episode_reward=-1235.14 +/- 37829.64\n",
      "Episode length: 1994.00 +/- 970.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.99e+03    |\n",
      "|    mean_reward          | -1.24e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002809953 |\n",
      "|    clip_fraction        | 0.011       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.53e+06    |\n",
      "|    n_updates            | 21970       |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 8.69e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 775       |\n",
      "|    ep_rew_mean     | -3.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 2198      |\n",
      "|    time_elapsed    | 8493      |\n",
      "|    total_timesteps | 4501504   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 793        |\n",
      "|    ep_rew_mean          | -3.46e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 530        |\n",
      "|    iterations           | 2199       |\n",
      "|    time_elapsed         | 8494       |\n",
      "|    total_timesteps      | 4503552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14241225 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.79       |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.97e+06   |\n",
      "|    n_updates            | 21980      |\n",
      "|    policy_gradient_loss | 0.0104     |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 9.94e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4505000, episode_reward=18998.85 +/- 544.62\n",
      "Episode length: 2374.60 +/- 51.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.37e+03    |\n",
      "|    mean_reward          | 1.9e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4505000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004633149 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.56e+06    |\n",
      "|    n_updates            | 21990       |\n",
      "|    policy_gradient_loss | -0.00459    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2e+07       |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 801       |\n",
      "|    ep_rew_mean     | -3.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2200      |\n",
      "|    time_elapsed    | 8502      |\n",
      "|    total_timesteps | 4505600   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 801         |\n",
      "|    ep_rew_mean          | -3.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 2201        |\n",
      "|    time_elapsed         | 8504        |\n",
      "|    total_timesteps      | 4507648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002658728 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.08e+05    |\n",
      "|    n_updates            | 22000       |\n",
      "|    policy_gradient_loss | 0.00166     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 9.35e+06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 817          |\n",
      "|    ep_rew_mean          | -3.51e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 2202         |\n",
      "|    time_elapsed         | 8506         |\n",
      "|    total_timesteps      | 4509696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091868965 |\n",
      "|    clip_fraction        | 0.0628       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.27e+03     |\n",
      "|    n_updates            | 22010        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.52e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4510000, episode_reward=-5241.47 +/- 14899.22\n",
      "Episode length: 2275.60 +/- 81.92\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.28e+03     |\n",
      "|    mean_reward          | -5.24e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4510000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074170534 |\n",
      "|    clip_fraction        | 0.0564       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.63e+03     |\n",
      "|    n_updates            | 22020        |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.95e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 830       |\n",
      "|    ep_rew_mean     | -3.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 2203      |\n",
      "|    time_elapsed    | 8513      |\n",
      "|    total_timesteps | 4511744   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 839        |\n",
      "|    ep_rew_mean          | -3.63e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 530        |\n",
      "|    iterations           | 2204       |\n",
      "|    time_elapsed         | 8515       |\n",
      "|    total_timesteps      | 4513792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19721241 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.79       |\n",
      "|    explained_variance   | 0.423      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.07e+07   |\n",
      "|    n_updates            | 22030      |\n",
      "|    policy_gradient_loss | 0.00951    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.03e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4515000, episode_reward=-43842.49 +/- 15847.05\n",
      "Episode length: 411.80 +/- 53.06\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 412        |\n",
      "|    mean_reward          | -4.38e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4515000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43281117 |\n",
      "|    clip_fraction        | 0.473      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.79       |\n",
      "|    explained_variance   | 0.446      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.33e+07   |\n",
      "|    n_updates            | 22040      |\n",
      "|    policy_gradient_loss | 0.0213     |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.08e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 845       |\n",
      "|    ep_rew_mean     | -3.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 2205      |\n",
      "|    time_elapsed    | 8517      |\n",
      "|    total_timesteps | 4515840   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 834          |\n",
      "|    ep_rew_mean          | -3.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 2206         |\n",
      "|    time_elapsed         | 8519         |\n",
      "|    total_timesteps      | 4517888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041291374 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.462        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12e+07     |\n",
      "|    n_updates            | 22050        |\n",
      "|    policy_gradient_loss | -0.000164    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.76e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 828          |\n",
      "|    ep_rew_mean          | -3.66e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 2207         |\n",
      "|    time_elapsed         | 8521         |\n",
      "|    total_timesteps      | 4519936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013837486 |\n",
      "|    clip_fraction        | 0.00698      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.453        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07e+07     |\n",
      "|    n_updates            | 22060        |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.81e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4520000, episode_reward=-52903.48 +/- 8516.92\n",
      "Episode length: 469.60 +/- 80.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 470         |\n",
      "|    mean_reward          | -5.29e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004312214 |\n",
      "|    clip_fraction        | 0.0201      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.21e+06    |\n",
      "|    n_updates            | 22070       |\n",
      "|    policy_gradient_loss | -0.00515    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.48e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 836       |\n",
      "|    ep_rew_mean     | -3.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 2208      |\n",
      "|    time_elapsed    | 8524      |\n",
      "|    total_timesteps | 4521984   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 845          |\n",
      "|    ep_rew_mean          | -3.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 2209         |\n",
      "|    time_elapsed         | 8526         |\n",
      "|    total_timesteps      | 4524032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024650272 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+07     |\n",
      "|    n_updates            | 22080        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.88e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4525000, episode_reward=-40789.59 +/- 30344.58\n",
      "Episode length: 709.00 +/- 532.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 709          |\n",
      "|    mean_reward          | -4.08e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4525000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045677517 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.574        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.95e+05     |\n",
      "|    n_updates            | 22090        |\n",
      "|    policy_gradient_loss | -0.00483     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.92e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 854       |\n",
      "|    ep_rew_mean     | -3.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 2210      |\n",
      "|    time_elapsed    | 8529      |\n",
      "|    total_timesteps | 4526080   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 860          |\n",
      "|    ep_rew_mean          | -3.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 2211         |\n",
      "|    time_elapsed         | 8531         |\n",
      "|    total_timesteps      | 4528128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074566337 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06e+07     |\n",
      "|    n_updates            | 22100        |\n",
      "|    policy_gradient_loss | -0.00868     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.52e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4530000, episode_reward=-45260.97 +/- 10772.28\n",
      "Episode length: 507.00 +/- 25.90\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 507         |\n",
      "|    mean_reward          | -4.53e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004227626 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.434       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.29e+06    |\n",
      "|    n_updates            | 22110       |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.69e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 854       |\n",
      "|    ep_rew_mean     | -3.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 2212      |\n",
      "|    time_elapsed    | 8534      |\n",
      "|    total_timesteps | 4530176   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 794         |\n",
      "|    ep_rew_mean          | -3.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 2213        |\n",
      "|    time_elapsed         | 8536        |\n",
      "|    total_timesteps      | 4532224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003442963 |\n",
      "|    clip_fraction        | 0.0195      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+07    |\n",
      "|    n_updates            | 22120       |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.66e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 780          |\n",
      "|    ep_rew_mean          | -3.78e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 531          |\n",
      "|    iterations           | 2214         |\n",
      "|    time_elapsed         | 8538         |\n",
      "|    total_timesteps      | 4534272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048296866 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.64e+06     |\n",
      "|    n_updates            | 22130        |\n",
      "|    policy_gradient_loss | -0.00284     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.96e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4535000, episode_reward=-56554.19 +/- 8612.15\n",
      "Episode length: 452.20 +/- 62.90\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 452        |\n",
      "|    mean_reward          | -5.66e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4535000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00629728 |\n",
      "|    clip_fraction        | 0.0347     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.79       |\n",
      "|    explained_variance   | 0.471      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.34e+07   |\n",
      "|    n_updates            | 22140      |\n",
      "|    policy_gradient_loss | -0.0047    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 2.3e+07    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 792       |\n",
      "|    ep_rew_mean     | -3.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 531       |\n",
      "|    iterations      | 2215      |\n",
      "|    time_elapsed    | 8541      |\n",
      "|    total_timesteps | 4536320   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 776         |\n",
      "|    ep_rew_mean          | -3.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 2216        |\n",
      "|    time_elapsed         | 8543        |\n",
      "|    total_timesteps      | 4538368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004612592 |\n",
      "|    clip_fraction        | 0.0271      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.72e+06    |\n",
      "|    n_updates            | 22150       |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.47e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4540000, episode_reward=-56131.01 +/- 29071.91\n",
      "Episode length: 426.40 +/- 182.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 426         |\n",
      "|    mean_reward          | -5.61e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005008245 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.75e+06    |\n",
      "|    n_updates            | 22160       |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.85e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 709      |\n",
      "|    ep_rew_mean     | -3.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 531      |\n",
      "|    iterations      | 2217     |\n",
      "|    time_elapsed    | 8546     |\n",
      "|    total_timesteps | 4540416  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 664          |\n",
      "|    ep_rew_mean          | -3.97e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 531          |\n",
      "|    iterations           | 2218         |\n",
      "|    time_elapsed         | 8547         |\n",
      "|    total_timesteps      | 4542464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046579526 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.18e+07     |\n",
      "|    n_updates            | 22170        |\n",
      "|    policy_gradient_loss | -0.00384     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.23e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 601          |\n",
      "|    ep_rew_mean          | -4.12e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 531          |\n",
      "|    iterations           | 2219         |\n",
      "|    time_elapsed         | 8549         |\n",
      "|    total_timesteps      | 4544512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034661181 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.26e+07     |\n",
      "|    n_updates            | 22180        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.96e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4545000, episode_reward=-25417.92 +/- 12809.37\n",
      "Episode length: 446.20 +/- 19.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 446          |\n",
      "|    mean_reward          | -2.54e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4545000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029294416 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+07     |\n",
      "|    n_updates            | 22190        |\n",
      "|    policy_gradient_loss | -0.000746    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.32e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 580       |\n",
      "|    ep_rew_mean     | -4.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 531       |\n",
      "|    iterations      | 2220      |\n",
      "|    time_elapsed    | 8552      |\n",
      "|    total_timesteps | 4546560   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 553         |\n",
      "|    ep_rew_mean          | -4.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 2221        |\n",
      "|    time_elapsed         | 8554        |\n",
      "|    total_timesteps      | 4548608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008798415 |\n",
      "|    clip_fraction        | 0.0409      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38e+06    |\n",
      "|    n_updates            | 22200       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1e+07       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4550000, episode_reward=-54339.21 +/- 31537.13\n",
      "Episode length: 465.20 +/- 170.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 465         |\n",
      "|    mean_reward          | -5.43e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003053167 |\n",
      "|    clip_fraction        | 0.0339      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+07    |\n",
      "|    n_updates            | 22210       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.08e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 500       |\n",
      "|    ep_rew_mean     | -4.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 531       |\n",
      "|    iterations      | 2222      |\n",
      "|    time_elapsed    | 8557      |\n",
      "|    total_timesteps | 4550656   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 474          |\n",
      "|    ep_rew_mean          | -4.16e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 531          |\n",
      "|    iterations           | 2223         |\n",
      "|    time_elapsed         | 8559         |\n",
      "|    total_timesteps      | 4552704      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050946428 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59e+07     |\n",
      "|    n_updates            | 22220        |\n",
      "|    policy_gradient_loss | -0.00484     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.34e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 438          |\n",
      "|    ep_rew_mean          | -4.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 532          |\n",
      "|    iterations           | 2224         |\n",
      "|    time_elapsed         | 8561         |\n",
      "|    total_timesteps      | 4554752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040826257 |\n",
      "|    clip_fraction        | 0.0233       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.517        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.47e+06     |\n",
      "|    n_updates            | 22230        |\n",
      "|    policy_gradient_loss | -0.00175     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.33e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4555000, episode_reward=-45098.49 +/- 26515.71\n",
      "Episode length: 416.60 +/- 51.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 417         |\n",
      "|    mean_reward          | -4.51e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4555000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003775553 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.77e+07    |\n",
      "|    n_updates            | 22240       |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 5.22e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 415       |\n",
      "|    ep_rew_mean     | -4.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 532       |\n",
      "|    iterations      | 2225      |\n",
      "|    time_elapsed    | 8563      |\n",
      "|    total_timesteps | 4556800   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 426          |\n",
      "|    ep_rew_mean          | -4.4e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 532          |\n",
      "|    iterations           | 2226         |\n",
      "|    time_elapsed         | 8565         |\n",
      "|    total_timesteps      | 4558848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057252333 |\n",
      "|    clip_fraction        | 0.0409       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.46e+07     |\n",
      "|    n_updates            | 22250        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.53e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4560000, episode_reward=-35432.34 +/- 30328.08\n",
      "Episode length: 419.00 +/- 199.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 419         |\n",
      "|    mean_reward          | -3.54e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007206825 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.07e+06    |\n",
      "|    n_updates            | 22260       |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.93e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 432       |\n",
      "|    ep_rew_mean     | -4.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 532       |\n",
      "|    iterations      | 2227      |\n",
      "|    time_elapsed    | 8568      |\n",
      "|    total_timesteps | 4560896   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 432          |\n",
      "|    ep_rew_mean          | -4.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 532          |\n",
      "|    iterations           | 2228         |\n",
      "|    time_elapsed         | 8570         |\n",
      "|    total_timesteps      | 4562944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057404786 |\n",
      "|    clip_fraction        | 0.027        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.65e+06     |\n",
      "|    n_updates            | 22270        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.87e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 430         |\n",
      "|    ep_rew_mean          | -4.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 532         |\n",
      "|    iterations           | 2229        |\n",
      "|    time_elapsed         | 8572        |\n",
      "|    total_timesteps      | 4564992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004352142 |\n",
      "|    clip_fraction        | 0.0459      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7e+07     |\n",
      "|    n_updates            | 22280       |\n",
      "|    policy_gradient_loss | -0.00383    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.06e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4565000, episode_reward=-40028.72 +/- 22701.88\n",
      "Episode length: 480.20 +/- 31.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 480          |\n",
      "|    mean_reward          | -4e+04       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4565000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061999727 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.48e+06     |\n",
      "|    n_updates            | 22290        |\n",
      "|    policy_gradient_loss | -0.0078      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.5e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 423       |\n",
      "|    ep_rew_mean     | -4.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 532       |\n",
      "|    iterations      | 2230      |\n",
      "|    time_elapsed    | 8575      |\n",
      "|    total_timesteps | 4567040   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 435          |\n",
      "|    ep_rew_mean          | -4.55e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 532          |\n",
      "|    iterations           | 2231         |\n",
      "|    time_elapsed         | 8577         |\n",
      "|    total_timesteps      | 4569088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049989605 |\n",
      "|    clip_fraction        | 0.0457       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.85e+06     |\n",
      "|    n_updates            | 22300        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.63e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4570000, episode_reward=-37810.26 +/- 29188.24\n",
      "Episode length: 481.80 +/- 137.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 482         |\n",
      "|    mean_reward          | -3.78e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004134494 |\n",
      "|    clip_fraction        | 0.0364      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.46e+06    |\n",
      "|    n_updates            | 22310       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.47e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 422       |\n",
      "|    ep_rew_mean     | -4.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 532       |\n",
      "|    iterations      | 2232      |\n",
      "|    time_elapsed    | 8580      |\n",
      "|    total_timesteps | 4571136   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 422         |\n",
      "|    ep_rew_mean          | -4.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 532         |\n",
      "|    iterations           | 2233        |\n",
      "|    time_elapsed         | 8581        |\n",
      "|    total_timesteps      | 4573184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008144224 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.489       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.98e+06    |\n",
      "|    n_updates            | 22320       |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.64e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4575000, episode_reward=-22252.02 +/- 19699.41\n",
      "Episode length: 484.60 +/- 49.59\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 485          |\n",
      "|    mean_reward          | -2.23e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4575000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028078612 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+07     |\n",
      "|    n_updates            | 22330        |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.63e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 413       |\n",
      "|    ep_rew_mean     | -4.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 532       |\n",
      "|    iterations      | 2234      |\n",
      "|    time_elapsed    | 8584      |\n",
      "|    total_timesteps | 4575232   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 423         |\n",
      "|    ep_rew_mean          | -4.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 533         |\n",
      "|    iterations           | 2235        |\n",
      "|    time_elapsed         | 8586        |\n",
      "|    total_timesteps      | 4577280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004946419 |\n",
      "|    clip_fraction        | 0.023       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.14e+07    |\n",
      "|    n_updates            | 22340       |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.05e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 428          |\n",
      "|    ep_rew_mean          | -4.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 533          |\n",
      "|    iterations           | 2236         |\n",
      "|    time_elapsed         | 8588         |\n",
      "|    total_timesteps      | 4579328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070289015 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.71e+06     |\n",
      "|    n_updates            | 22350        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.15e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4580000, episode_reward=-33158.23 +/- 17944.52\n",
      "Episode length: 453.40 +/- 68.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 453          |\n",
      "|    mean_reward          | -3.32e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4580000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039549237 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.499        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+06     |\n",
      "|    n_updates            | 22360        |\n",
      "|    policy_gradient_loss | -0.00463     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.02e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 432       |\n",
      "|    ep_rew_mean     | -4.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 533       |\n",
      "|    iterations      | 2237      |\n",
      "|    time_elapsed    | 8591      |\n",
      "|    total_timesteps | 4581376   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 437          |\n",
      "|    ep_rew_mean          | -4.41e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 533          |\n",
      "|    iterations           | 2238         |\n",
      "|    time_elapsed         | 8593         |\n",
      "|    total_timesteps      | 4583424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062515032 |\n",
      "|    clip_fraction        | 0.0639       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.557        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.91e+06     |\n",
      "|    n_updates            | 22370        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 5.49e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4585000, episode_reward=-25474.25 +/- 16781.34\n",
      "Episode length: 454.80 +/- 51.17\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 455          |\n",
      "|    mean_reward          | -2.55e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4585000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034324962 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.408        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.34e+06     |\n",
      "|    n_updates            | 22380        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.12e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 434       |\n",
      "|    ep_rew_mean     | -4.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 533       |\n",
      "|    iterations      | 2239      |\n",
      "|    time_elapsed    | 8596      |\n",
      "|    total_timesteps | 4585472   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 447          |\n",
      "|    ep_rew_mean          | -4.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 533          |\n",
      "|    iterations           | 2240         |\n",
      "|    time_elapsed         | 8597         |\n",
      "|    total_timesteps      | 4587520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056925192 |\n",
      "|    clip_fraction        | 0.0641       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+07     |\n",
      "|    n_updates            | 22390        |\n",
      "|    policy_gradient_loss | -0.00688     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.09e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 451         |\n",
      "|    ep_rew_mean          | -4.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 533         |\n",
      "|    iterations           | 2241        |\n",
      "|    time_elapsed         | 8599        |\n",
      "|    total_timesteps      | 4589568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012515558 |\n",
      "|    clip_fraction        | 0.0906      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.614       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.76e+06    |\n",
      "|    n_updates            | 22400       |\n",
      "|    policy_gradient_loss | 0.000876    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.59e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4590000, episode_reward=-29730.05 +/- 20841.82\n",
      "Episode length: 465.80 +/- 43.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 466         |\n",
      "|    mean_reward          | -2.97e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004535619 |\n",
      "|    clip_fraction        | 0.028       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+07    |\n",
      "|    n_updates            | 22410       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.26e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 442       |\n",
      "|    ep_rew_mean     | -4.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 533       |\n",
      "|    iterations      | 2242      |\n",
      "|    time_elapsed    | 8602      |\n",
      "|    total_timesteps | 4591616   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 449          |\n",
      "|    ep_rew_mean          | -4.33e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 533          |\n",
      "|    iterations           | 2243         |\n",
      "|    time_elapsed         | 8604         |\n",
      "|    total_timesteps      | 4593664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034156903 |\n",
      "|    clip_fraction        | 0.0261       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.47         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+07     |\n",
      "|    n_updates            | 22420        |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.45e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4595000, episode_reward=-23905.09 +/- 23939.21\n",
      "Episode length: 417.00 +/- 50.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 417         |\n",
      "|    mean_reward          | -2.39e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4595000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005366837 |\n",
      "|    clip_fraction        | 0.0304      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+07    |\n",
      "|    n_updates            | 22430       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.83e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 455       |\n",
      "|    ep_rew_mean     | -4.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 533       |\n",
      "|    iterations      | 2244      |\n",
      "|    time_elapsed    | 8607      |\n",
      "|    total_timesteps | 4595712   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 454         |\n",
      "|    ep_rew_mean          | -4.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 534         |\n",
      "|    iterations           | 2245        |\n",
      "|    time_elapsed         | 8609        |\n",
      "|    total_timesteps      | 4597760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005819375 |\n",
      "|    clip_fraction        | 0.035       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.67e+07    |\n",
      "|    n_updates            | 22440       |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.23e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 455          |\n",
      "|    ep_rew_mean          | -4.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 534          |\n",
      "|    iterations           | 2246         |\n",
      "|    time_elapsed         | 8610         |\n",
      "|    total_timesteps      | 4599808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067838524 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.96e+07     |\n",
      "|    n_updates            | 22450        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2e+07        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4600000, episode_reward=-16212.78 +/- 16257.71\n",
      "Episode length: 452.80 +/- 53.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 453          |\n",
      "|    mean_reward          | -1.62e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060705077 |\n",
      "|    clip_fraction        | 0.0644       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.76e+06     |\n",
      "|    n_updates            | 22460        |\n",
      "|    policy_gradient_loss | -0.00729     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.02e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 459       |\n",
      "|    ep_rew_mean     | -4.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 534       |\n",
      "|    iterations      | 2247      |\n",
      "|    time_elapsed    | 8613      |\n",
      "|    total_timesteps | 4601856   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 450         |\n",
      "|    ep_rew_mean          | -4.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 534         |\n",
      "|    iterations           | 2248        |\n",
      "|    time_elapsed         | 8615        |\n",
      "|    total_timesteps      | 4603904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004070715 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.6e+07     |\n",
      "|    n_updates            | 22470       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.79e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4605000, episode_reward=-57098.62 +/- 24301.27\n",
      "Episode length: 409.20 +/- 36.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 409         |\n",
      "|    mean_reward          | -5.71e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4605000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008302148 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.49e+07    |\n",
      "|    n_updates            | 22480       |\n",
      "|    policy_gradient_loss | -0.00582    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.71e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 444      |\n",
      "|    ep_rew_mean     | -4.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 534      |\n",
      "|    iterations      | 2249     |\n",
      "|    time_elapsed    | 8618     |\n",
      "|    total_timesteps | 4605952  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 443          |\n",
      "|    ep_rew_mean          | -4.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 534          |\n",
      "|    iterations           | 2250         |\n",
      "|    time_elapsed         | 8620         |\n",
      "|    total_timesteps      | 4608000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050138785 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+07     |\n",
      "|    n_updates            | 22490        |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.6e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4610000, episode_reward=-46074.52 +/- 21897.85\n",
      "Episode length: 390.20 +/- 72.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 390         |\n",
      "|    mean_reward          | -4.61e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008151092 |\n",
      "|    clip_fraction        | 0.077       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.478       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.1e+06     |\n",
      "|    n_updates            | 22500       |\n",
      "|    policy_gradient_loss | -0.000695   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.06e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 441       |\n",
      "|    ep_rew_mean     | -4.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 534       |\n",
      "|    iterations      | 2251      |\n",
      "|    time_elapsed    | 8623      |\n",
      "|    total_timesteps | 4610048   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 428          |\n",
      "|    ep_rew_mean          | -4.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 534          |\n",
      "|    iterations           | 2252         |\n",
      "|    time_elapsed         | 8624         |\n",
      "|    total_timesteps      | 4612096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025306838 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.315        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.41e+07     |\n",
      "|    n_updates            | 22510        |\n",
      "|    policy_gradient_loss | -0.000974    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 6.06e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 426         |\n",
      "|    ep_rew_mean          | -4.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 534         |\n",
      "|    iterations           | 2253        |\n",
      "|    time_elapsed         | 8626        |\n",
      "|    total_timesteps      | 4614144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005870591 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.26e+06    |\n",
      "|    n_updates            | 22520       |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.98e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4615000, episode_reward=-45006.46 +/- 14715.11\n",
      "Episode length: 345.80 +/- 20.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 346         |\n",
      "|    mean_reward          | -4.5e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4615000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004189879 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.354       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+07    |\n",
      "|    n_updates            | 22530       |\n",
      "|    policy_gradient_loss | -0.00324    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.99e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 422       |\n",
      "|    ep_rew_mean     | -4.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 534       |\n",
      "|    iterations      | 2254      |\n",
      "|    time_elapsed    | 8629      |\n",
      "|    total_timesteps | 4616192   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 424         |\n",
      "|    ep_rew_mean          | -4.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 2255        |\n",
      "|    time_elapsed         | 8631        |\n",
      "|    total_timesteps      | 4618240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010848677 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.1e+07     |\n",
      "|    n_updates            | 22540       |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.56e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4620000, episode_reward=-22763.82 +/- 27204.49\n",
      "Episode length: 386.40 +/- 27.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 386         |\n",
      "|    mean_reward          | -2.28e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009083266 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+07    |\n",
      "|    n_updates            | 22550       |\n",
      "|    policy_gradient_loss | -0.00133    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.3e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 410       |\n",
      "|    ep_rew_mean     | -4.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 535       |\n",
      "|    iterations      | 2256      |\n",
      "|    time_elapsed    | 8633      |\n",
      "|    total_timesteps | 4620288   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -4.42e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 2257        |\n",
      "|    time_elapsed         | 8635        |\n",
      "|    total_timesteps      | 4622336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008906351 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+07    |\n",
      "|    n_updates            | 22560       |\n",
      "|    policy_gradient_loss | -0.000872   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.71e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 400         |\n",
      "|    ep_rew_mean          | -4.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 2258        |\n",
      "|    time_elapsed         | 8637        |\n",
      "|    total_timesteps      | 4624384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006198222 |\n",
      "|    clip_fraction        | 0.0726      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.56e+07    |\n",
      "|    n_updates            | 22570       |\n",
      "|    policy_gradient_loss | 0.00267     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.14e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4625000, episode_reward=-32196.89 +/- 20259.23\n",
      "Episode length: 379.60 +/- 31.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 380          |\n",
      "|    mean_reward          | -3.22e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4625000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042935954 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.504        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.86e+06     |\n",
      "|    n_updates            | 22580        |\n",
      "|    policy_gradient_loss | -0.000854    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.07e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 388       |\n",
      "|    ep_rew_mean     | -4.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 535       |\n",
      "|    iterations      | 2259      |\n",
      "|    time_elapsed    | 8640      |\n",
      "|    total_timesteps | 4626432   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 387         |\n",
      "|    ep_rew_mean          | -4.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 2260        |\n",
      "|    time_elapsed         | 8642        |\n",
      "|    total_timesteps      | 4628480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004332629 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.18e+06    |\n",
      "|    n_updates            | 22590       |\n",
      "|    policy_gradient_loss | -0.00682    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.28e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4630000, episode_reward=-40721.26 +/- 15322.55\n",
      "Episode length: 353.80 +/- 6.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 354         |\n",
      "|    mean_reward          | -4.07e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004605594 |\n",
      "|    clip_fraction        | 0.0326      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.74e+06    |\n",
      "|    n_updates            | 22600       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.22e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 387       |\n",
      "|    ep_rew_mean     | -4.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 535       |\n",
      "|    iterations      | 2261      |\n",
      "|    time_elapsed    | 8644      |\n",
      "|    total_timesteps | 4630528   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 380         |\n",
      "|    ep_rew_mean          | -4.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 535         |\n",
      "|    iterations           | 2262        |\n",
      "|    time_elapsed         | 8646        |\n",
      "|    total_timesteps      | 4632576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004800385 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.73e+06    |\n",
      "|    n_updates            | 22610       |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.98e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 380          |\n",
      "|    ep_rew_mean          | -4.21e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 535          |\n",
      "|    iterations           | 2263         |\n",
      "|    time_elapsed         | 8648         |\n",
      "|    total_timesteps      | 4634624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042228657 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.79         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.21e+07     |\n",
      "|    n_updates            | 22620        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.63e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4635000, episode_reward=-36198.59 +/- 31878.32\n",
      "Episode length: 411.80 +/- 58.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 412         |\n",
      "|    mean_reward          | -3.62e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4635000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009485571 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.45e+06    |\n",
      "|    n_updates            | 22630       |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.31e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 378       |\n",
      "|    ep_rew_mean     | -4.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 535       |\n",
      "|    iterations      | 2264      |\n",
      "|    time_elapsed    | 8651      |\n",
      "|    total_timesteps | 4636672   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 373         |\n",
      "|    ep_rew_mean          | -4.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 2265        |\n",
      "|    time_elapsed         | 8653        |\n",
      "|    total_timesteps      | 4638720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008262739 |\n",
      "|    clip_fraction        | 0.0595      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.79        |\n",
      "|    explained_variance   | 0.47        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+07    |\n",
      "|    n_updates            | 22640       |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.92e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4640000, episode_reward=-57835.40 +/- 13030.27\n",
      "Episode length: 350.80 +/- 24.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 351         |\n",
      "|    mean_reward          | -5.78e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008169699 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.88e+07    |\n",
      "|    n_updates            | 22650       |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.49e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 371      |\n",
      "|    ep_rew_mean     | -4.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 536      |\n",
      "|    iterations      | 2266     |\n",
      "|    time_elapsed    | 8655     |\n",
      "|    total_timesteps | 4640768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 373         |\n",
      "|    ep_rew_mean          | -4.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 2267        |\n",
      "|    time_elapsed         | 8657        |\n",
      "|    total_timesteps      | 4642816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009541023 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.99e+06    |\n",
      "|    n_updates            | 22660       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.54e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 370          |\n",
      "|    ep_rew_mean          | -4.23e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 536          |\n",
      "|    iterations           | 2268         |\n",
      "|    time_elapsed         | 8659         |\n",
      "|    total_timesteps      | 4644864      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065659406 |\n",
      "|    clip_fraction        | 0.0632       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+07     |\n",
      "|    n_updates            | 22670        |\n",
      "|    policy_gradient_loss | 9.63e-05     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.91e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4645000, episode_reward=-43185.57 +/- 39949.10\n",
      "Episode length: 420.20 +/- 89.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 420         |\n",
      "|    mean_reward          | -4.32e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4645000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004639212 |\n",
      "|    clip_fraction        | 0.0455      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.09e+06    |\n",
      "|    n_updates            | 22680       |\n",
      "|    policy_gradient_loss | 0.0011      |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.17e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 371       |\n",
      "|    ep_rew_mean     | -4.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 536       |\n",
      "|    iterations      | 2269      |\n",
      "|    time_elapsed    | 8662      |\n",
      "|    total_timesteps | 4646912   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 370         |\n",
      "|    ep_rew_mean          | -4.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 2270        |\n",
      "|    time_elapsed         | 8664        |\n",
      "|    total_timesteps      | 4648960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005435735 |\n",
      "|    clip_fraction        | 0.0548      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.02e+07    |\n",
      "|    n_updates            | 22690       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.39e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4650000, episode_reward=-51517.60 +/- 30894.27\n",
      "Episode length: 448.20 +/- 138.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 448         |\n",
      "|    mean_reward          | -5.15e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005110722 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.454       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.93e+06    |\n",
      "|    n_updates            | 22700       |\n",
      "|    policy_gradient_loss | -0.00621    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.53e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 367       |\n",
      "|    ep_rew_mean     | -4.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 536       |\n",
      "|    iterations      | 2271      |\n",
      "|    time_elapsed    | 8667      |\n",
      "|    total_timesteps | 4651008   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 372          |\n",
      "|    ep_rew_mean          | -4.3e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 536          |\n",
      "|    iterations           | 2272         |\n",
      "|    time_elapsed         | 8668         |\n",
      "|    total_timesteps      | 4653056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057207937 |\n",
      "|    clip_fraction        | 0.0564       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.73e+07     |\n",
      "|    n_updates            | 22710        |\n",
      "|    policy_gradient_loss | -0.000199    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.45e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4655000, episode_reward=-43759.43 +/- 17031.95\n",
      "Episode length: 658.60 +/- 339.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 659          |\n",
      "|    mean_reward          | -4.38e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4655000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046870424 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.29e+07     |\n",
      "|    n_updates            | 22720        |\n",
      "|    policy_gradient_loss | -0.00337     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.93e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 371       |\n",
      "|    ep_rew_mean     | -4.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 536       |\n",
      "|    iterations      | 2273      |\n",
      "|    time_elapsed    | 8672      |\n",
      "|    total_timesteps | 4655104   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | -4.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 536         |\n",
      "|    iterations           | 2274        |\n",
      "|    time_elapsed         | 8674        |\n",
      "|    total_timesteps      | 4657152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009125106 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.465       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29e+07    |\n",
      "|    n_updates            | 22730       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.58e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 368          |\n",
      "|    ep_rew_mean          | -4.44e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 537          |\n",
      "|    iterations           | 2275         |\n",
      "|    time_elapsed         | 8675         |\n",
      "|    total_timesteps      | 4659200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023207678 |\n",
      "|    clip_fraction        | 0.0406       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.348        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.83e+07     |\n",
      "|    n_updates            | 22740        |\n",
      "|    policy_gradient_loss | -0.000701    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 5.68e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4660000, episode_reward=-43359.81 +/- 21205.14\n",
      "Episode length: 348.20 +/- 28.10\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 348          |\n",
      "|    mean_reward          | -4.34e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4660000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064310245 |\n",
      "|    clip_fraction        | 0.055        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.76e+06     |\n",
      "|    n_updates            | 22750        |\n",
      "|    policy_gradient_loss | -0.00448     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.54e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 373       |\n",
      "|    ep_rew_mean     | -4.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 537       |\n",
      "|    iterations      | 2276      |\n",
      "|    time_elapsed    | 8678      |\n",
      "|    total_timesteps | 4661248   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 373          |\n",
      "|    ep_rew_mean          | -4.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 537          |\n",
      "|    iterations           | 2277         |\n",
      "|    time_elapsed         | 8680         |\n",
      "|    total_timesteps      | 4663296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049872035 |\n",
      "|    clip_fraction        | 0.0434       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+07     |\n",
      "|    n_updates            | 22760        |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.93e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4665000, episode_reward=-25269.66 +/- 26505.28\n",
      "Episode length: 398.80 +/- 41.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 399         |\n",
      "|    mean_reward          | -2.53e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4665000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005101308 |\n",
      "|    clip_fraction        | 0.0389      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.27e+06    |\n",
      "|    n_updates            | 22770       |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.28e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 368       |\n",
      "|    ep_rew_mean     | -4.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 537       |\n",
      "|    iterations      | 2278      |\n",
      "|    time_elapsed    | 8683      |\n",
      "|    total_timesteps | 4665344   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 371          |\n",
      "|    ep_rew_mean          | -4.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 537          |\n",
      "|    iterations           | 2279         |\n",
      "|    time_elapsed         | 8685         |\n",
      "|    total_timesteps      | 4667392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048501166 |\n",
      "|    clip_fraction        | 0.0441       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.42e+06     |\n",
      "|    n_updates            | 22780        |\n",
      "|    policy_gradient_loss | -0.00247     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.84e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 371         |\n",
      "|    ep_rew_mean          | -4.7e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 537         |\n",
      "|    iterations           | 2280        |\n",
      "|    time_elapsed         | 8686        |\n",
      "|    total_timesteps      | 4669440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005002065 |\n",
      "|    clip_fraction        | 0.0471      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02e+07    |\n",
      "|    n_updates            | 22790       |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.52e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4670000, episode_reward=-55994.78 +/- 13621.82\n",
      "Episode length: 365.20 +/- 8.82\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 365          |\n",
      "|    mean_reward          | -5.6e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4670000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051667723 |\n",
      "|    clip_fraction        | 0.0495       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+07     |\n",
      "|    n_updates            | 22800        |\n",
      "|    policy_gradient_loss | -0.00759     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.16e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 370       |\n",
      "|    ep_rew_mean     | -4.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 537       |\n",
      "|    iterations      | 2281      |\n",
      "|    time_elapsed    | 8689      |\n",
      "|    total_timesteps | 4671488   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 370          |\n",
      "|    ep_rew_mean          | -4.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 537          |\n",
      "|    iterations           | 2282         |\n",
      "|    time_elapsed         | 8691         |\n",
      "|    total_timesteps      | 4673536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051297722 |\n",
      "|    clip_fraction        | 0.0581       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.82e+06     |\n",
      "|    n_updates            | 22810        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.31e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4675000, episode_reward=-40293.77 +/- 28270.45\n",
      "Episode length: 384.60 +/- 56.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 385         |\n",
      "|    mean_reward          | -4.03e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4675000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003047537 |\n",
      "|    clip_fraction        | 0.0256      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.64e+07    |\n",
      "|    n_updates            | 22820       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.32e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 369       |\n",
      "|    ep_rew_mean     | -4.71e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 537       |\n",
      "|    iterations      | 2283      |\n",
      "|    time_elapsed    | 8694      |\n",
      "|    total_timesteps | 4675584   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 369          |\n",
      "|    ep_rew_mean          | -4.85e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 537          |\n",
      "|    iterations           | 2284         |\n",
      "|    time_elapsed         | 8695         |\n",
      "|    total_timesteps      | 4677632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039000777 |\n",
      "|    clip_fraction        | 0.0204       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.24e+07     |\n",
      "|    n_updates            | 22830        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 5.61e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 368          |\n",
      "|    ep_rew_mean          | -4.78e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 2285         |\n",
      "|    time_elapsed         | 8697         |\n",
      "|    total_timesteps      | 4679680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037252414 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+07     |\n",
      "|    n_updates            | 22840        |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3e+07        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4680000, episode_reward=-50076.90 +/- 26798.04\n",
      "Episode length: 383.40 +/- 31.58\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 383        |\n",
      "|    mean_reward          | -5.01e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4680000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00319908 |\n",
      "|    clip_fraction        | 0.0268     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.78       |\n",
      "|    explained_variance   | 0.383      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.1e+07    |\n",
      "|    n_updates            | 22850      |\n",
      "|    policy_gradient_loss | -0.00196   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 3e+07      |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 367       |\n",
      "|    ep_rew_mean     | -4.84e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 538       |\n",
      "|    iterations      | 2286      |\n",
      "|    time_elapsed    | 8700      |\n",
      "|    total_timesteps | 4681728   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 367          |\n",
      "|    ep_rew_mean          | -4.68e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 2287         |\n",
      "|    time_elapsed         | 8702         |\n",
      "|    total_timesteps      | 4683776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046087475 |\n",
      "|    clip_fraction        | 0.0222       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.42e+06     |\n",
      "|    n_updates            | 22860        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.7e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4685000, episode_reward=-46442.55 +/- 21806.05\n",
      "Episode length: 351.80 +/- 22.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 352         |\n",
      "|    mean_reward          | -4.64e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4685000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005257731 |\n",
      "|    clip_fraction        | 0.064       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.63e+07    |\n",
      "|    n_updates            | 22870       |\n",
      "|    policy_gradient_loss | -0.000843   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.28e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 366       |\n",
      "|    ep_rew_mean     | -4.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 538       |\n",
      "|    iterations      | 2288      |\n",
      "|    time_elapsed    | 8704      |\n",
      "|    total_timesteps | 4685824   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 368          |\n",
      "|    ep_rew_mean          | -4.56e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 2289         |\n",
      "|    time_elapsed         | 8706         |\n",
      "|    total_timesteps      | 4687872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050958972 |\n",
      "|    clip_fraction        | 0.0498       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04e+07     |\n",
      "|    n_updates            | 22880        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.64e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 363          |\n",
      "|    ep_rew_mean          | -4.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 2290         |\n",
      "|    time_elapsed         | 8708         |\n",
      "|    total_timesteps      | 4689920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046413764 |\n",
      "|    clip_fraction        | 0.028        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+07     |\n",
      "|    n_updates            | 22890        |\n",
      "|    policy_gradient_loss | -0.00344     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.22e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4690000, episode_reward=-16900.81 +/- 24722.88\n",
      "Episode length: 376.60 +/- 10.97\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 377          |\n",
      "|    mean_reward          | -1.69e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4690000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030204963 |\n",
      "|    clip_fraction        | 0.0309       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.72e+07     |\n",
      "|    n_updates            | 22900        |\n",
      "|    policy_gradient_loss | -0.00151     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.14e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 367       |\n",
      "|    ep_rew_mean     | -4.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 538       |\n",
      "|    iterations      | 2291      |\n",
      "|    time_elapsed    | 8711      |\n",
      "|    total_timesteps | 4691968   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 374         |\n",
      "|    ep_rew_mean          | -4.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 538         |\n",
      "|    iterations           | 2292        |\n",
      "|    time_elapsed         | 8713        |\n",
      "|    total_timesteps      | 4694016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005547657 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9e+06       |\n",
      "|    n_updates            | 22910       |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.27e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4695000, episode_reward=-48097.18 +/- 17316.83\n",
      "Episode length: 348.20 +/- 28.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 348         |\n",
      "|    mean_reward          | -4.81e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4695000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009280018 |\n",
      "|    clip_fraction        | 0.055       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.493       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+06    |\n",
      "|    n_updates            | 22920       |\n",
      "|    policy_gradient_loss | -0.00626    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.07e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 374       |\n",
      "|    ep_rew_mean     | -4.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 538       |\n",
      "|    iterations      | 2293      |\n",
      "|    time_elapsed    | 8715      |\n",
      "|    total_timesteps | 4696064   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 371          |\n",
      "|    ep_rew_mean          | -4.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 538          |\n",
      "|    iterations           | 2294         |\n",
      "|    time_elapsed         | 8717         |\n",
      "|    total_timesteps      | 4698112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050214413 |\n",
      "|    clip_fraction        | 0.046        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.412        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.94e+06     |\n",
      "|    n_updates            | 22930        |\n",
      "|    policy_gradient_loss | -0.00127     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.56e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4700000, episode_reward=-23725.08 +/- 19723.62\n",
      "Episode length: 362.40 +/- 8.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 362         |\n",
      "|    mean_reward          | -2.37e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009487959 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.94e+07    |\n",
      "|    n_updates            | 22940       |\n",
      "|    policy_gradient_loss | -0.00542    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.66e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 365       |\n",
      "|    ep_rew_mean     | -4.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 538       |\n",
      "|    iterations      | 2295      |\n",
      "|    time_elapsed    | 8720      |\n",
      "|    total_timesteps | 4700160   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | -4.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 2296        |\n",
      "|    time_elapsed         | 8722        |\n",
      "|    total_timesteps      | 4702208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004993345 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.364       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.41e+07    |\n",
      "|    n_updates            | 22950       |\n",
      "|    policy_gradient_loss | -0.00651    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 5.99e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 360         |\n",
      "|    ep_rew_mean          | -4.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 2297        |\n",
      "|    time_elapsed         | 8723        |\n",
      "|    total_timesteps      | 4704256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003887727 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.69e+06    |\n",
      "|    n_updates            | 22960       |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.14e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4705000, episode_reward=-8628.88 +/- 13879.80\n",
      "Episode length: 381.00 +/- 39.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 381         |\n",
      "|    mean_reward          | -8.63e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4705000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004081132 |\n",
      "|    clip_fraction        | 0.027       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.67e+07    |\n",
      "|    n_updates            | 22970       |\n",
      "|    policy_gradient_loss | -0.00356    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.29e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 357       |\n",
      "|    ep_rew_mean     | -4.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 539       |\n",
      "|    iterations      | 2298      |\n",
      "|    time_elapsed    | 8726      |\n",
      "|    total_timesteps | 4706304   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 354         |\n",
      "|    ep_rew_mean          | -4.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 2299        |\n",
      "|    time_elapsed         | 8728        |\n",
      "|    total_timesteps      | 4708352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007835352 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2e+07     |\n",
      "|    n_updates            | 22980       |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.54e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4710000, episode_reward=-20367.68 +/- 25694.64\n",
      "Episode length: 357.00 +/- 31.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 357         |\n",
      "|    mean_reward          | -2.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007928954 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.1e+07     |\n",
      "|    n_updates            | 22990       |\n",
      "|    policy_gradient_loss | -0.0077     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.49e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 353       |\n",
      "|    ep_rew_mean     | -4.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 539       |\n",
      "|    iterations      | 2300      |\n",
      "|    time_elapsed    | 8731      |\n",
      "|    total_timesteps | 4710400   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 354          |\n",
      "|    ep_rew_mean          | -4.21e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 539          |\n",
      "|    iterations           | 2301         |\n",
      "|    time_elapsed         | 8733         |\n",
      "|    total_timesteps      | 4712448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033385037 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58e+07     |\n",
      "|    n_updates            | 23000        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.63e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 356         |\n",
      "|    ep_rew_mean          | -4.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 539         |\n",
      "|    iterations           | 2302        |\n",
      "|    time_elapsed         | 8734        |\n",
      "|    total_timesteps      | 4714496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006090778 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47e+07    |\n",
      "|    n_updates            | 23010       |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.14e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4715000, episode_reward=-40960.32 +/- 28605.17\n",
      "Episode length: 386.20 +/- 48.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 386          |\n",
      "|    mean_reward          | -4.1e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4715000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062935213 |\n",
      "|    clip_fraction        | 0.0646       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.04e+07     |\n",
      "|    n_updates            | 23020        |\n",
      "|    policy_gradient_loss | -0.00927     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.64e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 353       |\n",
      "|    ep_rew_mean     | -4.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 539       |\n",
      "|    iterations      | 2303      |\n",
      "|    time_elapsed    | 8737      |\n",
      "|    total_timesteps | 4716544   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 355          |\n",
      "|    ep_rew_mean          | -4.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 539          |\n",
      "|    iterations           | 2304         |\n",
      "|    time_elapsed         | 8739         |\n",
      "|    total_timesteps      | 4718592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044646133 |\n",
      "|    clip_fraction        | 0.0346       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05e+07     |\n",
      "|    n_updates            | 23030        |\n",
      "|    policy_gradient_loss | -0.00171     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.07e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4720000, episode_reward=-17990.59 +/- 11586.84\n",
      "Episode length: 363.60 +/- 21.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 364          |\n",
      "|    mean_reward          | -1.8e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032342044 |\n",
      "|    clip_fraction        | 0.0268       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.38e+07     |\n",
      "|    n_updates            | 23040        |\n",
      "|    policy_gradient_loss | -0.00203     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.26e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 353       |\n",
      "|    ep_rew_mean     | -4.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 539       |\n",
      "|    iterations      | 2305      |\n",
      "|    time_elapsed    | 8742      |\n",
      "|    total_timesteps | 4720640   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 350          |\n",
      "|    ep_rew_mean          | -4.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 2306         |\n",
      "|    time_elapsed         | 8743         |\n",
      "|    total_timesteps      | 4722688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036962735 |\n",
      "|    clip_fraction        | 0.0171       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.17e+07     |\n",
      "|    n_updates            | 23050        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.7e+07      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 355          |\n",
      "|    ep_rew_mean          | -4.4e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 2307         |\n",
      "|    time_elapsed         | 8745         |\n",
      "|    total_timesteps      | 4724736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049605556 |\n",
      "|    clip_fraction        | 0.0323       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.73e+07     |\n",
      "|    n_updates            | 23060        |\n",
      "|    policy_gradient_loss | -0.00447     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.33e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4725000, episode_reward=-31669.85 +/- 27293.55\n",
      "Episode length: 386.60 +/- 54.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 387          |\n",
      "|    mean_reward          | -3.17e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4725000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026274156 |\n",
      "|    clip_fraction        | 0.0247       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.765        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.23e+05     |\n",
      "|    n_updates            | 23070        |\n",
      "|    policy_gradient_loss | -0.000757    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.6e+05      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 354      |\n",
      "|    ep_rew_mean     | -4.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 540      |\n",
      "|    iterations      | 2308     |\n",
      "|    time_elapsed    | 8748     |\n",
      "|    total_timesteps | 4726784  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 350          |\n",
      "|    ep_rew_mean          | -4.42e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 2309         |\n",
      "|    time_elapsed         | 8750         |\n",
      "|    total_timesteps      | 4728832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042701745 |\n",
      "|    clip_fraction        | 0.0389       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.497        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.8e+06      |\n",
      "|    n_updates            | 23080        |\n",
      "|    policy_gradient_loss | -0.0012      |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.52e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4730000, episode_reward=-17141.94 +/- 25134.99\n",
      "Episode length: 382.40 +/- 29.18\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 382          |\n",
      "|    mean_reward          | -1.71e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4730000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053263525 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.05e+06     |\n",
      "|    n_updates            | 23090        |\n",
      "|    policy_gradient_loss | -0.00501     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 2.48e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 352       |\n",
      "|    ep_rew_mean     | -4.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 540       |\n",
      "|    iterations      | 2310      |\n",
      "|    time_elapsed    | 8752      |\n",
      "|    total_timesteps | 4730880   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 358          |\n",
      "|    ep_rew_mean          | -4.23e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 2311         |\n",
      "|    time_elapsed         | 8754         |\n",
      "|    total_timesteps      | 4732928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072923987 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.633        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.54e+06     |\n",
      "|    n_updates            | 23100        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 4.37e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 359          |\n",
      "|    ep_rew_mean          | -4.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 540          |\n",
      "|    iterations           | 2312         |\n",
      "|    time_elapsed         | 8756         |\n",
      "|    total_timesteps      | 4734976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024824014 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.98e+06     |\n",
      "|    n_updates            | 23110        |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.46e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4735000, episode_reward=-15285.62 +/- 38938.43\n",
      "Episode length: 325.20 +/- 126.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 325         |\n",
      "|    mean_reward          | -1.53e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4735000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009313289 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.74e+06    |\n",
      "|    n_updates            | 23120       |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.04e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 364       |\n",
      "|    ep_rew_mean     | -3.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 540       |\n",
      "|    iterations      | 2313      |\n",
      "|    time_elapsed    | 8759      |\n",
      "|    total_timesteps | 4737024   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 365         |\n",
      "|    ep_rew_mean          | -4.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 540         |\n",
      "|    iterations           | 2314        |\n",
      "|    time_elapsed         | 8761        |\n",
      "|    total_timesteps      | 4739072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004172199 |\n",
      "|    clip_fraction        | 0.0405      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.48e+06    |\n",
      "|    n_updates            | 23130       |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.41e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4740000, episode_reward=-31705.59 +/- 28492.58\n",
      "Episode length: 394.80 +/- 27.14\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 395          |\n",
      "|    mean_reward          | -3.17e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4740000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027873213 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.43e+07     |\n",
      "|    n_updates            | 23140        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.84e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 365       |\n",
      "|    ep_rew_mean     | -3.85e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 540       |\n",
      "|    iterations      | 2315      |\n",
      "|    time_elapsed    | 8763      |\n",
      "|    total_timesteps | 4741120   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 369         |\n",
      "|    ep_rew_mean          | -3.7e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 541         |\n",
      "|    iterations           | 2316        |\n",
      "|    time_elapsed         | 8765        |\n",
      "|    total_timesteps      | 4743168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009663761 |\n",
      "|    clip_fraction        | 0.0744      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.546       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+07    |\n",
      "|    n_updates            | 23150       |\n",
      "|    policy_gradient_loss | -0.00774    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.4e+07     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4745000, episode_reward=-11660.66 +/- 24687.89\n",
      "Episode length: 374.20 +/- 8.66\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 374        |\n",
      "|    mean_reward          | -1.17e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4745000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00400389 |\n",
      "|    clip_fraction        | 0.0244     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.78       |\n",
      "|    explained_variance   | 0.47       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.81e+06   |\n",
      "|    n_updates            | 23160      |\n",
      "|    policy_gradient_loss | -0.00161   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.53e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 368       |\n",
      "|    ep_rew_mean     | -3.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 541       |\n",
      "|    iterations      | 2317      |\n",
      "|    time_elapsed    | 8768      |\n",
      "|    total_timesteps | 4745216   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 369         |\n",
      "|    ep_rew_mean          | -3.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 541         |\n",
      "|    iterations           | 2318        |\n",
      "|    time_elapsed         | 8770        |\n",
      "|    total_timesteps      | 4747264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007015202 |\n",
      "|    clip_fraction        | 0.0568      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+07    |\n",
      "|    n_updates            | 23170       |\n",
      "|    policy_gradient_loss | -0.00222    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.72e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 372         |\n",
      "|    ep_rew_mean          | -3.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 541         |\n",
      "|    iterations           | 2319        |\n",
      "|    time_elapsed         | 8771        |\n",
      "|    total_timesteps      | 4749312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006498521 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.42e+07    |\n",
      "|    n_updates            | 23180       |\n",
      "|    policy_gradient_loss | -0.00403    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.86e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4750000, episode_reward=-4329.16 +/- 8877.63\n",
      "Episode length: 389.40 +/- 35.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 389          |\n",
      "|    mean_reward          | -4.33e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4750000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053041684 |\n",
      "|    clip_fraction        | 0.0463       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.2e+07      |\n",
      "|    n_updates            | 23190        |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.63e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 371       |\n",
      "|    ep_rew_mean     | -3.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 541       |\n",
      "|    iterations      | 2320      |\n",
      "|    time_elapsed    | 8774      |\n",
      "|    total_timesteps | 4751360   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 374          |\n",
      "|    ep_rew_mean          | -3.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 2321         |\n",
      "|    time_elapsed         | 8776         |\n",
      "|    total_timesteps      | 4753408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045871614 |\n",
      "|    clip_fraction        | 0.0252       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+07      |\n",
      "|    n_updates            | 23200        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.56e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4755000, episode_reward=-58128.83 +/- 29646.75\n",
      "Episode length: 416.20 +/- 214.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 416          |\n",
      "|    mean_reward          | -5.81e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4755000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049210563 |\n",
      "|    clip_fraction        | 0.0503       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.857        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.1e+05      |\n",
      "|    n_updates            | 23210        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 7e+05        |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 375       |\n",
      "|    ep_rew_mean     | -3.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 541       |\n",
      "|    iterations      | 2322      |\n",
      "|    time_elapsed    | 8779      |\n",
      "|    total_timesteps | 4755456   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 379          |\n",
      "|    ep_rew_mean          | -3.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 2323         |\n",
      "|    time_elapsed         | 8781         |\n",
      "|    total_timesteps      | 4757504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041109435 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.22e+06     |\n",
      "|    n_updates            | 23220        |\n",
      "|    policy_gradient_loss | -0.004       |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.49e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 380          |\n",
      "|    ep_rew_mean          | -3.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 541          |\n",
      "|    iterations           | 2324         |\n",
      "|    time_elapsed         | 8782         |\n",
      "|    total_timesteps      | 4759552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067727254 |\n",
      "|    clip_fraction        | 0.0429       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+07      |\n",
      "|    n_updates            | 23230        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 2.61e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4760000, episode_reward=-15213.77 +/- 20517.12\n",
      "Episode length: 364.80 +/- 18.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 365         |\n",
      "|    mean_reward          | -1.52e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004921049 |\n",
      "|    clip_fraction        | 0.0557      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+07    |\n",
      "|    n_updates            | 23240       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.67e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 382       |\n",
      "|    ep_rew_mean     | -3.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 541       |\n",
      "|    iterations      | 2325      |\n",
      "|    time_elapsed    | 8785      |\n",
      "|    total_timesteps | 4761600   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 379          |\n",
      "|    ep_rew_mean          | -3.61e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 542          |\n",
      "|    iterations           | 2326         |\n",
      "|    time_elapsed         | 8787         |\n",
      "|    total_timesteps      | 4763648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059232535 |\n",
      "|    clip_fraction        | 0.0497       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.39         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.43e+07     |\n",
      "|    n_updates            | 23250        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.56e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4765000, episode_reward=-19703.50 +/- 33125.02\n",
      "Episode length: 367.00 +/- 21.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 367         |\n",
      "|    mean_reward          | -1.97e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4765000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005070285 |\n",
      "|    clip_fraction        | 0.0526      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.41        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.09e+07    |\n",
      "|    n_updates            | 23260       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.41e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 378       |\n",
      "|    ep_rew_mean     | -3.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 542       |\n",
      "|    iterations      | 2327      |\n",
      "|    time_elapsed    | 8790      |\n",
      "|    total_timesteps | 4765696   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 373          |\n",
      "|    ep_rew_mean          | -3.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 542          |\n",
      "|    iterations           | 2328         |\n",
      "|    time_elapsed         | 8791         |\n",
      "|    total_timesteps      | 4767744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043889484 |\n",
      "|    clip_fraction        | 0.0304       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.78e+07     |\n",
      "|    n_updates            | 23270        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.13e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 369          |\n",
      "|    ep_rew_mean          | -3.78e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 542          |\n",
      "|    iterations           | 2329         |\n",
      "|    time_elapsed         | 8793         |\n",
      "|    total_timesteps      | 4769792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055762827 |\n",
      "|    clip_fraction        | 0.0445       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.53e+07     |\n",
      "|    n_updates            | 23280        |\n",
      "|    policy_gradient_loss | -0.00367     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.34e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4770000, episode_reward=4322.02 +/- 2535.70\n",
      "Episode length: 382.20 +/- 4.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 382         |\n",
      "|    mean_reward          | 4.32e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009290395 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+07    |\n",
      "|    n_updates            | 23290       |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.32e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 368       |\n",
      "|    ep_rew_mean     | -3.93e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 542       |\n",
      "|    iterations      | 2330      |\n",
      "|    time_elapsed    | 8796      |\n",
      "|    total_timesteps | 4771840   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 366          |\n",
      "|    ep_rew_mean          | -3.95e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 542          |\n",
      "|    iterations           | 2331         |\n",
      "|    time_elapsed         | 8798         |\n",
      "|    total_timesteps      | 4773888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056135384 |\n",
      "|    clip_fraction        | 0.0425       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+07      |\n",
      "|    n_updates            | 23300        |\n",
      "|    policy_gradient_loss | -0.00724     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 4.35e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4775000, episode_reward=-25027.14 +/- 30941.94\n",
      "Episode length: 371.60 +/- 31.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 372         |\n",
      "|    mean_reward          | -2.5e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4775000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004912397 |\n",
      "|    clip_fraction        | 0.0467      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.55e+06    |\n",
      "|    n_updates            | 23310       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 2.6e+07     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 372       |\n",
      "|    ep_rew_mean     | -3.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 542       |\n",
      "|    iterations      | 2332      |\n",
      "|    time_elapsed    | 8801      |\n",
      "|    total_timesteps | 4775936   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 371         |\n",
      "|    ep_rew_mean          | -3.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 2333        |\n",
      "|    time_elapsed         | 8802        |\n",
      "|    total_timesteps      | 4777984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004720771 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+05    |\n",
      "|    n_updates            | 23320       |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 3.79e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4780000, episode_reward=-18800.72 +/- 30527.54\n",
      "Episode length: 359.60 +/- 24.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 360         |\n",
      "|    mean_reward          | -1.88e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003501358 |\n",
      "|    clip_fraction        | 0.0291      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47e+07    |\n",
      "|    n_updates            | 23330       |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 2.42e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 370       |\n",
      "|    ep_rew_mean     | -3.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 542       |\n",
      "|    iterations      | 2334      |\n",
      "|    time_elapsed    | 8805      |\n",
      "|    total_timesteps | 4780032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 376         |\n",
      "|    ep_rew_mean          | -3.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 542         |\n",
      "|    iterations           | 2335        |\n",
      "|    time_elapsed         | 8807        |\n",
      "|    total_timesteps      | 4782080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008641059 |\n",
      "|    clip_fraction        | 0.0621      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.58e+06    |\n",
      "|    n_updates            | 23340       |\n",
      "|    policy_gradient_loss | -0.00521    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 2.99e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 381          |\n",
      "|    ep_rew_mean          | -3.54e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 543          |\n",
      "|    iterations           | 2336         |\n",
      "|    time_elapsed         | 8809         |\n",
      "|    total_timesteps      | 4784128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045957426 |\n",
      "|    clip_fraction        | 0.0338       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.576        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.22e+05     |\n",
      "|    n_updates            | 23350        |\n",
      "|    policy_gradient_loss | -0.00165     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 3.6e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4785000, episode_reward=-30786.76 +/- 16878.05\n",
      "Episode length: 358.60 +/- 5.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 359          |\n",
      "|    mean_reward          | -3.08e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4785000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0087603405 |\n",
      "|    clip_fraction        | 0.0744       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.84e+05     |\n",
      "|    n_updates            | 23360        |\n",
      "|    policy_gradient_loss | -0.00595     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 3.1e+06      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 380       |\n",
      "|    ep_rew_mean     | -3.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 543       |\n",
      "|    iterations      | 2337      |\n",
      "|    time_elapsed    | 8811      |\n",
      "|    total_timesteps | 4786176   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 382          |\n",
      "|    ep_rew_mean          | -3.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 543          |\n",
      "|    iterations           | 2338         |\n",
      "|    time_elapsed         | 8813         |\n",
      "|    total_timesteps      | 4788224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043317545 |\n",
      "|    clip_fraction        | 0.0427       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.55e+07     |\n",
      "|    n_updates            | 23370        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 2.24e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4790000, episode_reward=146.36 +/- 4951.35\n",
      "Episode length: 389.80 +/- 18.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 390          |\n",
      "|    mean_reward          | 146          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4790000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069485805 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.56         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.75e+06     |\n",
      "|    n_updates            | 23380        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 5.26e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 380       |\n",
      "|    ep_rew_mean     | -3.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 543       |\n",
      "|    iterations      | 2339      |\n",
      "|    time_elapsed    | 8816      |\n",
      "|    total_timesteps | 4790272   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 386          |\n",
      "|    ep_rew_mean          | -3.58e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 543          |\n",
      "|    iterations           | 2340         |\n",
      "|    time_elapsed         | 8818         |\n",
      "|    total_timesteps      | 4792320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051688636 |\n",
      "|    clip_fraction        | 0.0327       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+07     |\n",
      "|    n_updates            | 23390        |\n",
      "|    policy_gradient_loss | -0.00377     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 3.51e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 384          |\n",
      "|    ep_rew_mean          | -3.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 543          |\n",
      "|    iterations           | 2341         |\n",
      "|    time_elapsed         | 8820         |\n",
      "|    total_timesteps      | 4794368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029326254 |\n",
      "|    clip_fraction        | 0.0137       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.16e+06     |\n",
      "|    n_updates            | 23400        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.27e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4795000, episode_reward=-56668.71 +/- 27709.54\n",
      "Episode length: 317.20 +/- 31.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 317          |\n",
      "|    mean_reward          | -5.67e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4795000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049095545 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+07      |\n",
      "|    n_updates            | 23410        |\n",
      "|    policy_gradient_loss | -0.00549     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 3.29e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 382       |\n",
      "|    ep_rew_mean     | -3.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 543       |\n",
      "|    iterations      | 2342      |\n",
      "|    time_elapsed    | 8822      |\n",
      "|    total_timesteps | 4796416   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 384          |\n",
      "|    ep_rew_mean          | -3.55e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 543          |\n",
      "|    iterations           | 2343         |\n",
      "|    time_elapsed         | 8824         |\n",
      "|    total_timesteps      | 4798464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024988553 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.474        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.05e+06     |\n",
      "|    n_updates            | 23420        |\n",
      "|    policy_gradient_loss | -0.00139     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.75e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4800000, episode_reward=-18135.35 +/- 20273.02\n",
      "Episode length: 372.80 +/- 13.29\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 373          |\n",
      "|    mean_reward          | -1.81e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050423327 |\n",
      "|    clip_fraction        | 0.0532       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.457        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.44e+07     |\n",
      "|    n_updates            | 23430        |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 2.31e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 383       |\n",
      "|    ep_rew_mean     | -3.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 543       |\n",
      "|    iterations      | 2344      |\n",
      "|    time_elapsed    | 8827      |\n",
      "|    total_timesteps | 4800512   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 385         |\n",
      "|    ep_rew_mean          | -3.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 543         |\n",
      "|    iterations           | 2345        |\n",
      "|    time_elapsed         | 8829        |\n",
      "|    total_timesteps      | 4802560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002979617 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+07    |\n",
      "|    n_updates            | 23440       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 2.88e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 382          |\n",
      "|    ep_rew_mean          | -3.39e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 2346         |\n",
      "|    time_elapsed         | 8830         |\n",
      "|    total_timesteps      | 4804608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020083566 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.03e+07     |\n",
      "|    n_updates            | 23450        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 3.28e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4805000, episode_reward=-12303.25 +/- 20982.04\n",
      "Episode length: 374.40 +/- 17.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 374         |\n",
      "|    mean_reward          | -1.23e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4805000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006018762 |\n",
      "|    clip_fraction        | 0.0376      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.02e+06    |\n",
      "|    n_updates            | 23460       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 2.62e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 389       |\n",
      "|    ep_rew_mean     | -3.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 544       |\n",
      "|    iterations      | 2347      |\n",
      "|    time_elapsed    | 8833      |\n",
      "|    total_timesteps | 4806656   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 387        |\n",
      "|    ep_rew_mean          | -3.41e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 544        |\n",
      "|    iterations           | 2348       |\n",
      "|    time_elapsed         | 8835       |\n",
      "|    total_timesteps      | 4808704    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00578827 |\n",
      "|    clip_fraction        | 0.0425     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.78       |\n",
      "|    explained_variance   | 0.444      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.19e+07   |\n",
      "|    n_updates            | 23470      |\n",
      "|    policy_gradient_loss | -0.00527   |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 2.6e+07    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4810000, episode_reward=-23500.96 +/- 7975.96\n",
      "Episode length: 370.80 +/- 30.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 371         |\n",
      "|    mean_reward          | -2.35e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007970579 |\n",
      "|    clip_fraction        | 0.0587      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4e+07     |\n",
      "|    n_updates            | 23480       |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 2.53e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 386       |\n",
      "|    ep_rew_mean     | -3.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 544       |\n",
      "|    iterations      | 2349      |\n",
      "|    time_elapsed    | 8838      |\n",
      "|    total_timesteps | 4810752   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 379         |\n",
      "|    ep_rew_mean          | -3.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 2350        |\n",
      "|    time_elapsed         | 8839        |\n",
      "|    total_timesteps      | 4812800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004900559 |\n",
      "|    clip_fraction        | 0.0273      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.06e+05    |\n",
      "|    n_updates            | 23490       |\n",
      "|    policy_gradient_loss | -0.000133   |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.11e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 380         |\n",
      "|    ep_rew_mean          | -3.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 2351        |\n",
      "|    time_elapsed         | 8841        |\n",
      "|    total_timesteps      | 4814848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011180308 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.77e+06    |\n",
      "|    n_updates            | 23500       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 5.03e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4815000, episode_reward=-31173.36 +/- 7676.93\n",
      "Episode length: 358.40 +/- 9.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 358         |\n",
      "|    mean_reward          | -3.12e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4815000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004353452 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73e+07    |\n",
      "|    n_updates            | 23510       |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 2.69e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 378       |\n",
      "|    ep_rew_mean     | -3.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 544       |\n",
      "|    iterations      | 2352      |\n",
      "|    time_elapsed    | 8844      |\n",
      "|    total_timesteps | 4816896   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 375         |\n",
      "|    ep_rew_mean          | -3.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 544         |\n",
      "|    iterations           | 2353        |\n",
      "|    time_elapsed         | 8846        |\n",
      "|    total_timesteps      | 4818944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004713587 |\n",
      "|    clip_fraction        | 0.0303      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.42e+07    |\n",
      "|    n_updates            | 23520       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 3.49e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4820000, episode_reward=-21588.52 +/- 20445.11\n",
      "Episode length: 377.60 +/- 47.92\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 378          |\n",
      "|    mean_reward          | -2.16e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4820000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038504314 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.432        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.15e+06     |\n",
      "|    n_updates            | 23530        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.79e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 368       |\n",
      "|    ep_rew_mean     | -3.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 544       |\n",
      "|    iterations      | 2354      |\n",
      "|    time_elapsed    | 8848      |\n",
      "|    total_timesteps | 4820992   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 371          |\n",
      "|    ep_rew_mean          | -3.91e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 544          |\n",
      "|    iterations           | 2355         |\n",
      "|    time_elapsed         | 8850         |\n",
      "|    total_timesteps      | 4823040      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118668135 |\n",
      "|    clip_fraction        | 0.0496       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.78         |\n",
      "|    explained_variance   | 0.449        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+07     |\n",
      "|    n_updates            | 23540        |\n",
      "|    policy_gradient_loss | 0.000486     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.6e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4825000, episode_reward=-24604.99 +/- 32282.94\n",
      "Episode length: 363.80 +/- 23.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 364         |\n",
      "|    mean_reward          | -2.46e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4825000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005417867 |\n",
      "|    clip_fraction        | 0.0445      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.67e+06    |\n",
      "|    n_updates            | 23550       |\n",
      "|    policy_gradient_loss | -0.00298    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.7e+07     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 371       |\n",
      "|    ep_rew_mean     | -3.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 544       |\n",
      "|    iterations      | 2356      |\n",
      "|    time_elapsed    | 8853      |\n",
      "|    total_timesteps | 4825088   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 372          |\n",
      "|    ep_rew_mean          | -3.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 545          |\n",
      "|    iterations           | 2357         |\n",
      "|    time_elapsed         | 8855         |\n",
      "|    total_timesteps      | 4827136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053880294 |\n",
      "|    clip_fraction        | 0.038        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+07     |\n",
      "|    n_updates            | 23560        |\n",
      "|    policy_gradient_loss | -0.00487     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.16e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 365        |\n",
      "|    ep_rew_mean          | -3.93e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 545        |\n",
      "|    iterations           | 2358       |\n",
      "|    time_elapsed         | 8857       |\n",
      "|    total_timesteps      | 4829184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00515992 |\n",
      "|    clip_fraction        | 0.0252     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.431      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.98e+06   |\n",
      "|    n_updates            | 23570      |\n",
      "|    policy_gradient_loss | -0.00266   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 2.75e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4830000, episode_reward=-36269.45 +/- 7686.59\n",
      "Episode length: 362.00 +/- 10.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 362         |\n",
      "|    mean_reward          | -3.63e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004410995 |\n",
      "|    clip_fraction        | 0.0266      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+07    |\n",
      "|    n_updates            | 23580       |\n",
      "|    policy_gradient_loss | -0.00548    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.18e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 364      |\n",
      "|    ep_rew_mean     | -3.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 545      |\n",
      "|    iterations      | 2359     |\n",
      "|    time_elapsed    | 8859     |\n",
      "|    total_timesteps | 4831232  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 360          |\n",
      "|    ep_rew_mean          | -3.98e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 545          |\n",
      "|    iterations           | 2360         |\n",
      "|    time_elapsed         | 8861         |\n",
      "|    total_timesteps      | 4833280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041614734 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.57e+06     |\n",
      "|    n_updates            | 23590        |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.7e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4835000, episode_reward=-44145.85 +/- 16043.06\n",
      "Episode length: 351.60 +/- 36.63\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 352          |\n",
      "|    mean_reward          | -4.41e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4835000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079580955 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+06     |\n",
      "|    n_updates            | 23600        |\n",
      "|    policy_gradient_loss | -0.00238     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.94e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 359       |\n",
      "|    ep_rew_mean     | -4.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 545       |\n",
      "|    iterations      | 2361      |\n",
      "|    time_elapsed    | 8864      |\n",
      "|    total_timesteps | 4835328   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 360         |\n",
      "|    ep_rew_mean          | -4.01e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 2362        |\n",
      "|    time_elapsed         | 8866        |\n",
      "|    total_timesteps      | 4837376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006389859 |\n",
      "|    clip_fraction        | 0.0479      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.77e+07    |\n",
      "|    n_updates            | 23610       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 5.31e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | -4.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 2363        |\n",
      "|    time_elapsed         | 8867        |\n",
      "|    total_timesteps      | 4839424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008697932 |\n",
      "|    clip_fraction        | 0.0607      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.72e+06    |\n",
      "|    n_updates            | 23620       |\n",
      "|    policy_gradient_loss | -0.00648    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.55e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4840000, episode_reward=-40846.92 +/- 31917.92\n",
      "Episode length: 352.80 +/- 33.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 353         |\n",
      "|    mean_reward          | -4.08e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004324232 |\n",
      "|    clip_fraction        | 0.0457      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.29e+06    |\n",
      "|    n_updates            | 23630       |\n",
      "|    policy_gradient_loss | -0.00391    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.61e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 362       |\n",
      "|    ep_rew_mean     | -4.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 545       |\n",
      "|    iterations      | 2364      |\n",
      "|    time_elapsed    | 8870      |\n",
      "|    total_timesteps | 4841472   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 363         |\n",
      "|    ep_rew_mean          | -4.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 545         |\n",
      "|    iterations           | 2365        |\n",
      "|    time_elapsed         | 8872        |\n",
      "|    total_timesteps      | 4843520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006203321 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.92e+06    |\n",
      "|    n_updates            | 23640       |\n",
      "|    policy_gradient_loss | -7.64e-05   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.9e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4845000, episode_reward=-49038.94 +/- 27416.66\n",
      "Episode length: 327.80 +/- 59.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 328          |\n",
      "|    mean_reward          | -4.9e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4845000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052829273 |\n",
      "|    clip_fraction        | 0.0628       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.475        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.07e+06     |\n",
      "|    n_updates            | 23650        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.34e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 361       |\n",
      "|    ep_rew_mean     | -4.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 545       |\n",
      "|    iterations      | 2366      |\n",
      "|    time_elapsed    | 8875      |\n",
      "|    total_timesteps | 4845568   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 364         |\n",
      "|    ep_rew_mean          | -4.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 2367        |\n",
      "|    time_elapsed         | 8876        |\n",
      "|    total_timesteps      | 4847616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006935397 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.96e+07    |\n",
      "|    n_updates            | 23660       |\n",
      "|    policy_gradient_loss | -0.00493    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.25e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 366         |\n",
      "|    ep_rew_mean          | -3.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 2368        |\n",
      "|    time_elapsed         | 8878        |\n",
      "|    total_timesteps      | 4849664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004567883 |\n",
      "|    clip_fraction        | 0.0462      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.5e+06     |\n",
      "|    n_updates            | 23670       |\n",
      "|    policy_gradient_loss | -0.00637    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.06e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4850000, episode_reward=-42245.44 +/- 16698.89\n",
      "Episode length: 318.00 +/- 36.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 318          |\n",
      "|    mean_reward          | -4.22e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4850000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059184832 |\n",
      "|    clip_fraction        | 0.0412       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.491        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+07     |\n",
      "|    n_updates            | 23680        |\n",
      "|    policy_gradient_loss | -0.00409     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.06e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 373       |\n",
      "|    ep_rew_mean     | -3.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 546       |\n",
      "|    iterations      | 2369      |\n",
      "|    time_elapsed    | 8881      |\n",
      "|    total_timesteps | 4851712   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 374          |\n",
      "|    ep_rew_mean          | -3.8e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 546          |\n",
      "|    iterations           | 2370         |\n",
      "|    time_elapsed         | 8883         |\n",
      "|    total_timesteps      | 4853760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065907286 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.448        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.78e+06     |\n",
      "|    n_updates            | 23690        |\n",
      "|    policy_gradient_loss | -0.00604     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 9.37e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4855000, episode_reward=-42882.33 +/- 28054.69\n",
      "Episode length: 350.60 +/- 34.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 351         |\n",
      "|    mean_reward          | -4.29e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4855000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004396083 |\n",
      "|    clip_fraction        | 0.0322      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.54e+07    |\n",
      "|    n_updates            | 23700       |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.99e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 375      |\n",
      "|    ep_rew_mean     | -3.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 546      |\n",
      "|    iterations      | 2371     |\n",
      "|    time_elapsed    | 8885     |\n",
      "|    total_timesteps | 4855808  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 377          |\n",
      "|    ep_rew_mean          | -3.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 546          |\n",
      "|    iterations           | 2372         |\n",
      "|    time_elapsed         | 8887         |\n",
      "|    total_timesteps      | 4857856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038562207 |\n",
      "|    clip_fraction        | 0.0354       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.423        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.5e+07      |\n",
      "|    n_updates            | 23710        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.85e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 369          |\n",
      "|    ep_rew_mean          | -4.08e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 546          |\n",
      "|    iterations           | 2373         |\n",
      "|    time_elapsed         | 8889         |\n",
      "|    total_timesteps      | 4859904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060823807 |\n",
      "|    clip_fraction        | 0.0485       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.465        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+07     |\n",
      "|    n_updates            | 23720        |\n",
      "|    policy_gradient_loss | -0.00525     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.94e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4860000, episode_reward=-20592.63 +/- 28160.31\n",
      "Episode length: 378.20 +/- 51.25\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 378          |\n",
      "|    mean_reward          | -2.06e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4860000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063787987 |\n",
      "|    clip_fraction        | 0.0686       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.16e+07     |\n",
      "|    n_updates            | 23730        |\n",
      "|    policy_gradient_loss | -0.00716     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.46e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 365       |\n",
      "|    ep_rew_mean     | -4.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 546       |\n",
      "|    iterations      | 2374      |\n",
      "|    time_elapsed    | 8892      |\n",
      "|    total_timesteps | 4861952   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 362         |\n",
      "|    ep_rew_mean          | -4.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 546         |\n",
      "|    iterations           | 2375        |\n",
      "|    time_elapsed         | 8893        |\n",
      "|    total_timesteps      | 4864000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008120468 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+07    |\n",
      "|    n_updates            | 23740       |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.03e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4865000, episode_reward=-24971.02 +/- 32595.44\n",
      "Episode length: 364.40 +/- 53.46\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 364          |\n",
      "|    mean_reward          | -2.5e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4865000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073796385 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+07     |\n",
      "|    n_updates            | 23750        |\n",
      "|    policy_gradient_loss | -0.00214     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.06e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 366       |\n",
      "|    ep_rew_mean     | -4.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 546       |\n",
      "|    iterations      | 2376      |\n",
      "|    time_elapsed    | 8896      |\n",
      "|    total_timesteps | 4866048   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 367         |\n",
      "|    ep_rew_mean          | -4.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 2377        |\n",
      "|    time_elapsed         | 8898        |\n",
      "|    total_timesteps      | 4868096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004520334 |\n",
      "|    clip_fraction        | 0.0302      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5e+06       |\n",
      "|    n_updates            | 23760       |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.1e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4870000, episode_reward=-36667.75 +/- 19913.56\n",
      "Episode length: 331.20 +/- 45.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 331         |\n",
      "|    mean_reward          | -3.67e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004621518 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.19e+06    |\n",
      "|    n_updates            | 23770       |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.81e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 366       |\n",
      "|    ep_rew_mean     | -4.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 547       |\n",
      "|    iterations      | 2378      |\n",
      "|    time_elapsed    | 8900      |\n",
      "|    total_timesteps | 4870144   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 365          |\n",
      "|    ep_rew_mean          | -4.18e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 2379         |\n",
      "|    time_elapsed         | 8902         |\n",
      "|    total_timesteps      | 4872192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036247603 |\n",
      "|    clip_fraction        | 0.0244       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.396        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.62e+06     |\n",
      "|    n_updates            | 23780        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.67e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 366          |\n",
      "|    ep_rew_mean          | -4.12e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 2380         |\n",
      "|    time_elapsed         | 8904         |\n",
      "|    total_timesteps      | 4874240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057986965 |\n",
      "|    clip_fraction        | 0.0344       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.88e+07     |\n",
      "|    n_updates            | 23790        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.91e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4875000, episode_reward=-32895.23 +/- 35252.39\n",
      "Episode length: 372.60 +/- 25.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 373          |\n",
      "|    mean_reward          | -3.29e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4875000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032745395 |\n",
      "|    clip_fraction        | 0.0188       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.13e+07     |\n",
      "|    n_updates            | 23800        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.39e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 360       |\n",
      "|    ep_rew_mean     | -4.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 547       |\n",
      "|    iterations      | 2381      |\n",
      "|    time_elapsed    | 8907      |\n",
      "|    total_timesteps | 4876288   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 353         |\n",
      "|    ep_rew_mean          | -4.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 547         |\n",
      "|    iterations           | 2382        |\n",
      "|    time_elapsed         | 8909        |\n",
      "|    total_timesteps      | 4878336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004950744 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+07    |\n",
      "|    n_updates            | 23810       |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.19e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4880000, episode_reward=-53708.53 +/- 14395.70\n",
      "Episode length: 342.60 +/- 26.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 343          |\n",
      "|    mean_reward          | -5.37e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033386687 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.349        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.87e+07     |\n",
      "|    n_updates            | 23820        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 5.09e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 350       |\n",
      "|    ep_rew_mean     | -4.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 547       |\n",
      "|    iterations      | 2383      |\n",
      "|    time_elapsed    | 8911      |\n",
      "|    total_timesteps | 4880384   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 350        |\n",
      "|    ep_rew_mean          | -4.19e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 547        |\n",
      "|    iterations           | 2384       |\n",
      "|    time_elapsed         | 8913       |\n",
      "|    total_timesteps      | 4882432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01579639 |\n",
      "|    clip_fraction        | 0.0526     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.76       |\n",
      "|    explained_variance   | 0.416      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.03e+07   |\n",
      "|    n_updates            | 23830      |\n",
      "|    policy_gradient_loss | -0.0049    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 3.28e+07   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 354          |\n",
      "|    ep_rew_mean          | -4.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 547          |\n",
      "|    iterations           | 2385         |\n",
      "|    time_elapsed         | 8915         |\n",
      "|    total_timesteps      | 4884480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041862726 |\n",
      "|    clip_fraction        | 0.0452       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.477        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.29e+06     |\n",
      "|    n_updates            | 23840        |\n",
      "|    policy_gradient_loss | -0.00332     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.28e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4885000, episode_reward=-38579.61 +/- 24990.51\n",
      "Episode length: 352.40 +/- 34.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 352          |\n",
      "|    mean_reward          | -3.86e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4885000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033905162 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.44e+07     |\n",
      "|    n_updates            | 23850        |\n",
      "|    policy_gradient_loss | -0.00644     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.23e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 342       |\n",
      "|    ep_rew_mean     | -4.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 547       |\n",
      "|    iterations      | 2386      |\n",
      "|    time_elapsed    | 8918      |\n",
      "|    total_timesteps | 4886528   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 344         |\n",
      "|    ep_rew_mean          | -4.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 548         |\n",
      "|    iterations           | 2387        |\n",
      "|    time_elapsed         | 8919        |\n",
      "|    total_timesteps      | 4888576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008748195 |\n",
      "|    clip_fraction        | 0.0415      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+07    |\n",
      "|    n_updates            | 23860       |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.81e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4890000, episode_reward=-48494.97 +/- 4209.35\n",
      "Episode length: 343.40 +/- 29.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 343         |\n",
      "|    mean_reward          | -4.85e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006198421 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.05e+07    |\n",
      "|    n_updates            | 23870       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.78e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 343       |\n",
      "|    ep_rew_mean     | -4.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 548       |\n",
      "|    iterations      | 2388      |\n",
      "|    time_elapsed    | 8922      |\n",
      "|    total_timesteps | 4890624   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 345          |\n",
      "|    ep_rew_mean          | -4.52e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 2389         |\n",
      "|    time_elapsed         | 8924         |\n",
      "|    total_timesteps      | 4892672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057231598 |\n",
      "|    clip_fraction        | 0.055        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.436        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.29e+07     |\n",
      "|    n_updates            | 23880        |\n",
      "|    policy_gradient_loss | -0.000378    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.35e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 343         |\n",
      "|    ep_rew_mean          | -4.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 548         |\n",
      "|    iterations           | 2390        |\n",
      "|    time_elapsed         | 8926        |\n",
      "|    total_timesteps      | 4894720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003487671 |\n",
      "|    clip_fraction        | 0.0246      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.67e+07    |\n",
      "|    n_updates            | 23890       |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.98e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4895000, episode_reward=-50925.45 +/- 20239.23\n",
      "Episode length: 354.80 +/- 31.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 355          |\n",
      "|    mean_reward          | -5.09e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4895000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062976615 |\n",
      "|    clip_fraction        | 0.0502       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.431        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.71e+06     |\n",
      "|    n_updates            | 23900        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.1e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 345       |\n",
      "|    ep_rew_mean     | -4.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 548       |\n",
      "|    iterations      | 2391      |\n",
      "|    time_elapsed    | 8928      |\n",
      "|    total_timesteps | 4896768   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 346         |\n",
      "|    ep_rew_mean          | -4.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 548         |\n",
      "|    iterations           | 2392        |\n",
      "|    time_elapsed         | 8930        |\n",
      "|    total_timesteps      | 4898816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006622253 |\n",
      "|    clip_fraction        | 0.0605      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.55e+06    |\n",
      "|    n_updates            | 23910       |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.32e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4900000, episode_reward=-48374.89 +/- 26527.73\n",
      "Episode length: 339.00 +/- 47.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 339          |\n",
      "|    mean_reward          | -4.84e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4900000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050405613 |\n",
      "|    clip_fraction        | 0.0424       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.484        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.37e+07     |\n",
      "|    n_updates            | 23920        |\n",
      "|    policy_gradient_loss | -0.00336     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.7e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 339       |\n",
      "|    ep_rew_mean     | -4.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 548       |\n",
      "|    iterations      | 2393      |\n",
      "|    time_elapsed    | 8933      |\n",
      "|    total_timesteps | 4900864   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 343          |\n",
      "|    ep_rew_mean          | -4.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 2394         |\n",
      "|    time_elapsed         | 8935         |\n",
      "|    total_timesteps      | 4902912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061252834 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11e+07     |\n",
      "|    n_updates            | 23930        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.6e+07      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 344          |\n",
      "|    ep_rew_mean          | -4.34e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 548          |\n",
      "|    iterations           | 2395         |\n",
      "|    time_elapsed         | 8936         |\n",
      "|    total_timesteps      | 4904960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035753178 |\n",
      "|    clip_fraction        | 0.0159       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.408        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.31e+07     |\n",
      "|    n_updates            | 23940        |\n",
      "|    policy_gradient_loss | -0.00138     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.55e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4905000, episode_reward=-73121.33 +/- 18795.38\n",
      "Episode length: 342.00 +/- 34.96\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 342          |\n",
      "|    mean_reward          | -7.31e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4905000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062028607 |\n",
      "|    clip_fraction        | 0.0503       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.408        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.34e+07     |\n",
      "|    n_updates            | 23950        |\n",
      "|    policy_gradient_loss | -0.00579     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.14e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 341       |\n",
      "|    ep_rew_mean     | -4.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 548       |\n",
      "|    iterations      | 2396      |\n",
      "|    time_elapsed    | 8939      |\n",
      "|    total_timesteps | 4907008   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 343          |\n",
      "|    ep_rew_mean          | -4.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 549          |\n",
      "|    iterations           | 2397         |\n",
      "|    time_elapsed         | 8941         |\n",
      "|    total_timesteps      | 4909056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045369235 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.64e+07     |\n",
      "|    n_updates            | 23960        |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.12e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4910000, episode_reward=-55195.35 +/- 17095.15\n",
      "Episode length: 319.00 +/- 37.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 319         |\n",
      "|    mean_reward          | -5.52e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008128239 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.52e+07    |\n",
      "|    n_updates            | 23970       |\n",
      "|    policy_gradient_loss | -0.00543    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.64e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 348       |\n",
      "|    ep_rew_mean     | -4.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 549       |\n",
      "|    iterations      | 2398      |\n",
      "|    time_elapsed    | 8943      |\n",
      "|    total_timesteps | 4911104   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | -4.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 549         |\n",
      "|    iterations           | 2399        |\n",
      "|    time_elapsed         | 8945        |\n",
      "|    total_timesteps      | 4913152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005995266 |\n",
      "|    clip_fraction        | 0.0555      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.41e+07    |\n",
      "|    n_updates            | 23980       |\n",
      "|    policy_gradient_loss | -0.00434    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.1e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4915000, episode_reward=-62413.21 +/- 22504.88\n",
      "Episode length: 331.80 +/- 30.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 332          |\n",
      "|    mean_reward          | -6.24e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4915000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042532226 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.438        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06e+07     |\n",
      "|    n_updates            | 23990        |\n",
      "|    policy_gradient_loss | -0.000817    |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.65e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 349       |\n",
      "|    ep_rew_mean     | -4.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 549       |\n",
      "|    iterations      | 2400      |\n",
      "|    time_elapsed    | 8948      |\n",
      "|    total_timesteps | 4915200   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 345          |\n",
      "|    ep_rew_mean          | -4.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 549          |\n",
      "|    iterations           | 2401         |\n",
      "|    time_elapsed         | 8950         |\n",
      "|    total_timesteps      | 4917248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039056065 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+07     |\n",
      "|    n_updates            | 24000        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.84e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | -4.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 549         |\n",
      "|    iterations           | 2402        |\n",
      "|    time_elapsed         | 8952        |\n",
      "|    total_timesteps      | 4919296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005122154 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.1e+07     |\n",
      "|    n_updates            | 24010       |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.28e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4920000, episode_reward=-58621.64 +/- 17224.47\n",
      "Episode length: 301.20 +/- 20.56\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 301          |\n",
      "|    mean_reward          | -5.86e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4920000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047933436 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.72e+07     |\n",
      "|    n_updates            | 24020        |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.6e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 347       |\n",
      "|    ep_rew_mean     | -4.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 549       |\n",
      "|    iterations      | 2403      |\n",
      "|    time_elapsed    | 8954      |\n",
      "|    total_timesteps | 4921344   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 345          |\n",
      "|    ep_rew_mean          | -4.21e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 549          |\n",
      "|    iterations           | 2404         |\n",
      "|    time_elapsed         | 8956         |\n",
      "|    total_timesteps      | 4923392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044374047 |\n",
      "|    clip_fraction        | 0.036        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.452        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.41e+06     |\n",
      "|    n_updates            | 24030        |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.69e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4925000, episode_reward=-54155.72 +/- 21552.25\n",
      "Episode length: 327.80 +/- 37.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 328          |\n",
      "|    mean_reward          | -5.42e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4925000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038904455 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.507        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.97e+07     |\n",
      "|    n_updates            | 24040        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.73e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 343       |\n",
      "|    ep_rew_mean     | -4.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 549       |\n",
      "|    iterations      | 2405      |\n",
      "|    time_elapsed    | 8959      |\n",
      "|    total_timesteps | 4925440   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 344          |\n",
      "|    ep_rew_mean          | -3.94e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 549          |\n",
      "|    iterations           | 2406         |\n",
      "|    time_elapsed         | 8960         |\n",
      "|    total_timesteps      | 4927488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0116518345 |\n",
      "|    clip_fraction        | 0.0596       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17e+07     |\n",
      "|    n_updates            | 24050        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.22e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 342          |\n",
      "|    ep_rew_mean          | -3.93e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 2407         |\n",
      "|    time_elapsed         | 8962         |\n",
      "|    total_timesteps      | 4929536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067188535 |\n",
      "|    clip_fraction        | 0.0742       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.501        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05e+07     |\n",
      "|    n_updates            | 24060        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.52e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4930000, episode_reward=-59483.13 +/- 19321.80\n",
      "Episode length: 304.00 +/- 27.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 304         |\n",
      "|    mean_reward          | -5.95e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004414353 |\n",
      "|    clip_fraction        | 0.0325      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+07    |\n",
      "|    n_updates            | 24070       |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.39e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 343       |\n",
      "|    ep_rew_mean     | -3.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 550       |\n",
      "|    iterations      | 2408      |\n",
      "|    time_elapsed    | 8965      |\n",
      "|    total_timesteps | 4931584   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 345         |\n",
      "|    ep_rew_mean          | -3.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 2409        |\n",
      "|    time_elapsed         | 8967        |\n",
      "|    total_timesteps      | 4933632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007967699 |\n",
      "|    clip_fraction        | 0.0599      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16e+06    |\n",
      "|    n_updates            | 24080       |\n",
      "|    policy_gradient_loss | 0.00244     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.86e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4935000, episode_reward=-58069.19 +/- 21279.45\n",
      "Episode length: 305.80 +/- 29.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 306          |\n",
      "|    mean_reward          | -5.81e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4935000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045331726 |\n",
      "|    clip_fraction        | 0.0286       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.531        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.57e+06     |\n",
      "|    n_updates            | 24090        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.09e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 346       |\n",
      "|    ep_rew_mean     | -4.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 550       |\n",
      "|    iterations      | 2410      |\n",
      "|    time_elapsed    | 8969      |\n",
      "|    total_timesteps | 4935680   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 352         |\n",
      "|    ep_rew_mean          | -4.19e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 2411        |\n",
      "|    time_elapsed         | 8971        |\n",
      "|    total_timesteps      | 4937728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003784813 |\n",
      "|    clip_fraction        | 0.0351      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+07    |\n",
      "|    n_updates            | 24100       |\n",
      "|    policy_gradient_loss | -0.00427    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.77e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 347         |\n",
      "|    ep_rew_mean          | -4.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 2412        |\n",
      "|    time_elapsed         | 8973        |\n",
      "|    total_timesteps      | 4939776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005972421 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.03e+07    |\n",
      "|    n_updates            | 24110       |\n",
      "|    policy_gradient_loss | -0.00455    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.16e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4940000, episode_reward=-49041.51 +/- 21101.34\n",
      "Episode length: 303.60 +/- 37.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 304         |\n",
      "|    mean_reward          | -4.9e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010668244 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.49e+07    |\n",
      "|    n_updates            | 24120       |\n",
      "|    policy_gradient_loss | -0.00336    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 4.1e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 344       |\n",
      "|    ep_rew_mean     | -4.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 550       |\n",
      "|    iterations      | 2413      |\n",
      "|    time_elapsed    | 8975      |\n",
      "|    total_timesteps | 4941824   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 337         |\n",
      "|    ep_rew_mean          | -4.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 550         |\n",
      "|    iterations           | 2414        |\n",
      "|    time_elapsed         | 8977        |\n",
      "|    total_timesteps      | 4943872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016610282 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78e+07    |\n",
      "|    n_updates            | 24130       |\n",
      "|    policy_gradient_loss | 0.0149      |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.09e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4945000, episode_reward=-44453.47 +/- 22139.86\n",
      "Episode length: 302.40 +/- 34.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 302         |\n",
      "|    mean_reward          | -4.45e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4945000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004809875 |\n",
      "|    clip_fraction        | 0.047       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.66e+07    |\n",
      "|    n_updates            | 24140       |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.44e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 334       |\n",
      "|    ep_rew_mean     | -4.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 550       |\n",
      "|    iterations      | 2415      |\n",
      "|    time_elapsed    | 8980      |\n",
      "|    total_timesteps | 4945920   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 335          |\n",
      "|    ep_rew_mean          | -3.94e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 550          |\n",
      "|    iterations           | 2416         |\n",
      "|    time_elapsed         | 8981         |\n",
      "|    total_timesteps      | 4947968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081574675 |\n",
      "|    clip_fraction        | 0.064        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.469        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.54e+06     |\n",
      "|    n_updates            | 24150        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2e+07        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4950000, episode_reward=-57040.21 +/- 25509.81\n",
      "Episode length: 315.00 +/- 41.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 315         |\n",
      "|    mean_reward          | -5.7e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013303321 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.71e+07    |\n",
      "|    n_updates            | 24160       |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.66e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 334       |\n",
      "|    ep_rew_mean     | -3.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 550       |\n",
      "|    iterations      | 2417      |\n",
      "|    time_elapsed    | 8984      |\n",
      "|    total_timesteps | 4950016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | -3.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 2418        |\n",
      "|    time_elapsed         | 8986        |\n",
      "|    total_timesteps      | 4952064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005303467 |\n",
      "|    clip_fraction        | 0.0465      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.552       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11e+07    |\n",
      "|    n_updates            | 24170       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.13e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 335         |\n",
      "|    ep_rew_mean          | -3.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 2419        |\n",
      "|    time_elapsed         | 8988        |\n",
      "|    total_timesteps      | 4954112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009316456 |\n",
      "|    clip_fraction        | 0.0451      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.587       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+05    |\n",
      "|    n_updates            | 24180       |\n",
      "|    policy_gradient_loss | 0.00161     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 6.02e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4955000, episode_reward=-58981.17 +/- 30215.71\n",
      "Episode length: 335.00 +/- 64.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 335         |\n",
      "|    mean_reward          | -5.9e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4955000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005820374 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.25e+07    |\n",
      "|    n_updates            | 24190       |\n",
      "|    policy_gradient_loss | -0.000164   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.52e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 336      |\n",
      "|    ep_rew_mean     | -3.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 551      |\n",
      "|    iterations      | 2420     |\n",
      "|    time_elapsed    | 8990     |\n",
      "|    total_timesteps | 4956160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 335         |\n",
      "|    ep_rew_mean          | -3.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 2421        |\n",
      "|    time_elapsed         | 8992        |\n",
      "|    total_timesteps      | 4958208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006404947 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+07    |\n",
      "|    n_updates            | 24200       |\n",
      "|    policy_gradient_loss | -0.00512    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.01e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4960000, episode_reward=-35128.75 +/- 12839.09\n",
      "Episode length: 287.00 +/- 5.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 287          |\n",
      "|    mean_reward          | -3.51e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042464416 |\n",
      "|    clip_fraction        | 0.0452       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.522        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+06     |\n",
      "|    n_updates            | 24210        |\n",
      "|    policy_gradient_loss | 0.0006       |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.79e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 334       |\n",
      "|    ep_rew_mean     | -3.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 551       |\n",
      "|    iterations      | 2422      |\n",
      "|    time_elapsed    | 8995      |\n",
      "|    total_timesteps | 4960256   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 335          |\n",
      "|    ep_rew_mean          | -3.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 551          |\n",
      "|    iterations           | 2423         |\n",
      "|    time_elapsed         | 8996         |\n",
      "|    total_timesteps      | 4962304      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038547304 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+07     |\n",
      "|    n_updates            | 24220        |\n",
      "|    policy_gradient_loss | -0.00353     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.03e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 333         |\n",
      "|    ep_rew_mean          | -3.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 2424        |\n",
      "|    time_elapsed         | 8998        |\n",
      "|    total_timesteps      | 4964352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008817695 |\n",
      "|    clip_fraction        | 0.0709      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.87e+07    |\n",
      "|    n_updates            | 24230       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.12e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4965000, episode_reward=-52143.74 +/- 19859.13\n",
      "Episode length: 330.20 +/- 37.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 330         |\n",
      "|    mean_reward          | -5.21e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4965000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003447182 |\n",
      "|    clip_fraction        | 0.0309      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.473       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.35e+06    |\n",
      "|    n_updates            | 24240       |\n",
      "|    policy_gradient_loss | -0.000765   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.31e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 329       |\n",
      "|    ep_rew_mean     | -3.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 551       |\n",
      "|    iterations      | 2425      |\n",
      "|    time_elapsed    | 9001      |\n",
      "|    total_timesteps | 4966400   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 328         |\n",
      "|    ep_rew_mean          | -3.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 551         |\n",
      "|    iterations           | 2426        |\n",
      "|    time_elapsed         | 9003        |\n",
      "|    total_timesteps      | 4968448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006556856 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.74e+06    |\n",
      "|    n_updates            | 24250       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.34e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4970000, episode_reward=-36381.65 +/- 11609.29\n",
      "Episode length: 296.40 +/- 18.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 296         |\n",
      "|    mean_reward          | -3.64e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004107049 |\n",
      "|    clip_fraction        | 0.0447      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.88e+06    |\n",
      "|    n_updates            | 24260       |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.12e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 323       |\n",
      "|    ep_rew_mean     | -3.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 551       |\n",
      "|    iterations      | 2427      |\n",
      "|    time_elapsed    | 9005      |\n",
      "|    total_timesteps | 4970496   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 326          |\n",
      "|    ep_rew_mean          | -3.35e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 552          |\n",
      "|    iterations           | 2428         |\n",
      "|    time_elapsed         | 9007         |\n",
      "|    total_timesteps      | 4972544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031277507 |\n",
      "|    clip_fraction        | 0.0533       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.83e+06     |\n",
      "|    n_updates            | 24270        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.03e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 329         |\n",
      "|    ep_rew_mean          | -3.19e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 552         |\n",
      "|    iterations           | 2429        |\n",
      "|    time_elapsed         | 9009        |\n",
      "|    total_timesteps      | 4974592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006150563 |\n",
      "|    clip_fraction        | 0.0488      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3e+07     |\n",
      "|    n_updates            | 24280       |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.21e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4975000, episode_reward=-28084.10 +/- 12850.17\n",
      "Episode length: 345.60 +/- 70.97\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 346          |\n",
      "|    mean_reward          | -2.81e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4975000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040163724 |\n",
      "|    clip_fraction        | 0.0494       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.97e+06     |\n",
      "|    n_updates            | 24290        |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.27e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 331       |\n",
      "|    ep_rew_mean     | -3.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 552       |\n",
      "|    iterations      | 2430      |\n",
      "|    time_elapsed    | 9011      |\n",
      "|    total_timesteps | 4976640   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 334         |\n",
      "|    ep_rew_mean          | -3.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 552         |\n",
      "|    iterations           | 2431        |\n",
      "|    time_elapsed         | 9013        |\n",
      "|    total_timesteps      | 4978688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012224996 |\n",
      "|    clip_fraction        | 0.0956      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.504       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.29e+06    |\n",
      "|    n_updates            | 24300       |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.94e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4980000, episode_reward=-58525.78 +/- 24890.42\n",
      "Episode length: 319.40 +/- 38.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 319         |\n",
      "|    mean_reward          | -5.85e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008051485 |\n",
      "|    clip_fraction        | 0.0724      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.62e+06    |\n",
      "|    n_updates            | 24310       |\n",
      "|    policy_gradient_loss | -0.00728    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.41e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 335       |\n",
      "|    ep_rew_mean     | -3.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 552       |\n",
      "|    iterations      | 2432      |\n",
      "|    time_elapsed    | 9016      |\n",
      "|    total_timesteps | 4980736   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 335          |\n",
      "|    ep_rew_mean          | -3.27e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 552          |\n",
      "|    iterations           | 2433         |\n",
      "|    time_elapsed         | 9018         |\n",
      "|    total_timesteps      | 4982784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037221243 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.541        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.04e+06     |\n",
      "|    n_updates            | 24320        |\n",
      "|    policy_gradient_loss | 0.000246     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.45e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 332       |\n",
      "|    ep_rew_mean          | -3.34e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 552       |\n",
      "|    iterations           | 2434      |\n",
      "|    time_elapsed         | 9020      |\n",
      "|    total_timesteps      | 4984832   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.006345  |\n",
      "|    clip_fraction        | 0.0428    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.74      |\n",
      "|    explained_variance   | 0.461     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.69e+07  |\n",
      "|    n_updates            | 24330     |\n",
      "|    policy_gradient_loss | -0.00235  |\n",
      "|    std                  | 0.207     |\n",
      "|    value_loss           | 3.24e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4985000, episode_reward=-38263.42 +/- 30412.89\n",
      "Episode length: 354.00 +/- 57.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 354          |\n",
      "|    mean_reward          | -3.83e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4985000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043458967 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.523        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.24e+06     |\n",
      "|    n_updates            | 24340        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.43e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 330      |\n",
      "|    ep_rew_mean     | -3.4e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 552      |\n",
      "|    iterations      | 2435     |\n",
      "|    time_elapsed    | 9022     |\n",
      "|    total_timesteps | 4986880  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 327          |\n",
      "|    ep_rew_mean          | -3.53e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 552          |\n",
      "|    iterations           | 2436         |\n",
      "|    time_elapsed         | 9024         |\n",
      "|    total_timesteps      | 4988928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062925788 |\n",
      "|    clip_fraction        | 0.0426       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.481        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+07     |\n",
      "|    n_updates            | 24350        |\n",
      "|    policy_gradient_loss | -0.00468     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.81e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4990000, episode_reward=-47835.02 +/- 21628.45\n",
      "Episode length: 297.60 +/- 23.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 298         |\n",
      "|    mean_reward          | -4.78e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4990000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010655288 |\n",
      "|    clip_fraction        | 0.069       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+07     |\n",
      "|    n_updates            | 24360       |\n",
      "|    policy_gradient_loss | 0.00307     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.88e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 327       |\n",
      "|    ep_rew_mean     | -3.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 552       |\n",
      "|    iterations      | 2437      |\n",
      "|    time_elapsed    | 9027      |\n",
      "|    total_timesteps | 4990976   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 330          |\n",
      "|    ep_rew_mean          | -3.5e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 553          |\n",
      "|    iterations           | 2438         |\n",
      "|    time_elapsed         | 9028         |\n",
      "|    total_timesteps      | 4993024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057712956 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+07      |\n",
      "|    n_updates            | 24370        |\n",
      "|    policy_gradient_loss | -0.00301     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.5e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4995000, episode_reward=-53764.27 +/- 18289.28\n",
      "Episode length: 334.40 +/- 42.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 334          |\n",
      "|    mean_reward          | -5.38e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4995000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052815694 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.47e+06     |\n",
      "|    n_updates            | 24380        |\n",
      "|    policy_gradient_loss | -0.00465     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.7e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 328       |\n",
      "|    ep_rew_mean     | -3.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 553       |\n",
      "|    iterations      | 2439      |\n",
      "|    time_elapsed    | 9031      |\n",
      "|    total_timesteps | 4995072   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 327         |\n",
      "|    ep_rew_mean          | -3.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 553         |\n",
      "|    iterations           | 2440        |\n",
      "|    time_elapsed         | 9033        |\n",
      "|    total_timesteps      | 4997120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004188276 |\n",
      "|    clip_fraction        | 0.0154      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.44        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27e+07    |\n",
      "|    n_updates            | 24390       |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.69e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 330         |\n",
      "|    ep_rew_mean          | -3.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 553         |\n",
      "|    iterations           | 2441        |\n",
      "|    time_elapsed         | 9035        |\n",
      "|    total_timesteps      | 4999168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006169839 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.74        |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.85e+06    |\n",
      "|    n_updates            | 24400       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.96e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5000000, episode_reward=-60110.87 +/- 30013.06\n",
      "Episode length: 346.20 +/- 37.51\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 346          |\n",
      "|    mean_reward          | -6.01e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075780884 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.74         |\n",
      "|    explained_variance   | 0.539        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.37e+06     |\n",
      "|    n_updates            | 24410        |\n",
      "|    policy_gradient_loss | -0.00591     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.59e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 330       |\n",
      "|    ep_rew_mean     | -3.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 553       |\n",
      "|    iterations      | 2442      |\n",
      "|    time_elapsed    | 9037      |\n",
      "|    total_timesteps | 5001216   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f6c2560a3c8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps = 5_000_000, callback = eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path + '/ppo_jl_ramp_jump_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"/home/bmsit/Ascento/jointed_limited/Training/model_for_demo.zip\", env = env)\n",
    "\n",
    "# #JL_10 -> STAYS AT SET POINT BUT KEEPS ON SPININING VERY VERY FAST\n",
    "# #JL_10_Best -> spins a bit slowly\n",
    "\n",
    "# # JL_11 -> MOVES AROUND, ALSO BENDS 1 LEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes = 30, render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n",
      "-0.0022270351445141867\n",
      "-0.09346595109841264\n",
      "-0.16100791757902005\n",
      "-0.13513593279792058\n",
      "-0.21833290118531834\n",
      "-0.2600217149798773\n",
      "-0.29824672778180455\n",
      "-0.20988890397500445\n",
      "-0.25635349951773856\n",
      "-0.2612076480325469\n",
      "-0.30100317379716324\n",
      "-0.2926429393739511\n",
      "-0.2377849501152849\n",
      "-0.1847871704048374\n",
      "-0.14017304960458898\n",
      "-0.2881502929996477\n",
      "-0.2302956496045851\n",
      "-0.142822005818177\n",
      "-0.12777105503597352\n",
      "-0.12122647369112423\n",
      "-0.12988144982250016\n",
      "-0.16727169878761303\n",
      "-0.23502189681839958\n",
      "-0.22172414393297346\n",
      "-0.13567356414239906\n",
      "-0.19298096749219132\n",
      "-0.15439240484430633\n",
      "-0.09624615654834343\n",
      "-0.06397313024143417\n",
      "-0.015436323199980995\n",
      "-0.0810567596602844\n",
      "-0.09095099521878353\n",
      "-0.09726737501119614\n",
      "0.0919724001036851\n",
      "0.018817778135910103\n",
      "-0.06189647746964532\n",
      "-0.015243821496955984\n",
      "-0.007640804452414246\n",
      "-0.006856736470168042\n",
      "-0.054776637327228574\n",
      "-0.04876076740053765\n",
      "-0.005439413536311652\n",
      "0.0333387503772067\n",
      "0.03720906710439993\n",
      "-0.10843597224049102\n",
      "-0.031019590174433207\n",
      "-0.036732485351265776\n",
      "-0.05944768127406777\n",
      "-0.01718744968856388\n",
      "-0.17495086163693327\n",
      "-0.016094469019445695\n",
      "-0.04116292242693426\n",
      "-0.00657624672038323\n",
      "-0.03311519444903372\n",
      "-0.023973465930595815\n",
      "0.06202310357883982\n",
      "0.012988839019660503\n",
      "-0.08699451272007874\n",
      "-0.07288060119616402\n",
      "0.013820153939962589\n",
      "-0.006004492509463688\n",
      "-0.14515084505420678\n",
      "0.008754785238707277\n",
      "-0.06548495561491317\n",
      "0.03477273391758606\n",
      "0.07033577257906164\n",
      "-0.11807963184570242\n",
      "-0.13923026438981326\n",
      "0.03966209157130224\n",
      "-0.09196574254258312\n",
      "0.02768482678810511\n",
      "-0.00922787530898006\n",
      "0.07743799336318893\n",
      "-0.012029398713797997\n",
      "0.03292686727274327\n",
      "-0.10412119189318211\n",
      "-0.07193291906223509\n",
      "-0.06407655505457772\n",
      "-0.02982825987344351\n",
      "-0.12165354288729313\n",
      "-0.0371779666574959\n",
      "-0.10225756765229044\n",
      "-0.17716896724774414\n",
      "-0.19200442319844427\n",
      "-0.08606026263345899\n",
      "-0.10904553765482156\n",
      "-0.06487835539300589\n",
      "-0.14482143179049772\n",
      "-0.14051333911609776\n",
      "-0.11889273289982139\n",
      "-0.20752541097342037\n",
      "-0.15787004171679628\n",
      "-0.05389136036697029\n",
      "-0.2609141331842871\n",
      "-0.17480947075219638\n",
      "-0.21616089324590648\n",
      "-0.18802433181310432\n",
      "-0.12104953318599443\n",
      "-0.27878206517409454\n",
      "-0.28955235920893413\n",
      "-0.3661060132880011\n",
      "-0.14790357912620516\n",
      "-0.19424599004505427\n",
      "-0.25601299993158166\n",
      "-0.2946841836236492\n",
      "-0.30586466148149427\n",
      "-0.27675025196770636\n",
      "-0.25153806985001337\n",
      "-0.25400650750569187\n",
      "-0.14494071340938863\n",
      "-0.30159213764851966\n",
      "-0.34088713402770715\n",
      "-0.3325325860971261\n",
      "-0.21429459185933153\n",
      "-0.24387819795849225\n",
      "-0.25846782017919306\n",
      "-0.31926816316246825\n",
      "-0.3269364738377301\n",
      "-0.4228366077667726\n",
      "-0.38678277529351535\n",
      "-0.20237125743164625\n",
      "-0.33584664274626314\n",
      "-0.36801572470003346\n",
      "-0.3960467722106998\n",
      "-0.27496012358643085\n",
      "-0.389817945635951\n",
      "-0.3224772793703349\n",
      "-0.33308321940488483\n",
      "-0.3015095972197638\n",
      "-0.340887821118928\n",
      "-0.4218349620555034\n",
      "-0.29834982642561136\n",
      "-0.3714957091490286\n",
      "-0.4250302707188748\n",
      "-0.4685348630613589\n",
      "-0.4574590155755664\n",
      "-0.369285076242883\n",
      "-0.4024917826570219\n",
      "-0.37713230798564973\n",
      "-0.4347884717612185\n",
      "-0.4414564126473618\n",
      "-0.3887151750347082\n",
      "-0.45405878394590843\n",
      "-0.35526532708146513\n",
      "-0.42275896937523755\n",
      "-0.48463591391147043\n",
      "-0.4097209263398251\n",
      "-0.4235990453230191\n",
      "-0.42720713966108864\n",
      "-0.44586964941253343\n",
      "-0.43772028592779605\n",
      "-0.47280539901243773\n",
      "-0.421862062906934\n",
      "-0.49701794725067283\n",
      "-0.5318237720626904\n",
      "-0.5550253728619273\n",
      "-0.5134581074131157\n",
      "-0.47215001211607355\n",
      "-0.4841138974469813\n",
      "-0.5047395028628863\n",
      "-0.508873030503019\n",
      "-0.4567844956086625\n",
      "-0.4469819566034023\n",
      "-0.46857399211915857\n",
      "-0.46299822086222553\n",
      "-0.5506747830798567\n",
      "-0.422242309468695\n",
      "-0.588441265021349\n",
      "-0.5484435205101995\n",
      "-0.5673280485502804\n",
      "-0.5264266199877071\n",
      "-0.5186269062260007\n",
      "-0.5093379945129373\n",
      "-0.4599808891342427\n",
      "-0.5474017803725054\n",
      "-0.5624704449999339\n",
      "-0.5238902155390569\n",
      "-0.44044641333824786\n",
      "-0.601141082973932\n",
      "-0.6508806880192821\n",
      "-0.4819234007485099\n",
      "-0.5934164313687282\n",
      "-0.5095304135492077\n",
      "-0.49171877135382913\n",
      "-0.5809663515545629\n",
      "-0.440808455452657\n",
      "-0.4848673006978275\n",
      "-0.4827062874059085\n",
      "-0.5828311216014586\n",
      "-0.47497033494748014\n",
      "-0.5520549136864829\n",
      "-0.5387299657424126\n",
      "-0.623163709244239\n",
      "-0.7096480619778753\n",
      "-0.681329189414395\n",
      "-0.663090195228975\n",
      "-0.7397068253452206\n",
      "-0.6761568018635574\n",
      "-0.6331203849456594\n",
      "-0.6397821021056196\n",
      "-0.6784170427186634\n",
      "-0.5457311638547341\n",
      "-0.6311604924247264\n",
      "-0.5242599320568907\n",
      "-0.4912354422747658\n",
      "-0.5758998070962422\n",
      "-0.5567414114541436\n",
      "-0.6330276483396297\n",
      "-0.5969595253820535\n",
      "-0.6092541734673236\n",
      "-0.6659240295124162\n",
      "-0.6854117794573251\n",
      "-0.5912196675324477\n",
      "-0.5240237235985072\n",
      "-0.5986817945719302\n",
      "-0.6409418715928374\n",
      "-0.6465088186125036\n",
      "-0.693575294398893\n",
      "-0.6151286438025234\n",
      "-0.7078749774557902\n",
      "-0.6496383615435974\n",
      "-0.6560905008620964\n",
      "-0.7029487769380925\n",
      "-0.582973979156779\n",
      "-0.7052468730334507\n",
      "-0.6812097928050574\n",
      "-0.7335980096341425\n",
      "-0.6927786482957436\n",
      "-0.6770498762186401\n",
      "-0.6934980693029825\n",
      "-0.7218637451199987\n",
      "-0.6277212587868075\n",
      "-0.732523469101675\n",
      "-0.6348874638309565\n",
      "-0.6441703509767145\n",
      "-0.760054319623729\n",
      "-0.7390105103472608\n",
      "-0.7936681364039326\n",
      "-0.821400066719063\n",
      "-0.6999684862298877\n",
      "-0.688820706503737\n",
      "-0.7060523065210247\n",
      "-0.763174833719472\n",
      "-0.8437428211682056\n",
      "-0.858414499017384\n",
      "-0.8705346235845194\n",
      "-0.7995860132758456\n",
      "-0.7308810018831237\n",
      "-0.6383919064259744\n",
      "-0.6105873354436947\n",
      "-0.6175920221167297\n",
      "-0.599504321522839\n",
      "-0.7233300744027238\n",
      "-0.6200683563344008\n",
      "-0.6686421869108833\n",
      "-0.6859876630934176\n",
      "-0.6897632828760875\n",
      "-0.6893511172924769\n",
      "-0.766878810175507\n",
      "-0.7445496700892\n",
      "-0.71379402738865\n",
      "-0.7041863584454241\n",
      "-0.6839837374547085\n",
      "-0.8610671442211111\n",
      "-0.85224904417959\n",
      "-0.809359525990518\n",
      "-0.718794756508796\n",
      "-0.7938157805383788\n",
      "-0.7414776178078487\n",
      "-0.7784737480983408\n",
      "-0.6981326388666022\n",
      "-0.7900708663849918\n",
      "-0.7395264610799055\n",
      "-0.7318842778226002\n",
      "-0.7097091439962315\n",
      "-0.7564809404129532\n",
      "-0.6979418337736459\n",
      "-0.6630043400089324\n",
      "-0.8121252359380083\n",
      "-0.8015491223197523\n",
      "-0.765640171263641\n",
      "-0.7528120252405421\n",
      "-0.8689154010813785\n",
      "-0.8345817806741823\n",
      "-0.8892315112290048\n",
      "-0.7780876307993321\n",
      "-0.8735506018159486\n",
      "-0.8426422152023367\n",
      "-0.7740410434063324\n",
      "-0.7751328291272331\n",
      "-0.748648445663656\n",
      "-0.7714582369351015\n",
      "-0.8839796025859717\n",
      "-0.7789545926041721\n",
      "-0.8058489433698103\n",
      "-0.8099174467789995\n",
      "-0.8285397869784076\n",
      "-0.8622413294237565\n",
      "-0.8216422644113711\n",
      "-0.802773860825658\n",
      "-0.8762556508015429\n",
      "-0.816376594547512\n",
      "-0.9539819189489398\n",
      "-0.980430715961669\n",
      "-0.8857827728596802\n",
      "-0.8767802364652583\n",
      "-0.7546171625474132\n",
      "-0.8384685297456673\n",
      "-0.8429650862088331\n",
      "-0.7980748727979984\n",
      "-0.7601073705451618\n",
      "-0.833771600215511\n",
      "-0.7144423143370131\n",
      "-0.822704182997164\n",
      "-0.8139868119969811\n",
      "-0.8534558616393828\n",
      "-0.8676567990584833\n",
      "-0.802915751535816\n",
      "-0.9017349026104747\n",
      "-0.8876644437192291\n",
      "-0.8315121460049769\n",
      "-0.8037018985888883\n",
      "-0.8670265895373018\n",
      "-0.9217419512050353\n",
      "-0.8569689655563356\n",
      "-0.902685595391836\n",
      "-0.8231989294303623\n",
      "-0.7982592793218384\n",
      "-0.8826104786634662\n",
      "-0.8536182310148124\n",
      "-0.8646746424606783\n",
      "-0.876314115659643\n",
      "-0.8958720594306523\n",
      "-0.956789990103808\n",
      "-0.9086308653606067\n",
      "-0.8342497977996927\n",
      "-0.8201194518158712\n",
      "-0.864726790507572\n",
      "-0.8164139453895044\n",
      "-0.8445840741379642\n",
      "-0.9265043323044587\n",
      "-0.8135770939694209\n",
      "-0.8267808608613834\n",
      "-0.7404045693880866\n",
      "-0.8533262946835783\n",
      "-0.8280734112027687\n",
      "-0.7808221711536357\n",
      "-0.767090404484364\n",
      "-0.8457021104403443\n",
      "-0.7643006375847391\n",
      "-0.814929959710568\n",
      "-0.91463112838117\n",
      "-0.8201449910257714\n",
      "-0.9501092162022303\n",
      "-0.8298300416883058\n",
      "-0.8021898494555043\n",
      "-0.789820597221386\n",
      "-0.7939731178725903\n",
      "-0.8669945070378231\n",
      "-0.9338845536633775\n",
      "-0.9399486219812978\n",
      "-0.843626581389437\n",
      "-0.9655749164911293\n",
      "-0.9170646674059634\n",
      "-0.8526575313303961\n",
      "-0.8583883969015966\n",
      "-0.7798824714535417\n",
      "-0.8099000103910855\n",
      "-0.8705316255602652\n",
      "-0.8728139440440043\n",
      "-0.9120219121108802\n",
      "-0.8167047197469355\n",
      "-0.8522911739151243\n",
      "-0.8379820448995005\n",
      "-0.9252664253161024\n",
      "-0.8355696613541259\n",
      "-0.9084435644476112\n",
      "-0.8205780486238238\n",
      "-0.8777830688505883\n",
      "-0.9338316256775518\n",
      "-0.7626222376945739\n",
      "-0.8160191040539894\n",
      "-0.8615635107577797\n",
      "-0.9487348708862992\n",
      "-0.9317659714956334\n",
      "-0.8316977626422056\n",
      "-0.8248441532945724\n",
      "-0.834263032098146\n",
      "-0.7596707638853276\n",
      "-0.900808949649178\n",
      "-0.9607153663796196\n",
      "-0.9239539183031782\n",
      "-0.952808904832219\n",
      "-1.0023553488171406\n",
      "-0.9097034887274627\n",
      "-0.8045562723355174\n",
      "-0.9256171223605919\n",
      "-0.8393327498493702\n",
      "-0.9332542816271062\n",
      "-0.8197558905919534\n",
      "-0.8431471028602637\n",
      "-0.8283462125050834\n",
      "-0.8716434694406981\n",
      "-0.8587807240158467\n",
      "-0.8849591276309492\n",
      "-0.8444698070889582\n",
      "-0.8658475859651238\n",
      "-0.8549920140476859\n",
      "-0.9091707504240113\n",
      "-0.9346855435036666\n",
      "-0.9129765740564024\n",
      "-0.9480881767708805\n",
      "-0.9050529732354659\n",
      "-0.8493901334831615\n",
      "-0.9468246124989939\n",
      "-0.8643945193157946\n",
      "-0.864738787174031\n",
      "-0.7441931123359183\n",
      "-0.7988307415888946\n",
      "-0.8667551999818726\n",
      "-0.7639821046406987\n",
      "-0.8782504805714064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8505432020962984\n",
      "-0.8543548926142935\n",
      "-0.8569042407563889\n",
      "-0.8264650410706043\n",
      "-0.8207217847036509\n",
      "-0.8874357800056306\n",
      "-0.8408317857610573\n",
      "-0.9462510160210265\n",
      "-0.8795794464819793\n",
      "-0.9320077347748608\n",
      "-0.849568122955506\n",
      "-0.7834107019943929\n",
      "-0.8506369939831064\n",
      "-0.9446959051331464\n",
      "-0.8931031720538194\n",
      "-0.8408927555295553\n",
      "-0.9631437034738315\n",
      "-0.8829619921056516\n",
      "-0.9394278729991408\n",
      "-0.8743777494389511\n",
      "-0.8457255703780134\n",
      "-0.8990978716318053\n",
      "-0.9717578173096046\n",
      "-0.9026582849503312\n",
      "-0.881757653053093\n",
      "-0.9242921127448024\n",
      "-0.9209943688505343\n",
      "-0.8923426428124818\n",
      "-0.7840540175995611\n",
      "-0.8318954886935594\n",
      "-0.9130170576191616\n",
      "-0.8899281645659533\n",
      "-0.9471696163242129\n",
      "-0.8905046751634809\n",
      "-0.836048569065026\n",
      "-0.8123135653155826\n",
      "-0.8261119566364578\n",
      "-0.8551271507923638\n",
      "-0.8673874204432863\n",
      "-0.9789588748416038\n",
      "-0.8687781398394883\n",
      "-0.8623650445086349\n",
      "-0.827048014830759\n",
      "-0.74972479806628\n",
      "-0.773927227406592\n",
      "-0.7190373206000695\n",
      "-0.7608238119437033\n",
      "-0.7680287617918553\n",
      "-0.9248460639003699\n",
      "-0.8193423459721382\n",
      "-0.8336384636182365\n",
      "-0.7964839880111224\n",
      "-0.992840496140909\n",
      "-0.8829182176585427\n",
      "-0.8785244567536287\n",
      "-0.8559448454215038\n",
      "-0.8751161206585703\n",
      "-0.8448817476679749\n",
      "-0.6880133640379389\n",
      "-0.7539535852834762\n",
      "-0.6864623120311646\n",
      "-0.7726206233475253\n",
      "-0.7845056682094953\n",
      "-0.8281402642213112\n",
      "-0.9120876289039247\n",
      "-0.8566564437055462\n",
      "-0.7430957879559985\n",
      "-0.7828875600352808\n",
      "-0.7939989141267015\n",
      "-0.7537317063473625\n",
      "-0.8062449176361501\n",
      "-0.8019852678524095\n",
      "-0.8343679596098675\n",
      "-0.8430063041383128\n",
      "-0.7520403311996636\n",
      "-0.8377150707008679\n",
      "-0.8370243397430319\n",
      "-0.8918303780634456\n",
      "-0.8259768279025692\n",
      "-0.7824352329309079\n",
      "-0.7940975810204777\n",
      "-0.8037855215750239\n",
      "-0.6968143646097442\n",
      "-0.7230507818127642\n",
      "-0.8356925857053846\n",
      "-0.7704698878223212\n",
      "-0.7657768026619025\n",
      "-0.8093429788424691\n",
      "-0.968696183216365\n",
      "-0.9402919463366141\n",
      "-0.9212064744154355\n",
      "-0.8374044923804219\n",
      "-0.7939931948479165\n",
      "-0.7933032173788849\n",
      "-0.7501138632439524\n",
      "-0.7961084920898186\n",
      "-0.7443328346775274\n",
      "-0.785179310894239\n",
      "-0.8059866243794966\n",
      "-0.7649910038902134\n",
      "-0.8687301909014927\n",
      "-0.8529457634978798\n",
      "-0.8311034919716668\n",
      "-0.799677186569678\n",
      "-0.7388164403184508\n",
      "-0.7921814003905543\n",
      "-0.859541155471258\n",
      "-0.832463024918881\n",
      "-0.9473279392051905\n",
      "-0.839469276543506\n",
      "-0.8238066050804627\n",
      "-0.8320429646322316\n",
      "-0.7472379771387452\n",
      "-0.8237064372585512\n",
      "-0.838519383241406\n",
      "-0.8151872640888814\n",
      "-0.834185345866539\n",
      "-0.7890874115633698\n",
      "-0.7243456104689431\n",
      "-0.7237343494190688\n",
      "-0.8025971215783945\n",
      "-0.8431481187008399\n",
      "-0.7391388110595745\n",
      "-0.7041779799702574\n",
      "-0.7385198739594107\n",
      "-0.7044782637801144\n",
      "-0.8306673413839969\n",
      "-0.7430976655308871\n",
      "-0.8139857482784062\n",
      "-0.6850000794116601\n",
      "-0.7182014025426974\n",
      "-0.8033444685541801\n",
      "-0.8618727181144611\n",
      "-0.7330360398764721\n",
      "-0.7597899743332936\n",
      "-0.7549669254440539\n",
      "-0.8349038054466594\n",
      "-0.704318239790829\n",
      "-0.7858687237677798\n",
      "-0.7644467020296037\n",
      "-0.8638646540197723\n",
      "-0.8236732784615264\n",
      "-0.8319295268657343\n",
      "-0.8280576063517159\n",
      "-0.7648258705138243\n",
      "-0.7784427240909396\n",
      "-0.7964220570926115\n",
      "-0.7094466024178347\n",
      "-0.7363837683753112\n",
      "-0.7398400501414371\n",
      "-0.8333494267652027\n",
      "-0.7436289307004743\n",
      "-0.7700264723445898\n",
      "-0.676860944203597\n",
      "-0.6935037806760871\n",
      "-0.6461330141697821\n",
      "-0.820209319540175\n",
      "-0.7682629404211297\n",
      "-0.8306135194488783\n",
      "-0.8786499211455487\n",
      "-0.8722727278312064\n",
      "-0.7746115806070488\n",
      "-0.8113464823741626\n",
      "-0.753860764398977\n",
      "-0.7762798654795646\n",
      "-0.8118650810801668\n",
      "-0.9197133360760316\n",
      "-0.8788790191673441\n",
      "-0.8301169507906921\n",
      "-0.8746195503587556\n",
      "-0.7857243532326129\n",
      "-0.7239766678191669\n",
      "-0.8749626504860623\n",
      "-0.8090456741695662\n",
      "-0.76366125245639\n",
      "-0.7733344484891349\n",
      "-0.6860467715845503\n",
      "-0.7163271342154617\n",
      "-0.7297350276563007\n",
      "-0.6947641271477322\n",
      "-0.6001758544072598\n",
      "-0.663761549735747\n",
      "-0.7060961242325522\n",
      "-0.7099461961143668\n",
      "-0.7701529926183177\n",
      "-0.7636312961583238\n",
      "-0.7488441048269786\n",
      "-0.7619965787755855\n",
      "-0.8471379325511922\n",
      "-0.7839686696050672\n",
      "-0.5741473513996953\n",
      "-0.6367730931551518\n",
      "-0.7259013653450874\n",
      "-0.6602687909615554\n",
      "-0.7634925938562654\n",
      "-0.6713130767390109\n",
      "-0.6050877497642372\n",
      "-0.6809179627566412\n",
      "-0.7015021635079222\n",
      "-0.7149573487452783\n",
      "-0.7417256656401046\n",
      "-0.8065212657725307\n",
      "-0.7311666009251556\n",
      "-0.6838028762677929\n",
      "-0.6532657153730189\n",
      "-0.6556364139675956\n",
      "-0.680118916430671\n",
      "-0.6507209510653618\n",
      "-0.6297095747352127\n",
      "-0.5904191550314574\n",
      "-0.5766952437657606\n",
      "-0.6697320172922478\n",
      "-0.6960158410605425\n",
      "-0.7948037011530621\n",
      "-0.7736650624575899\n",
      "-0.798338868944588\n",
      "-0.6400108861368107\n",
      "-0.6489823031238459\n",
      "-0.6556057854715865\n",
      "-0.6848760612504834\n",
      "-0.6088401988796013\n",
      "-0.6265711311692378\n",
      "-0.7210632167939114\n",
      "-0.7093864128054337\n",
      "-0.7407588765274239\n",
      "-0.7117847606350672\n",
      "-0.7683166270773114\n",
      "-0.6749074567706246\n",
      "-0.7149582266623784\n",
      "-0.6089519225637353\n",
      "-0.6891329590136185\n",
      "-0.6684740235258894\n",
      "-0.7307179407001\n",
      "-0.7119872816521975\n",
      "-0.6581221150117834\n",
      "-0.6649567520654657\n",
      "-0.5737056988208573\n",
      "-0.6342748949043363\n",
      "-0.6157542331914115\n",
      "-0.6061959669986567\n",
      "-0.5268433008615099\n",
      "-0.6114750855514272\n",
      "-0.5740612894507837\n",
      "-0.7702953076222958\n",
      "-0.6463605329706311\n",
      "-0.6511343406500443\n",
      "-0.6934730735031154\n",
      "-0.6690229962241886\n",
      "-0.7094401410420491\n",
      "-0.5449275175147378\n",
      "-0.5763801237596402\n",
      "-0.5393413740737623\n",
      "-0.7024861621356522\n",
      "-0.6826793529054297\n",
      "-0.5847603732448603\n",
      "-0.5515100810128457\n",
      "-0.588518148583721\n",
      "-0.6688547869563736\n",
      "-0.6258014683587703\n",
      "-0.698051084484737\n",
      "-0.6999984054758088\n",
      "-0.6251492698539308\n",
      "-0.6949525778263218\n",
      "-0.6228171320668846\n",
      "-0.6654288267521946\n",
      "-0.6340657801940408\n",
      "-0.6437986669595294\n",
      "-0.6802405532589552\n",
      "-0.6312365764438006\n",
      "-0.6473153403189998\n",
      "-0.5620724074302755\n",
      "-0.6547679849965748\n",
      "-0.6330817889289827\n",
      "-0.5605248206049036\n",
      "-0.6382128152936221\n",
      "-0.6351314327000237\n",
      "-0.5832827342556\n",
      "-0.6323212735088866\n",
      "-0.6044433124294586\n",
      "-0.5716346450661938\n",
      "-0.4898678739195303\n",
      "-0.507438257286709\n",
      "-0.5354760379586104\n",
      "-0.5384059157281134\n",
      "-0.5821128508923382\n",
      "-0.5928066764582823\n",
      "-0.5028712659173242\n",
      "-0.5708624796102792\n",
      "-0.6828425107950165\n",
      "-0.5708307008848534\n",
      "-0.5930608615718049\n",
      "-0.656745078610518\n",
      "-0.593499727058447\n",
      "-0.5627810567291706\n",
      "-0.5672002295183424\n",
      "-0.49078568832821834\n",
      "-0.581982931524079\n",
      "-0.5024865598374813\n",
      "-0.5878274718375778\n",
      "-0.583517564848169\n",
      "-0.6462676553775866\n",
      "-0.677779873813538\n",
      "-0.6236282739669812\n",
      "-0.6776603179859563\n",
      "-0.6753471930226042\n",
      "-0.5690824452090483\n",
      "-0.6346382223925231\n",
      "-0.5489382464382492\n",
      "-0.6648298167836584\n",
      "-0.6073167696669208\n",
      "-0.6257427562134897\n",
      "-0.6320801558346054\n",
      "-0.6517294979153824\n",
      "-0.6266201550266395\n",
      "-0.5639656520716574\n",
      "-0.599128793786465\n",
      "-0.650315418897091\n",
      "-0.648662053063136\n",
      "-0.6025095310393365\n",
      "-0.5460379231483581\n",
      "-0.6377280584923725\n",
      "-0.6374779124894879\n",
      "-0.46134326220698385\n",
      "-0.5570041813161036\n",
      "-0.5297980917737701\n",
      "-0.5329999496544584\n",
      "-0.5201064286276477\n",
      "-0.5085733191764625\n",
      "-0.6464977586973011\n",
      "-0.6405178541909962\n",
      "-0.5891648097980536\n",
      "-0.6151698103402079\n",
      "-0.5488339400086862\n",
      "-0.639773498657452\n",
      "-0.512563522951566\n",
      "-0.5413792723996154\n",
      "-0.4550201181149377\n",
      "-0.4967017647801853\n",
      "-0.500577319383271\n",
      "-0.48515961298888494\n",
      "-0.5624040149380821\n",
      "-0.4711897982768464\n",
      "-0.4676186591922856\n",
      "-0.5086990892527421\n",
      "-0.540952640816459\n",
      "-0.4453509335786249\n",
      "-0.4389174304059039\n",
      "-0.4990216195502724\n",
      "-0.6057759022749447\n",
      "-0.5748098425133518\n",
      "-0.6567946437971903\n",
      "-0.5425823656410538\n",
      "-0.5209459280688677\n",
      "-0.48981372611488405\n",
      "-0.5923813039403028\n",
      "-0.5370683867185692\n",
      "-0.4834929533660832\n",
      "-0.5422046426215539\n",
      "-0.4739601706150493\n",
      "-0.5925324466786205\n",
      "-0.5150209542224092\n",
      "-0.5571357813799706\n",
      "-0.6540407881537922\n",
      "-0.5955862143083036\n",
      "-0.5318112681764097\n",
      "-0.6208492537963152\n",
      "-0.5013762200762378\n",
      "-0.5312674219515274\n",
      "-0.4792252985726308\n",
      "-0.4427630710098413\n",
      "-0.47341112256249684\n",
      "-0.4284944371928683\n",
      "-0.500742067504851\n",
      "-0.5274711406558333\n",
      "-0.6050531987081431\n",
      "-0.4527625046085661\n",
      "-0.46229512352630053\n",
      "-0.5131912410034738\n",
      "-0.5605318813281849\n",
      "-0.4392276202940805\n",
      "-0.5309607088252661\n",
      "-0.5975969709171166\n",
      "-0.5220595964026425\n",
      "-0.5419819309932071\n",
      "-0.6115402830446005\n",
      "-0.5732255243333096\n",
      "-0.5941124332277915\n",
      "-0.6878169600224612\n",
      "-0.633683928541666\n",
      "-0.6700905357919792\n",
      "-0.6339682281825751\n",
      "-0.49491267983020504\n",
      "-0.6223836271866379\n",
      "-0.5550662681920747\n",
      "-0.5239412493659504\n",
      "-0.5628363710327339\n",
      "-0.5244907377484618\n",
      "-0.6181982675970652\n",
      "-0.5712688745328656\n",
      "-0.48930293323896634\n",
      "-0.5200443633565492\n",
      "-0.6048892494092062\n",
      "-0.6262354135744134\n",
      "-0.6493099272850997\n",
      "-0.62017844772226\n",
      "-0.6429108036138513\n",
      "-0.5886467646889183\n",
      "-0.5969033726104261\n",
      "-0.4741213231091385\n",
      "-0.5780594771529546\n",
      "-0.6559911233295823\n",
      "-0.6259106232157793\n",
      "-0.5566955641748768\n",
      "-0.6015233318129936\n",
      "-0.5798646299190149\n",
      "-0.4857737121248089\n",
      "-0.5380041478944381\n",
      "-0.6239937202766737\n",
      "-0.6401171848832587\n",
      "-0.4956236898865842\n",
      "-0.5730208989366234\n",
      "-0.5617653540030434\n",
      "-0.5060298073050347\n",
      "-0.6429340080719146\n",
      "-0.5724151662357242\n",
      "-0.5605077673729822\n",
      "-0.5682673889238427\n",
      "-0.5916802332326021\n",
      "-0.4798206603314204\n",
      "-0.5722858177105019\n",
      "-0.5082530354898397\n",
      "-0.6010856235687921\n",
      "-0.5562938309053802\n",
      "-0.5353342484735703\n",
      "-0.5767488717101933\n",
      "-0.5794882755589854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5151830613809592\n",
      "-0.543458474896495\n",
      "-0.5448954247291872\n",
      "-0.6045750113607915\n",
      "-0.4741302607828944\n",
      "-0.4534355891609448\n",
      "-0.4836563297017673\n",
      "-0.522678135903862\n",
      "-0.6447575298638445\n",
      "-0.598004155653597\n",
      "-0.5923799828797117\n",
      "-0.4969255704030842\n",
      "-0.550395884900626\n",
      "-0.46625204331867726\n",
      "-0.5835909935395396\n",
      "-0.6134458868659741\n",
      "-0.5126287865893533\n",
      "-0.5705823982641945\n",
      "-0.5655731069018324\n",
      "-0.6774375780769444\n",
      "-0.5651196725416066\n",
      "-0.6358034118012463\n",
      "-0.6106563969357861\n",
      "-0.717771610084537\n",
      "-0.6066117807820175\n",
      "-0.5395784401681443\n",
      "-0.5817572558166105\n",
      "-0.5570810908923951\n",
      "-0.6059966587189684\n",
      "-0.6192802100264932\n",
      "-0.5006455350905964\n",
      "-0.5358659236625963\n",
      "-0.5628750901380808\n",
      "-0.6023633196070244\n",
      "-0.5920753560196522\n",
      "-0.7028436677244275\n",
      "-0.62016401947029\n",
      "-0.6341012421236013\n",
      "-0.6891941803255018\n",
      "-0.6841234527706108\n",
      "-0.6137335867494524\n",
      "-0.7362975422028379\n",
      "-0.7310923132149305\n",
      "-0.7526958354544117\n",
      "-0.7118281338851875\n",
      "-0.7796216966958887\n",
      "-0.7407706432514999\n",
      "-0.7281439430232873\n",
      "-0.8105257573103922\n",
      "-0.8330566540931403\n",
      "-0.7978906566012014\n",
      "-0.7892731629571473\n",
      "-0.7611186268443937\n",
      "-0.7883118400292922\n",
      "-0.7270802636251323\n",
      "-0.6507696038976475\n",
      "-0.6674440995294021\n",
      "-0.739736531234437\n",
      "-0.7532541520262596\n",
      "-0.6776530586927907\n",
      "-0.6080803006934102\n",
      "-0.7205197655990242\n",
      "-0.6315879491101581\n",
      "-0.6726730560433125\n",
      "-0.6882130979875813\n",
      "-0.6089002650725893\n",
      "-0.6025306584627266\n",
      "-0.5202699974112533\n",
      "-0.5871817612276811\n",
      "-0.6567086636828123\n",
      "-0.5510040846919309\n",
      "-0.6413983484577332\n",
      "-0.6746644011471279\n",
      "-0.7783733802098226\n",
      "-0.6951697210957241\n",
      "-0.6560621693134185\n",
      "-0.734169981565908\n",
      "-0.6912025200410826\n",
      "-0.5823193357994412\n",
      "-0.7623581098689116\n",
      "-0.643745083543604\n",
      "-0.6167347707386158\n",
      "-0.6243313072550263\n",
      "-0.6818518565578164\n",
      "-0.5116378206154423\n",
      "-0.5894864741135724\n",
      "-0.5434075094000942\n",
      "-0.638732760462852\n",
      "-0.6554162715319376\n",
      "-0.7860341990912061\n",
      "-0.8008987477912988\n",
      "-0.833059248871643\n",
      "-0.8297730519662702\n",
      "-0.7880722220408042\n",
      "-0.6376349847012466\n",
      "-0.6952536843198038\n",
      "-0.7261348354608441\n",
      "-0.6714074432790031\n",
      "-0.7629001229697152\n",
      "-0.6318311417042083\n",
      "-0.7582825034297144\n",
      "-0.758455424090693\n",
      "-0.7180087916756095\n",
      "-0.711589696010998\n",
      "-0.7980559305488278\n",
      "-0.8140020630824998\n",
      "-0.7119845890875695\n",
      "-0.7002116632563768\n",
      "-0.8033522588880154\n",
      "-0.7573989727864663\n",
      "-0.6672152668914181\n",
      "-0.8524106270294862\n",
      "-0.7703216629533961\n",
      "-0.668294040395126\n",
      "-0.6826793900042963\n",
      "-0.7999229340670818\n",
      "-0.7552629359687538\n",
      "-0.7173780984828334\n",
      "-0.7647558602945672\n",
      "-0.7309024250221495\n",
      "-0.8186411019038298\n",
      "-0.8210032136435319\n",
      "-0.8482954953987547\n",
      "-0.7899579481853158\n",
      "-0.7290844191390451\n",
      "-0.8807046371739827\n",
      "-0.8842718799297017\n",
      "-0.7874772493034274\n",
      "-0.8067630887882007\n",
      "-0.7571132729810665\n",
      "-0.8039579497130165\n",
      "-0.780651160344539\n",
      "-0.812244497632767\n",
      "-0.8442421278290195\n",
      "-0.823866526840121\n",
      "-0.7663242848169266\n",
      "-0.837223282712401\n",
      "-0.8276130973839512\n",
      "-0.7780180858994262\n",
      "-0.7288178468025676\n",
      "-0.7692096419013753\n",
      "-0.7298413447177265\n",
      "-0.8032388199322639\n",
      "-0.7856601741581423\n",
      "-0.8578040885910356\n",
      "-0.7823584913894565\n",
      "-0.7951331392589432\n",
      "-0.816036984397211\n",
      "-0.7829331890395844\n",
      "-0.7978265529164316\n",
      "-0.8648205561595845\n",
      "-0.9330251753194312\n",
      "-0.847746664726232\n",
      "-0.7336716437229892\n",
      "-0.8507103802000717\n",
      "-0.8632947278717711\n",
      "-0.8488964194453401\n",
      "-0.8351888897270534\n",
      "-0.8044018919347992\n",
      "-0.838509155870097\n",
      "-0.9576737429557914\n",
      "-0.8364795777123513\n",
      "-0.7735297636950412\n",
      "-0.7193331748541256\n",
      "-0.7938635869170265\n",
      "-0.7985153890515044\n",
      "-0.745883340677806\n",
      "-0.709448583518291\n",
      "-0.8378849281165667\n",
      "-0.8467132352848629\n",
      "-0.9651601304552587\n",
      "-0.9430636876109657\n",
      "-0.9171506360599619\n",
      "-0.8906559015956824\n",
      "-0.9405492379893685\n",
      "-0.8962003822720647\n",
      "-0.9349480228000706\n",
      "-0.9140214662715651\n",
      "-0.8116452677620023\n",
      "-0.9139351771368498\n",
      "-0.80317387831011\n",
      "-0.825152186045369\n",
      "-0.9253280746614946\n",
      "-0.8923993361895711\n",
      "-0.879200593580603\n",
      "-0.8797813146580699\n",
      "-0.8687737976161729\n",
      "-0.7341707111082627\n",
      "-0.8994102596139272\n",
      "-0.8160106158011046\n",
      "-0.8467476949609634\n",
      "-0.8596755044546421\n",
      "-0.9332914463034954\n",
      "-0.9264486464312375\n",
      "-0.848580934238899\n",
      "-0.9251206809216793\n",
      "-0.8209469740934097\n",
      "-0.8809992316726377\n",
      "-0.8564415629384581\n",
      "-0.8637723189705377\n",
      "-0.808774948159379\n",
      "-0.856702392384949\n",
      "-0.9488824596945084\n",
      "-0.8189302549629018\n",
      "-0.8394393848598614\n",
      "-0.7802010432596992\n",
      "-0.8010528984903306\n",
      "-0.8148433394412864\n",
      "-0.8772458847762523\n",
      "-0.7769669341411917\n",
      "-0.8432853037223171\n",
      "-0.9044599248481094\n",
      "-0.9546592928669193\n",
      "-0.8600202586808612\n",
      "-0.8479643033884335\n",
      "-0.864076695578086\n",
      "-0.9185738724604978\n",
      "-0.9599869646813782\n",
      "-0.8884029338647916\n",
      "-0.8790183779357622\n",
      "-0.8383510740029568\n",
      "-0.847988219756324\n",
      "-0.8876724511147722\n",
      "-0.7983049165770578\n",
      "-0.8998243598029353\n",
      "-0.8609051026287905\n",
      "-0.8463218818610928\n",
      "-0.8503822900653453\n",
      "-0.8801772845867094\n",
      "-0.959473471171887\n",
      "-0.9234025282124338\n",
      "-0.8972205574684243\n",
      "-0.7786604320489735\n",
      "-0.9057820672446459\n",
      "-0.8328235005618526\n",
      "-0.9218664041508559\n",
      "-0.9012919636259938\n",
      "-0.9125669306696208\n",
      "-0.9517371315121879\n",
      "-0.8552868886103666\n",
      "-0.8489091477647043\n",
      "-0.8426957733471533\n",
      "-0.7889661396934297\n",
      "-0.8836784099383019\n",
      "-0.8224089999727762\n",
      "-0.8298362712582137\n",
      "-0.7258173624468353\n",
      "-0.8300113249609314\n",
      "-0.9698772182654101\n",
      "-0.9523070769467697\n",
      "-0.9431013934181971\n",
      "-0.8881489886657518\n",
      "-0.9039425434803098\n",
      "-0.8757092864809273\n",
      "-0.8672763312166416\n",
      "-0.9180879246955842\n",
      "-0.9468903502688757\n",
      "-0.8944329990665387\n",
      "-0.8089118115253677\n",
      "-0.9759842317492372\n",
      "-0.9115657547325201\n",
      "-0.8977060765776934\n",
      "-0.88725360851841\n",
      "-0.8093877293961809\n",
      "-0.8046099684166773\n",
      "-0.890099652089182\n",
      "-0.9217424582768264\n",
      "-0.8040649409875312\n",
      "-0.9611525377937006\n",
      "-0.9188113326609997\n",
      "-0.9562776660114556\n",
      "-0.8758025703313312\n",
      "-0.8089306321601848\n",
      "-0.8028378029607016\n",
      "-0.8177957276173101\n",
      "-0.8577821041288984\n",
      "-0.9297251474249162\n",
      "-0.8087814422191918\n",
      "-0.8735082031871441\n",
      "-0.9184621659200091\n",
      "-0.8839494068302167\n",
      "-0.9026453926855434\n",
      "-0.8766885106777456\n",
      "-0.9136116611726169\n",
      "-0.912579454927917\n",
      "-0.848996933271704\n",
      "-0.9164453399067457\n",
      "-0.8259776356159998\n",
      "-0.935535852557452\n",
      "-0.9723513004510885\n",
      "-0.9091020419568833\n",
      "-0.9431833422753427\n",
      "-0.883128004951615\n",
      "-1.0007453781972675\n",
      "-0.8805162926607681\n",
      "-0.9005468871649999\n",
      "-0.8779650434462934\n",
      "-0.7791661246322888\n",
      "-0.9127571724506857\n",
      "-0.8982077539995084\n",
      "-0.7877625807408009\n",
      "-0.8965414827985048\n",
      "-0.7563961869628513\n",
      "-0.8415903610489773\n",
      "-0.9749486940241558\n",
      "-0.7620114423720171\n",
      "-0.8657981959638403\n",
      "-0.8937313369119627\n",
      "-0.8964447321180684\n",
      "-0.9964854911812691\n",
      "-0.8131686978068988\n",
      "-0.8919651811131368\n",
      "-0.8477447174501616\n",
      "-0.9203309863967377\n",
      "-0.843109707481108\n",
      "-0.8412981540851504\n",
      "-0.8953670431348048\n",
      "-0.9269677091752999\n",
      "-0.866780206690091\n",
      "-0.9277182752520579\n",
      "-0.7988779295634799\n",
      "-0.9277936736563146\n",
      "-0.8581373198944323\n",
      "-0.8367083395352483\n",
      "-0.9038934279498276\n",
      "-0.8993965236229495\n",
      "-0.8721055117165475\n",
      "-0.8535210488363654\n",
      "-0.8738262521593427\n",
      "-0.7205481084760619\n",
      "-0.7994502967603426\n",
      "-0.881830171967425\n",
      "-0.7873370849564918\n",
      "-0.8501689522524012\n",
      "-0.7990000034777207\n",
      "-0.8458944666381448\n",
      "-0.8108157196757385\n",
      "-0.9044316725810967\n",
      "-0.8561854399336157\n",
      "-0.9819128276285154\n",
      "-0.9234238391798459\n",
      "-0.8013125467741951\n",
      "-0.8016056848452976\n",
      "-0.8535717516442626\n",
      "-0.7733048006932798\n",
      "-0.8553217559863201\n",
      "-0.9207291611579487\n",
      "-0.8800422392325533\n",
      "-0.8080042381698983\n",
      "-0.8049819537070967\n",
      "-0.9251235652831244\n",
      "-0.8492124944191518\n",
      "-0.7865302368531991\n",
      "-0.879378074216036\n",
      "-0.7754346534419592\n",
      "-0.9134993557035435\n",
      "-0.8198648998815744\n",
      "-0.8184584002011166\n",
      "-0.792500185717069\n",
      "-0.8125132061091574\n",
      "-0.7866030848322707\n",
      "-0.7762662070741889\n",
      "-0.8253151414172275\n",
      "-0.8443347825184937\n",
      "-0.8811559236251427\n",
      "-0.8139617915889198\n",
      "-0.910479577298043\n",
      "-0.8487287921994314\n",
      "-0.8240490108740425\n",
      "-0.7937921153014638\n",
      "-0.876788914843132\n",
      "-0.8626622834562968\n",
      "-0.8908132253835356\n",
      "-0.9020357758359192\n",
      "-0.8775909325343618\n",
      "-0.8584389733677056\n",
      "-0.8258153856059531\n",
      "-0.8581580118875899\n",
      "-0.910340683324824\n",
      "-0.8163427873995074\n",
      "-0.8609806673935186\n",
      "-0.7900402162266167\n",
      "-0.9002239803337811\n",
      "-0.8192844473022927\n",
      "-0.7934471418076424\n",
      "-0.9231438154391924\n",
      "-0.7639556590223651\n",
      "-0.759158617173449\n",
      "-0.7860150239514555\n",
      "-0.8605542189844428\n",
      "-0.7763456224230928\n",
      "-0.8411815076573665\n",
      "-0.9250484273516394\n",
      "-0.9325416198912909\n",
      "-0.8802954438486792\n",
      "-0.7186933788872033\n",
      "-0.828891785207165\n",
      "-0.9090341541013527\n",
      "-0.8612356205182418\n",
      "-0.8692251605217338\n",
      "-0.8544396168948074\n",
      "-0.8948658479476804\n",
      "-0.8163523278040454\n",
      "-0.8062283864289637\n",
      "-0.7329802539621487\n",
      "-0.8568464730274106\n",
      "-0.8085935555451936\n",
      "-0.8460883462383275\n",
      "-0.874271140675666\n",
      "-0.8653493588000425\n",
      "-0.8465268356041519\n",
      "-0.8000100939923772\n",
      "-0.8252868989262578\n",
      "-0.863120165166507\n",
      "-0.8977097658217592\n",
      "-0.9226496760167273\n",
      "-0.8299388998724\n",
      "-0.8087779714634515\n",
      "-0.9070719197804235\n",
      "-0.8740143185096259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.924049112840763\n",
      "-0.9157901311169845\n",
      "-0.8947082437570447\n",
      "-0.7801173932397627\n",
      "-0.8758654666886242\n",
      "-0.7605566791296163\n",
      "-0.8593793495695481\n",
      "-0.909555134480383\n",
      "-0.8812020765487865\n",
      "-0.8240805850246821\n",
      "-0.8618396587667514\n",
      "-0.7482357945652991\n",
      "-0.7873165266416485\n",
      "-0.7078978260695671\n",
      "-0.7456143473488621\n",
      "-0.8210133929387788\n",
      "-0.9181824691333073\n",
      "-0.8080320159778409\n",
      "-0.722582224665229\n",
      "-0.7907134927234627\n",
      "-0.875238654497845\n",
      "-0.8406246759634428\n",
      "-0.878533610362851\n",
      "-0.8121357134960662\n",
      "-0.847630177310498\n",
      "-0.8399553523542258\n",
      "-0.7106734144647234\n",
      "-0.8726408471636816\n",
      "-0.7251740037554151\n",
      "-0.7702375379307561\n",
      "-0.8108352538625254\n",
      "-0.8430357316834368\n",
      "-0.9509846485872141\n",
      "-0.8032040138774372\n",
      "-0.8478292689275436\n",
      "-0.8907354766453478\n",
      "-0.8668351079858538\n",
      "-0.7984527175187796\n",
      "-0.813222062925893\n",
      "-0.734494231516556\n",
      "-0.8976623945187674\n",
      "-0.7864165751399997\n",
      "-0.8380254696032334\n",
      "-0.8111841985229575\n",
      "-0.753615647030944\n",
      "-0.7699351089485665\n",
      "-0.8272190275719051\n",
      "-0.8292327448847332\n",
      "-0.9123536417057667\n",
      "-0.8373457566658383\n",
      "-0.8585886939713242\n",
      "-0.9304296600975734\n",
      "-0.8713857413343362\n",
      "-0.9268539008141734\n",
      "-0.8245299650743696\n",
      "-0.879049355764942\n",
      "-0.8845508382483546\n",
      "-0.7759845295697797\n",
      "-0.7244449393128677\n",
      "-0.8501347552177861\n",
      "-0.8445703624791956\n",
      "-0.8408615017578801\n",
      "-0.7986034631407445\n",
      "-0.8590570920803248\n",
      "-0.9084424306269606\n",
      "-0.7980513475213834\n",
      "-0.8500965237079282\n",
      "-0.9576804456382983\n",
      "-0.8710009097517871\n",
      "-0.8861284313077574\n",
      "-0.8316897037928477\n",
      "-0.8959413259108981\n",
      "-0.9201706680529128\n",
      "-0.899828103002757\n",
      "-0.8518522965682903\n",
      "-0.9396077357921928\n",
      "-0.8598822877560961\n",
      "-0.726021928893092\n",
      "-0.7521899397229106\n",
      "-0.8142596048088492\n",
      "-0.8249408134551175\n",
      "-0.8866285665750716\n",
      "-0.9180501138553204\n",
      "-0.8384897667426457\n",
      "-0.7497905903190685\n",
      "-0.7296329154299539\n",
      "-0.8142203327791817\n",
      "-0.8601019164650768\n",
      "-0.821196803940142\n",
      "-0.8337904128748234\n",
      "-0.874191449083804\n",
      "-0.896946163212508\n",
      "-0.8901677817626402\n",
      "-0.8743069731844322\n",
      "-0.8576522302884021\n",
      "-0.9121519749983247\n",
      "-0.9227040136212045\n",
      "-0.8919320340297506\n",
      "-0.7536188027379258\n",
      "-0.8298334741389154\n",
      "-0.800104928793879\n",
      "-0.9168557991795218\n",
      "-0.9591974367355366\n",
      "-0.7365721535613698\n",
      "-0.9537077242398544\n",
      "-0.8938900917800789\n",
      "-0.9084050991215602\n",
      "-0.8184418297873479\n",
      "-0.841697339813627\n",
      "-0.8158252755539858\n",
      "-0.9512748563029496\n",
      "-0.946810214109619\n",
      "-0.8435298642571768\n",
      "-0.8676781262695306\n",
      "-0.7931648530138963\n",
      "-0.8202590938018268\n",
      "-0.8844781684755497\n",
      "-0.8587201270116716\n",
      "-0.7240467322175849\n",
      "-0.8799205292633332\n",
      "-0.7678182140497035\n",
      "-0.8855089332319734\n",
      "-1.0753007669452912\n",
      "-1.0005498894162437\n",
      "-0.9104114327395036\n",
      "-0.8243017028717537\n",
      "-0.7748198680504181\n",
      "-0.8264258985262823\n",
      "-0.7914946460038154\n",
      "-0.8019189381489966\n",
      "-0.8478272884705885\n",
      "-0.7828991154760478\n",
      "-0.7754058162348244\n",
      "-0.7274127211098601\n",
      "-0.7502951101516898\n",
      "-0.7229260035448961\n",
      "-0.793361398741475\n",
      "-0.7225941213959989\n",
      "-0.8456530032529602\n",
      "-0.8609874701844594\n",
      "-0.8673915194363438\n",
      "-0.8217476522357292\n",
      "-0.8595551150887214\n",
      "-0.8642611518418762\n",
      "-0.7850608197084934\n",
      "-0.8085168845343034\n",
      "-0.8956215608796873\n",
      "-0.7306404268034336\n",
      "-0.805454883061507\n",
      "-0.7115764309333914\n",
      "-0.7172651634556485\n",
      "-0.856190868907854\n",
      "-0.7584194024295278\n",
      "-0.8857991263553561\n",
      "-0.8462837888566215\n",
      "-0.898175904950074\n",
      "-0.8361637749781804\n",
      "-0.8652328702164004\n",
      "-0.932455470965302\n",
      "-0.8274586588927125\n",
      "-0.8324558488460145\n",
      "-0.807715619106822\n",
      "-0.8056862641765067\n",
      "-0.8541471307382141\n",
      "-0.8246415776371484\n",
      "-0.8081053752752791\n",
      "-0.8738199106521255\n",
      "-0.802030042813387\n",
      "-0.7624615184927662\n",
      "-0.7689999457420928\n",
      "-0.8181624588531349\n",
      "-0.7651319178149357\n",
      "-0.8032706028468474\n",
      "-0.7423514541984815\n",
      "-0.827045008670932\n",
      "-0.8675995887418863\n",
      "-0.8046461947306277\n",
      "-0.9151995782853324\n",
      "-0.8824735016391654\n",
      "-0.8381959855614041\n",
      "-0.8998620386920977\n",
      "-0.7689694809391115\n",
      "-0.8387422922866287\n",
      "-0.84059211960544\n",
      "-0.8266418933395328\n",
      "-0.8778167637741359\n",
      "-0.8137967744413415\n",
      "-0.8767767722895363\n",
      "-0.8428815864916459\n",
      "-0.8355058698597796\n",
      "-0.9358693533905799\n",
      "-0.8213327837466385\n",
      "-0.8500069649412088\n",
      "-0.8441539275128959\n",
      "-0.8469719667414443\n",
      "-0.8629627799788263\n",
      "-0.9246295855589778\n",
      "-0.8198235864219459\n",
      "-0.8418268272411522\n",
      "-0.7450979117649189\n",
      "-0.8401371354741071\n",
      "-0.83253862673951\n",
      "-0.8332891509869131\n",
      "-0.7700378186364446\n",
      "-0.9452233318591575\n",
      "-0.8104649390243865\n",
      "-0.8438819928304843\n",
      "-0.9235192739545087\n",
      "-0.8367754160752259\n",
      "-0.7650176260592395\n",
      "-0.9020443194472573\n",
      "-0.8261093051992416\n",
      "-0.9119590971736944\n",
      "-0.9461030211672252\n",
      "-0.9508691948403453\n",
      "-0.9042660661825088\n",
      "-0.8800456792572594\n",
      "-0.7728408087691405\n",
      "-0.7825677547476553\n",
      "-0.7625452839568919\n",
      "-0.9277914282373245\n",
      "-0.8992032740921223\n",
      "-0.8990163123245491\n",
      "-0.7768247855044115\n",
      "-0.7591906914637276\n",
      "-0.8271499487183964\n",
      "-0.8315267958777479\n",
      "-0.8037655400305724\n",
      "-0.8229818753761236\n",
      "-0.8420368235011867\n",
      "-0.7569476830326447\n",
      "-0.8296406846651035\n",
      "-0.8077656163040209\n",
      "-0.7894112257902144\n",
      "-0.7200800698110218\n",
      "-0.7003922189349614\n",
      "-0.7355009310965634\n",
      "-0.6651346724969879\n",
      "-0.6894066392463245\n",
      "-0.6388831806876583\n",
      "-0.5887611165706975\n",
      "-0.66172488784506\n",
      "-0.6923297663643938\n",
      "-0.7413859884788806\n",
      "-0.724008161623248\n",
      "-0.7371360867377359\n",
      "-0.6841663036067176\n",
      "-0.7095138267137502\n",
      "-0.653618682253545\n",
      "-0.6210284965311109\n",
      "-0.6378258173445158\n",
      "-0.6209113874881247\n",
      "-0.6701448744034357\n",
      "-0.680424820676213\n",
      "-0.5537724632629852\n",
      "-0.6902248722852227\n",
      "-0.7184775774669521\n",
      "-0.7448323649362122\n",
      "-0.7415463128689198\n",
      "-0.657043728656492\n",
      "-0.6569678949233871\n",
      "-0.5861754765021042\n",
      "-0.5913601749466981\n",
      "-0.6263382755838248\n",
      "-0.6436556237965047\n",
      "-0.7136262610847698\n",
      "-0.7000388692267318\n",
      "-0.6508796661109277\n",
      "-0.6931153686506518\n",
      "-0.6389396497197359\n",
      "-0.5966663168451753\n",
      "-0.6316923414224266\n",
      "-0.6028581308398128\n",
      "-0.7097819516023656\n",
      "-0.726068528463991\n",
      "-0.6784755232403268\n",
      "-0.6768973626533319\n",
      "-0.6608123815719938\n",
      "-0.7327394184060239\n",
      "-0.6834392979102182\n",
      "-0.5953998463998983\n",
      "-0.6833270141906129\n",
      "-0.7481865570348936\n",
      "-0.6671792134262969\n",
      "-0.6223881402194573\n",
      "-0.6110742600909134\n",
      "-0.6957762209390498\n",
      "-0.6548449123635091\n",
      "-0.617138809126102\n",
      "-0.6048786617671249\n",
      "-0.6122668396224942\n",
      "-0.5868877679739722\n",
      "-0.6031395270638711\n",
      "-0.6662523223999027\n",
      "-0.5926625818811099\n",
      "-0.6564501809513205\n",
      "-0.6335266851905017\n",
      "-0.7169739529648183\n",
      "-0.5771731593292713\n",
      "-0.6640501180528022\n",
      "-0.554976754636936\n",
      "-0.5536555838257299\n",
      "-0.5903969647928475\n",
      "-0.6620420245076631\n",
      "-0.6079566418340878\n",
      "-0.5834859988195067\n",
      "-0.5947829283253394\n",
      "-0.5973523154193604\n",
      "-0.6389247011731347\n",
      "-0.5935370486191257\n",
      "-0.6769641237600015\n",
      "-0.6564826931735689\n",
      "-0.6644041302962926\n",
      "-0.6820480302678551\n",
      "-0.6670530461885281\n",
      "-0.68370022842227\n",
      "-0.6169826144783548\n",
      "-0.6851998611376318\n",
      "-0.7079318711341555\n",
      "-0.646402281257536\n",
      "-0.662310421064356\n",
      "-0.6669714251992629\n",
      "-0.736260710163085\n",
      "-0.6426890607298716\n",
      "-0.6738248974592097\n",
      "-0.7091203424806375\n",
      "-0.6573808565088212\n",
      "-0.6575981756035238\n",
      "-0.7575943759834148\n",
      "-0.6413056860468335\n",
      "-0.7752424571395359\n",
      "-0.7408605269372249\n",
      "-0.6912188855499523\n",
      "-0.6376060679753704\n",
      "-0.724629365673119\n",
      "-0.5857431294667285\n",
      "-0.6597672515737543\n",
      "-0.5654146083849118\n",
      "-0.5800325967850654\n",
      "-0.582999793737787\n",
      "-0.5562100038598907\n",
      "-0.5982959092973469\n",
      "-0.6072903818708123\n",
      "-0.6227794996001027\n",
      "-0.624238809013979\n",
      "-0.6199358179805582\n",
      "-0.5970972815146911\n",
      "-0.6704763652764161\n",
      "-0.6473011085603969\n",
      "-0.6319143968977041\n",
      "-0.6740717558318888\n",
      "-0.7438654366170401\n",
      "-0.6509300809461317\n",
      "-0.603849916892648\n",
      "-0.7116807489471273\n",
      "-0.6233235543414165\n",
      "-0.6794023051317846\n",
      "-0.6705703374999723\n",
      "-0.6059092261821234\n",
      "-0.6632644035121138\n",
      "-0.684163134901785\n",
      "-0.6465629668225298\n",
      "-0.6105783674576135\n",
      "-0.5770372593417479\n",
      "-0.621257404074861\n",
      "-0.667593826414449\n",
      "-0.6833641422751662\n",
      "-0.6315695356965763\n",
      "-0.6846961944741297\n",
      "-0.7158105430563334\n",
      "-0.5844879676706232\n",
      "-0.5991088371750889\n",
      "-0.5358609078659948\n",
      "-0.5546308505220738\n",
      "-0.6294313130125326\n",
      "-0.6218646936479977\n",
      "-0.6702735356406291\n",
      "-0.7554331428601736\n",
      "-0.7813214447494962\n",
      "-0.6941801113034752\n",
      "-0.7283692405324436\n",
      "-0.5994891958406712\n",
      "-0.6319963538162852\n",
      "-0.7503645843280989\n",
      "-0.6738928626479471\n",
      "-0.779947080983421\n",
      "-0.7097327013326635\n",
      "-0.6748571182720653\n",
      "-0.6763154210451582\n",
      "-0.5912216603720084\n",
      "-0.6940573233790585\n",
      "-0.6671586965867896\n",
      "-0.7508564488945366\n",
      "-0.7203404008122667\n",
      "-0.7026616209952468\n",
      "-0.5902567972526642\n",
      "-0.7381419299094305\n",
      "-0.6627710107508255\n",
      "-0.6671427283855473\n",
      "-0.7136164186084546\n",
      "-0.7126799438520732\n",
      "-0.6061555117665294\n",
      "-0.6236654240317194\n",
      "-0.6225371879320561\n",
      "-0.6155231597366297\n",
      "-0.6172408659255227\n",
      "-0.6451116223932839\n",
      "-0.6064118093243451\n",
      "-0.6526251089280726\n",
      "-0.652343220465357\n",
      "-0.6900173236151289\n",
      "-0.701138194534538\n",
      "-0.7207284499081801\n",
      "-0.716535381092933\n",
      "-0.7592965197346495\n",
      "-0.7372079950946\n",
      "-0.7705235744233051\n",
      "-0.6343003099786118\n",
      "-0.6857359617872604\n",
      "-0.7414083301177319\n",
      "-0.6785799607363749\n",
      "-0.6213763813916117\n",
      "-0.647142042695138\n",
      "-0.6707852377649661\n",
      "-0.681033126113614\n",
      "-0.7938206430389217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7583344392972329\n",
      "-0.7388459582415066\n",
      "-0.7126997596034149\n",
      "-0.696905131713268\n",
      "-0.6733898521515681\n",
      "-0.6289211471378021\n",
      "-0.7546352966775419\n",
      "-0.7755425069669627\n",
      "-0.7451152377650064\n",
      "-0.6524918926298204\n",
      "-0.7493512687760242\n",
      "-0.6738743896616564\n",
      "-0.6108533295326461\n",
      "-0.5249993471554324\n",
      "-0.7046223613795363\n",
      "-0.6124782558942594\n",
      "-0.6953592965466036\n",
      "-0.6402996270004887\n",
      "-0.6654014130262348\n",
      "-0.6161183839089499\n",
      "-0.5265417449730814\n",
      "-0.6286726690641309\n",
      "-0.6015380662537423\n",
      "-0.6733169704600759\n",
      "-0.6383616437111983\n",
      "-0.5943584910771031\n",
      "-0.6170795913166762\n",
      "-0.6749701955828341\n",
      "-0.6307314253490099\n",
      "-0.7467737003021842\n",
      "-0.6662594476906495\n",
      "-0.8268566663340499\n",
      "-0.7609164965350008\n",
      "-0.7805925314676015\n",
      "-0.6940772922031502\n",
      "-0.7056427306791154\n",
      "-0.6183312908714067\n",
      "-0.7181919384022574\n",
      "-0.5763415306600764\n",
      "-0.6621938703133254\n",
      "-0.620842335224447\n",
      "-0.6335817616165127\n",
      "-0.6322766824732206\n",
      "-0.7337732237164338\n",
      "-0.6587121431423947\n",
      "-0.6244215060805204\n",
      "-0.704664541230741\n",
      "-0.6515259253926383\n",
      "-0.7148004540761241\n",
      "-0.5664105143986606\n",
      "-0.6205651016531343\n",
      "-0.7429307513657287\n",
      "-0.6594978253565709\n",
      "-0.7330880126254814\n",
      "-0.7621092543779382\n",
      "-0.744732825558967\n",
      "-0.8448316601426944\n",
      "-0.7924817682678708\n",
      "-0.8893470599613424\n",
      "-0.7027056771574428\n",
      "-0.7840217929013511\n",
      "-0.7676351790127146\n",
      "-0.6526477374340004\n",
      "-0.833607238045589\n",
      "-0.7193958626943906\n",
      "-0.7080432216759178\n",
      "-0.6818987858639626\n",
      "-0.6601455905797152\n",
      "-0.7324195356964176\n",
      "-0.7121919853464824\n",
      "-0.6519884808103843\n",
      "-0.6492999151515951\n",
      "-0.7172703923458184\n",
      "-0.8279838440424848\n",
      "-0.8991048999265108\n",
      "-0.7651969656087927\n",
      "-0.7761936081751948\n",
      "-0.6928103018955223\n",
      "-0.7291410738970749\n",
      "-0.74654489760494\n",
      "-0.6672261406218102\n",
      "-0.6505515839347391\n",
      "-0.5840060593294771\n",
      "-0.5975805966483813\n",
      "-0.6454267512750345\n",
      "-0.5768765346388944\n",
      "-0.668248554172046\n",
      "-0.6537441871379621\n",
      "-0.630835805943147\n",
      "-0.6691198969817751\n",
      "-0.6840075260208636\n",
      "-0.7434860874153668\n",
      "-0.7131459728779745\n",
      "-0.7178632890597977\n",
      "-0.7267564062962848\n",
      "-0.7455319250328186\n",
      "-0.6672828490812072\n",
      "-0.6978389006901013\n",
      "-0.7497867313698287\n",
      "-0.5909033760373964\n",
      "-0.6923722524788435\n",
      "-0.7175823293579687\n",
      "-0.6744672524095937\n",
      "-0.7008438540861603\n",
      "-0.7839462427843635\n",
      "-0.6724034874138076\n",
      "-0.8062360743353184\n",
      "-0.7798036091386663\n",
      "-0.6817829198717317\n",
      "-0.8263098357580511\n",
      "-0.730283768337371\n",
      "-0.6597385755965954\n",
      "-0.6941427334405087\n",
      "-0.6727500598720183\n",
      "-0.64025678859589\n",
      "-0.8544293396122956\n",
      "-0.7474250129578119\n",
      "-0.7611782043346091\n",
      "-0.7546689337551399\n",
      "-0.8665377422062241\n",
      "-0.7515578013998021\n",
      "-0.77829336291728\n",
      "-0.7385670788826778\n",
      "-0.7620547544169657\n",
      "-0.7238090634970882\n",
      "-0.7939238376541785\n",
      "-0.7626518459169468\n",
      "-0.8088759591311377\n",
      "-0.770453312295217\n",
      "-0.7191231631835159\n",
      "-0.8305320167866739\n",
      "-0.6943223975671061\n",
      "-0.8075597236163872\n",
      "-0.7775990107922633\n",
      "-0.8585854153667547\n",
      "-0.7910929043895308\n",
      "-0.7995666759191146\n",
      "-0.8018469775163785\n",
      "-0.7988052684549946\n",
      "-0.7338072826723521\n",
      "-0.616713720798318\n",
      "-0.7442848004504825\n",
      "-0.7127451685771868\n",
      "-0.8624852944524923\n",
      "-0.7556648506814814\n",
      "-0.8262873844223954\n",
      "-0.8724570543118267\n",
      "-0.8826029215397345\n",
      "-0.8091551815045421\n",
      "-0.812571990686968\n",
      "-0.8081187807873998\n",
      "-0.8354154672955778\n",
      "-0.7667888278393039\n",
      "-0.7665675782124098\n",
      "-0.7752212261451331\n",
      "-0.8109825591052389\n",
      "-0.6962436654018309\n",
      "-0.7631269235440369\n",
      "-0.839608540540832\n",
      "-0.9261800195605552\n",
      "-0.7486330835088124\n",
      "-0.7270794957303831\n",
      "-0.752361546271834\n",
      "-0.7354350993070857\n",
      "-0.7715290230456275\n",
      "-0.7673709210708901\n",
      "-0.8140581112008085\n",
      "-0.8234316989727305\n",
      "-0.821145112851291\n",
      "-0.737166630014384\n",
      "-0.8111033581444898\n",
      "-0.8412186421376853\n",
      "-0.8196768381574785\n",
      "-0.7992150653476905\n",
      "-0.8014773031083158\n",
      "-0.7453515063392577\n",
      "-0.7633073759842188\n",
      "-0.8730923904954305\n",
      "-0.7874153545320776\n",
      "-0.6911085128434105\n",
      "-0.7959585697564336\n",
      "-0.7942428249673074\n",
      "-0.8286652422885186\n",
      "-0.694851710129163\n",
      "-0.7923923929930036\n",
      "-0.7301199361746938\n",
      "-0.8004396716354776\n",
      "-0.8630046882411956\n",
      "-0.8643141171763868\n",
      "-0.907242602988125\n",
      "-0.8874356220891931\n",
      "-0.9018402525271341\n",
      "-0.925188049938871\n",
      "-0.7803865827103328\n",
      "-0.7698714535549601\n",
      "-0.7546602051653071\n",
      "-0.8684521677279222\n",
      "-0.7881061604566967\n",
      "-0.7429461748315976\n",
      "-0.7991616204132659\n",
      "-0.7197006304554064\n",
      "-0.8353472497278134\n",
      "-0.7287032638764415\n",
      "-0.7633455496805063\n",
      "-0.8450282869821237\n",
      "-0.9390992361933417\n",
      "-0.9130266555248002\n",
      "-0.9516202739356133\n",
      "-0.844406943193621\n",
      "-0.8132390970431262\n",
      "-0.8659354590460367\n",
      "-0.7603281975226136\n",
      "-0.7637953972032571\n",
      "-0.8574371991245319\n",
      "-0.8864639991176062\n",
      "-0.8172907631250149\n",
      "-0.867226997207214\n",
      "-0.9214290396649888\n",
      "-0.8935195229790992\n",
      "-0.9003982070300651\n",
      "-0.7760100317517546\n",
      "-0.8616253864619985\n",
      "-0.8611944849982368\n",
      "-0.7896119261558199\n",
      "-0.8786651418683192\n",
      "-0.8581989299454558\n",
      "-0.871290782062009\n",
      "-0.7430358978766354\n",
      "-0.8628142856883788\n",
      "-0.8099098467660947\n",
      "-0.8374035300614324\n",
      "-0.792776658761213\n",
      "-0.8317376786797532\n",
      "-0.8318305184185519\n",
      "-0.7925322857063776\n",
      "-0.8013143640573501\n",
      "-0.7689228816070302\n",
      "-0.6670864403850294\n",
      "-0.9885390187174484\n",
      "-0.859835557245298\n",
      "-0.8759191386443105\n",
      "-0.8826689894195159\n",
      "-0.8540450107449468\n",
      "-0.8877527268601874\n",
      "-0.7674222867984889\n",
      "-0.8223698038052146\n",
      "-0.8501852303235792\n",
      "-0.880424278402298\n",
      "-0.8984668783930129\n",
      "-0.8125029645426689\n",
      "-0.8789576517371385\n",
      "-0.7869106032302092\n",
      "-0.7824237106372619\n",
      "-0.8530033894945436\n",
      "-0.8076341004174044\n",
      "-0.7885377388113692\n",
      "-0.6970212048264993\n",
      "-0.7530073299550303\n",
      "-0.7809943668191224\n",
      "-0.7535011694531206\n",
      "-0.8980040913578451\n",
      "-0.8977156422817921\n",
      "-0.8995723274414146\n",
      "-0.884437149403166\n",
      "-0.880582845388729\n",
      "-0.8419519665235045\n",
      "-0.8458336374805882\n",
      "-0.8156591676098074\n",
      "-0.8330039651384732\n",
      "-0.8065936175896817\n",
      "-0.8089081868103335\n",
      "-0.8271172593865284\n",
      "-0.8472194547138463\n",
      "-0.8183998344663047\n",
      "-0.8394442896070125\n",
      "-0.8516007334615652\n",
      "-0.77398979051051\n",
      "-0.7990225200943699\n",
      "-0.8218812905865445\n",
      "-0.7978297696351511\n",
      "-0.7441627749210467\n",
      "-0.8211075926284387\n",
      "-0.7853483438894336\n",
      "-0.7080276829808223\n",
      "-0.7185347781558815\n",
      "-0.8311094841432254\n",
      "-0.8656974079319585\n",
      "-0.8795189898857991\n",
      "-0.8464341397353482\n",
      "-0.8452549062345659\n",
      "-0.8322196241328066\n",
      "-0.8296542191521826\n",
      "-0.8682271906324321\n",
      "-0.879425041389426\n",
      "-0.9151607612747901\n",
      "-0.8781489571385318\n",
      "-0.7760243409016957\n",
      "-0.8896432476458784\n",
      "-0.836183793564858\n",
      "-0.852227805026309\n",
      "-0.8737595790155277\n",
      "-0.7514782551441044\n",
      "-0.7470381547120948\n",
      "-0.7934707976578645\n",
      "-0.8884022164148577\n",
      "-0.8347270295638208\n",
      "-0.7580188086671811\n",
      "-0.7882566302148466\n",
      "-0.9333279327811432\n",
      "-0.7687865160663548\n",
      "-0.7757620551125138\n",
      "-0.9927535809988618\n",
      "-0.9298389691594316\n",
      "-0.902557490363622\n",
      "-0.801854944381\n",
      "-0.8335278183670125\n",
      "-0.9035025475926411\n",
      "-0.8906409083031235\n",
      "-0.778859141224886\n",
      "-0.8686069478518265\n",
      "-0.9394284463062049\n",
      "-0.9171094728986902\n",
      "-0.9414539696699697\n",
      "-0.8969915302721807\n",
      "-0.8178970376921917\n",
      "-0.8721705042376684\n",
      "-0.897211632488541\n",
      "-0.8503950123649668\n",
      "-0.8191145461503844\n",
      "-0.8689297069240264\n",
      "-0.7702228257492532\n",
      "-0.8131182394923823\n",
      "-0.829098046467792\n",
      "-0.872019095939694\n",
      "-0.8274154112715738\n",
      "-0.8724625594300089\n",
      "-0.7642562309962886\n",
      "-0.9034594097502979\n",
      "-0.9048540296450595\n",
      "-0.8417784002723472\n",
      "-0.8495452737513058\n",
      "-0.8820623482067947\n",
      "-0.7528248804119906\n",
      "-0.8421191300355981\n",
      "-0.8624408938470508\n",
      "-0.8023557671033908\n",
      "-0.7919246556103138\n",
      "-0.9300089878761091\n",
      "-0.8599498978520264\n",
      "-0.8227025064948779\n",
      "-0.9211027414921811\n",
      "-0.8539037829074176\n",
      "-0.9994063673787125\n",
      "-0.9154559302951372\n",
      "-0.865203953227051\n",
      "-1.0010920098850424\n",
      "-1.0499760655862738\n",
      "-0.9762401661992998\n",
      "-0.8618717618693013\n",
      "-0.8726706998436536\n",
      "-0.8149147797767031\n",
      "-0.8749594416506798\n",
      "-0.8495960225598058\n",
      "-0.9298641166858866\n",
      "-0.8989937589719157\n",
      "-0.9162390092015982\n",
      "-1.0883743344761716\n",
      "-0.9511578074923042\n",
      "-0.9572420264438576\n",
      "-0.8517207882397455\n",
      "-0.8620793347193499\n",
      "-0.9157457256108731\n",
      "-0.8874071150568882\n",
      "-0.8968355323482875\n",
      "-0.9018070641419088\n",
      "-0.8846351715203535\n",
      "-0.9472429283471407\n",
      "-0.9263386518367074\n",
      "-0.9565308758944522\n",
      "-0.9062273067680384\n",
      "-0.9411666484094865\n",
      "-0.9738353631853425\n",
      "-0.941846621752366\n",
      "-0.7909109811852142\n",
      "-0.8266905070567584\n",
      "-0.9618819706520908\n",
      "-0.9558448375885713\n",
      "-0.8768402494148958\n",
      "-0.9235856728503726\n",
      "-0.9285940999031176\n",
      "-0.9476610791199298\n",
      "-0.8748227351011632\n",
      "-0.8634224282344709\n",
      "-0.8996674590979292\n",
      "-0.8268049863611446\n",
      "-0.9577214287472358\n",
      "-0.9183308334145613\n",
      "-0.9475910200063646\n",
      "-0.8730977930009645\n",
      "-0.9038377274368643\n",
      "-0.9030692920927688\n",
      "-0.9254394219608285\n",
      "-0.9599786793132044\n",
      "-0.8970744457234026\n",
      "-0.9517683443029833\n",
      "-0.9963067783651162\n",
      "-1.047044408087103\n",
      "-0.9715331397420836\n",
      "-0.966170677123174\n",
      "-0.9470220398387567\n",
      "-1.007969744205419\n",
      "-1.0286038645913098\n",
      "-0.9658192192086218\n",
      "-0.9115603129701532\n",
      "-0.8513030000369984\n",
      "-1.0297351850004237\n",
      "-0.9206368925134675\n",
      "-1.0390547292749452\n",
      "-0.9466307016070326\n",
      "-0.8636434881136031\n",
      "-0.8188631046528673\n",
      "-0.8682777952696065\n",
      "-0.9587116478049129\n",
      "-0.9845569908955097\n",
      "-0.8907549518371105\n",
      "-1.0010678533432829\n",
      "-0.9376341485762132\n",
      "-1.0891069808679987\n",
      "-0.9436942886901164\n",
      "-0.9322872771325387\n",
      "-0.973087666560497\n",
      "-0.962994668358819\n",
      "-0.9885915526825694\n",
      "-1.025430374566728\n",
      "-0.9215576820807371\n",
      "-1.0080198395065607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8626090389473003\n",
      "-0.8811049271648312\n",
      "-0.8606831513014647\n",
      "-0.9567089781970533\n",
      "-0.9195939131731464\n",
      "-1.0043732778654935\n",
      "-0.9396543261723518\n",
      "-0.9662963181519624\n",
      "-1.0248720731051404\n",
      "-0.9801198145822203\n",
      "-1.0379514686842126\n",
      "-0.9973017690119027\n",
      "-0.9017437473982353\n",
      "-0.9949657026642811\n",
      "-1.083468658638989\n",
      "-1.010076789376061\n",
      "-1.0331595783575154\n",
      "-0.9493364591629674\n",
      "-0.9714762912201346\n",
      "-0.8018314181836791\n",
      "-0.8648559833794955\n",
      "-0.9172822766474158\n",
      "-0.9900118591496644\n",
      "-0.971399757109396\n",
      "-0.9060939834736093\n",
      "-0.9678332406786524\n",
      "-0.9461448152233907\n",
      "-0.9803563481508322\n",
      "-1.0238420198537244\n",
      "-0.9699253684025352\n",
      "-1.0529054451739386\n",
      "-0.9665013291954768\n",
      "-0.8841848034994751\n",
      "-0.8499080592733623\n",
      "-0.9728815294473814\n",
      "-1.0213837523166984\n",
      "-1.0618654649638006\n",
      "-0.9641715365684278\n",
      "-1.0082406059547495\n",
      "-1.0139936637494513\n",
      "-0.9267910936592781\n",
      "-0.931933925737612\n",
      "-1.0114479446595908\n",
      "-0.9444449592124846\n",
      "-0.9446189514696367\n",
      "-0.8314521769009993\n",
      "-0.8616314911254972\n",
      "-0.8981104684858585\n",
      "-0.9588178520455043\n",
      "-0.9211611625509214\n",
      "-0.9362627088900404\n",
      "-1.024639422206781\n",
      "-0.9992719552265641\n",
      "-0.9422447640851513\n",
      "-0.9466616885279246\n",
      "-0.9493930282274696\n",
      "-0.9166672976855169\n",
      "-0.8863808586535227\n",
      "-1.0120043889849544\n",
      "-1.0283702230579932\n",
      "-0.9737837348727949\n",
      "-0.8532558389001133\n",
      "-0.9178319922431994\n",
      "-0.9998392650349484\n",
      "-0.9091957684991843\n",
      "-0.9711708031312551\n",
      "-0.9784081130970346\n",
      "-0.8706905491028293\n",
      "-0.8981501836728799\n",
      "-0.9630601909409519\n",
      "-1.0277510959097076\n",
      "-0.9517233862654874\n",
      "-0.9834354417941151\n",
      "-0.955229624068706\n",
      "-0.9700722560054105\n",
      "-0.9281290942549215\n",
      "-0.9517465331255958\n",
      "-1.0124531501394358\n",
      "-0.9397945692650396\n",
      "-0.9776517267822351\n",
      "-1.0205534567399897\n",
      "-0.9353065142828965\n",
      "-1.05288268762254\n",
      "-0.9853861963033907\n",
      "-1.0306835532661593\n",
      "-0.9751792623618676\n",
      "-0.9749535332082054\n",
      "-0.9150891533020782\n",
      "-0.8410841372421165\n",
      "-0.9012970836058356\n",
      "-0.8716799355722097\n",
      "-0.9479428850324847\n",
      "-0.9443572170867309\n",
      "-0.964290606312992\n",
      "-0.9262196119268002\n",
      "-0.9501019876351047\n",
      "-0.9401875466722261\n",
      "-1.0330498593581046\n",
      "-0.9245058094286904\n",
      "-0.984395161071281\n",
      "-0.9859321721029445\n",
      "-1.0346187085958285\n",
      "-1.0486107788234071\n",
      "-1.0347697151514648\n",
      "-0.9969235862160055\n",
      "-1.0549629547519364\n",
      "-0.928288813643924\n",
      "-0.852083177652607\n",
      "-0.9165600439289381\n",
      "-0.9706871301993709\n",
      "-0.9607918395540859\n",
      "-1.025122580224679\n",
      "-1.0460424533046093\n",
      "-1.020615215002964\n",
      "-0.8588748180796117\n",
      "-0.9387831710751562\n",
      "-1.0154833785443662\n",
      "-0.9486128288756086\n",
      "-0.9346775511414681\n",
      "-0.9106037861986851\n",
      "-0.8687437461709918\n",
      "-0.8336391307465986\n",
      "-0.817408714813536\n",
      "-0.9792306173217222\n",
      "-1.0403550697151662\n",
      "-1.0327463951306766\n",
      "-1.0575295639862043\n",
      "-0.9258367109887916\n",
      "-0.9150685901910066\n",
      "-0.8869326449414601\n",
      "-1.0128078282441548\n",
      "-0.9708704366714224\n",
      "-0.878264688107016\n",
      "-0.8565318423189723\n",
      "-0.866042778097847\n",
      "-0.9737264391133618\n",
      "-0.8702320751613409\n",
      "-0.9438971363247469\n",
      "-0.9289075804713798\n",
      "-0.9091263456406322\n",
      "-0.9763266039430576\n",
      "-0.9527991726120181\n",
      "-1.016276246571726\n",
      "-1.0331670796798358\n",
      "-1.0354714269039\n",
      "-0.9487525187106474\n",
      "-0.9712185857087416\n",
      "-1.0505598028541343\n",
      "-1.0782982211575518\n",
      "-0.9816841187100079\n",
      "-0.9781907000429029\n",
      "-0.9450752264949869\n",
      "-1.0048359294332045\n",
      "-0.9564063169652071\n",
      "-1.0193853778669972\n",
      "-1.1079625035955298\n",
      "-1.0056492840149154\n",
      "-1.17099461165611\n",
      "-0.9806497631540214\n",
      "-0.9883189071325231\n",
      "-1.0566306432704506\n",
      "-0.9445259362617376\n",
      "-0.9995644000231376\n",
      "-0.9573463751888222\n",
      "-0.932570053683094\n",
      "-0.9521348797365988\n",
      "-0.9483602062823352\n",
      "-1.0487991551616072\n",
      "-0.969526990002866\n",
      "-0.9365915795545002\n",
      "-0.8613748521730359\n",
      "-0.9291570621127263\n",
      "-1.0085520304741185\n",
      "-1.0089388955659842\n",
      "-0.9704269867918762\n",
      "-1.002444641850355\n",
      "-1.0068765242176465\n",
      "-0.985758630114977\n",
      "-1.0921101300048368\n",
      "-1.0225456609298125\n",
      "-0.8986616674399407\n",
      "-0.9284853914848351\n",
      "-0.9924103065337911\n",
      "-0.9345022437440346\n",
      "-0.972951075659224\n",
      "-0.9568078697673056\n",
      "-0.9396948487411823\n",
      "-0.9194120318992152\n",
      "-0.9427785521163701\n",
      "-0.9205753277970056\n",
      "-0.8949637571968482\n",
      "-0.8665274016818152\n",
      "-0.9411293872307578\n",
      "-1.070234108548776\n",
      "-1.1099836727216268\n",
      "-1.0340643424787919\n",
      "-0.9703875077528423\n",
      "-1.055061414752481\n",
      "-0.963737099976279\n",
      "-0.9592318422236653\n",
      "-0.9608424603926641\n",
      "-1.0064777106037377\n",
      "-1.015734895403911\n",
      "-0.9980124305767921\n",
      "-0.9660616404168012\n",
      "-1.0539567950230906\n",
      "-0.9309613691308244\n",
      "-0.8819146106540853\n",
      "-0.9073771818704566\n",
      "-0.9269181463960628\n",
      "-0.9952196157995786\n",
      "-1.0255004375444425\n",
      "-0.9701490962653074\n",
      "-0.9231030325231803\n",
      "-0.8286205708318756\n",
      "-0.9046870044580527\n",
      "-1.0163935810451643\n",
      "-0.9732770095843297\n",
      "-0.9175861703090227\n",
      "-1.0657076512479908\n",
      "-0.895840181293332\n",
      "-0.9798848041912201\n",
      "-0.8620916289595383\n",
      "-0.9346274568019424\n",
      "-0.8994360017986687\n",
      "-0.8939511473930966\n",
      "-0.9875192571914057\n",
      "-0.8990688435575092\n",
      "-0.9813447836087668\n",
      "-0.9490452942744262\n",
      "-0.9982789920340233\n",
      "-0.9343877008240686\n",
      "-0.8312354319157577\n",
      "-0.868426608408024\n",
      "-0.9190688018471393\n",
      "-0.9432532621675562\n",
      "-0.9266418431369065\n",
      "-0.9527648696332335\n",
      "-0.8977336708853147\n",
      "-0.9030999437092492\n",
      "-0.9056254824181514\n",
      "-0.9084764797702624\n",
      "-1.009069747708668\n",
      "-0.9621889582850944\n",
      "-0.9283688734950802\n",
      "-0.8450774531825043\n",
      "-0.8658559137969944\n",
      "-0.7729262744770206\n",
      "-0.8702315203737775\n",
      "-0.7849050956549338\n",
      "-0.8755419791446419\n",
      "-0.858601672786126\n",
      "-0.9986970575061447\n",
      "-0.864097295459417\n",
      "-0.8954558490107863\n",
      "-0.9748357479215498\n",
      "-0.9341125569642403\n",
      "-1.12561477217696\n",
      "-0.9419663292353648\n",
      "-1.0229116370411189\n",
      "-0.9917023605329337\n",
      "-0.9176480135689107\n",
      "-0.9616056549922894\n",
      "-1.0390598423744983\n",
      "-1.025723660239719\n",
      "-1.0312355446328785\n",
      "-1.0798126733949112\n",
      "-1.0159865711753382\n",
      "-0.9147245662667739\n",
      "-0.9941626703932849\n",
      "-1.0155317024792112\n",
      "-0.951843098654422\n",
      "-0.843944163756036\n",
      "-0.8803589389660748\n",
      "-0.903478805505051\n",
      "-0.8205151399482585\n",
      "-0.8672099741474286\n",
      "-0.9592410686097037\n",
      "-0.992648735902219\n",
      "-0.9411588662022844\n",
      "-0.9231447595881905\n",
      "-0.8918873744123018\n",
      "-0.8444441948251358\n",
      "-0.8952117419285183\n",
      "-0.9449078296384638\n",
      "-0.9397890100172053\n",
      "-0.9280366880262638\n",
      "-0.9929315424009254\n",
      "-0.878574103147418\n",
      "-0.9868962064769118\n",
      "-0.9361310188595213\n",
      "-1.0043973974253366\n",
      "-1.073467820644424\n",
      "-0.9630915047783182\n",
      "-0.976627348793477\n",
      "-0.9199285791564196\n",
      "-0.9398262812818563\n",
      "-0.859724167091086\n",
      "-0.9980046577826893\n",
      "-0.9799871921046404\n",
      "-0.91732718589229\n",
      "-0.9032717211146122\n",
      "-0.9114536115757407\n",
      "-1.0213282247423978\n",
      "-0.9987270015460042\n",
      "-1.1073097072740246\n",
      "-0.9683954988288018\n",
      "-1.016791892069183\n",
      "-1.0369915457134635\n",
      "-0.9603385430001774\n",
      "-0.9366966899203165\n",
      "-0.9619956375790836\n",
      "-1.0445008083655911\n",
      "-1.0107234929207547\n",
      "-1.069339950967948\n",
      "-1.0427084934123028\n",
      "-0.9504456688081475\n",
      "-0.9740086529653268\n",
      "-0.9170160832832751\n",
      "-0.9980352268949093\n",
      "-1.0040419101692823\n",
      "-0.9183673801916195\n",
      "-1.0056891158700179\n",
      "-1.0030317171281151\n",
      "-1.023709345155703\n",
      "-0.932695842975061\n",
      "-0.9836921117444568\n",
      "-0.9974961195970504\n",
      "-0.9863433624606169\n",
      "-1.0335985567250352\n",
      "-0.9884273765656674\n",
      "-1.0792162083735575\n",
      "-1.055613338151034\n",
      "-1.074184139135458\n",
      "-0.9548598309532305\n",
      "-1.0365132887113533\n",
      "-0.9370511092781812\n",
      "-0.9746710859601523\n",
      "-0.9438857026829226\n",
      "-1.0015917372780418\n",
      "-0.9919372687974554\n",
      "-1.0648428112494785\n",
      "-1.0861660205953882\n",
      "-1.1167642511774558\n",
      "-0.9479334243304245\n",
      "-1.0179784577869044\n",
      "-1.087544775264813\n",
      "-1.133438069095465\n",
      "-1.0613178603426212\n",
      "-1.0402661408298193\n",
      "-1.0028981987912162\n",
      "-1.0227468928595884\n",
      "-0.9351207660339047\n",
      "-0.8829033020852457\n",
      "-0.9250737443822992\n",
      "-0.9950762891354282\n",
      "-1.0051418726126646\n",
      "-1.004766812134423\n",
      "-0.9816341577651984\n",
      "-1.01597709414258\n",
      "-0.9423560182866652\n",
      "-0.914137188983579\n",
      "-0.9177795404755122\n",
      "-1.0215743510824495\n",
      "-0.8862275662375299\n",
      "-0.8659600921151541\n",
      "-0.8106793056700102\n",
      "-0.8842856282110257\n",
      "-0.9400052415797389\n",
      "-1.082256993905519\n",
      "-1.0513277591767096\n",
      "-1.0581753557054003\n",
      "-1.0188205744390495\n",
      "-1.0260684075727646\n",
      "-1.0071377962342696\n",
      "-0.9772911962059647\n",
      "-1.0287249040766273\n",
      "-1.061687360150497\n",
      "-0.9659623728448443\n",
      "-1.018290566567463\n",
      "-0.9841372091041068\n",
      "-0.9847900492988617\n",
      "-0.9262557336533133\n",
      "-1.0344638901816994\n",
      "-1.0368427136852882\n",
      "-0.9680635902759305\n",
      "-1.0001767139080313\n",
      "-0.9596163687710884\n",
      "-1.0345070099888123\n",
      "-0.9439003116391537\n",
      "-0.9607475171678705\n",
      "-0.85843868635093\n",
      "-0.8974766533509902\n",
      "-0.8809713649259716\n",
      "-0.8995573580686601\n",
      "-0.7490244330149354\n",
      "-0.77211044103188\n",
      "-0.863497956885895\n",
      "-0.8539536765312137\n",
      "-0.9511218145578514\n",
      "-0.9668836663361019\n",
      "-1.03697926243614\n",
      "-1.037643087245669\n",
      "-1.0545105214425423\n",
      "-1.0403889180166501\n",
      "-1.019559441594602\n",
      "-0.9827279017783815\n",
      "-0.9144469674296586\n",
      "-0.8172971476192076\n",
      "-0.9209749677945522\n",
      "-1.0137806557117992\n",
      "-1.0179152064876282\n",
      "-0.9202105083180273\n",
      "-1.0157926947471847\n",
      "-1.0865756784507987\n",
      "-1.0844732500766698\n",
      "-0.9611856937034835\n",
      "-0.9675348817181094\n",
      "-1.0757491112206234\n",
      "-0.9687206527256508\n",
      "-0.9810481027106598\n",
      "-0.929555300066803\n",
      "-0.9168440616305576\n",
      "-0.903803772951865\n",
      "-0.9907108027647357\n",
      "-1.112325345998432\n",
      "-1.0545255626817875\n",
      "-0.9358256301514561\n",
      "-0.9077578242559001\n",
      "-0.9311805732263168\n",
      "-0.921467838224958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0116284916795424\n",
      "-0.8810769238066658\n",
      "-0.9289001770352886\n",
      "-0.9361852174249792\n",
      "-0.8998647322180767\n",
      "-0.8629968836477014\n",
      "-0.9819159569441982\n",
      "-0.9396335597753849\n",
      "-0.921771040177521\n",
      "-0.8706886416128281\n",
      "-0.8621762335095232\n",
      "-0.9661291191921141\n",
      "-0.852866587460418\n",
      "-0.8961825239555171\n",
      "-0.9326205893176835\n",
      "-0.878242520876458\n",
      "-0.8749676677883506\n",
      "-0.9197683476943553\n",
      "-0.9365369423757001\n",
      "-0.8826140690266392\n",
      "-0.8586436057536341\n",
      "-0.9534411706101702\n",
      "-0.8742523965239071\n",
      "-0.8999440374527619\n",
      "-0.9176057418387603\n",
      "-0.8664293580209758\n",
      "-0.857381985622248\n",
      "-0.9723764438450316\n",
      "-1.096865438544276\n",
      "-1.0576557089907517\n",
      "-1.12914834780217\n",
      "-0.9222591690975456\n",
      "-1.0828840239278745\n",
      "-1.0736260470735375\n",
      "-1.0453878094006108\n",
      "-1.081891457896856\n",
      "-1.112284707462745\n",
      "-0.9961747840473193\n",
      "-1.0550460065126304\n",
      "-1.1252162225607025\n",
      "-1.029531693880159\n",
      "-1.2192561387729373\n",
      "-1.1136629380598717\n",
      "-1.0548401512733485\n",
      "-0.9574363792423237\n",
      "-1.0146596951449431\n",
      "-1.0063094098084382\n",
      "-1.1204808042291616\n",
      "-1.0514690874936505\n",
      "-0.9618301061769666\n",
      "-1.0256441169546135\n",
      "-1.0117363305867646\n",
      "-0.977046036989025\n",
      "-1.0276446889303301\n",
      "-0.9638362089676207\n",
      "-1.003525425809112\n",
      "-1.047208772946967\n",
      "-0.9300715890009534\n",
      "-0.996593892178133\n",
      "-0.9410713089943027\n",
      "-0.9338332515640977\n",
      "-0.954390070946563\n",
      "-0.9295092742336134\n",
      "-0.9386335306221124\n",
      "-0.998242904289925\n",
      "-1.0031987703178882\n",
      "-0.9151811193567518\n",
      "-0.8506066943928744\n",
      "-0.8998669136118073\n",
      "-0.8806658057693089\n",
      "-0.8085443261858104\n",
      "-0.8738989583106898\n",
      "-0.9005643827450837\n",
      "-0.9214935221676556\n",
      "-0.9247250484338134\n",
      "-0.8754610564091583\n",
      "-0.8319763450692065\n",
      "-1.0218395722584683\n",
      "-0.9154540112873547\n",
      "-0.9317785642332775\n",
      "-0.8732627937876636\n",
      "-0.9268158548134676\n",
      "-0.8655024368295827\n",
      "-0.8869525537306369\n",
      "-0.8870096184944194\n",
      "-0.9044316668756267\n",
      "-0.9786968916551065\n",
      "-0.904634159740911\n",
      "-0.92438513002941\n",
      "-0.9445871499263725\n",
      "-0.9076076184549036\n",
      "-0.9078406403929059\n",
      "-0.9626201849012612\n",
      "-1.052078895073728\n",
      "-0.9987102422247097\n",
      "-0.910006075897356\n",
      "-0.8785708466547117\n",
      "-0.9292363263598441\n",
      "-0.998987023463231\n",
      "-0.99232954658501\n",
      "-1.002250119896839\n",
      "-0.8667960254317516\n",
      "-0.8563154762319397\n",
      "-0.9306582655590707\n",
      "-0.958291473079835\n",
      "-0.8693031812681269\n",
      "-0.8414038013049904\n",
      "-0.9412958192258979\n",
      "-0.9575664294413193\n",
      "-0.9614511701704571\n",
      "-0.820728759607094\n",
      "-0.945855310432088\n",
      "-0.9336112073020569\n",
      "-0.9847408204254021\n",
      "-0.8721573933367869\n",
      "-0.8248718524594512\n",
      "-0.8140069745338522\n",
      "-0.8570849676808776\n",
      "-0.9088970461199511\n",
      "-1.0076179909719958\n",
      "-1.086850130705179\n",
      "-0.9753995492515706\n",
      "-0.943968051237839\n",
      "-1.0836040474372812\n",
      "-1.02500368307357\n",
      "-0.9505658574116322\n",
      "-0.7696207253661832\n",
      "-0.7262867449220269\n",
      "-0.8249080773822999\n",
      "-0.821832241379248\n",
      "-0.8427055853212386\n",
      "-0.8630985844973553\n",
      "-0.8932837037344228\n",
      "-0.8997559131138435\n",
      "-0.8963211199270718\n",
      "-0.8246026678472377\n",
      "-0.9468968206677763\n",
      "-0.7906470347942077\n",
      "-0.8448164674460029\n",
      "-0.8413883002488056\n",
      "-0.9118251435132052\n",
      "-0.9288265208288637\n",
      "-0.8483157596556387\n",
      "-0.8477487104483534\n",
      "-0.8340313137407697\n",
      "-0.8817018982177757\n",
      "-0.8821590145441642\n",
      "-0.8437167340341223\n",
      "-0.9042735543896547\n",
      "-0.7856685808658905\n",
      "-0.7428477473861037\n",
      "-0.7760195772100733\n",
      "-0.8093153198049082\n",
      "-0.8722715725860748\n",
      "-0.8798189527597353\n",
      "-0.83297874221805\n",
      "-0.8054598446909647\n",
      "-0.8322015981576174\n",
      "-0.7433931609729801\n",
      "-0.7863698362111536\n",
      "-0.7043597032948545\n",
      "-0.7563518680718642\n",
      "-0.8219088387161967\n",
      "-0.8371090025728355\n",
      "-0.8550598980935694\n",
      "-0.9329392707542004\n",
      "-0.9557120050533882\n",
      "-0.9053259923076882\n",
      "-0.9169356928776139\n",
      "-0.935293410637468\n",
      "-0.9187805290981987\n",
      "-1.0391140995973547\n",
      "-1.0498361747454927\n",
      "-1.017789419256736\n",
      "-0.9569685988692003\n",
      "-0.8800554775375038\n",
      "-1.001083911304451\n",
      "-0.9813713730891684\n",
      "-0.8076544161910199\n",
      "-0.9200105324442334\n",
      "-0.8840744830290896\n",
      "-0.9207572082500693\n",
      "-0.934509150398614\n",
      "-0.9113085358853065\n",
      "-0.9114246902465009\n",
      "-0.857082904108288\n",
      "-0.9540040580992493\n",
      "-0.9772782180816277\n",
      "-0.9754306935942669\n",
      "-0.9376440682221777\n",
      "-0.9295380221144328\n",
      "-1.022970933361793\n",
      "-1.0937229796501011\n",
      "-0.984035147364935\n",
      "-0.9900684275558913\n",
      "-1.0277255430191072\n",
      "-1.0035721149568502\n",
      "-0.9615740020607983\n",
      "-0.9982115485058404\n",
      "-0.9714826961126464\n",
      "-0.845963219880557\n",
      "-0.8956222200929217\n",
      "-0.9730983785361066\n",
      "-0.9311891678071773\n",
      "-0.9197378872484863\n",
      "-0.8538085607680638\n",
      "-0.8307962569065112\n",
      "-0.9267398253697071\n",
      "-1.0093025610860624\n",
      "-0.869102543751784\n",
      "-0.9304749816595438\n",
      "-0.9461328173902346\n",
      "-0.9509334138695995\n",
      "-0.9494839019344842\n",
      "-0.9097467542917175\n",
      "-0.8762586596834823\n",
      "-0.8910580442494322\n",
      "-0.9425797298894509\n",
      "-0.952992873711414\n",
      "-0.9206053651601053\n",
      "-0.8347751043562956\n",
      "-0.8211766068908081\n",
      "-0.810645651692738\n",
      "-0.9252438262651188\n",
      "-0.814029907144885\n",
      "-0.9469228478104458\n",
      "-0.8748312657299082\n",
      "-0.8071937959734148\n",
      "-0.8228676823440688\n",
      "-0.9174965151883222\n",
      "-0.8462447842654036\n",
      "-0.9061632630616245\n",
      "-0.8266152607580151\n",
      "-0.8341333286403104\n",
      "-0.8758847975272513\n",
      "-0.9841204377996661\n",
      "-0.9325914330974668\n",
      "-0.8936960825412706\n",
      "-0.9339586512410072\n",
      "-0.8622239684232578\n",
      "-1.0626187845237258\n",
      "-0.9732584767137722\n",
      "-0.8905620900379697\n",
      "-0.9368603708554503\n",
      "-0.930335949993286\n",
      "-0.9206452341999234\n",
      "-0.838784033100263\n",
      "-0.8400289550603965\n",
      "-0.9285335445460875\n",
      "-0.9058155172005514\n",
      "-0.9461048793565386\n",
      "-0.8926631026068576\n",
      "-0.833718633589724\n",
      "-0.9014317795624592\n",
      "-0.8962902983139103\n",
      "-0.8366331403530347\n",
      "-0.8284592644941938\n",
      "-0.9100216755054358\n",
      "-0.955902636716306\n",
      "-0.925917912508736\n",
      "-1.0008449968744284\n",
      "-0.9330885116790004\n",
      "-0.9412152551984622\n",
      "-0.9093019144385568\n",
      "-0.8557261270205357\n",
      "-0.7734127877375222\n",
      "-0.8498921243010095\n",
      "-0.8117842751116142\n",
      "-0.8361041312446725\n",
      "-0.9102137097960156\n",
      "-0.8887858322670356\n",
      "-0.8026445684556539\n",
      "-0.8156010275208557\n",
      "-0.8146336886477855\n",
      "-0.8646633587807174\n",
      "-0.8967317099364663\n",
      "-0.9965369131288443\n",
      "-1.0138571193126322\n",
      "-0.9293344356225017\n",
      "-0.8821599871055279\n",
      "-0.8794193350382692\n",
      "-0.8281601758501276\n",
      "-0.8631780778933743\n",
      "-0.8837109831336478\n",
      "-0.9947019696164303\n",
      "-0.9939757679762224\n",
      "-0.9539837057649414\n",
      "-0.9959203935811046\n",
      "-0.9539805103197222\n",
      "-0.8205224848711863\n",
      "-0.8665514263632347\n",
      "-0.8889554106618793\n",
      "-0.876433080023585\n",
      "-0.8650476731778493\n",
      "-0.8917072272764087\n",
      "-0.904394421484877\n",
      "-0.8416447380968264\n",
      "-0.7860928190254695\n",
      "-0.8739000465730371\n",
      "-0.8238177115245345\n",
      "-0.9069567098340603\n",
      "-0.8430459418863516\n",
      "-0.9051028793842653\n",
      "-0.7343541296027061\n",
      "-0.8427535905534089\n",
      "-0.7678125785766581\n",
      "-0.8167221239256823\n",
      "-0.7810894775972635\n",
      "-0.8523437186226064\n",
      "-0.9150400164888157\n",
      "-0.9583801972208636\n",
      "-0.8221346545175211\n",
      "-0.8421203190909334\n",
      "-0.8638098164818664\n",
      "-0.9283653615341387\n",
      "-0.9539738445705611\n",
      "-0.9492189524632705\n",
      "-0.8945290598779062\n",
      "-0.878341442561472\n",
      "-0.8058184869542058\n",
      "-0.9196331554990664\n",
      "-0.8705479044050216\n",
      "-0.9447412145305898\n",
      "-0.7995165018781646\n",
      "-0.9503287223972687\n",
      "-0.8502839498963694\n",
      "-0.8448871049396072\n",
      "-0.8773622849625486\n",
      "-0.9070222873220101\n",
      "-0.8845809802116361\n",
      "-0.8530311242577084\n",
      "-0.8903308823718207\n",
      "-0.948806139357625\n",
      "-0.9442661942868262\n",
      "-0.9506162113754592\n",
      "-0.9398805400913981\n",
      "-0.9116651919964017\n",
      "-1.0046519500760653\n",
      "-0.9286540909438162\n",
      "-0.8410675785509567\n",
      "-0.8883652100043892\n",
      "-1.034583181088671\n",
      "-0.9091937964442927\n",
      "-0.9838235719438279\n",
      "-0.932457911919096\n",
      "-0.7952707000498882\n",
      "-0.8064739053792704\n",
      "-0.7864725045909354\n",
      "-0.813251795613797\n",
      "-0.9773957626294538\n",
      "-0.8986764835888364\n",
      "-0.9098134487628173\n",
      "-0.901336855810396\n",
      "-0.9194127024031872\n",
      "-0.8917682470746957\n",
      "-0.8768844763182143\n",
      "-0.8564033839271978\n",
      "-0.9054961502327291\n",
      "-0.8739483312047266\n",
      "-0.7970686575453886\n",
      "-0.826536498559952\n",
      "-0.8244927017311675\n",
      "-0.8249385125360272\n",
      "-0.9571314083671983\n",
      "-0.995626059098758\n",
      "-0.9253506307423529\n",
      "-0.8909137249624625\n",
      "-0.8607793134494252\n",
      "-0.897936984025487\n",
      "-0.9624122441950772\n",
      "-0.8163421570829432\n",
      "-0.7596409542495783\n",
      "-0.7227014359124255\n",
      "-0.7132584495292521\n",
      "-0.6848135449365338\n",
      "-0.7702779119667896\n",
      "-0.827670653940938\n",
      "-0.7171844681257508\n",
      "-0.8552230907825639\n",
      "-0.8487081390251942\n",
      "-0.7647117093227239\n",
      "-0.8240236537379592\n",
      "-0.8783425114853577\n",
      "-0.7753209802985326\n",
      "-0.7992474761380731\n",
      "-0.8595761409530209\n",
      "-0.8037635320304806\n",
      "-0.7852434991571561\n",
      "-0.9187990112876602\n",
      "-0.7888018788086801\n",
      "-0.7721739920993225\n",
      "-0.7273095772159321\n",
      "-0.7364196216620823\n",
      "-0.8263765629979818\n",
      "-0.8175853726989434\n",
      "-0.8718612172467098\n",
      "-0.7721353375776723\n",
      "-0.8482831047483121\n",
      "-0.9054937336562148\n",
      "-0.8439299653740318\n",
      "-0.7590268411546599\n",
      "-0.7532196843801456\n",
      "-0.7120824996052378\n",
      "-0.7777600991226017\n",
      "-0.8150442017050159\n",
      "-0.7657079465573846\n",
      "-0.7702399508122705\n",
      "-0.7081619298786428\n",
      "-0.7542704772647234\n",
      "-0.7684031064935591\n",
      "-0.7871162138227913\n",
      "-0.8254647734994993\n",
      "-0.781905735147211\n",
      "-0.7709279396009352\n",
      "-0.7036649061314545\n",
      "-0.6648159403057563\n",
      "-0.6693254094912792\n",
      "-0.7712708486894853\n",
      "-0.8126398137256037\n",
      "-0.7138830169420988\n",
      "-0.7955249991897736\n",
      "-0.708240525788097\n",
      "-0.8047443968276278\n",
      "-0.7869289264936398\n",
      "-0.7603220065682835\n",
      "-0.7907442097373693\n",
      "-0.8050780383066363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7586058282738319\n",
      "-0.8710688738845579\n",
      "-0.8807312616500977\n",
      "-0.895327959805192\n",
      "-0.7726559891903747\n",
      "-0.7102954342748974\n",
      "-0.7644413049315931\n",
      "-0.8535825856887043\n",
      "-0.8611983087772835\n",
      "-0.8957945712439513\n",
      "-0.9668074457323806\n",
      "-0.9960340463288122\n",
      "-0.9108780231395844\n",
      "-0.8869343532559772\n",
      "-0.9029938629185941\n",
      "-0.7470162056128835\n",
      "-0.8132787684620597\n",
      "-0.72770823524479\n",
      "-0.8381535905782995\n",
      "-0.8296564651540326\n",
      "-0.7827072640320615\n",
      "-0.8283343673968147\n",
      "-0.870852593586646\n",
      "-0.7986831632082421\n",
      "-0.8820934049998407\n",
      "-0.968814973995435\n",
      "-0.8944041182040228\n",
      "-0.9149191240560376\n",
      "-0.9782751898368586\n",
      "-0.9030176197523028\n",
      "-0.9738617127097007\n",
      "-0.9097534459521506\n",
      "-0.9140131728402529\n",
      "-0.9249296520720256\n",
      "-0.8488668231716578\n",
      "-0.8301768761841338\n",
      "-0.7663787012909153\n",
      "-0.8743571883494157\n",
      "-0.7842511963212462\n",
      "-0.8708076388436498\n",
      "-0.8256249841255953\n",
      "-0.8466394949981267\n",
      "-0.8482864621735745\n",
      "-0.8978640956442916\n",
      "-0.8553787735847046\n",
      "-0.8433292062310097\n",
      "-0.8912417966540451\n",
      "-0.8982200801315506\n",
      "-0.8316108346386433\n",
      "-0.916524388865606\n",
      "-0.9307212758939819\n",
      "-0.9370136986437322\n",
      "-0.8353776137857583\n",
      "-0.8960313363496646\n",
      "-0.8671429359724135\n",
      "-0.784628102066102\n",
      "-0.7746146774840093\n",
      "-0.9076289099966978\n",
      "-0.894666025576331\n",
      "-0.8464722338209244\n",
      "-0.9298203673725609\n",
      "-0.8818800895750856\n",
      "-0.8104392217788614\n",
      "-0.8192903294633563\n",
      "-0.8829596956722982\n",
      "-0.8443893817640304\n",
      "-0.9090097120712639\n",
      "-0.932601799433141\n",
      "-0.8646946836806609\n",
      "-0.9424319844249982\n",
      "-0.7804427220872742\n",
      "-0.7834487338519576\n",
      "-0.7563102173354357\n",
      "-0.8228916332380005\n",
      "-0.752666683463895\n",
      "-0.8036727488156211\n",
      "-0.8415197232427687\n",
      "-0.9476745316257926\n",
      "-0.9166095291092209\n",
      "-0.7817034223518896\n",
      "-0.823230623187038\n",
      "-0.919403836223341\n",
      "-0.9327546734262715\n",
      "-0.8936051691439668\n",
      "-0.947823422927321\n",
      "-0.9019575777605682\n",
      "-0.8235396826804086\n",
      "-0.9647745578787839\n",
      "-0.9320636156610845\n",
      "-0.9131676838246449\n",
      "-0.9285197527597882\n",
      "-0.8080892074639116\n",
      "-0.9426866858134879\n",
      "-0.8898511906220781\n",
      "-0.7098184711923105\n",
      "-0.7721927091017726\n",
      "-0.7942195318966081\n",
      "-0.8047277273209511\n",
      "-0.7685453439577475\n",
      "-0.8830018052327633\n",
      "-0.7986891406655969\n",
      "-0.8585578004456699\n",
      "-0.7989068627578088\n",
      "-0.738123088122097\n",
      "-0.8084254059827382\n",
      "-0.7274740390756725\n",
      "-0.7899393889127466\n",
      "-0.7645449746423016\n",
      "-0.6301137557627308\n",
      "-0.7410224417768962\n",
      "-0.6609644160129802\n",
      "-0.8049510406181583\n",
      "-0.7345619398621748\n",
      "-0.7722628724114201\n",
      "-0.8003614429551308\n",
      "-0.8144253394119334\n",
      "-0.6978005570678512\n",
      "-0.7917636869647217\n",
      "-0.7560017235670023\n",
      "-0.7634531861703063\n",
      "-0.7430346584486945\n",
      "-0.7771289605367003\n",
      "-0.7553116740761441\n",
      "-0.8288567340161243\n",
      "-0.7630050513141178\n",
      "-0.775913536194618\n",
      "-0.854253621490081\n",
      "-0.7566655405885743\n",
      "-0.8524114355608972\n",
      "-0.8893753129438922\n",
      "-0.764149495820073\n",
      "-0.7972972119402126\n",
      "-0.7786883787140008\n",
      "-0.7233666714252719\n",
      "-0.7487464791386141\n",
      "-0.8905920211837728\n",
      "-0.8318757466493911\n",
      "-0.7878581063487906\n",
      "-0.6946617866064968\n",
      "-0.6618003072683798\n",
      "-0.8225040183320271\n",
      "-0.6927471702903689\n",
      "-0.7110910731265307\n",
      "-0.6732951615468179\n",
      "-0.7982328622012143\n",
      "-0.7908004620496616\n",
      "-0.8137992583706336\n",
      "-0.7469093731984042\n",
      "-0.7217876245172767\n",
      "-0.7945010523918224\n",
      "-0.8967681118093797\n",
      "-0.8356040105574994\n",
      "-0.8459432753897234\n",
      "-0.8063237915570036\n",
      "-0.7993632311301402\n",
      "-0.7067717342677532\n",
      "-0.8776579279006705\n",
      "-0.7638517729799148\n",
      "-0.8442049962034603\n",
      "-0.7811302227501814\n",
      "-0.766484512289048\n",
      "-0.7395666722082731\n",
      "-0.7649225494797032\n",
      "-0.6976101169048408\n",
      "-0.83203745703282\n",
      "-0.7404938517183666\n",
      "-0.8039265135036165\n",
      "-0.7512034826010096\n",
      "-0.8499733479188727\n",
      "-0.6727679064806293\n",
      "-0.7215779730025874\n",
      "-0.7424827146877703\n",
      "-0.7056403453133889\n",
      "-0.861604297684388\n",
      "-0.795524679735607\n",
      "-0.7423681456597149\n",
      "-0.8175306855411059\n",
      "-0.7388315756920141\n",
      "-0.7553130473619121\n",
      "-0.8718462113325297\n",
      "-0.8839808384650325\n",
      "-0.8882469325277472\n",
      "-0.8079734462526713\n",
      "-0.7672954811978618\n",
      "-0.772209149449423\n",
      "-0.8803781447571462\n",
      "-0.8339390641454092\n",
      "-0.7499315794971877\n",
      "-0.8488183528887738\n",
      "-0.8881317271109381\n",
      "-0.8640976551111466\n",
      "-0.7715641249648612\n",
      "-0.7936234812787268\n",
      "-0.7093566890892609\n",
      "-0.8018749699733073\n",
      "-0.6373797075433766\n",
      "-0.8008323112227866\n",
      "-0.7789331614627026\n",
      "-0.8475120267098504\n",
      "-0.791107538955399\n",
      "-0.7655252023019772\n",
      "-0.711182699511633\n",
      "-0.6788356885314066\n",
      "-0.7220187406406608\n",
      "-0.7671089260481646\n",
      "-0.8141262909813496\n",
      "-0.7462635440902683\n",
      "-0.6572972214818161\n",
      "-0.7387408530502169\n",
      "-0.7632394256019945\n",
      "-0.6226626669323992\n",
      "-0.7297237181800635\n",
      "-0.7270766003101864\n",
      "-0.7588709530362863\n",
      "-0.7601857060549932\n",
      "-0.7808198109994003\n",
      "-0.7594254734522732\n",
      "-0.6743991393914651\n",
      "-0.8022197262705786\n",
      "-0.8414361980266696\n",
      "-0.7873434407490104\n",
      "-0.8002701021349738\n",
      "-0.7481651070692654\n",
      "-0.7585033233450474\n",
      "-0.804462621531525\n",
      "-0.8347220972117008\n",
      "-0.8152902789570394\n",
      "-0.7584502983415206\n",
      "-0.76865858470921\n",
      "-0.7190705412213841\n",
      "-0.7451615666263228\n",
      "-0.7343137161387068\n",
      "-0.6740087687511461\n",
      "-0.5966874253550388\n",
      "-0.5338008656508871\n",
      "-0.5695984490765399\n",
      "-0.6304057505463698\n",
      "-0.656971028372906\n",
      "-0.5989424400222353\n",
      "-0.7122833191502559\n",
      "-0.6756912597827814\n",
      "-0.5840810219232055\n",
      "-0.6438241094319328\n",
      "-0.6882724088183538\n",
      "-0.5991131799458341\n",
      "-0.6419558449765697\n",
      "-0.7363250397427432\n",
      "-0.7406727640256813\n",
      "-0.6539461936343154\n",
      "-0.737639045547606\n",
      "-0.5970545115020234\n",
      "-0.6999441341961062\n",
      "-0.6791776279855652\n",
      "-0.7211258183573238\n",
      "-0.5895937230259333\n",
      "-0.6006742402489399\n",
      "-0.6685690967000811\n",
      "-0.7264583494293246\n",
      "-0.6850955743527316\n",
      "-0.7781898147295567\n",
      "-0.7149546137967115\n",
      "-0.8385043112929466\n",
      "-0.7052553785142037\n",
      "-0.7529347602882334\n",
      "-0.6976639317770771\n",
      "-0.6045934657961396\n",
      "-0.6502179529618962\n",
      "-0.6568090869740196\n",
      "-0.6717039480064644\n",
      "-0.7168157104591957\n",
      "-0.7984805541076094\n",
      "-0.8466249649298478\n",
      "-0.7990494499242812\n",
      "-0.7215547780218174\n",
      "-0.8541920300704786\n",
      "-0.8064685880152207\n",
      "-0.8213820690496049\n",
      "-0.7229551067803542\n",
      "-0.7488842809978249\n",
      "-0.6320295214065565\n",
      "-0.6695026850180782\n",
      "-0.6424492926125654\n",
      "-0.6499293397471172\n",
      "-0.7132063976182091\n",
      "-0.704538448266223\n",
      "-0.7554460211984368\n",
      "-0.6511323614851797\n",
      "-0.6696757370737713\n",
      "-0.6491011547384289\n",
      "-0.6371420368967227\n",
      "-0.7149284061841734\n",
      "-0.6499103528578439\n",
      "-0.6204505574241812\n",
      "-0.6554115939993131\n",
      "-0.6836718851224647\n",
      "-0.7087938668982359\n",
      "-0.6899014495901042\n",
      "-0.6688656940434097\n",
      "-0.6380245270285159\n",
      "-0.73857357578367\n",
      "-0.6879346338367475\n",
      "-0.6824785963721358\n",
      "-0.7259160545328095\n",
      "-0.6512440264838578\n",
      "-0.6370602142964505\n",
      "-0.5647893825445338\n",
      "-0.5387135632456023\n",
      "-0.5344297662608827\n",
      "-0.6912178395126509\n",
      "-0.5436201954599362\n",
      "-0.583203505681359\n",
      "-0.5921707797038989\n",
      "-0.6904879429249456\n",
      "-0.6265019165635437\n",
      "-0.5831846551431468\n",
      "-0.6154817432295226\n",
      "-0.6228513403665187\n",
      "-0.5471949477254671\n",
      "-0.5690971204824603\n",
      "-0.5467478206660923\n",
      "-0.5772058519460669\n",
      "-0.5352744405709483\n",
      "-0.5657522205354601\n",
      "-0.5800069951311233\n",
      "-0.6842213184195578\n",
      "-0.5319342924114742\n",
      "-0.5973473794459004\n",
      "-0.6687168066427358\n",
      "-0.5312212794731598\n",
      "-0.6840940520401672\n",
      "-0.6138472128175689\n",
      "-0.5568908146458262\n",
      "-0.5721077127945178\n",
      "-0.6477014510589763\n",
      "-0.5873184231759053\n",
      "-0.6576508916478977\n",
      "-0.64531518914454\n",
      "-0.6308583259351515\n",
      "-0.6736276035926292\n",
      "-0.5548453037914353\n",
      "-0.6028571627623467\n",
      "-0.5323834789542042\n",
      "-0.6375652356281706\n",
      "-0.6255318053620553\n",
      "-0.5237494928006725\n",
      "-0.573451334323059\n",
      "-0.51743390099722\n",
      "-0.6773937383255466\n",
      "-0.6135316456034314\n",
      "-0.7045849029156567\n",
      "-0.6260845202751135\n",
      "-0.6072834034323353\n",
      "-0.5258723593435936\n",
      "-0.7103876478231285\n",
      "-0.7536552763063707\n",
      "-0.6470969096638631\n",
      "-0.688604622370279\n",
      "-0.6688808305561533\n",
      "-0.7071948865497936\n",
      "-0.6856091556003718\n",
      "-0.6166937919109292\n",
      "-0.5604913298041162\n",
      "-0.5588458568992638\n",
      "-0.6249522769385761\n",
      "-0.5450652507528071\n",
      "-0.5260686980360815\n",
      "-0.6003885576769078\n",
      "-0.5870319629941817\n",
      "-0.5371412972169748\n",
      "-0.5789082234723674\n",
      "-0.5186773866474211\n",
      "-0.5624518755011808\n",
      "-0.5384124601506647\n",
      "-0.5094375859553648\n",
      "-0.4772907070111194\n",
      "-0.5426055593946545\n",
      "-0.48591452829789444\n",
      "-0.5361626959536482\n",
      "-0.5105759255039475\n",
      "-0.4774002968967681\n",
      "-0.5934818721792222\n",
      "-0.5885893850832641\n",
      "-0.6234610735174253\n",
      "-0.6515760350953085\n",
      "-0.5772374946185783\n",
      "-0.5460766062263863\n",
      "-0.5487335000727858\n",
      "-0.5677589552951362\n",
      "-0.6396172934711716\n",
      "-0.679814836774084\n",
      "-0.5439700348833401\n",
      "-0.5508788264076344\n",
      "-0.6556007913352372\n",
      "-0.5518875036381254\n",
      "-0.5418447436677015\n",
      "-0.5115623106644382\n",
      "-0.5364282342936006\n",
      "-0.618003784957158\n",
      "-0.6065618870128819\n",
      "-0.585421285305586\n",
      "-0.5945052053262506\n",
      "-0.53030710581906\n",
      "-0.6296020431666957\n",
      "-0.5528676304777498\n",
      "-0.6077942670047958\n",
      "-0.5930049766460546\n",
      "-0.6042825655545556\n",
      "-0.5390956143633098\n",
      "-0.5432648864732745\n",
      "-0.5546345796754822\n",
      "-0.5044467854286311\n",
      "-0.4451655913454673\n",
      "-0.5961576282761439\n",
      "-0.5153537345391707\n",
      "-0.5776825145319814\n",
      "-0.5049488519470359\n",
      "-0.5260595064109039\n",
      "-0.48622218632912634\n",
      "-0.41402607376744016\n",
      "-0.4638499650065313\n",
      "-0.38164020787000014\n",
      "-0.5062731412270524\n",
      "-0.5751209522607839\n",
      "-0.4905681320405358\n",
      "-0.581520976439325\n",
      "-0.3943346421824129\n",
      "-0.38971106035387276\n",
      "-0.4259726836817991\n",
      "-0.4749014701473058\n",
      "-0.456382630687477\n",
      "-0.357755608835921\n",
      "-0.3884995771897671\n",
      "-0.40916310688646956\n",
      "-0.4475583370343708\n",
      "-0.33667792318029943\n",
      "-0.4300760455411954\n",
      "-0.4778719243842667\n",
      "-0.5420672774483184\n",
      "-0.5617112521284832\n",
      "-0.5087770353336422\n",
      "-0.5318143041523664\n",
      "-0.4646205414802617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5520898927055408\n",
      "-0.521812653148545\n",
      "-0.4122265103917536\n",
      "-0.36563120534128907\n",
      "-0.4568650038211482\n",
      "-0.5738293408478974\n",
      "-0.4517372177024371\n",
      "-0.4086304133404733\n",
      "-0.4902570230642521\n",
      "-0.596434958088782\n",
      "-0.5631655558367289\n",
      "-0.49919599348316485\n",
      "-0.49072621139999634\n",
      "-0.44020901421430314\n",
      "-0.4982699528684767\n",
      "-0.5483070214580738\n",
      "-0.5341815730095459\n",
      "-0.5804898495642377\n",
      "-0.4944237621270519\n",
      "-0.5533920356039528\n",
      "-0.5757349264184622\n",
      "-0.5978913962541103\n",
      "-0.5848794565383069\n",
      "-0.5793766769940687\n",
      "-0.5322910786492951\n",
      "-0.47120708276723167\n",
      "-0.5578248901402713\n",
      "-0.49385306421869934\n",
      "-0.46899308168082393\n",
      "-0.4134076729816082\n",
      "-0.5600481698188844\n",
      "-0.5353805709124744\n",
      "-0.5277044254312915\n",
      "-0.5539415188158764\n",
      "-0.6252126990705401\n",
      "-0.6288233370855562\n",
      "-0.6085639172924509\n",
      "-0.5903692578006654\n",
      "-0.5946264674477991\n",
      "-0.4178490188420541\n",
      "-0.5690416202967776\n",
      "-0.47725873017986764\n",
      "-0.546413461378268\n",
      "-0.580577616359342\n",
      "-0.5325665108434025\n",
      "-0.6085620584925607\n",
      "-0.5846741695207727\n",
      "-0.5458657772411655\n",
      "-0.4972922077882721\n",
      "-0.5833484114745987\n",
      "-0.5793091319054827\n",
      "-0.5229037797014886\n",
      "-0.592185116137108\n",
      "-0.5535523149344087\n",
      "-0.5864640963863148\n",
      "-0.464855199758156\n",
      "-0.6564712838447181\n",
      "-0.5173590574957507\n",
      "-0.5258893095519726\n",
      "-0.5034088677581404\n",
      "-0.46427127872202617\n",
      "-0.5041735882947672\n",
      "-0.45951105629453537\n",
      "-0.501238269925002\n",
      "-0.46147416560634286\n",
      "-0.41293577273494114\n",
      "-0.42267290164118043\n",
      "-0.520933722750656\n",
      "-0.5171505438669968\n",
      "-0.6053166311758912\n",
      "-0.45709463058716426\n",
      "-0.5230733636671485\n",
      "-0.41215091679234933\n",
      "-0.501039362778518\n",
      "-0.5017597213365296\n",
      "-0.526291266279295\n",
      "-0.4909173527226554\n",
      "-0.4962409285949866\n",
      "-0.5192446027688865\n",
      "-0.4118509171115818\n",
      "-0.5134378410106211\n",
      "-0.5132286007321875\n",
      "-0.3728318574987236\n",
      "-0.5075730021983702\n",
      "-0.4804149783984565\n",
      "-0.4357380790815849\n",
      "-0.49762995539704735\n",
      "-0.5536823019638611\n",
      "-0.4584465552741716\n",
      "-0.5077947540815779\n",
      "-0.5691149873128115\n",
      "-0.4965758369037121\n",
      "-0.6397136256551299\n",
      "-0.5400993146524263\n",
      "-0.47442228158927796\n",
      "-0.6016447811663335\n",
      "-0.5175773167137993\n",
      "-0.5290437654356197\n",
      "-0.5641640693826555\n",
      "-0.5608488969999146\n",
      "-0.5200214641644988\n",
      "-0.5236610790389727\n",
      "-0.5803697360152028\n",
      "-0.6277593492373912\n",
      "-0.6626156267338956\n",
      "-0.5352160373284859\n",
      "-0.6107059537847183\n",
      "-0.5055583447364956\n",
      "-0.5469241392418766\n",
      "-0.6408982036689683\n",
      "-0.6654297114395874\n",
      "-0.5334730608570992\n",
      "-0.5359357582541596\n",
      "-0.5646461425285143\n",
      "-0.6297301727000963\n",
      "-0.5432517347191312\n",
      "-0.4558406173881253\n",
      "-0.5048533786093762\n",
      "-0.4736374609407383\n",
      "-0.6133550340737222\n",
      "-0.7388418075295732\n",
      "-0.6514027666554969\n",
      "-0.5238579574019353\n",
      "-0.6609102198683\n",
      "-0.670079912858674\n",
      "-0.6311460987645194\n",
      "-0.5785757497830406\n",
      "-0.5295423450946299\n",
      "-0.5510666762186874\n",
      "-0.4654017364794893\n",
      "-0.45028178260787477\n",
      "-0.39718877039591866\n",
      "-0.4118605633181635\n",
      "-0.3628654255712346\n",
      "-0.481322286556372\n",
      "-0.5462246076602639\n",
      "-0.5226063948686273\n",
      "-0.3824604884831439\n",
      "-0.4334672739733912\n",
      "-0.3704276128875806\n",
      "-0.375106557904738\n",
      "-0.38424174382726084\n",
      "-0.40020658245374235\n",
      "-0.383792847352347\n",
      "-0.5555987520698067\n",
      "-0.4581756896667456\n",
      "-0.5731194553624371\n",
      "-0.6455369586441574\n",
      "-0.5504100250100656\n",
      "-0.547266274562784\n",
      "-0.5989752723148722\n",
      "-0.7108235363428063\n",
      "-0.5300851441566862\n",
      "-0.5927502207520693\n",
      "-0.4915291468711063\n",
      "-0.5385102841519334\n",
      "-0.5557232186035233\n",
      "-0.5454381491936212\n",
      "-0.5137631780136448\n",
      "-0.4770381544378026\n",
      "-0.45815057296659006\n",
      "-0.6104639918343497\n",
      "-0.5229446669845768\n",
      "-0.49819906499577415\n",
      "-0.47421742033591546\n",
      "-0.5481837820299215\n",
      "-0.5346882029791402\n",
      "-0.562928372707168\n",
      "-0.5575039204974347\n",
      "-0.6191239146193074\n",
      "-0.4928706432284576\n",
      "-0.5714926884250401\n",
      "-0.47947470477433946\n",
      "-0.5367407914404109\n",
      "-0.5451134042171323\n",
      "-0.482460350338344\n",
      "-0.5771244241824132\n",
      "-0.5224657461384054\n",
      "-0.5514328009182762\n",
      "-0.46233864573015193\n",
      "-0.5532203941775001\n",
      "-0.5034697318204613\n",
      "-0.5867348219288332\n",
      "-0.5503991232921347\n",
      "-0.6339930644085594\n",
      "-0.6171915304946267\n",
      "-0.6557622895791971\n",
      "-0.6644947481693945\n",
      "-0.5930868003723806\n",
      "-0.5300516164545163\n",
      "-0.6139188809495295\n",
      "-0.6337575786728218\n",
      "-0.6033477585807229\n",
      "-0.5509245528318752\n",
      "-0.7164660868903765\n",
      "-0.6193685268606308\n",
      "-0.6629732594134007\n",
      "-0.7827866205648644\n",
      "-0.6198047495797219\n",
      "-0.7121375447392952\n",
      "-0.6746298073674256\n",
      "-0.6772677972761396\n",
      "-0.781281198110647\n",
      "-0.6155012874745192\n",
      "-0.6441180028736054\n",
      "-0.7318230349077823\n",
      "-0.5694945654445018\n",
      "-0.596343197631515\n",
      "-0.5757561904669027\n",
      "-0.5891840458337702\n",
      "-0.6959324755282544\n",
      "-0.6246812324984811\n",
      "-0.6585004020557969\n",
      "-0.6574199884039711\n",
      "-0.5155094353224238\n",
      "-0.5663989249011943\n",
      "-0.6207647924014673\n",
      "-0.6359807923278789\n",
      "-0.7238695223957667\n",
      "-0.6183115721919872\n",
      "-0.6465066156717286\n",
      "-0.6978070603211479\n",
      "-0.7552841963240464\n",
      "-0.7378119119223097\n",
      "-0.6610742066944362\n",
      "-0.6791272356331368\n",
      "-0.593009125266789\n",
      "-0.5771117397969291\n",
      "-0.6445679641487218\n",
      "-0.6832143848291292\n",
      "-0.7556392094113012\n",
      "-0.6652922759373938\n",
      "-0.6339120135134652\n",
      "-0.5963669506102066\n",
      "-0.6159684670207431\n",
      "-0.6269145248329083\n",
      "-0.6855218649461315\n",
      "-0.7195911472645306\n",
      "-0.6542108513105693\n",
      "-0.7119865886077191\n",
      "-0.6646509354651485\n",
      "-0.6777374725316264\n",
      "-0.7627927322111809\n",
      "-0.6936091474448214\n",
      "-0.7052551942489544\n",
      "-0.6541234330646365\n",
      "-0.6932350929603084\n",
      "-0.7366931991472291\n",
      "-0.6937515140947438\n",
      "-0.7777786759077722\n",
      "-0.6800214893695318\n",
      "-0.7711759946032184\n",
      "-0.7101561277841992\n",
      "-0.6678977967742501\n",
      "-0.710796530034754\n",
      "-0.6652229112685446\n",
      "-0.7299894169052442\n",
      "-0.8167705950060771\n",
      "-0.7675198332105678\n",
      "-0.7050970743000213\n",
      "-0.6681160612391477\n",
      "-0.6830102235733401\n",
      "-0.710962867387798\n",
      "-0.667998442040801\n",
      "-0.6714425647227847\n",
      "-0.6475657299283236\n",
      "-0.7526424497076075\n",
      "-0.6763577646236895\n",
      "-0.7337676393891062\n",
      "-0.6547960752393639\n",
      "-0.6620410115380845\n",
      "-0.610048594797285\n",
      "-0.5328369834526411\n",
      "-0.6516845848614943\n",
      "-0.5904078990251239\n",
      "-0.6566380433974905\n",
      "-0.6282830484320633\n",
      "-0.6288488541594379\n",
      "-0.6542181132750803\n",
      "-0.7502350634428151\n",
      "-0.6967076406926033\n",
      "-0.7003775043443257\n",
      "-0.6830742228085401\n",
      "-0.7893939586910268\n",
      "-0.6837343737026393\n",
      "-0.7459183253301614\n",
      "-0.7732908770160539\n",
      "-0.7801465402940848\n",
      "-0.6456908408316647\n",
      "-0.6247505801307458\n",
      "-0.5791438330380564\n",
      "-0.6055328141241879\n",
      "-0.6649130060418299\n",
      "-0.7346445749336151\n",
      "-0.7595388314909287\n",
      "-0.7107909686209937\n",
      "-0.6070819423773517\n",
      "-0.7103131681475044\n",
      "-0.699419525349597\n",
      "-0.6423231227317496\n",
      "-0.6456284654528042\n",
      "-0.6718222494824858\n",
      "-0.6009026379042975\n",
      "-0.5939987135393507\n",
      "-0.5345126815131713\n",
      "-0.6003101118458064\n",
      "-0.6488359415570975\n",
      "-0.6151372375190203\n",
      "-0.5994953863783207\n",
      "-0.6797893421761555\n",
      "-0.619747530832803\n",
      "-0.64071343052936\n",
      "-0.5409928804272786\n",
      "-0.6012693428136672\n",
      "-0.5094879896702688\n",
      "-0.609363771936675\n",
      "-0.6163384071935465\n",
      "-0.5266369577201172\n",
      "-0.4863856377071826\n",
      "-0.48082045885181235\n",
      "-0.6178183165661438\n",
      "-0.6008322497614169\n",
      "-0.5736550952377428\n",
      "-0.6679040919821245\n",
      "-0.7180868454889272\n",
      "-0.673562765577171\n",
      "-0.6953272850939256\n",
      "-0.6483226260142199\n",
      "-0.6334718558458934\n",
      "-0.7205039327492873\n",
      "-0.6936901788654847\n",
      "-0.745409305735782\n",
      "-0.6651570192040099\n",
      "-0.6256018752088661\n",
      "-0.7034582273795457\n",
      "-0.6290363698089556\n",
      "-0.5949692621776718\n",
      "-0.6383022846407669\n",
      "-0.564589935676526\n",
      "-0.6890824189907768\n",
      "-0.6191913614852271\n",
      "-0.6085857972760793\n",
      "-0.6900366338979411\n",
      "-0.6658608421572028\n",
      "-0.6038250400486556\n",
      "-0.7558566344616718\n",
      "-0.7063607821152298\n",
      "-0.6542072312060198\n",
      "-0.6100285184294723\n",
      "-0.6222070087928305\n",
      "-0.6882154983067987\n",
      "-0.6031394511767321\n",
      "-0.7729048196083838\n",
      "-0.573145606966589\n",
      "-0.5982379264714307\n",
      "-0.6042247220191902\n",
      "-0.6205525117469196\n",
      "-0.5685363524319768\n",
      "-0.5833452793264656\n",
      "-0.5468970830511536\n",
      "-0.5471578358179415\n",
      "-0.6525155194237128\n",
      "-0.4527815598543638\n",
      "-0.43190847162075324\n",
      "-0.4249140951187425\n",
      "-0.42382379492527306\n",
      "-0.5243695402185222\n",
      "-0.4430897616833064\n",
      "-0.49199431559704826\n",
      "-0.5855158270607664\n",
      "-0.5375677706742696\n",
      "-0.6325509587322709\n",
      "-0.6271247736089757\n",
      "-0.6673776255306205\n",
      "-0.6832091964629193\n",
      "-0.7022210835367632\n",
      "-0.5482695535650477\n",
      "-0.6238009962515679\n",
      "-0.6309775585013268\n",
      "-0.6251915741069014\n",
      "-0.5316420235274287\n",
      "-0.6116073582956285\n",
      "-0.5748451771518094\n",
      "-0.5016400632336165\n",
      "-0.5035120698346542\n",
      "-0.49229310746299104\n",
      "-0.47374542035050393\n",
      "-0.3938230085571601\n",
      "-0.43809338574235446\n",
      "-0.5333366694456854\n",
      "-0.5656397310294298\n",
      "-0.5696719612270555\n",
      "-0.5588584384938039\n",
      "-0.5509471220307113\n",
      "-0.5348374892330757\n",
      "-0.5629217932996363\n",
      "-0.37289024534054005\n",
      "-0.4683515181441594\n",
      "-0.5223400382399574\n",
      "-0.4895504009735499\n",
      "-0.39655225031516445\n",
      "-0.3695844026058862\n",
      "-0.38834106129226514\n",
      "-0.4087538774356018\n",
      "-0.3779275385187216\n",
      "-0.37826706099791235\n",
      "-0.5715502198051584\n",
      "-0.43252017164336787\n",
      "-0.4468943216691626\n",
      "-0.507323507928649\n",
      "-0.5133275917163599\n",
      "-0.6016049033036348\n",
      "-0.4922341949511886\n",
      "-0.47522427477042734\n",
      "-0.4600934185178116\n",
      "-0.4270575636968033\n",
      "-0.46358684322021043\n",
      "-0.5593990319196901\n",
      "-0.48919072132091845\n",
      "-0.4212396969912258\n",
      "-0.5085812409619694\n",
      "-0.5610546768886173\n",
      "-0.48145359703867646\n",
      "-0.43406901586120616\n",
      "-0.43662946901332067\n",
      "-0.3903014708638513\n",
      "-0.3415533452762555\n",
      "-0.380544593688278\n",
      "-0.39808371498045336\n",
      "-0.4048354224787953\n",
      "-0.37216061808871626\n",
      "-0.3869675207257141\n",
      "-0.41520942294895924\n",
      "-0.3751514887202145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.42347589711599615\n",
      "-0.4203678392980908\n",
      "-0.5865749221185176\n",
      "-0.4658181238858787\n",
      "-0.42560178397780063\n",
      "-0.5148915930514114\n",
      "-0.5034847669215603\n",
      "-0.44587832753185086\n",
      "-0.5297241662044104\n",
      "-0.544710472158049\n",
      "-0.5281842778305746\n",
      "-0.4879413682535678\n",
      "-0.4649820537340638\n",
      "-0.36758382478118984\n",
      "-0.41691692224505894\n",
      "-0.3830299487829152\n",
      "-0.49583843589107446\n",
      "-0.5513809273530679\n",
      "-0.5271877150226097\n",
      "-0.521437693007049\n",
      "-0.5244841636508256\n",
      "-0.5015913748731623\n",
      "-0.5245913487009894\n",
      "-0.45724662998299237\n",
      "-0.44848411761524715\n",
      "-0.40658704264481726\n",
      "-0.3209490197928014\n",
      "-0.34772901662855893\n",
      "-0.35907648495808525\n",
      "-0.45781108869274173\n",
      "-0.41739578037494723\n",
      "-0.4677893777084343\n",
      "-0.54260460367433\n",
      "-0.45458185015198904\n",
      "-0.42727587206883977\n",
      "-0.348289336546148\n",
      "-0.39336435342894305\n",
      "-0.3802224214425885\n",
      "-0.32670003046374535\n",
      "-0.34218304151976714\n",
      "-0.37709881175232923\n",
      "-0.41426681691168915\n",
      "-0.4085032091702965\n",
      "-0.438836098963167\n",
      "-0.4896709567300032\n",
      "-0.49650975863840263\n",
      "-0.3906683228421451\n",
      "-0.36823546034700505\n",
      "-0.42768014278919897\n",
      "-0.44450707011926194\n",
      "-0.4733253751184377\n",
      "-0.47246727636693947\n",
      "-0.4628714571845759\n",
      "-0.4818255868318542\n",
      "-0.48031770375989463\n",
      "-0.5114944222899226\n",
      "-0.4599972078057628\n",
      "-0.4411442965901116\n",
      "-0.3626562013902421\n",
      "-0.4682857464168464\n",
      "-0.4912953736034174\n",
      "-0.46196422216582134\n",
      "-0.5104153908498443\n",
      "-0.43705273574974846\n",
      "-0.4708190165785679\n",
      "-0.4248328263220932\n",
      "-0.39014702024792\n",
      "-0.28735389095685526\n",
      "-0.341207273920932\n",
      "-0.4137281415528056\n",
      "-0.45625872660673816\n",
      "-0.42449560237864165\n",
      "-0.44916633804954514\n",
      "-0.507996031744973\n",
      "-0.40445682755544676\n",
      "-0.4460453189188645\n",
      "-0.4118290609785403\n",
      "-0.4929964092550999\n",
      "-0.3688583040774244\n",
      "-0.36366337213954864\n",
      "-0.3902156360055725\n",
      "-0.3017633486439376\n",
      "-0.3739354200364257\n",
      "-0.365229552785532\n",
      "-0.4008069499295616\n",
      "-0.4563290682257412\n",
      "-0.4769923969882923\n",
      "-0.4777718152995053\n",
      "-0.47452565789620393\n",
      "-0.33948126389292\n",
      "-0.5784550804849733\n",
      "-0.5418326583959076\n",
      "-0.5178430122518294\n",
      "-0.4879051139461538\n",
      "-0.45616336848925104\n",
      "-0.3648288910707165\n",
      "-0.537069992827522\n",
      "-0.49216701596641727\n",
      "-0.5425567509606353\n",
      "-0.5572203168947139\n",
      "-0.4988639131052528\n",
      "-0.46439014972853876\n",
      "-0.4910232714981549\n",
      "-0.5614477158729567\n",
      "-0.5845487143910194\n",
      "-0.5838340098886748\n",
      "-0.5974430503056749\n",
      "-0.6373896965807464\n",
      "-0.5085278098988035\n",
      "-0.5724721606646611\n",
      "-0.5389278497368032\n",
      "-0.6016974135161517\n",
      "-0.5661133978417152\n",
      "-0.5840182546588623\n",
      "-0.6626265477164204\n",
      "-0.6102244656152513\n",
      "-0.5256916499802029\n",
      "-0.5094889093641912\n",
      "-0.4667360981181854\n",
      "-0.616419227256434\n",
      "-0.5351029978350309\n",
      "-0.5677793253702363\n",
      "-0.5671164869613324\n",
      "-0.5163831296168837\n",
      "-0.6196770679836753\n",
      "-0.5575534888322509\n",
      "-0.5745942040224657\n",
      "-0.5173770957315263\n",
      "-0.5379656119625307\n",
      "-0.5565375741396051\n",
      "-0.6222453175250325\n",
      "-0.5118851908642152\n",
      "-0.4545299817968728\n",
      "-0.4039018293148248\n",
      "-0.4111317407336581\n",
      "-0.4248644161794619\n",
      "-0.541284572853587\n",
      "-0.4379666746758713\n",
      "-0.4471748280017408\n",
      "-0.46260232805443474\n",
      "-0.4581600376865947\n",
      "-0.47938913065412525\n",
      "-0.4674763487971746\n",
      "-0.3944590740531382\n",
      "-0.49397016363265855\n",
      "-0.4794450830295291\n",
      "-0.5178781445467735\n",
      "-0.5446779436526547\n",
      "-0.5092029275843238\n",
      "-0.5898080176116454\n",
      "-0.5207072672205516\n",
      "-0.5404897594122825\n",
      "-0.4312264884269016\n",
      "-0.4110507074691366\n",
      "-0.4853318183027795\n",
      "-0.5030928696265055\n",
      "-0.48861710858834695\n",
      "-0.4369062113775212\n",
      "-0.42780236122948423\n",
      "-0.4207717415633982\n",
      "-0.44721567243318927\n",
      "-0.4856512074782753\n",
      "-0.47265687067010786\n",
      "-0.5238565769603486\n",
      "-0.5353129354450331\n",
      "-0.474574439002958\n",
      "-0.5508501478426107\n",
      "-0.4574665909444199\n",
      "-0.5476512775086205\n",
      "-0.4995653182274377\n",
      "-0.6246342281503482\n",
      "-0.5142761311489862\n",
      "-0.4857127225669996\n",
      "-0.5433155154482581\n",
      "-0.6282753633155156\n",
      "-0.5094094034830057\n",
      "-0.49268062733953405\n",
      "-0.4819319495844571\n",
      "-0.412888527812655\n",
      "-0.6015128765717186\n",
      "-0.5955202900087913\n",
      "-0.49638059826906356\n",
      "-0.45462159940326075\n",
      "-0.618806841815391\n",
      "-0.5962092302581794\n",
      "-0.5342010868697384\n",
      "-0.5802354917463418\n",
      "-0.624204791177673\n",
      "-0.5625248323256896\n",
      "-0.5193812626500036\n",
      "-0.5880659192440384\n",
      "-0.4964292993012977\n",
      "-0.5965979047205227\n",
      "-0.5311854960415161\n",
      "-0.5717931427911055\n",
      "-0.5003561541757733\n",
      "-0.5402617296968131\n",
      "-0.5461461943457991\n",
      "-0.669416133341927\n",
      "-0.6396097080983509\n",
      "-0.6345651054677695\n",
      "-0.5329746554969913\n",
      "-0.5014977731942312\n",
      "-0.4555133601781439\n",
      "-0.39633693576772083\n",
      "-0.4523792392187305\n",
      "-0.4470141974768414\n",
      "-0.4006969379745505\n",
      "-0.43708356006424975\n",
      "-0.5454412127368639\n",
      "-0.5203586414916422\n",
      "-0.5113526179939257\n",
      "-0.5494266123478135\n",
      "-0.4752246431269649\n",
      "-0.40983134191894793\n",
      "-0.4202426574714523\n",
      "-0.3586958165053557\n",
      "-0.3874157982882442\n",
      "-0.5397884753127656\n",
      "-0.517521226768173\n",
      "-0.4424699306446414\n",
      "-0.40400737132316467\n",
      "-0.3981895770837137\n",
      "-0.49887480319343286\n",
      "-0.507547071340154\n",
      "-0.5082267794596653\n",
      "-0.3703653111412813\n",
      "-0.4068914043662448\n",
      "-0.35716313473248723\n",
      "-0.46464033870340776\n",
      "-0.4766419369925201\n",
      "-0.38806334513378277\n",
      "-0.46359391902459546\n",
      "-0.4143525590153877\n",
      "-0.3921123525065192\n",
      "-0.4523762850383224\n",
      "-0.4611551473146645\n",
      "-0.3065351477746979\n",
      "-0.4367961869697339\n",
      "-0.5044976909644495\n",
      "-0.5173707982030544\n",
      "-0.4353746884996363\n",
      "-0.5477217625430697\n",
      "-0.4369747664217355\n",
      "-0.4964012486021838\n",
      "-0.42496218412752634\n",
      "-0.49252003365683794\n",
      "-0.5637279377190668\n",
      "-0.39378947177990103\n",
      "-0.42809425745940255\n",
      "-0.35636300889493155\n",
      "-0.3281244641906703\n",
      "-0.3192400996942122\n",
      "-0.3154382186292347\n",
      "-0.31434677005492484\n",
      "-0.3277641727199724\n",
      "-0.28207986655865386\n",
      "-0.40719082627044834\n",
      "-0.46290699611264857\n",
      "-0.40355574357081986\n",
      "-0.46691161251805224\n",
      "-0.37606948126400896\n",
      "-0.5106511697712482\n",
      "-0.475571431045204\n",
      "-0.468387377393695\n",
      "-0.5732324805093657\n",
      "-0.46692888154261813\n",
      "-0.42518165579543327\n",
      "-0.45728016752761347\n",
      "-0.4206918549790731\n",
      "-0.4490884470103628\n",
      "-0.39954381089573465\n",
      "-0.3425697961457441\n",
      "-0.4439791613211534\n",
      "-0.3769574639807344\n",
      "-0.317935476337386\n",
      "-0.21062271144001593\n",
      "-0.2799942256682593\n",
      "-0.44064074475048887\n",
      "-0.33697883145063695\n",
      "-0.2815479087516185\n",
      "-0.4531609751933162\n",
      "-0.2911416904811038\n",
      "-0.4615845579328155\n",
      "-0.4563465173467431\n",
      "-0.40657566494111874\n",
      "-0.4075525846674554\n",
      "-0.43510592818358423\n",
      "-0.38941941570160055\n",
      "-0.5075639374378875\n",
      "-0.4365986219652036\n",
      "-0.29750515683392287\n",
      "-0.29961539503580176\n",
      "-0.24772981899010033\n",
      "-0.3139665195460052\n",
      "-0.3979405851149401\n",
      "-0.42264714164621375\n",
      "-0.46898133082113774\n",
      "-0.40388148592163103\n",
      "-0.3597797196730013\n",
      "-0.32500768644213707\n",
      "-0.2733572517337899\n",
      "-0.29883624815510706\n",
      "-0.2785787525929443\n",
      "-0.30869896662678653\n",
      "-0.2413569112731639\n",
      "-0.22659282356908833\n",
      "-0.1814996893940774\n",
      "-0.19841508029814978\n",
      "-0.21103219922661945\n",
      "-0.1904404642117889\n",
      "-0.2951957443882924\n",
      "-0.24630285207336408\n",
      "-0.2899722247736079\n",
      "-0.37273202439413855\n",
      "-0.4111195813608174\n",
      "-0.327972914482534\n",
      "-0.4223162317707352\n",
      "-0.40472612994940443\n",
      "-0.34240174645562\n",
      "-0.3714240565458119\n",
      "-0.30692373777902165\n",
      "-0.3605737066605556\n",
      "-0.29191060716259265\n",
      "-0.3257765188925391\n",
      "-0.3161563986963679\n",
      "-0.3406681661282625\n",
      "-0.3657072112961353\n",
      "-0.4018199219852518\n",
      "-0.35795271366945014\n",
      "-0.4022478618834347\n",
      "-0.41747455160425195\n",
      "-0.3229713914308096\n",
      "-0.2863734239984837\n",
      "-0.3447253556858251\n",
      "-0.3745846958695539\n",
      "-0.24551317368840944\n",
      "-0.24426929747749043\n",
      "-0.2393267606525982\n",
      "-0.26466037223691835\n",
      "-0.2805612445677341\n",
      "-0.3412951256809799\n",
      "-0.2953429123536561\n",
      "-0.3874774379701955\n",
      "-0.3616259519190824\n",
      "-0.327043199535188\n",
      "-0.33204766240557027\n",
      "-0.39749093890609405\n",
      "-0.337312071613865\n",
      "-0.26042303683910767\n",
      "-0.35303060270161607\n",
      "-0.2798185775123437\n",
      "-0.337684997773246\n",
      "-0.29965711788182803\n",
      "-0.32829330185372646\n",
      "-0.2684160969099447\n",
      "-0.27666758171004624\n",
      "-0.2996336934184402\n",
      "-0.3946003167658483\n",
      "-0.2865428757767367\n",
      "-0.44914693296211894\n",
      "-0.3129101686792428\n",
      "-0.34356368781248087\n",
      "-0.35279504146104157\n",
      "-0.29569369500406056\n",
      "-0.27785910456180557\n",
      "-0.27750904583853725\n",
      "-0.2928704458825498\n",
      "-0.32416243784444376\n",
      "-0.27849797581913915\n",
      "-0.225597207539607\n",
      "-0.2589502453746123\n",
      "-0.3215848925286616\n",
      "-0.21154996759119496\n",
      "-0.38555106502163006\n",
      "-0.4058827276424222\n",
      "-0.3790038895389396\n",
      "-0.28695226556347436\n",
      "-0.23063360605180902\n",
      "-0.24874003883394344\n",
      "-0.2731710738695723\n",
      "-0.2519404310801342\n",
      "-0.2626802936909593\n",
      "-0.18074405803496096\n",
      "-0.06910730548284813\n",
      "-0.23376204873850018\n",
      "-0.16347428493101074\n",
      "-0.2944386333467195\n",
      "-0.3056718928001455\n",
      "-0.240759813162768\n",
      "-0.33342184799275276\n",
      "-0.15794639222908383\n",
      "-0.29822902003848656\n",
      "-0.3051004414004947\n",
      "-0.2618312057179837\n",
      "-0.24047639546543678\n",
      "-0.1973545018368425\n",
      "-0.23033481227199007\n",
      "-0.2201548127049846\n",
      "-0.4085728090160583\n",
      "-0.15857454217881384\n",
      "-0.23875488600665426\n",
      "-0.22317680620529293\n",
      "-0.2898373994932406\n",
      "-0.23121517533843586\n",
      "-0.1960136057617632\n",
      "-0.30416356983424636\n",
      "-0.2165183944993431\n",
      "-0.11615642067784794\n",
      "-0.24673626268870869\n",
      "-0.1564309206796197\n",
      "-0.13034099109226321\n",
      "-0.15411574312619863\n",
      "-0.1330291446520796\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.17476721169221726\n",
      "-0.2405428157360098\n",
      "-0.23619028409799656\n",
      "-0.2927660567915588\n",
      "-0.3223274896615948\n",
      "-0.2579627310747487\n",
      "-0.2627697023894236\n",
      "-0.2878169132421432\n",
      "-0.282002101301739\n",
      "-0.24590690310869143\n",
      "-0.24372004101080338\n",
      "-0.18549515628250168\n",
      "-0.23887392388903042\n",
      "-0.373777942264606\n",
      "-0.24705365739686114\n",
      "-0.3266121549846647\n",
      "-0.29606354157151926\n",
      "-0.21124520924887924\n",
      "-0.24255620644736672\n",
      "-0.17524320945078345\n",
      "-0.20346675222625382\n",
      "-0.24357116291637765\n",
      "-0.2358926179121122\n",
      "-0.20358192074041762\n",
      "-0.27590595507014415\n",
      "-0.237619992298282\n",
      "-0.3196889022415967\n",
      "-0.2590228007943837\n",
      "-0.12702087982852855\n",
      "-0.19881542619453127\n",
      "-0.22054320963124938\n",
      "-0.22730878113408903\n",
      "-0.2812170051415347\n",
      "-0.3134354180558342\n",
      "-0.33398702011814224\n",
      "-0.18917766902677235\n",
      "-0.25747233354987537\n",
      "-0.23346683234944923\n",
      "-0.08564969083830529\n",
      "-0.22421085107714922\n",
      "-0.23078720394635263\n",
      "-0.15889153488631275\n",
      "-0.24024850705843592\n",
      "-0.18796048982932106\n",
      "-0.0319967515666655\n",
      "-0.091761603287635\n",
      "-0.0992438394858534\n",
      "-0.03714347177534194\n",
      "-0.107724078232487\n",
      "-0.10201792395872121\n",
      "-0.07231878112268984\n",
      "-0.10287880789407522\n",
      "-0.09062201381005465\n",
      "-0.06998797853018174\n",
      "-0.1290206866946972\n",
      "-0.22941982318874699\n",
      "-0.31421741151583205\n",
      "-0.21848170715412482\n",
      "-0.18443006929773342\n",
      "-0.18085477401544767\n",
      "-0.05580864245958546\n",
      "-0.11749968326458844\n",
      "-0.17420762983687588\n",
      "-0.11468265072538564\n",
      "-0.17149658601069231\n",
      "-0.09071846249355231\n",
      "-0.08385622251127742\n",
      "-0.13965703516923544\n",
      "-0.0537162329613418\n",
      "-0.1109971833478515\n",
      "-0.1918721409596323\n",
      "-0.2638736836491139\n",
      "-0.22178762028750085\n",
      "-0.3274509463823894\n",
      "-0.3213819674348397\n",
      "-0.35890784252279334\n",
      "-0.31165437070324586\n",
      "-0.29360093294748574\n",
      "-0.3136257712227076\n",
      "-0.23575936268809997\n",
      "-0.2075516363099824\n",
      "-0.20702415230288068\n",
      "-0.2278338281060179\n",
      "-0.18156105172514964\n",
      "-0.11858472221075775\n",
      "-0.17615868835372286\n",
      "-0.18393607185426136\n",
      "-0.12718393264727448\n",
      "-0.10800303128152035\n",
      "-0.1734044280114353\n",
      "-0.10329282418694907\n",
      "-0.14724098667481383\n",
      "-0.18064002060523346\n",
      "-0.18533034729356895\n",
      "-0.23517102371033022\n",
      "-0.26992718681822164\n",
      "-0.2573253777472376\n",
      "-0.2216225184784757\n",
      "-0.11487963910332856\n",
      "-0.1265398823789581\n",
      "-0.17314097690944164\n",
      "-0.20994078921595952\n",
      "-0.19415140665566866\n",
      "-0.21760632062397284\n",
      "-0.31528198525940915\n",
      "-0.22070037082208555\n",
      "-0.291343825418446\n",
      "-0.23697265979672016\n",
      "-0.1773970658025911\n",
      "-0.31040671142207105\n",
      "-0.268740630956664\n",
      "-0.1626862063783031\n",
      "-0.1434922103524307\n",
      "-0.2593410484866632\n",
      "-0.1807828626834166\n",
      "-0.1996708471918857\n",
      "-0.1775062178504821\n",
      "-0.1471669054930081\n",
      "-0.16300320605513835\n",
      "-0.07156528893444467\n",
      "-0.17379311607973402\n",
      "-0.11828934406101185\n",
      "-0.1286511649110781\n",
      "-0.16354077716688475\n",
      "-0.15701376336331957\n",
      "-0.01200801619820719\n",
      "-0.14255774386165881\n",
      "-0.08095483128253367\n",
      "-0.06116104603652564\n",
      "-0.11110737531209419\n",
      "-0.10130828002834569\n",
      "-0.1382224647598301\n",
      "-0.14179863619970873\n",
      "-0.07368813194330298\n",
      "-0.09513329950234875\n",
      "-0.12470805152610825\n",
      "-0.18208534720768516\n",
      "-0.06610951324191042\n",
      "-0.10761968323826132\n",
      "-0.12245399251360493\n",
      "-0.07583529548920061\n",
      "-0.028209344817598656\n",
      "-0.04863687697453688\n",
      "-0.04651254574287348\n",
      "-0.016337741438465666\n",
      "-0.15025222808726507\n",
      "-0.16480775688941662\n",
      "-0.16056853583399303\n",
      "-0.25891643796322733\n",
      "-0.2650389152502064\n",
      "-0.2134610724751622\n",
      "-0.12648429812960682\n",
      "-0.18335846483672633\n",
      "-0.17590098198492993\n",
      "-0.23002926776794475\n",
      "-0.30212432696973823\n",
      "-0.2896224670631602\n",
      "-0.23778748655681958\n",
      "-0.23706046803525252\n",
      "-0.22110460301306287\n",
      "-0.20253679895044863\n",
      "-0.1496044168689554\n",
      "-0.22428154980997975\n",
      "-0.3189248067699817\n",
      "-0.2578534680592415\n",
      "-0.21869500745286613\n",
      "-0.3205825641641032\n",
      "-0.3036782499998292\n",
      "-0.19434279061963386\n",
      "-0.35022770209308074\n",
      "-0.2630270602812184\n",
      "-0.31588338466622873\n",
      "-0.18227907395058202\n",
      "-0.20271823010344076\n",
      "-0.27291305418094775\n",
      "-0.20499288380377323\n",
      "-0.19064598195096574\n",
      "-0.23929171405664976\n",
      "-0.20709504910752877\n",
      "-0.29302576097771305\n",
      "-0.2736178733485883\n",
      "-0.2750430309453141\n",
      "-0.18798579266517876\n",
      "-0.15386297879507163\n",
      "-0.2102421979256162\n",
      "-0.30160800445808367\n",
      "-0.296473236182077\n",
      "-0.29662333618802533\n",
      "-0.2792297700497194\n",
      "-0.1863730954889889\n",
      "-0.25605123801183866\n",
      "-0.234794445498488\n",
      "-0.23692061030824005\n",
      "-0.27240809228931917\n",
      "-0.17146310571838996\n",
      "-0.25645185643125445\n",
      "-0.15516923107673306\n",
      "-0.24239801850264547\n",
      "-0.270771650808753\n",
      "-0.2094406072463717\n",
      "-0.22739034836131958\n",
      "-0.2518363312902763\n",
      "-0.21623292320606727\n",
      "-0.30357220773610494\n",
      "-0.2582278212028659\n",
      "-0.1730782900956807\n",
      "-0.1863405988558426\n",
      "-0.29726892424784346\n",
      "-0.2878240757996373\n",
      "-0.264753767430575\n",
      "-0.35260392224378295\n",
      "-0.3052513987647912\n",
      "-0.2732080060746876\n",
      "-0.34183484200467873\n",
      "-0.2960782241618368\n",
      "-0.3099609848428968\n",
      "-0.2268994768777285\n",
      "-0.20206937073213774\n",
      "-0.33988640537264736\n",
      "-0.22080707102385688\n",
      "-0.1708104244655071\n",
      "-0.17075485429581433\n",
      "-0.1614567560650396\n",
      "-0.15956824884114557\n",
      "-0.16945891950082512\n",
      "-0.16256735681606937\n",
      "-0.18432481324334413\n",
      "-0.3161545912181882\n",
      "-0.27777494801790803\n",
      "-0.21831540600306398\n",
      "-0.3351966907470584\n",
      "-0.18771190279496627\n",
      "-0.17493639420034063\n",
      "-0.14055291240946238\n",
      "-0.2324726244596959\n",
      "-0.17165884502808526\n",
      "-0.25072530338711757\n",
      "-0.2466469001351683\n",
      "-0.27308641733798156\n",
      "-0.30061145166676295\n",
      "-0.2669198066614185\n",
      "-0.24407211490611075\n",
      "-0.2674664612450694\n",
      "-0.17541065798492547\n",
      "-0.16857442214456436\n",
      "-0.13760754743389708\n",
      "-0.25096295959324716\n",
      "-0.23164369516725444\n",
      "-0.2229249989212755\n",
      "-0.17383789157387095\n",
      "-0.2024974396256228\n",
      "-0.14628662644100598\n",
      "-0.16515631524347535\n",
      "-0.10916694350467786\n",
      "-0.1481088757461785\n",
      "-0.07920085090533645\n",
      "-0.1040381445977263\n",
      "-0.20522383400486685\n",
      "-0.21744527394274463\n",
      "-0.18332388094940497\n",
      "-0.20809838834335193\n",
      "-0.14498869896916128\n",
      "-0.2751406053181545\n",
      "-0.2225312891796479\n",
      "-0.23767385297056007\n",
      "-0.179520638987627\n",
      "-0.16439437671095444\n",
      "-0.06172606576229846\n",
      "-0.08674797226823565\n",
      "-0.11473537133642475\n",
      "-0.1248699662520728\n",
      "-0.20297893802176267\n",
      "-0.12803612460233288\n",
      "-0.039556049534021726\n",
      "-0.1668111764291642\n",
      "-0.19865358746796458\n",
      "-0.2690925655330266\n",
      "-0.23522743761439957\n",
      "-0.20841030936197869\n",
      "-0.17158642311697475\n",
      "-0.25537650166085596\n",
      "-0.16813786191325622\n",
      "-0.17466531362664775\n",
      "-0.14752738080838515\n",
      "-0.11713126897936807\n",
      "-0.13261278101731008\n",
      "-0.25551183691812507\n",
      "-0.1533522220788298\n",
      "-0.1349953024391826\n",
      "-0.02579413948070857\n",
      "-0.12995468750093153\n",
      "-0.12948332561861792\n",
      "-0.08769786515419097\n",
      "-0.25814780065689213\n",
      "-0.05882521995562855\n",
      "-0.1824932976080001\n",
      "-0.2104894122617469\n",
      "-0.2271168639008445\n",
      "-0.27464967898912834\n",
      "-0.22404978973087838\n",
      "-0.10485062647992854\n",
      "-0.1070254901110862\n",
      "-0.15905515070932374\n",
      "-0.17092115348116432\n",
      "-0.18395672116847958\n",
      "-0.2793294638270961\n",
      "-0.1835461821084643\n",
      "-0.09264154166111183\n",
      "-0.17489995074844852\n",
      "-0.1256687621250255\n",
      "-0.16576392362261758\n",
      "-0.27590714098972596\n",
      "-0.2663741586543505\n",
      "-0.2582266555029516\n",
      "-0.3513047028306901\n",
      "-0.41250552320502865\n",
      "-0.2879969870905832\n",
      "-0.18785049954600208\n",
      "-0.293179160140149\n",
      "-0.2564169099203754\n",
      "-0.21041321989141473\n",
      "-0.2077596725189953\n",
      "-0.17666364071498408\n",
      "-0.2023617272501175\n",
      "-0.12645662254109485\n",
      "-0.06671160538711766\n",
      "-0.08850741678781152\n",
      "-0.21092497372179658\n",
      "-0.11621720094733173\n",
      "-0.06976779920051308\n",
      "-0.11445574494800118\n",
      "-0.1660579638358367\n",
      "-0.1327804721383896\n",
      "-0.15337694272663333\n",
      "-0.21407900060841495\n",
      "-0.23703919306292692\n",
      "-0.23232268768709738\n",
      "-0.19433418882864367\n",
      "-0.13756527367085894\n",
      "-0.2917659593764411\n",
      "-0.22283892002345462\n",
      "-0.26711955184559216\n",
      "-0.19718847140823315\n",
      "-0.2759687380490141\n",
      "-0.22213282165207032\n",
      "-0.25319399872595766\n",
      "-0.15490371583627474\n",
      "-0.21506717187762386\n",
      "-0.2339019019209891\n",
      "-0.2033628796155708\n",
      "-0.15188223603933088\n",
      "-0.2628871039468456\n",
      "-0.23368913948417244\n",
      "-0.2324340355316069\n",
      "-0.2408995660395773\n",
      "-0.31457158565058985\n",
      "-0.17015705945963674\n",
      "-0.22829927940841327\n",
      "-0.21185589052588064\n",
      "-0.18186806120389584\n",
      "-0.3014142308720948\n",
      "-0.2801672697412821\n",
      "-0.24468855652522492\n",
      "-0.28196790742930944\n",
      "-0.31033650902276466\n",
      "-0.24723218346303877\n",
      "-0.2707434206894733\n",
      "-0.22267782880831663\n",
      "-0.2150030152222419\n",
      "-0.1068083701333788\n",
      "-0.12186163313045281\n",
      "-0.0666302156928111\n",
      "-0.03282388773019012\n",
      "-0.08942331478508163\n",
      "-0.1422923385332802\n",
      "-0.13737270140966862\n",
      "-0.1905302294524274\n",
      "-0.1998366889461887\n",
      "-0.2558802314212263\n",
      "-0.2612826357527096\n",
      "-0.15872808270853128\n",
      "-0.252258320650962\n",
      "-0.26117836206805944\n",
      "-0.2693361613209924\n",
      "-0.26578936537034537\n",
      "-0.21120622052997312\n",
      "-0.283974240675624\n",
      "-0.3799405883812729\n",
      "-0.38550263293105924\n",
      "-0.29418301174646316\n",
      "-0.2428009936839881\n",
      "-0.16592008652125284\n",
      "-0.1789158656843865\n",
      "-0.21963265885979644\n",
      "-0.18866590190927304\n",
      "-0.127013101005738\n",
      "-0.20776284470633838\n",
      "-0.18654981473842439\n",
      "-0.225816868630441\n",
      "-0.16108373806947102\n",
      "-0.23214715313870887\n",
      "-0.24683406886114523\n",
      "-0.38419644735758485\n",
      "-0.4338333341119389\n",
      "-0.4108506478416018\n",
      "-0.36586305490473126\n",
      "-0.322128161957293\n",
      "-0.37825442854111335\n",
      "-0.3839198782884791\n",
      "-0.29785361523942794\n",
      "-0.34059571427280677\n",
      "-0.27836627147452186\n",
      "-0.2742612006184931\n",
      "-0.33620210043745\n",
      "-0.22053471561035293\n",
      "-0.15489488701633808\n",
      "-0.10985726979605395\n",
      "-0.2428150309149208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.3607383142837698\n",
      "-0.30480402967871517\n",
      "-0.3190671719630967\n",
      "-0.2666618482536267\n",
      "-0.16278410885124822\n",
      "-0.3104209479667555\n",
      "-0.22196287423417993\n",
      "-0.29314060943292725\n",
      "-0.2710441111763947\n",
      "-0.2019846076387492\n",
      "-0.22427431853634544\n",
      "-0.2622052614218983\n",
      "-0.24219065961757844\n",
      "-0.2582295591293754\n",
      "-0.382166663374517\n",
      "-0.39033327705174004\n",
      "-0.2910126229363038\n",
      "-0.3189431414229871\n",
      "-0.23441714447550735\n",
      "-0.3087832799572361\n",
      "-0.2561463436655557\n",
      "-0.29378607331582784\n",
      "-0.26730581665326586\n",
      "-0.22667915045148768\n",
      "-0.2135444561161787\n",
      "-0.30409287372035865\n",
      "-0.2844221304924682\n",
      "-0.18499392532067216\n",
      "-0.20988287159384877\n",
      "-0.29689383895024424\n",
      "-0.3365253261069452\n",
      "-0.3399501714315995\n",
      "-0.2372672973269992\n",
      "-0.24173673799817183\n",
      "-0.2535619989070581\n",
      "-0.315263404483826\n",
      "-0.26753593693558086\n",
      "-0.2740737737767883\n",
      "-0.241902835779191\n",
      "-0.4036752528452053\n",
      "-0.47708144788837237\n",
      "-0.31580044427485454\n",
      "-0.35857738110599935\n",
      "-0.25997899573651523\n",
      "-0.26430390108240903\n",
      "-0.15819163402102\n",
      "-0.20536388876257058\n",
      "-0.17537615069023807\n",
      "-0.1304085303032661\n",
      "-0.16476084347382372\n",
      "-0.21022922727550095\n",
      "-0.2105799236162066\n",
      "-0.16892648518455392\n",
      "-0.294761233699296\n",
      "-0.22300124418503123\n",
      "-0.20883147534895852\n",
      "-0.2841252876125524\n",
      "-0.2307820566180291\n",
      "-0.2609853307636896\n",
      "-0.17517137626341248\n",
      "-0.0880271135924961\n",
      "-0.10959004484411321\n",
      "-0.09338096794828575\n",
      "-0.21998421599424994\n",
      "-0.1273091496545527\n",
      "-0.1141367515666376\n",
      "-0.10937231809938888\n",
      "-0.16866294296248133\n",
      "-0.083743514520811\n",
      "-0.10413840520743232\n",
      "-0.0742755157177229\n",
      "-0.0974519229636089\n",
      "-0.11468008736684733\n",
      "-0.017057363665762593\n",
      "-0.22704439921869896\n",
      "-0.2762445201448641\n",
      "-0.07237053828342987\n",
      "-0.15896006798182946\n",
      "-0.09595983380013089\n",
      "-0.1624508399222525\n",
      "-0.08910287702422043\n",
      "-0.07540266065409156\n",
      "-0.09601779215071961\n",
      "-0.010488189469796329\n",
      "0.015685809221000165\n",
      "-0.037586700304672364\n",
      "0.0092091922938888\n",
      "-0.04399914939154444\n",
      "-0.01575721577388325\n",
      "-0.021351485266527432\n",
      "0.006566172175560504\n",
      "-0.07741666419607895\n",
      "-0.15412502295384342\n",
      "-0.17720818967966692\n",
      "-0.18992528375208786\n",
      "-0.12213882202195842\n",
      "-0.1652277713786893\n",
      "-0.10880240307583276\n",
      "-0.28736675883616997\n",
      "-0.1378971016261961\n",
      "-0.08050270347001318\n",
      "-0.18829824967856157\n",
      "-0.12966840188643125\n",
      "-0.0944801457190988\n",
      "-0.22230349165015525\n",
      "-0.159625093816006\n",
      "-0.07016678611913857\n",
      "0.0048491326245044195\n",
      "-0.023103567890621474\n",
      "-0.08770097125686707\n",
      "-0.027166170618907096\n",
      "-0.035513261895194874\n",
      "-0.06185793178055653\n",
      "-0.06991699639185944\n",
      "-0.035767386893800684\n",
      "-0.017727908100112277\n",
      "-0.04982003440970658\n",
      "0.007403005523581804\n",
      "-0.0610549562057349\n",
      "-0.03384778456969186\n",
      "-0.09823240111180155\n",
      "0.011943518533289014\n",
      "-0.07494468044253216\n",
      "-0.03604035501460686\n",
      "-0.028127744673893045\n",
      "-0.07138994759188891\n",
      "-0.1285095957727123\n",
      "-0.13229552833451844\n",
      "-0.15190833679349358\n",
      "-0.034552293901485016\n",
      "-0.06798549272280707\n",
      "-0.040009653506768036\n",
      "-0.11972679559936396\n",
      "0.03330576257110456\n",
      "0.018207213241332038\n",
      "-0.10752735085517193\n",
      "-0.020364514491402603\n",
      "-0.024303766843789352\n",
      "-0.02074470859158139\n",
      "0.08418772097675893\n",
      "-0.07182859298567895\n",
      "0.042590509547257786\n",
      "0.026028393399316674\n",
      "-0.06363954269034998\n",
      "0.009240242036622024\n",
      "0.010275281421812395\n",
      "-0.06973946980101306\n",
      "-0.08131587780941978\n",
      "-0.09003702382826073\n",
      "0.01655530353100474\n",
      "0.012846830351961585\n",
      "0.07988920440716887\n",
      "0.045697803972152666\n",
      "0.04981199587014065\n",
      "-0.06995906989106301\n",
      "0.030851221616569603\n",
      "-0.03821266188583004\n",
      "-0.03787819100835808\n",
      "-0.011926028943524798\n",
      "-0.09720767083508745\n",
      "-0.05372389665678505\n",
      "0.08138884817543007\n",
      "0.08103708069779815\n",
      "0.0768191584989185\n",
      "0.04771965687193759\n",
      "0.07256479998334842\n",
      "0.07993808020186649\n",
      "0.123488266596551\n",
      "0.04376159391209661\n",
      "0.08208938379130834\n",
      "0.1355653833869289\n",
      "0.06808151549720512\n",
      "0.12867654883462182\n",
      "0.20054269488904702\n",
      "0.2004183993895643\n",
      "0.14299523052766933\n",
      "0.12906076371887476\n",
      "0.17383786466871495\n",
      "0.12352494997941617\n",
      "0.10312850405831216\n",
      "0.1474549067134265\n",
      "0.1289650283776496\n",
      "0.12589886477284074\n",
      "0.11149126290281183\n",
      "0.05177549851288446\n",
      "0.13372705306918678\n",
      "0.20811646878463358\n",
      "0.26058646202896696\n",
      "0.19927266293403728\n",
      "0.05661185877167958\n",
      "0.06655939233333034\n",
      "0.1471377162232488\n",
      "0.14298315281635093\n",
      "0.09512247077059822\n",
      "0.04139881206168104\n",
      "0.11422938488880217\n",
      "0.09964145551077268\n",
      "0.10571436215774227\n",
      "0.08384801155375918\n",
      "0.03350965936664242\n",
      "0.03704436545113074\n",
      "0.0887219007600051\n",
      "0.13812301289230863\n",
      "0.06489376292201532\n",
      "0.07118530785709207\n",
      "0.008772203095072281\n",
      "-0.00023939190363554685\n",
      "0.03355646802649512\n",
      "0.10552356162787886\n",
      "0.13858863786958486\n",
      "0.1201404038136659\n",
      "0.17018453821997687\n",
      "0.10927466637541712\n",
      "0.1225257853707218\n",
      "0.05803103797710032\n",
      "0.13184175934691342\n",
      "0.09387008494797286\n",
      "0.028446422068614224\n",
      "0.09454424582883782\n",
      "0.024236634299025082\n",
      "0.06965388102321304\n",
      "0.10762295407161511\n",
      "0.03595129249649319\n",
      "0.004853096981838905\n",
      "0.060354495052384535\n",
      "0.09389324497030697\n",
      "0.1600361113325363\n",
      "0.16280182385843178\n",
      "0.10934812704602602\n",
      "0.0654880428379984\n",
      "0.11933860061722984\n",
      "0.12456336370418256\n",
      "0.16998630326218966\n",
      "0.13861662252712845\n",
      "0.1504478314994769\n",
      "0.10372326514112591\n",
      "0.1995566577399395\n",
      "0.1050755956741827\n",
      "0.1689643025003098\n",
      "0.1345620902705312\n",
      "0.21335914769504402\n",
      "0.1200427207427239\n",
      "0.05985462424980226\n",
      "0.062174658567629326\n",
      "0.14680002022405048\n",
      "0.07594290178773885\n",
      "0.09738345669176242\n",
      "0.15303814069619684\n",
      "0.10224937418136497\n",
      "0.09873743323430062\n",
      "0.22000892914084028\n",
      "0.22877064353827925\n",
      "0.24574694924804794\n",
      "0.19577467833322162\n",
      "0.3199547524652152\n",
      "0.23640451952794145\n",
      "0.214382908058041\n",
      "0.30442692019594386\n",
      "0.271800347340362\n",
      "0.38530266312462\n",
      "0.2818377992104983\n",
      "0.2005887579642989\n",
      "0.13998081008184332\n",
      "0.10998267999584847\n",
      "0.05052105878286878\n",
      "0.1057364954960413\n",
      "0.07752936680675228\n",
      "0.1709490209588889\n",
      "0.16833928677522905\n",
      "0.18642172200742602\n",
      "0.16428919760321856\n",
      "0.27591619489913566\n",
      "0.18967800232421264\n",
      "0.23500680477538197\n",
      "0.21848334982035406\n",
      "0.2795915350598203\n",
      "0.2653739443339742\n",
      "0.3206759302733265\n",
      "0.2992131966548591\n",
      "0.32489753946539107\n",
      "0.13936571706886497\n",
      "0.1643339811623646\n",
      "0.2004373349321981\n",
      "0.20939701777355946\n",
      "0.19904969212106902\n",
      "0.24718167048470652\n",
      "0.24616722139797564\n",
      "0.2891951459501395\n",
      "0.2715459755291389\n",
      "0.22564391691162528\n",
      "0.21752710398564742\n",
      "0.22275177795958467\n",
      "0.18448992525569363\n",
      "-0.0007116541917138834\n",
      "0.13200314272147082\n",
      "0.05419298140775358\n",
      "0.06810665194092004\n",
      "0.005328725889939342\n",
      "0.05894690851383185\n",
      "0.06575544719329468\n",
      "0.023676781733008075\n",
      "-0.0327002261740631\n",
      "0.05814037796095069\n",
      "0.019746385917407103\n",
      "0.0794757662403309\n",
      "0.08635894917894786\n",
      "0.018140807128387566\n",
      "-0.049803524201928004\n",
      "-0.05976723647545952\n",
      "-0.10841130633631516\n",
      "-0.0705152561838029\n",
      "-0.11287299872859534\n",
      "-0.14667940451702027\n",
      "-0.22042205233571294\n",
      "-0.06398544087861044\n",
      "-0.08896016580699613\n",
      "0.054369941454112794\n",
      "-0.1100250831494419\n",
      "-0.09503957213400163\n",
      "-0.10665527367565067\n",
      "-0.18291940258978887\n",
      "-0.09475117670349942\n",
      "-0.10228381111223223\n",
      "-0.08359921609399434\n",
      "-0.02052617210061075\n",
      "0.08469880747655789\n",
      "-0.0032649971662992924\n",
      "-0.023655280328170533\n",
      "-0.025535628379782543\n",
      "-0.015670030358287842\n",
      "-0.09411330195066642\n",
      "-0.10047837231871914\n",
      "-0.07350312000579334\n",
      "-0.1164272052357051\n",
      "-0.08036369310788685\n",
      "-0.1711870139185243\n",
      "-0.20155329642590572\n",
      "-0.04519504346059387\n",
      "-0.06105649822000646\n",
      "-0.16280416605349873\n",
      "-0.17743498832997148\n",
      "-0.15631907738398676\n",
      "-0.2513311335679186\n",
      "-0.13696905068132806\n",
      "-0.19657469777904807\n",
      "-0.11076818725086605\n",
      "-0.06764796794273965\n",
      "-0.14964403912491556\n",
      "-0.04492734708839646\n",
      "-0.03403148735942552\n",
      "-0.06404713475663382\n",
      "-0.12070411547652257\n",
      "-0.20974577972420874\n",
      "-0.11726590655835907\n",
      "-0.30834473424099107\n",
      "-0.28731236252639775\n",
      "-0.23243393429216966\n",
      "-0.21072639449247585\n",
      "-0.21079071384545656\n",
      "-0.21157989156245074\n",
      "-0.227745959120368\n",
      "-0.1914221525130831\n",
      "-0.12666677768324452\n",
      "-0.29661192317222207\n",
      "-0.20810635387974183\n",
      "-0.25987529367208273\n",
      "-0.17921051103480273\n",
      "-0.2874478420583991\n",
      "-0.25257148726383744\n",
      "-0.28764139479334344\n",
      "-0.29578209758656865\n",
      "-0.3567901603956519\n",
      "-0.2930788869591518\n",
      "-0.3225200075865614\n",
      "-0.271600488622119\n",
      "-0.205100932715471\n",
      "-0.2119266598676033\n",
      "-0.23842979842300696\n",
      "-0.25503080506627174\n",
      "-0.3369083178219606\n",
      "-0.3338569548200165\n",
      "-0.35043769460229685\n",
      "-0.3598887266460849\n",
      "-0.338601068877692\n",
      "-0.36107052035668574\n",
      "-0.3931915147208082\n",
      "-0.3477462895755799\n",
      "-0.37104152900299836\n",
      "-0.34491123964231446\n",
      "-0.4361012140158305\n",
      "-0.40904748090286264\n",
      "-0.3774781535296423\n",
      "-0.42224321076312826\n",
      "-0.28890970115470854\n",
      "-0.32690250884396865\n",
      "-0.28175808921680584\n",
      "-0.2940129385896183\n",
      "-0.3292209962136545\n",
      "-0.3642884805340571\n",
      "-0.34749024537982365\n",
      "-0.3830516612937182\n",
      "-0.38983076975133074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.4602059171279886\n",
      "-0.4427227542010982\n",
      "-0.3793714523421616\n",
      "-0.393967741939423\n",
      "-0.30415052871122017\n",
      "-0.37299340006086723\n",
      "-0.469856480168224\n",
      "-0.5300559981163484\n",
      "-0.44435892513972264\n",
      "-0.40095629856353593\n",
      "-0.5445557294401983\n",
      "-0.3805325339279836\n",
      "-0.42317466350177946\n",
      "-0.6052239504576024\n",
      "-0.6388296087194038\n",
      "-0.5924045860559384\n",
      "-0.492815397372355\n",
      "-0.5545736973354259\n",
      "-0.574530019731725\n",
      "-0.572145143699596\n",
      "-0.5137729170165544\n",
      "-0.549608047564589\n",
      "-0.571713421227506\n",
      "-0.5923290594779542\n",
      "-0.5705956871960502\n",
      "-0.5100939386165796\n",
      "-0.4709939076263481\n",
      "-0.5116432587404143\n",
      "-0.5369552266089018\n",
      "-0.5598269249255323\n",
      "-0.5020853595255536\n",
      "-0.5708127765831209\n",
      "-0.5907485144644394\n",
      "-0.5686412785937611\n",
      "-0.6167915159852763\n",
      "-0.6636031430363865\n",
      "-0.5839307431167847\n",
      "-0.5800037893066199\n",
      "-0.5087526310066051\n",
      "-0.5349995293636843\n",
      "-0.586722553890322\n",
      "-0.5761729967321215\n",
      "-0.5741702729516198\n",
      "-0.6133709321392025\n",
      "-0.5920980717974997\n",
      "-0.5647840028124311\n",
      "-0.5629500930949327\n",
      "-0.521676946222029\n",
      "-0.7276639589401052\n",
      "-0.5830839609956998\n",
      "-0.5716902847286227\n",
      "-0.6231504376485208\n",
      "-0.6175817910614304\n",
      "-0.6339801022525826\n",
      "-0.5949424089577088\n",
      "-0.6295475972752494\n",
      "-0.6158203235949389\n",
      "-0.6308882735503876\n",
      "-0.5689700438658047\n",
      "-0.6539034191335367\n",
      "-0.6975525968486334\n",
      "-0.6965710570551387\n",
      "-0.6502904445825991\n",
      "-0.7226427925045581\n",
      "-0.7119954848678095\n",
      "-0.6604609083584699\n",
      "-0.7721229956051621\n",
      "-0.5876955899173623\n",
      "-0.78387761790193\n",
      "-0.7226222237894419\n",
      "-0.6900590777262108\n",
      "-0.6515902242443384\n",
      "-0.6718883847944871\n",
      "-0.6493980045017098\n",
      "-0.7271645183382432\n",
      "-0.681847042149386\n",
      "-0.7405079023942169\n",
      "-0.6957584179202926\n",
      "-0.7775275104818322\n",
      "-0.8068162100653735\n",
      "-0.7368273401697994\n",
      "-0.7791115345989207\n",
      "-0.7074791307053315\n",
      "-0.7618393346758949\n",
      "-0.7847756086320197\n",
      "-0.705329651818021\n",
      "-0.6947180847873987\n",
      "-0.758838902058275\n",
      "-0.6592549969148269\n",
      "-0.7139374875674018\n",
      "-0.6943382907891285\n",
      "-0.7951466900726647\n",
      "-0.8243673665983609\n",
      "-0.866798856245274\n",
      "-0.7690257860997202\n",
      "-0.7482471172589917\n",
      "-0.7825406413952032\n",
      "-0.7853124409510855\n",
      "-0.7008518022383851\n",
      "-0.805755242805783\n",
      "-0.8587465493641486\n",
      "-0.7324015717347019\n",
      "-0.7731150421262277\n",
      "-0.7424138686592422\n",
      "-0.819269041984881\n",
      "-0.7239203513742328\n",
      "-0.7595501187293374\n",
      "-0.7706821757174183\n",
      "-0.7636590205515735\n",
      "-0.6192345963409185\n",
      "-0.7485526458991913\n",
      "-0.7663452039210187\n",
      "-0.8390075320323478\n",
      "-0.7789931399537487\n",
      "-0.8316425259966301\n",
      "-0.7709953113396193\n",
      "-0.8689412070269806\n",
      "-0.8333529616586056\n",
      "-0.828989762460106\n",
      "-0.7681391706918232\n",
      "-0.8605123079319988\n",
      "-0.8835840858190345\n",
      "-0.8070100330622079\n",
      "-0.8627773084840596\n",
      "-0.8526853859918135\n",
      "-0.8721485326383199\n",
      "-0.7318763791147828\n",
      "-0.7534776032262795\n",
      "-0.7336212182754861\n",
      "-0.730000642409342\n",
      "-0.7297319148025332\n",
      "-0.7754042816775295\n",
      "-0.809605220732548\n",
      "-0.8056610237005327\n",
      "-0.7090067161649786\n",
      "-0.7988172173367262\n",
      "-0.8234454190007259\n",
      "-0.7675681891862803\n",
      "-0.7471506750476753\n",
      "-0.854321448237433\n",
      "-0.8127570478204251\n",
      "-0.7600881762239431\n",
      "-0.733622014490704\n",
      "-0.7567115017324327\n",
      "-0.7438042274138179\n",
      "-0.8310033853762596\n",
      "-0.9198364059651681\n",
      "-0.867504164852734\n",
      "-0.8714541401897351\n",
      "-0.8582988915149856\n",
      "-0.8806034822212162\n",
      "-0.8390380499478446\n",
      "-0.9418995012157882\n",
      "-0.9060065412900997\n",
      "-0.9421475547618248\n",
      "-0.880329504732477\n",
      "-0.8420452324502752\n",
      "-0.8379240871360468\n",
      "-0.9114730702880878\n",
      "-0.7434859686299181\n",
      "-0.7417931796794996\n",
      "-0.8217357862574596\n",
      "-0.7950042074919975\n",
      "-0.9209970233469803\n",
      "-0.9356120440991045\n",
      "-0.9592976052102491\n",
      "-0.9858600289963528\n",
      "-0.8246369988093913\n",
      "-0.825605279072587\n",
      "-0.7564023292119323\n",
      "-0.8363868100460985\n",
      "-0.8869588011444367\n",
      "-0.8221930355051816\n",
      "-0.9256717789609934\n",
      "-0.9812328076973988\n",
      "-0.849487500854062\n",
      "-0.9801332832448423\n",
      "-0.809614006321444\n",
      "-0.8725748990708819\n",
      "-0.9972941703132105\n",
      "-0.9157817358320314\n",
      "-0.8670902272232396\n",
      "-0.7292753989967062\n",
      "-0.7996351418003254\n",
      "-0.843880650075314\n",
      "-0.7731670426439828\n",
      "-0.7485329256533245\n",
      "-0.835557969870068\n",
      "-0.7096376015034438\n",
      "-0.7953876300280973\n",
      "-0.9498573791973126\n",
      "-0.8545552743777077\n",
      "-0.8866380413218969\n",
      "-0.873766153599252\n",
      "-0.9452419863296874\n",
      "-0.9273455076428905\n",
      "-0.8865534329093289\n",
      "-0.8299054748530454\n",
      "-0.8423504565331073\n",
      "-0.8178876174922813\n",
      "-0.9318612658705022\n",
      "-0.8375595729636414\n",
      "-0.8257786538152677\n",
      "-0.8537331654509802\n",
      "-0.864474231750092\n",
      "-0.9015133162348233\n",
      "-0.9245536265697769\n",
      "-0.8433844065883442\n",
      "-0.8082753776793028\n",
      "-0.911594272643038\n",
      "-0.9101827282112739\n",
      "-0.9312775708423267\n",
      "-0.8870832116304848\n",
      "-0.8003726781746133\n",
      "-0.7998331921599254\n",
      "-0.885526866099503\n",
      "-0.8596161563121091\n",
      "-0.99951099254535\n",
      "-0.9591757543673839\n",
      "-1.0127566942759278\n",
      "-0.9107713108220498\n",
      "-0.8764141147434343\n",
      "-0.8744920356104139\n",
      "-0.9550275079923293\n",
      "-0.86446848633806\n",
      "-0.9574598353761226\n",
      "-0.9367608192301258\n",
      "-0.9173921256510922\n",
      "-0.9758185379820854\n",
      "-0.8113802585925164\n",
      "-0.8866050799820069\n",
      "-0.8698591646923977\n",
      "-0.8612194458448211\n",
      "-0.83127527190287\n",
      "-0.7697570912606989\n",
      "-0.7762370041203616\n",
      "-0.9026215335596813\n",
      "-0.8206300058658941\n",
      "-0.866381066254545\n",
      "-0.8859292545189066\n",
      "-0.7587631572188942\n",
      "-0.8069372436537009\n",
      "-0.9490054995424555\n",
      "-0.8695198319361394\n",
      "-0.8765491670100509\n",
      "-0.8446726828048379\n",
      "-0.9272207323734474\n",
      "-0.9263687656701384\n",
      "-0.8969784929302876\n",
      "-0.8744186889952238\n",
      "-0.8610630062079777\n",
      "-0.9544808411811109\n",
      "-0.8225701060634848\n",
      "-0.8311697173274082\n",
      "-0.8570831451484057\n",
      "-0.7141282341492966\n",
      "-0.808150945509683\n",
      "-0.8632617322555981\n",
      "-0.8436567911165148\n",
      "-0.8209037129392651\n",
      "-0.7998853571370313\n",
      "-0.7303132165805215\n",
      "-0.7527133242764777\n",
      "-0.8431203258725976\n",
      "-0.8273973253887645\n",
      "-0.8496711972062206\n",
      "-0.7586860574797278\n",
      "-0.7580680454474077\n",
      "-0.8233497816227632\n",
      "-0.8478152763435699\n",
      "-0.8939147758843122\n",
      "-0.8702553125041089\n",
      "-0.8937412457237747\n",
      "-0.8423017196281632\n",
      "-0.8670591890160453\n",
      "-0.740772010674949\n",
      "-0.7435320187419208\n",
      "-0.840433286796005\n",
      "-0.8268330662103374\n",
      "-0.761887986526892\n",
      "-0.7859821064780877\n",
      "-0.7814922170148754\n",
      "-0.9009053685789734\n",
      "-0.7271897464513317\n",
      "-0.8025237133600692\n",
      "-0.7266372339143814\n",
      "-0.8350596592772784\n",
      "-0.6992094230198231\n",
      "-0.6769203159334304\n",
      "-0.7233079589562134\n",
      "-0.7928187878964169\n",
      "-0.835380543724369\n",
      "-0.7561077030023067\n",
      "-0.9105016870465871\n",
      "-0.7859514092124308\n",
      "-0.7821640983219075\n",
      "-0.8186939604441514\n",
      "-0.7981181261410137\n",
      "-0.7174106284889523\n",
      "-0.7318763972288146\n",
      "-0.7181339057486525\n",
      "-0.6199343181673103\n",
      "-0.5809833067210086\n",
      "-0.7935916083600385\n",
      "-0.7043049912707849\n",
      "-0.8666553094625383\n",
      "-0.755310651373145\n",
      "-0.7872694399382458\n",
      "-0.8577701325043586\n",
      "-0.834346981043316\n",
      "-0.6884802566646547\n",
      "-0.8116189899624993\n",
      "-0.8064231331358329\n",
      "-0.7526067803949631\n",
      "-0.7227964259926969\n",
      "-0.70675258757904\n",
      "-0.8582681307577027\n",
      "-0.7826349666366258\n",
      "-0.8059017884914436\n",
      "-0.720206483923735\n",
      "-0.9048392578731135\n",
      "-0.9180942399880603\n",
      "-0.8326878408503368\n",
      "-0.7789997555813813\n",
      "-0.6958779426737929\n",
      "-0.7827451816579989\n",
      "-0.7102066334293077\n",
      "-0.7557537343976531\n",
      "-0.7958416028537775\n",
      "-0.7356928004750475\n",
      "-0.7204743781189344\n",
      "-0.846247995901915\n",
      "-0.6864052748858986\n",
      "-0.703505559778273\n",
      "-0.6544898932794979\n",
      "-0.7138211384999814\n",
      "-0.8567665714291917\n",
      "-0.738171767686858\n",
      "-0.8790036947503045\n",
      "-0.7763012368424516\n",
      "-0.8346422987301451\n",
      "-0.8795178172334611\n",
      "-0.7985488427671713\n",
      "-0.8000064767078512\n",
      "-0.8207325474685275\n",
      "-0.7785330659792556\n",
      "-0.7335029117750147\n",
      "-0.8200363660537968\n",
      "-0.8163705300989839\n",
      "-0.8763038585187886\n",
      "-0.7645644391284582\n",
      "-0.8214309529598475\n",
      "-0.8357361285806806\n",
      "-0.9900057984266045\n",
      "-0.8997506025518116\n",
      "-0.8461820950547155\n",
      "-0.7490575469948534\n",
      "-0.6174881869921419\n",
      "-0.6613745872116281\n",
      "-0.7632935841515158\n",
      "-0.7671602981531465\n",
      "-0.7621960256662091\n",
      "-0.7471682367390364\n",
      "-0.7780289240664435\n",
      "-0.7968403408698869\n",
      "-0.8141756786770573\n",
      "-0.7734037449350429\n",
      "-0.7551112310067928\n",
      "-0.6528971095876175\n",
      "-0.7865389891268463\n",
      "-0.7853839127621707\n",
      "-0.7281072002230454\n",
      "-0.7018787018362801\n",
      "-0.7313087363147779\n",
      "-0.7642850302916552\n",
      "-0.6351727619509163\n",
      "-0.6433079139949519\n",
      "-0.8022095458180938\n",
      "-0.7682184292116867\n",
      "-0.6332188846783304\n",
      "-0.7529599571900591\n",
      "-0.8283799509282161\n",
      "-0.6862527011293883\n",
      "-0.7457070853030429\n",
      "-0.7809806926868731\n",
      "-0.6992743449718165\n",
      "-0.7460458798253975\n",
      "-0.7560895856964976\n",
      "-0.7120952296661451\n",
      "-0.8318043746987696\n",
      "-0.7827873706142598\n",
      "-0.7717738261307547\n",
      "-0.7063519358075966\n",
      "-0.7985561306708191\n",
      "-0.8463070903507031\n",
      "-0.7970662717845357\n",
      "-0.6683619069757961\n",
      "-0.7177593215200145\n",
      "-0.7586837754399516\n",
      "-0.6940192355815638\n",
      "-0.7663286493855629\n",
      "-0.6803010794743464\n",
      "-0.8030909256246246\n",
      "-0.6973586779496226\n",
      "-0.6811918465241821\n",
      "-0.5991073599428345\n",
      "-0.7158048060602008\n",
      "-0.7528770780846933\n",
      "-0.6188645323421369\n",
      "-0.7360765666004104\n",
      "-0.6979654076214421\n",
      "-0.7373053265529058\n",
      "-0.6547084028242488\n",
      "-0.7673548527732474\n",
      "-0.6987853175297573\n",
      "-0.733556994584518\n",
      "-0.7341470806092104\n",
      "-0.8513241076540129\n",
      "-0.7747458791041\n",
      "-0.7124529896409506\n",
      "-0.6454453468970108\n",
      "-0.7311252284823617\n",
      "-0.6105702791266383\n",
      "-0.6256141234915429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6285103697496589\n",
      "-0.6137885095829342\n",
      "-0.6885181199703\n",
      "-0.5909660278064942\n",
      "-0.6029588213493434\n",
      "-0.7134606167513414\n",
      "-0.755430049386035\n",
      "-0.6688452961564917\n",
      "-0.7130723437724649\n",
      "-0.6293191664620198\n",
      "-0.7800868081323554\n",
      "-0.7445305065241973\n",
      "-0.721059538529311\n",
      "-0.6757963293633075\n",
      "-0.6830013589700267\n",
      "-0.7078131665692284\n",
      "-0.7640171332780902\n",
      "-0.7433271438867389\n",
      "-0.7893626162813392\n",
      "-0.666755169237061\n",
      "-0.7546823428142214\n",
      "-0.7731159935798287\n",
      "-0.6571116671447274\n",
      "-0.7070157636754522\n",
      "-0.757776809457398\n",
      "-0.7779325120717783\n",
      "-0.7131074845287209\n",
      "-0.6871694648654117\n",
      "-0.6769758093178235\n",
      "-0.6637807715741061\n",
      "-0.7288969617024513\n",
      "-0.7135634033916987\n",
      "-0.808337101240329\n",
      "-0.8105576286401298\n",
      "-0.8473986460153241\n",
      "-0.8024521196999386\n",
      "-0.7683105690198234\n",
      "-0.6768227968319793\n",
      "-0.6341680592487272\n",
      "-0.7639153467437545\n",
      "-0.7290542507525062\n",
      "-0.6982909987153374\n",
      "-0.6625116881815714\n",
      "-0.7127188201118733\n",
      "-0.6631543227444339\n",
      "-0.7280682742805296\n",
      "-0.681897060544136\n",
      "-0.6979623530608153\n",
      "-0.6780762482123512\n",
      "-0.6137817268231424\n",
      "-0.7596688151836208\n",
      "-0.7039655663049732\n",
      "-0.7932206298947587\n",
      "-0.7179090508636325\n",
      "-0.6579790392149235\n",
      "-0.6641843298599103\n",
      "-0.6557094390633503\n",
      "-0.7043148879165372\n",
      "-0.7588013503232096\n",
      "-0.6122992990333794\n",
      "-0.7060765310513445\n",
      "-0.6259124443124052\n",
      "-0.5765791306637769\n",
      "-0.6216589395419809\n",
      "-0.5228690469157946\n",
      "-0.7367350916428151\n",
      "-0.5948550675819556\n",
      "-0.6841092402690381\n",
      "-0.6884691913021402\n",
      "-0.7766122128230911\n",
      "-0.8603991806843208\n",
      "-0.7274554206123525\n",
      "-0.6790584645869635\n",
      "-0.6354683622092595\n",
      "-0.6804911419914453\n",
      "-0.6290478433359755\n",
      "-0.5363972287920206\n",
      "-0.5431942149487528\n",
      "-0.5783581134295026\n",
      "-0.5427399052977825\n",
      "-0.5125263213072718\n",
      "-0.5518098733073105\n",
      "-0.6583318427378831\n",
      "-0.7505128527322026\n",
      "-0.7190094960841219\n",
      "-0.6783326220002248\n",
      "-0.5667286753680152\n",
      "-0.6266070982773847\n",
      "-0.6919327887054061\n",
      "-0.65504074906789\n",
      "-0.6122954368512208\n",
      "-0.5693614143747762\n",
      "-0.6374511103332212\n",
      "-0.6029802144688277\n",
      "-0.6591766624798225\n",
      "-0.7234305859352573\n",
      "-0.6395018659200074\n",
      "-0.6697142165279788\n",
      "-0.6861738794801379\n",
      "-0.5464429809795571\n",
      "-0.6445583560431273\n",
      "-0.7176209659616365\n",
      "-0.5946230018883057\n",
      "-0.6404434032822104\n",
      "-0.5544694516500005\n",
      "-0.5837000360493265\n",
      "-0.5373083792971869\n",
      "-0.5616521208389601\n",
      "-0.6894320469092122\n",
      "-0.601749760761758\n",
      "-0.6685964550095576\n",
      "-0.7246491994366155\n",
      "-0.5758160414202281\n",
      "-0.6714695295043833\n",
      "-0.7149449228400441\n",
      "-0.653170315242715\n",
      "-0.6120826818536728\n",
      "-0.511115427255493\n",
      "-0.6291285131985299\n",
      "-0.6805383931810662\n",
      "-0.6612357372474659\n",
      "-0.601466116175938\n",
      "-0.5997401700049707\n",
      "-0.5269754699677652\n",
      "-0.581785043802115\n",
      "-0.5589351875517138\n",
      "-0.6840644461177677\n",
      "-0.656196861420706\n",
      "-0.602242609520213\n",
      "-0.548666318818589\n",
      "-0.48037604185607274\n",
      "-0.6134406751864463\n",
      "-0.5808479708433624\n",
      "-0.5825683254102255\n",
      "-0.48935146231532356\n",
      "-0.610610346053238\n",
      "-0.6350771994100727\n",
      "-0.5915000477808434\n",
      "-0.4950997609753648\n",
      "-0.6111398447250627\n",
      "-0.6619633653363448\n",
      "-0.6946839234219111\n",
      "-0.7503522467107098\n",
      "-0.6519154756301848\n",
      "-0.6692531494949995\n",
      "-0.5817526222437943\n",
      "-0.6319356294749418\n",
      "-0.6245564793845387\n",
      "-0.5469051177289164\n",
      "-0.618955974403444\n",
      "-0.5677718745208503\n",
      "-0.5871075408480945\n",
      "-0.6949426143776095\n",
      "-0.5600278841496743\n",
      "-0.6070629111102623\n",
      "-0.5753122039598307\n",
      "-0.5575211962032673\n",
      "-0.7024065783841295\n",
      "-0.6796760064592108\n",
      "-0.614105906555632\n",
      "-0.5506858493762365\n",
      "-0.5712497062749315\n",
      "-0.6584765690192225\n",
      "-0.5547027746921511\n",
      "-0.6684233659105584\n",
      "-0.5622959484826139\n",
      "-0.5696689786543117\n",
      "-0.6072711776811958\n",
      "-0.5237530182679133\n",
      "-0.5519506369948023\n",
      "-0.5594470211824797\n",
      "-0.5553129035917589\n",
      "-0.5359324379369398\n",
      "-0.6558469998075165\n",
      "-0.5374723973130824\n",
      "-0.46446821696261986\n",
      "-0.5844827246163949\n",
      "-0.5260597616847594\n",
      "-0.5331684771468722\n",
      "-0.58548906722333\n",
      "-0.49863653437104183\n",
      "-0.5998392039362122\n",
      "-0.5872397421262566\n",
      "-0.5678718907810391\n",
      "-0.5123258962425279\n",
      "-0.5112263431698484\n",
      "-0.5036249247918386\n",
      "-0.5676679146444136\n",
      "-0.5370156419336976\n",
      "-0.6213357752347242\n",
      "-0.554907805597241\n",
      "-0.5512391506973354\n",
      "-0.43869131455061966\n",
      "-0.44600428877137516\n",
      "-0.48419998863288993\n",
      "-0.4996139987821357\n",
      "-0.5566033307131044\n",
      "-0.5561429279995291\n",
      "-0.5006065608253246\n",
      "-0.506455091888098\n",
      "-0.48556670175529654\n",
      "-0.4937439569585021\n",
      "-0.5295123526664147\n",
      "-0.5259016532514699\n",
      "-0.5438242928861527\n",
      "-0.575811026529933\n",
      "-0.6014134045884806\n",
      "-0.5676747851046047\n",
      "-0.5947733635078648\n",
      "-0.5110177227134163\n",
      "-0.5640397600901242\n",
      "-0.5836479593134082\n",
      "-0.6183458877027577\n",
      "-0.6227510936235333\n",
      "-0.6427923545629809\n",
      "-0.48977385437943066\n",
      "-0.43110279676607416\n",
      "-0.5646792954145377\n",
      "-0.4552136619670376\n",
      "-0.5677524530225245\n",
      "-0.5225292604058407\n",
      "-0.483126765774531\n",
      "-0.5636878514297246\n",
      "-0.5012518265173389\n",
      "-0.5116091623915804\n",
      "-0.34183296166952215\n",
      "-0.47788873945415355\n",
      "-0.4853142149894587\n",
      "-0.501291672256003\n",
      "-0.4959926071984631\n",
      "-0.5235806974733073\n",
      "-0.5004331217240684\n",
      "-0.5759634795316679\n",
      "-0.568353261467842\n",
      "-0.4969319069488101\n",
      "-0.6096690977688092\n",
      "-0.3587670265410091\n",
      "-0.49124298865115323\n",
      "-0.5640480652889179\n",
      "-0.48596279058737657\n",
      "-0.4978756797006468\n",
      "-0.4028919250710809\n",
      "-0.45518648875598056\n",
      "-0.522239945106686\n",
      "-0.4332354476626269\n",
      "-0.4561806777346899\n",
      "-0.4516404931894607\n",
      "-0.41810328061666086\n",
      "-0.4541846577705603\n",
      "-0.525099790469601\n",
      "-0.48563632948845953\n",
      "-0.527012506247823\n",
      "-0.5897928236003367\n",
      "-0.5113710795861105\n",
      "-0.5614946892498754\n",
      "-0.4948554038432547\n",
      "-0.4956154572611399\n",
      "-0.6019837864439663\n",
      "-0.753364426226331\n",
      "-0.7150829591776294\n",
      "-0.6634471759278752\n",
      "-0.6622813737353767\n",
      "-0.6206998945148358\n",
      "-0.5697465579346862\n",
      "-0.5565848010318867\n",
      "-0.6314533633574874\n",
      "-0.5532312776294581\n",
      "-0.6274774119510611\n",
      "-0.5521655832778454\n",
      "-0.47249494561463923\n",
      "-0.5609667642019596\n",
      "-0.4450577678277429\n",
      "-0.6041024991444427\n",
      "-0.5812662154493307\n",
      "-0.5736002378403334\n",
      "-0.6217944885828064\n",
      "-0.5711931365586087\n",
      "-0.5614872520874826\n",
      "-0.5769692606613274\n",
      "-0.5335527115377622\n",
      "-0.581312489507236\n",
      "-0.5710026381306361\n",
      "-0.6307074491373988\n",
      "-0.5483932041388105\n",
      "-0.618544289220352\n",
      "-0.6499520193905185\n",
      "-0.6022351564838119\n",
      "-0.653092105576784\n",
      "-0.6315744652880797\n",
      "-0.5841217670262424\n",
      "-0.6111678752473169\n",
      "-0.5688821639880034\n",
      "-0.4444447439372717\n",
      "-0.5506607789258962\n",
      "-0.5086604998887814\n",
      "-0.5430610604934427\n",
      "-0.5833267904149658\n",
      "-0.5316554709565907\n",
      "-0.537443383568127\n",
      "-0.34015261867807106\n",
      "-0.5419541422380353\n",
      "-0.5258560134587427\n",
      "-0.4369585806908718\n",
      "-0.4762507393972917\n",
      "-0.6070561483995824\n",
      "-0.5504995086211292\n",
      "-0.5500359316379368\n",
      "-0.4545212907778148\n",
      "-0.44756397070564385\n",
      "-0.4046024498631287\n",
      "-0.5230161832494592\n",
      "-0.4254029446372152\n",
      "-0.5195947005223167\n",
      "-0.5554185568548968\n",
      "-0.5410166999885295\n",
      "-0.539245685931114\n",
      "-0.5874657215737282\n",
      "-0.49361567257569244\n",
      "-0.5507396523152988\n",
      "-0.5764209172677325\n",
      "-0.610947173931895\n",
      "-0.5665538065030901\n",
      "-0.5293396549362765\n",
      "-0.478019174796272\n",
      "-0.5338949802966614\n",
      "-0.5065645580230136\n",
      "-0.5680413282503292\n",
      "-0.5191748511270841\n",
      "-0.5392918732351528\n",
      "-0.683444771467665\n",
      "-0.5462164590590114\n",
      "-0.5710181758235581\n",
      "-0.6562319007541355\n",
      "-0.7153806891761513\n",
      "-0.5333936010716348\n",
      "-0.4787026510497388\n",
      "-0.40760360523839667\n",
      "-0.4892246602944088\n",
      "-0.5225403114270556\n",
      "-0.49803913484210593\n",
      "-0.45300108712385073\n",
      "-0.5044938056704047\n",
      "-0.5890008697814324\n",
      "-0.5882487209132745\n",
      "-0.6028719970878714\n",
      "-0.6818230850713916\n",
      "-0.53006377965232\n",
      "-0.4746061879480512\n",
      "-0.5447589981736813\n",
      "-0.5689332552880909\n",
      "-0.5178069061441992\n",
      "-0.48503690041205244\n",
      "-0.4386873597694996\n",
      "-0.5019907271188964\n",
      "-0.5353555208801223\n",
      "-0.5208925732374886\n",
      "-0.5658047337111332\n",
      "-0.37433572092790784\n",
      "-0.5524170749561985\n",
      "-0.5169623790378888\n",
      "-0.469771120522635\n",
      "-0.5921708752985747\n",
      "-0.5271236486798112\n",
      "-0.6789007530437547\n",
      "-0.5938316554160391\n",
      "-0.6754368787962239\n",
      "-0.7349794262997613\n",
      "-0.6125848985234631\n",
      "-0.5905294790469366\n",
      "-0.5784413514475626\n",
      "-0.5882916023090554\n",
      "-0.5499976981954485\n",
      "-0.5004584995582892\n",
      "-0.49995487978884\n",
      "-0.5229996617237215\n",
      "-0.5764201652001008\n",
      "-0.5151967580946734\n",
      "-0.5715815411522638\n",
      "-0.6149721163844817\n",
      "-0.5108736853598127\n",
      "-0.6024320867742788\n",
      "-0.6535849505660767\n",
      "-0.5340180312763918\n",
      "-0.616888266667061\n",
      "-0.5552514771312208\n",
      "-0.5807395609782988\n",
      "-0.6023354372454673\n",
      "-0.609828730435971\n",
      "-0.5984812105767937\n",
      "-0.6548693634788612\n",
      "-0.6164677808026825\n",
      "-0.5711564386251723\n",
      "-0.6159282401508366\n",
      "-0.641083351006712\n",
      "-0.5848601378416117\n",
      "-0.48238520289569903\n",
      "-0.5397399621055872\n",
      "-0.654031761463862\n",
      "-0.6658105316142041\n",
      "-0.5211950232255486\n",
      "-0.6381739687076542\n",
      "-0.4813361186409735\n",
      "-0.5890623894148055\n",
      "-0.6522514357875245\n",
      "-0.6135987816610513\n",
      "-0.6258695720319741\n",
      "-0.5717457908129454\n",
      "-0.573971538534078\n",
      "-0.6783468048410805\n",
      "-0.4414499857017379\n",
      "-0.5473429332507334\n",
      "-0.6185609615788961\n",
      "-0.6905328950256837\n",
      "-0.5803759239681641\n",
      "-0.6661536119472322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6588933317820109\n",
      "-0.6299284560740745\n",
      "-0.5942962627306921\n",
      "-0.5382203444125\n",
      "-0.5521565055876273\n",
      "-0.49335832133253005\n",
      "-0.5249279790111163\n",
      "-0.6117953546769475\n",
      "-0.5486710232299338\n",
      "-0.6187198898029901\n",
      "-0.5927929736709537\n",
      "-0.5812358524871649\n",
      "-0.6554915080716952\n",
      "-0.7460390491967425\n",
      "-0.8077493658592062\n",
      "-0.6571117605475258\n",
      "-0.634962930849194\n",
      "-0.5880117752402019\n",
      "-0.5335557149607361\n",
      "-0.5270168776990556\n",
      "-0.5481269943986458\n",
      "-0.5722401400763034\n",
      "-0.5599798510684608\n",
      "-0.6353262928156785\n",
      "-0.5935775093588278\n",
      "-0.527205786654924\n",
      "-0.5554897868965119\n",
      "-0.5375561920735286\n",
      "-0.54989708089842\n",
      "-0.5531535130789765\n",
      "-0.5652078036908263\n",
      "-0.6439508878964586\n",
      "-0.6681488386145469\n",
      "-0.6104533274008639\n",
      "-0.6781876904162176\n",
      "-0.6613750247760717\n",
      "-0.6095481961266521\n",
      "-0.6069895941520881\n",
      "-0.5819122663689605\n",
      "-0.6333053294898935\n",
      "-0.6008025199917748\n",
      "-0.6190843387498\n",
      "-0.6500485084157632\n",
      "-0.573184725521461\n",
      "-0.5760192570852795\n",
      "-0.4805525931240132\n",
      "-0.5654409131198025\n",
      "-0.5230219556623846\n",
      "-0.5603594351023663\n",
      "-0.5585728111518955\n",
      "-0.5325145163722407\n",
      "-0.6496524604606652\n",
      "-0.6824421101099148\n",
      "-0.5235255000275723\n",
      "-0.5316105848358299\n",
      "-0.429116977531922\n",
      "-0.5930152453058127\n",
      "-0.5540109629404946\n",
      "-0.6352529761346509\n",
      "-0.6483756020549372\n",
      "-0.6035734434185914\n",
      "-0.6466319817174758\n",
      "-0.595171579597316\n",
      "-0.5978346284579381\n",
      "-0.609850972227112\n",
      "-0.5575100153462529\n",
      "-0.41047087247987046\n",
      "-0.502282931593838\n",
      "-0.4946336147301053\n",
      "-0.40843984179347786\n",
      "-0.5048971315351184\n",
      "-0.5413607518387161\n",
      "-0.6648509622124107\n",
      "-0.6010347098591984\n",
      "-0.6384415673133724\n",
      "-0.5230994861667464\n",
      "-0.5661078426935877\n",
      "-0.6014712779039167\n",
      "-0.5228438426627645\n",
      "-0.5535683770942018\n",
      "-0.5520847990307981\n",
      "-0.6099009983514536\n",
      "-0.5746746027762603\n",
      "-0.549014493496772\n",
      "-0.5757120491662513\n",
      "-0.5230281988303433\n",
      "-0.5275400733866618\n",
      "-0.5947854742490736\n",
      "-0.5142087814094597\n",
      "-0.5738013908683285\n",
      "-0.5737021913041845\n",
      "-0.6106094005472206\n",
      "-0.6517240412908203\n",
      "-0.7269743085306056\n",
      "-0.5946048340528409\n",
      "-0.5761846862908891\n",
      "-0.5812904508734951\n",
      "-0.5290523986729548\n",
      "-0.5708630484201865\n",
      "-0.5757863929665157\n",
      "-0.6505480160655301\n",
      "-0.5811899800426948\n",
      "-0.6410226079812353\n",
      "-0.5394808737745894\n",
      "-0.667267282303024\n",
      "-0.7571803855043161\n",
      "-0.658040478261973\n",
      "-0.6543006692695044\n",
      "-0.5810323393125906\n",
      "-0.6394500139500835\n",
      "-0.6028627062567141\n",
      "-0.6258630995041872\n",
      "-0.5963135374764973\n",
      "-0.6774621885766189\n",
      "-0.5772899241494027\n",
      "-0.6779586760020228\n",
      "-0.7002323002130826\n",
      "-0.6340073780770645\n",
      "-0.6914581130033758\n",
      "-0.514190914240212\n",
      "-0.658720403893896\n",
      "-0.6838466804750573\n",
      "-0.7134876238327011\n",
      "-0.6269680263226715\n",
      "-0.6521140993897065\n",
      "-0.5892356751271767\n",
      "-0.6568380871919726\n",
      "-0.5208627456523435\n",
      "-0.5604283533067412\n",
      "-0.692611733858522\n",
      "-0.6340560773595332\n",
      "-0.7320822616518816\n",
      "-0.6149257617671796\n",
      "-0.6498532410494743\n",
      "-0.5242522223416901\n",
      "-0.6096256826967366\n",
      "-0.6404498333959473\n",
      "-0.7322264769993638\n",
      "-0.6241553460960606\n",
      "-0.77928243493376\n",
      "-0.6004769193468236\n",
      "-0.7049707509237485\n",
      "-0.6119186835930512\n",
      "-0.6449133745117658\n",
      "-0.6811363231762758\n",
      "-0.673036551239577\n",
      "-0.6553133411978885\n",
      "-0.6173107942149798\n",
      "-0.5141412282111781\n",
      "-0.6728788582617222\n",
      "-0.586264660824937\n",
      "-0.6404968173902185\n",
      "-0.7188532451472873\n",
      "-0.6322787850365656\n",
      "-0.6254794393294894\n",
      "-0.5904481882789298\n",
      "-0.6217006243955567\n",
      "-0.6648795148207801\n",
      "-0.6298929544296169\n",
      "-0.6883403819954682\n",
      "-0.6284019383787335\n",
      "-0.6882903566583144\n",
      "-0.6368620835669269\n",
      "-0.7996952932340227\n",
      "-0.7760357278646041\n",
      "-0.6627177106472584\n",
      "-0.7106178092635123\n",
      "-0.8226864660769756\n",
      "-0.8149888919183521\n",
      "-0.6876638349079311\n",
      "-0.7201585983704436\n",
      "-0.8323939732412722\n",
      "-0.6912611691822848\n",
      "-0.783741764812774\n",
      "-0.7068682472808989\n",
      "-0.6549468922519834\n",
      "-0.728242305718396\n",
      "-0.7357267730899202\n",
      "-0.6872334571292085\n",
      "-0.6376538656972558\n",
      "-0.6909568047666365\n",
      "-0.6081379531173385\n",
      "-0.6989405261810806\n",
      "-0.6746524392804089\n",
      "-0.7088279923914259\n",
      "-0.6625008688536054\n",
      "-0.6117078980328123\n",
      "-0.7514208281146775\n",
      "-0.7102066884891811\n",
      "-0.7747811190581096\n",
      "-0.8741204713536742\n",
      "-0.6974790427666304\n",
      "-0.6868665839184339\n",
      "-0.7968946740387804\n",
      "-0.6820684261441482\n",
      "-0.8518114751227898\n",
      "-0.7617501080779833\n",
      "-0.6156886094376979\n",
      "-0.651734827009803\n",
      "-0.6602000034945843\n",
      "-0.7884312519851013\n",
      "-0.7581964126250893\n",
      "-0.7877062036578143\n",
      "-0.6211454420481743\n",
      "-0.6959563780044397\n",
      "-0.7453166092328729\n",
      "-0.7263388619291181\n",
      "-0.7411538836484939\n",
      "-0.7429151855638282\n",
      "-0.7316888747511054\n",
      "-0.7529648901378151\n",
      "-0.8374010199178281\n",
      "-0.8743177430742581\n",
      "-0.7133509594996945\n",
      "-0.706060721548042\n",
      "-0.7514182129757553\n",
      "-0.6583023135946368\n",
      "-0.7970298361519927\n",
      "-0.6780573587470534\n",
      "-0.6464977291775318\n",
      "-0.7364048666942429\n",
      "-0.6551557274270343\n",
      "-0.7729068596461035\n",
      "-0.8160247507060313\n",
      "-0.7995063287663053\n",
      "-0.7637137950662339\n",
      "-0.7297017188197161\n",
      "-0.7296184335596808\n",
      "-0.7770051734900788\n",
      "-0.783114208162075\n",
      "-0.7490248209632919\n",
      "-0.8557222561324356\n",
      "-0.7963947856743108\n",
      "-0.7343272961197393\n",
      "-0.8409518591850658\n",
      "-0.7828111173095169\n",
      "-0.80203373476605\n",
      "-0.7433568189568422\n",
      "-0.6472396906017068\n",
      "-0.7478822073378727\n",
      "-0.8056177859031679\n",
      "-0.7917389200963648\n",
      "-0.806128564245205\n",
      "-0.7773767193747495\n",
      "-0.6805238861516475\n",
      "-0.7176125467040705\n",
      "-0.7537880631004459\n",
      "-0.7956382613184381\n",
      "-0.726358246278219\n",
      "-0.7873924575336527\n",
      "-0.791191072050667\n",
      "-0.7894619839333568\n",
      "-0.8184537324927738\n",
      "-0.8219322145952989\n",
      "-0.8482198646687191\n",
      "-0.7600889502557385\n",
      "-0.7602773128373022\n",
      "-0.6980779350773902\n",
      "-0.8248183552487975\n",
      "-0.7750670501774787\n",
      "-0.8939379401248495\n",
      "-0.7811296257678373\n",
      "-0.8317841261825916\n",
      "-0.819537523790395\n",
      "-0.7579335973286868\n",
      "-0.7347453019486072\n",
      "-0.6964167372260944\n",
      "-0.7252405334105104\n",
      "-0.7574211695120979\n",
      "-0.8077884346791744\n",
      "-0.8316469627864913\n",
      "-0.7860110003890902\n",
      "-0.8664278463011997\n",
      "-0.737846889101079\n",
      "-0.7994624201719465\n",
      "-0.7225257230057143\n",
      "-0.8326481972445432\n",
      "-0.7736744446552307\n",
      "-0.8170297336192777\n",
      "-0.7425151655458565\n",
      "-0.727640869441108\n",
      "-0.7865730336995812\n",
      "-0.834781511720308\n",
      "-0.7526722044589478\n",
      "-0.8312863795179852\n",
      "-0.8058711195399741\n",
      "-0.7966922168956191\n",
      "-0.7675229122054497\n",
      "-0.815501855351273\n",
      "-0.8225677633781568\n",
      "-0.8831571126500374\n",
      "-0.8734105475829458\n",
      "-0.7962288995224538\n",
      "-0.8678491448974816\n",
      "-0.8084015351062298\n",
      "-0.8343770909714745\n",
      "-0.7879723870610406\n",
      "-0.7533969930951501\n",
      "-0.8415595509813852\n",
      "-0.7272189318129134\n",
      "-0.841440306317831\n",
      "-0.8560149399174428\n",
      "-0.8574239140892899\n",
      "-0.8557283572541419\n",
      "-0.781213475792871\n",
      "-0.8086090529702342\n",
      "-0.8870718471930161\n",
      "-0.9095890946974466\n",
      "-0.8487799263391262\n",
      "-0.8804610571499285\n",
      "-0.9284429099362312\n",
      "-0.8745225764728748\n",
      "-0.9084161978911666\n",
      "-0.9964580896878598\n",
      "-0.8611080583413594\n",
      "-0.9380776836466451\n",
      "-0.8123558139018534\n",
      "-0.8357475197954356\n",
      "-0.9039027952671305\n",
      "-0.9481012501845432\n",
      "-0.9519219930973759\n",
      "-0.9065003529801627\n",
      "-1.0023797869244566\n",
      "-0.9165910275934046\n",
      "-0.9353346414440443\n",
      "-0.9159890234972831\n",
      "-0.8432393327344803\n",
      "-0.8624520192839816\n",
      "-0.9641133140851079\n",
      "-0.9840738818789788\n",
      "-0.9700627980532932\n",
      "-0.9577990100779948\n",
      "-0.8528080197804297\n",
      "-0.9369089053169561\n",
      "-0.986059750727807\n",
      "-0.8657326083350135\n",
      "-0.9061675535174923\n",
      "-0.8281609857572281\n",
      "-0.8765587293593848\n",
      "-0.8931293288030842\n",
      "-0.8074613788536313\n",
      "-0.8679439913905825\n",
      "-0.888176714047349\n",
      "-0.8842229370206915\n",
      "-0.8529059124178878\n",
      "-0.8692562936778492\n",
      "-0.992550261869819\n",
      "-0.9938190713446361\n",
      "-0.9078392078983384\n",
      "-0.8175052989577322\n",
      "-0.8681993998228572\n",
      "-0.9207251379835837\n",
      "-0.9021537900703173\n",
      "-0.8219299148910765\n",
      "-0.9185825789317142\n",
      "-0.9062749196750243\n",
      "-0.8695821553262584\n",
      "-0.9404615516333256\n",
      "-0.9332544569484279\n",
      "-0.9019510634410717\n",
      "-0.9604842222912793\n",
      "-0.93479300359587\n",
      "-0.960769781536099\n",
      "-0.9647052361904394\n",
      "-0.9590691782111717\n",
      "-0.9967674773179668\n",
      "-0.9599570776995945\n",
      "-0.9232047039234329\n",
      "-0.9491644575016299\n",
      "-0.9780604805189771\n",
      "-0.9368860443121814\n",
      "-0.9243645504059357\n",
      "-1.0127480228245167\n",
      "-0.9568085466859986\n",
      "-0.95309703801714\n",
      "-0.9921986872158888\n",
      "-0.9626301016886402\n",
      "-0.9669963400871342\n",
      "-0.9177194781097979\n",
      "-0.9302872004021189\n",
      "-0.9675833347887849\n",
      "-0.9902347406470821\n",
      "-0.8853403182385868\n",
      "-0.8366096841894591\n",
      "-0.9569861776384174\n",
      "-0.9169773330298029\n",
      "-1.0182880136427817\n",
      "-1.0665019625796897\n",
      "-1.0298616686328772\n",
      "-0.8759199782970992\n",
      "-1.0080851163962579\n",
      "-1.0038872069513\n",
      "-0.9721548071842937\n",
      "-1.1206006236685953\n",
      "-1.0246204379332517\n",
      "-0.9833266262979573\n",
      "-0.8940557345489378\n",
      "-0.9687994423366985\n",
      "-0.9318972570245433\n",
      "-0.9578479338425875\n",
      "-0.8864669440117163\n",
      "-0.9484297175692801\n",
      "-0.9765924040601532\n",
      "-0.9322390267142873\n",
      "-0.8662505048738613\n",
      "-0.9623231467494598\n",
      "-0.9316274052529545\n",
      "-1.0095757747538412\n",
      "-0.9539805614468079\n",
      "-0.8536285379950067\n",
      "-0.9267982491864831\n",
      "-0.963176175687216\n",
      "-0.9210990946620975\n",
      "-0.9106352641484085\n",
      "-1.0157720616666714\n",
      "-0.9931340786637919\n",
      "-0.9840922650007093\n",
      "-1.0120420712726033\n",
      "-0.9279027581473309\n",
      "-1.0004128559239673\n",
      "-0.9093386062908518\n",
      "-1.0111734055175383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.98173432780847\n",
      "-0.9408911385631987\n",
      "-1.0101265176101588\n",
      "-0.9406794883058458\n",
      "-0.9603550679160621\n",
      "-1.0196975679475115\n",
      "-0.9509966865458672\n",
      "-1.0263603383170508\n",
      "-1.0344106416957122\n",
      "-0.9866328357833205\n",
      "-1.0366780620033489\n",
      "-0.9815251762065186\n",
      "-1.0591908064591764\n",
      "-1.0646379551178005\n",
      "-1.036411944396772\n",
      "-1.0817118611679855\n",
      "-1.1093063749735714\n",
      "-1.097644217477415\n",
      "-1.0200651739709383\n",
      "-0.9450258097227009\n",
      "-0.9563840705796401\n",
      "-0.8990679186472708\n",
      "-1.0926668080059219\n",
      "-1.0598644291831567\n",
      "-1.0054673903748068\n",
      "-0.8731905118766831\n",
      "-0.9012847508350648\n",
      "-0.8925039829467903\n",
      "-0.8602546409003852\n",
      "-0.9439441886335644\n",
      "-0.9758199606716977\n",
      "-0.8925243235661944\n",
      "-0.9222573146676105\n",
      "-1.1105349703553737\n",
      "-1.0814639325086857\n",
      "-1.078225286066273\n",
      "-1.063573638969864\n",
      "-1.1765743112586975\n",
      "-1.0435289323558132\n",
      "-0.9892879699533499\n",
      "-1.1792316552213158\n",
      "-0.9515304831401229\n",
      "-1.1178851619386432\n",
      "-0.8988886610528616\n",
      "-0.9451920817311444\n",
      "-0.9295730481579849\n",
      "-0.9269219353500762\n",
      "-0.9211296224673817\n",
      "-0.9759425652741831\n",
      "-0.969868085641509\n",
      "-0.9548058096712597\n",
      "-1.034850426642936\n",
      "-1.100742908655603\n",
      "-1.0710829130564659\n",
      "-1.00692366602337\n",
      "-0.9347890417376866\n",
      "-0.9967537182568152\n",
      "-0.9233834455522936\n",
      "-0.9531620014028118\n",
      "-0.8334646016604028\n",
      "-0.9514645880318191\n",
      "-0.9746790828488181\n",
      "-0.9325153657628145\n",
      "-0.9902671668927454\n",
      "-0.9746602366627442\n",
      "-1.0499468052730183\n",
      "-0.9307791837697049\n",
      "-0.9563051491978323\n",
      "-0.9551138927976436\n",
      "-1.0152534862214666\n",
      "-1.0518958813583024\n",
      "-1.0066179568461227\n",
      "-0.9724442840657386\n",
      "-1.0123701364202569\n",
      "-1.0200790587524338\n",
      "-1.0001179437524883\n",
      "-1.1075603364748283\n",
      "-0.9431358277255303\n",
      "-1.009372607725207\n",
      "-1.0014574238760001\n",
      "-0.90461216640252\n",
      "-0.9055935490339758\n",
      "-1.0176438752394714\n",
      "-0.9689275881752555\n",
      "-0.9303845621128907\n",
      "-0.8882114373999702\n",
      "-0.9386195620104187\n",
      "-0.928088333197064\n",
      "-1.086143250603122\n",
      "-1.0876752825106764\n",
      "-0.9320278473490239\n",
      "-0.9177359767559853\n",
      "-0.9325773768449059\n",
      "-0.9925394568194779\n",
      "-1.018810403287016\n",
      "-0.9050263648208344\n",
      "-1.0360193407136271\n",
      "-1.0334456582151756\n",
      "-0.9893181190406389\n",
      "-1.0493870068487992\n",
      "-0.9778851721330495\n",
      "-1.0103718860658428\n",
      "-1.0256074212787323\n",
      "-0.9389186543050655\n",
      "-1.056749651060618\n",
      "-1.0685240938118974\n",
      "-1.011319565072526\n",
      "-0.9945208454774043\n",
      "-0.9966990115590314\n",
      "-1.036906898174748\n",
      "-0.9380067160359277\n",
      "-1.0518229671605794\n",
      "-1.0656303666991223\n",
      "-1.0388846173372128\n",
      "-1.051629680712012\n",
      "-1.0187407775261386\n",
      "-0.9620324843517005\n",
      "-0.979237783294471\n",
      "-1.0205738327005673\n",
      "-1.1243675431397058\n",
      "-1.0703341526377614\n",
      "-0.9544112939724319\n",
      "-1.0243890515246523\n",
      "-1.0004913983213857\n",
      "-1.0403914917578092\n",
      "-1.079361098797888\n",
      "-0.9736600778265071\n",
      "-0.9900876981861488\n",
      "-1.0006302487088852\n",
      "-0.9564011150736885\n",
      "-1.0743484926217544\n",
      "-1.0346985803418987\n",
      "-0.9867475565040117\n",
      "-1.0780978873511917\n",
      "-1.0334534795005894\n",
      "-0.9795007215009984\n",
      "-0.9872036394048993\n",
      "-0.9603615463557522\n",
      "-1.0765606758103294\n",
      "-0.9699478770021883\n",
      "-1.0052693629776523\n",
      "-0.9859421941366996\n",
      "-1.0628873252634703\n",
      "-0.9633095457747886\n",
      "-0.8920664905551534\n",
      "-1.011249808803743\n",
      "-1.0695972730138283\n",
      "-0.9595927209289082\n",
      "-1.0123693639918856\n",
      "-1.0147165151969788\n",
      "-1.0259439672951807\n",
      "-1.1281467501516251\n",
      "-1.1070746596947005\n",
      "-1.0782385656235352\n",
      "-1.1832626508204067\n",
      "-1.1468204202282222\n",
      "-1.1104154138085875\n",
      "-1.2544803658339139\n",
      "-1.1438802287617997\n",
      "-1.1210183220950272\n",
      "-1.040939426729688\n",
      "-1.0754202481854984\n",
      "-1.057433248819943\n",
      "-1.0098089757627842\n",
      "-1.0331177950243304\n",
      "-0.9287808295077722\n",
      "-0.9015459521928642\n",
      "-1.0443600464159286\n",
      "-1.005951467346595\n",
      "-0.9700818373339413\n",
      "-0.8507603425972317\n",
      "-0.8461894949310743\n",
      "-0.8819105971631098\n",
      "-0.9375866392466475\n",
      "-0.8564106753729416\n",
      "-0.9667591550983063\n",
      "-1.0508659179563204\n",
      "-1.0126601457889346\n",
      "-1.0116821674566265\n",
      "-0.9402452687576373\n",
      "-0.931939092178944\n",
      "-0.8777075884438156\n",
      "-0.9070735494847367\n",
      "-0.9447959296864801\n",
      "-0.8036484007178901\n",
      "-0.8367092869572811\n",
      "-0.8942936419181055\n",
      "-0.8333486692170258\n",
      "-0.9415827693570733\n",
      "-0.7780417125027526\n",
      "-0.8909072191436165\n",
      "-0.8041640929663549\n",
      "-0.7414491292450087\n",
      "-0.8680524196818105\n",
      "-0.936296101259384\n",
      "-0.9376178408060941\n",
      "-1.1080942554608517\n",
      "-1.272042027941334\n",
      "-1.3044075487419853\n",
      "-1.3167619167668827\n",
      "-1.4197898683787544\n",
      "-1.455548752072579\n",
      "-1.5664930387129732\n",
      "-1.622049634746078\n",
      "-1.724878076082674\n",
      "-1.736526291922457\n",
      "-1.671019619282078\n",
      "-1.6152082368911003\n",
      "-1.7136038384203636\n",
      "-1.7293228361507824\n",
      "-1.8242154422654804\n",
      "-1.6630239368958772\n",
      "-1.661369174475821\n",
      "-1.7539135874237044\n",
      "-1.7802653468450151\n",
      "-1.8038581935175015\n",
      "-1.7521787964472118\n",
      "-1.7891506283585068\n",
      "-1.740907253846296\n",
      "-1.7416456859243452\n",
      "-1.7180426393083468\n",
      "-1.680273097415581\n",
      "-1.6041315462224808\n",
      "-1.600281292754545\n",
      "-1.6587653114445668\n",
      "-1.674262273477875\n",
      "-1.8140774196320113\n",
      "-1.882406489843935\n",
      "-1.8019792201510834\n",
      "-1.6815881798013088\n",
      "-1.6172092783446252\n",
      "-1.5811571179301807\n",
      "-1.5255568147934067\n",
      "-1.5464624445165085\n",
      "-1.511916566302208\n",
      "-1.4140583527925068\n",
      "-1.3406751925751965\n",
      "-1.3236686590697302\n",
      "-1.3119061864170611\n",
      "-1.276111080978433\n",
      "-1.2319733105368482\n",
      "-1.1315244425738322\n",
      "-1.0964722770274533\n",
      "-1.024569718753372\n",
      "-0.00361292384079631\n",
      "0.05305076498231419\n",
      "0.11271248612422853\n",
      "0.0459637468830246\n",
      "-0.04952026753650639\n",
      "0.038277253124768915\n",
      "-0.049837745941624934\n",
      "0.011057117352552433\n",
      "0.06420015776310538\n",
      "-0.0029761632641419865\n",
      "0.03239730858521585\n",
      "-0.04857318367853541\n",
      "0.017911796076134356\n",
      "-0.01619002316292625\n",
      "-0.056269672516741656\n",
      "-0.0215343458229305\n",
      "-0.1864743416083676\n",
      "0.004675203549165549\n",
      "-0.16266869854755567\n",
      "0.004523490978451644\n",
      "0.10625054946677823\n",
      "-0.010686765787828019\n",
      "0.037374597962310865\n",
      "0.005106476617797305\n",
      "-0.012331021120895989\n",
      "0.014132264077392513\n",
      "0.022412810169543364\n",
      "-0.0755530273307459\n",
      "-0.09136549671108593\n",
      "-0.11263072695434292\n",
      "-0.13935477602692553\n",
      "-0.03760600723959333\n",
      "-0.11142261584982896\n",
      "-0.16814568138686276\n",
      "-0.22514323802876693\n",
      "-0.20740839293212124\n",
      "-0.17826553370051157\n",
      "-0.15569895052692734\n",
      "-0.11317746780800386\n",
      "-0.08636814356294158\n",
      "-0.05897387572120375\n",
      "-0.1359598029414003\n",
      "-0.20776564790934554\n",
      "-0.15337187452310408\n",
      "-0.14205323332971675\n",
      "-0.16709919648862637\n",
      "-0.07236866949189498\n",
      "-0.1996296520921474\n",
      "-0.1784681702588913\n",
      "-0.21977626169484066\n",
      "-0.3156955836333035\n",
      "-0.15216824025538883\n",
      "-0.18854260378689966\n",
      "-0.16202340248260833\n",
      "-0.10330031717458361\n",
      "-0.2547110568160937\n",
      "-0.24241958040210634\n",
      "-0.2538123126196563\n",
      "-0.15614359801853056\n",
      "-0.20706543799531055\n",
      "-0.16893742305779288\n",
      "-0.11699410820226523\n",
      "-0.18626961944523812\n",
      "-0.14514849628467136\n",
      "-0.13103049373582099\n",
      "-0.24499714240423015\n",
      "-0.30942856380660144\n",
      "-0.43381190692283744\n",
      "-0.35419890813445476\n",
      "-0.32132142712938017\n",
      "-0.21332077614000647\n",
      "-0.30241854010806457\n",
      "-0.2456040231482821\n",
      "-0.34272651800293996\n",
      "-0.40717310659388\n",
      "-0.3074475514935249\n",
      "-0.26785901041027405\n",
      "-0.2608545574151792\n",
      "-0.30331472860690134\n",
      "-0.2993575863834663\n",
      "-0.3068821926340262\n",
      "-0.39683555391273473\n",
      "-0.29700086688315486\n",
      "-0.31102376891492184\n",
      "-0.3256158632698804\n",
      "-0.4514013069295675\n",
      "-0.45130367968681734\n",
      "-0.38713948526363406\n",
      "-0.4055934871355464\n",
      "-0.3912577341772982\n",
      "-0.42667251227618275\n",
      "-0.4631053666213727\n",
      "-0.40202352718573864\n",
      "-0.5581695231307304\n",
      "-0.5696051305881439\n",
      "-0.44390093676660203\n",
      "-0.4747884242508651\n",
      "-0.5154548399736617\n",
      "-0.43197727207783726\n",
      "-0.5428875771987296\n",
      "-0.5045807083180317\n",
      "-0.47256270869379613\n",
      "-0.4635465382697268\n",
      "-0.45902328701230183\n",
      "-0.32881037046037903\n",
      "-0.4137950145964643\n",
      "-0.4560752637245283\n",
      "-0.4810170176674697\n",
      "-0.5135453893461959\n",
      "-0.44866103899730936\n",
      "-0.5359992101825726\n",
      "-0.44053995853806005\n",
      "-0.4241661583143343\n",
      "-0.4751220769725987\n",
      "-0.5511535315406152\n",
      "-0.43063316895474124\n",
      "-0.5734745868636986\n",
      "-0.4703132357838243\n",
      "-0.6062677986088449\n",
      "-0.4608611943730471\n",
      "-0.46157840827699365\n",
      "-0.4862094532263621\n",
      "-0.3746937583485638\n",
      "-0.5195630455820938\n",
      "-0.5550376639382594\n",
      "-0.5875713839219266\n",
      "-0.5646127987406824\n",
      "-0.4798065908586743\n",
      "-0.5370593761529668\n",
      "-0.57940294301057\n",
      "-0.69606671209292\n",
      "-0.636367918231893\n",
      "-0.5856688786413798\n",
      "-0.532453058159318\n",
      "-0.6042927408460351\n",
      "-0.5457991182157489\n",
      "-0.5350355622807007\n",
      "-0.6404815055652155\n",
      "-0.6482899895008715\n",
      "-0.6084777799292824\n",
      "-0.5900425397064863\n",
      "-0.7521209792247812\n",
      "-0.6632014559961927\n",
      "-0.6676927731833258\n",
      "-0.6452739758448428\n",
      "-0.6212836163485632\n",
      "-0.6328122968355873\n",
      "-0.5766700190145698\n",
      "-0.5596922491024994\n",
      "-0.6203833990747398\n",
      "-0.6628979524668793\n",
      "-0.6191857196395184\n",
      "-0.6233390402641225\n",
      "-0.6192153233711309\n",
      "-0.5782394214358431\n",
      "-0.6902903140396962\n",
      "-0.5998515675469049\n",
      "-0.6057907073276573\n",
      "-0.668001380179855\n",
      "-0.6729746773745335\n",
      "-0.776918566766645\n",
      "-0.7421008319164507\n",
      "-0.6702441119165107\n",
      "-0.6398642538899597\n",
      "-0.6599776520618873\n",
      "-0.7017776375143631\n",
      "-0.6415993359261111\n",
      "-0.6718050907795002\n",
      "-0.6549755300579335\n",
      "-0.7463807983209072\n",
      "-0.7057506288365917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6373565981114494\n",
      "-0.6703049960789028\n",
      "-0.7412413250642615\n",
      "-0.6189715456157953\n",
      "-0.757703295154485\n",
      "-0.6193490750975771\n",
      "-0.724611832897144\n",
      "-0.6654739774984213\n",
      "-0.6313579843361942\n",
      "-0.7609922428791273\n",
      "-0.719605312154516\n",
      "-0.74619521333035\n",
      "-0.6978366893206686\n",
      "-0.643756143772084\n",
      "-0.8258503360429176\n",
      "-0.7647382393621847\n",
      "-0.6679015139493173\n",
      "-0.8277937029023625\n",
      "-0.7254559882795306\n",
      "-0.7829577465107145\n",
      "-0.7158651206189504\n",
      "-0.8183198017652102\n",
      "-0.8847703214321643\n",
      "-0.8278108872807641\n",
      "-0.8895021372986042\n",
      "-0.8374494106284072\n",
      "-0.906409664464597\n",
      "-0.8508594591146593\n",
      "-0.7820398448237372\n",
      "-0.8250274273213299\n",
      "-0.7839609425932721\n",
      "-0.7538508105067478\n",
      "-0.7601304187408704\n",
      "-0.7826322825939347\n",
      "-0.8167500714556992\n",
      "-0.6781298900152268\n",
      "-0.7876824902462232\n",
      "-0.9014892034354708\n",
      "-0.8345708535520724\n",
      "-0.8855057022082131\n",
      "-0.8169931084558124\n",
      "-0.8153629401411187\n",
      "-0.7543465156142886\n",
      "-0.8498345963923583\n",
      "-0.897420489174422\n",
      "-0.8603973189951432\n",
      "-0.855600340196566\n",
      "-0.7718110039323245\n",
      "-0.7571215993200866\n",
      "-0.7324809251157839\n",
      "-0.71481317227796\n",
      "-0.7268211340434346\n",
      "-0.770437938480475\n",
      "-0.7311519885665348\n",
      "-0.7637990241510526\n",
      "-0.7401922133221496\n",
      "-0.687752407001119\n",
      "-0.7770877726478613\n",
      "-0.7629383363544913\n",
      "-0.8392511161148162\n",
      "-0.8540689879257828\n",
      "-0.8455859717639559\n",
      "-0.7394131629031173\n",
      "-0.731664635714127\n",
      "-0.834777729258294\n",
      "-0.8272424110693365\n",
      "-0.8809868143659327\n",
      "-0.8707286260023357\n",
      "-0.9406138596586245\n",
      "-0.9210581372613027\n",
      "-0.921078979555685\n",
      "-0.7610679257292797\n",
      "-0.775462235721499\n",
      "-0.7754157649926616\n",
      "-0.7948056322518979\n",
      "-0.7692578828771395\n",
      "-0.8626180787036665\n",
      "-0.975076961594139\n",
      "-0.9897027999411289\n",
      "-0.9859151219783416\n",
      "-0.9439125579578211\n",
      "-0.8386685228457544\n",
      "-0.9787800741862588\n",
      "-0.9052747111299786\n",
      "-0.9361549403130702\n",
      "-0.8298236240047172\n",
      "-0.951051633141929\n",
      "-0.8866429259309134\n",
      "-0.8514932614301611\n",
      "-0.8498543091815465\n",
      "-0.9454818996879099\n",
      "-0.9009450801437122\n",
      "-0.9230928933774417\n",
      "-0.9167121434533201\n",
      "-0.934335438141222\n",
      "-0.9582719490750162\n",
      "-0.9562950303245585\n",
      "-0.8317815398982074\n",
      "-0.8749475009866718\n",
      "-0.9241813323098766\n",
      "-0.8518014602173662\n",
      "-0.8438013068427266\n",
      "-0.8530334266476395\n",
      "-0.830098509463123\n",
      "-0.849332077832144\n",
      "-1.0360790664637358\n",
      "-0.9514713241643853\n",
      "-0.8608129148399994\n",
      "-0.86519253367023\n",
      "-0.9502000503412786\n",
      "-0.7988782729475716\n",
      "-0.8867789883645176\n",
      "-0.8257919136734262\n",
      "-0.785892736106002\n",
      "-0.7708840200455986\n",
      "-0.794031361089203\n",
      "-0.8317171123214685\n",
      "-0.8725452975743148\n",
      "-0.9030129415973459\n",
      "-0.8509670763621335\n",
      "-0.8389388580680158\n",
      "-0.8968766148075579\n",
      "-0.8134475864882457\n",
      "-0.8565792045304863\n",
      "-0.8294466849366258\n",
      "-0.9068164401161986\n",
      "-0.8501479302144306\n",
      "-0.9205948506538719\n",
      "-0.9104155307540233\n",
      "-0.9904017729472108\n",
      "-0.9828994402593754\n",
      "-1.0277320692680705\n",
      "-1.0426312516117873\n",
      "-0.983832402700232\n",
      "-1.0145240559220101\n",
      "-0.9462864026117225\n",
      "-1.0219201019984991\n",
      "-0.9038670872688086\n",
      "-0.8686051585887369\n",
      "-0.8434097130349199\n",
      "-0.8833216354486404\n",
      "-0.8227504519230472\n",
      "-0.8875427623745379\n",
      "-0.85051586788303\n",
      "-0.8906913665542872\n",
      "-0.756723727045617\n",
      "-0.9297791495966186\n",
      "-0.834473002217585\n",
      "-0.9243527646148905\n",
      "-0.8779099248929492\n",
      "-0.8493473519189213\n",
      "-0.9562556225059791\n",
      "-0.8968284000525377\n",
      "-0.8999916301102591\n",
      "-0.9145429552125484\n",
      "-0.8746477569768636\n",
      "-0.9338084430797502\n",
      "-0.9211179188683514\n",
      "-1.08862358626049\n",
      "-1.0245108501628204\n",
      "-1.0126512051503866\n",
      "-0.9637070594625005\n",
      "-1.0017959738424826\n",
      "-0.8883781343903049\n",
      "-0.9598717516463017\n",
      "-0.9481456467812188\n",
      "-0.9201246667617616\n",
      "-0.964683987222518\n",
      "-0.9718054190273264\n",
      "-0.9569188051041397\n",
      "-0.9818217354333867\n",
      "-0.890027277763317\n",
      "-0.9549516875694647\n",
      "-0.8771786782196173\n",
      "-0.9560360042606247\n",
      "-0.8760043402750786\n",
      "-0.9309927221459574\n",
      "-0.9937033209148367\n",
      "-0.8789352878028627\n",
      "-0.9801171856528527\n",
      "-0.97909455893413\n",
      "-1.003516973874388\n",
      "-0.9631629438572141\n",
      "-1.0359539162961977\n",
      "-0.9053944996116385\n",
      "-0.9001203715477175\n",
      "-0.904288313553072\n",
      "-0.9845738993607565\n",
      "-0.9646144958928745\n",
      "-0.9529765802069415\n",
      "-0.881505313546431\n",
      "-0.9384121452176217\n",
      "-1.0020039509145968\n",
      "-1.002194615119582\n",
      "-1.0197983871415317\n",
      "-1.0594777284362125\n",
      "-1.0464114815207926\n",
      "-0.9218700594357738\n",
      "-0.9866323598702973\n",
      "-0.8454519335591436\n",
      "-0.953529542854268\n",
      "-0.9977366332754297\n",
      "-1.0564055889195174\n",
      "-1.0446301763614994\n",
      "-1.0496288925340733\n",
      "-1.0293601356403947\n",
      "-0.9388304017130885\n",
      "-1.114355961946843\n",
      "-1.0548375586100545\n",
      "-1.0442899586390573\n",
      "-1.00125987587885\n",
      "-0.9275940910144445\n",
      "-0.8636514638486457\n",
      "-0.8356046436821382\n",
      "-0.9163151693408768\n",
      "-0.9335651041512892\n",
      "-0.9964177727596432\n",
      "-0.8365989349104842\n",
      "-0.9291005630917696\n",
      "-0.9549489678666637\n",
      "-0.8889608198140053\n",
      "-0.936319709091839\n",
      "-0.7673407461966638\n",
      "-0.8626058582501492\n",
      "-0.8408689308235614\n",
      "-0.9576832846783151\n",
      "-0.9542885044858467\n",
      "-0.9231354661363973\n",
      "-1.035023046431687\n",
      "-1.0361844165100749\n",
      "-0.946597921441011\n",
      "-0.9677764476237085\n",
      "-1.00511529505253\n",
      "-0.9041769474894435\n",
      "-1.0361897661541215\n",
      "-1.0008692581031193\n",
      "-0.9638390999053843\n",
      "-0.8851249692964963\n",
      "-0.9754443272398948\n",
      "-0.8755004156007155\n",
      "-0.9048832708945118\n",
      "-0.8312981285065038\n",
      "-0.9184107257770304\n",
      "-0.9228723037085864\n",
      "-0.8195158830034144\n",
      "-0.934784775351222\n",
      "-0.9804028981524935\n",
      "-0.8845466572912482\n",
      "-0.8735772497641194\n",
      "-0.9358488598547662\n",
      "-0.8764456812616328\n",
      "-1.0464320474822286\n",
      "-1.0338723211520473\n",
      "-1.0873649631809144\n",
      "-0.9600912270275404\n",
      "-0.9926004652962958\n",
      "-0.8374494387001623\n",
      "-0.8338456464975569\n",
      "-0.8587758705690177\n",
      "-0.9664789092903423\n",
      "-0.9711127296339415\n",
      "-0.9302866286949679\n",
      "-0.9183228640872947\n",
      "-0.9686329724428014\n",
      "-1.0692264133845553\n",
      "-1.0246041349597177\n",
      "-0.8993390112527244\n",
      "-0.8828646184539292\n",
      "-1.0070309942054276\n",
      "-0.9973964907944743\n",
      "-0.9737182038582859\n",
      "-0.9988729023800255\n",
      "-1.0045522801116111\n",
      "-0.9707490947549708\n",
      "-1.0016967382928375\n",
      "-0.931325771660157\n",
      "-0.8444833795490139\n",
      "-0.9240752992450566\n",
      "-0.8611791767713134\n",
      "-0.9960827907934755\n",
      "-0.9078449682056182\n",
      "-0.8261239977213696\n",
      "-0.8287713375698268\n",
      "-0.9351822531640893\n",
      "-0.8254826011920305\n",
      "-0.9006487326400408\n",
      "-0.9501107135177241\n",
      "-0.9048349574106617\n",
      "-0.8454041765484396\n",
      "-0.7351881453555804\n",
      "-0.8707348383712689\n",
      "-0.7868332950617896\n",
      "-0.9328058190124681\n",
      "-0.9148147734992258\n",
      "-0.8506486093776567\n",
      "-0.7930494722154864\n",
      "-0.7687987654757907\n",
      "-0.7928464595489664\n",
      "-0.7729700106827626\n",
      "-0.7033708624189958\n",
      "-0.8522155075859948\n",
      "-0.7112663423299275\n",
      "-0.740852025191355\n",
      "-0.7264785719103698\n",
      "-0.7620492883218416\n",
      "-0.8400953869844415\n",
      "-0.9054294077279758\n",
      "-0.871367138264963\n",
      "-0.8955974123644337\n",
      "-0.915007533331375\n",
      "-0.795589557879831\n",
      "-0.7691093892673982\n",
      "-0.8653210837169886\n",
      "-0.832791209738117\n",
      "-0.8886344302549952\n",
      "-0.7924576516210132\n",
      "-0.857823118125165\n",
      "-0.8284779023530391\n",
      "-0.7363912367969352\n",
      "-0.7987657181653405\n",
      "-0.8615504199869216\n",
      "-0.880286474861126\n",
      "-0.8010897004264075\n",
      "-0.8495498576078794\n",
      "-0.7809975815588295\n",
      "-0.8413072731532818\n",
      "-0.8103295514954528\n",
      "-0.8489191509004442\n",
      "-0.8606589580744077\n",
      "-0.8897515274418814\n",
      "-0.8725503013546729\n",
      "-0.8669913104654722\n",
      "-0.9218183670161767\n",
      "-0.8286253395168612\n",
      "-0.8872535836303218\n",
      "-0.9039644850621281\n",
      "-0.7901551642456821\n",
      "-0.9386445569015246\n",
      "-0.8208285128386075\n",
      "-0.8386842597827725\n",
      "-0.8138674204818026\n",
      "-0.8778279963367432\n",
      "-0.9069971894110705\n",
      "-0.8386425552807519\n",
      "-0.7534370638523468\n",
      "-0.8150283306890677\n",
      "-0.7353424409938156\n",
      "-0.8482086642316947\n",
      "-0.8156330681012243\n",
      "-0.8107804192809722\n",
      "-0.8168573425120158\n",
      "-0.813279982594909\n",
      "-0.7784651106509639\n",
      "-0.6058646664437054\n",
      "-0.705965642464017\n",
      "-0.7352105944426888\n",
      "-0.7474842319462641\n",
      "-0.913073482380927\n",
      "-0.8045506443576448\n",
      "-0.7503293631190919\n",
      "-0.797872194392355\n",
      "-0.8366873337133087\n",
      "-0.7578977639156318\n",
      "-0.7836196512561862\n",
      "-0.9191612350266172\n",
      "-0.7594950414964811\n",
      "-0.7414533287931327\n",
      "-0.8530001275644029\n",
      "-0.7809541746775037\n",
      "-0.8690895630657445\n",
      "-0.795379411567996\n",
      "-0.878775209556158\n",
      "-0.8539740079335617\n",
      "-0.8131247577298407\n",
      "-0.7525441150894236\n",
      "-0.808870356037332\n",
      "-0.7513745863591678\n",
      "-0.7706847911408347\n",
      "-0.864198688568136\n",
      "-0.8139366182162422\n",
      "-0.7194073091833112\n",
      "-0.7952744922149986\n",
      "-0.8148355911297267\n",
      "-0.7159970069174354\n",
      "-0.7578871073480984\n",
      "-0.6707195093297111\n",
      "-0.7285064829804854\n",
      "-0.803962603098815\n",
      "-0.9702630633539623\n",
      "-0.866458475723741\n",
      "-0.9125426338821394\n",
      "-0.9302958668036087\n",
      "-0.8296184318389593\n",
      "-0.8355722333498521\n",
      "-0.8737039102567031\n",
      "-0.9136786877079004\n",
      "-0.8401395575508285\n",
      "-0.846348084221607\n",
      "-0.8202205755935048\n",
      "-0.7998634737312994\n",
      "-0.7070888346274685\n",
      "-0.8038307033141062\n",
      "-0.8055897368340341\n",
      "-0.7106722141587749\n",
      "-0.7153372325532911\n",
      "-0.6837039507465917\n",
      "-0.7651147308213231\n",
      "-0.7954076864727224\n",
      "-0.7371964065352389\n",
      "-0.7785463317560838\n",
      "-0.7971785821788796\n",
      "-0.7781943819197414\n",
      "-0.7810040363368431\n",
      "-0.749195742273048\n",
      "-0.8871607696342898\n",
      "-0.7799344482826893\n",
      "-0.8043904646486816\n",
      "-0.8024174228746379\n",
      "-0.7910676742353581\n",
      "-0.7704545516508222\n",
      "-0.7748408356306279\n",
      "-0.8317641497298374\n",
      "-0.8580568041430371\n",
      "-0.8136092746252461\n",
      "-0.7865709346525838\n",
      "-0.9072536251398935\n",
      "-0.7707235484360075\n",
      "-0.6961771680071506\n",
      "-0.8717584371783467\n",
      "-0.7996657952791845\n",
      "-0.7467975476337605\n",
      "-0.902992052508167\n",
      "-0.8027728778605403\n",
      "-0.7614794361277991\n",
      "-0.8389313000604756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.730415142134277\n",
      "-0.6929752031588726\n",
      "-0.8254845106108392\n",
      "-0.7512523218160807\n",
      "-0.5582972003957152\n",
      "-0.7247202400867371\n",
      "-0.8238945669786903\n",
      "-0.7632396875143719\n",
      "-0.6366399991473615\n",
      "-0.5546742986105817\n",
      "-0.6569531235668208\n",
      "-0.7918115407623807\n",
      "-0.6855952108034766\n",
      "-0.6752126130584128\n",
      "-0.6836908416812821\n",
      "-0.7666505905415881\n",
      "-0.7400169452241695\n",
      "-0.7031886755161263\n",
      "-0.7832101010005263\n",
      "-0.8032731882696053\n",
      "-0.8109288147156869\n",
      "-0.8368575503849498\n",
      "-0.7984472109513271\n",
      "-0.8418035644664362\n",
      "-0.8378589391856636\n",
      "-0.7716209735473389\n",
      "-0.790020535075055\n",
      "-0.713664403761465\n",
      "-0.7292840847289491\n",
      "-0.8449810725728257\n",
      "-0.7848728508942955\n",
      "-0.8019711328629052\n",
      "-0.7826227231862872\n",
      "-0.7843460806817033\n",
      "-0.7232503813682917\n",
      "-0.7600171095228176\n",
      "-0.7038789252404574\n",
      "-0.6235554138003834\n",
      "-0.7534886385089815\n",
      "-0.7447447402337879\n",
      "-0.7758881098395348\n",
      "-0.7491222676932573\n",
      "-0.7867250718928165\n",
      "-0.7960770532640022\n",
      "-0.7443187568279255\n",
      "-0.848548552872274\n",
      "-0.7797408277078982\n",
      "-0.7498215307612361\n",
      "-0.7735050028209451\n",
      "-0.8887625524763596\n",
      "-0.784002421798625\n",
      "-0.6518200923841749\n",
      "-0.6621014281424743\n",
      "-0.6610272043039301\n",
      "-0.6442467810480146\n",
      "-0.6069654177214532\n",
      "-0.6380906527137045\n",
      "-0.559656044643379\n",
      "-0.6393879192833594\n",
      "-0.6317949082501921\n",
      "-0.6322437111357665\n",
      "-0.5215951751928605\n",
      "-0.6226465579522272\n",
      "-0.7087274071670888\n",
      "-0.6819055095749549\n",
      "-0.6219516902282544\n",
      "-0.6179729227104342\n",
      "-0.6679509698609942\n",
      "-0.6855651579932109\n",
      "-0.7388890532993643\n",
      "-0.787631634004065\n",
      "-0.7224090100465694\n",
      "-0.6405530982314908\n",
      "-0.6605988607965941\n",
      "-0.6836297899676964\n",
      "-0.6497206496080782\n",
      "-0.637217414120546\n",
      "-0.7116077713462071\n",
      "-0.5833759620345302\n",
      "-0.6470851970664951\n",
      "-0.6358641416266638\n",
      "-0.578443406567283\n",
      "-0.683173335907163\n",
      "-0.7260305443159303\n",
      "-0.651112996890032\n",
      "-0.6760223818305432\n",
      "-0.6791418283978242\n",
      "-0.62759404320449\n",
      "-0.6448613518623373\n",
      "-0.6332070932383786\n",
      "-0.6087245293786974\n",
      "-0.5401540476951965\n",
      "-0.6389626790147577\n",
      "-0.6265989689884695\n",
      "-0.5776549062734952\n",
      "-0.6927163454978265\n",
      "-0.6125756689821265\n",
      "-0.7414399357371898\n",
      "-0.6005138162015237\n",
      "-0.5671250911018958\n",
      "-0.6390706646986767\n",
      "-0.660557566794449\n",
      "-0.7036109042902103\n",
      "-0.6845329065237782\n",
      "-0.6044809940962284\n",
      "-0.552100065148318\n",
      "-0.5669689319933406\n",
      "-0.5927270051492834\n",
      "-0.6675535497810466\n",
      "-0.675080402019987\n",
      "-0.6933032203268258\n",
      "-0.6728602333128173\n",
      "-0.5817915602918171\n",
      "-0.6275107775113664\n",
      "-0.5788032734910042\n",
      "-0.6049516282250267\n",
      "-0.7053952131532406\n",
      "-0.6831399249036714\n",
      "-0.6185859675251688\n",
      "-0.6717529006839327\n",
      "-0.6917245736272145\n",
      "-0.601184596841187\n",
      "-0.6824549750500232\n",
      "-0.6128742822895135\n",
      "-0.6388051979099169\n",
      "-0.5987077263042933\n",
      "-0.6054900333750759\n",
      "-0.5635706666512368\n",
      "-0.6169939879444861\n",
      "-0.5537097287180639\n",
      "-0.5938516646110471\n",
      "-0.6286400641102983\n",
      "-0.5598266051151327\n",
      "-0.5781951825991377\n",
      "-0.6155972409460293\n",
      "-0.6543269295691698\n",
      "-0.6686742297784154\n",
      "-0.7001216741489857\n",
      "-0.6073518287165968\n",
      "-0.5805246738688892\n",
      "-0.6546764828536957\n",
      "-0.6796718507629953\n",
      "-0.6681281366873363\n",
      "-0.6969939294057439\n",
      "-0.6665791562270699\n",
      "-0.641830205704646\n",
      "-0.6643068412239481\n",
      "-0.661848068816895\n",
      "-0.7069915735235295\n",
      "-0.6212586218944876\n",
      "-0.7072983084553036\n",
      "-0.5472580138820137\n",
      "-0.5501529544147065\n",
      "-0.5975435841559857\n",
      "-0.5561642649800963\n",
      "-0.5558551270682118\n",
      "-0.5876694081665126\n",
      "-0.5224661698043366\n",
      "-0.5413416011694256\n",
      "-0.6638421842583566\n",
      "-0.5093595172312222\n",
      "-0.6080518793323783\n",
      "-0.5831921032855338\n",
      "-0.4680655599787593\n",
      "-0.4938417401832205\n",
      "-0.523498586672733\n",
      "-0.4514269779433372\n",
      "-0.546556459565619\n",
      "-0.5469969543435357\n",
      "-0.6019486391242107\n",
      "-0.5423795881811981\n",
      "-0.6400177060022556\n",
      "-0.679102621927145\n",
      "-0.5735541665615616\n",
      "-0.47107085346396227\n",
      "-0.5852386565439983\n",
      "-0.5738625138816825\n",
      "-0.5415936432724408\n",
      "-0.5324415663613133\n",
      "-0.5708532945096771\n",
      "-0.566596051733285\n",
      "-0.596194068500858\n",
      "-0.5013825132387147\n",
      "-0.6059750762956615\n",
      "-0.5722209874533256\n",
      "-0.5916783913982999\n",
      "-0.5109162380112632\n",
      "-0.4709450611423186\n",
      "-0.5410050684782799\n",
      "-0.587598540946198\n",
      "-0.5676280788359387\n",
      "-0.5117492765900805\n",
      "-0.5188094956320961\n",
      "-0.4978272496880437\n",
      "-0.5686459483303197\n",
      "-0.645389186453668\n",
      "-0.5950113319249982\n",
      "-0.6645590875208556\n",
      "-0.5543038559708662\n",
      "-0.5433296161523207\n",
      "-0.6853175777715005\n",
      "-0.69161412137771\n",
      "-0.6075224547846019\n",
      "-0.6287149896810846\n",
      "-0.4650024221670702\n",
      "-0.5143735294257668\n",
      "-0.5210706803441533\n",
      "-0.636834633476068\n",
      "-0.6427047143526544\n",
      "-0.6276249830216276\n",
      "-0.5252778675378942\n",
      "-0.5722191669597672\n",
      "-0.5526210360630851\n",
      "-0.5056308786221968\n",
      "-0.5601894096218183\n",
      "-0.753652013341585\n",
      "-0.5109252800890803\n",
      "-0.6486785069341748\n",
      "-0.5036994988515178\n",
      "-0.5235635800605116\n",
      "-0.6454117094470417\n",
      "-0.5883482644741583\n",
      "-0.5793336852983623\n",
      "-0.601042745718142\n",
      "-0.6353188833936321\n",
      "-0.6148392409276319\n",
      "-0.49988961857453335\n",
      "-0.5447036091649357\n",
      "-0.5631744541401085\n",
      "-0.6822927976902752\n",
      "-0.637344182190393\n",
      "-0.6768038891709112\n",
      "-0.7109940977392328\n",
      "-0.5671391239478878\n",
      "-0.6166929389054494\n",
      "-0.6315948750090793\n",
      "-0.7175086738601032\n",
      "-0.5585965935415068\n",
      "-0.6081833054925261\n",
      "-0.6154347490813014\n",
      "-0.6946568756882407\n",
      "-0.636437684752031\n",
      "-0.6387275917126637\n",
      "-0.7110705525086068\n",
      "-0.6682417948679584\n",
      "-0.6600176903368025\n",
      "-0.5450512000161314\n",
      "-0.6934756434598737\n",
      "-0.5993127777936096\n",
      "-0.5973361283071654\n",
      "-0.5859002699077159\n",
      "-0.6819699450650902\n",
      "-0.5951525371303585\n",
      "-0.6201228902306342\n",
      "-0.5506318752591213\n",
      "-0.4924217053453618\n",
      "-0.6864396004523875\n",
      "-0.5003461488993469\n",
      "-0.6181892653522172\n",
      "-0.61264854013791\n",
      "-0.618541407136987\n",
      "-0.6083175695061229\n",
      "-0.5849408677887886\n",
      "-0.5981148510612181\n",
      "-0.661735380160666\n",
      "-0.6228780822311282\n",
      "-0.62777496135678\n",
      "-0.6959040145326865\n",
      "-0.6361621262605375\n",
      "-0.6968466671077479\n",
      "-0.7144616402416243\n",
      "-0.7155649381473183\n",
      "-0.7351301436128345\n",
      "-0.6390712146157395\n",
      "-0.6143408689401889\n",
      "-0.6611652446620112\n",
      "-0.606785958953169\n",
      "-0.5601743282471975\n",
      "-0.7000704643900293\n",
      "-0.6764406430773876\n",
      "-0.7062770316608888\n",
      "-0.6193117435596381\n",
      "-0.6913586090420468\n",
      "-0.7387446085353478\n",
      "-0.6962819931770294\n",
      "-0.7356299107549015\n",
      "-0.6442137723096585\n",
      "-0.7026380254190445\n",
      "-0.607757513878845\n",
      "-0.5371039363182943\n",
      "-0.5437029922966172\n",
      "-0.5453488450113674\n",
      "-0.7867220928360766\n",
      "-0.6749891233407901\n",
      "-0.6956643141834152\n",
      "-0.6489775707000245\n",
      "-0.6551145193299139\n",
      "-0.5895283640614399\n",
      "-0.7009349622628828\n",
      "-0.6841324578787287\n",
      "-0.6311980707544509\n",
      "-0.6605119749512007\n",
      "-0.7040253261251908\n",
      "-0.6687952918505107\n",
      "-0.5823762284491847\n",
      "-0.7030835241077865\n",
      "-0.5857099958156943\n",
      "-0.6880269616065458\n",
      "-0.659939341901774\n",
      "-0.7014262152786359\n",
      "-0.5658663986641613\n",
      "-0.6738381698692872\n",
      "-0.6138664809669113\n",
      "-0.5996933351072551\n",
      "-0.6103128112574117\n",
      "-0.663661286185393\n",
      "-0.5950342402123442\n",
      "-0.6692721667415256\n",
      "-0.6711241337242256\n",
      "-0.5875523896061923\n",
      "-0.7061537641970332\n",
      "-0.6494850705362841\n",
      "-0.6652715871106216\n",
      "-0.6663364029674715\n",
      "-0.6649124202639951\n",
      "-0.7189318748130598\n",
      "-0.7519190419957951\n",
      "-0.6513961453655369\n",
      "-0.5795045377266146\n",
      "-0.6626780925272066\n",
      "-0.6576485765715763\n",
      "-0.8188817153823514\n",
      "-0.5938391766923165\n",
      "-0.6736363681075515\n",
      "-0.7303804973846758\n",
      "-0.6272538940071279\n",
      "-0.7242882385674172\n",
      "-0.6339235972176984\n",
      "-0.7568563915433578\n",
      "-0.7028758757632062\n",
      "-0.5721902139816473\n",
      "-0.7282928173506674\n",
      "-0.47772711848336075\n",
      "-0.571653568439961\n",
      "-0.5474232031250463\n",
      "-0.5944040732779139\n",
      "-0.6573401725866471\n",
      "-0.5927673945917219\n",
      "-0.7510655103633448\n",
      "-0.6977164743666805\n",
      "-0.6801809379238345\n",
      "-0.7234952085272435\n",
      "-0.6766085467573755\n",
      "-0.8112312409732242\n",
      "-0.7275330849261155\n",
      "-0.6663714234964397\n",
      "-0.6554412975288622\n",
      "-0.6592396339148431\n",
      "-0.7508730773955093\n",
      "-0.6540562607321381\n",
      "-0.6260908240495833\n",
      "-0.5899570797771433\n",
      "-0.7559139836114037\n",
      "-0.7690290180469669\n",
      "-0.6318332930059416\n",
      "-0.7139982919955223\n",
      "-0.6953994657318878\n",
      "-0.7752062059888958\n",
      "-0.6475355310886022\n",
      "-0.6753229131134397\n",
      "-0.7401120650383324\n",
      "-0.6455706078693414\n",
      "-0.5732747421638372\n",
      "-0.6225785080513505\n",
      "-0.6870222500719726\n",
      "-0.6321048876702804\n",
      "-0.5992710820869224\n",
      "-0.5790097072051934\n",
      "-0.6215568272007485\n",
      "-0.652971014042674\n",
      "-0.728221208562509\n",
      "-0.7419532404739099\n",
      "-0.6890074604421781\n",
      "-0.7086438495801156\n",
      "-0.7417804419131621\n",
      "-0.6630085661485928\n",
      "-0.6178838972901278\n",
      "-0.7130085341329889\n",
      "-0.6441491167715743\n",
      "-0.5366119697595194\n",
      "-0.6289575667670747\n",
      "-0.6495130159430997\n",
      "-0.6307456296660358\n",
      "-0.6571103392018696\n",
      "-0.5717343955690275\n",
      "-0.6509379191022152\n",
      "-0.7715359590093553\n",
      "-0.6759604396420253\n",
      "-0.6951812699241597\n",
      "-0.6748747110011435\n",
      "-0.6940556720179978\n",
      "-0.6909832770741999\n",
      "-0.7238236746083692\n",
      "-0.7710705945142707\n",
      "-0.7596306195106434\n",
      "-0.7017541393676194\n",
      "-0.5133896224320171\n",
      "-0.6626933066914927\n",
      "-0.6242920585767041\n",
      "-0.6486709718102175\n",
      "-0.6824311759662957\n",
      "-0.7260892664029108\n",
      "-0.6898531205369653\n",
      "-0.7634607885857155\n",
      "-0.6593089025954287\n",
      "-0.6895020545056524\n",
      "-0.6218982967252056\n",
      "-0.6503530223536252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7085218311771051\n",
      "-0.6821949976536862\n",
      "-0.769360661032513\n",
      "-0.7896096092919139\n",
      "-0.7786992903044405\n",
      "-0.7522052436989337\n",
      "-0.7753091334784055\n",
      "-0.7527386858800013\n",
      "-0.7015110625182467\n",
      "-0.6590239017766314\n",
      "-0.6681032880127481\n",
      "-0.7005155340401342\n",
      "-0.7935841778936106\n",
      "-0.7956278447023147\n",
      "-0.730858070045187\n",
      "-0.6695353127049961\n",
      "-0.6835554193439288\n",
      "-0.7133265564170409\n",
      "-0.7949841806974376\n",
      "-0.7738210066927472\n",
      "-0.7370964750396193\n",
      "-0.7151651290926158\n",
      "-0.7035216066899025\n",
      "-0.812912661623986\n",
      "-0.7409043054066007\n",
      "-0.7571100128225793\n",
      "-0.7266328150306339\n",
      "-0.6121169938858751\n",
      "-0.7547543439441704\n",
      "-0.7861525595970582\n",
      "-0.8099325313002739\n",
      "-0.777406781384992\n",
      "-0.854744212592756\n",
      "-0.8543238268713522\n",
      "-0.6876678288867348\n",
      "-0.6614375538137848\n",
      "-0.7120770785615352\n",
      "-0.6612406330099037\n",
      "-0.7477955390913973\n",
      "-0.6893194378915093\n",
      "-0.6577332585524812\n",
      "-0.7441710347918364\n",
      "-0.7089697815966429\n",
      "-0.7405234122608726\n",
      "-0.6998101750680572\n",
      "-0.6889375446426\n",
      "-0.7273740904807199\n",
      "-0.696390690214501\n",
      "-0.7510645390280359\n",
      "-0.7299218664198194\n",
      "-0.7355439195992133\n",
      "-0.6923917452330437\n",
      "-0.7157461373477799\n",
      "-0.7823534096016771\n",
      "-0.8174664114891881\n",
      "-0.8754246351919178\n",
      "-0.684457980241269\n",
      "-0.7593726027530614\n",
      "-0.8026489932444776\n",
      "-0.7357766927446769\n",
      "-0.7766990105943723\n",
      "-0.8585078391848636\n",
      "-0.8322168605788504\n",
      "-0.7261858960931806\n",
      "-0.8307705283606202\n",
      "-0.6885001213279547\n",
      "-0.7538496046902567\n",
      "-0.81771016690766\n",
      "-0.8158697180209247\n",
      "-0.8419147044520428\n",
      "-0.7759758363245701\n",
      "-0.8552279729627024\n",
      "-0.8056928138375908\n",
      "-0.8549537342372647\n",
      "-0.9887076806992073\n",
      "-0.8257759686008396\n",
      "-0.7326832275578924\n",
      "-0.7520100283752431\n",
      "-0.7500093120596009\n",
      "-0.7508069626386846\n",
      "-0.8309015388975962\n",
      "-0.8448444610971162\n",
      "-0.8415225607526036\n",
      "-0.8745821920060274\n",
      "-0.8510872593619401\n",
      "-0.76146002572584\n",
      "-0.9218464223349009\n",
      "-0.8414897537807927\n",
      "-0.9182220590939347\n",
      "-0.8668963483454938\n",
      "-0.865637889930545\n",
      "-0.9174493012584997\n",
      "-0.8399105405702586\n",
      "-0.7558913340463429\n",
      "-0.7669118217067148\n",
      "-0.9150752704872557\n",
      "-0.9002509264174235\n",
      "-1.0089919795813715\n",
      "-0.8941176840592252\n",
      "-0.8363443835586262\n",
      "-0.8240614827757264\n",
      "-0.7079851312990829\n",
      "-0.7724155375544963\n",
      "-0.7520811912309625\n",
      "-0.8040711691168173\n",
      "-0.7327560170701355\n",
      "-0.809921576873193\n",
      "-0.8767247441949008\n",
      "-0.865367457636669\n",
      "-0.8868448184971308\n",
      "-0.8915656371989017\n",
      "-0.8967533068896754\n",
      "-0.8373833929068599\n",
      "-0.8472573809838002\n",
      "-0.8898431692783766\n",
      "-0.9358309287795263\n",
      "-0.851769883085469\n",
      "-0.954552089111381\n",
      "-0.9671497085527595\n",
      "-0.83615987174932\n",
      "-0.9055114648791959\n",
      "-0.7060248921174097\n",
      "-0.8041499162545697\n",
      "-0.7529686689561622\n",
      "-0.8466448149407323\n",
      "-0.9662850486870561\n",
      "-0.9982775332148014\n",
      "-1.005380092101322\n",
      "-0.9236458366163962\n",
      "-0.8461003768789457\n",
      "-0.8872469025311618\n",
      "-0.8502581316072431\n",
      "-0.8579702986953774\n",
      "-0.8817299567680295\n",
      "-0.9289623651080717\n",
      "-0.8888698125561925\n",
      "-0.8967070580914811\n",
      "-0.8638933070375953\n",
      "-0.881126064860285\n",
      "-0.9374229495017266\n",
      "-0.9234846877776441\n",
      "-0.9495195619252188\n",
      "-0.8854108200742943\n",
      "-0.9623802388792714\n",
      "-0.8094110255196918\n",
      "-0.8682017090724926\n",
      "-0.8751440777030911\n",
      "-0.8322879926700338\n",
      "-0.9314323905800101\n",
      "-0.939957329933393\n",
      "-0.9497978586127778\n",
      "-0.8815083511572284\n",
      "-0.9228409867824091\n",
      "-0.9645526307186733\n",
      "-0.8775057011428782\n",
      "-0.8235364648474826\n",
      "-0.7933532875801632\n",
      "-0.8318918746481188\n",
      "-0.8515084046390011\n",
      "-0.848213554298808\n",
      "-0.8371648549941725\n",
      "-0.9214241271687631\n",
      "-0.9660305131809022\n",
      "-0.9588778596062606\n",
      "-0.8295762969673914\n",
      "-0.8926429261042005\n",
      "-0.8387649032174601\n",
      "-0.8250999758587542\n",
      "-0.9739537441114062\n",
      "-0.8764044017783251\n",
      "-0.9463830424086491\n",
      "-0.8746781833256448\n",
      "-0.793400116984216\n",
      "-0.968395957903358\n",
      "-0.8735316280323172\n",
      "-1.0134536062285948\n",
      "-0.912352924635853\n",
      "-1.039247093304814\n",
      "-0.9207860104676975\n",
      "-0.9460872461300736\n",
      "-0.8644578653982441\n",
      "-0.9153769462184231\n",
      "-0.9165293916140481\n",
      "-0.9023523269440431\n",
      "-0.7712799442402268\n",
      "-0.9277175900227969\n",
      "-0.8206305496751595\n",
      "-0.843169177381237\n",
      "-0.8274831386697942\n",
      "-0.8838968611608115\n",
      "-0.9183639815945406\n",
      "-0.9627067671863122\n",
      "-0.8519663567231331\n",
      "-0.8725193023089024\n",
      "-0.9288528354674893\n",
      "-0.7721979932949905\n",
      "-0.8768469044800891\n",
      "-0.9862252150871751\n",
      "-0.9318458449105121\n",
      "-0.8471995101935724\n",
      "-0.9067715640388397\n",
      "-0.8697217315512609\n",
      "-0.8450853858514055\n",
      "-0.8697477654041267\n",
      "-0.8966319983194097\n",
      "-0.867767979994211\n",
      "-0.8618197845783584\n",
      "-0.873659101347383\n",
      "-0.8984510314606411\n",
      "-0.9204342432037\n",
      "-0.9514537446755904\n",
      "-1.0007965482206016\n",
      "-0.9346010057969134\n",
      "-0.9874604957693748\n",
      "-0.978712988495264\n",
      "-0.9517759039529767\n",
      "-0.9097120472503686\n",
      "-0.8915526819307358\n",
      "-0.8884398866463715\n",
      "-0.9003204767187549\n",
      "-0.9634319468782767\n",
      "-0.8966534130229575\n",
      "-0.9079404925724291\n",
      "-0.9030128760813073\n",
      "-0.9673434786595639\n",
      "-0.9400022101721832\n",
      "-1.004740860633407\n",
      "-1.0717823641393733\n",
      "-0.8719140527436154\n",
      "-0.9500157001534338\n",
      "-0.8984219696041431\n",
      "-1.0067994272425673\n",
      "-1.056141235984896\n",
      "-1.0439463517381784\n",
      "-0.9530841953917146\n",
      "-0.9154025884382105\n",
      "-0.878376248292656\n",
      "-0.8509760682071993\n",
      "-0.8435328632608541\n",
      "-0.9134318281770893\n",
      "-0.9507375978267041\n",
      "-0.8335128001932177\n",
      "-0.9676840374978936\n",
      "-0.8235204881439545\n",
      "-0.9001875390554014\n",
      "-0.8683279782971036\n",
      "-0.8943264317865726\n",
      "-0.8683585528888151\n",
      "-0.8155229641851436\n",
      "-0.8830741451106141\n",
      "-0.8815979741181307\n",
      "-0.7963127781326771\n",
      "-0.8184726934089589\n",
      "-0.8307919189347275\n",
      "-0.9302690718726281\n",
      "-0.9220591552134076\n",
      "-0.9245539853987816\n",
      "-0.8702090634944568\n",
      "-0.8360320703994999\n",
      "-0.8180338167775522\n",
      "-0.9291018378771279\n",
      "-0.8320722985136623\n",
      "-0.9689582919704767\n",
      "-0.8757843807935136\n",
      "-0.8955593144064573\n",
      "-0.9322667742819504\n",
      "-0.9845115888647822\n",
      "-0.9281398442858666\n",
      "-0.8728446149386424\n",
      "-0.87356511252311\n",
      "-0.9395132762630245\n",
      "-0.984393496715612\n",
      "-0.9231196713742279\n",
      "-1.1491024429930385\n",
      "-0.9731971968820599\n",
      "-0.8408535076591133\n",
      "-0.9199373848753061\n",
      "-0.94789664844331\n",
      "-1.0221140344237718\n",
      "-0.9774781419031546\n",
      "-0.9002854756181227\n",
      "-0.953484911067044\n",
      "-0.915080840620033\n",
      "-0.982891756565805\n",
      "-0.821941967372603\n",
      "-0.9638074990738609\n",
      "-0.9438664278437185\n",
      "-0.8513691029613606\n",
      "-0.9052654593802877\n",
      "-0.8412068066690844\n",
      "-0.9070349269071476\n",
      "-0.8651218484764508\n",
      "-0.9648654143063192\n",
      "-0.9375721521411468\n",
      "-0.9821291240770122\n",
      "-0.9110943039253134\n",
      "-0.9249181808643606\n",
      "-0.9292445279688749\n",
      "-0.8653365431608995\n",
      "-0.874062866049004\n",
      "-1.032978092389622\n",
      "-0.9456965498750518\n",
      "-0.9004227427315606\n",
      "-0.9376137628319647\n",
      "-0.9149655253852577\n",
      "-0.9352414492839454\n",
      "-1.070755667098128\n",
      "-0.9025670221901435\n",
      "-0.8947589738241375\n",
      "-0.9188361460035717\n",
      "-0.9637271932642067\n",
      "-0.9199337396904637\n",
      "-0.8778521086605567\n",
      "-0.8581554342318316\n",
      "-1.0107760001762587\n",
      "-0.965348694208547\n",
      "-0.9251862438817716\n",
      "-0.9680197370065711\n",
      "-0.8935278260876304\n",
      "-1.042606079298156\n",
      "-1.0415083834995376\n",
      "-0.9220778701374952\n",
      "-0.8544547449116532\n",
      "-0.9420353136171287\n",
      "-0.962895716590648\n",
      "-0.914757251561837\n",
      "-0.7804536360821905\n",
      "-0.8098879383936952\n",
      "-0.9248582365402256\n",
      "-1.0507532832221853\n",
      "-0.883021813380696\n",
      "-0.966025818040774\n",
      "-0.8492785437553272\n",
      "-0.8812220074894186\n",
      "-0.8989084428110399\n",
      "-0.8435848170539701\n",
      "-0.9211828411856132\n",
      "-0.9023943962221564\n",
      "-0.9829736080687512\n",
      "-0.8206821795543605\n",
      "-0.8750916051007895\n",
      "-0.9304121087427407\n",
      "-0.9601172137518356\n",
      "-0.8700580924260933\n",
      "-0.8934201410743259\n",
      "-1.0281601481174123\n",
      "-0.9783877983374092\n",
      "-0.8747948122512157\n",
      "-0.9699541317467472\n",
      "-1.1518511350960303\n",
      "-1.2439934859611785\n",
      "-1.3505111226072404\n",
      "-1.315742270551747\n",
      "-1.4167801885177238\n",
      "-1.4851497890496452\n",
      "-1.477258549127909\n",
      "-1.4783327059414393\n",
      "-1.501212977735984\n",
      "-1.501040772916809\n",
      "-1.5065440113674575\n",
      "-1.501515340181735\n",
      "-1.479186012066987\n",
      "-1.5340515786888953\n",
      "-1.457604977469724\n",
      "-1.4136752447778185\n",
      "-1.4339104621535852\n",
      "-1.3407518154877995\n",
      "-1.3587668912689541\n",
      "-1.5089431902728023\n",
      "-1.4847921729438023\n",
      "-1.4191213310908013\n",
      "-1.5550226055074186\n",
      "-1.5449605804206767\n",
      "-1.5640779001091665\n",
      "-1.5568251816033913\n",
      "-1.494420857473836\n",
      "-1.4798158304288944\n",
      "-1.5414394214878153\n",
      "-1.4745021474320326\n",
      "-1.4488032926732999\n",
      "-1.4057170410493363\n",
      "-1.4107219933429875\n",
      "-1.340627310241022\n",
      "-1.378722547279892\n",
      "-1.4160404282666155\n",
      "-1.4006022685734736\n",
      "-1.7454443025952948\n",
      "-2.4086793542721923\n",
      "-2.7239191808971825\n",
      "-2.667906406365622\n",
      "-2.594569631482986\n",
      "-2.484126366870097\n",
      "-2.415660260127717\n",
      "-2.3576159574775923\n",
      "-2.311666350852285\n",
      "-2.227390365822674\n",
      "-2.1137280138268313\n",
      "-2.0186925543852143\n",
      "-1.9211212246335503\n",
      "-1.8260130143468123\n",
      "-1.7604879258375106\n",
      "-1.6658400610878354\n",
      "-0.0055974801411461895\n",
      "-0.02133761122707951\n",
      "0.0017247444132773913\n",
      "0.00409388394683918\n",
      "0.042042144767135595\n",
      "-0.01771359214412677\n",
      "-0.016463051387938587\n",
      "-0.017312832315655828\n",
      "-0.05129022504579888\n",
      "0.011875135167911999\n",
      "-0.09763544918478512\n",
      "-0.05264720019860021\n",
      "0.007078595851352536\n",
      "0.0017556085128060046\n",
      "-0.04008098934856762\n",
      "-0.05850183417188526\n",
      "-0.04555124796489307\n",
      "-0.1615127419883277\n",
      "-0.21031824296604873\n",
      "-0.24060673957707382\n",
      "-0.18576227118674846\n",
      "-0.13051658047237244\n",
      "-0.04570065422254183\n",
      "-0.1376480848654874\n",
      "-0.20958124675552334\n",
      "-0.19543724406502608\n",
      "-0.11156665739696837\n",
      "-0.13539976506924672\n",
      "-0.20610037496253045\n",
      "-0.09517382511872788\n",
      "-0.08743958475839393\n",
      "-0.033147094593343085\n",
      "0.005043788787676062\n",
      "0.006776995826436924\n",
      "-0.1200803781094937\n",
      "-0.00600098553392836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.06429517853813874\n",
      "0.0213679274264604\n",
      "-0.08605237528405352\n",
      "-0.08190177432433149\n",
      "-0.09031347788187802\n",
      "-0.1722173198291017\n",
      "-0.1308330828801724\n",
      "-0.23021078965202138\n",
      "-0.17098521152024712\n",
      "-0.05500007562030593\n",
      "-0.02646452988332859\n",
      "-0.12230549549964502\n",
      "-0.11910870405980507\n",
      "-0.06856710368320498\n",
      "-0.04730593705349715\n",
      "-0.06601393594327634\n",
      "-0.11220839399560067\n",
      "-0.19884534229398818\n",
      "-0.10463589140827098\n",
      "-0.08373905685756747\n",
      "-0.18205928232188773\n",
      "-0.10667357659233306\n",
      "-0.12022070056294713\n",
      "-0.10002121319016488\n",
      "-0.1598004950165243\n",
      "-0.08748977691248441\n",
      "-0.10548555885235708\n",
      "-0.09101012157294855\n",
      "-0.15382771466041303\n",
      "-0.2607249465019137\n",
      "-0.26223439524840697\n",
      "-0.2417420381161018\n",
      "-0.14453496191643997\n",
      "-0.09582711676501204\n",
      "-0.17304340831537598\n",
      "-0.15378664540847412\n",
      "-0.07027665735118255\n",
      "-0.12578154523593724\n",
      "-0.2567877875739703\n",
      "-0.25226286926518404\n",
      "-0.17929992599801514\n",
      "-0.2920134859785348\n",
      "-0.17346257986767738\n",
      "-0.28670293698575267\n",
      "-0.21156074049634782\n",
      "-0.16188703181290423\n",
      "-0.20101347801562497\n",
      "-0.09726845531266112\n",
      "-0.10864998314782816\n",
      "-0.13509829848322724\n",
      "-0.23789334564859158\n",
      "-0.24393957221987722\n",
      "-0.1922087717811683\n",
      "-0.2974685820839306\n",
      "-0.19172667468644158\n",
      "-0.19535427151007984\n",
      "-0.23679522750594795\n",
      "-0.186541015994023\n",
      "-0.330751847853525\n",
      "-0.27488008923919116\n",
      "-0.2784945176861466\n",
      "-0.3298465260984219\n",
      "-0.34383939777307515\n",
      "-0.3186703242432973\n",
      "-0.3092158719685327\n",
      "-0.23577161788391474\n",
      "-0.24811387781883507\n",
      "-0.24940360643870998\n",
      "-0.24855978941453913\n",
      "-0.2709399502082118\n",
      "-0.3284527735188483\n",
      "-0.3820701204452152\n",
      "-0.39800953379628934\n",
      "-0.33176444265769056\n",
      "-0.30683770556169365\n",
      "-0.31884911553174117\n",
      "-0.21813773500730416\n",
      "-0.31015528456578906\n",
      "-0.46480253175014036\n",
      "-0.35623521595149865\n",
      "-0.2787134041912036\n",
      "-0.3859672167485355\n",
      "-0.3143682064380697\n",
      "-0.44893934161190024\n",
      "-0.3171336226908317\n",
      "-0.36031921057508287\n",
      "-0.344650588943779\n",
      "-0.3935651828139037\n",
      "-0.4805200577475303\n",
      "-0.449203243412774\n",
      "-0.3684994097637282\n",
      "-0.3822472650176046\n",
      "-0.399591874197097\n",
      "-0.4095754713401184\n",
      "-0.3461998304817677\n",
      "-0.4523532437491727\n",
      "-0.4795906050951393\n",
      "-0.4615440283237959\n",
      "-0.4866577483084502\n",
      "-0.3908076976362652\n",
      "-0.3900417506160107\n",
      "-0.40505599030219014\n",
      "-0.4155177778600356\n",
      "-0.4847396789457789\n",
      "-0.4827587420810174\n",
      "-0.45573552957026886\n",
      "-0.4721161859236625\n",
      "-0.5071599492316847\n",
      "-0.4270145860330741\n",
      "-0.5158144885602167\n",
      "-0.545210552686099\n",
      "-0.5149235937050322\n",
      "-0.5458320085217458\n",
      "-0.3965383463997438\n",
      "-0.4647547135139043\n",
      "-0.4535087893033061\n",
      "-0.5159485417870601\n",
      "-0.5942074648908924\n",
      "-0.5930466993789367\n",
      "-0.5990184894394467\n",
      "-0.5855009968946758\n",
      "-0.5683896469633936\n",
      "-0.577627063370073\n",
      "-0.5132288609989717\n",
      "-0.4472326571439216\n",
      "-0.5878911982859936\n",
      "-0.5354685179109853\n",
      "-0.4739716802187578\n",
      "-0.4735074052193338\n",
      "-0.48193606625999313\n",
      "-0.5565244806485952\n",
      "-0.49381491191039434\n",
      "-0.5116259152221283\n",
      "-0.5155820266019837\n",
      "-0.42124961354989027\n",
      "-0.48381155426573774\n",
      "-0.4577932185937279\n",
      "-0.5197669425393335\n",
      "-0.4941878357922546\n",
      "-0.4187079105696884\n",
      "-0.40808676405777133\n",
      "-0.4856290468786312\n",
      "-0.605891400567402\n",
      "-0.5021686910038957\n",
      "-0.4515816227002022\n",
      "-0.5422705683195137\n",
      "-0.4777381537197852\n",
      "-0.5225868647271416\n",
      "-0.5978268076918023\n",
      "-0.6107005542061735\n",
      "-0.6275658094931529\n",
      "-0.6137352643327598\n",
      "-0.6988973665204219\n",
      "-0.5919906283785519\n",
      "-0.5862746798028089\n",
      "-0.5485061681480113\n",
      "-0.5882062151849866\n",
      "-0.5396243252852582\n",
      "-0.5053154523267841\n",
      "-0.5142161735440439\n",
      "-0.5142552898583473\n",
      "-0.6994797614524051\n",
      "-0.677907886642344\n",
      "-0.6181926485903395\n",
      "-0.5507410823254262\n",
      "-0.7060281553905976\n",
      "-0.6080687055195932\n",
      "-0.6910339660902106\n",
      "-0.5481487959906989\n",
      "-0.5533809963540844\n",
      "-0.6229906949066659\n",
      "-0.5159196146381135\n",
      "-0.592955238751049\n",
      "-0.536166578953986\n",
      "-0.47077617478217265\n",
      "-0.4810077296393856\n",
      "-0.48460105743952564\n",
      "-0.5743054804739615\n",
      "-0.5325196325502992\n",
      "-0.5999641166429316\n",
      "-0.671603492122458\n",
      "-0.5788499728461383\n",
      "-0.5683821108915269\n",
      "-0.6241912702709075\n",
      "-0.6454286063015636\n",
      "-0.5636528987045766\n",
      "-0.5993855051995727\n",
      "-0.5821116410652596\n",
      "-0.6226610724904705\n",
      "-0.6383004041029938\n",
      "-0.6966843211135799\n",
      "-0.6412960208114756\n",
      "-0.6174824215888888\n",
      "-0.5956324678819247\n",
      "-0.6074833133218581\n",
      "-0.6052180608177815\n",
      "-0.5911758355892455\n",
      "-0.603316351600678\n",
      "-0.5617471241705773\n",
      "-0.5736315187376755\n",
      "-0.6439972670899116\n",
      "-0.653205928764642\n",
      "-0.784037965776025\n",
      "-0.6726716040295553\n",
      "-0.7004665174498362\n",
      "-0.7514677707293839\n",
      "-0.7710666252859919\n",
      "-0.5335541691106535\n",
      "-0.6418032621892608\n",
      "-0.68861347675004\n",
      "-0.6990040839020873\n",
      "-0.6960466045080287\n",
      "-0.6539981047570915\n",
      "-0.7506619675164312\n",
      "-0.737836250015089\n",
      "-0.749115021600071\n",
      "-0.7220122240088266\n",
      "-0.7859985719702883\n",
      "-0.7703657978670538\n",
      "-0.6438304879498393\n",
      "-0.6858133580090199\n",
      "-0.7130657021508804\n",
      "-0.6795311187440387\n",
      "-0.6184542523688195\n",
      "-0.7057394161397983\n",
      "-0.7071708421074857\n",
      "-0.7054621085804952\n",
      "-0.5807217201640605\n",
      "-0.7564464013429724\n",
      "-0.8248740610297404\n",
      "-0.6818883863877399\n",
      "-0.7006248342578262\n",
      "-0.8005981651409954\n",
      "-0.785932295933926\n",
      "-0.6629543679020484\n",
      "-0.731846768036187\n",
      "-0.678159022261062\n",
      "-0.7237522040814792\n",
      "-0.8425401965223276\n",
      "-0.7640701101665561\n",
      "-0.7531139027390921\n",
      "-0.6799362788541938\n",
      "-0.7592335692900247\n",
      "-0.6248126234527681\n",
      "-0.6713738981251463\n",
      "-0.6194353473128228\n",
      "-0.6213853420816688\n",
      "-0.7563412476198276\n",
      "-0.7460641086695587\n",
      "-0.6848376744010252\n",
      "-0.8490329317829692\n",
      "-0.6817336152866562\n",
      "-0.6827026161486485\n",
      "-0.7071523898735288\n",
      "-0.7461497181334499\n",
      "-0.8430182440746554\n",
      "-0.8361421028860916\n",
      "-0.8488934607482824\n",
      "-0.7874861042460359\n",
      "-0.7986881719760313\n",
      "-0.7509205459175726\n",
      "-0.8335406797824887\n",
      "-0.8428188390222576\n",
      "-0.8295472416194634\n",
      "-0.8505448399578337\n",
      "-0.786962713207536\n",
      "-0.815627181414238\n",
      "-0.703002371992942\n",
      "-0.7534311117418337\n",
      "-0.7621612981339919\n",
      "-0.795686413127217\n",
      "-0.7391014835951654\n",
      "-0.760043544827469\n",
      "-0.7636094005894912\n",
      "-0.8210163358855658\n",
      "-0.781318033330719\n",
      "-0.765230968053664\n",
      "-0.8685483860954152\n",
      "-0.7450641566638962\n",
      "-0.7903222604107955\n",
      "-0.7832473346587084\n",
      "-0.715405384668919\n",
      "-0.790454070176841\n",
      "-0.7052270228698146\n",
      "-0.7346812176895042\n",
      "-0.8030783012969581\n",
      "-0.7038274241565123\n",
      "-0.7549639158246514\n",
      "-0.7821116669582449\n",
      "-0.7192853493848705\n",
      "-0.6652139653941943\n",
      "-0.7359460686021546\n",
      "-0.7360145876242385\n",
      "-0.6243907379629297\n",
      "-0.7122509585535409\n",
      "-0.7998774517323711\n",
      "-0.7563383000974492\n",
      "-0.7916413611393104\n",
      "-0.8273043606949056\n",
      "-0.8753652611895073\n",
      "-0.7761491444685799\n",
      "-0.7306901992318623\n",
      "-0.7967201351807716\n",
      "-0.7938748728474212\n",
      "-0.6924238550545524\n",
      "-0.7487071448459148\n",
      "-0.7125505173263451\n",
      "-0.6448421405542898\n",
      "-0.7835191850542018\n",
      "-0.7216778565098123\n",
      "-0.7245865107198873\n",
      "-0.6920794948572292\n",
      "-0.8418013455710813\n",
      "-0.7538391163680682\n",
      "-0.7234286063079001\n",
      "-0.7459305190335724\n",
      "-0.719147647006381\n",
      "-0.8726986326958506\n",
      "-0.8747681106642885\n",
      "-0.8260396891470841\n",
      "-0.8281580881748327\n",
      "-0.8566497303910786\n",
      "-0.7836112842878279\n",
      "-0.825369756929621\n",
      "-0.854213642701332\n",
      "-0.8287877407562031\n",
      "-0.7274335998726168\n",
      "-0.6553844379620766\n",
      "-0.7933107504169369\n",
      "-0.8067562045422112\n",
      "-0.9208280539293026\n",
      "-0.7516544933509838\n",
      "-0.8111798495520894\n",
      "-0.8488822900640922\n",
      "-0.8039903109080766\n",
      "-0.8376113649514281\n",
      "-0.8593351054924985\n",
      "-0.7728005509147214\n",
      "-0.8169009327092448\n",
      "-0.6982688087015301\n",
      "-0.733949189837605\n",
      "-0.8247824253338591\n",
      "-0.8345508597683927\n",
      "-0.7567436990844489\n",
      "-0.7340836251475871\n",
      "-0.6202935027641096\n",
      "-0.6200146036456049\n",
      "-0.6888688268007447\n",
      "-0.6158072275166265\n",
      "-0.6860152946751956\n",
      "-0.7735037362933553\n",
      "-0.6928179719214127\n",
      "-0.7983174777463043\n",
      "-0.7517066749729987\n",
      "-0.6600105352521117\n",
      "-0.6822132051159547\n",
      "-0.6618782216656084\n",
      "-0.6382776662973051\n",
      "-0.6712707906724087\n",
      "-0.6335327032163233\n",
      "-0.7127819479251437\n",
      "-0.7370997305565716\n",
      "-0.8032804776943862\n",
      "-0.867360085467141\n",
      "-0.8447229506495558\n",
      "-0.8506662338599728\n",
      "-0.7671972526932964\n",
      "-0.7763310158355221\n",
      "-0.6961445417074634\n",
      "-0.716392320881264\n",
      "-0.6939071008358929\n",
      "-0.6919633321512779\n",
      "-0.7492620936928218\n",
      "-0.7476192956029785\n",
      "-0.7071098127716688\n",
      "-0.7578277295011908\n",
      "-0.6826536831801112\n",
      "-0.7249869203893908\n",
      "-0.749691002429857\n",
      "-0.7576844356365808\n",
      "-0.6811102695494071\n",
      "-0.7126685772248881\n",
      "-0.6990369494501623\n",
      "-0.7404881534324509\n",
      "-0.7729224856561031\n",
      "-0.7437095716056159\n",
      "-0.7942620113560227\n",
      "-0.719371995506518\n",
      "-0.755879912896055\n",
      "-0.7736592664044766\n",
      "-0.8787556807114204\n",
      "-0.8402419290286062\n",
      "-0.7698077186028061\n",
      "-0.6702975959473721\n",
      "-0.7353089375246943\n",
      "-0.7042821670167344\n",
      "-0.789305059217916\n",
      "-0.7193310577879334\n",
      "-0.7744047634741876\n",
      "-0.7868859547721403\n",
      "-0.7018286286699321\n",
      "-0.661218113997024\n",
      "-0.7580992280690491\n",
      "-0.769868173111244\n",
      "-0.8350774264353279\n",
      "-0.9051175727972216\n",
      "-0.827960847610642\n",
      "-0.9243114279740852\n",
      "-0.8020165304742953\n",
      "-0.776948219553288\n",
      "-0.6970265818468726\n",
      "-0.6618165816565279\n",
      "-0.692376120312565\n",
      "-0.7790129658107267\n",
      "-0.7808629927413399\n",
      "-0.7673275638468083\n",
      "-0.7579510424086838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.748314853940889\n",
      "-0.7109302481623855\n",
      "-0.7552552967382367\n",
      "-0.7708117257676652\n",
      "-0.8792908718952177\n",
      "-0.7460435439250137\n",
      "-0.8358548915190381\n",
      "-0.761038181157436\n",
      "-0.6975649810245788\n",
      "-0.6908678705056217\n",
      "-0.7826604739677809\n",
      "-0.8067169705531896\n",
      "-0.8344244357667358\n",
      "-0.8026312251136973\n",
      "-0.7173767673779101\n",
      "-0.796242421524288\n",
      "-0.8129949256969794\n",
      "-0.6916540596434622\n",
      "-0.7223836995282236\n",
      "-0.7214565680859213\n",
      "-0.6636138843647841\n",
      "-0.7242902618420911\n",
      "-0.6774087311518956\n",
      "-0.6410576265889445\n",
      "-0.6544822758477283\n",
      "-0.6410907411077204\n",
      "-0.7446392235186791\n",
      "-0.6455059214693677\n",
      "-0.5901689066509443\n",
      "-0.6233950856220958\n",
      "-0.649768624625147\n",
      "-0.7786493850053898\n",
      "-0.7351445587501843\n",
      "-0.7741364314032826\n",
      "-0.7647685120800771\n",
      "-0.732552579398525\n",
      "-0.7058574209493859\n",
      "-0.6982333596462756\n",
      "-0.7657741526180724\n",
      "-0.6696894492253167\n",
      "-0.6385983789050371\n",
      "-0.6264811214307104\n",
      "-0.7170185514275419\n",
      "-0.6910704340314704\n",
      "-0.6454930625560542\n",
      "-0.6727146084888501\n",
      "-0.6784098396173843\n",
      "-0.6809731293123442\n",
      "-0.7524024826492608\n",
      "-0.7590722153399175\n",
      "-0.6982293945565523\n",
      "-0.7499703518966188\n",
      "-0.6548451579922672\n",
      "-0.671650509027621\n",
      "-0.6842839667037701\n",
      "-0.7348442289018348\n",
      "-0.6285662590123321\n",
      "-0.6368553692050971\n",
      "-0.6754427978242175\n",
      "-0.7430181243626673\n",
      "-0.6799935282430101\n",
      "-0.6837123141982518\n",
      "-0.7202676533562091\n",
      "-0.7081371878424775\n",
      "-0.6790695773432306\n",
      "-0.678417384224103\n",
      "-0.6981482227271708\n",
      "-0.7615148508692422\n",
      "-0.6755987158099234\n",
      "-0.7908248606690427\n",
      "-0.7706346797129897\n",
      "-0.7493670594631192\n",
      "-0.752259714546776\n",
      "-0.8413329081877\n",
      "-0.8256231399304419\n",
      "-0.8346055374927637\n",
      "-0.7955816076843651\n",
      "-0.6912475966422371\n",
      "-0.6305807347682815\n",
      "-0.7023016243946327\n",
      "-0.6887327148647941\n",
      "-0.7346962459859289\n",
      "-0.656015615400258\n",
      "-0.5932440478515177\n",
      "-0.6591101179897281\n",
      "-0.6861347357262864\n",
      "-0.6828965991694105\n",
      "-0.6620662623108653\n",
      "-0.5986398940795181\n",
      "-0.6878428260684946\n",
      "-0.700561630596408\n",
      "-0.5017769630681749\n",
      "-0.6098250579155771\n",
      "-0.6053883338406311\n",
      "-0.662420082552647\n",
      "-0.61781027810671\n",
      "-0.7294907406665851\n",
      "-0.73389017345636\n",
      "-0.6778348557523957\n",
      "-0.7118249654027986\n",
      "-0.7007091943903282\n",
      "-0.7343017235898747\n",
      "-0.7230275648390333\n",
      "-0.7399050928290443\n",
      "-0.6906099069035724\n",
      "-0.5392906840620484\n",
      "-0.6805880680171998\n",
      "-0.6923197698303065\n",
      "-0.783188682050242\n",
      "-0.6762058656375813\n",
      "-0.7628158039858965\n",
      "-0.7236346375316035\n",
      "-0.6681249058891162\n",
      "-0.7466762968550799\n",
      "-0.6993080563329973\n",
      "-0.728212545615282\n",
      "-0.7000285121864103\n",
      "-0.5522307432394417\n",
      "-0.6756884565839658\n",
      "-0.697803005957211\n",
      "-0.6857887968389279\n",
      "-0.6525229154459926\n",
      "-0.5922816301052534\n",
      "-0.7264271496274757\n",
      "-0.6825896591633343\n",
      "-0.7215325956117\n",
      "-0.7202820341133899\n",
      "-0.6567301821142618\n",
      "-0.6688176938729065\n",
      "-0.7103274488312501\n",
      "-0.6220036540220755\n",
      "-0.6579029547989382\n",
      "-0.7196486870698366\n",
      "-0.6704424061855188\n",
      "-0.6779438906374196\n",
      "-0.6912060373050393\n",
      "-0.7772419216828097\n",
      "-0.663219982680736\n",
      "-0.7122100668194835\n",
      "-0.5633890376173897\n",
      "-0.7516633967291364\n",
      "-0.690977391195745\n",
      "-0.5903558368362943\n",
      "-0.718789476622595\n",
      "-0.7238252234607069\n",
      "-0.6359182780870208\n",
      "-0.7345621440878891\n",
      "-0.7358906014131419\n",
      "-0.6600070086222941\n",
      "-0.6573252979589759\n",
      "-0.571432199995646\n",
      "-0.6029044792267315\n",
      "-0.5773867142532035\n",
      "-0.64813181653772\n",
      "-0.636421934737613\n",
      "-0.6061856672749163\n",
      "-0.64875663514024\n",
      "-0.7030341081645713\n",
      "-0.6483296353581305\n",
      "-0.6626274031489053\n",
      "-0.7742046918978044\n",
      "-0.6429504986792183\n",
      "-0.7568494720386776\n",
      "-0.7209048860437334\n",
      "-0.713931529985071\n",
      "-0.7488210468461681\n",
      "-0.7035778512577626\n",
      "-0.6588973642957233\n",
      "-0.5944298896870304\n",
      "-0.6402082789056018\n",
      "-0.5621705509261473\n",
      "-0.5937389946028683\n",
      "-0.7020686644848019\n",
      "-0.6784071974433967\n",
      "-0.7078825996171105\n",
      "-0.7508905563532782\n",
      "-0.8124463515193655\n",
      "-0.7198044851837526\n",
      "-0.6850856049040758\n",
      "-0.6917016461304238\n",
      "-0.6910070797685031\n",
      "-0.6492719401284113\n",
      "-0.5940440916627052\n",
      "-0.6434815389491937\n",
      "-0.7356829717795709\n",
      "-0.6649116672115204\n",
      "-0.6474216010863335\n",
      "-0.5724354610434257\n",
      "-0.6622509278199906\n",
      "-0.6039919313437752\n",
      "-0.6631697816733583\n",
      "-0.597503873113751\n",
      "-0.5705535889555085\n",
      "-0.6000685726481734\n",
      "-0.647011900686489\n",
      "-0.5380492955482633\n",
      "-0.6439265829149965\n",
      "-0.49907180947469176\n",
      "-0.5526680798602338\n",
      "-0.5517952437224839\n",
      "-0.5974235176733695\n",
      "-0.5766105804100707\n",
      "-0.6343381060187069\n",
      "-0.6397575777965815\n",
      "-0.6512876071335056\n",
      "-0.7162358772902232\n",
      "-0.6362331277504029\n",
      "-0.6229804328164804\n",
      "-0.727270348092121\n",
      "-0.684063230998332\n",
      "-0.7379314606103272\n",
      "-0.627950209849677\n",
      "-0.5718335498115775\n",
      "-0.6796571568317216\n",
      "-0.5554535036046424\n",
      "-0.5873931928643936\n",
      "-0.6106615078646925\n",
      "-0.6450293122386609\n",
      "-0.5324605721477835\n",
      "-0.6037380576441935\n",
      "-0.6153736275733146\n",
      "-0.6050901151858108\n",
      "-0.555805638328238\n",
      "-0.7057661086061305\n",
      "-0.5845102143426752\n",
      "-0.5534461216477737\n",
      "-0.7183144374902927\n",
      "-0.573691680066825\n",
      "-0.6702461642243677\n",
      "-0.6160106397544438\n",
      "-0.6257565373577795\n",
      "-0.6521321817730222\n",
      "-0.6485332917190058\n",
      "-0.6580080333000686\n",
      "-0.6901540250504081\n",
      "-0.7065248186245712\n",
      "-0.653219412302457\n",
      "-0.5637128600694242\n",
      "-0.6870125934260886\n",
      "-0.6804013644533317\n",
      "-0.6159447386534755\n",
      "-0.5737312098637103\n",
      "-0.5604855424972643\n",
      "-0.6068606512299867\n",
      "-0.6938691708864325\n",
      "-0.6708935845161521\n",
      "-0.5823008834423736\n",
      "-0.5856131827798144\n",
      "-0.5666582126236334\n",
      "-0.5797141640269858\n",
      "-0.6143102221914662\n",
      "-0.5707509501651232\n",
      "-0.6257967804634643\n",
      "-0.6773035668783446\n",
      "-0.6514396808644333\n",
      "-0.6693723397864553\n",
      "-0.4923387304552329\n",
      "-0.5819488680237499\n",
      "-0.7035814077401092\n",
      "-0.6105633954500272\n",
      "-0.6620808154769552\n",
      "-0.597014105972556\n",
      "-0.5546641133036352\n",
      "-0.5719876670451222\n",
      "-0.6658204063691565\n",
      "-0.6475733353334171\n",
      "-0.6208590382763157\n",
      "-0.6706713994963612\n",
      "-0.6190267783142472\n",
      "-0.6090828873536476\n",
      "-0.7183387000309233\n",
      "-0.5738660826653258\n",
      "-0.646407471929955\n",
      "-0.686548894472824\n",
      "-0.5889189344570555\n",
      "-0.7207830044281706\n",
      "-0.6455192506689571\n",
      "-0.6688632510142788\n",
      "-0.6322528462103053\n",
      "-0.7159955480274138\n",
      "-0.5959578050773099\n",
      "-0.6057123739914984\n",
      "-0.6230112453010433\n",
      "-0.6164285442877129\n",
      "-0.5910811731577555\n",
      "-0.6758520300036543\n",
      "-0.7327733938332359\n",
      "-0.8077042997460332\n",
      "-0.7906764507609366\n",
      "-0.7557744860366461\n",
      "-0.7137709222406257\n",
      "-0.6480035314040374\n",
      "-0.7143565508794968\n",
      "-0.5887182134541651\n",
      "-0.6088113097974209\n",
      "-0.5511637075827959\n",
      "-0.6626852655735948\n",
      "-0.5740788614411747\n",
      "-0.4569875373239344\n",
      "-0.5007496580073164\n",
      "-0.581530963518156\n",
      "-0.5334780447358237\n",
      "-0.5407745308360495\n",
      "-0.5570415596962692\n",
      "-0.5301253260818939\n",
      "-0.6861848343515973\n",
      "-0.6160439496030522\n",
      "-0.5703943410431387\n",
      "-0.5311877311836395\n",
      "-0.5643982376513883\n",
      "-0.5579998690802026\n",
      "-0.5317345786932586\n",
      "-0.5551619960373223\n",
      "-0.5557247179563725\n",
      "-0.6416434146810239\n",
      "-0.6829480486239873\n",
      "-0.7078544957204338\n",
      "-0.6716341866519211\n",
      "-0.674767936266651\n",
      "-0.6318831095445837\n",
      "-0.6972026403567646\n",
      "-0.7679094996048875\n",
      "-0.6633912790704458\n",
      "-0.6462030335554976\n",
      "-0.634257455231369\n",
      "-0.6955679938174851\n",
      "-0.6428893284806138\n",
      "-0.7659635233214964\n",
      "-0.5767259307550675\n",
      "-0.5807037709517218\n",
      "-0.5878195551220461\n",
      "-0.6055642748935015\n",
      "-0.5925806246779866\n",
      "-0.5648791422030761\n",
      "-0.5442932492452115\n",
      "-0.5795941136519024\n",
      "-0.612309230279117\n",
      "-0.6106498827870043\n",
      "-0.5923170629009191\n",
      "-0.5451969591699503\n",
      "-0.5056339702084958\n",
      "-0.45278866421127634\n",
      "-0.642525508044899\n",
      "-0.6417860298545991\n",
      "-0.6117032208288602\n",
      "-0.5644010158419347\n",
      "-0.5707253834292497\n",
      "-0.5300555664361108\n",
      "-0.6272476992016272\n",
      "-0.6703251556507273\n",
      "-0.6381738072939949\n",
      "-0.7558391062000095\n",
      "-0.7323374029760216\n",
      "-0.6711387023617095\n",
      "-0.7232568604700292\n",
      "-0.6038931385421817\n",
      "-0.5883217261719438\n",
      "-0.6292680689388447\n",
      "-0.5483463960845917\n",
      "-0.5326639088071521\n",
      "-0.5575787937250687\n",
      "-0.5581870290682369\n",
      "-0.6626537115938881\n",
      "-0.6160169675989845\n",
      "-0.558530898172233\n",
      "-0.616032869035257\n",
      "-0.6485012269007038\n",
      "-0.6716609575257908\n",
      "-0.5794566516371773\n",
      "-0.6919472532852894\n",
      "-0.6311356259530086\n",
      "-0.6729651284052914\n",
      "-0.6834573308196771\n",
      "-0.5565927745116912\n",
      "-0.657096102102723\n",
      "-0.6246095726796369\n",
      "-0.6756240453471565\n",
      "-0.6403197379187398\n",
      "-0.5798693952136516\n",
      "-0.5406121051601401\n",
      "-0.4979401395591384\n",
      "-0.5912982607394537\n",
      "-0.6087356258287875\n",
      "-0.5209398724033911\n",
      "-0.41495955269188695\n",
      "-0.6259558632233037\n",
      "-0.60738258645245\n",
      "-0.5623520856204985\n",
      "-0.6182963238770672\n",
      "-0.7480582306049429\n",
      "-0.5689762595322209\n",
      "-0.5891794375561787\n",
      "-0.567983430464784\n",
      "-0.4667453353978917\n",
      "-0.47600741436418964\n",
      "-0.4515698741305353\n",
      "-0.4901241348400948\n",
      "-0.6983031527071517\n",
      "-0.656409698781729\n",
      "-0.5764220472120672\n",
      "-0.6504280700599282\n",
      "-0.6333350907102663\n",
      "-0.6216558138694301\n",
      "-0.6954591409360715\n",
      "-0.6272661790601184\n",
      "-0.5439895020849705\n",
      "-0.5151705693738975\n",
      "-0.6766047970273025\n",
      "-0.59765243421542\n",
      "-0.6742025998975435\n",
      "-0.6711763695491446\n",
      "-0.5992956929573184\n",
      "-0.602629407331239\n",
      "-0.6206402577721272\n",
      "-0.5271797954764634\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6191102676724469\n",
      "-0.5716277088447648\n",
      "-0.5798110569032905\n",
      "-0.6791280663893863\n",
      "-0.7104048636144151\n",
      "-0.5711603682563057\n",
      "-0.5836705640919526\n",
      "-0.6414866599580162\n",
      "-0.671884923749835\n",
      "-0.5724304363194906\n",
      "-0.6678822380509996\n",
      "-0.6439961872688267\n",
      "-0.6715726477394793\n",
      "-0.6764693411167445\n",
      "-0.5985781625176272\n",
      "-0.5583437953905777\n",
      "-0.5587390782517018\n",
      "-0.503815339635378\n",
      "-0.5931746315907828\n",
      "-0.6500971315195893\n",
      "-0.543929966713665\n",
      "-0.5704508238654453\n",
      "-0.6149371366539855\n",
      "-0.46630345326693046\n",
      "-0.5674829075974794\n",
      "-0.6034676060213294\n",
      "-0.663228416667947\n",
      "-0.5487664407562106\n",
      "-0.5298488339123277\n",
      "-0.5846464289200362\n",
      "-0.6225396574609225\n",
      "-0.6387569409968292\n",
      "-0.5989559251939539\n",
      "-0.6554743559637324\n",
      "-0.679285520261112\n",
      "-0.6069173401905897\n",
      "-0.6460713147010309\n",
      "-0.6346078443193214\n",
      "-0.5864845984113567\n",
      "-0.6807626348908418\n",
      "-0.5928891187009842\n",
      "-0.6949411424820197\n",
      "-0.628017983469476\n",
      "-0.6097143806465974\n",
      "-0.49833948676267603\n",
      "-0.5144936722215511\n",
      "-0.6096243949305254\n",
      "-0.5982243307613284\n",
      "-0.586551173695314\n",
      "-0.6449597425142799\n",
      "-0.636787985989178\n",
      "-0.6400021642223953\n",
      "-0.6357479091164249\n",
      "-0.706305004014537\n",
      "-0.6049997742621588\n",
      "-0.7145633945316109\n",
      "-0.559457119935065\n",
      "-0.715979492170708\n",
      "-0.6425144190838019\n",
      "-0.6121030426819071\n",
      "-0.5888947027948424\n",
      "-0.6166305966079776\n",
      "-0.63771947069929\n",
      "-0.6591067023746513\n",
      "-0.6668132635677321\n",
      "-0.6613058707871553\n",
      "-0.6859640532549987\n",
      "-0.6424411256878051\n",
      "-0.6614107137807346\n",
      "-0.6380569257760464\n",
      "-0.7701100378312827\n",
      "-0.6859900839968962\n",
      "-0.6712977965630315\n",
      "-0.6650409598987274\n",
      "-0.7391834518248878\n",
      "-0.6031603050468421\n",
      "-0.5720830898331677\n",
      "-0.6087130364975377\n",
      "-0.7412259799054354\n",
      "-0.7074170457141714\n",
      "-0.7815513655394326\n",
      "-0.6912990338948434\n",
      "-0.5974975594092033\n",
      "-0.6781229679939317\n",
      "-0.6545105156354982\n",
      "-0.5669435068600412\n",
      "-0.7111680547805456\n",
      "-0.5562931995295215\n",
      "-0.5587456593779835\n",
      "-0.5291678787894494\n",
      "-0.5693725729326461\n",
      "-0.5669509266492064\n",
      "-0.6298131500411529\n",
      "-0.6397689711256591\n",
      "-0.6380620566605358\n",
      "-0.5815507070128799\n",
      "-0.6406177759205426\n",
      "-0.5797451398982034\n",
      "-0.6617220758151302\n",
      "-0.6898180010990873\n",
      "-0.8140171713655227\n",
      "-0.7853313258610389\n",
      "-0.6786227387389641\n",
      "-0.7186001568451553\n",
      "-0.7034989369721333\n",
      "-0.6897448515301653\n",
      "-0.6580223962988466\n",
      "-0.7481133740525647\n",
      "-0.6944910531724001\n",
      "-0.7087406399735965\n",
      "-0.7789758971426936\n",
      "-0.639986090864286\n",
      "-0.8226341131840734\n",
      "-0.7554258217957308\n",
      "-0.7166182428272369\n",
      "-0.6826689909097663\n",
      "-0.7036752377160683\n",
      "-0.6658069634013106\n",
      "-0.6309209858529394\n",
      "-0.632503386779237\n",
      "-0.7058059378632312\n",
      "-0.7242218180653348\n",
      "-0.6881789011869427\n",
      "-0.6645684975453283\n",
      "-0.7816225536521529\n",
      "-0.7700483341406228\n",
      "-0.6920843078985299\n",
      "-0.637315825789106\n",
      "-0.769126401052681\n",
      "-0.7842354025477456\n",
      "-0.8258888760509256\n",
      "-0.7696817288956317\n",
      "-0.6707236856647256\n",
      "-0.6723572015949993\n",
      "-0.7041297486927858\n",
      "-0.7340217929737376\n",
      "-0.6272018972041336\n",
      "-0.687025784578389\n",
      "-0.7169454414783799\n",
      "-0.7641681885549789\n",
      "-0.697707599156339\n",
      "-0.7379196070154765\n",
      "-0.6872585940384701\n",
      "-0.7081244776217421\n",
      "-0.6111212046596834\n",
      "-0.7023922423227864\n",
      "-0.6538233973759403\n",
      "-0.8213630089760892\n",
      "-0.7051013854305125\n",
      "-0.6586036759016373\n",
      "-0.6330901089048936\n",
      "-0.6216601530962974\n",
      "-0.7078694967643624\n",
      "-0.7190947641594693\n",
      "-0.694467590867652\n",
      "-0.7531729004850188\n",
      "-0.7119933884214857\n",
      "-0.7043616374240688\n",
      "-0.7288736245020822\n",
      "-0.8239376957616464\n",
      "-0.820760764085687\n",
      "-0.806186333983368\n",
      "-0.8176825674372041\n",
      "-0.7979599096900265\n",
      "-0.851388072605121\n",
      "-0.7515864633003965\n",
      "-0.7851877354277395\n",
      "-0.8111234119262939\n",
      "-0.8111333306279961\n",
      "-0.7639792891848503\n",
      "-0.8224124576254068\n",
      "-0.7353189132964724\n",
      "-0.7706086522632442\n",
      "-0.7526576974185508\n",
      "-0.6538924695740189\n",
      "-0.7006176141940456\n",
      "-0.8103972761258427\n",
      "-0.7565001692638356\n",
      "-0.7284652545668815\n",
      "-0.7842229535813392\n",
      "-0.7380608605189137\n",
      "-0.7542639605013188\n",
      "-0.7228761121484873\n",
      "-0.8144976954514038\n",
      "-0.7336395262943404\n",
      "-0.7219564270233196\n",
      "-0.7603516323613297\n",
      "-0.7686596549453957\n",
      "-0.648950459370668\n",
      "-0.6784235552484669\n",
      "-0.6829866329059624\n",
      "-0.6887099708419407\n",
      "-0.8191309432634571\n",
      "-0.8387671455510686\n",
      "-0.8325649685647353\n",
      "-0.8816931410113964\n",
      "-0.8093579147380872\n",
      "-0.7405409582466215\n",
      "-0.7264114001910683\n",
      "-0.7532511866720585\n",
      "-0.7144254245245885\n",
      "-0.8117714025945135\n",
      "-0.8607714847499977\n",
      "-0.7652260589898121\n",
      "-0.6895116030588678\n",
      "-0.7875406096933191\n",
      "-0.860743911585713\n",
      "-0.8851804420011558\n",
      "-0.7953036246739987\n",
      "-0.7807870133330025\n",
      "-0.7796749291164592\n",
      "-0.7510958136029865\n",
      "-0.6847673552784941\n",
      "-0.8161279394798014\n",
      "-0.7147438236063678\n",
      "-0.8316067320017466\n",
      "-0.7413342371186401\n",
      "-0.7925681823038697\n",
      "-0.8297838582022716\n",
      "-0.7440229515036838\n",
      "-0.695778595415777\n",
      "-0.7980506551956349\n",
      "-0.8231714260716705\n",
      "-0.8430572334072798\n",
      "-0.6922761987812694\n",
      "-0.7444198405036864\n",
      "-0.919912099556702\n",
      "-0.8107833130915693\n",
      "-0.7524502060314703\n",
      "-0.7760799266537353\n",
      "-0.7213655630465727\n",
      "-0.7396815891506064\n",
      "-0.7041349838471619\n",
      "-0.7319388032080394\n",
      "-0.8450724026677513\n",
      "-0.7569576311973076\n",
      "-0.93202707144813\n",
      "-0.8303530167670702\n",
      "-0.9108125188248767\n",
      "-0.9704615423474308\n",
      "-0.8111424866999956\n",
      "-0.7814113715473632\n",
      "-0.8546934976772552\n",
      "-0.8162911445520434\n",
      "-0.8455339368850682\n",
      "-0.7121375810637348\n",
      "-0.7428076628949792\n",
      "-0.764339979446822\n",
      "-0.7619721263284063\n",
      "-0.8482071132733364\n",
      "-0.7399637497141341\n",
      "-0.674395531298669\n",
      "-0.7329882164602458\n",
      "-0.7520383896001082\n",
      "-0.6943405838527851\n",
      "-0.8247520699565881\n",
      "-0.6689673188707252\n",
      "-0.8127172808275934\n",
      "-0.802728524574026\n",
      "-0.7507633363160456\n",
      "-0.8132202527455289\n",
      "-0.8717831577792922\n",
      "-0.7292558761661663\n",
      "-0.7206182614674571\n",
      "-0.8306263692423541\n",
      "-0.7629980671706407\n",
      "-0.7373229894653847\n",
      "-0.7696302299675731\n",
      "-0.7683540363068326\n",
      "-0.7620836422148246\n",
      "-0.6448958202206311\n",
      "-0.7600077005856063\n",
      "-0.8230386625574915\n",
      "-0.7460839776485418\n",
      "-0.708435738519395\n",
      "-0.7410503113424147\n",
      "-0.7568240989077424\n",
      "-0.6197687546884721\n",
      "-0.7421942311003605\n",
      "-0.773313294088283\n",
      "-0.8029784654507494\n",
      "-0.7612200324049534\n",
      "-0.7976477199646616\n",
      "-0.8052654138401891\n",
      "-0.8903556419248543\n",
      "-0.8687104531508746\n",
      "-0.7934074013626278\n",
      "-0.7141324240865469\n",
      "-0.7864576747089357\n",
      "-0.7122323442353502\n",
      "-0.7234936366868469\n",
      "-0.828829208867356\n",
      "-0.7399540889741877\n",
      "-0.7062778829153309\n",
      "-0.7718702072152156\n",
      "-0.9004412845391402\n",
      "-0.8558781113058667\n",
      "-0.8689544485926741\n",
      "-0.7889692165082206\n",
      "-0.697864156733996\n",
      "-0.8228982988747962\n",
      "-0.8036905563501613\n",
      "-0.8340554980943382\n",
      "-0.7103722943368093\n",
      "-0.7789026009516101\n",
      "-0.8301757493441796\n",
      "-0.8563079617825974\n",
      "-0.8464715874275537\n",
      "-0.8326464733726368\n",
      "-0.8375290694298859\n",
      "-0.7376116210934939\n",
      "-0.84631566358858\n",
      "-0.8746286061874498\n",
      "-0.8622373193736397\n",
      "-0.7513005960354162\n",
      "-0.8230425436503017\n",
      "-0.8506396431333492\n",
      "-0.8223071560954432\n",
      "-0.9533279776445647\n",
      "-0.8934535813767969\n",
      "-0.8778428915404757\n",
      "-0.9071241543004923\n",
      "-0.8477085070627598\n",
      "-0.9264249601795927\n",
      "-0.854152015293768\n",
      "-0.8500310594108818\n",
      "-0.7595181821315814\n",
      "-0.9157457992996911\n",
      "-0.8767727038034298\n",
      "-0.8723296884616761\n",
      "-0.9209720252905784\n",
      "-0.9076087210259769\n",
      "-0.8176507002454596\n",
      "-0.7591372443120761\n",
      "-0.7703292939470983\n",
      "-0.9219198207631776\n",
      "-0.9556663628342751\n",
      "-0.8639643828565036\n",
      "-0.8158799272939102\n",
      "-0.9200885773442988\n",
      "-0.8461348044610832\n",
      "-0.8859409024783205\n",
      "-0.869062492152002\n",
      "-1.0294991313652027\n",
      "-0.907711663169072\n",
      "-0.9936010286663006\n",
      "-0.9558529253356206\n",
      "-0.8941479705633671\n",
      "-0.9699571484912491\n",
      "-0.9320337503989431\n",
      "-0.9785108769966704\n",
      "-0.8869050385874437\n",
      "-0.8054019416890377\n",
      "-0.8294796332613803\n",
      "-0.9052085291253517\n",
      "-0.8560286683871323\n",
      "-0.9911962196216575\n",
      "-0.9826008439146099\n",
      "-0.988628596683851\n",
      "-0.9700822502911423\n",
      "-1.0154317068226433\n",
      "-0.9180306735229499\n",
      "-1.1160616699037171\n",
      "-0.9748214192280509\n",
      "-0.9214379561015499\n",
      "-0.9323612973607018\n",
      "-1.0456985443492879\n",
      "-0.9631017590302523\n",
      "-1.0721887667667027\n",
      "-0.9845955314119853\n",
      "-0.9605703952574572\n",
      "-0.9802594861623078\n",
      "-0.9209621913861807\n",
      "-0.8779284996495087\n",
      "-0.8362131442289927\n",
      "-0.9851018517089496\n",
      "-1.0145981825931016\n",
      "-0.9561971744400549\n",
      "-0.868384253537501\n",
      "-0.8781491681117447\n",
      "-0.9028785667315321\n",
      "-0.8220736131937912\n",
      "-0.8967205959522005\n",
      "-0.9547506126293962\n",
      "-0.8764767477056868\n",
      "-0.8243023054783802\n",
      "-0.8020399927770688\n",
      "-0.8441291404716654\n",
      "-1.004713783763775\n",
      "-0.8849941959342816\n",
      "-0.941607258762064\n",
      "-0.9864382735273255\n",
      "-0.8632403119983197\n",
      "-0.8802224696007118\n",
      "-0.9405929605401452\n",
      "-1.0280658385871797\n",
      "-0.923514540275891\n",
      "-0.7887292340222792\n",
      "-0.8454012832433839\n",
      "-0.8474788727209301\n",
      "-0.762124886122835\n",
      "-0.8550109784332813\n",
      "-0.9031210844612276\n",
      "-0.9413341914883544\n",
      "-0.8976830828368225\n",
      "-0.9517725703562283\n",
      "-1.0128308876085013\n",
      "-0.9540099768127446\n",
      "-0.8006721464466108\n",
      "-0.91535613792632\n",
      "-0.7935520642744139\n",
      "-0.9208936879355213\n",
      "-0.814311485921932\n",
      "-0.8110867288068786\n",
      "-0.7947168132599264\n",
      "-0.7968125334835656\n",
      "-0.9147783853243818\n",
      "-0.8302828378468718\n",
      "-0.9470335246601564\n",
      "-0.8819575801044487\n",
      "-0.8849230886733029\n",
      "-0.9594652286900741\n",
      "-0.9562703975635782\n",
      "-0.8876742276989652\n",
      "-0.8003729727045286\n",
      "-0.8618143848816703\n",
      "-0.9427723864485439\n",
      "-0.8428200613440401\n",
      "-0.8323564684656553\n",
      "-0.8655595235937751\n",
      "-0.948105453972613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8769010077272582\n",
      "-0.9395830808501471\n",
      "-0.9610685177026728\n",
      "-0.9721351831896932\n",
      "-0.9753436496887428\n",
      "-0.9080488833701102\n",
      "-0.9300971676135248\n",
      "-0.8572623376710751\n",
      "-0.8532802933545802\n",
      "-0.7984430408336151\n",
      "-0.901994577518457\n",
      "-0.9272583802755914\n",
      "-0.9237963056509302\n",
      "-0.943424034977488\n",
      "-0.9495473136218876\n",
      "-0.9279863410749871\n",
      "-0.9248876876222931\n",
      "-0.9918551940263547\n",
      "-0.9309050340064823\n",
      "-0.8996901857057695\n",
      "-0.9125253040391356\n",
      "-0.9656959974574794\n",
      "-1.0409644538042995\n",
      "-0.9319428863846299\n",
      "-0.9168391876544782\n",
      "-0.9431701485712658\n",
      "-0.9076430020163292\n",
      "-0.8589914747761971\n",
      "-0.8880004146643733\n",
      "-0.8458698563000209\n",
      "-0.9215244002829219\n",
      "-0.9190028357348009\n",
      "-0.8696793236550091\n",
      "-0.9462550518876138\n",
      "-0.857419665498753\n",
      "-0.8969186033558286\n",
      "-0.8883628455758523\n",
      "-0.9234181525881359\n",
      "-0.9687294782693257\n",
      "-0.83435082993621\n",
      "-1.0144763928267775\n",
      "-0.9665833863224381\n",
      "-1.009398397234407\n",
      "-0.9892766827824079\n",
      "-0.9399889248300004\n",
      "-1.0159465575067688\n",
      "-1.0057639247528016\n",
      "-1.0885336913640473\n",
      "-0.9908733590506577\n",
      "-0.9384507724169296\n",
      "-1.0366072787377918\n",
      "-1.0012675287015371\n",
      "-1.044313651839823\n",
      "-1.0731565567768067\n",
      "-1.0605213948149064\n",
      "-1.0223669421257178\n",
      "-0.9261073667738079\n",
      "-0.9323079668299025\n",
      "-1.0649928816147338\n",
      "-0.9413074407670363\n",
      "-1.106680684890113\n",
      "-0.9587523292571214\n",
      "-1.0049812587353388\n",
      "-0.9532406270153918\n",
      "-0.9395742762061599\n",
      "-0.9534877217557022\n",
      "-0.9198298988547029\n",
      "-0.939656964662203\n",
      "-0.9453904890003116\n",
      "-1.023408768028804\n",
      "-0.969833584662268\n",
      "-0.9263103256012787\n",
      "-0.9655243100344013\n",
      "-1.030375722990976\n",
      "-0.9124028325342464\n",
      "-0.9890548764255943\n",
      "-1.0067883654424463\n",
      "-1.000945469015132\n",
      "-0.9446079074139956\n",
      "-0.9097077997488602\n",
      "-0.9634897452995669\n",
      "-0.9787112357574043\n",
      "-0.9685987518130649\n",
      "-0.8673900932948722\n",
      "-0.9541179965483539\n",
      "-0.8584996012349644\n",
      "-0.8698987887786778\n",
      "-0.9941867914806533\n",
      "-0.8559120307056284\n",
      "-0.9346481495744278\n",
      "-0.9476046516957137\n",
      "-1.0169316657702085\n",
      "-0.9276913698499439\n",
      "-0.9886775645154612\n",
      "-0.9706387211145622\n",
      "-0.9572472176793065\n",
      "-1.0625443750576133\n",
      "-1.0376436025598024\n",
      "-1.1365881738184431\n",
      "-1.040579467373498\n",
      "-1.0795101515061076\n",
      "-1.0312884790094454\n",
      "-0.9480194804690677\n",
      "-0.9693571283310788\n",
      "-0.983973884518793\n",
      "-1.0346515736537096\n",
      "-0.8919417598194634\n",
      "-0.9504942287538785\n",
      "-0.8843958323025672\n",
      "-0.8779661664486542\n",
      "-0.8903094795666331\n",
      "-0.9541922916028555\n",
      "-1.0013667676473736\n",
      "-0.8795757597519068\n",
      "-0.8985360293565529\n",
      "-0.8700660999120777\n",
      "-0.9104769809419702\n",
      "-0.8441439846113351\n",
      "-0.9497853621266124\n",
      "-0.867085701082331\n",
      "-1.0432534691688171\n",
      "-0.9548661736153486\n",
      "-0.9576002511571342\n",
      "-0.8907132311027078\n",
      "-0.918907417701978\n",
      "-0.913302777719226\n",
      "-0.9830448733256932\n",
      "-0.897367405762304\n",
      "-0.8943125967562784\n",
      "-0.9868311451566528\n",
      "-0.935037803731518\n",
      "-0.8950070624579561\n",
      "-1.029511663688327\n",
      "-1.0537857502512278\n",
      "-1.058222739498485\n",
      "-0.9790297173077364\n",
      "-0.8997609735564974\n",
      "-0.7741954233108053\n",
      "-0.9100392283872959\n",
      "-0.8409973454583547\n",
      "-1.0199344491610887\n",
      "-0.8540297289804966\n",
      "-0.8849499199026664\n",
      "-0.8568540243976903\n",
      "-0.8185251169587136\n",
      "-0.8935228329780446\n",
      "-0.8225499282372456\n",
      "-0.931696330654821\n",
      "-0.9303133108836702\n",
      "-0.9490665766929101\n",
      "-0.9102812534588337\n",
      "-0.9300309488900018\n",
      "-0.9279778706144595\n",
      "-0.9793077415562287\n",
      "-0.9381328720546785\n",
      "-0.9824027520248413\n",
      "-0.9168901733065692\n",
      "-0.838405128000167\n",
      "-0.844428642183377\n",
      "-0.870479093309536\n",
      "-0.9367584133645379\n",
      "-0.9234492254613993\n",
      "-0.8340872764444803\n",
      "-0.9281601629149452\n",
      "-0.9419946515805931\n",
      "-0.9287529494179554\n",
      "-0.8318709614944368\n",
      "-0.821335984198589\n",
      "-0.9242532324342324\n",
      "-0.8805315193784466\n",
      "-0.9568110883416748\n",
      "-0.9132178048298794\n",
      "-0.9508681328911394\n",
      "-0.8853665130947888\n",
      "-0.9522507828163629\n",
      "-0.8744995405822801\n",
      "-0.8358964117647106\n",
      "-0.8813944550289681\n",
      "-0.8310869137031253\n",
      "-0.9363886915850096\n",
      "-0.8429359869102498\n",
      "-0.9004996563365015\n",
      "-1.0124765303076144\n",
      "-0.8696795927950121\n",
      "-0.9665621237740859\n",
      "-0.993058872208495\n",
      "-0.8996770237890305\n",
      "-0.9549423777060397\n",
      "-0.9929530410167783\n",
      "-0.9516726194173101\n",
      "-0.9675575791784187\n",
      "-0.9436199161954281\n",
      "-0.85316106043033\n",
      "-0.8685806887982183\n",
      "-0.8862307783576243\n",
      "-0.9284232171971999\n",
      "-0.9425172989481643\n",
      "-0.9785036815874788\n",
      "-0.8603552774447588\n",
      "-0.9918077363837073\n",
      "-0.8633589562524715\n",
      "-0.8331419760382863\n",
      "-0.8794388326072127\n",
      "-0.9085058661741114\n",
      "-0.9852106353852123\n",
      "-0.8743120780703325\n",
      "-0.9139233405150698\n",
      "-0.8707049447174223\n",
      "-0.9177738331701901\n",
      "-0.8415936550038606\n",
      "-0.8781890807444411\n",
      "-0.9159329650430681\n",
      "-0.8424468056029242\n",
      "-0.8420335623277232\n",
      "-0.8660897080763589\n",
      "-1.0160343752133856\n",
      "-1.031103548285212\n",
      "-1.0786071106125439\n",
      "-1.0152117495334152\n",
      "-0.9622126848068481\n",
      "-0.9158239001928624\n",
      "-0.9440015097564277\n",
      "-0.9111464072199551\n",
      "-0.9146791713854169\n",
      "-0.8725552361875477\n",
      "-0.8409693556235087\n",
      "-0.8369012718745689\n",
      "-0.7805851494209829\n",
      "-0.8928028333948828\n",
      "-0.9893847069875487\n",
      "-0.9117134305279678\n",
      "-0.9623041186424774\n",
      "-0.9543319916350548\n",
      "-0.9783932412541445\n",
      "-0.8369510282158344\n",
      "-0.807662292132314\n",
      "-0.7706040397317676\n",
      "-0.7842938233925969\n",
      "-0.7510349774289884\n",
      "-0.747428172834428\n",
      "-0.6565657796244703\n",
      "-0.7201916934033913\n",
      "-0.7455874116506968\n",
      "-0.7148778292035686\n",
      "-0.6626182221444823\n",
      "-0.7651910661337272\n",
      "-0.8024344911758345\n",
      "-0.7780745472487272\n",
      "-0.8250233397196903\n",
      "-0.7629272379430827\n",
      "-0.7393057677861974\n",
      "-0.7586451285112649\n",
      "-0.7482590753985546\n",
      "-0.6980177032423025\n",
      "-0.7521625243648096\n",
      "-0.7002665932970608\n",
      "-0.6591085926464499\n",
      "-0.6526755066841113\n",
      "-0.7388564664247015\n",
      "-0.7444080934728224\n",
      "-0.6721570136969568\n",
      "-0.7022223674081732\n",
      "-0.7393709476503297\n",
      "-0.6431027892944944\n",
      "-0.6470324066250739\n",
      "-0.631110249846879\n",
      "-0.6441468452763349\n",
      "-0.6473297634163341\n",
      "-0.6596217955813835\n",
      "-0.7896607656106547\n",
      "-0.6386813527298334\n",
      "-0.6279162954267266\n",
      "-0.6343539803715238\n",
      "-0.7015224590629506\n",
      "-0.6583338173160631\n",
      "-0.8111661423335162\n",
      "-0.649352765416383\n",
      "-0.8051104966567824\n",
      "-0.6925831646934971\n",
      "-0.654874891423498\n",
      "-0.7425169446623735\n",
      "-0.621510354392068\n",
      "-0.6112881627649503\n",
      "-0.604846366800576\n",
      "-0.6743054460219984\n",
      "-0.6800262887879422\n",
      "-0.7644210562506728\n",
      "-0.7207611785155223\n",
      "-0.7247045546572476\n",
      "-0.8122861492382712\n",
      "-0.7377524081389931\n",
      "-0.682171380250122\n",
      "-0.8582335045828183\n",
      "-0.7191619461894404\n",
      "-0.727850605381602\n",
      "-0.6352746932682468\n",
      "-0.759020120531271\n",
      "-0.7282080214041561\n",
      "-0.5993203845037527\n",
      "-0.6683121701493135\n",
      "-0.6592590894344289\n",
      "-0.6691730751741173\n",
      "-0.6254589368772463\n",
      "-0.6416062754718882\n",
      "-0.6523711315563948\n",
      "-0.6224523692474407\n",
      "-0.6178322284742294\n",
      "-0.5143791157686198\n",
      "-0.5741960167438674\n",
      "-0.5821231733954103\n",
      "-0.5980823169532764\n",
      "-0.6577533989697607\n",
      "-0.6458513728872975\n",
      "-0.6080164699340801\n",
      "-0.5937174714233389\n",
      "-0.5933784401844591\n",
      "-0.7251833123290737\n",
      "-0.7547297262766742\n",
      "-0.6995311475071702\n",
      "-0.645030921941708\n",
      "-0.5826883850511124\n",
      "-0.6314660929466801\n",
      "-0.6902770848035632\n",
      "-0.5839502518778051\n",
      "-0.7282522871982436\n",
      "-0.7152788405543504\n",
      "-0.6354491571108433\n",
      "-0.6616110306323383\n",
      "-0.6228120875425657\n",
      "-0.6245458823671618\n",
      "-0.704777828828727\n",
      "-0.618122022859589\n",
      "-0.6133509698616271\n",
      "-0.66848438012446\n",
      "-0.7073903026729566\n",
      "-0.6504542389858761\n",
      "-0.6025064342051263\n",
      "-0.5707617897694389\n",
      "-0.539899395750612\n",
      "-0.6611980537557289\n",
      "-0.6104777801064821\n",
      "-0.7141557309039199\n",
      "-0.6113601017879845\n",
      "-0.5488737815178839\n",
      "-0.5830689398559908\n",
      "-0.6662857167043792\n",
      "-0.6369003479482354\n",
      "-0.6611469012075563\n",
      "-0.6385804985058428\n",
      "-0.6284515154042132\n",
      "-0.5836901421934675\n",
      "-0.5814336928495242\n",
      "-0.5655746725868389\n",
      "-0.5957396076298006\n",
      "-0.6093633120679453\n",
      "-0.641529345988686\n",
      "-0.714641177102912\n",
      "-0.6841565944544247\n",
      "-0.6409814467343105\n",
      "-0.5974729161368174\n",
      "-0.605505548746962\n",
      "-0.6729092730250981\n",
      "-0.6810841413467603\n",
      "-0.7997483574194045\n",
      "-0.6528506820175846\n",
      "-0.6799219772061962\n",
      "-0.7784610831261415\n",
      "-0.7044871398768724\n",
      "-0.675057401245489\n",
      "-0.7041076499260539\n",
      "-0.6660787949649644\n",
      "-0.6547855693082972\n",
      "-0.6697977565699564\n",
      "-0.7142602383913305\n",
      "-0.6476402606007459\n",
      "-0.673314878466293\n",
      "-0.6962493649375413\n",
      "-0.7257387465657621\n",
      "-0.8110547330286086\n",
      "-0.687551740400226\n",
      "-0.6030232055267764\n",
      "-0.6924147347955695\n",
      "-0.6616642488044965\n",
      "-0.6831108865933986\n",
      "-0.6576436358157907\n",
      "-0.7084356043774953\n",
      "-0.6553098058759216\n",
      "-0.66154302100433\n",
      "-0.6438848669139884\n",
      "-0.5828347413018744\n",
      "-0.6319036342033766\n",
      "-0.6427075675473325\n",
      "-0.46851328642647544\n",
      "-0.5587154599625687\n",
      "-0.7545402135757792\n",
      "-0.6370076712845437\n",
      "-0.6019004035370987\n",
      "-0.5804364867809053\n",
      "-0.6317249015993484\n",
      "-0.6193723875691468\n",
      "-0.59856827345784\n",
      "-0.6930069850277581\n",
      "-0.6793176815842589\n",
      "-0.7267517273598224\n",
      "-0.790558833784693\n",
      "-0.724443332942942\n",
      "-0.6816421176592717\n",
      "-0.6896885561589491\n",
      "-0.6969330314738794\n",
      "-0.703948938965792\n",
      "-0.5912533123923753\n",
      "-0.6259489479142957\n",
      "-0.6607101090565805\n",
      "-0.6090602081913157\n",
      "-0.6137216378246059\n",
      "-0.5978432968545745\n",
      "-0.656042196243551\n",
      "-0.738289694124451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6910275106984464\n",
      "-0.6540574380073649\n",
      "-0.6384966559255006\n",
      "-0.7000573813610197\n",
      "-0.6131458479313457\n",
      "-0.7009237284642349\n",
      "-0.7535535278114891\n",
      "-0.7280011357505588\n",
      "-0.650926762993585\n",
      "-0.7521910881555262\n",
      "-0.6644470282887863\n",
      "-0.647736966578619\n",
      "-0.7190193608982532\n",
      "-0.7142193386985735\n",
      "-0.6776945950293418\n",
      "-0.5973947831852487\n",
      "-0.5129443755751115\n",
      "-0.5790236580954978\n",
      "-0.6360914170931007\n",
      "-0.7138832264626145\n",
      "-0.6948372916089599\n",
      "-0.6440351587719509\n",
      "-0.6632311472678842\n",
      "-0.7110398926957076\n",
      "-0.7547494107137237\n",
      "-0.6962447273238109\n",
      "-0.5531826385853726\n",
      "-0.6728028189959688\n",
      "-0.8165895796225952\n",
      "-0.8203852455452137\n",
      "-0.8364980954426332\n",
      "-0.7585834794123945\n",
      "-0.80461559414114\n",
      "-0.6975751254971773\n",
      "-0.8242604241361239\n",
      "-0.7323458854268459\n",
      "-0.7119554972636144\n",
      "-0.7020602745409424\n",
      "-0.6892964173305866\n",
      "-0.6119317179080939\n",
      "-0.6892262083841576\n",
      "-0.6995910787539046\n",
      "-0.7909957701801931\n",
      "-0.7895051079500918\n",
      "-0.7964535056233384\n",
      "-0.7087745661387632\n",
      "-0.6459822783187401\n",
      "-0.719196089440568\n",
      "-0.704344122725405\n",
      "-0.8352404993763904\n",
      "-0.718088236875429\n",
      "-0.6221459766219543\n",
      "-0.6939396468370357\n",
      "-0.6338060782605716\n",
      "-0.7015412120942797\n",
      "-0.7980198680916287\n",
      "-0.8123431333964558\n",
      "-0.7476655586409822\n",
      "-0.7791771168796354\n",
      "-0.8311229979313635\n",
      "-0.8022385229813128\n",
      "-0.7843710331619456\n",
      "-0.7336352179215347\n",
      "-0.6936853202237822\n",
      "-0.7359295867028649\n",
      "-0.729469941682772\n",
      "-0.8058524676607515\n",
      "-0.7574286496615462\n",
      "-0.7163274864807626\n",
      "-0.6859739414348258\n",
      "-0.7786277587449407\n",
      "-0.6195829160763893\n",
      "-0.7803377185686577\n",
      "-0.7022668553119824\n",
      "-0.6763620287055911\n",
      "-0.7927521560608364\n",
      "-0.8070036205259634\n",
      "-0.6821870853058383\n",
      "-0.8041052002660934\n",
      "-0.7109121319135407\n",
      "-0.7662222687460943\n",
      "-0.7728234020322094\n",
      "-0.7195559168074451\n",
      "-0.7319791891603027\n",
      "-0.8002386326996841\n",
      "-0.8445916416038174\n",
      "-0.7554864294006929\n",
      "-0.7457688608334485\n",
      "-0.7781512966603887\n",
      "-0.6934585022114989\n",
      "-0.8063451269654476\n",
      "-0.7458117858272792\n",
      "-0.7713519677062084\n",
      "-0.6651323915634291\n",
      "-0.7881407087178378\n",
      "-0.7455599745937176\n",
      "-0.9192868430036926\n",
      "-0.8794542381147562\n",
      "-0.8032877456338567\n",
      "-0.8844274192676411\n",
      "-0.933233319696599\n",
      "-0.8055763340889708\n",
      "-0.8905968993663483\n",
      "-0.7856553080597104\n",
      "-0.6350259547184349\n",
      "-0.6792540585841947\n",
      "-0.740988103914298\n",
      "-0.7250781541152919\n",
      "-0.7176735671446202\n",
      "-0.7937185498537805\n",
      "-0.8135955205385648\n",
      "-0.7413409380258866\n",
      "-0.8099692096432545\n",
      "-0.7956775377901384\n",
      "-0.7566049765613014\n",
      "-0.8256590603472481\n",
      "-0.6857419688849756\n",
      "-0.7534706714292787\n",
      "-0.7121804974034244\n",
      "-0.6979111776426918\n",
      "-0.7145308949292093\n",
      "-0.7674212941206606\n",
      "-0.6781972641089933\n",
      "-0.6905807573413805\n",
      "-0.8361648033370164\n",
      "-0.8149264158315154\n",
      "-0.8597672397974512\n",
      "-0.7985044358010085\n",
      "-0.835770757143726\n",
      "-0.7967163750600983\n",
      "-0.7696023439170517\n",
      "-0.7352426526544321\n",
      "-0.8248873282704732\n",
      "-0.8431586371335134\n",
      "-0.8650868538592696\n",
      "-0.8509190570786476\n",
      "-0.8244588940266018\n",
      "-0.7743393718519483\n",
      "-0.7955466786605068\n",
      "-0.8651174787640512\n",
      "-0.8704030456139205\n",
      "-0.9092697917847002\n",
      "-0.8612470988281745\n",
      "-0.7347831437052987\n",
      "-0.8330095929503942\n",
      "-0.7374087890174958\n",
      "-0.7619518292943733\n",
      "-0.8162847535183202\n",
      "-0.7195264962561515\n",
      "-0.7503938246473798\n",
      "-0.7782998696588106\n",
      "-0.8542532164982664\n",
      "-0.7126199657474885\n",
      "-0.815688159670067\n",
      "-0.7528584844002892\n",
      "-0.8532663983266335\n",
      "-0.8569191291110996\n",
      "-0.7701967740526706\n",
      "-0.7353976778499202\n",
      "-0.8533695646590714\n",
      "-0.8114383046261294\n",
      "-0.7784175820455972\n",
      "-0.7219383070410325\n",
      "-0.7889153959357459\n",
      "-0.8367419481726943\n",
      "-0.7974558134831401\n",
      "-0.8809426347755583\n",
      "-0.7859808087279796\n",
      "-0.779679897967672\n",
      "-0.8211088975764137\n",
      "-0.8924835597730345\n",
      "-0.7756104669781861\n",
      "-0.7865031691479908\n",
      "-0.7575082145915949\n",
      "-0.8050036006896104\n",
      "-0.836473107740678\n",
      "-0.8724993416798454\n",
      "-0.7915729242316429\n",
      "-0.745407138534292\n",
      "-0.7698739667780912\n",
      "-0.8362686932516056\n",
      "-0.728393559992818\n",
      "-0.7668584048191143\n",
      "-0.7392385985101546\n",
      "-0.8576388624339691\n",
      "-0.698706958063625\n",
      "-0.7665461193774762\n",
      "-0.6772960381540301\n",
      "-0.7614701974509099\n",
      "-0.8345480478261539\n",
      "-0.7929454599055006\n",
      "-0.7571038764268516\n",
      "-0.8051434844780748\n",
      "-0.7512852173076614\n",
      "-0.8254134915606005\n",
      "-0.8514246262402576\n",
      "-0.7421725339354766\n",
      "-0.8095520157008644\n",
      "-0.7165220584488953\n",
      "-0.7960236303066126\n",
      "-0.7672139006729155\n",
      "-0.8745164188401845\n",
      "-0.8027716554529357\n",
      "-0.9263405632997203\n",
      "-0.8833483448201347\n",
      "-0.7372749922772339\n",
      "-0.7662480844360954\n",
      "-0.80363106647706\n",
      "-0.7749875232732149\n",
      "-0.7835539065191283\n",
      "-0.8672554914434782\n",
      "-0.8915498012476213\n",
      "-0.9144182868998662\n",
      "-0.9250218565340244\n",
      "-0.8214999781334338\n",
      "-0.7546586123540167\n",
      "-0.7657553353156322\n",
      "-0.8051817995466393\n",
      "-0.722006900115512\n",
      "-0.7424832993029004\n",
      "-0.7386268438644493\n",
      "-0.8228749008872518\n",
      "-0.8618219586034829\n",
      "-0.8018724358262604\n",
      "-0.8228679049719668\n",
      "-0.7558704929119568\n",
      "-0.8325781058177388\n",
      "-0.7986124024137461\n",
      "-0.8809889420421183\n",
      "-0.988975283642062\n",
      "-0.9747277458078576\n",
      "-0.8829219681397603\n",
      "-0.8790917163524167\n",
      "-0.9216686260461895\n",
      "-0.9297038283609809\n",
      "-0.9972016271116612\n",
      "-0.9256104978705928\n",
      "-0.870096308230641\n",
      "-0.9395899983859424\n",
      "-0.8368658976856731\n",
      "-0.7891029728777685\n",
      "-0.731979839779878\n",
      "-0.8497369509616798\n",
      "-0.8083446584650705\n",
      "-0.9112250796001965\n",
      "-0.8009715413941892\n",
      "-0.7513048788263772\n",
      "-0.8830164938847899\n",
      "-0.745588107077842\n",
      "-0.8502089706192816\n",
      "-0.9677235002672168\n",
      "-0.8999005410013393\n",
      "-0.9536636594182164\n",
      "-0.8329007047480718\n",
      "-0.7514889212393003\n",
      "-0.847809699327239\n",
      "-0.8407990737431227\n",
      "-0.8002799466147633\n",
      "-0.8084807439405138\n",
      "-0.8084206486263531\n",
      "-0.8130257739704426\n",
      "-0.8609075790559126\n",
      "-0.7739647651036792\n",
      "-0.8376739208843578\n",
      "-0.8621744265998897\n",
      "-0.7038872762709429\n",
      "-0.7286788891164202\n",
      "-0.8182013635680926\n",
      "-0.6889309407349508\n",
      "-0.765281743994993\n",
      "-0.7606676215245282\n",
      "-0.7761651483807257\n",
      "-0.716364483954156\n",
      "-0.8058574227656531\n",
      "-0.7781133223733784\n",
      "-0.8518854131663013\n",
      "-0.784597977167342\n",
      "-0.7881322075017403\n",
      "-0.8328284381307686\n",
      "-0.7490111961230098\n",
      "-0.8024364628603953\n",
      "-0.8916508585792721\n",
      "-0.870441335476071\n",
      "-0.7722041496349141\n",
      "-0.7345583842051304\n",
      "-0.7395985947666958\n",
      "-0.8589890116782365\n",
      "-0.9064373510271239\n",
      "-0.9182670407715\n",
      "-0.8925191699830382\n",
      "-0.8565801231915618\n",
      "-0.8770578852258023\n",
      "-0.7790428624436138\n",
      "-0.8429262003267066\n",
      "-0.8201948876142794\n",
      "-0.868517035658322\n",
      "-0.8870386501034476\n",
      "-0.8466865311952565\n",
      "-0.8540291551304424\n",
      "-0.9494909037768425\n",
      "-0.904156802344869\n",
      "-0.8474291351841317\n",
      "-0.7493380823597151\n",
      "-0.9170514232679297\n",
      "-0.876576565460925\n",
      "-0.7924851160703896\n",
      "-0.8034663398636581\n",
      "-0.8127139952024599\n",
      "-0.773937808723154\n",
      "-0.8823085788643771\n",
      "-0.9742785188142451\n",
      "-0.8694556829451324\n",
      "-0.9315514566691212\n",
      "-0.8589823544724748\n",
      "-0.9235572997410243\n",
      "-0.9351626906073548\n",
      "-0.8240384968567062\n",
      "-0.8303856220631105\n",
      "-0.7849016542412353\n",
      "-0.6985287439626453\n",
      "-0.6583567802525856\n",
      "-0.6425717332781675\n",
      "-0.7049119857199311\n",
      "-0.688169616383432\n",
      "-0.6365023027239272\n",
      "-0.6848560893764579\n",
      "-0.8087126502159562\n",
      "-0.7934774905277182\n",
      "-0.8443828464989707\n",
      "-0.8407414254670251\n",
      "-0.9457096619776426\n",
      "-0.849704358713522\n",
      "-0.853034949981084\n",
      "-0.8526166715872285\n",
      "-0.7987426020408537\n",
      "-0.885899107158023\n",
      "-0.9162421142056689\n",
      "-0.7819068690936629\n",
      "-0.8128888493113974\n",
      "-0.8563901590884361\n",
      "-0.7951287151998347\n",
      "-0.8423438567965121\n",
      "-0.8210605529657456\n",
      "-0.8374633497143524\n",
      "-0.8642249877128112\n",
      "-0.7143424004117743\n",
      "-0.863034460133996\n",
      "-0.8749302228372017\n",
      "-0.8427884982169797\n",
      "-0.7621526626714068\n",
      "-0.7698669151632278\n",
      "-0.8653634433259298\n",
      "-0.8097332844316616\n",
      "-0.8183476631795926\n",
      "-0.7995330914922852\n",
      "-0.7560186083696177\n",
      "-0.7548066515076394\n",
      "-0.7979682184962641\n",
      "-0.7615296718462177\n",
      "-0.7216746263297503\n",
      "-0.8230325350741096\n",
      "-0.8253860185150234\n",
      "-0.8526947590211305\n",
      "-0.7952933793240403\n",
      "-0.7614999438203947\n",
      "-0.8246061034081636\n",
      "-0.8329722711263692\n",
      "-0.8154303394973779\n",
      "-0.8996318583413071\n",
      "-0.903352015499994\n",
      "-1.000651512402156\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "env = Ascento()\n",
    "env.reset_model()\n",
    "m1 = []\n",
    "m2 = []\n",
    "m3 = []\n",
    "m4 = []\n",
    "\n",
    "for i_episode in range(15):\n",
    "    observation = env.reset()\n",
    "    done = None\n",
    "    while not done:\n",
    "        env.render()\n",
    "        print(env.vx)\n",
    "        action, _ = model.predict(env._get_obs())\n",
    "        m1.append(action[0])\n",
    "        m2.append(action[1])\n",
    "        m3.append(action[2])\n",
    "        m4.append(action[3])\n",
    "#         action[2] = 1\n",
    "#         action[3] = 1\n",
    "\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(m3[:1000])\n",
    "plt.plot(m4[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
