{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install squaternion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gym\n",
    "import time\n",
    "from ascento_gym import Ascento\n",
    "# from balance_pend import InvertedPendulumEnv as Ascento\n",
    "from stable_baselines3 import PPO, DDPG, SAC\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# env = Ascento()\n",
    "# env.reset_model()\n",
    "# for i_episode in range(150):\n",
    "#     observation = env.reset()\n",
    "#     done = None\n",
    "#     while not done:\n",
    "#         env.render()\n",
    "# #         print(env.yaw)\n",
    "#         action = env.action_space.sample()\n",
    "# #         action[2] = 1\n",
    "# #         action[3] = 1\n",
    "\n",
    "#         observation, reward, done, info = env.step(action)\n",
    "        \n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\n"
     ]
    }
   ],
   "source": [
    "env = Ascento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00630185, -0.00610593,  0.00697123, -0.0171266 , -0.01993565,\n",
       "       -0.01507844,  0.00116767,  0.00616349, -0.00552244, -0.00734333,\n",
       "        0.00606152,  0.00253454])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1. -1. -1. -1.], [1. 1. 1. 1.], (4,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.36021268, -0.8051224 ,  0.49500093,  0.2233509 ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf -inf], [inf inf inf inf inf inf inf inf inf inf inf inf], (12,), float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.51159374, -0.6171539 ,  0.39161395, -1.05690847,  0.08634642,\n",
       "        0.07779644, -0.62138438, -1.15849097,  1.17287362,  0.47127434,\n",
       "       -0.17946263, -0.31566511])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.env_util import make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_env = make_vec_env(Ascento, n_envs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Ascento()\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'models_ascento')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold = 20*1e5, verbose = 1)\n",
    "\n",
    "eval_callback = EvalCallback(env, callback_on_new_best = stop_callback,\n",
    "                            eval_freq = 5000, best_model_save_path = save_path, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "logs_dir = os.path.join('Training', 'logs_dir_ascento')\n",
    "model = PPO('MlpPolicy', vec_env, verbose = 1, tensorboard_log = logs_dir, create_eval_env = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load('/home/bmsit/Ascento/jointed_limited/Training/models_ascento/best_model.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(\"/home/bmsit/Ascento/jointed_limited/Training/model_for_demo.zip\", env = vec_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/logs_dir_ascento/PPO_65\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.39e+03  |\n",
      "|    ep_rew_mean     | -1.46e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 1605      |\n",
      "|    iterations      | 1         |\n",
      "|    time_elapsed    | 1         |\n",
      "|    total_timesteps | 2048      |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.36e+03     |\n",
      "|    ep_rew_mean          | -1.52e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 1253         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014324198 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.25e+07     |\n",
      "|    n_updates            | 15920        |\n",
      "|    policy_gradient_loss | -0.00285     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 3.23e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5000, episode_reward=-185980.05 +/- 9127.81\n",
      "Episode length: 1418.80 +/- 28.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.42e+03     |\n",
      "|    mean_reward          | -1.86e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 5000         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010429877 |\n",
      "|    clip_fraction        | 0.00464      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.45e+07     |\n",
      "|    n_updates            | 15930        |\n",
      "|    policy_gradient_loss | -0.00329     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 6.66e+07     |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.38e+03  |\n",
      "|    ep_rew_mean     | -1.57e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 695       |\n",
      "|    iterations      | 3         |\n",
      "|    time_elapsed    | 8         |\n",
      "|    total_timesteps | 6144      |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | -1.59e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 759         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001139031 |\n",
      "|    clip_fraction        | 0.0107      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27e+07    |\n",
      "|    n_updates            | 15940       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    std                  | 0.257       |\n",
      "|    value_loss           | 3.36e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bmsit/.local/lib/python3.6/site-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=-187861.48 +/- 7272.71\n",
      "Episode length: 1402.20 +/- 20.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4e+03      |\n",
      "|    mean_reward          | -1.88e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013259506 |\n",
      "|    clip_fraction        | 0.00767      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.32e+07     |\n",
      "|    n_updates            | 15950        |\n",
      "|    policy_gradient_loss | -0.00333     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 6.99e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.2e+03   |\n",
      "|    ep_rew_mean     | -1.47e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 621       |\n",
      "|    iterations      | 5         |\n",
      "|    time_elapsed    | 16        |\n",
      "|    total_timesteps | 10240     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | -1.38e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 647          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 18           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012415783 |\n",
      "|    clip_fraction        | 0.00776      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.357        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.43e+07     |\n",
      "|    n_updates            | 15960        |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 4.17e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.27e+03     |\n",
      "|    ep_rew_mean          | -1.45e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 670          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012431081 |\n",
      "|    clip_fraction        | 0.00317      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.479        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.41e+05     |\n",
      "|    n_updates            | 15970        |\n",
      "|    policy_gradient_loss | -0.00234     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 1.12e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=15000, episode_reward=-176308.66 +/- 2274.63\n",
      "Episode length: 1420.00 +/- 10.53\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.42e+03      |\n",
      "|    mean_reward          | -1.76e+05     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 15000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00093850103 |\n",
      "|    clip_fraction        | 0.00439       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.73          |\n",
      "|    explained_variance   | 0.353         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.46e+07      |\n",
      "|    n_updates            | 15980         |\n",
      "|    policy_gradient_loss | -0.000356     |\n",
      "|    std                  | 0.257         |\n",
      "|    value_loss           | 7.05e+07      |\n",
      "-------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.27e+03  |\n",
      "|    ep_rew_mean     | -1.45e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 8         |\n",
      "|    time_elapsed    | 32        |\n",
      "|    total_timesteps | 16384     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.27e+03     |\n",
      "|    ep_rew_mean          | -1.45e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 533          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 34           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018160262 |\n",
      "|    clip_fraction        | 0.000537     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+04     |\n",
      "|    n_updates            | 15990        |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 8.77e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=93916.70 +/- 9469.27\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 9.39e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013948031 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.85e+03    |\n",
      "|    n_updates            | 16000       |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    std                  | 0.257       |\n",
      "|    value_loss           | 4.98e+04    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -1.24e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 402       |\n",
      "|    iterations      | 10        |\n",
      "|    time_elapsed    | 50        |\n",
      "|    total_timesteps | 20480     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | -1.24e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 426          |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 52           |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012926473 |\n",
      "|    clip_fraction        | 0.00508      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.76e+06     |\n",
      "|    n_updates            | 16010        |\n",
      "|    policy_gradient_loss | -0.00132     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 2.88e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | -1.24e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 449          |\n",
      "|    iterations           | 12           |\n",
      "|    time_elapsed         | 54           |\n",
      "|    total_timesteps      | 24576        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039403383 |\n",
      "|    clip_fraction        | 0.00732      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.27e+03     |\n",
      "|    n_updates            | 16020        |\n",
      "|    policy_gradient_loss | -0.00249     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 2.8e+04      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=25000, episode_reward=58434.32 +/- 85503.15\n",
      "Episode length: 4015.00 +/- 1970.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.02e+03    |\n",
      "|    mean_reward          | 5.84e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 25000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007530708 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69e+03    |\n",
      "|    n_updates            | 16030       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 9.95e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.09e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 402       |\n",
      "|    iterations      | 13        |\n",
      "|    time_elapsed    | 66        |\n",
      "|    total_timesteps | 26624     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.66e+03    |\n",
      "|    ep_rew_mean          | -1.19e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 421         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006756978 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.326       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.37e+06    |\n",
      "|    n_updates            | 16040       |\n",
      "|    policy_gradient_loss | -0.00509    |\n",
      "|    std                  | 0.257       |\n",
      "|    value_loss           | 1.51e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=53234.49 +/- 82441.82\n",
      "Episode length: 4013.80 +/- 1972.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.01e+03     |\n",
      "|    mean_reward          | 5.32e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020256676 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.67e+07     |\n",
      "|    n_updates            | 16050        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 0.257        |\n",
      "|    value_loss           | 8.47e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -1.19e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 386       |\n",
      "|    iterations      | 15        |\n",
      "|    time_elapsed    | 79        |\n",
      "|    total_timesteps | 30720     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.66e+03    |\n",
      "|    ep_rew_mean          | -1.19e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 403         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005318839 |\n",
      "|    clip_fraction        | 0.0112      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.75e+04    |\n",
      "|    n_updates            | 16060       |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    std                  | 0.257       |\n",
      "|    value_loss           | 8.57e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | -1.09e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 83          |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006943973 |\n",
      "|    clip_fraction        | 0.0696      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.4e+03     |\n",
      "|    n_updates            | 16070       |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 1.54e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=35000, episode_reward=-291494.72 +/- 90114.85\n",
      "Episode length: 1463.60 +/- 70.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.46e+03    |\n",
      "|    mean_reward          | -2.91e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 35000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001391791 |\n",
      "|    clip_fraction        | 0.00664     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.42e+06    |\n",
      "|    n_updates            | 16080       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 2.92e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.8e+03   |\n",
      "|    ep_rew_mean     | -1.12e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 416       |\n",
      "|    iterations      | 18        |\n",
      "|    time_elapsed    | 88        |\n",
      "|    total_timesteps | 36864     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -1.1e+05     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 430          |\n",
      "|    iterations           | 19           |\n",
      "|    time_elapsed         | 90           |\n",
      "|    total_timesteps      | 38912        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015214568 |\n",
      "|    clip_fraction        | 0.0083       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.351        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.36e+07     |\n",
      "|    n_updates            | 16090        |\n",
      "|    policy_gradient_loss | -0.00157     |\n",
      "|    std                  | 0.256        |\n",
      "|    value_loss           | 3.91e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=-350022.91 +/- 5908.19\n",
      "Episode length: 1508.00 +/- 34.75\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.51e+03      |\n",
      "|    mean_reward          | -3.5e+05      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 40000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084180175 |\n",
      "|    clip_fraction        | 0.00605       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.73          |\n",
      "|    explained_variance   | 0.368         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.23e+07      |\n",
      "|    n_updates            | 16100         |\n",
      "|    policy_gradient_loss | -0.00106      |\n",
      "|    std                  | 0.256         |\n",
      "|    value_loss           | 4.77e+07      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.77e+03  |\n",
      "|    ep_rew_mean     | -1.16e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 426       |\n",
      "|    iterations      | 20        |\n",
      "|    time_elapsed    | 96        |\n",
      "|    total_timesteps | 40960     |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.77e+03  |\n",
      "|    ep_rew_mean          | -1.16e+05 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 439       |\n",
      "|    iterations           | 21        |\n",
      "|    time_elapsed         | 97        |\n",
      "|    total_timesteps      | 43008     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0023173 |\n",
      "|    clip_fraction        | 0.00645   |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 1.73      |\n",
      "|    explained_variance   | 0.478     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.07e+06  |\n",
      "|    n_updates            | 16110     |\n",
      "|    policy_gradient_loss | -0.00345  |\n",
      "|    std                  | 0.256     |\n",
      "|    value_loss           | 1.09e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=45000, episode_reward=48398.03 +/- 80590.69\n",
      "Episode length: 4015.20 +/- 1969.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.02e+03    |\n",
      "|    mean_reward          | 4.84e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 45000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005292947 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.854       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 16120       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 1.25e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.84e+03  |\n",
      "|    ep_rew_mean     | -1.08e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 411       |\n",
      "|    iterations      | 22        |\n",
      "|    time_elapsed    | 109       |\n",
      "|    total_timesteps | 45056     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.82e+03    |\n",
      "|    ep_rew_mean          | -1.06e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 423         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 111         |\n",
      "|    total_timesteps      | 47104       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007848535 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.09e+06    |\n",
      "|    n_updates            | 16130       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 1.41e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.82e+03     |\n",
      "|    ep_rew_mean          | -1.06e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 434          |\n",
      "|    iterations           | 24           |\n",
      "|    time_elapsed         | 113          |\n",
      "|    total_timesteps      | 49152        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023046418 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.96e+06     |\n",
      "|    n_updates            | 16140        |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    std                  | 0.256        |\n",
      "|    value_loss           | 1.19e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=83699.15 +/- 7521.96\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 8.37e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 50000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01047367 |\n",
      "|    clip_fraction        | 0.045      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.73       |\n",
      "|    explained_variance   | 0.755      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.88e+03   |\n",
      "|    n_updates            | 16150      |\n",
      "|    policy_gradient_loss | -0.00226   |\n",
      "|    std                  | 0.256      |\n",
      "|    value_loss           | 1.57e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.95e+03  |\n",
      "|    ep_rew_mean     | -9.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 394       |\n",
      "|    iterations      | 25        |\n",
      "|    time_elapsed    | 129       |\n",
      "|    total_timesteps | 51200     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.93e+03    |\n",
      "|    ep_rew_mean          | -9.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 399         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 133         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013325127 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.73        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 810         |\n",
      "|    n_updates            | 16160       |\n",
      "|    policy_gradient_loss | -0.00418    |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 6.87e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=55000, episode_reward=-300789.61 +/- 7589.49\n",
      "Episode length: 1393.20 +/- 32.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.39e+03    |\n",
      "|    mean_reward          | -3.01e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 55000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006947421 |\n",
      "|    clip_fraction        | 0.0257      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.64e+07    |\n",
      "|    n_updates            | 16170       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    std                  | 0.256       |\n",
      "|    value_loss           | 1.38e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.85e+03  |\n",
      "|    ep_rew_mean     | -1.04e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 389       |\n",
      "|    iterations      | 27        |\n",
      "|    time_elapsed    | 141       |\n",
      "|    total_timesteps | 55296     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.85e+03     |\n",
      "|    ep_rew_mean          | -1.04e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 397          |\n",
      "|    iterations           | 28           |\n",
      "|    time_elapsed         | 144          |\n",
      "|    total_timesteps      | 57344        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021875403 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.44e+07     |\n",
      "|    n_updates            | 16180        |\n",
      "|    policy_gradient_loss | -0.00178     |\n",
      "|    std                  | 0.256        |\n",
      "|    value_loss           | 6.97e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.95e+03   |\n",
      "|    ep_rew_mean          | -9.73e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 29         |\n",
      "|    time_elapsed         | 147        |\n",
      "|    total_timesteps      | 59392      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00686205 |\n",
      "|    clip_fraction        | 0.0803     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.74       |\n",
      "|    explained_variance   | 0.809      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.42e+03   |\n",
      "|    n_updates            | 16190      |\n",
      "|    policy_gradient_loss | -0.00169   |\n",
      "|    std                  | 0.255      |\n",
      "|    value_loss           | 6.51e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-157830.35 +/- 59707.67\n",
      "Episode length: 566.00 +/- 608.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 566         |\n",
      "|    mean_reward          | -1.58e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041293006 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 325         |\n",
      "|    n_updates            | 16200       |\n",
      "|    policy_gradient_loss | 0.0223      |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 1.93e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -1.06e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 404       |\n",
      "|    iterations      | 30        |\n",
      "|    time_elapsed    | 152       |\n",
      "|    total_timesteps | 61440     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.86e+03   |\n",
      "|    ep_rew_mean          | -1.16e+05  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 407        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 155        |\n",
      "|    total_timesteps      | 63488      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00818955 |\n",
      "|    clip_fraction        | 0.148      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.74       |\n",
      "|    explained_variance   | 0.37       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.94e+07   |\n",
      "|    n_updates            | 16210      |\n",
      "|    policy_gradient_loss | -0.00188   |\n",
      "|    std                  | 0.255      |\n",
      "|    value_loss           | 6.99e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=65000, episode_reward=-214391.91 +/- 91649.94\n",
      "Episode length: 862.00 +/- 648.61\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 862          |\n",
      "|    mean_reward          | -2.14e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 65000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037428609 |\n",
      "|    clip_fraction        | 0.0336       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.74         |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.84e+07     |\n",
      "|    n_updates            | 16220        |\n",
      "|    policy_gradient_loss | -0.00582     |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 1.14e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -1.19e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 402       |\n",
      "|    iterations      | 32        |\n",
      "|    time_elapsed    | 162       |\n",
      "|    total_timesteps | 65536     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | -1.23e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 407         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 165         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004765887 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.53e+07    |\n",
      "|    n_updates            | 16230       |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 6.17e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | -1.22e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 408          |\n",
      "|    iterations           | 34           |\n",
      "|    time_elapsed         | 170          |\n",
      "|    total_timesteps      | 69632        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027060467 |\n",
      "|    clip_fraction        | 0.0125       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.74         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.15e+07     |\n",
      "|    n_updates            | 16240        |\n",
      "|    policy_gradient_loss | -0.00108     |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 9.26e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-243020.22 +/- 114123.35\n",
      "Episode length: 903.00 +/- 689.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 903          |\n",
      "|    mean_reward          | -2.43e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 70000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049746046 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.74         |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+07     |\n",
      "|    n_updates            | 16250        |\n",
      "|    policy_gradient_loss | 0.00119      |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 2.55e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -1.26e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 408       |\n",
      "|    iterations      | 35        |\n",
      "|    time_elapsed    | 175       |\n",
      "|    total_timesteps | 71680     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.71e+03    |\n",
      "|    ep_rew_mean          | -1.33e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 415         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 177         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005198785 |\n",
      "|    clip_fraction        | 0.0411      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.402       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.89e+07    |\n",
      "|    n_updates            | 16260       |\n",
      "|    policy_gradient_loss | -0.00641    |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 5.03e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=75000, episode_reward=-237186.95 +/- 65623.49\n",
      "Episode length: 1139.80 +/- 541.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.14e+03    |\n",
      "|    mean_reward          | -2.37e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 75000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004366169 |\n",
      "|    clip_fraction        | 0.0236      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.33e+07    |\n",
      "|    n_updates            | 16270       |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 1.07e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.7e+03   |\n",
      "|    ep_rew_mean     | -1.36e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 416       |\n",
      "|    iterations      | 37        |\n",
      "|    time_elapsed    | 181       |\n",
      "|    total_timesteps | 75776     |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -1.36e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 423          |\n",
      "|    iterations           | 38           |\n",
      "|    time_elapsed         | 183          |\n",
      "|    total_timesteps      | 77824        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046726493 |\n",
      "|    clip_fraction        | 0.0468       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.74         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.01e+07     |\n",
      "|    n_updates            | 16280        |\n",
      "|    policy_gradient_loss | -0.00472     |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 4.69e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -1.36e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 430          |\n",
      "|    iterations           | 39           |\n",
      "|    time_elapsed         | 185          |\n",
      "|    total_timesteps      | 79872        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044561336 |\n",
      "|    clip_fraction        | 0.00898      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.73         |\n",
      "|    explained_variance   | 0.889        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.76e+04     |\n",
      "|    n_updates            | 16290        |\n",
      "|    policy_gradient_loss | -0.00209     |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 1.21e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=80000, episode_reward=-225111.77 +/- 168352.48\n",
      "Episode length: 2251.20 +/- 1375.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.25e+03    |\n",
      "|    mean_reward          | -2.25e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014772965 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.94e+03    |\n",
      "|    n_updates            | 16300       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 3.14e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.77e+03 |\n",
      "|    ep_rew_mean     | -1.3e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 424      |\n",
      "|    iterations      | 40       |\n",
      "|    time_elapsed    | 192      |\n",
      "|    total_timesteps | 81920    |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | -1.3e+05    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 431         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 194         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008186188 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2e+06       |\n",
      "|    n_updates            | 16310       |\n",
      "|    policy_gradient_loss | 0.0029      |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 2.17e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=85000, episode_reward=85235.65 +/- 4530.08\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 8.52e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 85000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055154893 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.74         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.41e+06     |\n",
      "|    n_updates            | 16320        |\n",
      "|    policy_gradient_loss | 0.00806      |\n",
      "|    std                  | 0.255        |\n",
      "|    value_loss           | 2.45e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.77e+03  |\n",
      "|    ep_rew_mean     | -1.29e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 412       |\n",
      "|    iterations      | 42        |\n",
      "|    time_elapsed    | 208       |\n",
      "|    total_timesteps | 86016     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.77e+03   |\n",
      "|    ep_rew_mean          | -1.29e+05  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 418        |\n",
      "|    iterations           | 43         |\n",
      "|    time_elapsed         | 210        |\n",
      "|    total_timesteps      | 88064      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00928269 |\n",
      "|    clip_fraction        | 0.032      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.73       |\n",
      "|    explained_variance   | 0.375      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.46e+07   |\n",
      "|    n_updates            | 16330      |\n",
      "|    policy_gradient_loss | 0.00187    |\n",
      "|    std                  | 0.255      |\n",
      "|    value_loss           | 2.82e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=90000, episode_reward=91387.55 +/- 2468.42\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 9.14e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 90000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006735846 |\n",
      "|    clip_fraction        | 0.0499      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.47e+03    |\n",
      "|    n_updates            | 16340       |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    std                  | 0.255       |\n",
      "|    value_loss           | 3.2e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.83e+03  |\n",
      "|    ep_rew_mean     | -1.25e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 402       |\n",
      "|    iterations      | 44        |\n",
      "|    time_elapsed    | 224       |\n",
      "|    total_timesteps | 90112     |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | -1.25e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 407         |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 225         |\n",
      "|    total_timesteps      | 92160       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014222599 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.74        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 244         |\n",
      "|    n_updates            | 16350       |\n",
      "|    policy_gradient_loss | 0.000431    |\n",
      "|    std                  | 0.254       |\n",
      "|    value_loss           | 1.84e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.83e+03   |\n",
      "|    ep_rew_mean          | -1.25e+05  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 413        |\n",
      "|    iterations           | 46         |\n",
      "|    time_elapsed         | 227        |\n",
      "|    total_timesteps      | 94208      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.13459952 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.75       |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.46e+07   |\n",
      "|    n_updates            | 16360      |\n",
      "|    policy_gradient_loss | 0.0018     |\n",
      "|    std                  | 0.254      |\n",
      "|    value_loss           | 2.91e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=95000, episode_reward=89151.23 +/- 7558.76\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.92e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 95000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006831254 |\n",
      "|    clip_fraction        | 0.0742      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.75        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 949         |\n",
      "|    n_updates            | 16370       |\n",
      "|    policy_gradient_loss | 0.00031     |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 2.97e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.83e+03  |\n",
      "|    ep_rew_mean     | -1.25e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 398       |\n",
      "|    iterations      | 47        |\n",
      "|    time_elapsed    | 241       |\n",
      "|    total_timesteps | 96256     |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.89e+03   |\n",
      "|    ep_rew_mean          | -1.21e+05  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 403        |\n",
      "|    iterations           | 48         |\n",
      "|    time_elapsed         | 243        |\n",
      "|    total_timesteps      | 98304      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05697763 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.75       |\n",
      "|    explained_variance   | 0.913      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 687        |\n",
      "|    n_updates            | 16380      |\n",
      "|    policy_gradient_loss | -0.0037    |\n",
      "|    std                  | 0.253      |\n",
      "|    value_loss           | 1.94e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=100000, episode_reward=98159.60 +/- 2472.95\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 9.82e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 100000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043737506 |\n",
      "|    clip_fraction        | 0.0923       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.75         |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.31e+03     |\n",
      "|    n_updates            | 16390        |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    std                  | 0.253        |\n",
      "|    value_loss           | 1.4e+04      |\n",
      "------------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -1.21e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 390       |\n",
      "|    iterations      | 49        |\n",
      "|    time_elapsed    | 257       |\n",
      "|    total_timesteps | 100352    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -1.17e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 395         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 258         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021306073 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.76        |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 16400       |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    std                  | 0.253       |\n",
      "|    value_loss           | 2.17e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -1.17e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 400         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 260         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008761725 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.75        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 893         |\n",
      "|    n_updates            | 16410       |\n",
      "|    policy_gradient_loss | 0.00531     |\n",
      "|    std                  | 0.252       |\n",
      "|    value_loss           | 3.86e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=105000, episode_reward=96802.64 +/- 6031.93\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 9.68e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 105000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039712456 |\n",
      "|    clip_fraction        | 0.0372       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.76         |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 999          |\n",
      "|    n_updates            | 16420        |\n",
      "|    policy_gradient_loss | -0.00117     |\n",
      "|    std                  | 0.252        |\n",
      "|    value_loss           | 5.56e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.01e+03  |\n",
      "|    ep_rew_mean     | -1.13e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 388       |\n",
      "|    iterations      | 52        |\n",
      "|    time_elapsed    | 274       |\n",
      "|    total_timesteps | 106496    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | -1.13e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 276         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034161076 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.77        |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.58e+03    |\n",
      "|    n_updates            | 16430       |\n",
      "|    policy_gradient_loss | 0.00753     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 6.4e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=110000, episode_reward=99210.23 +/- 87.53\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 9.92e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009754102 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.78        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 559         |\n",
      "|    n_updates            | 16440       |\n",
      "|    policy_gradient_loss | 0.00187     |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 2.5e+03     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.01e+03  |\n",
      "|    ep_rew_mean     | -1.13e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 381       |\n",
      "|    iterations      | 54        |\n",
      "|    time_elapsed    | 289       |\n",
      "|    total_timesteps | 110592    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.06e+03   |\n",
      "|    ep_rew_mean          | -1.09e+05  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 386        |\n",
      "|    iterations           | 55         |\n",
      "|    time_elapsed         | 291        |\n",
      "|    total_timesteps      | 112640     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07974568 |\n",
      "|    clip_fraction        | 0.391      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.79       |\n",
      "|    explained_variance   | 0.832      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 43.5       |\n",
      "|    n_updates            | 16450      |\n",
      "|    policy_gradient_loss | 0.0268     |\n",
      "|    std                  | 0.25       |\n",
      "|    value_loss           | 319        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.06e+03     |\n",
      "|    ep_rew_mean          | -1.09e+05    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 390          |\n",
      "|    iterations           | 56           |\n",
      "|    time_elapsed         | 293          |\n",
      "|    total_timesteps      | 114688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074917916 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.79         |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 385          |\n",
      "|    n_updates            | 16460        |\n",
      "|    policy_gradient_loss | -0.000807    |\n",
      "|    std                  | 0.25         |\n",
      "|    value_loss           | 5.99e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=115000, episode_reward=93404.11 +/- 5235.00\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 9.34e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 115000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011337543 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 237         |\n",
      "|    n_updates            | 16470       |\n",
      "|    policy_gradient_loss | -0.00618    |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 2.3e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.12e+03  |\n",
      "|    ep_rew_mean     | -1.05e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 379       |\n",
      "|    iterations      | 57        |\n",
      "|    time_elapsed    | 307       |\n",
      "|    total_timesteps | 116736    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | -1.05e+05   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 383         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 309         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007991355 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.8         |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 734         |\n",
      "|    n_updates            | 16480       |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 9.92e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=120000, episode_reward=-13736.38 +/- 57845.21\n",
      "Episode length: 1389.00 +/- 193.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.39e+03    |\n",
      "|    mean_reward          | -1.37e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014473883 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 16490       |\n",
      "|    policy_gradient_loss | 0.0017      |\n",
      "|    std                  | 0.251       |\n",
      "|    value_loss           | 1.06e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.12e+03  |\n",
      "|    ep_rew_mean     | -1.05e+05 |\n",
      "| time/              |           |\n",
      "|    fps             | 384       |\n",
      "|    iterations      | 59        |\n",
      "|    time_elapsed    | 314       |\n",
      "|    total_timesteps | 120832    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.15e+03    |\n",
      "|    ep_rew_mean          | -9.94e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 388         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 316         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029590718 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.79        |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 16500       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    std                  | 0.25        |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.13e+03    |\n",
      "|    ep_rew_mean          | -9.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 318         |\n",
      "|    total_timesteps      | 124928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012034259 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.8         |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 701         |\n",
      "|    n_updates            | 16510       |\n",
      "|    policy_gradient_loss | 0.00271     |\n",
      "|    std                  | 0.249       |\n",
      "|    value_loss           | 1.41e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=125000, episode_reward=-49511.13 +/- 40211.28\n",
      "Episode length: 1131.60 +/- 90.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.13e+03     |\n",
      "|    mean_reward          | -4.95e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 125000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052873893 |\n",
      "|    clip_fraction        | 0.0565       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.81         |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.58e+03     |\n",
      "|    n_updates            | 16520        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.249        |\n",
      "|    value_loss           | 2.5e+04      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.1e+03   |\n",
      "|    ep_rew_mean     | -9.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 393       |\n",
      "|    iterations      | 62        |\n",
      "|    time_elapsed    | 322       |\n",
      "|    total_timesteps | 126976    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.1e+03    |\n",
      "|    ep_rew_mean          | -9.36e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 397        |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 324        |\n",
      "|    total_timesteps      | 129024     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03829232 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.82       |\n",
      "|    explained_variance   | 0.914      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 78.2       |\n",
      "|    n_updates            | 16530      |\n",
      "|    policy_gradient_loss | 0.0153     |\n",
      "|    std                  | 0.248      |\n",
      "|    value_loss           | 1.61e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=130000, episode_reward=-63197.85 +/- 36237.71\n",
      "Episode length: 1393.80 +/- 360.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.39e+03    |\n",
      "|    mean_reward          | -6.32e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008989291 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 16540       |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 1.2e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.1e+03   |\n",
      "|    ep_rew_mean     | -9.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 397       |\n",
      "|    iterations      | 64        |\n",
      "|    time_elapsed    | 329       |\n",
      "|    total_timesteps | 131072    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.08e+03     |\n",
      "|    ep_rew_mean          | -9.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 401          |\n",
      "|    iterations           | 65           |\n",
      "|    time_elapsed         | 331          |\n",
      "|    total_timesteps      | 133120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024383455 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.83         |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.06e+06     |\n",
      "|    n_updates            | 16550        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    std                  | 0.248        |\n",
      "|    value_loss           | 1.83e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=135000, episode_reward=-51426.38 +/- 45627.60\n",
      "Episode length: 1251.00 +/- 322.51\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.25e+03      |\n",
      "|    mean_reward          | -5.14e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 135000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00058344915 |\n",
      "|    clip_fraction        | 0.000635      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 1.83          |\n",
      "|    explained_variance   | 0.312         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.06e+07      |\n",
      "|    n_updates            | 16560         |\n",
      "|    policy_gradient_loss | -0.000928     |\n",
      "|    std                  | 0.248         |\n",
      "|    value_loss           | 5.17e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.07e+03  |\n",
      "|    ep_rew_mean     | -9.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 401       |\n",
      "|    iterations      | 66        |\n",
      "|    time_elapsed    | 336       |\n",
      "|    total_timesteps | 135168    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.06e+03    |\n",
      "|    ep_rew_mean          | -8.92e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 405         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 338         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005935199 |\n",
      "|    clip_fraction        | 0.0352      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.82e+06    |\n",
      "|    n_updates            | 16570       |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 7.76e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.04e+03    |\n",
      "|    ep_rew_mean          | -8.61e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 340         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006168292 |\n",
      "|    clip_fraction        | 0.0519      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.84e+03    |\n",
      "|    n_updates            | 16580       |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    std                  | 0.248       |\n",
      "|    value_loss           | 4.43e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=140000, episode_reward=18829.49 +/- 2604.77\n",
      "Episode length: 940.80 +/- 14.40\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 941          |\n",
      "|    mean_reward          | 1.88e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 140000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069120172 |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+03     |\n",
      "|    n_updates            | 16590        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    std                  | 0.247        |\n",
      "|    value_loss           | 1.79e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.01e+03  |\n",
      "|    ep_rew_mean     | -8.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 410       |\n",
      "|    iterations      | 69        |\n",
      "|    time_elapsed    | 344       |\n",
      "|    total_timesteps | 141312    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.01e+03   |\n",
      "|    ep_rew_mean          | -8.34e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 413        |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 346        |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01678216 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.84       |\n",
      "|    explained_variance   | 0.928      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.95e+04   |\n",
      "|    n_updates            | 16600      |\n",
      "|    policy_gradient_loss | 0.00203    |\n",
      "|    std                  | 0.247      |\n",
      "|    value_loss           | 6.64e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=145000, episode_reward=-18294.52 +/- 27674.41\n",
      "Episode length: 1554.80 +/- 291.98\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.55e+03     |\n",
      "|    mean_reward          | -1.83e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 145000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039109252 |\n",
      "|    clip_fraction        | 0.075        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.361        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.5e+04      |\n",
      "|    n_updates            | 16610        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    std                  | 0.247        |\n",
      "|    value_loss           | 2.04e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.98e+03  |\n",
      "|    ep_rew_mean     | -8.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 413       |\n",
      "|    iterations      | 71        |\n",
      "|    time_elapsed    | 351       |\n",
      "|    total_timesteps | 145408    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.96e+03    |\n",
      "|    ep_rew_mean          | -7.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 353         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056272104 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 133         |\n",
      "|    n_updates            | 16620       |\n",
      "|    policy_gradient_loss | 0.0101      |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 8.65e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.96e+03    |\n",
      "|    ep_rew_mean          | -7.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 420         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 355         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017005833 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 16630       |\n",
      "|    policy_gradient_loss | 0.00391     |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 3.7e+05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=150000, episode_reward=-71634.21 +/- 70521.21\n",
      "Episode length: 1320.00 +/- 258.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.32e+03     |\n",
      "|    mean_reward          | -7.16e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 150000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105045345 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.722        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 503          |\n",
      "|    n_updates            | 16640        |\n",
      "|    policy_gradient_loss | -0.000814    |\n",
      "|    std                  | 0.246        |\n",
      "|    value_loss           | 4.47e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.96e+03  |\n",
      "|    ep_rew_mean     | -7.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 420       |\n",
      "|    iterations      | 74        |\n",
      "|    time_elapsed    | 360       |\n",
      "|    total_timesteps | 151552    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.99e+03    |\n",
      "|    ep_rew_mean          | -7.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 423         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 362         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021434486 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 16650       |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 5.65e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=155000, episode_reward=-70537.11 +/- 51234.46\n",
      "Episode length: 2001.20 +/- 1501.66\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2e+03      |\n",
      "|    mean_reward          | -7.05e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 155000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00498379 |\n",
      "|    clip_fraction        | 0.0346     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.85       |\n",
      "|    explained_variance   | 0.323      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.94e+07   |\n",
      "|    n_updates            | 16660      |\n",
      "|    policy_gradient_loss | -0.00618   |\n",
      "|    std                  | 0.246      |\n",
      "|    value_loss           | 2.96e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.99e+03  |\n",
      "|    ep_rew_mean     | -7.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 421       |\n",
      "|    iterations      | 76        |\n",
      "|    time_elapsed    | 369       |\n",
      "|    total_timesteps | 155648    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.99e+03     |\n",
      "|    ep_rew_mean          | -7.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 425          |\n",
      "|    iterations           | 77           |\n",
      "|    time_elapsed         | 371          |\n",
      "|    total_timesteps      | 157696       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040151794 |\n",
      "|    clip_fraction        | 0.00894      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.86         |\n",
      "|    explained_variance   | 0.721        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.57e+03     |\n",
      "|    n_updates            | 16670        |\n",
      "|    policy_gradient_loss | -0.00159     |\n",
      "|    std                  | 0.246        |\n",
      "|    value_loss           | 8.38e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.02e+03   |\n",
      "|    ep_rew_mean          | -7.47e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 428        |\n",
      "|    iterations           | 78         |\n",
      "|    time_elapsed         | 372        |\n",
      "|    total_timesteps      | 159744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03236118 |\n",
      "|    clip_fraction        | 0.337      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.85       |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 172        |\n",
      "|    n_updates            | 16680      |\n",
      "|    policy_gradient_loss | 0.0212     |\n",
      "|    std                  | 0.247      |\n",
      "|    value_loss           | 947        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=160000, episode_reward=24196.44 +/- 98971.89\n",
      "Episode length: 3588.00 +/- 1730.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.59e+03    |\n",
      "|    mean_reward          | 2.42e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005625859 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.83        |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.14e+04    |\n",
      "|    n_updates            | 16690       |\n",
      "|    policy_gradient_loss | -0.000975   |\n",
      "|    std                  | 0.247       |\n",
      "|    value_loss           | 3.75e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.02e+03  |\n",
      "|    ep_rew_mean     | -7.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 422       |\n",
      "|    iterations      | 79        |\n",
      "|    time_elapsed    | 383       |\n",
      "|    total_timesteps | 161792    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.06e+03     |\n",
      "|    ep_rew_mean          | -7.25e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 425          |\n",
      "|    iterations           | 80           |\n",
      "|    time_elapsed         | 385          |\n",
      "|    total_timesteps      | 163840       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072049256 |\n",
      "|    clip_fraction        | 0.0647       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.56e+03     |\n",
      "|    n_updates            | 16700        |\n",
      "|    policy_gradient_loss | -0.00677     |\n",
      "|    std                  | 0.247        |\n",
      "|    value_loss           | 1.55e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=165000, episode_reward=-239105.70 +/- 80456.09\n",
      "Episode length: 2195.80 +/- 53.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.2e+03     |\n",
      "|    mean_reward          | -2.39e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 165000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012682907 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 404         |\n",
      "|    n_updates            | 16710       |\n",
      "|    policy_gradient_loss | 0.00211     |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 1.15e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.07e+03  |\n",
      "|    ep_rew_mean     | -8.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 422       |\n",
      "|    iterations      | 81        |\n",
      "|    time_elapsed    | 392       |\n",
      "|    total_timesteps | 165888    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.06e+03     |\n",
      "|    ep_rew_mean          | -8.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 426          |\n",
      "|    iterations           | 82           |\n",
      "|    time_elapsed         | 394          |\n",
      "|    total_timesteps      | 167936       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028674898 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.35         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.43e+07     |\n",
      "|    n_updates            | 16720        |\n",
      "|    policy_gradient_loss | -0.00016     |\n",
      "|    std                  | 0.246        |\n",
      "|    value_loss           | 1.64e+08     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.06e+03    |\n",
      "|    ep_rew_mean          | -8.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 429         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 395         |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019657724 |\n",
      "|    clip_fraction        | 0.0381      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.36e+06    |\n",
      "|    n_updates            | 16730       |\n",
      "|    policy_gradient_loss | 0.00231     |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 2.09e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=170000, episode_reward=-101932.02 +/- 20123.52\n",
      "Episode length: 2127.40 +/- 218.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.13e+03     |\n",
      "|    mean_reward          | -1.02e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 170000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058699637 |\n",
      "|    clip_fraction        | 0.0364       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.84         |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.38e+07     |\n",
      "|    n_updates            | 16740        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    std                  | 0.246        |\n",
      "|    value_loss           | 2.97e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.06e+03  |\n",
      "|    ep_rew_mean     | -8.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 426       |\n",
      "|    iterations      | 84        |\n",
      "|    time_elapsed    | 402       |\n",
      "|    total_timesteps | 172032    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.06e+03    |\n",
      "|    ep_rew_mean          | -8.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 430         |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 404         |\n",
      "|    total_timesteps      | 174080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006168478 |\n",
      "|    clip_fraction        | 0.0316      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.84        |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.03e+03    |\n",
      "|    n_updates            | 16750       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    std                  | 0.246       |\n",
      "|    value_loss           | 4.02e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=175000, episode_reward=-99616.36 +/- 58906.38\n",
      "Episode length: 1585.00 +/- 61.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.58e+03     |\n",
      "|    mean_reward          | -9.96e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 175000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061234282 |\n",
      "|    clip_fraction        | 0.0915       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.799        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 646          |\n",
      "|    n_updates            | 16760        |\n",
      "|    policy_gradient_loss | -0.00626     |\n",
      "|    std                  | 0.246        |\n",
      "|    value_loss           | 2.68e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.1e+03   |\n",
      "|    ep_rew_mean     | -8.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 429       |\n",
      "|    iterations      | 86        |\n",
      "|    time_elapsed    | 410       |\n",
      "|    total_timesteps | 176128    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.1e+03      |\n",
      "|    ep_rew_mean          | -8.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 432          |\n",
      "|    iterations           | 87           |\n",
      "|    time_elapsed         | 412          |\n",
      "|    total_timesteps      | 178176       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046925982 |\n",
      "|    clip_fraction        | 0.0264       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.85         |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.03e+04     |\n",
      "|    n_updates            | 16770        |\n",
      "|    policy_gradient_loss | -0.00152     |\n",
      "|    std                  | 0.246        |\n",
      "|    value_loss           | 2.04e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=180000, episode_reward=-125196.47 +/- 9537.52\n",
      "Episode length: 1350.40 +/- 115.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.35e+03    |\n",
      "|    mean_reward          | -1.25e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037337244 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.5        |\n",
      "|    n_updates            | 16780       |\n",
      "|    policy_gradient_loss | 0.0126      |\n",
      "|    std                  | 0.245       |\n",
      "|    value_loss           | 1.47e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.13e+03  |\n",
      "|    ep_rew_mean     | -7.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 431       |\n",
      "|    iterations      | 88        |\n",
      "|    time_elapsed    | 417       |\n",
      "|    total_timesteps | 180224    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.13e+03    |\n",
      "|    ep_rew_mean          | -7.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 434         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 419         |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007300075 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.13e+03    |\n",
      "|    n_updates            | 16790       |\n",
      "|    policy_gradient_loss | 0.0022      |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 8.95e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.17e+03    |\n",
      "|    ep_rew_mean          | -7.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 437         |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 421         |\n",
      "|    total_timesteps      | 184320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008331474 |\n",
      "|    clip_fraction        | 0.0818      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.87        |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 915         |\n",
      "|    n_updates            | 16800       |\n",
      "|    policy_gradient_loss | -0.00483    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 3.82e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=185000, episode_reward=-91400.62 +/- 52822.89\n",
      "Episode length: 1420.40 +/- 308.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.42e+03    |\n",
      "|    mean_reward          | -9.14e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 185000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014186873 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 752         |\n",
      "|    n_updates            | 16810       |\n",
      "|    policy_gradient_loss | 0.00231     |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 5.23e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.16e+03  |\n",
      "|    ep_rew_mean     | -7.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 437       |\n",
      "|    iterations      | 91        |\n",
      "|    time_elapsed    | 426       |\n",
      "|    total_timesteps | 186368    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.16e+03    |\n",
      "|    ep_rew_mean          | -7.72e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 439         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032900136 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.72e+03    |\n",
      "|    n_updates            | 16820       |\n",
      "|    policy_gradient_loss | 0.00121     |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 1.42e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=190000, episode_reward=-117753.23 +/- 16397.84\n",
      "Episode length: 1141.20 +/- 21.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.14e+03    |\n",
      "|    mean_reward          | -1.18e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002903125 |\n",
      "|    clip_fraction        | 0.0146      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78e+04    |\n",
      "|    n_updates            | 16830       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 9.36e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.16e+03  |\n",
      "|    ep_rew_mean     | -7.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 439       |\n",
      "|    iterations      | 93        |\n",
      "|    time_elapsed    | 432       |\n",
      "|    total_timesteps | 190464    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.18e+03    |\n",
      "|    ep_rew_mean          | -7.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 442         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005446462 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.11e+03    |\n",
      "|    n_updates            | 16840       |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 2.7e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.17e+03   |\n",
      "|    ep_rew_mean          | -7.66e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 445        |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 436        |\n",
      "|    total_timesteps      | 194560     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11407793 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.86       |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.11e+06   |\n",
      "|    n_updates            | 16850      |\n",
      "|    policy_gradient_loss | -0.000565  |\n",
      "|    std                  | 0.244      |\n",
      "|    value_loss           | 2.92e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=195000, episode_reward=-86060.06 +/- 50539.36\n",
      "Episode length: 1452.80 +/- 389.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.45e+03    |\n",
      "|    mean_reward          | -8.61e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 195000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003456208 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.01e+07    |\n",
      "|    n_updates            | 16860       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 3.27e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.17e+03  |\n",
      "|    ep_rew_mean     | -7.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 444       |\n",
      "|    iterations      | 96        |\n",
      "|    time_elapsed    | 442       |\n",
      "|    total_timesteps | 196608    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2e+03     |\n",
      "|    ep_rew_mean          | -7.49e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 447         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 443         |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013060272 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 16870       |\n",
      "|    policy_gradient_loss | 0.0037      |\n",
      "|    std                  | 0.244       |\n",
      "|    value_loss           | 4.95e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=-61489.95 +/- 52109.65\n",
      "Episode length: 1724.40 +/- 433.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.72e+03    |\n",
      "|    mean_reward          | -6.15e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008611572 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.85        |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.98e+03    |\n",
      "|    n_updates            | 16880       |\n",
      "|    policy_gradient_loss | 0.00375     |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 3.9e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.2e+03   |\n",
      "|    ep_rew_mean     | -7.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 446       |\n",
      "|    iterations      | 98        |\n",
      "|    time_elapsed    | 449       |\n",
      "|    total_timesteps | 200704    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2e+03     |\n",
      "|    ep_rew_mean          | -7.49e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 448         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 451         |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003496828 |\n",
      "|    clip_fraction        | 0.068       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02e+04    |\n",
      "|    n_updates            | 16890       |\n",
      "|    policy_gradient_loss | -0.00061    |\n",
      "|    std                  | 0.243       |\n",
      "|    value_loss           | 9.25e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.23e+03    |\n",
      "|    ep_rew_mean          | -7.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 451         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 453         |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013463866 |\n",
      "|    clip_fraction        | 0.318       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.86        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.4        |\n",
      "|    n_updates            | 16900       |\n",
      "|    policy_gradient_loss | 0.0171      |\n",
      "|    std                  | 0.242       |\n",
      "|    value_loss           | 305         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=205000, episode_reward=77902.78 +/- 43437.41\n",
      "Episode length: 4267.00 +/- 1466.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.27e+03     |\n",
      "|    mean_reward          | 7.79e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 205000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055468166 |\n",
      "|    clip_fraction        | 0.0895       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.86         |\n",
      "|    explained_variance   | 0.817        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+05     |\n",
      "|    n_updates            | 16910        |\n",
      "|    policy_gradient_loss | 0.00214      |\n",
      "|    std                  | 0.242        |\n",
      "|    value_loss           | 3.32e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.23e+03  |\n",
      "|    ep_rew_mean     | -7.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 444       |\n",
      "|    iterations      | 101       |\n",
      "|    time_elapsed    | 465       |\n",
      "|    total_timesteps | 206848    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.26e+03   |\n",
      "|    ep_rew_mean          | -7.13e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 446        |\n",
      "|    iterations           | 102        |\n",
      "|    time_elapsed         | 467        |\n",
      "|    total_timesteps      | 208896     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01451429 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.87       |\n",
      "|    explained_variance   | 0.923      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 74.1       |\n",
      "|    n_updates            | 16920      |\n",
      "|    policy_gradient_loss | -0.0026    |\n",
      "|    std                  | 0.24       |\n",
      "|    value_loss           | 752        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=210000, episode_reward=97060.82 +/- 7775.19\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 9.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 210000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013271364 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.88        |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 412         |\n",
      "|    n_updates            | 16930       |\n",
      "|    policy_gradient_loss | 0.000181    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 6.3e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.25e+03  |\n",
      "|    ep_rew_mean     | -7.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 438       |\n",
      "|    iterations      | 103       |\n",
      "|    time_elapsed    | 481       |\n",
      "|    total_timesteps | 210944    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.25e+03    |\n",
      "|    ep_rew_mean          | -7.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 440         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 483         |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008455754 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.88        |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.09e+03    |\n",
      "|    n_updates            | 16940       |\n",
      "|    policy_gradient_loss | -0.00184    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 2.44e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=215000, episode_reward=97350.76 +/- 5981.83\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 9.74e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 215000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017446777 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.89        |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 16950       |\n",
      "|    policy_gradient_loss | -3.93e-05   |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 901         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.28e+03  |\n",
      "|    ep_rew_mean     | -6.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 432       |\n",
      "|    iterations      | 105       |\n",
      "|    time_elapsed    | 496       |\n",
      "|    total_timesteps | 215040    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.28e+03    |\n",
      "|    ep_rew_mean          | -6.87e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 435         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008776305 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.9         |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 16960       |\n",
      "|    policy_gradient_loss | 0.000752    |\n",
      "|    std                  | 0.24        |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.28e+03    |\n",
      "|    ep_rew_mean          | -6.87e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 437         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 500         |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030470219 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.91        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 16970       |\n",
      "|    policy_gradient_loss | 0.00708     |\n",
      "|    std                  | 0.237       |\n",
      "|    value_loss           | 765         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=98335.81 +/- 8539.23\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 9.83e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 220000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06566037 |\n",
      "|    clip_fraction        | 0.42       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.94       |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 22.8       |\n",
      "|    n_updates            | 16980      |\n",
      "|    policy_gradient_loss | 0.0167     |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 90.5       |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.31e+03  |\n",
      "|    ep_rew_mean     | -6.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 430       |\n",
      "|    iterations      | 108       |\n",
      "|    time_elapsed    | 514       |\n",
      "|    total_timesteps | 221184    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.32e+03    |\n",
      "|    ep_rew_mean          | -6.65e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 516         |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006427996 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.94        |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.54e+03    |\n",
      "|    n_updates            | 16990       |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.25e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=225000, episode_reward=96217.02 +/- 7380.29\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 9.62e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 225000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019450766 |\n",
      "|    clip_fraction        | 0.00244      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.94         |\n",
      "|    explained_variance   | 0.295        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.85e+06     |\n",
      "|    n_updates            | 17000        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 1.56e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.32e+03  |\n",
      "|    ep_rew_mean     | -6.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 425       |\n",
      "|    iterations      | 110       |\n",
      "|    time_elapsed    | 529       |\n",
      "|    total_timesteps | 225280    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.32e+03    |\n",
      "|    ep_rew_mean          | -6.65e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 427         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 531         |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023977146 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.97        |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.9        |\n",
      "|    n_updates            | 17010       |\n",
      "|    policy_gradient_loss | 0.00404     |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 274         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.35e+03    |\n",
      "|    ep_rew_mean          | -6.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 429         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 533         |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014490114 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 309         |\n",
      "|    n_updates            | 17020       |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=48414.57 +/- 75973.21\n",
      "Episode length: 4013.20 +/- 1973.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.01e+03    |\n",
      "|    mean_reward          | 4.84e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008315202 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.8        |\n",
      "|    n_updates            | 17030       |\n",
      "|    policy_gradient_loss | 0.00256     |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 3.59e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.35e+03  |\n",
      "|    ep_rew_mean     | -6.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 424       |\n",
      "|    iterations      | 113       |\n",
      "|    time_elapsed    | 544       |\n",
      "|    total_timesteps | 231424    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.38e+03   |\n",
      "|    ep_rew_mean          | -6.31e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 426        |\n",
      "|    iterations           | 114        |\n",
      "|    time_elapsed         | 546        |\n",
      "|    total_timesteps      | 233472     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03739898 |\n",
      "|    clip_fraction        | 0.376      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2          |\n",
      "|    explained_variance   | 0.781      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 17040      |\n",
      "|    policy_gradient_loss | 0.0227     |\n",
      "|    std                  | 0.232      |\n",
      "|    value_loss           | 101        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=235000, episode_reward=100738.56 +/- 3133.06\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 1.01e+05   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 235000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00912227 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2          |\n",
      "|    explained_variance   | 0.58       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 880        |\n",
      "|    n_updates            | 17050      |\n",
      "|    policy_gradient_loss | -0.00206   |\n",
      "|    std                  | 0.232      |\n",
      "|    value_loss           | 1.39e+04   |\n",
      "----------------------------------------\n",
      "New best mean reward!\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.38e+03  |\n",
      "|    ep_rew_mean     | -6.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 420       |\n",
      "|    iterations      | 115       |\n",
      "|    time_elapsed    | 560       |\n",
      "|    total_timesteps | 235520    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | -6.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 422         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 562         |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019223215 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.8        |\n",
      "|    n_updates            | 17060       |\n",
      "|    policy_gradient_loss | 0.00432     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 133         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | -6.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 424         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 564         |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025195297 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.6        |\n",
      "|    n_updates            | 17070       |\n",
      "|    policy_gradient_loss | 0.00875     |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 119         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=60786.89 +/- 80889.09\n",
      "Episode length: 4014.20 +/- 1971.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.01e+03    |\n",
      "|    mean_reward          | 6.08e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020330101 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 17080       |\n",
      "|    policy_gradient_loss | 0.00189     |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 1.56e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -6.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 419       |\n",
      "|    iterations      | 118       |\n",
      "|    time_elapsed    | 575       |\n",
      "|    total_timesteps | 241664    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.43e+03    |\n",
      "|    ep_rew_mean          | -5.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 422         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 577         |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009228916 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.4        |\n",
      "|    n_updates            | 17090       |\n",
      "|    policy_gradient_loss | -0.00461    |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 296         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=245000, episode_reward=91502.77 +/- 8645.90\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 9.15e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 245000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033721388 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 1.99         |\n",
      "|    explained_variance   | 0.701        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.25e+04     |\n",
      "|    n_updates            | 17100        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    std                  | 0.232        |\n",
      "|    value_loss           | 1.98e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.43e+03  |\n",
      "|    ep_rew_mean     | -5.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 415       |\n",
      "|    iterations      | 120       |\n",
      "|    time_elapsed    | 590       |\n",
      "|    total_timesteps | 245760    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.46e+03    |\n",
      "|    ep_rew_mean          | -5.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 418         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 592         |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019319061 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.51        |\n",
      "|    n_updates            | 17110       |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 64.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.46e+03   |\n",
      "|    ep_rew_mean          | -5.77e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 420        |\n",
      "|    iterations           | 122        |\n",
      "|    time_elapsed         | 594        |\n",
      "|    total_timesteps      | 249856     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00626147 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2          |\n",
      "|    explained_variance   | 0.793      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.76e+03   |\n",
      "|    n_updates            | 17120      |\n",
      "|    policy_gradient_loss | 0.00298    |\n",
      "|    std                  | 0.231      |\n",
      "|    value_loss           | 8.47e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=-10063.87 +/- 3067.20\n",
      "Episode length: 4510.40 +/- 18.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.51e+03    |\n",
      "|    mean_reward          | -1.01e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016204312 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.4        |\n",
      "|    n_updates            | 17130       |\n",
      "|    policy_gradient_loss | 0.00377     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 87.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.46e+03  |\n",
      "|    ep_rew_mean     | -5.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 414       |\n",
      "|    iterations      | 123       |\n",
      "|    time_elapsed    | 607       |\n",
      "|    total_timesteps | 251904    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+03    |\n",
      "|    ep_rew_mean          | -5.6e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 416         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 609         |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008373119 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.4e+04     |\n",
      "|    n_updates            | 17140       |\n",
      "|    policy_gradient_loss | 0.00216     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 2.97e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=255000, episode_reward=-7782.01 +/- 5941.64\n",
      "Episode length: 4446.20 +/- 23.61\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.45e+03   |\n",
      "|    mean_reward          | -7.78e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 255000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12827985 |\n",
      "|    clip_fraction        | 0.289      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.364      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.55e+06   |\n",
      "|    n_updates            | 17150      |\n",
      "|    policy_gradient_loss | -0.00399   |\n",
      "|    std                  | 0.228      |\n",
      "|    value_loss           | 8.92e+06   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.49e+03 |\n",
      "|    ep_rew_mean     | -5.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 411      |\n",
      "|    iterations      | 125      |\n",
      "|    time_elapsed    | 621      |\n",
      "|    total_timesteps | 256000   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | -5.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 413         |\n",
      "|    iterations           | 126         |\n",
      "|    time_elapsed         | 623         |\n",
      "|    total_timesteps      | 258048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016721055 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.803       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87.6        |\n",
      "|    n_updates            | 17160       |\n",
      "|    policy_gradient_loss | 0.00154     |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 402         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=310.58 +/- 885.88\n",
      "Episode length: 4399.80 +/- 8.70\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.4e+03      |\n",
      "|    mean_reward          | 311          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 260000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041830996 |\n",
      "|    clip_fraction        | 0.067        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.05         |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.93e+06     |\n",
      "|    n_updates            | 17170        |\n",
      "|    policy_gradient_loss | 0.00103      |\n",
      "|    std                  | 0.228        |\n",
      "|    value_loss           | 1.27e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.53e+03  |\n",
      "|    ep_rew_mean     | -5.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 409       |\n",
      "|    iterations      | 127       |\n",
      "|    time_elapsed    | 635       |\n",
      "|    total_timesteps | 260096    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.55e+03   |\n",
      "|    ep_rew_mean          | -5.29e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 411        |\n",
      "|    iterations           | 128        |\n",
      "|    time_elapsed         | 637        |\n",
      "|    total_timesteps      | 262144     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05384712 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.719      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 51.8       |\n",
      "|    n_updates            | 17180      |\n",
      "|    policy_gradient_loss | 0.0163     |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 202        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.55e+03   |\n",
      "|    ep_rew_mean          | -5.29e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 413        |\n",
      "|    iterations           | 129        |\n",
      "|    time_elapsed         | 639        |\n",
      "|    total_timesteps      | 264192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01590947 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.419      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.96e+06   |\n",
      "|    n_updates            | 17190      |\n",
      "|    policy_gradient_loss | 0.00223    |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 1.35e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=265000, episode_reward=-4113.14 +/- 3610.36\n",
      "Episode length: 4415.80 +/- 17.63\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.42e+03   |\n",
      "|    mean_reward          | -4.11e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 265000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02762075 |\n",
      "|    clip_fraction        | 0.256      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 44.4       |\n",
      "|    n_updates            | 17200      |\n",
      "|    policy_gradient_loss | -0.00818   |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 246        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.58e+03  |\n",
      "|    ep_rew_mean     | -5.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 408       |\n",
      "|    iterations      | 130       |\n",
      "|    time_elapsed    | 651       |\n",
      "|    total_timesteps | 266240    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.58e+03    |\n",
      "|    ep_rew_mean          | -5.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 410         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 653         |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008279591 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.26e+04    |\n",
      "|    n_updates            | 17210       |\n",
      "|    policy_gradient_loss | 0.00769     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 1.09e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=270000, episode_reward=7296.18 +/- 2282.88\n",
      "Episode length: 4310.20 +/- 8.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.31e+03    |\n",
      "|    mean_reward          | 7.3e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 270000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020932432 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.7        |\n",
      "|    n_updates            | 17220       |\n",
      "|    policy_gradient_loss | 0.00602     |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 184         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.61e+03  |\n",
      "|    ep_rew_mean     | -4.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 406       |\n",
      "|    iterations      | 132       |\n",
      "|    time_elapsed    | 665       |\n",
      "|    total_timesteps | 270336    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.62e+03   |\n",
      "|    ep_rew_mean          | -4.72e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 408        |\n",
      "|    iterations           | 133        |\n",
      "|    time_elapsed         | 667        |\n",
      "|    total_timesteps      | 272384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04321288 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.801      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 51.6       |\n",
      "|    n_updates            | 17230      |\n",
      "|    policy_gradient_loss | -0.00116   |\n",
      "|    std                  | 0.228      |\n",
      "|    value_loss           | 2.21e+03   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.62e+03     |\n",
      "|    ep_rew_mean          | -4.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 410          |\n",
      "|    iterations           | 134          |\n",
      "|    time_elapsed         | 669          |\n",
      "|    total_timesteps      | 274432       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063611153 |\n",
      "|    clip_fraction        | 0.198        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21e+06     |\n",
      "|    n_updates            | 17240        |\n",
      "|    policy_gradient_loss | 0.00433      |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 6.5e+06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=275000, episode_reward=-39063.25 +/- 7247.97\n",
      "Episode length: 2894.20 +/- 29.77\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.89e+03  |\n",
      "|    mean_reward          | -3.91e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 275000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0756415 |\n",
      "|    clip_fraction        | 0.297     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.02      |\n",
      "|    explained_variance   | 0.989     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 61        |\n",
      "|    n_updates            | 17250     |\n",
      "|    policy_gradient_loss | 0.0116    |\n",
      "|    std                  | 0.228     |\n",
      "|    value_loss           | 126       |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.65e+03  |\n",
      "|    ep_rew_mean     | -4.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 407       |\n",
      "|    iterations      | 135       |\n",
      "|    time_elapsed    | 677       |\n",
      "|    total_timesteps | 276480    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.66e+03   |\n",
      "|    ep_rew_mean          | -4.6e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 409        |\n",
      "|    iterations           | 136        |\n",
      "|    time_elapsed         | 679        |\n",
      "|    total_timesteps      | 278528     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01600485 |\n",
      "|    clip_fraction        | 0.455      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.461      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.04e+05   |\n",
      "|    n_updates            | 17260      |\n",
      "|    policy_gradient_loss | 0.0235     |\n",
      "|    std                  | 0.228      |\n",
      "|    value_loss           | 1.02e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=280000, episode_reward=18668.76 +/- 6388.35\n",
      "Episode length: 3942.80 +/- 32.75\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 3.94e+03  |\n",
      "|    mean_reward          | 1.87e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 280000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0094418 |\n",
      "|    clip_fraction        | 0.0484    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.04      |\n",
      "|    explained_variance   | 0.556     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.06e+06  |\n",
      "|    n_updates            | 17270     |\n",
      "|    policy_gradient_loss | -0.00791  |\n",
      "|    std                  | 0.228     |\n",
      "|    value_loss           | 5.28e+06  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.68e+03  |\n",
      "|    ep_rew_mean     | -4.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 406       |\n",
      "|    iterations      | 137       |\n",
      "|    time_elapsed    | 690       |\n",
      "|    total_timesteps | 280576    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.68e+03     |\n",
      "|    ep_rew_mean          | -4.45e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 407          |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 692          |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035098868 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.52e+06     |\n",
      "|    n_updates            | 17280        |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    std                  | 0.228        |\n",
      "|    value_loss           | 1.49e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.7e+03    |\n",
      "|    ep_rew_mean          | -4.32e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 409        |\n",
      "|    iterations           | 139        |\n",
      "|    time_elapsed         | 694        |\n",
      "|    total_timesteps      | 284672     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02907876 |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.04       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.59       |\n",
      "|    n_updates            | 17290      |\n",
      "|    policy_gradient_loss | 0.0185     |\n",
      "|    std                  | 0.23       |\n",
      "|    value_loss           | 31.9       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=285000, episode_reward=-32710.01 +/- 554.76\n",
      "Episode length: 3002.40 +/- 24.35\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3e+03      |\n",
      "|    mean_reward          | -3.27e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 285000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05733726 |\n",
      "|    clip_fraction        | 0.569      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.444      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.6e+04    |\n",
      "|    n_updates            | 17300      |\n",
      "|    policy_gradient_loss | 0.0307     |\n",
      "|    std                  | 0.23       |\n",
      "|    value_loss           | 1.14e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.7e+03   |\n",
      "|    ep_rew_mean     | -4.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 407       |\n",
      "|    iterations      | 140       |\n",
      "|    time_elapsed    | 703       |\n",
      "|    total_timesteps | 286720    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | -4.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 409         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 705         |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047650926 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.9        |\n",
      "|    n_updates            | 17310       |\n",
      "|    policy_gradient_loss | 0.000488    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 61.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=290000, episode_reward=33666.72 +/- 1188.62\n",
      "Episode length: 1975.20 +/- 30.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.98e+03     |\n",
      "|    mean_reward          | 3.37e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 290000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034028077 |\n",
      "|    clip_fraction        | 0.0385       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 125          |\n",
      "|    n_updates            | 17320        |\n",
      "|    policy_gradient_loss | -0.0025      |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 1.92e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.69e+03  |\n",
      "|    ep_rew_mean     | -4.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 408       |\n",
      "|    iterations      | 142       |\n",
      "|    time_elapsed    | 711       |\n",
      "|    total_timesteps | 290816    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.66e+03   |\n",
      "|    ep_rew_mean          | -4.29e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 410        |\n",
      "|    iterations           | 143        |\n",
      "|    time_elapsed         | 713        |\n",
      "|    total_timesteps      | 292864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01671546 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.928      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 22.1       |\n",
      "|    n_updates            | 17330      |\n",
      "|    policy_gradient_loss | 0.00305    |\n",
      "|    std                  | 0.232      |\n",
      "|    value_loss           | 604        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.68e+03    |\n",
      "|    ep_rew_mean          | -4.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 715         |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011180055 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.9        |\n",
      "|    n_updates            | 17340       |\n",
      "|    policy_gradient_loss | 0.0136      |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 347         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=295000, episode_reward=36042.14 +/- 2250.97\n",
      "Episode length: 2144.80 +/- 14.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.14e+03    |\n",
      "|    mean_reward          | 3.6e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 295000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013403875 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 17350       |\n",
      "|    policy_gradient_loss | 0.00302     |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 1.5e+04     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | -3.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 411      |\n",
      "|    iterations      | 145      |\n",
      "|    time_elapsed    | 722      |\n",
      "|    total_timesteps | 296960   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | -3.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 412         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010470058 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 13.2        |\n",
      "|    n_updates            | 17360       |\n",
      "|    policy_gradient_loss | 0.00112     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 122         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=5110.31 +/- 52290.67\n",
      "Episode length: 1564.40 +/- 750.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.56e+03    |\n",
      "|    mean_reward          | 5.11e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 300000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006092613 |\n",
      "|    clip_fraction        | 0.0552      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 17370       |\n",
      "|    policy_gradient_loss | -0.000561   |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 1.29e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.66e+03  |\n",
      "|    ep_rew_mean     | -3.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 412       |\n",
      "|    iterations      | 147       |\n",
      "|    time_elapsed    | 729       |\n",
      "|    total_timesteps | 301056    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.64e+03    |\n",
      "|    ep_rew_mean          | -3.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 414         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 731         |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015035193 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.05e+04    |\n",
      "|    n_updates            | 17380       |\n",
      "|    policy_gradient_loss | -0.000387   |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 3.27e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=305000, episode_reward=-1776.46 +/- 56008.03\n",
      "Episode length: 1602.60 +/- 764.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -1.78e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 305000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011783734 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+07    |\n",
      "|    n_updates            | 17390       |\n",
      "|    policy_gradient_loss | -0.000988   |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 2.32e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.64e+03  |\n",
      "|    ep_rew_mean     | -3.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 413       |\n",
      "|    iterations      | 149       |\n",
      "|    time_elapsed    | 737       |\n",
      "|    total_timesteps | 305152    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.63e+03    |\n",
      "|    ep_rew_mean          | -3.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 415         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 739         |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009287186 |\n",
      "|    clip_fraction        | 0.096       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 82.7        |\n",
      "|    n_updates            | 17400       |\n",
      "|    policy_gradient_loss | -0.00663    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 409         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.62e+03    |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 417         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 741         |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015192874 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.839       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96.7        |\n",
      "|    n_updates            | 17410       |\n",
      "|    policy_gradient_loss | 0.00128     |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 8.76e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=-76807.22 +/- 39420.29\n",
      "Episode length: 514.80 +/- 910.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 515         |\n",
      "|    mean_reward          | -7.68e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002098706 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.48e+07    |\n",
      "|    n_updates            | 17420       |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 3.61e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.59e+03  |\n",
      "|    ep_rew_mean     | -3.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 418       |\n",
      "|    iterations      | 152       |\n",
      "|    time_elapsed    | 744       |\n",
      "|    total_timesteps | 311296    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.6e+03      |\n",
      "|    ep_rew_mean          | -3.27e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 419          |\n",
      "|    iterations           | 153          |\n",
      "|    time_elapsed         | 746          |\n",
      "|    total_timesteps      | 313344       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054768426 |\n",
      "|    clip_fraction        | 0.0303       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2            |\n",
      "|    explained_variance   | 0.862        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.87e+04     |\n",
      "|    n_updates            | 17430        |\n",
      "|    policy_gradient_loss | -0.0049      |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 5.77e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=315000, episode_reward=-15822.79 +/- 44696.62\n",
      "Episode length: 1892.60 +/- 912.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.89e+03    |\n",
      "|    mean_reward          | -1.58e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 315000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007972151 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.16e+03    |\n",
      "|    n_updates            | 17440       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 2.09e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.61e+03  |\n",
      "|    ep_rew_mean     | -2.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 419       |\n",
      "|    iterations      | 154       |\n",
      "|    time_elapsed    | 752       |\n",
      "|    total_timesteps | 315392    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.63e+03     |\n",
      "|    ep_rew_mean          | -2.86e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 420          |\n",
      "|    iterations           | 155          |\n",
      "|    time_elapsed         | 754          |\n",
      "|    total_timesteps      | 317440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059463796 |\n",
      "|    clip_fraction        | 0.0295       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2            |\n",
      "|    explained_variance   | 0.659        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 357          |\n",
      "|    n_updates            | 17450        |\n",
      "|    policy_gradient_loss | -0.00812     |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 8.66e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.6e+03      |\n",
      "|    ep_rew_mean          | -2.91e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 422          |\n",
      "|    iterations           | 156          |\n",
      "|    time_elapsed         | 756          |\n",
      "|    total_timesteps      | 319488       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052419463 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2            |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 291          |\n",
      "|    n_updates            | 17460        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 1.57e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=320000, episode_reward=4392.53 +/- 54400.69\n",
      "Episode length: 1813.60 +/- 874.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.81e+03    |\n",
      "|    mean_reward          | 4.39e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034197215 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 17470       |\n",
      "|    policy_gradient_loss | -0.00246    |\n",
      "|    std                  | 0.237       |\n",
      "|    value_loss           | 1.56e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.59e+03  |\n",
      "|    ep_rew_mean     | -2.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 421       |\n",
      "|    iterations      | 157       |\n",
      "|    time_elapsed    | 762       |\n",
      "|    total_timesteps | 321536    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.6e+03    |\n",
      "|    ep_rew_mean          | -2.04e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 423        |\n",
      "|    iterations           | 158        |\n",
      "|    time_elapsed         | 764        |\n",
      "|    total_timesteps      | 323584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16649237 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.98       |\n",
      "|    explained_variance   | 0.428      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 131        |\n",
      "|    n_updates            | 17480      |\n",
      "|    policy_gradient_loss | 0.00583    |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 8.25e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=325000, episode_reward=-1100.71 +/- 59412.37\n",
      "Episode length: 1769.80 +/- 849.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.77e+03    |\n",
      "|    mean_reward          | -1.1e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 325000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012781242 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 17490       |\n",
      "|    policy_gradient_loss | -4.27e-05   |\n",
      "|    std                  | 0.237       |\n",
      "|    value_loss           | 1.53e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.61e+03  |\n",
      "|    ep_rew_mean     | -1.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 422       |\n",
      "|    iterations      | 159       |\n",
      "|    time_elapsed    | 770       |\n",
      "|    total_timesteps | 325632    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.59e+03    |\n",
      "|    ep_rew_mean          | -1.49e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 424         |\n",
      "|    iterations           | 160         |\n",
      "|    time_elapsed         | 772         |\n",
      "|    total_timesteps      | 327680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007942457 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 1.99        |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.34e+07    |\n",
      "|    n_updates            | 17500       |\n",
      "|    policy_gradient_loss | 0.00157     |\n",
      "|    std                  | 0.237       |\n",
      "|    value_loss           | 3.1e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.59e+03   |\n",
      "|    ep_rew_mean          | -1.37e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 425        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 774        |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31630385 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 1.99       |\n",
      "|    explained_variance   | 0.365      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.78e+07   |\n",
      "|    n_updates            | 17510      |\n",
      "|    policy_gradient_loss | 0.00188    |\n",
      "|    std                  | 0.235      |\n",
      "|    value_loss           | 3.27e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=24256.62 +/- 7520.86\n",
      "Episode length: 2205.80 +/- 39.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.21e+03    |\n",
      "|    mean_reward          | 2.43e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 330000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008468422 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.6        |\n",
      "|    n_updates            | 17520       |\n",
      "|    policy_gradient_loss | 0.00573     |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 180         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.6e+03   |\n",
      "|    ep_rew_mean     | -1.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 424       |\n",
      "|    iterations      | 162       |\n",
      "|    time_elapsed    | 781       |\n",
      "|    total_timesteps | 331776    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.61e+03    |\n",
      "|    ep_rew_mean          | -7.88e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 426         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 783         |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012778225 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.76e+05    |\n",
      "|    n_updates            | 17530       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 1.99e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=335000, episode_reward=28297.24 +/- 2364.17\n",
      "Episode length: 2182.60 +/- 7.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.18e+03     |\n",
      "|    mean_reward          | 2.83e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 335000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0085180905 |\n",
      "|    clip_fraction        | 0.123        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2            |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 111          |\n",
      "|    n_updates            | 17540        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 842          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.61e+03  |\n",
      "|    ep_rew_mean     | -4.52e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 425       |\n",
      "|    iterations      | 164       |\n",
      "|    time_elapsed    | 790       |\n",
      "|    total_timesteps | 335872    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.62e+03   |\n",
      "|    ep_rew_mean          | -1.59e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 426        |\n",
      "|    iterations           | 165        |\n",
      "|    time_elapsed         | 791        |\n",
      "|    total_timesteps      | 337920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01913767 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2          |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 38.8       |\n",
      "|    n_updates            | 17550      |\n",
      "|    policy_gradient_loss | 0.0126     |\n",
      "|    std                  | 0.235      |\n",
      "|    value_loss           | 180        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.58e+03    |\n",
      "|    ep_rew_mean          | -4.23e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 428         |\n",
      "|    iterations           | 166         |\n",
      "|    time_elapsed         | 793         |\n",
      "|    total_timesteps      | 339968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019031817 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 17560       |\n",
      "|    policy_gradient_loss | 0.00525     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 2.07e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=340000, episode_reward=-34709.20 +/- 48570.83\n",
      "Episode length: 1929.40 +/- 924.83\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.93e+03   |\n",
      "|    mean_reward          | -3.47e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 340000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03692077 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.347      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.73e+07   |\n",
      "|    n_updates            | 17570      |\n",
      "|    policy_gradient_loss | 0.0109     |\n",
      "|    std                  | 0.234      |\n",
      "|    value_loss           | 5.6e+07    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.57e+03  |\n",
      "|    ep_rew_mean     | -4.33e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 427       |\n",
      "|    iterations      | 167       |\n",
      "|    time_elapsed    | 800       |\n",
      "|    total_timesteps | 342016    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.54e+03     |\n",
      "|    ep_rew_mean          | -5.14e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 428          |\n",
      "|    iterations           | 168          |\n",
      "|    time_elapsed         | 802          |\n",
      "|    total_timesteps      | 344064       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006506783 |\n",
      "|    clip_fraction        | 0.00366      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.32         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+07     |\n",
      "|    n_updates            | 17580        |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 1.94e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=345000, episode_reward=-17580.33 +/- 5680.40\n",
      "Episode length: 2412.20 +/- 36.52\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.41e+03     |\n",
      "|    mean_reward          | -1.76e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 345000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008307161 |\n",
      "|    clip_fraction        | 0.00249      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+07     |\n",
      "|    n_updates            | 17590        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 2.45e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.54e+03  |\n",
      "|    ep_rew_mean     | -3.97e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 427       |\n",
      "|    iterations      | 169       |\n",
      "|    time_elapsed    | 809       |\n",
      "|    total_timesteps | 346112    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.54e+03     |\n",
      "|    ep_rew_mean          | -3.97e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 428          |\n",
      "|    iterations           | 170          |\n",
      "|    time_elapsed         | 811          |\n",
      "|    total_timesteps      | 348160       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023285348 |\n",
      "|    clip_fraction        | 0.00581      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.561        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.52e+06     |\n",
      "|    n_updates            | 17600        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 4.19e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=-2426.99 +/- 3119.22\n",
      "Episode length: 2374.60 +/- 12.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.37e+03    |\n",
      "|    mean_reward          | -2.43e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 350000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004337283 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.87e+03    |\n",
      "|    n_updates            | 17610       |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 3.45e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.52e+03  |\n",
      "|    ep_rew_mean     | -4.79e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 427       |\n",
      "|    iterations      | 171       |\n",
      "|    time_elapsed    | 819       |\n",
      "|    total_timesteps | 350208    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+03    |\n",
      "|    ep_rew_mean          | -5.42e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 429         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 821         |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009792368 |\n",
      "|    clip_fraction        | 0.0404      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.759       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.01e+05    |\n",
      "|    n_updates            | 17620       |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 7.85e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.46e+03     |\n",
      "|    ep_rew_mean          | -6.36e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 430          |\n",
      "|    iterations           | 173          |\n",
      "|    time_elapsed         | 822          |\n",
      "|    total_timesteps      | 354304       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023770658 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.918        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.04e+03     |\n",
      "|    n_updates            | 17630        |\n",
      "|    policy_gradient_loss | -0.0022      |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 3.49e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=355000, episode_reward=6314.29 +/- 6621.15\n",
      "Episode length: 2363.40 +/- 18.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.36e+03    |\n",
      "|    mean_reward          | 6.31e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 355000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004098098 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.596       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 17640       |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 1.85e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.44e+03  |\n",
      "|    ep_rew_mean     | -7.27e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 429       |\n",
      "|    iterations      | 174       |\n",
      "|    time_elapsed    | 830       |\n",
      "|    total_timesteps | 356352    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.41e+03     |\n",
      "|    ep_rew_mean          | -8.01e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 430          |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 832          |\n",
      "|    total_timesteps      | 358400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034580003 |\n",
      "|    clip_fraction        | 0.0219       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.02         |\n",
      "|    explained_variance   | 0.611        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+06      |\n",
      "|    n_updates            | 17650        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 2.47e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=1347.70 +/- 65511.85\n",
      "Episode length: 1850.40 +/- 885.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.85e+03    |\n",
      "|    mean_reward          | 1.35e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 360000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013844299 |\n",
      "|    clip_fraction        | 0.0838      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 348         |\n",
      "|    n_updates            | 17660       |\n",
      "|    policy_gradient_loss | 0.0013      |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 1.19e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.38e+03  |\n",
      "|    ep_rew_mean     | -8.73e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 429       |\n",
      "|    iterations      | 176       |\n",
      "|    time_elapsed    | 838       |\n",
      "|    total_timesteps | 360448    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.39e+03   |\n",
      "|    ep_rew_mean          | -8.83e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 431        |\n",
      "|    iterations           | 177        |\n",
      "|    time_elapsed         | 840        |\n",
      "|    total_timesteps      | 362496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02153688 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.01       |\n",
      "|    explained_variance   | 0.876      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 363        |\n",
      "|    n_updates            | 17670      |\n",
      "|    policy_gradient_loss | 0.000751   |\n",
      "|    std                  | 0.235      |\n",
      "|    value_loss           | 1.33e+05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | -8.78e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 432         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 842         |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017130302 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 243         |\n",
      "|    n_updates            | 17680       |\n",
      "|    policy_gradient_loss | 0.00153     |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 861         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=365000, episode_reward=24519.69 +/- 4046.30\n",
      "Episode length: 1781.80 +/- 18.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.78e+03    |\n",
      "|    mean_reward          | 2.45e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 365000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019841041 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 280         |\n",
      "|    n_updates            | 17690       |\n",
      "|    policy_gradient_loss | 0.00987     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 1.6e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -8.68e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 432       |\n",
      "|    iterations      | 179       |\n",
      "|    time_elapsed    | 848       |\n",
      "|    total_timesteps | 366592    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+03    |\n",
      "|    ep_rew_mean          | -8.72e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 433         |\n",
      "|    iterations           | 180         |\n",
      "|    time_elapsed         | 849         |\n",
      "|    total_timesteps      | 368640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021316586 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.2        |\n",
      "|    n_updates            | 17700       |\n",
      "|    policy_gradient_loss | 0.00353     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.23e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=370000, episode_reward=24064.13 +/- 6386.19\n",
      "Episode length: 2134.00 +/- 21.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.13e+03    |\n",
      "|    mean_reward          | 2.41e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 370000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011946393 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 17710       |\n",
      "|    policy_gradient_loss | 0.00222     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.69e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -9.94e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 432       |\n",
      "|    iterations      | 181       |\n",
      "|    time_elapsed    | 856       |\n",
      "|    total_timesteps | 370688    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+03    |\n",
      "|    ep_rew_mean          | -7.55e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 434         |\n",
      "|    iterations           | 182         |\n",
      "|    time_elapsed         | 858         |\n",
      "|    total_timesteps      | 372736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002735182 |\n",
      "|    clip_fraction        | 0.0533      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.21e+06    |\n",
      "|    n_updates            | 17720       |\n",
      "|    policy_gradient_loss | -0.0037     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 3.02e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | -1.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 435         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 860         |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008847047 |\n",
      "|    clip_fraction        | 0.042       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.14e+03    |\n",
      "|    n_updates            | 17730       |\n",
      "|    policy_gradient_loss | -0.00342    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 3.32e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=375000, episode_reward=18027.93 +/- 7096.97\n",
      "Episode length: 1765.20 +/- 33.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.77e+03    |\n",
      "|    mean_reward          | 1.8e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 375000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003051268 |\n",
      "|    clip_fraction        | 0.0128      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.89e+07    |\n",
      "|    n_updates            | 17740       |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 8.07e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.39e+03  |\n",
      "|    ep_rew_mean     | -1.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 434       |\n",
      "|    iterations      | 184       |\n",
      "|    time_elapsed    | 866       |\n",
      "|    total_timesteps | 376832    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -1.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 436         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 868         |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003682098 |\n",
      "|    clip_fraction        | 0.0116      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.26e+03    |\n",
      "|    n_updates            | 17750       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.04e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=380000, episode_reward=23192.96 +/- 3924.37\n",
      "Episode length: 2124.00 +/- 10.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.12e+03    |\n",
      "|    mean_reward          | 2.32e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 380000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007113482 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2           |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 641         |\n",
      "|    n_updates            | 17760       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.23e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.4e+03   |\n",
      "|    ep_rew_mean     | -1.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 435       |\n",
      "|    iterations      | 186       |\n",
      "|    time_elapsed    | 875       |\n",
      "|    total_timesteps | 380928    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.41e+03     |\n",
      "|    ep_rew_mean          | -1.16e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 436          |\n",
      "|    iterations           | 187          |\n",
      "|    time_elapsed         | 877          |\n",
      "|    total_timesteps      | 382976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060691275 |\n",
      "|    clip_fraction        | 0.0251       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 773          |\n",
      "|    n_updates            | 17770        |\n",
      "|    policy_gradient_loss | -0.00145     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 1.26e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=385000, episode_reward=-8199.09 +/- 70421.32\n",
      "Episode length: 1915.00 +/- 521.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.92e+03    |\n",
      "|    mean_reward          | -8.2e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 385000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004857488 |\n",
      "|    clip_fraction        | 0.0289      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.63e+03    |\n",
      "|    n_updates            | 17780       |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.27e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.41e+03  |\n",
      "|    ep_rew_mean     | -1.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 435       |\n",
      "|    iterations      | 188       |\n",
      "|    time_elapsed    | 883       |\n",
      "|    total_timesteps | 385024    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.42e+03     |\n",
      "|    ep_rew_mean          | -1.03e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 437          |\n",
      "|    iterations           | 189          |\n",
      "|    time_elapsed         | 885          |\n",
      "|    total_timesteps      | 387072       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054269517 |\n",
      "|    clip_fraction        | 0.0537       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.912        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.59e+04     |\n",
      "|    n_updates            | 17790        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 7.65e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.43e+03     |\n",
      "|    ep_rew_mean          | -1.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 438          |\n",
      "|    iterations           | 190          |\n",
      "|    time_elapsed         | 887          |\n",
      "|    total_timesteps      | 389120       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063366643 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.01         |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.85e+03     |\n",
      "|    n_updates            | 17800        |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 1.87e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=26032.75 +/- 6577.89\n",
      "Episode length: 2307.60 +/- 21.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.31e+03    |\n",
      "|    mean_reward          | 2.6e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014319953 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 679         |\n",
      "|    n_updates            | 17810       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 2.59e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.43e+03  |\n",
      "|    ep_rew_mean     | -1.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 437       |\n",
      "|    iterations      | 191       |\n",
      "|    time_elapsed    | 894       |\n",
      "|    total_timesteps | 391168    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+03    |\n",
      "|    ep_rew_mean          | -1.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 438         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 896         |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004007411 |\n",
      "|    clip_fraction        | 0.0191      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.01        |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5e+05       |\n",
      "|    n_updates            | 17820       |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.95e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=395000, episode_reward=26584.98 +/- 919.76\n",
      "Episode length: 1846.40 +/- 9.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.85e+03    |\n",
      "|    mean_reward          | 2.66e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 395000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016514698 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 895         |\n",
      "|    n_updates            | 17830       |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 3.22e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.41e+03  |\n",
      "|    ep_rew_mean     | -1.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 437       |\n",
      "|    iterations      | 193       |\n",
      "|    time_elapsed    | 902       |\n",
      "|    total_timesteps | 395264    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | -1.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 439         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 904         |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012715984 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.02        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 364         |\n",
      "|    n_updates            | 17840       |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.33e+03   |\n",
      "|    ep_rew_mean          | -5e+03     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 440        |\n",
      "|    iterations           | 195        |\n",
      "|    time_elapsed         | 906        |\n",
      "|    total_timesteps      | 399360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00856238 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.02       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 499        |\n",
      "|    n_updates            | 17850      |\n",
      "|    policy_gradient_loss | 0.000296   |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 1.58e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=27855.67 +/- 281.68\n",
      "Episode length: 1797.20 +/- 12.69\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 1.8e+03  |\n",
      "|    mean_reward          | 2.79e+04 |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 400000   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.00192  |\n",
      "|    clip_fraction        | 0.0137   |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 2.03     |\n",
      "|    explained_variance   | 0.297    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 9.82e+06 |\n",
      "|    n_updates            | 17860    |\n",
      "|    policy_gradient_loss | -0.00691 |\n",
      "|    std                  | 0.236    |\n",
      "|    value_loss           | 2.63e+07 |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.27e+03  |\n",
      "|    ep_rew_mean     | -6.75e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 440       |\n",
      "|    iterations      | 196       |\n",
      "|    time_elapsed    | 912       |\n",
      "|    total_timesteps | 401408    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.23e+03   |\n",
      "|    ep_rew_mean          | -8.66e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 441        |\n",
      "|    iterations           | 197        |\n",
      "|    time_elapsed         | 914        |\n",
      "|    total_timesteps      | 403456     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00495119 |\n",
      "|    clip_fraction        | 0.0217     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.03       |\n",
      "|    explained_variance   | 0.386      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.97e+07   |\n",
      "|    n_updates            | 17870      |\n",
      "|    policy_gradient_loss | -0.00112   |\n",
      "|    std                  | 0.236      |\n",
      "|    value_loss           | 4.37e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=405000, episode_reward=26338.24 +/- 313.18\n",
      "Episode length: 1665.20 +/- 13.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.67e+03    |\n",
      "|    mean_reward          | 2.63e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 405000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003563198 |\n",
      "|    clip_fraction        | 0.0151      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.57e+06    |\n",
      "|    n_updates            | 17880       |\n",
      "|    policy_gradient_loss | -0.0068     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.91e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.2e+03   |\n",
      "|    ep_rew_mean     | -7.79e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 440       |\n",
      "|    iterations      | 198       |\n",
      "|    time_elapsed    | 919       |\n",
      "|    total_timesteps | 405504    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.17e+03     |\n",
      "|    ep_rew_mean          | -8.11e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 442          |\n",
      "|    iterations           | 199          |\n",
      "|    time_elapsed         | 921          |\n",
      "|    total_timesteps      | 407552       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036453148 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | 0.878        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.83e+04     |\n",
      "|    n_updates            | 17890        |\n",
      "|    policy_gradient_loss | -0.00432     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 8.11e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.17e+03    |\n",
      "|    ep_rew_mean          | -6.5e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 443         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 923         |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004619993 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.46e+03    |\n",
      "|    n_updates            | 17900       |\n",
      "|    policy_gradient_loss | -0.00104    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 3.68e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=25053.38 +/- 3145.38\n",
      "Episode length: 1745.60 +/- 18.61\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.75e+03     |\n",
      "|    mean_reward          | 2.51e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 410000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057807136 |\n",
      "|    clip_fraction        | 0.0717       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.03         |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.79e+03     |\n",
      "|    n_updates            | 17910        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 1.69e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.18e+03  |\n",
      "|    ep_rew_mean     | -4.86e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 442       |\n",
      "|    iterations      | 201       |\n",
      "|    time_elapsed    | 929       |\n",
      "|    total_timesteps | 411648    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.14e+03    |\n",
      "|    ep_rew_mean          | -5.35e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 444         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 931         |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004443836 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.03        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+03    |\n",
      "|    n_updates            | 17920       |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 6.26e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=415000, episode_reward=22255.22 +/- 4846.57\n",
      "Episode length: 1762.20 +/- 13.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.76e+03    |\n",
      "|    mean_reward          | 2.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 415000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014914354 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 299         |\n",
      "|    n_updates            | 17930       |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    std                  | 0.236       |\n",
      "|    value_loss           | 1.91e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.05e+03  |\n",
      "|    ep_rew_mean     | -9.78e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 443       |\n",
      "|    iterations      | 203       |\n",
      "|    time_elapsed    | 937       |\n",
      "|    total_timesteps | 415744    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.02e+03     |\n",
      "|    ep_rew_mean          | -1.05e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 444          |\n",
      "|    iterations           | 204          |\n",
      "|    time_elapsed         | 939          |\n",
      "|    total_timesteps      | 417792       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033794423 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.04         |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+07     |\n",
      "|    n_updates            | 17940        |\n",
      "|    policy_gradient_loss | -0.000856    |\n",
      "|    std                  | 0.236        |\n",
      "|    value_loss           | 4.95e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.99e+03    |\n",
      "|    ep_rew_mean          | -1.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 446         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 941         |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022672148 |\n",
      "|    clip_fraction        | 0.0892      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.04        |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 586         |\n",
      "|    n_updates            | 17950       |\n",
      "|    policy_gradient_loss | 0.0073      |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 2.38e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=16569.24 +/- 2817.72\n",
      "Episode length: 2252.40 +/- 18.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.25e+03    |\n",
      "|    mean_reward          | 1.66e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 420000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009271577 |\n",
      "|    clip_fraction        | 0.0928      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 377         |\n",
      "|    n_updates            | 17960       |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 6.23e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.97e+03  |\n",
      "|    ep_rew_mean     | -1.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 444       |\n",
      "|    iterations      | 206       |\n",
      "|    time_elapsed    | 948       |\n",
      "|    total_timesteps | 421888    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -1.19e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 446         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 950         |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010200262 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 233         |\n",
      "|    n_updates            | 17970       |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=425000, episode_reward=-87363.94 +/- 90512.23\n",
      "Episode length: 1384.40 +/- 706.43\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.38e+03   |\n",
      "|    mean_reward          | -8.74e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 425000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01286748 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.05       |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 428        |\n",
      "|    n_updates            | 17980      |\n",
      "|    policy_gradient_loss | -0.00163   |\n",
      "|    std                  | 0.235      |\n",
      "|    value_loss           | 1.36e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -1.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 445       |\n",
      "|    iterations      | 208       |\n",
      "|    time_elapsed    | 955       |\n",
      "|    total_timesteps | 425984    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.84e+03   |\n",
      "|    ep_rew_mean          | -1.54e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 447        |\n",
      "|    iterations           | 209        |\n",
      "|    time_elapsed         | 957        |\n",
      "|    total_timesteps      | 428032     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03895214 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.05       |\n",
      "|    explained_variance   | 0.934      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 464        |\n",
      "|    n_updates            | 17990      |\n",
      "|    policy_gradient_loss | 0.0035     |\n",
      "|    std                  | 0.235      |\n",
      "|    value_loss           | 5.68e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=3111.21 +/- 9179.52\n",
      "Episode length: 2523.40 +/- 33.53\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.52e+03     |\n",
      "|    mean_reward          | 3.11e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 430000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030765012 |\n",
      "|    clip_fraction        | 0.0428       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.05         |\n",
      "|    explained_variance   | 0.306        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+07     |\n",
      "|    n_updates            | 18000        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    std                  | 0.235        |\n",
      "|    value_loss           | 2.08e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.81e+03  |\n",
      "|    ep_rew_mean     | -1.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 445       |\n",
      "|    iterations      | 210       |\n",
      "|    time_elapsed    | 965       |\n",
      "|    total_timesteps | 430080    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -1.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 446         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 967         |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012891961 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.56e+05    |\n",
      "|    n_updates            | 18010       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 9.94e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | -1.53e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 448         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 968         |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011451619 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.05        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 364         |\n",
      "|    n_updates            | 18020       |\n",
      "|    policy_gradient_loss | -0.00527    |\n",
      "|    std                  | 0.235       |\n",
      "|    value_loss           | 2.3e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=435000, episode_reward=-11582.85 +/- 70655.02\n",
      "Episode length: 1332.40 +/- 620.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.33e+03    |\n",
      "|    mean_reward          | -1.16e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 435000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044911154 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.49e+04    |\n",
      "|    n_updates            | 18030       |\n",
      "|    policy_gradient_loss | 0.012       |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 3.67e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -1.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 447       |\n",
      "|    iterations      | 213       |\n",
      "|    time_elapsed    | 973       |\n",
      "|    total_timesteps | 436224    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.66e+03     |\n",
      "|    ep_rew_mean          | -1.81e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 449          |\n",
      "|    iterations           | 214          |\n",
      "|    time_elapsed         | 975          |\n",
      "|    total_timesteps      | 438272       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071303453 |\n",
      "|    clip_fraction        | 0.161        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.06         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.09e+07     |\n",
      "|    n_updates            | 18040        |\n",
      "|    policy_gradient_loss | 0.00208      |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 3.71e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=-4381.03 +/- 74375.97\n",
      "Episode length: 1981.20 +/- 566.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.98e+03    |\n",
      "|    mean_reward          | -4.38e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014610328 |\n",
      "|    clip_fraction        | 0.0827      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+04    |\n",
      "|    n_updates            | 18050       |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 3.94e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -1.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 448       |\n",
      "|    iterations      | 215       |\n",
      "|    time_elapsed    | 982       |\n",
      "|    total_timesteps | 440320    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.66e+03    |\n",
      "|    ep_rew_mean          | -1.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 449         |\n",
      "|    iterations           | 216         |\n",
      "|    time_elapsed         | 984         |\n",
      "|    total_timesteps      | 442368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006766784 |\n",
      "|    clip_fraction        | 0.0623      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.889       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2e+03     |\n",
      "|    n_updates            | 18060       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 2.39e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -1.65e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 450         |\n",
      "|    iterations           | 217         |\n",
      "|    time_elapsed         | 986         |\n",
      "|    total_timesteps      | 444416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013189516 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 663         |\n",
      "|    n_updates            | 18070       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 3.56e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=445000, episode_reward=26075.59 +/- 6914.53\n",
      "Episode length: 2239.20 +/- 26.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.24e+03    |\n",
      "|    mean_reward          | 2.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 445000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025621437 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 271         |\n",
      "|    n_updates            | 18080       |\n",
      "|    policy_gradient_loss | 0.00453     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 7.1e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.61e+03  |\n",
      "|    ep_rew_mean     | -1.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 449       |\n",
      "|    iterations      | 218       |\n",
      "|    time_elapsed    | 993       |\n",
      "|    total_timesteps | 446464    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | -1.83e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 450          |\n",
      "|    iterations           | 219          |\n",
      "|    time_elapsed         | 995          |\n",
      "|    total_timesteps      | 448512       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018376141 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+07     |\n",
      "|    n_updates            | 18090        |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 3.38e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=450000, episode_reward=25812.83 +/- 3267.45\n",
      "Episode length: 2208.80 +/- 11.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.21e+03     |\n",
      "|    mean_reward          | 2.58e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 450000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030005956 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.951        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.99e+03     |\n",
      "|    n_updates            | 18100        |\n",
      "|    policy_gradient_loss | -0.000194    |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.81e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -1.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 449       |\n",
      "|    iterations      | 220       |\n",
      "|    time_elapsed    | 1002      |\n",
      "|    total_timesteps | 450560    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | -1.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 450         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 1004        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006117911 |\n",
      "|    clip_fraction        | 0.0505      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.61e+03    |\n",
      "|    n_updates            | 18110       |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 1.03e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | -2.14e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 452          |\n",
      "|    iterations           | 222          |\n",
      "|    time_elapsed         | 1005         |\n",
      "|    total_timesteps      | 454656       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043108463 |\n",
      "|    clip_fraction        | 0.0131       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.33         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69e+07     |\n",
      "|    n_updates            | 18120        |\n",
      "|    policy_gradient_loss | -0.00726     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.9e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=455000, episode_reward=26759.30 +/- 6474.63\n",
      "Episode length: 2226.80 +/- 19.45\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 2.23e+03      |\n",
      "|    mean_reward          | 2.68e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 455000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00032325654 |\n",
      "|    clip_fraction        | 0.00181       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 2.07          |\n",
      "|    explained_variance   | 0.33          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.61e+05      |\n",
      "|    n_updates            | 18130         |\n",
      "|    policy_gradient_loss | -0.00133      |\n",
      "|    std                  | 0.233         |\n",
      "|    value_loss           | 2.94e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -2.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 450       |\n",
      "|    iterations      | 223       |\n",
      "|    time_elapsed    | 1013      |\n",
      "|    total_timesteps | 456704    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | -2.17e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 452          |\n",
      "|    iterations           | 224          |\n",
      "|    time_elapsed         | 1014         |\n",
      "|    total_timesteps      | 458752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057324986 |\n",
      "|    clip_fraction        | 0.0511       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.772        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.79e+04     |\n",
      "|    n_updates            | 18140        |\n",
      "|    policy_gradient_loss | -0.00866     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 8.54e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=460000, episode_reward=25213.26 +/- 5563.87\n",
      "Episode length: 2101.60 +/- 24.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.1e+03      |\n",
      "|    mean_reward          | 2.52e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 460000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050180047 |\n",
      "|    clip_fraction        | 0.0467       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.789        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.28e+05     |\n",
      "|    n_updates            | 18150        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 2.29e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -2.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 451       |\n",
      "|    iterations      | 225       |\n",
      "|    time_elapsed    | 1021      |\n",
      "|    total_timesteps | 460800    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | -2.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 452         |\n",
      "|    iterations           | 226         |\n",
      "|    time_elapsed         | 1023        |\n",
      "|    total_timesteps      | 462848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010339108 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57e+03    |\n",
      "|    n_updates            | 18160       |\n",
      "|    policy_gradient_loss | -0.00245    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 1.27e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -1.92e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 453         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 1025        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008966945 |\n",
      "|    clip_fraction        | 0.0873      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 881         |\n",
      "|    n_updates            | 18170       |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 3.88e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=465000, episode_reward=-106543.86 +/- 70272.69\n",
      "Episode length: 1115.60 +/- 542.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.12e+03    |\n",
      "|    mean_reward          | -1.07e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 465000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008959269 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 718         |\n",
      "|    n_updates            | 18180       |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.62e+03  |\n",
      "|    ep_rew_mean     | -2.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 453       |\n",
      "|    iterations      | 228       |\n",
      "|    time_elapsed    | 1029      |\n",
      "|    total_timesteps | 466944    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.61e+03     |\n",
      "|    ep_rew_mean          | -2.39e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 454          |\n",
      "|    iterations           | 229          |\n",
      "|    time_elapsed         | 1031         |\n",
      "|    total_timesteps      | 468992       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038104034 |\n",
      "|    clip_fraction        | 0.047        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.2e+07      |\n",
      "|    n_updates            | 18190        |\n",
      "|    policy_gradient_loss | 0.0012       |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 5.28e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=470000, episode_reward=-72318.37 +/- 86089.97\n",
      "Episode length: 1375.00 +/- 649.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.38e+03    |\n",
      "|    mean_reward          | -7.23e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 470000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002921136 |\n",
      "|    clip_fraction        | 0.0101      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.11e+06    |\n",
      "|    n_updates            | 18200       |\n",
      "|    policy_gradient_loss | -0.000828   |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 3.14e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.62e+03  |\n",
      "|    ep_rew_mean     | -2.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 454       |\n",
      "|    iterations      | 230       |\n",
      "|    time_elapsed    | 1036      |\n",
      "|    total_timesteps | 471040    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | -2.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 455          |\n",
      "|    iterations           | 231          |\n",
      "|    time_elapsed         | 1038         |\n",
      "|    total_timesteps      | 473088       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059591974 |\n",
      "|    clip_fraction        | 0.0402       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.905        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.63e+03     |\n",
      "|    n_updates            | 18210        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    std                  | 0.233        |\n",
      "|    value_loss           | 1.55e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=475000, episode_reward=-43150.98 +/- 82513.32\n",
      "Episode length: 1337.00 +/- 1017.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.34e+03     |\n",
      "|    mean_reward          | -4.32e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 475000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043741297 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.77e+07     |\n",
      "|    n_updates            | 18220        |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 2.39e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -2.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 455       |\n",
      "|    iterations      | 232       |\n",
      "|    time_elapsed    | 1043      |\n",
      "|    total_timesteps | 475136    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | -2.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 456          |\n",
      "|    iterations           | 233          |\n",
      "|    time_elapsed         | 1045         |\n",
      "|    total_timesteps      | 477184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063848635 |\n",
      "|    clip_fraction        | 0.0798       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.07         |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 395          |\n",
      "|    n_updates            | 18230        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    std                  | 0.234        |\n",
      "|    value_loss           | 7.83e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | -2.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 1047        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013592256 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 829         |\n",
      "|    n_updates            | 18240       |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 3.32e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=32167.53 +/- 1392.31\n",
      "Episode length: 2166.40 +/- 14.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.17e+03    |\n",
      "|    mean_reward          | 3.22e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 480000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005557534 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 458         |\n",
      "|    n_updates            | 18250       |\n",
      "|    policy_gradient_loss | 0.00078     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 2.68e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.59e+03  |\n",
      "|    ep_rew_mean     | -2.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 456       |\n",
      "|    iterations      | 235       |\n",
      "|    time_elapsed    | 1054      |\n",
      "|    total_timesteps | 481280    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -2.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 1056        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014204324 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 259         |\n",
      "|    n_updates            | 18260       |\n",
      "|    policy_gradient_loss | -0.00642    |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 1.82e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=485000, episode_reward=29773.40 +/- 4387.68\n",
      "Episode length: 2207.00 +/- 21.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.21e+03    |\n",
      "|    mean_reward          | 2.98e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 485000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015628293 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 891         |\n",
      "|    n_updates            | 18270       |\n",
      "|    policy_gradient_loss | 0.0014      |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 1.93e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.62e+03  |\n",
      "|    ep_rew_mean     | -2.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 456       |\n",
      "|    iterations      | 237       |\n",
      "|    time_elapsed    | 1063      |\n",
      "|    total_timesteps | 485376    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -2.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 457         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 1065        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027524568 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32e+04    |\n",
      "|    n_updates            | 18280       |\n",
      "|    policy_gradient_loss | 0.00308     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 2.64e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -2.12e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 239         |\n",
      "|    time_elapsed         | 1067        |\n",
      "|    total_timesteps      | 489472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026054587 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 242         |\n",
      "|    n_updates            | 18290       |\n",
      "|    policy_gradient_loss | 0.004       |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=30017.48 +/- 5986.96\n",
      "Episode length: 2222.60 +/- 12.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.22e+03    |\n",
      "|    mean_reward          | 3e+04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 490000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018664138 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.06        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 411         |\n",
      "|    n_updates            | 18300       |\n",
      "|    policy_gradient_loss | 0.00128     |\n",
      "|    std                  | 0.234       |\n",
      "|    value_loss           | 2.11e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -1.97e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 457       |\n",
      "|    iterations      | 240       |\n",
      "|    time_elapsed    | 1074      |\n",
      "|    total_timesteps | 491520    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.66e+03    |\n",
      "|    ep_rew_mean          | -1.96e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 1076        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019563816 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.07        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 18310       |\n",
      "|    policy_gradient_loss | 0.00444     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 695         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=495000, episode_reward=29427.86 +/- 729.58\n",
      "Episode length: 2045.20 +/- 17.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.05e+03    |\n",
      "|    mean_reward          | 2.94e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 495000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014415693 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.08        |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 18320       |\n",
      "|    policy_gradient_loss | 0.00416     |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 8.44e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -1.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 457       |\n",
      "|    iterations      | 242       |\n",
      "|    time_elapsed    | 1082      |\n",
      "|    total_timesteps | 495616    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -1.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 458         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 1084        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047558192 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.09        |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.5        |\n",
      "|    n_updates            | 18330       |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    std                  | 0.232       |\n",
      "|    value_loss           | 1.23e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.7e+03    |\n",
      "|    ep_rew_mean          | -1.69e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 459        |\n",
      "|    iterations           | 244        |\n",
      "|    time_elapsed         | 1086       |\n",
      "|    total_timesteps      | 499712     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05401424 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.1        |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 63.3       |\n",
      "|    n_updates            | 18340      |\n",
      "|    policy_gradient_loss | 0.0138     |\n",
      "|    std                  | 0.232      |\n",
      "|    value_loss           | 206        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=500000, episode_reward=23075.93 +/- 3172.56\n",
      "Episode length: 1621.80 +/- 11.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.62e+03    |\n",
      "|    mean_reward          | 2.31e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037086252 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.11        |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 335         |\n",
      "|    n_updates            | 18350       |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    std                  | 0.233       |\n",
      "|    value_loss           | 1.73e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -1.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 459       |\n",
      "|    iterations      | 245       |\n",
      "|    time_elapsed    | 1092      |\n",
      "|    total_timesteps | 501760    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.66e+03    |\n",
      "|    ep_rew_mean          | -2.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 460         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 1093        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054274853 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.12        |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.77e+04    |\n",
      "|    n_updates            | 18360       |\n",
      "|    policy_gradient_loss | 0.0354      |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 3.83e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=505000, episode_reward=-55508.65 +/- 91671.83\n",
      "Episode length: 1040.80 +/- 768.65\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.04e+03  |\n",
      "|    mean_reward          | -5.55e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 505000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1972172 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.13      |\n",
      "|    explained_variance   | 0.312     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.22e+07  |\n",
      "|    n_updates            | 18370     |\n",
      "|    policy_gradient_loss | 0.0167    |\n",
      "|    std                  | 0.231     |\n",
      "|    value_loss           | 5.59e+07  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.65e+03 |\n",
      "|    ep_rew_mean     | -1.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 460      |\n",
      "|    iterations      | 247      |\n",
      "|    time_elapsed    | 1098     |\n",
      "|    total_timesteps | 505856   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.65e+03     |\n",
      "|    ep_rew_mean          | -1.79e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 461          |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 1100         |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014610585 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.13         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.36e+06     |\n",
      "|    n_updates            | 18380        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 3.02e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.64e+03     |\n",
      "|    ep_rew_mean          | -1.75e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 462          |\n",
      "|    iterations           | 249          |\n",
      "|    time_elapsed         | 1101         |\n",
      "|    total_timesteps      | 509952       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054127187 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.13         |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.89e+03     |\n",
      "|    n_updates            | 18390        |\n",
      "|    policy_gradient_loss | -0.00528     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 3.39e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=17606.08 +/- 7212.89\n",
      "Episode length: 1541.80 +/- 12.01\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.54e+03      |\n",
      "|    mean_reward          | 1.76e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 510000        |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00086903095 |\n",
      "|    clip_fraction        | 0.0022        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 2.13          |\n",
      "|    explained_variance   | 0.327         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.09e+06      |\n",
      "|    n_updates            | 18400         |\n",
      "|    policy_gradient_loss | -0.00124      |\n",
      "|    std                  | 0.231         |\n",
      "|    value_loss           | 2.33e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -2.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 462       |\n",
      "|    iterations      | 250       |\n",
      "|    time_elapsed    | 1107      |\n",
      "|    total_timesteps | 512000    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | -2.3e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 463          |\n",
      "|    iterations           | 251          |\n",
      "|    time_elapsed         | 1109         |\n",
      "|    total_timesteps      | 514048       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049657905 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.13         |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.8e+07      |\n",
      "|    n_updates            | 18410        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    std                  | 0.231        |\n",
      "|    value_loss           | 8.49e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=515000, episode_reward=20329.43 +/- 4171.70\n",
      "Episode length: 1638.40 +/- 12.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.64e+03    |\n",
      "|    mean_reward          | 2.03e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 515000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013808552 |\n",
      "|    clip_fraction        | 0.0601      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.13        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.57e+03    |\n",
      "|    n_updates            | 18420       |\n",
      "|    policy_gradient_loss | -0.00296    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 4.16e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -2.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 462       |\n",
      "|    iterations      | 252       |\n",
      "|    time_elapsed    | 1115      |\n",
      "|    total_timesteps | 516096    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -2.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 463         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 1116        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011092761 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.13        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 263         |\n",
      "|    n_updates            | 18430       |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.59e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=-16393.22 +/- 71390.55\n",
      "Episode length: 1524.60 +/- 713.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.52e+03    |\n",
      "|    mean_reward          | -1.64e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 520000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008797178 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.13        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 373         |\n",
      "|    n_updates            | 18440       |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.34e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -2.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 463       |\n",
      "|    iterations      | 254       |\n",
      "|    time_elapsed    | 1122      |\n",
      "|    total_timesteps | 520192    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -2.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 464         |\n",
      "|    iterations           | 255         |\n",
      "|    time_elapsed         | 1124        |\n",
      "|    total_timesteps      | 522240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009810766 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.13        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 18450       |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    std                  | 0.231       |\n",
      "|    value_loss           | 1.69e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -2.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 465         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 1126        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014657401 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.13        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 304         |\n",
      "|    n_updates            | 18460       |\n",
      "|    policy_gradient_loss | 0.00443     |\n",
      "|    std                  | 0.23        |\n",
      "|    value_loss           | 1.11e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=525000, episode_reward=-20659.45 +/- 72699.14\n",
      "Episode length: 1396.00 +/- 647.03\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.4e+03      |\n",
      "|    mean_reward          | -2.07e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 525000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068166396 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.14         |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 99.9         |\n",
      "|    n_updates            | 18470        |\n",
      "|    policy_gradient_loss | 0.0038       |\n",
      "|    std                  | 0.23         |\n",
      "|    value_loss           | 2.15e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -2.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 465       |\n",
      "|    iterations      | 257       |\n",
      "|    time_elapsed    | 1131      |\n",
      "|    total_timesteps | 526336    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -1.95e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 466         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 1133        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013376826 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.15        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 18480       |\n",
      "|    policy_gradient_loss | 0.00222     |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.66e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=18251.50 +/- 3276.51\n",
      "Episode length: 1696.40 +/- 10.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 1.83e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 530000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017929465 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.16        |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 18490       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.41e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -1.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 465       |\n",
      "|    iterations      | 259       |\n",
      "|    time_elapsed    | 1138      |\n",
      "|    total_timesteps | 530432    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.57e+03   |\n",
      "|    ep_rew_mean          | -1.65e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 466        |\n",
      "|    iterations           | 260        |\n",
      "|    time_elapsed         | 1140       |\n",
      "|    total_timesteps      | 532480     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02131647 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.16       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 118        |\n",
      "|    n_updates            | 18500      |\n",
      "|    policy_gradient_loss | 0.00168    |\n",
      "|    std                  | 0.228      |\n",
      "|    value_loss           | 552        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | -1.66e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 467         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 1142        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037416637 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.16        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 18510       |\n",
      "|    policy_gradient_loss | 0.00319     |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 2.15e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=535000, episode_reward=16077.58 +/- 2998.77\n",
      "Episode length: 1643.20 +/- 11.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.64e+03    |\n",
      "|    mean_reward          | 1.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 535000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021190098 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.16        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 18520       |\n",
      "|    policy_gradient_loss | 0.00892     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 408         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -1.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 467       |\n",
      "|    iterations      | 262       |\n",
      "|    time_elapsed    | 1148      |\n",
      "|    total_timesteps | 536576    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.56e+03   |\n",
      "|    ep_rew_mean          | -1.66e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 468        |\n",
      "|    iterations           | 263        |\n",
      "|    time_elapsed         | 1150       |\n",
      "|    total_timesteps      | 538624     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03563967 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.16       |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 31         |\n",
      "|    n_updates            | 18530      |\n",
      "|    policy_gradient_loss | 0.00987    |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 1.69e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=540000, episode_reward=-23029.93 +/- 76894.78\n",
      "Episode length: 1362.00 +/- 628.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.36e+03    |\n",
      "|    mean_reward          | -2.3e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 540000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041503794 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.15        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29e+04    |\n",
      "|    n_updates            | 18540       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -1.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 467       |\n",
      "|    iterations      | 264       |\n",
      "|    time_elapsed    | 1155      |\n",
      "|    total_timesteps | 540672    |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.51e+03  |\n",
      "|    ep_rew_mean          | -2.07e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 469       |\n",
      "|    iterations           | 265       |\n",
      "|    time_elapsed         | 1157      |\n",
      "|    total_timesteps      | 542720    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4009921 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.15      |\n",
      "|    explained_variance   | 0.311     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.95e+07  |\n",
      "|    n_updates            | 18550     |\n",
      "|    policy_gradient_loss | -0.0193   |\n",
      "|    std                  | 0.229     |\n",
      "|    value_loss           | 3e+07     |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.53e+03   |\n",
      "|    ep_rew_mean          | -1.92e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 470        |\n",
      "|    iterations           | 266        |\n",
      "|    time_elapsed         | 1159       |\n",
      "|    total_timesteps      | 544768     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14759892 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.16       |\n",
      "|    explained_variance   | 0.334      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.98e+07   |\n",
      "|    n_updates            | 18560      |\n",
      "|    policy_gradient_loss | -0.0232    |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 2.76e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=545000, episode_reward=14058.24 +/- 6089.37\n",
      "Episode length: 1726.20 +/- 9.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.73e+03    |\n",
      "|    mean_reward          | 1.41e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 545000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020713594 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.16        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.1        |\n",
      "|    n_updates            | 18570       |\n",
      "|    policy_gradient_loss | 0.00124     |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.48e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -1.93e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 469       |\n",
      "|    iterations      | 267       |\n",
      "|    time_elapsed    | 1164      |\n",
      "|    total_timesteps | 546816    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.52e+03   |\n",
      "|    ep_rew_mean          | -1.94e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 470        |\n",
      "|    iterations           | 268        |\n",
      "|    time_elapsed         | 1166       |\n",
      "|    total_timesteps      | 548864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08557377 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.17       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 89.3       |\n",
      "|    n_updates            | 18580      |\n",
      "|    policy_gradient_loss | 0.0197     |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 422        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=550000, episode_reward=-15386.11 +/- 56783.81\n",
      "Episode length: 1374.20 +/- 648.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.37e+03    |\n",
      "|    mean_reward          | -1.54e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009923674 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.763       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+05    |\n",
      "|    n_updates            | 18590       |\n",
      "|    policy_gradient_loss | 0.001       |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 2.15e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -2.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 470       |\n",
      "|    iterations      | 269       |\n",
      "|    time_elapsed    | 1171      |\n",
      "|    total_timesteps | 550912    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -2.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 1173        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001699797 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.16e+07    |\n",
      "|    n_updates            | 18600       |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 4.96e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=555000, episode_reward=-13668.07 +/- 59194.26\n",
      "Episode length: 1352.20 +/- 635.63\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.35e+03     |\n",
      "|    mean_reward          | -1.37e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 555000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077857506 |\n",
      "|    clip_fraction        | 0.0469       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.17         |\n",
      "|    explained_variance   | 0.899        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.29e+03     |\n",
      "|    n_updates            | 18610        |\n",
      "|    policy_gradient_loss | -0.00602     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 3.52e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -1.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 470       |\n",
      "|    iterations      | 271       |\n",
      "|    time_elapsed    | 1178      |\n",
      "|    total_timesteps | 555008    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -1.7e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 1180        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007632665 |\n",
      "|    clip_fraction        | 0.0578      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.16        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 513         |\n",
      "|    n_updates            | 18620       |\n",
      "|    policy_gradient_loss | -0.00506    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 3.79e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.54e+03   |\n",
      "|    ep_rew_mean          | -1.71e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 472        |\n",
      "|    iterations           | 273        |\n",
      "|    time_elapsed         | 1182       |\n",
      "|    total_timesteps      | 559104     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01485184 |\n",
      "|    clip_fraction        | 0.0977     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.16       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 162        |\n",
      "|    n_updates            | 18630      |\n",
      "|    policy_gradient_loss | -0.00216   |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 1.29e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=-19270.33 +/- 57747.97\n",
      "Episode length: 1346.80 +/- 631.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.35e+03    |\n",
      "|    mean_reward          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 560000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012852452 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.3        |\n",
      "|    n_updates            | 18640       |\n",
      "|    policy_gradient_loss | 0.00552     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 775         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -1.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 472       |\n",
      "|    iterations      | 274       |\n",
      "|    time_elapsed    | 1187      |\n",
      "|    total_timesteps | 561152    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -1.75e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 1189        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014833296 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.8        |\n",
      "|    n_updates            | 18650       |\n",
      "|    policy_gradient_loss | 0.00436     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 1.67e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=565000, episode_reward=7997.77 +/- 5616.66\n",
      "Episode length: 1670.40 +/- 11.94\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.67e+03     |\n",
      "|    mean_reward          | 8e+03        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 565000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0081265895 |\n",
      "|    clip_fraction        | 0.0839       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.18         |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.75e+05     |\n",
      "|    n_updates            | 18660        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 5.64e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -1.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 472       |\n",
      "|    iterations      | 276       |\n",
      "|    time_elapsed    | 1195      |\n",
      "|    total_timesteps | 565248    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.54e+03   |\n",
      "|    ep_rew_mean          | -1.77e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 473        |\n",
      "|    iterations           | 277        |\n",
      "|    time_elapsed         | 1197       |\n",
      "|    total_timesteps      | 567296     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01423918 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.18       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 223        |\n",
      "|    n_updates            | 18670      |\n",
      "|    policy_gradient_loss | -0.00178   |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 504        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -1.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 474         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 1198        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025139447 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.9        |\n",
      "|    n_updates            | 18680       |\n",
      "|    policy_gradient_loss | 0.00549     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 1.57e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=-13231.69 +/- 58100.24\n",
      "Episode length: 1332.80 +/- 624.94\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.33e+03   |\n",
      "|    mean_reward          | -1.32e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 570000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01585965 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.17       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 175        |\n",
      "|    n_updates            | 18690      |\n",
      "|    policy_gradient_loss | 0.00335    |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 486        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -1.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 474       |\n",
      "|    iterations      | 279       |\n",
      "|    time_elapsed    | 1204      |\n",
      "|    total_timesteps | 571392    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -1.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 280         |\n",
      "|    time_elapsed         | 1205        |\n",
      "|    total_timesteps      | 573440      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024726808 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 18700       |\n",
      "|    policy_gradient_loss | 0.0051      |\n",
      "|    std                  | 0.23        |\n",
      "|    value_loss           | 3.68e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=575000, episode_reward=18016.55 +/- 198.29\n",
      "Episode length: 1633.80 +/- 7.96\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.63e+03     |\n",
      "|    mean_reward          | 1.8e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 575000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060121734 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.17         |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.09e+03     |\n",
      "|    n_updates            | 18710        |\n",
      "|    policy_gradient_loss | 0.00163      |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 3.83e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -1.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 474       |\n",
      "|    iterations      | 281       |\n",
      "|    time_elapsed    | 1211      |\n",
      "|    total_timesteps | 575488    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.55e+03   |\n",
      "|    ep_rew_mean          | -1.64e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 475        |\n",
      "|    iterations           | 282        |\n",
      "|    time_elapsed         | 1213       |\n",
      "|    total_timesteps      | 577536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07146403 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.17       |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 90.2       |\n",
      "|    n_updates            | 18720      |\n",
      "|    policy_gradient_loss | 0.00612    |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 3.28e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -1.66e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 283         |\n",
      "|    time_elapsed         | 1215        |\n",
      "|    total_timesteps      | 579584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010315927 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.311       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11e+07    |\n",
      "|    n_updates            | 18730       |\n",
      "|    policy_gradient_loss | -0.00099    |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.74e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=8523.04 +/- 6116.64\n",
      "Episode length: 1677.20 +/- 5.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.68e+03    |\n",
      "|    mean_reward          | 8.52e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008939285 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 273         |\n",
      "|    n_updates            | 18740       |\n",
      "|    policy_gradient_loss | -0.00733    |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -1.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 284       |\n",
      "|    time_elapsed    | 1221      |\n",
      "|    total_timesteps | 581632    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -1.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 285         |\n",
      "|    time_elapsed         | 1223        |\n",
      "|    total_timesteps      | 583680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012373797 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 18750       |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 2.18e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=585000, episode_reward=12984.88 +/- 5391.57\n",
      "Episode length: 1685.00 +/- 6.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.68e+03    |\n",
      "|    mean_reward          | 1.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 585000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028360827 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 18760       |\n",
      "|    policy_gradient_loss | 0.0146      |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 397         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -1.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 286       |\n",
      "|    time_elapsed    | 1228      |\n",
      "|    total_timesteps | 585728    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -1.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 287         |\n",
      "|    time_elapsed         | 1230        |\n",
      "|    total_timesteps      | 587776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026226887 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.01e+03    |\n",
      "|    n_updates            | 18770       |\n",
      "|    policy_gradient_loss | 0.00595     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 5.31e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.54e+03   |\n",
      "|    ep_rew_mean          | -1.51e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 478        |\n",
      "|    iterations           | 288        |\n",
      "|    time_elapsed         | 1232       |\n",
      "|    total_timesteps      | 589824     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11539067 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.18       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 37.8       |\n",
      "|    n_updates            | 18780      |\n",
      "|    policy_gradient_loss | 0.00868    |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 190        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=590000, episode_reward=-93913.12 +/- 4544.49\n",
      "Episode length: 2430.80 +/- 12.16\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.43e+03  |\n",
      "|    mean_reward          | -9.39e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 590000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4280969 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.18      |\n",
      "|    explained_variance   | 0.357     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.73e+06  |\n",
      "|    n_updates            | 18790     |\n",
      "|    policy_gradient_loss | 0.00652   |\n",
      "|    std                  | 0.229     |\n",
      "|    value_loss           | 1.83e+07  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -1.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 477       |\n",
      "|    iterations      | 289       |\n",
      "|    time_elapsed    | 1240      |\n",
      "|    total_timesteps | 591872    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -1.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 1242        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009172477 |\n",
      "|    clip_fraction        | 0.098       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.19e+04    |\n",
      "|    n_updates            | 18800       |\n",
      "|    policy_gradient_loss | 0.00131     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 1.97e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=595000, episode_reward=-128019.77 +/- 7759.73\n",
      "Episode length: 2647.60 +/- 12.14\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.65e+03   |\n",
      "|    mean_reward          | -1.28e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 595000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01173401 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.18       |\n",
      "|    explained_variance   | 0.559      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.27e+05   |\n",
      "|    n_updates            | 18810      |\n",
      "|    policy_gradient_loss | 0.00678    |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 9.55e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.55e+03  |\n",
      "|    ep_rew_mean     | -1.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 291       |\n",
      "|    time_elapsed    | 1250      |\n",
      "|    total_timesteps | 595968    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -1.91e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 1252        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010413885 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.56e+05    |\n",
      "|    n_updates            | 18820       |\n",
      "|    policy_gradient_loss | 0.00142     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 2.15e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=600000, episode_reward=-150804.06 +/- 5616.23\n",
      "Episode length: 2642.40 +/- 36.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.64e+03     |\n",
      "|    mean_reward          | -1.51e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 600000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054010097 |\n",
      "|    clip_fraction        | 0.0923       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.17         |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.81e+04     |\n",
      "|    n_updates            | 18830        |\n",
      "|    policy_gradient_loss | -0.0024      |\n",
      "|    std                  | 0.23         |\n",
      "|    value_loss           | 1.51e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -1.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 293       |\n",
      "|    time_elapsed    | 1260      |\n",
      "|    total_timesteps | 600064    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | -1.73e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 477          |\n",
      "|    iterations           | 294          |\n",
      "|    time_elapsed         | 1262         |\n",
      "|    total_timesteps      | 602112       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058724424 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.17         |\n",
      "|    explained_variance   | 0.746        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.45e+03     |\n",
      "|    n_updates            | 18840        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    std                  | 0.23         |\n",
      "|    value_loss           | 5.2e+04      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.52e+03   |\n",
      "|    ep_rew_mean          | -1.88e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 477        |\n",
      "|    iterations           | 295        |\n",
      "|    time_elapsed         | 1264       |\n",
      "|    total_timesteps      | 604160     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00718241 |\n",
      "|    clip_fraction        | 0.034      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.17       |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 887        |\n",
      "|    n_updates            | 18850      |\n",
      "|    policy_gradient_loss | -0.00453   |\n",
      "|    std                  | 0.229      |\n",
      "|    value_loss           | 7.57e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=605000, episode_reward=-147444.54 +/- 2591.85\n",
      "Episode length: 2640.80 +/- 12.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.64e+03    |\n",
      "|    mean_reward          | -1.47e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 605000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008111097 |\n",
      "|    clip_fraction        | 0.0466      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.96e+06    |\n",
      "|    n_updates            | 18860       |\n",
      "|    policy_gradient_loss | -0.00485    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 1.81e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -1.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 296       |\n",
      "|    time_elapsed    | 1272      |\n",
      "|    total_timesteps | 606208    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -1.75e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 297         |\n",
      "|    time_elapsed         | 1274        |\n",
      "|    total_timesteps      | 608256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010614385 |\n",
      "|    clip_fraction        | 0.0737      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 357         |\n",
      "|    n_updates            | 18870       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 4.87e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=15005.86 +/- 4597.36\n",
      "Episode length: 1806.80 +/- 12.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.81e+03    |\n",
      "|    mean_reward          | 1.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 610000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025038848 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.1e+06     |\n",
      "|    n_updates            | 18880       |\n",
      "|    policy_gradient_loss | 0.00214     |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 3.5e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -1.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 298       |\n",
      "|    time_elapsed    | 1280      |\n",
      "|    total_timesteps | 610304    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -1.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 1281        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020004835 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 251         |\n",
      "|    n_updates            | 18890       |\n",
      "|    policy_gradient_loss | -0.000708   |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 2.42e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | -1.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 1283        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013798613 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 432         |\n",
      "|    n_updates            | 18900       |\n",
      "|    policy_gradient_loss | -0.00749    |\n",
      "|    std                  | 0.229       |\n",
      "|    value_loss           | 939         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=615000, episode_reward=12534.69 +/- 4974.86\n",
      "Episode length: 1733.40 +/- 6.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.73e+03     |\n",
      "|    mean_reward          | 1.25e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 615000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064387973 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.17         |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+07      |\n",
      "|    n_updates            | 18910        |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    std                  | 0.229        |\n",
      "|    value_loss           | 1.83e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -1.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 477       |\n",
      "|    iterations      | 301       |\n",
      "|    time_elapsed    | 1289      |\n",
      "|    total_timesteps | 616448    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | -1.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 302         |\n",
      "|    time_elapsed         | 1291        |\n",
      "|    total_timesteps      | 618496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017729571 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.17        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+03    |\n",
      "|    n_updates            | 18920       |\n",
      "|    policy_gradient_loss | 0.00433     |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.43e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=12745.60 +/- 1719.94\n",
      "Episode length: 1739.80 +/- 10.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.74e+03    |\n",
      "|    mean_reward          | 1.27e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 620000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012430081 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.18        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 18930       |\n",
      "|    policy_gradient_loss | -0.000413   |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.58e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -1.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 478       |\n",
      "|    iterations      | 303       |\n",
      "|    time_elapsed    | 1297      |\n",
      "|    total_timesteps | 620544    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | -1.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 479         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 1299        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020641487 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 308         |\n",
      "|    n_updates            | 18940       |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -1.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 480         |\n",
      "|    iterations           | 305         |\n",
      "|    time_elapsed         | 1301        |\n",
      "|    total_timesteps      | 624640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008599808 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 18950       |\n",
      "|    policy_gradient_loss | 0.0141      |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 3.91e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=625000, episode_reward=13419.35 +/- 4600.87\n",
      "Episode length: 1425.80 +/- 10.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.43e+03    |\n",
      "|    mean_reward          | 1.34e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 625000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027700918 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.3        |\n",
      "|    n_updates            | 18960       |\n",
      "|    policy_gradient_loss | 0.00918     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.78e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -1.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 479       |\n",
      "|    iterations      | 306       |\n",
      "|    time_elapsed    | 1306      |\n",
      "|    total_timesteps | 626688    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -1.42e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 480         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 1308        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019925663 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 282         |\n",
      "|    n_updates            | 18970       |\n",
      "|    policy_gradient_loss | 0.0025      |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=8466.85 +/- 6358.15\n",
      "Episode length: 1310.20 +/- 13.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.31e+03    |\n",
      "|    mean_reward          | 8.47e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 630000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037500784 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 18980       |\n",
      "|    policy_gradient_loss | 0.00707     |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 5.03e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -1.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 480       |\n",
      "|    iterations      | 308       |\n",
      "|    time_elapsed    | 1313      |\n",
      "|    total_timesteps | 630784    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | -1.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 481         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 1315        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017739113 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.19        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.2        |\n",
      "|    n_updates            | 18990       |\n",
      "|    policy_gradient_loss | 0.0051      |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 3.29e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -1.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 482         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 1316        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025692016 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72          |\n",
      "|    n_updates            | 19000       |\n",
      "|    policy_gradient_loss | 0.00724     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 7.03e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=635000, episode_reward=12433.47 +/- 6580.63\n",
      "Episode length: 1332.40 +/- 19.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.33e+03    |\n",
      "|    mean_reward          | 1.24e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 635000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016327834 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.9        |\n",
      "|    n_updates            | 19010       |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 360         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -1.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 481       |\n",
      "|    iterations      | 311       |\n",
      "|    time_elapsed    | 1321      |\n",
      "|    total_timesteps | 636928    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | -1.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 482         |\n",
      "|    iterations           | 312         |\n",
      "|    time_elapsed         | 1323        |\n",
      "|    total_timesteps      | 638976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027246349 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.9        |\n",
      "|    n_updates            | 19020       |\n",
      "|    policy_gradient_loss | 0.000993    |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 2.19e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=11122.93 +/- 8030.64\n",
      "Episode length: 1318.60 +/- 28.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.32e+03    |\n",
      "|    mean_reward          | 1.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 640000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051397435 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.3        |\n",
      "|    n_updates            | 19030       |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 1.48e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.41e+03 |\n",
      "|    ep_rew_mean     | -1.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 482      |\n",
      "|    iterations      | 313      |\n",
      "|    time_elapsed    | 1328     |\n",
      "|    total_timesteps | 641024   |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.41e+03  |\n",
      "|    ep_rew_mean          | -1.6e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 483       |\n",
      "|    iterations           | 314       |\n",
      "|    time_elapsed         | 1330      |\n",
      "|    total_timesteps      | 643072    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0373863 |\n",
      "|    clip_fraction        | 0.255     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.2       |\n",
      "|    explained_variance   | 0.867     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 37        |\n",
      "|    n_updates            | 19040     |\n",
      "|    policy_gradient_loss | 0.0149    |\n",
      "|    std                  | 0.228     |\n",
      "|    value_loss           | 1.42e+05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=645000, episode_reward=15523.63 +/- 4655.21\n",
      "Episode length: 1779.80 +/- 14.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.78e+03    |\n",
      "|    mean_reward          | 1.55e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 645000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018895375 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.2         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.8        |\n",
      "|    n_updates            | 19050       |\n",
      "|    policy_gradient_loss | -0.000242   |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.42e+03  |\n",
      "|    ep_rew_mean     | -1.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 482       |\n",
      "|    iterations      | 315       |\n",
      "|    time_elapsed    | 1336      |\n",
      "|    total_timesteps | 645120    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | -1.27e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 483         |\n",
      "|    iterations           | 316         |\n",
      "|    time_elapsed         | 1338        |\n",
      "|    total_timesteps      | 647168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009971202 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.21        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.8        |\n",
      "|    n_updates            | 19060       |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    std                  | 0.228       |\n",
      "|    value_loss           | 358         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -1.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 484         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 1340        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015326584 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.22        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 19070       |\n",
      "|    policy_gradient_loss | 0.00227     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 90.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=15462.27 +/- 5655.17\n",
      "Episode length: 1766.80 +/- 6.34\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.77e+03   |\n",
      "|    mean_reward          | 1.55e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 650000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01810331 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.23       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 80.4       |\n",
      "|    n_updates            | 19080      |\n",
      "|    policy_gradient_loss | -0.00654   |\n",
      "|    std                  | 0.227      |\n",
      "|    value_loss           | 2.2e+04    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -1.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 483       |\n",
      "|    iterations      | 318       |\n",
      "|    time_elapsed    | 1346      |\n",
      "|    total_timesteps | 651264    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -9.39e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 484         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 1348        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009412893 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 182         |\n",
      "|    n_updates            | 19090       |\n",
      "|    policy_gradient_loss | 0.00118     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 447         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=655000, episode_reward=17156.63 +/- 4532.13\n",
      "Episode length: 1766.80 +/- 18.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.77e+03    |\n",
      "|    mean_reward          | 1.72e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 655000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019229244 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 19100       |\n",
      "|    policy_gradient_loss | 0.0262      |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 75.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -9.56e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 483       |\n",
      "|    iterations      | 320       |\n",
      "|    time_elapsed    | 1354      |\n",
      "|    total_timesteps | 655360    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.46e+03   |\n",
      "|    ep_rew_mean          | -7.68e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 484        |\n",
      "|    iterations           | 321        |\n",
      "|    time_elapsed         | 1356       |\n",
      "|    total_timesteps      | 657408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01126172 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.23       |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 40.8       |\n",
      "|    n_updates            | 19110      |\n",
      "|    policy_gradient_loss | -0.00294   |\n",
      "|    std                  | 0.227      |\n",
      "|    value_loss           | 3.27e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -5.86e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 485         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 1357        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055513147 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.7        |\n",
      "|    n_updates            | 19120       |\n",
      "|    policy_gradient_loss | 0.00536     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.66e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=18521.94 +/- 1494.19\n",
      "Episode length: 1387.20 +/- 8.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.39e+03    |\n",
      "|    mean_reward          | 1.85e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 660000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020341853 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.8        |\n",
      "|    n_updates            | 19130       |\n",
      "|    policy_gradient_loss | 0.00194     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 1.24e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -3.95e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 485       |\n",
      "|    iterations      | 323       |\n",
      "|    time_elapsed    | 1363      |\n",
      "|    total_timesteps | 661504    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -3.92e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 486         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 1365        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019619068 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.23        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.4        |\n",
      "|    n_updates            | 19140       |\n",
      "|    policy_gradient_loss | 0.00333     |\n",
      "|    std                  | 0.227       |\n",
      "|    value_loss           | 74.4        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=665000, episode_reward=17048.24 +/- 4482.14\n",
      "Episode length: 1698.80 +/- 12.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 1.7e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 665000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015172346 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.24        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50          |\n",
      "|    n_updates            | 19150       |\n",
      "|    policy_gradient_loss | -0.00595    |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -3.98e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 485       |\n",
      "|    iterations      | 325       |\n",
      "|    time_elapsed    | 1370      |\n",
      "|    total_timesteps | 665600    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -3.98e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 486         |\n",
      "|    iterations           | 326         |\n",
      "|    time_elapsed         | 1372        |\n",
      "|    total_timesteps      | 667648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012642568 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55          |\n",
      "|    n_updates            | 19160       |\n",
      "|    policy_gradient_loss | 0.000153    |\n",
      "|    std                  | 0.226       |\n",
      "|    value_loss           | 587         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -4.13e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 487         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 1374        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029687492 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.2        |\n",
      "|    n_updates            | 19170       |\n",
      "|    policy_gradient_loss | 0.00979     |\n",
      "|    std                  | 0.225       |\n",
      "|    value_loss           | 1.7e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=18772.35 +/- 3335.69\n",
      "Episode length: 1777.20 +/- 14.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.78e+03   |\n",
      "|    mean_reward          | 1.88e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 670000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03222434 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.28       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.18e+04   |\n",
      "|    n_updates            | 19180      |\n",
      "|    policy_gradient_loss | -0.000488  |\n",
      "|    std                  | 0.223      |\n",
      "|    value_loss           | 2.89e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -4.05e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 486       |\n",
      "|    iterations      | 328       |\n",
      "|    time_elapsed    | 1380      |\n",
      "|    total_timesteps | 671744    |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.47e+03   |\n",
      "|    ep_rew_mean          | -4.07e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 487        |\n",
      "|    iterations           | 329        |\n",
      "|    time_elapsed         | 1382       |\n",
      "|    total_timesteps      | 673792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02819661 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.29       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 34.7       |\n",
      "|    n_updates            | 19190      |\n",
      "|    policy_gradient_loss | 0.00657    |\n",
      "|    std                  | 0.222      |\n",
      "|    value_loss           | 332        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=675000, episode_reward=17351.56 +/- 5929.90\n",
      "Episode length: 1783.80 +/- 10.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.78e+03    |\n",
      "|    mean_reward          | 1.74e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 675000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020705856 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.29        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.3        |\n",
      "|    n_updates            | 19200       |\n",
      "|    policy_gradient_loss | -0.00665    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 74.9        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -4.04e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 486       |\n",
      "|    iterations      | 330       |\n",
      "|    time_elapsed    | 1388      |\n",
      "|    total_timesteps | 675840    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -3.84e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 487         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 1390        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008439003 |\n",
      "|    clip_fraction        | 0.0993      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.29        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 19210       |\n",
      "|    policy_gradient_loss | 0.00339     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 295         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -3.82e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 488         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 1392        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015173304 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.29        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.6        |\n",
      "|    n_updates            | 19220       |\n",
      "|    policy_gradient_loss | 0.000139    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=680000, episode_reward=15783.65 +/- 8807.65\n",
      "Episode length: 1912.40 +/- 31.38\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.91e+03   |\n",
      "|    mean_reward          | 1.58e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 680000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01506455 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.29       |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 264        |\n",
      "|    n_updates            | 19230      |\n",
      "|    policy_gradient_loss | 0.000984   |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 4.87e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -3.86e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 487       |\n",
      "|    iterations      | 333       |\n",
      "|    time_elapsed    | 1398      |\n",
      "|    total_timesteps | 681984    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -3.74e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 488         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 1400        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.076061726 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.29        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 19240       |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=685000, episode_reward=22061.40 +/- 4457.63\n",
      "Episode length: 1882.40 +/- 10.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.88e+03    |\n",
      "|    mean_reward          | 2.21e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 685000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019309519 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.27        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 19250       |\n",
      "|    policy_gradient_loss | 0.00697     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 107         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -3.71e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 487       |\n",
      "|    iterations      | 335       |\n",
      "|    time_elapsed    | 1407      |\n",
      "|    total_timesteps | 686080    |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -1.61e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 488         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 1408        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021328488 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.27        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.2        |\n",
      "|    n_updates            | 19260       |\n",
      "|    policy_gradient_loss | 0.00106     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.63e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=18464.17 +/- 5077.26\n",
      "Episode length: 1945.00 +/- 12.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.94e+03    |\n",
      "|    mean_reward          | 1.85e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 690000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018148482 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.28        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.7        |\n",
      "|    n_updates            | 19270       |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 129         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -1.54e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 487       |\n",
      "|    iterations      | 337       |\n",
      "|    time_elapsed    | 1415      |\n",
      "|    total_timesteps | 690176    |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | 338          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 488          |\n",
      "|    iterations           | 338          |\n",
      "|    time_elapsed         | 1417         |\n",
      "|    total_timesteps      | 692224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0117476415 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.3          |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32.6         |\n",
      "|    n_updates            | 19280        |\n",
      "|    policy_gradient_loss | 0.00453      |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 1.24e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | 362         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 1419        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015463071 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.31        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 19290       |\n",
      "|    policy_gradient_loss | 0.0062      |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1.66e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=695000, episode_reward=-26216.82 +/- 62063.76\n",
      "Episode length: 1267.00 +/- 977.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.27e+03    |\n",
      "|    mean_reward          | -2.62e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 695000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008705583 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.31        |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.9        |\n",
      "|    n_updates            | 19300       |\n",
      "|    policy_gradient_loss | 0.00453     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 2.3e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.51e+03 |\n",
      "|    ep_rew_mean     | 424      |\n",
      "| time/              |          |\n",
      "|    fps             | 489      |\n",
      "|    iterations      | 340      |\n",
      "|    time_elapsed    | 1423     |\n",
      "|    total_timesteps | 696320   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | 496         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 341         |\n",
      "|    time_elapsed         | 1425        |\n",
      "|    total_timesteps      | 698368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016376495 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.3        |\n",
      "|    n_updates            | 19310       |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1.25e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=2358.36 +/- 8144.01\n",
      "Episode length: 2356.00 +/- 145.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.36e+03    |\n",
      "|    mean_reward          | 2.36e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 700000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022973508 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.6        |\n",
      "|    n_updates            | 19320       |\n",
      "|    policy_gradient_loss | 0.00604     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.51e+03 |\n",
      "|    ep_rew_mean     | 581      |\n",
      "| time/              |          |\n",
      "|    fps             | 488      |\n",
      "|    iterations      | 342      |\n",
      "|    time_elapsed    | 1433     |\n",
      "|    total_timesteps | 700416   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 2.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 1435        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021365661 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.1        |\n",
      "|    n_updates            | 19330       |\n",
      "|    policy_gradient_loss | 0.0129      |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 3.68e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 1436        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014568077 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.33        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.6        |\n",
      "|    n_updates            | 19340       |\n",
      "|    policy_gradient_loss | 0.0054      |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 3.27e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=705000, episode_reward=18797.77 +/- 6351.45\n",
      "Episode length: 1956.00 +/- 19.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.96e+03    |\n",
      "|    mean_reward          | 1.88e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 705000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026248543 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.6        |\n",
      "|    n_updates            | 19350       |\n",
      "|    policy_gradient_loss | 0.00733     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | 2.72e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 489      |\n",
      "|    iterations      | 345      |\n",
      "|    time_elapsed    | 1443     |\n",
      "|    total_timesteps | 706560   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 1.83e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 490          |\n",
      "|    iterations           | 346          |\n",
      "|    time_elapsed         | 1445         |\n",
      "|    total_timesteps      | 708608       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072353953 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.32         |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1e+07        |\n",
      "|    n_updates            | 19360        |\n",
      "|    policy_gradient_loss | -0.000475    |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 2.07e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=-52006.17 +/- 64361.36\n",
      "Episode length: 813.20 +/- 912.29\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 813          |\n",
      "|    mean_reward          | -5.2e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 710000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017158194 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.32         |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.27e+07     |\n",
      "|    n_updates            | 19370        |\n",
      "|    policy_gradient_loss | -0.00575     |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 1.88e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | 1.98e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 490      |\n",
      "|    iterations      | 347      |\n",
      "|    time_elapsed    | 1449     |\n",
      "|    total_timesteps | 710656   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 1.97e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 491          |\n",
      "|    iterations           | 348          |\n",
      "|    time_elapsed         | 1450         |\n",
      "|    total_timesteps      | 712704       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067792693 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.32         |\n",
      "|    explained_variance   | 0.887        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+03     |\n",
      "|    n_updates            | 19380        |\n",
      "|    policy_gradient_loss | -0.00382     |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 3.14e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.53e+03     |\n",
      "|    ep_rew_mean          | 2.07e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 491          |\n",
      "|    iterations           | 349          |\n",
      "|    time_elapsed         | 1452         |\n",
      "|    total_timesteps      | 714752       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105545875 |\n",
      "|    clip_fraction        | 0.0686       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.32         |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 429          |\n",
      "|    n_updates            | 19390        |\n",
      "|    policy_gradient_loss | -0.00559     |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 2.53e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=715000, episode_reward=-28146.66 +/- 56447.44\n",
      "Episode length: 1202.40 +/- 929.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.2e+03     |\n",
      "|    mean_reward          | -2.81e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 715000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005147745 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 202         |\n",
      "|    n_updates            | 19400       |\n",
      "|    policy_gradient_loss | -0.000599   |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 3.41e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | 2.28e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 491      |\n",
      "|    iterations      | 350      |\n",
      "|    time_elapsed    | 1457     |\n",
      "|    total_timesteps | 716800   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 1.28e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 492         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 1459        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007640947 |\n",
      "|    clip_fraction        | 0.0695      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 19410       |\n",
      "|    policy_gradient_loss | -0.00176    |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 3.47e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=24855.86 +/- 2067.34\n",
      "Episode length: 1962.80 +/- 13.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.96e+03    |\n",
      "|    mean_reward          | 2.49e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 720000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017619928 |\n",
      "|    clip_fraction        | 0.0534      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.7e+06     |\n",
      "|    n_updates            | 19420       |\n",
      "|    policy_gradient_loss | 0.00428     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1.02e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.52e+03 |\n",
      "|    ep_rew_mean     | 1.41e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 491      |\n",
      "|    iterations      | 352      |\n",
      "|    time_elapsed    | 1465     |\n",
      "|    total_timesteps | 720896   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 1.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 492         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 1467        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012070056 |\n",
      "|    clip_fraction        | 0.0943      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 276         |\n",
      "|    n_updates            | 19430       |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.52e+03   |\n",
      "|    ep_rew_mean          | 1.79e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 493        |\n",
      "|    iterations           | 354        |\n",
      "|    time_elapsed         | 1469       |\n",
      "|    total_timesteps      | 724992     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06395877 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.33       |\n",
      "|    explained_variance   | 0.922      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 201        |\n",
      "|    n_updates            | 19440      |\n",
      "|    policy_gradient_loss | -0.00202   |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 1.89e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=725000, episode_reward=-3653.59 +/- 46544.05\n",
      "Episode length: 1498.60 +/- 717.15\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.5e+03    |\n",
      "|    mean_reward          | -3.65e+03  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 725000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03193576 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.32       |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 200        |\n",
      "|    n_updates            | 19450      |\n",
      "|    policy_gradient_loss | 6.52e-05   |\n",
      "|    std                  | 0.22       |\n",
      "|    value_loss           | 1.84e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.52e+03 |\n",
      "|    ep_rew_mean     | 1.86e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 492      |\n",
      "|    iterations      | 355      |\n",
      "|    time_elapsed    | 1475     |\n",
      "|    total_timesteps | 727040   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 2.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 1476        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011106295 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 19460       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 728         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=730000, episode_reward=21872.96 +/- 394.82\n",
      "Episode length: 1793.20 +/- 14.77\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.79e+03   |\n",
      "|    mean_reward          | 2.19e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 730000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00823475 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.33       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 126        |\n",
      "|    n_updates            | 19470      |\n",
      "|    policy_gradient_loss | 0.00272    |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 627        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | 3.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 492      |\n",
      "|    iterations      | 357      |\n",
      "|    time_elapsed    | 1483     |\n",
      "|    total_timesteps | 731136   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 3.31e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 358         |\n",
      "|    time_elapsed         | 1484        |\n",
      "|    total_timesteps      | 733184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019935474 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.33        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 19480       |\n",
      "|    policy_gradient_loss | 0.00721     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 1.3e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=735000, episode_reward=18701.96 +/- 7079.24\n",
      "Episode length: 1781.60 +/- 26.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.78e+03    |\n",
      "|    mean_reward          | 1.87e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 735000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014545318 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.34        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.5        |\n",
      "|    n_updates            | 19490       |\n",
      "|    policy_gradient_loss | 0.00566     |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 266         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | 3.37e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 493      |\n",
      "|    iterations      | 359      |\n",
      "|    time_elapsed    | 1491     |\n",
      "|    total_timesteps | 735232   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.54e+03   |\n",
      "|    ep_rew_mean          | 3.52e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 493        |\n",
      "|    iterations           | 360        |\n",
      "|    time_elapsed         | 1492       |\n",
      "|    total_timesteps      | 737280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07801283 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.34       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 247        |\n",
      "|    n_updates            | 19500      |\n",
      "|    policy_gradient_loss | 0.00709    |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 527        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | 3.45e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 361          |\n",
      "|    time_elapsed         | 1494         |\n",
      "|    total_timesteps      | 739328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0143044265 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.33         |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.98e+03     |\n",
      "|    n_updates            | 19510        |\n",
      "|    policy_gradient_loss | 0.00455      |\n",
      "|    std                  | 0.219        |\n",
      "|    value_loss           | 6.42e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=-10865.48 +/- 47583.48\n",
      "Episode length: 1581.60 +/- 754.58\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.58e+03   |\n",
      "|    mean_reward          | -1.09e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 740000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01809023 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.32       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 45.4       |\n",
      "|    n_updates            | 19520      |\n",
      "|    policy_gradient_loss | 0.00426    |\n",
      "|    std                  | 0.22       |\n",
      "|    value_loss           | 235        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.54e+03 |\n",
      "|    ep_rew_mean     | 3.63e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 494      |\n",
      "|    iterations      | 362      |\n",
      "|    time_elapsed    | 1500     |\n",
      "|    total_timesteps | 741376   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 4.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 363         |\n",
      "|    time_elapsed         | 1502        |\n",
      "|    total_timesteps      | 743424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020423852 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.31        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.2        |\n",
      "|    n_updates            | 19530       |\n",
      "|    policy_gradient_loss | 0.00658     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 367         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=745000, episode_reward=20121.77 +/- 5077.77\n",
      "Episode length: 1951.40 +/- 12.75\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.95e+03     |\n",
      "|    mean_reward          | 2.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 745000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0154305305 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.3          |\n",
      "|    explained_variance   | 0.384        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.77e+06     |\n",
      "|    n_updates            | 19540        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 1.23e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.54e+03 |\n",
      "|    ep_rew_mean     | 4.17e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 494      |\n",
      "|    iterations      | 364      |\n",
      "|    time_elapsed    | 1508     |\n",
      "|    total_timesteps | 745472   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 6.06e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 365         |\n",
      "|    time_elapsed         | 1510        |\n",
      "|    total_timesteps      | 747520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012098325 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.3         |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 19550       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 380         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.52e+03     |\n",
      "|    ep_rew_mean          | 5.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 495          |\n",
      "|    iterations           | 366          |\n",
      "|    time_elapsed         | 1512         |\n",
      "|    total_timesteps      | 749568       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013642147 |\n",
      "|    clip_fraction        | 0.00991      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.3          |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.95e+07     |\n",
      "|    n_updates            | 19560        |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 1.37e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=750000, episode_reward=18641.52 +/- 3608.46\n",
      "Episode length: 1497.00 +/- 14.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.5e+03      |\n",
      "|    mean_reward          | 1.86e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 750000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015142942 |\n",
      "|    clip_fraction        | 0.00293      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.3          |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86e+06     |\n",
      "|    n_updates            | 19570        |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    std                  | 0.22         |\n",
      "|    value_loss           | 1.64e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.52e+03 |\n",
      "|    ep_rew_mean     | 6.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 495      |\n",
      "|    iterations      | 367      |\n",
      "|    time_elapsed    | 1517     |\n",
      "|    total_timesteps | 751616   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 6.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 1519        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003291001 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.3         |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.01e+03    |\n",
      "|    n_updates            | 19580       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 2.72e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=755000, episode_reward=17378.93 +/- 4350.94\n",
      "Episode length: 1803.20 +/- 13.78\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.8e+03    |\n",
      "|    mean_reward          | 1.74e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 755000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01198159 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.3        |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 282        |\n",
      "|    n_updates            | 19590      |\n",
      "|    policy_gradient_loss | -0.00379   |\n",
      "|    std                  | 0.22       |\n",
      "|    value_loss           | 1.37e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.51e+03 |\n",
      "|    ep_rew_mean     | 6.04e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 495      |\n",
      "|    iterations      | 369      |\n",
      "|    time_elapsed    | 1525     |\n",
      "|    total_timesteps | 755712   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 7.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 1527        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018107936 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.3         |\n",
      "|    explained_variance   | 0.86        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 350         |\n",
      "|    n_updates            | 19600       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1.39e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.52e+03   |\n",
      "|    ep_rew_mean          | 8.76e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 371        |\n",
      "|    time_elapsed         | 1529       |\n",
      "|    total_timesteps      | 759808     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06089364 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.3        |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.17e+03   |\n",
      "|    n_updates            | 19610      |\n",
      "|    policy_gradient_loss | 0.0101     |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 3.56e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=17365.05 +/- 6513.39\n",
      "Episode length: 1794.00 +/- 11.61\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.79e+03   |\n",
      "|    mean_reward          | 1.74e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 760000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01684047 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.3        |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 38.8       |\n",
      "|    n_updates            | 19620      |\n",
      "|    policy_gradient_loss | 0.000913   |\n",
      "|    std                  | 0.218      |\n",
      "|    value_loss           | 315        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.5e+03  |\n",
      "|    ep_rew_mean     | 7.71e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 496      |\n",
      "|    iterations      | 372      |\n",
      "|    time_elapsed    | 1535     |\n",
      "|    total_timesteps | 761856   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.5e+03    |\n",
      "|    ep_rew_mean          | 7.73e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 373        |\n",
      "|    time_elapsed         | 1537       |\n",
      "|    total_timesteps      | 763904     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12371926 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.3        |\n",
      "|    explained_variance   | 0.37       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.89e+07   |\n",
      "|    n_updates            | 19630      |\n",
      "|    policy_gradient_loss | -0.00234   |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 9.92e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=765000, episode_reward=16190.58 +/- 5703.89\n",
      "Episode length: 1891.20 +/- 13.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.89e+03    |\n",
      "|    mean_reward          | 1.62e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 765000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022142671 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.28        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 436         |\n",
      "|    n_updates            | 19640       |\n",
      "|    policy_gradient_loss | 0.00279     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 438         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.52e+03 |\n",
      "|    ep_rew_mean     | 9.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 496      |\n",
      "|    iterations      | 374      |\n",
      "|    time_elapsed    | 1543     |\n",
      "|    total_timesteps | 765952   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 9.25e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 1545        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008289915 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.3        |\n",
      "|    n_updates            | 19650       |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 508         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=17259.70 +/- 4960.41\n",
      "Episode length: 1757.20 +/- 9.68\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.76e+03   |\n",
      "|    mean_reward          | 1.73e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 770000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02245374 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.25       |\n",
      "|    explained_variance   | 0.795      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.52e+04   |\n",
      "|    n_updates            | 19660      |\n",
      "|    policy_gradient_loss | 0.00218    |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 9.22e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.52e+03 |\n",
      "|    ep_rew_mean     | 9.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 496      |\n",
      "|    iterations      | 376      |\n",
      "|    time_elapsed    | 1551     |\n",
      "|    total_timesteps | 770048   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 9.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 1553        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018354442 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 19670       |\n",
      "|    policy_gradient_loss | 0.00365     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 2.23e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | 9.37e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 1555        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024978817 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.2        |\n",
      "|    n_updates            | 19680       |\n",
      "|    policy_gradient_loss | 0.0177      |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 132         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=775000, episode_reward=17026.54 +/- 2809.27\n",
      "Episode length: 1696.40 +/- 3.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 1.7e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 775000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014541494 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.4        |\n",
      "|    n_updates            | 19690       |\n",
      "|    policy_gradient_loss | 0.00311     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 854         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | 9.53e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 497      |\n",
      "|    iterations      | 379      |\n",
      "|    time_elapsed    | 1561     |\n",
      "|    total_timesteps | 776192   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | 9.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 1562        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008326401 |\n",
      "|    clip_fraction        | 0.0643      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 19700       |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.74e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=780000, episode_reward=-10138.96 +/- 41805.51\n",
      "Episode length: 1326.60 +/- 630.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.33e+03    |\n",
      "|    mean_reward          | -1.01e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 780000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010788134 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.1        |\n",
      "|    n_updates            | 19710       |\n",
      "|    policy_gradient_loss | -0.00297    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 99          |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | 9.69e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 497      |\n",
      "|    iterations      | 381      |\n",
      "|    time_elapsed    | 1567     |\n",
      "|    total_timesteps | 780288   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 9.54e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 1569        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010505233 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.91e+04    |\n",
      "|    n_updates            | 19720       |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 8.09e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.54e+03   |\n",
      "|    ep_rew_mean          | 9.73e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 499        |\n",
      "|    iterations           | 383        |\n",
      "|    time_elapsed         | 1571       |\n",
      "|    total_timesteps      | 784384     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00924496 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.26       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 74.6       |\n",
      "|    n_updates            | 19730      |\n",
      "|    policy_gradient_loss | -0.00409   |\n",
      "|    std                  | 0.223      |\n",
      "|    value_loss           | 527        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=785000, episode_reward=11675.71 +/- 4767.56\n",
      "Episode length: 1723.80 +/- 8.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.72e+03    |\n",
      "|    mean_reward          | 1.17e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 785000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011438804 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.8        |\n",
      "|    n_updates            | 19740       |\n",
      "|    policy_gradient_loss | -0.00202    |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 477         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.55e+03 |\n",
      "|    ep_rew_mean     | 9.83e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 498      |\n",
      "|    iterations      | 384      |\n",
      "|    time_elapsed    | 1577     |\n",
      "|    total_timesteps | 786432   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 8.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 385         |\n",
      "|    time_elapsed         | 1579        |\n",
      "|    total_timesteps      | 788480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009640985 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.25        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.7        |\n",
      "|    n_updates            | 19750       |\n",
      "|    policy_gradient_loss | -0.00343    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 673         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=790000, episode_reward=14932.76 +/- 3219.67\n",
      "Episode length: 1819.40 +/- 7.66\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.82e+03   |\n",
      "|    mean_reward          | 1.49e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 790000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09956291 |\n",
      "|    clip_fraction        | 0.198      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.26       |\n",
      "|    explained_variance   | 0.328      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.49e+07   |\n",
      "|    n_updates            | 19760      |\n",
      "|    policy_gradient_loss | 0.0125     |\n",
      "|    std                  | 0.223      |\n",
      "|    value_loss           | 1.23e+07   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.55e+03 |\n",
      "|    ep_rew_mean     | 8.67e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 498      |\n",
      "|    iterations      | 386      |\n",
      "|    time_elapsed    | 1585     |\n",
      "|    total_timesteps | 790528   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | 8.67e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 1587        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004681986 |\n",
      "|    clip_fraction        | 0.0491      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.92e+05    |\n",
      "|    n_updates            | 19770       |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 2.05e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | 8.35e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 1589        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016731568 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.26        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 19780       |\n",
      "|    policy_gradient_loss | 0.00264     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 199         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=795000, episode_reward=12617.00 +/- 5553.37\n",
      "Episode length: 1863.60 +/- 26.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.86e+03    |\n",
      "|    mean_reward          | 1.26e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 795000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008731142 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.27        |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.96e+05    |\n",
      "|    n_updates            | 19790       |\n",
      "|    policy_gradient_loss | 0.00797     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 1.76e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.56e+03 |\n",
      "|    ep_rew_mean     | 8.37e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 499      |\n",
      "|    iterations      | 389      |\n",
      "|    time_elapsed    | 1595     |\n",
      "|    total_timesteps | 796672   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | 8.54e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 1597        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004554015 |\n",
      "|    clip_fraction        | 0.0205      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.27        |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27e+04    |\n",
      "|    n_updates            | 19800       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 4.56e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=16126.52 +/- 5903.57\n",
      "Episode length: 1887.40 +/- 15.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.89e+03    |\n",
      "|    mean_reward          | 1.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010067158 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.27        |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 227         |\n",
      "|    n_updates            | 19810       |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 3.91e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.58e+03 |\n",
      "|    ep_rew_mean     | 8.59e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 499      |\n",
      "|    iterations      | 391      |\n",
      "|    time_elapsed    | 1603     |\n",
      "|    total_timesteps | 800768   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 8.64e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 392         |\n",
      "|    time_elapsed         | 1605        |\n",
      "|    total_timesteps      | 802816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008654412 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.27        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29e+03    |\n",
      "|    n_updates            | 19820       |\n",
      "|    policy_gradient_loss | -0.000504   |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 2.03e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 8.65e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 393         |\n",
      "|    time_elapsed         | 1607        |\n",
      "|    total_timesteps      | 804864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035326824 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.28        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.1        |\n",
      "|    n_updates            | 19830       |\n",
      "|    policy_gradient_loss | -0.000405   |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 512         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=805000, episode_reward=18047.27 +/- 2240.90\n",
      "Episode length: 1908.20 +/- 10.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.91e+03    |\n",
      "|    mean_reward          | 1.8e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 805000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012451171 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.28        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 19840       |\n",
      "|    policy_gradient_loss | 0.0042      |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 438         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.59e+03 |\n",
      "|    ep_rew_mean     | 8.66e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 499      |\n",
      "|    iterations      | 394      |\n",
      "|    time_elapsed    | 1613     |\n",
      "|    total_timesteps | 806912   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | 8.74e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 1615        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024177004 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.29        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 167         |\n",
      "|    n_updates            | 19850       |\n",
      "|    policy_gradient_loss | 0.00266     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1.76e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=16774.17 +/- 3175.74\n",
      "Episode length: 1856.00 +/- 9.88\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.86e+03   |\n",
      "|    mean_reward          | 1.68e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 810000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03157114 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.29       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.28e+03   |\n",
      "|    n_updates            | 19860      |\n",
      "|    policy_gradient_loss | -0.00141   |\n",
      "|    std                  | 0.22       |\n",
      "|    value_loss           | 1.76e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.59e+03 |\n",
      "|    ep_rew_mean     | 8.65e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 499      |\n",
      "|    iterations      | 396      |\n",
      "|    time_elapsed    | 1622     |\n",
      "|    total_timesteps | 811008   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | 8.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 1623        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023407353 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.28        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.2        |\n",
      "|    n_updates            | 19870       |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1.72e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=815000, episode_reward=20832.75 +/- 3476.84\n",
      "Episode length: 1978.00 +/- 15.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.98e+03    |\n",
      "|    mean_reward          | 2.08e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 815000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016828675 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.28        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.1        |\n",
      "|    n_updates            | 19880       |\n",
      "|    policy_gradient_loss | 0.00411     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 1.72e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.6e+03  |\n",
      "|    ep_rew_mean     | 8.72e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 499      |\n",
      "|    iterations      | 398      |\n",
      "|    time_elapsed    | 1630     |\n",
      "|    total_timesteps | 815104   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | 8.71e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 399         |\n",
      "|    time_elapsed         | 1632        |\n",
      "|    total_timesteps      | 817152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010302078 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.31        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.1        |\n",
      "|    n_updates            | 19890       |\n",
      "|    policy_gradient_loss | 0.0026      |\n",
      "|    std                  | 0.218       |\n",
      "|    value_loss           | 292         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.6e+03    |\n",
      "|    ep_rew_mean          | 8.76e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 501        |\n",
      "|    iterations           | 400        |\n",
      "|    time_elapsed         | 1634       |\n",
      "|    total_timesteps      | 819200     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03360258 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.33       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.8       |\n",
      "|    n_updates            | 19900      |\n",
      "|    policy_gradient_loss | -0.000449  |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 1.28e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=13314.99 +/- 4665.34\n",
      "Episode length: 1825.40 +/- 17.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.83e+03    |\n",
      "|    mean_reward          | 1.33e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012893524 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.7        |\n",
      "|    n_updates            | 19910       |\n",
      "|    policy_gradient_loss | -0.000917   |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 269         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.6e+03  |\n",
      "|    ep_rew_mean     | 8.75e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 500      |\n",
      "|    iterations      | 401      |\n",
      "|    time_elapsed    | 1640     |\n",
      "|    total_timesteps | 821248   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | 8.75e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 1642        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015762001 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.4        |\n",
      "|    n_updates            | 19920       |\n",
      "|    policy_gradient_loss | 0.00405     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 1.72e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=825000, episode_reward=13984.73 +/- 5662.16\n",
      "Episode length: 2023.40 +/- 13.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | 1.4e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 825000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014570591 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96.7        |\n",
      "|    n_updates            | 19930       |\n",
      "|    policy_gradient_loss | 0.0027      |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 370         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.61e+03 |\n",
      "|    ep_rew_mean     | 8.77e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 500      |\n",
      "|    iterations      | 403      |\n",
      "|    time_elapsed    | 1648     |\n",
      "|    total_timesteps | 825344   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | 8.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 1650        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020104093 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 19940       |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 204         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.62e+03   |\n",
      "|    ep_rew_mean          | 8.74e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 501        |\n",
      "|    iterations           | 405        |\n",
      "|    time_elapsed         | 1652       |\n",
      "|    total_timesteps      | 829440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02634482 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.31       |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.3       |\n",
      "|    n_updates            | 19950      |\n",
      "|    policy_gradient_loss | 0.00732    |\n",
      "|    std                  | 0.219      |\n",
      "|    value_loss           | 1.71e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=13541.78 +/- 3038.37\n",
      "Episode length: 2025.80 +/- 13.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.03e+03    |\n",
      "|    mean_reward          | 1.35e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 830000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012032265 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 19960       |\n",
      "|    policy_gradient_loss | 0.00296     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.62e+03 |\n",
      "|    ep_rew_mean     | 8.81e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 406      |\n",
      "|    time_elapsed    | 1659     |\n",
      "|    total_timesteps | 831488   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | 8.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 407         |\n",
      "|    time_elapsed         | 1660        |\n",
      "|    total_timesteps      | 833536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021305487 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.3         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 19970       |\n",
      "|    policy_gradient_loss | 0.00339     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=835000, episode_reward=15874.40 +/- 7672.15\n",
      "Episode length: 1789.00 +/- 591.03\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.79e+03   |\n",
      "|    mean_reward          | 1.59e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 835000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01537566 |\n",
      "|    clip_fraction        | 0.0993     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.3        |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 74.4       |\n",
      "|    n_updates            | 19980      |\n",
      "|    policy_gradient_loss | -0.00315   |\n",
      "|    std                  | 0.22       |\n",
      "|    value_loss           | 527        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.61e+03 |\n",
      "|    ep_rew_mean     | 8.66e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 408      |\n",
      "|    time_elapsed    | 1667     |\n",
      "|    total_timesteps | 835584   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | 8.64e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 409         |\n",
      "|    time_elapsed         | 1668        |\n",
      "|    total_timesteps      | 837632      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054318383 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.3         |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 863         |\n",
      "|    n_updates            | 19990       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 2.14e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | 8.76e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 410         |\n",
      "|    time_elapsed         | 1670        |\n",
      "|    total_timesteps      | 839680      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014445977 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.3         |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 20000       |\n",
      "|    policy_gradient_loss | 0.00726     |\n",
      "|    std                  | 0.222       |\n",
      "|    value_loss           | 329         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=19183.34 +/- 1443.15\n",
      "Episode length: 2152.40 +/- 5.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.15e+03    |\n",
      "|    mean_reward          | 1.92e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 840000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016076881 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.29        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.3        |\n",
      "|    n_updates            | 20010       |\n",
      "|    policy_gradient_loss | -0.00487    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.6e+03  |\n",
      "|    ep_rew_mean     | 8.67e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 411      |\n",
      "|    time_elapsed    | 1677     |\n",
      "|    total_timesteps | 841728   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.58e+03   |\n",
      "|    ep_rew_mean          | 7.26e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 412        |\n",
      "|    time_elapsed         | 1679       |\n",
      "|    total_timesteps      | 843776     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06807335 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.3        |\n",
      "|    explained_variance   | 0.95       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 698        |\n",
      "|    n_updates            | 20020      |\n",
      "|    policy_gradient_loss | -0.00279   |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 2e+04      |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=845000, episode_reward=14465.87 +/- 6487.88\n",
      "Episode length: 2121.80 +/- 18.79\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.12e+03     |\n",
      "|    mean_reward          | 1.45e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 845000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091972165 |\n",
      "|    clip_fraction        | 0.175        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.3          |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.49e+06     |\n",
      "|    n_updates            | 20030        |\n",
      "|    policy_gradient_loss | 0.00105      |\n",
      "|    std                  | 0.221        |\n",
      "|    value_loss           | 2.08e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.58e+03 |\n",
      "|    ep_rew_mean     | 7.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 413      |\n",
      "|    time_elapsed    | 1686     |\n",
      "|    total_timesteps | 845824   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | 7.12e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 1688        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015732717 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.3         |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 20040       |\n",
      "|    policy_gradient_loss | -0.00671    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 813         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.59e+03   |\n",
      "|    ep_rew_mean          | 7e+03      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 415        |\n",
      "|    time_elapsed         | 1690       |\n",
      "|    total_timesteps      | 849920     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01040311 |\n",
      "|    clip_fraction        | 0.139      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.3        |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 127        |\n",
      "|    n_updates            | 20050      |\n",
      "|    policy_gradient_loss | -0.002     |\n",
      "|    std                  | 0.221      |\n",
      "|    value_loss           | 1.82e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=21850.60 +/- 5203.13\n",
      "Episode length: 2021.40 +/- 13.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | 2.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 850000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017137673 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.3         |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.1        |\n",
      "|    n_updates            | 20060       |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 363         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.58e+03 |\n",
      "|    ep_rew_mean     | 6.91e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 416      |\n",
      "|    time_elapsed    | 1696     |\n",
      "|    total_timesteps | 851968   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 6.95e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 1698        |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014702801 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.29        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 20070       |\n",
      "|    policy_gradient_loss | 0.00618     |\n",
      "|    std                  | 0.223       |\n",
      "|    value_loss           | 2.21e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=855000, episode_reward=23090.28 +/- 3048.10\n",
      "Episode length: 2121.20 +/- 11.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.12e+03    |\n",
      "|    mean_reward          | 2.31e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 855000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014668191 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.29        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.3        |\n",
      "|    n_updates            | 20080       |\n",
      "|    policy_gradient_loss | 6.31e-06    |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 1.7e+04     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.58e+03 |\n",
      "|    ep_rew_mean     | 6.88e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 418      |\n",
      "|    time_elapsed    | 1705     |\n",
      "|    total_timesteps | 856064   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 6.88e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 419         |\n",
      "|    time_elapsed         | 1707        |\n",
      "|    total_timesteps      | 858112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027222786 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.3         |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 20090       |\n",
      "|    policy_gradient_loss | 0.00231     |\n",
      "|    std                  | 0.221       |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=23534.09 +/- 4901.50\n",
      "Episode length: 2077.00 +/- 19.13\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.08e+03   |\n",
      "|    mean_reward          | 2.35e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 860000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02136691 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.31       |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 32.6       |\n",
      "|    n_updates            | 20100      |\n",
      "|    policy_gradient_loss | 0.00181    |\n",
      "|    std                  | 0.22       |\n",
      "|    value_loss           | 2.21e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.58e+03 |\n",
      "|    ep_rew_mean     | 6.72e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 420      |\n",
      "|    time_elapsed    | 1713     |\n",
      "|    total_timesteps | 860160   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 6.72e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 1715        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018510483 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.88e+04    |\n",
      "|    n_updates            | 20110       |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 3.89e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 6.74e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 422         |\n",
      "|    time_elapsed         | 1717        |\n",
      "|    total_timesteps      | 864256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013878523 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.32        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.3        |\n",
      "|    n_updates            | 20120       |\n",
      "|    policy_gradient_loss | 0.00274     |\n",
      "|    std                  | 0.22        |\n",
      "|    value_loss           | 153         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=865000, episode_reward=25517.83 +/- 4433.66\n",
      "Episode length: 2311.20 +/- 18.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.31e+03    |\n",
      "|    mean_reward          | 2.55e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 865000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025484065 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.33        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.4        |\n",
      "|    n_updates            | 20130       |\n",
      "|    policy_gradient_loss | 0.00259     |\n",
      "|    std                  | 0.219       |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.59e+03 |\n",
      "|    ep_rew_mean     | 8.01e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 423      |\n",
      "|    time_elapsed    | 1724     |\n",
      "|    total_timesteps | 866304   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.59e+03   |\n",
      "|    ep_rew_mean          | 8.03e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 424        |\n",
      "|    time_elapsed         | 1726       |\n",
      "|    total_timesteps      | 868352     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02318938 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.36       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 37.1       |\n",
      "|    n_updates            | 20140      |\n",
      "|    policy_gradient_loss | 0.00292    |\n",
      "|    std                  | 0.218      |\n",
      "|    value_loss           | 141        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=21773.68 +/- 4429.67\n",
      "Episode length: 2083.20 +/- 13.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.08e+03    |\n",
      "|    mean_reward          | 2.18e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 870000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013842601 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.37        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.4        |\n",
      "|    n_updates            | 20150       |\n",
      "|    policy_gradient_loss | 0.00155     |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 106         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.61e+03 |\n",
      "|    ep_rew_mean     | 9.25e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 425      |\n",
      "|    time_elapsed    | 1733     |\n",
      "|    total_timesteps | 870400   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | 9.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 1735        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016168859 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.38        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 20160       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    std                  | 0.217       |\n",
      "|    value_loss           | 1.07e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.6e+03    |\n",
      "|    ep_rew_mean          | 9.07e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 427        |\n",
      "|    time_elapsed         | 1737       |\n",
      "|    total_timesteps      | 874496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03797866 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.39       |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 26         |\n",
      "|    n_updates            | 20170      |\n",
      "|    policy_gradient_loss | 0.00226    |\n",
      "|    std                  | 0.217      |\n",
      "|    value_loss           | 3.27e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=875000, episode_reward=30116.46 +/- 1003.14\n",
      "Episode length: 2222.80 +/- 8.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.22e+03    |\n",
      "|    mean_reward          | 3.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 875000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019539487 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.4         |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.4        |\n",
      "|    n_updates            | 20180       |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    std                  | 0.216       |\n",
      "|    value_loss           | 1.72e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.6e+03  |\n",
      "|    ep_rew_mean     | 9.09e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 428      |\n",
      "|    time_elapsed    | 1744     |\n",
      "|    total_timesteps | 876544   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | 9.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 1746        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013748437 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.41        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.7        |\n",
      "|    n_updates            | 20190       |\n",
      "|    policy_gradient_loss | -0.000499   |\n",
      "|    std                  | 0.214       |\n",
      "|    value_loss           | 66.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=22288.50 +/- 4196.91\n",
      "Episode length: 2514.60 +/- 24.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.51e+03    |\n",
      "|    mean_reward          | 2.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 880000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015712095 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.43        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 20200       |\n",
      "|    policy_gradient_loss | 0.00458     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 82          |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.61e+03 |\n",
      "|    ep_rew_mean     | 9.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 430      |\n",
      "|    time_elapsed    | 1753     |\n",
      "|    total_timesteps | 880640   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 1.03e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 1755        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015120454 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.44        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.1        |\n",
      "|    n_updates            | 20210       |\n",
      "|    policy_gradient_loss | 0.00344     |\n",
      "|    std                  | 0.213       |\n",
      "|    value_loss           | 88.3        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 1.02e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 1757        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013776518 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.45        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.2        |\n",
      "|    n_updates            | 20220       |\n",
      "|    policy_gradient_loss | -0.000875   |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 3.28e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=885000, episode_reward=-72534.39 +/- 5183.52\n",
      "Episode length: 3280.20 +/- 14.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.28e+03    |\n",
      "|    mean_reward          | -7.25e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 885000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021071494 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.45        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.3        |\n",
      "|    n_updates            | 20230       |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.63e+03 |\n",
      "|    ep_rew_mean     | 1.03e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 433      |\n",
      "|    time_elapsed    | 1767     |\n",
      "|    total_timesteps | 886784   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.64e+03     |\n",
      "|    ep_rew_mean          | 1.05e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 502          |\n",
      "|    iterations           | 434          |\n",
      "|    time_elapsed         | 1768         |\n",
      "|    total_timesteps      | 888832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126638785 |\n",
      "|    clip_fraction        | 0.197        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.47         |\n",
      "|    explained_variance   | 1            |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 29.4         |\n",
      "|    n_updates            | 20240        |\n",
      "|    policy_gradient_loss | 0.00319      |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 53.9         |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=28801.28 +/- 4721.61\n",
      "Episode length: 2438.00 +/- 15.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.44e+03    |\n",
      "|    mean_reward          | 2.88e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 890000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024467535 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.48        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 20250       |\n",
      "|    policy_gradient_loss | 0.000542    |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 114         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.65e+03 |\n",
      "|    ep_rew_mean     | 1.06e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 435      |\n",
      "|    time_elapsed    | 1776     |\n",
      "|    total_timesteps | 890880   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | 1.06e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 1778        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011836621 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.47        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 20260       |\n",
      "|    policy_gradient_loss | -0.00368    |\n",
      "|    std                  | 0.212       |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | 9.51e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 1780        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015782457 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.47        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39          |\n",
      "|    n_updates            | 20270       |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 8.32e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=895000, episode_reward=34207.52 +/- 1373.66\n",
      "Episode length: 2451.40 +/- 18.92\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.45e+03     |\n",
      "|    mean_reward          | 3.42e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 895000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060452567 |\n",
      "|    clip_fraction        | 0.0865       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.48         |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.04e+07     |\n",
      "|    n_updates            | 20280        |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    std                  | 0.211        |\n",
      "|    value_loss           | 1.73e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.65e+03 |\n",
      "|    ep_rew_mean     | 9.54e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 438      |\n",
      "|    time_elapsed    | 1787     |\n",
      "|    total_timesteps | 897024   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.66e+03   |\n",
      "|    ep_rew_mean          | 9.7e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 439        |\n",
      "|    time_elapsed         | 1789       |\n",
      "|    total_timesteps      | 899072     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00922204 |\n",
      "|    clip_fraction        | 0.0671     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.48       |\n",
      "|    explained_variance   | 0.885      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.42e+03   |\n",
      "|    n_updates            | 20290      |\n",
      "|    policy_gradient_loss | -0.00766   |\n",
      "|    std                  | 0.211      |\n",
      "|    value_loss           | 1.59e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=32286.92 +/- 4286.16\n",
      "Episode length: 2516.40 +/- 14.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.52e+03    |\n",
      "|    mean_reward          | 3.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 900000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009916231 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 411         |\n",
      "|    n_updates            | 20300       |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 859         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.66e+03 |\n",
      "|    ep_rew_mean     | 9.8e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 440      |\n",
      "|    time_elapsed    | 1797     |\n",
      "|    total_timesteps | 901120   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | 9.89e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 1799        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010271595 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 20310       |\n",
      "|    policy_gradient_loss | -0.000584   |\n",
      "|    std                  | 0.211       |\n",
      "|    value_loss           | 1.74e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=905000, episode_reward=40316.84 +/- 3284.19\n",
      "Episode length: 2764.80 +/- 27.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.76e+03    |\n",
      "|    mean_reward          | 4.03e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 905000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013806932 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 20320       |\n",
      "|    policy_gradient_loss | -0.00552    |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 733         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.67e+03 |\n",
      "|    ep_rew_mean     | 1.01e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 500      |\n",
      "|    iterations      | 442      |\n",
      "|    time_elapsed    | 1807     |\n",
      "|    total_timesteps | 905216   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | 1.03e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 1809        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020411547 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.5         |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41          |\n",
      "|    n_updates            | 20330       |\n",
      "|    policy_gradient_loss | 0.00849     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 2.24e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | 1.03e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 444         |\n",
      "|    time_elapsed         | 1811        |\n",
      "|    total_timesteps      | 909312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014377583 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.5         |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 20340       |\n",
      "|    policy_gradient_loss | 0.00111     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=910000, episode_reward=42156.14 +/- 1167.97\n",
      "Episode length: 2891.80 +/- 20.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.89e+03    |\n",
      "|    mean_reward          | 4.22e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 910000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026586939 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.51        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.2        |\n",
      "|    n_updates            | 20350       |\n",
      "|    policy_gradient_loss | 0.00123     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 79.5        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.69e+03 |\n",
      "|    ep_rew_mean     | 1.05e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 500      |\n",
      "|    iterations      | 445      |\n",
      "|    time_elapsed    | 1820     |\n",
      "|    total_timesteps | 911360   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | 1.06e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 446         |\n",
      "|    time_elapsed         | 1822        |\n",
      "|    total_timesteps      | 913408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013623675 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.51        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.1        |\n",
      "|    n_updates            | 20360       |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 115         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=915000, episode_reward=37825.98 +/- 5089.12\n",
      "Episode length: 2667.00 +/- 17.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.67e+03    |\n",
      "|    mean_reward          | 3.78e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 915000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016909204 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.52        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.5        |\n",
      "|    n_updates            | 20370       |\n",
      "|    policy_gradient_loss | 0.00511     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 2.61e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.72e+03 |\n",
      "|    ep_rew_mean     | 1.19e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 500      |\n",
      "|    iterations      | 447      |\n",
      "|    time_elapsed    | 1830     |\n",
      "|    total_timesteps | 915456   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.73e+03   |\n",
      "|    ep_rew_mean          | 1.21e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 448        |\n",
      "|    time_elapsed         | 1832       |\n",
      "|    total_timesteps      | 917504     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01666159 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.54       |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 26.2       |\n",
      "|    n_updates            | 20380      |\n",
      "|    policy_gradient_loss | 0.00271    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 1.73e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | 1.21e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 1834        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014266137 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.5        |\n",
      "|    n_updates            | 20390       |\n",
      "|    policy_gradient_loss | 0.0019      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=38228.94 +/- 5438.23\n",
      "Episode length: 3064.20 +/- 21.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.06e+03    |\n",
      "|    mean_reward          | 3.82e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 920000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033482887 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 20400       |\n",
      "|    policy_gradient_loss | 0.0077      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.74e+03 |\n",
      "|    ep_rew_mean     | 1.21e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 499      |\n",
      "|    iterations      | 450      |\n",
      "|    time_elapsed    | 1843     |\n",
      "|    total_timesteps | 921600   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.75e+03   |\n",
      "|    ep_rew_mean          | 1.32e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 451        |\n",
      "|    time_elapsed         | 1845       |\n",
      "|    total_timesteps      | 923648     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02782058 |\n",
      "|    clip_fraction        | 0.28       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.54       |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.4       |\n",
      "|    n_updates            | 20410      |\n",
      "|    policy_gradient_loss | 0.00932    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 30.1       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=925000, episode_reward=47316.95 +/- 1172.02\n",
      "Episode length: 3327.00 +/- 19.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.33e+03    |\n",
      "|    mean_reward          | 4.73e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 925000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042167988 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.54        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 20420       |\n",
      "|    policy_gradient_loss | 0.00369     |\n",
      "|    std                  | 0.21        |\n",
      "|    value_loss           | 1.28e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.77e+03 |\n",
      "|    ep_rew_mean     | 1.44e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 499      |\n",
      "|    iterations      | 452      |\n",
      "|    time_elapsed    | 1854     |\n",
      "|    total_timesteps | 925696   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.77e+03   |\n",
      "|    ep_rew_mean          | 1.44e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 499        |\n",
      "|    iterations           | 453        |\n",
      "|    time_elapsed         | 1856       |\n",
      "|    total_timesteps      | 927744     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07204473 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.55       |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 12.6       |\n",
      "|    n_updates            | 20430      |\n",
      "|    policy_gradient_loss | 0.0122     |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 1.69e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.8e+03    |\n",
      "|    ep_rew_mean          | 1.23e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 454        |\n",
      "|    time_elapsed         | 1858       |\n",
      "|    total_timesteps      | 929792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01284898 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.56       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16.2       |\n",
      "|    n_updates            | 20440      |\n",
      "|    policy_gradient_loss | 0.0046     |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 75.2       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=-227636.85 +/- 2396.93\n",
      "Episode length: 4957.20 +/- 28.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.96e+03     |\n",
      "|    mean_reward          | -2.28e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 930000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036727856 |\n",
      "|    clip_fraction        | 0.165        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.57         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.57e+05     |\n",
      "|    n_updates            | 20450        |\n",
      "|    policy_gradient_loss | 0.00997      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.96e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.8e+03  |\n",
      "|    ep_rew_mean     | 1.23e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 497      |\n",
      "|    iterations      | 455      |\n",
      "|    time_elapsed    | 1871     |\n",
      "|    total_timesteps | 931840   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.83e+03   |\n",
      "|    ep_rew_mean          | 1.27e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 498        |\n",
      "|    iterations           | 456        |\n",
      "|    time_elapsed         | 1873       |\n",
      "|    total_timesteps      | 933888     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01957612 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.56       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 13.2       |\n",
      "|    n_updates            | 20460      |\n",
      "|    policy_gradient_loss | 0.00415    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 72.1       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=935000, episode_reward=-168209.88 +/- 6188.72\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | -1.68e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 935000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064774384 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.56         |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+03     |\n",
      "|    n_updates            | 20470        |\n",
      "|    policy_gradient_loss | -0.00066     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 4.75e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.83e+03 |\n",
      "|    ep_rew_mean     | 1.27e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 495      |\n",
      "|    iterations      | 457      |\n",
      "|    time_elapsed    | 1887     |\n",
      "|    total_timesteps | 935936   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.85e+03   |\n",
      "|    ep_rew_mean          | 1.31e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 458        |\n",
      "|    time_elapsed         | 1889       |\n",
      "|    total_timesteps      | 937984     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01633204 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.56       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 15.1       |\n",
      "|    n_updates            | 20480      |\n",
      "|    policy_gradient_loss | -0.00715   |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 60.8       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=940000, episode_reward=-309130.91 +/- 30515.93\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | -3.09e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 940000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068679056 |\n",
      "|    clip_fraction        | 0.0977       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.56         |\n",
      "|    explained_variance   | 0.933        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 267          |\n",
      "|    n_updates            | 20490        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.92e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.85e+03 |\n",
      "|    ep_rew_mean     | 1.31e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 493      |\n",
      "|    iterations      | 459      |\n",
      "|    time_elapsed    | 1902     |\n",
      "|    total_timesteps | 940032   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.87e+03    |\n",
      "|    ep_rew_mean          | 1.34e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 1904        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023149308 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.54        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.22        |\n",
      "|    n_updates            | 20500       |\n",
      "|    policy_gradient_loss | 0.00249     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 38.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.87e+03    |\n",
      "|    ep_rew_mean          | 1.34e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 1906        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007496876 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.51        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 342         |\n",
      "|    n_updates            | 20510       |\n",
      "|    policy_gradient_loss | 0.00316     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.81e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=945000, episode_reward=26333.18 +/- 2734.47\n",
      "Episode length: 3451.00 +/- 24.92\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.45e+03   |\n",
      "|    mean_reward          | 2.63e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 945000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02492471 |\n",
      "|    clip_fraction        | 0.233      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.52       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14         |\n",
      "|    n_updates            | 20520      |\n",
      "|    policy_gradient_loss | 0.00869    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 66.9       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.88e+03 |\n",
      "|    ep_rew_mean     | 1.21e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 493      |\n",
      "|    iterations      | 462      |\n",
      "|    time_elapsed    | 1916     |\n",
      "|    total_timesteps | 946176   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.89e+03     |\n",
      "|    ep_rew_mean          | 1.23e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 463          |\n",
      "|    time_elapsed         | 1918         |\n",
      "|    total_timesteps      | 948224       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043431027 |\n",
      "|    clip_fraction        | 0.0739       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.53         |\n",
      "|    explained_variance   | 0.314        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69e+07     |\n",
      "|    n_updates            | 20530        |\n",
      "|    policy_gradient_loss | 0.00186      |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 3.16e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=18594.36 +/- 5035.42\n",
      "Episode length: 3345.40 +/- 34.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.35e+03     |\n",
      "|    mean_reward          | 1.86e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 950000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053636404 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.53         |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.82e+04     |\n",
      "|    n_updates            | 20540        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.04e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.89e+03 |\n",
      "|    ep_rew_mean     | 1.13e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 492      |\n",
      "|    iterations      | 464      |\n",
      "|    time_elapsed    | 1928     |\n",
      "|    total_timesteps | 950272   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.89e+03     |\n",
      "|    ep_rew_mean          | 1.13e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 493          |\n",
      "|    iterations           | 465          |\n",
      "|    time_elapsed         | 1930         |\n",
      "|    total_timesteps      | 952320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020598152 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.53         |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.08e+04     |\n",
      "|    n_updates            | 20550        |\n",
      "|    policy_gradient_loss | -0.00489     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.75e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.91e+03     |\n",
      "|    ep_rew_mean          | 1.14e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 493          |\n",
      "|    iterations           | 466          |\n",
      "|    time_elapsed         | 1931         |\n",
      "|    total_timesteps      | 954368       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067017972 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.53         |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+04     |\n",
      "|    n_updates            | 20560        |\n",
      "|    policy_gradient_loss | -0.00879     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 5.44e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=955000, episode_reward=30264.44 +/- 3842.11\n",
      "Episode length: 4240.00 +/- 26.50\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.24e+03     |\n",
      "|    mean_reward          | 3.03e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 955000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002884071 |\n",
      "|    clip_fraction        | 0.00137      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.53         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.38e+06     |\n",
      "|    n_updates            | 20570        |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 1.56e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.91e+03 |\n",
      "|    ep_rew_mean     | 1.14e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 492      |\n",
      "|    iterations      | 467      |\n",
      "|    time_elapsed    | 1943     |\n",
      "|    total_timesteps | 956416   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.92e+03    |\n",
      "|    ep_rew_mean          | 1.15e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 492         |\n",
      "|    iterations           | 468         |\n",
      "|    time_elapsed         | 1945        |\n",
      "|    total_timesteps      | 958464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008553531 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.53        |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55e+04    |\n",
      "|    n_updates            | 20580       |\n",
      "|    policy_gradient_loss | -0.00984    |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 3.45e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=960000, episode_reward=37217.87 +/- 4508.35\n",
      "Episode length: 4479.20 +/- 26.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.48e+03     |\n",
      "|    mean_reward          | 3.72e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 960000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062963087 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.53         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 957          |\n",
      "|    n_updates            | 20590        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 5.16e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.93e+03 |\n",
      "|    ep_rew_mean     | 1.17e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 490      |\n",
      "|    iterations      | 469      |\n",
      "|    time_elapsed    | 1957     |\n",
      "|    total_timesteps | 960512   |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.93e+03     |\n",
      "|    ep_rew_mean          | 1.17e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 491          |\n",
      "|    iterations           | 470          |\n",
      "|    time_elapsed         | 1959         |\n",
      "|    total_timesteps      | 962560       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053968346 |\n",
      "|    clip_fraction        | 0.0405       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.54         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 251          |\n",
      "|    n_updates            | 20600        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.208        |\n",
      "|    value_loss           | 2.11e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.95e+03   |\n",
      "|    ep_rew_mean          | 1.2e+04    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 491        |\n",
      "|    iterations           | 471        |\n",
      "|    time_elapsed         | 1961       |\n",
      "|    total_timesteps      | 964608     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00602577 |\n",
      "|    clip_fraction        | 0.0807     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.54       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 418        |\n",
      "|    n_updates            | 20610      |\n",
      "|    policy_gradient_loss | -0.0044    |\n",
      "|    std                  | 0.208      |\n",
      "|    value_loss           | 1.99e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=965000, episode_reward=41454.80 +/- 269.88\n",
      "Episode length: 3266.80 +/- 10.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.27e+03    |\n",
      "|    mean_reward          | 4.15e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 965000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009378973 |\n",
      "|    clip_fraction        | 0.0602      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.54        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 20620       |\n",
      "|    policy_gradient_loss | -0.00359    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.46e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.96e+03 |\n",
      "|    ep_rew_mean     | 1.23e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 490      |\n",
      "|    iterations      | 472      |\n",
      "|    time_elapsed    | 1971     |\n",
      "|    total_timesteps | 966656   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.96e+03    |\n",
      "|    ep_rew_mean          | 1.23e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 1973        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005097829 |\n",
      "|    clip_fraction        | 0.0701      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.54        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 696         |\n",
      "|    n_updates            | 20630       |\n",
      "|    policy_gradient_loss | -0.00751    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.91e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=35734.68 +/- 3547.25\n",
      "Episode length: 3177.40 +/- 18.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.18e+03    |\n",
      "|    mean_reward          | 3.57e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 970000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016481489 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.3        |\n",
      "|    n_updates            | 20640       |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 498         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.98e+03 |\n",
      "|    ep_rew_mean     | 1.25e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 489      |\n",
      "|    iterations      | 474      |\n",
      "|    time_elapsed    | 1982     |\n",
      "|    total_timesteps | 970752   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.99e+03    |\n",
      "|    ep_rew_mean          | 1.27e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 1984        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040564008 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28          |\n",
      "|    n_updates            | 20650       |\n",
      "|    policy_gradient_loss | 0.000357    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | 1.3e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 476         |\n",
      "|    time_elapsed         | 1986        |\n",
      "|    total_timesteps      | 974848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013844065 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.5        |\n",
      "|    n_updates            | 20660       |\n",
      "|    policy_gradient_loss | 0.00416     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.33e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=975000, episode_reward=42979.12 +/- 4810.29\n",
      "Episode length: 3084.00 +/- 7.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.08e+03    |\n",
      "|    mean_reward          | 4.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 975000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023679443 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 20670       |\n",
      "|    policy_gradient_loss | 0.00365     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 8.21e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2e+03    |\n",
      "|    ep_rew_mean     | 1.3e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 489      |\n",
      "|    iterations      | 477      |\n",
      "|    time_elapsed    | 1995     |\n",
      "|    total_timesteps | 976896   |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.01e+03   |\n",
      "|    ep_rew_mean          | 1.31e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 490        |\n",
      "|    iterations           | 478        |\n",
      "|    time_elapsed         | 1997       |\n",
      "|    total_timesteps      | 978944     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01119055 |\n",
      "|    clip_fraction        | 0.169      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.56       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 20         |\n",
      "|    n_updates            | 20680      |\n",
      "|    policy_gradient_loss | -0.000875  |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 202        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=41523.42 +/- 2923.79\n",
      "Episode length: 2963.00 +/- 10.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.96e+03    |\n",
      "|    mean_reward          | 4.15e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 980000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019235328 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.7        |\n",
      "|    n_updates            | 20690       |\n",
      "|    policy_gradient_loss | 0.0061      |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.02e+03 |\n",
      "|    ep_rew_mean     | 1.34e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 489      |\n",
      "|    iterations      | 479      |\n",
      "|    time_elapsed    | 2005     |\n",
      "|    total_timesteps | 980992   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.04e+03    |\n",
      "|    ep_rew_mean          | 1.35e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 480         |\n",
      "|    time_elapsed         | 2007        |\n",
      "|    total_timesteps      | 983040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012796612 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45          |\n",
      "|    n_updates            | 20700       |\n",
      "|    policy_gradient_loss | 0.00223     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=985000, episode_reward=45056.98 +/- 4541.40\n",
      "Episode length: 3428.20 +/- 37.77\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.43e+03   |\n",
      "|    mean_reward          | 4.51e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 985000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01633788 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.56       |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 21.6       |\n",
      "|    n_updates            | 20710      |\n",
      "|    policy_gradient_loss | 0.0115     |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 1.31e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.04e+03 |\n",
      "|    ep_rew_mean     | 1.35e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 488      |\n",
      "|    iterations      | 481      |\n",
      "|    time_elapsed    | 2017     |\n",
      "|    total_timesteps | 985088   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.05e+03    |\n",
      "|    ep_rew_mean          | 1.4e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 488         |\n",
      "|    iterations           | 482         |\n",
      "|    time_elapsed         | 2019        |\n",
      "|    total_timesteps      | 987136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025479456 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.57        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 20720       |\n",
      "|    policy_gradient_loss | 0.00986     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 57          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.06e+03    |\n",
      "|    ep_rew_mean          | 1.42e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 483         |\n",
      "|    time_elapsed         | 2021        |\n",
      "|    total_timesteps      | 989184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021206044 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.57        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67          |\n",
      "|    n_updates            | 20730       |\n",
      "|    policy_gradient_loss | -0.000143   |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 1.78e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=43308.60 +/- 5062.45\n",
      "Episode length: 3457.60 +/- 21.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.46e+03    |\n",
      "|    mean_reward          | 4.33e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 990000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022519302 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.8        |\n",
      "|    n_updates            | 20740       |\n",
      "|    policy_gradient_loss | 0.000899    |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.06e+03 |\n",
      "|    ep_rew_mean     | 1.42e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 487      |\n",
      "|    iterations      | 484      |\n",
      "|    time_elapsed    | 2031     |\n",
      "|    total_timesteps | 991232   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | 1.44e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 488         |\n",
      "|    iterations           | 485         |\n",
      "|    time_elapsed         | 2033        |\n",
      "|    total_timesteps      | 993280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014656123 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.54        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.4        |\n",
      "|    n_updates            | 20750       |\n",
      "|    policy_gradient_loss | 0.00689     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 50.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=995000, episode_reward=39417.42 +/- 4234.83\n",
      "Episode length: 3409.40 +/- 107.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.41e+03    |\n",
      "|    mean_reward          | 3.94e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 995000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014062962 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.53        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 20760       |\n",
      "|    policy_gradient_loss | -3.38e-05   |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 2.24e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.08e+03 |\n",
      "|    ep_rew_mean     | 1.44e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 487      |\n",
      "|    iterations      | 486      |\n",
      "|    time_elapsed    | 2043     |\n",
      "|    total_timesteps | 995328   |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.1e+03     |\n",
      "|    ep_rew_mean          | 1.46e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 487         |\n",
      "|    iterations           | 487         |\n",
      "|    time_elapsed         | 2044        |\n",
      "|    total_timesteps      | 997376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015563332 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.53        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.3        |\n",
      "|    n_updates            | 20770       |\n",
      "|    policy_gradient_loss | 0.00574     |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 91.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.12e+03   |\n",
      "|    ep_rew_mean          | 1.49e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 488        |\n",
      "|    iterations           | 488        |\n",
      "|    time_elapsed         | 2046       |\n",
      "|    total_timesteps      | 999424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12689579 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.52       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.6       |\n",
      "|    n_updates            | 20780      |\n",
      "|    policy_gradient_loss | 0.0132     |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 55.6       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=44156.23 +/- 4161.43\n",
      "Episode length: 3298.60 +/- 23.14\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.3e+03    |\n",
      "|    mean_reward          | 4.42e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1000000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02761997 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.5        |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.2       |\n",
      "|    n_updates            | 20790      |\n",
      "|    policy_gradient_loss | 0.00186    |\n",
      "|    std                  | 0.209      |\n",
      "|    value_loss           | 2.24e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.12e+03 |\n",
      "|    ep_rew_mean     | 1.49e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 487      |\n",
      "|    iterations      | 489      |\n",
      "|    time_elapsed    | 2056     |\n",
      "|    total_timesteps | 1001472  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.15e+03    |\n",
      "|    ep_rew_mean          | 1.62e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 487         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 2058        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023451937 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.5         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.7        |\n",
      "|    n_updates            | 20800       |\n",
      "|    policy_gradient_loss | -0.0099     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 82          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1005000, episode_reward=-79980.03 +/- 8412.38\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | -8e+04      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1005000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039222345 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.9        |\n",
      "|    n_updates            | 20810       |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 1.94e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.15e+03 |\n",
      "|    ep_rew_mean     | 1.62e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 485      |\n",
      "|    iterations      | 491      |\n",
      "|    time_elapsed    | 2071     |\n",
      "|    total_timesteps | 1005568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.18e+03    |\n",
      "|    ep_rew_mean          | 1.5e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 485         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 2073        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012783197 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 20820       |\n",
      "|    policy_gradient_loss | 0.00144     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.18e+03     |\n",
      "|    ep_rew_mean          | 1.5e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 486          |\n",
      "|    iterations           | 493          |\n",
      "|    time_elapsed         | 2075         |\n",
      "|    total_timesteps      | 1009664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015398429 |\n",
      "|    clip_fraction        | 0.0928       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.49         |\n",
      "|    explained_variance   | 0.693        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+05     |\n",
      "|    n_updates            | 20830        |\n",
      "|    policy_gradient_loss | 0.00439      |\n",
      "|    std                  | 0.209        |\n",
      "|    value_loss           | 5.83e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1010000, episode_reward=-97050.93 +/- 4663.37\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | -9.71e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036190897 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.3        |\n",
      "|    n_updates            | 20840       |\n",
      "|    policy_gradient_loss | 0.00869     |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 64.7        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.21e+03 |\n",
      "|    ep_rew_mean     | 1.31e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 484      |\n",
      "|    iterations      | 494      |\n",
      "|    time_elapsed    | 2089     |\n",
      "|    total_timesteps | 1011712  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.21e+03    |\n",
      "|    ep_rew_mean          | 1.31e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 484         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 2091        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005272059 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.49        |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.13e+06    |\n",
      "|    n_updates            | 20850       |\n",
      "|    policy_gradient_loss | 0.024       |\n",
      "|    std                  | 0.209       |\n",
      "|    value_loss           | 4.97e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1015000, episode_reward=-54069.70 +/- 4841.48\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | -5.41e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1015000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022022821 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.5         |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.4        |\n",
      "|    n_updates            | 20860       |\n",
      "|    policy_gradient_loss | 0.00147     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 84.9        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.21e+03 |\n",
      "|    ep_rew_mean     | 1.31e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 482      |\n",
      "|    iterations      | 496      |\n",
      "|    time_elapsed    | 2104     |\n",
      "|    total_timesteps | 1015808  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.24e+03     |\n",
      "|    ep_rew_mean          | 1.26e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 483          |\n",
      "|    iterations           | 497          |\n",
      "|    time_elapsed         | 2106         |\n",
      "|    total_timesteps      | 1017856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027437597 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.51         |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21e+04     |\n",
      "|    n_updates            | 20870        |\n",
      "|    policy_gradient_loss | 0.00479      |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.25e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.24e+03     |\n",
      "|    ep_rew_mean          | 1.26e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 483          |\n",
      "|    iterations           | 498          |\n",
      "|    time_elapsed         | 2108         |\n",
      "|    total_timesteps      | 1019904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076037743 |\n",
      "|    clip_fraction        | 0.0651       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.51         |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.24e+05     |\n",
      "|    n_updates            | 20880        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 3.87e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=-31712.45 +/- 4694.21\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | -3.17e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025761288 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.51        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.6        |\n",
      "|    n_updates            | 20890       |\n",
      "|    policy_gradient_loss | 0.000431    |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 124         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.27e+03 |\n",
      "|    ep_rew_mean     | 1.16e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 481      |\n",
      "|    iterations      | 499      |\n",
      "|    time_elapsed    | 2122     |\n",
      "|    total_timesteps | 1021952  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.27e+03     |\n",
      "|    ep_rew_mean          | 1.16e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 482          |\n",
      "|    iterations           | 500          |\n",
      "|    time_elapsed         | 2123         |\n",
      "|    total_timesteps      | 1024000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051837265 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.51         |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.66e+06     |\n",
      "|    n_updates            | 20900        |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 2.67e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1025000, episode_reward=14878.62 +/- 4212.35\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 1.49e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1025000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03178583 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.51       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.8       |\n",
      "|    n_updates            | 20910      |\n",
      "|    policy_gradient_loss | 0.00884    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 61.3       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.27e+03 |\n",
      "|    ep_rew_mean     | 1.16e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 479      |\n",
      "|    iterations      | 501      |\n",
      "|    time_elapsed    | 2137     |\n",
      "|    total_timesteps | 1026048  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.31e+03     |\n",
      "|    ep_rew_mean          | 1.17e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 480          |\n",
      "|    iterations           | 502          |\n",
      "|    time_elapsed         | 2139         |\n",
      "|    total_timesteps      | 1028096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077286046 |\n",
      "|    clip_fraction        | 0.174        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.51         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.63e+03     |\n",
      "|    n_updates            | 20920        |\n",
      "|    policy_gradient_loss | -0.00228     |\n",
      "|    std                  | 0.207        |\n",
      "|    value_loss           | 1.85e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1030000, episode_reward=1465.36 +/- 6007.05\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 1.47e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024192475 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.51        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.27e+03    |\n",
      "|    n_updates            | 20930       |\n",
      "|    policy_gradient_loss | 0.024       |\n",
      "|    std                  | 0.208       |\n",
      "|    value_loss           | 1.09e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.31e+03 |\n",
      "|    ep_rew_mean     | 1.17e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 478      |\n",
      "|    iterations      | 503      |\n",
      "|    time_elapsed    | 2153     |\n",
      "|    total_timesteps | 1030144  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.33e+03    |\n",
      "|    ep_rew_mean          | 1.2e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 504         |\n",
      "|    time_elapsed         | 2155        |\n",
      "|    total_timesteps      | 1032192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010588173 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.51        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 20940       |\n",
      "|    policy_gradient_loss | 0.00815     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 83.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.33e+03    |\n",
      "|    ep_rew_mean          | 1.2e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 479         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 2157        |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005418063 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.51        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 582         |\n",
      "|    n_updates            | 20950       |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.46e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1035000, episode_reward=61827.09 +/- 3982.61\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 6.18e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1035000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01743985 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.51       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.2       |\n",
      "|    n_updates            | 20960      |\n",
      "|    policy_gradient_loss | 0.00677    |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 54.6       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.36e+03 |\n",
      "|    ep_rew_mean     | 1.24e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 477      |\n",
      "|    iterations      | 506      |\n",
      "|    time_elapsed    | 2170     |\n",
      "|    total_timesteps | 1036288  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.36e+03     |\n",
      "|    ep_rew_mean          | 1.24e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 477          |\n",
      "|    iterations           | 507          |\n",
      "|    time_elapsed         | 2172         |\n",
      "|    total_timesteps      | 1038336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038349447 |\n",
      "|    clip_fraction        | 0.0239       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.52         |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6e+03        |\n",
      "|    n_updates            | 20970        |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 3.1e+04      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=71047.41 +/- 3909.33\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029400691 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.5        |\n",
      "|    n_updates            | 20980       |\n",
      "|    policy_gradient_loss | 0.00735     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 35.8        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.36e+03 |\n",
      "|    ep_rew_mean     | 1.24e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 475      |\n",
      "|    iterations      | 508      |\n",
      "|    time_elapsed    | 2186     |\n",
      "|    total_timesteps | 1040384  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | 1.29e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 2188        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022642609 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.3        |\n",
      "|    n_updates            | 20990       |\n",
      "|    policy_gradient_loss | 0.0064      |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 131         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.39e+03   |\n",
      "|    ep_rew_mean          | 1.29e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 476        |\n",
      "|    iterations           | 510        |\n",
      "|    time_elapsed         | 2189       |\n",
      "|    total_timesteps      | 1044480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03820246 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.57       |\n",
      "|    explained_variance   | 0.855      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 21000      |\n",
      "|    policy_gradient_loss | 0.00732    |\n",
      "|    std                  | 0.204      |\n",
      "|    value_loss           | 2e+04      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1045000, episode_reward=71478.65 +/- 4378.04\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 7.15e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1045000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05168017 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.57       |\n",
      "|    explained_variance   | 0.88       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 39.4       |\n",
      "|    n_updates            | 21010      |\n",
      "|    policy_gradient_loss | 0.00556    |\n",
      "|    std                  | 0.205      |\n",
      "|    value_loss           | 117        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.42e+03 |\n",
      "|    ep_rew_mean     | 1.34e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 474      |\n",
      "|    iterations      | 511      |\n",
      "|    time_elapsed    | 2203     |\n",
      "|    total_timesteps | 1046528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | 1.34e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 2205        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010156606 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.2        |\n",
      "|    n_updates            | 21020       |\n",
      "|    policy_gradient_loss | 0.00365     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 587         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=68271.75 +/- 5572.78\n",
      "Episode length: 4422.60 +/- 34.64\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 4.42e+03 |\n",
      "|    mean_reward          | 6.83e+04 |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 1050000  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.019908 |\n",
      "|    clip_fraction        | 0.3      |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 2.55     |\n",
      "|    explained_variance   | 0.989    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 30.4     |\n",
      "|    n_updates            | 21030    |\n",
      "|    policy_gradient_loss | 0.0155   |\n",
      "|    std                  | 0.207    |\n",
      "|    value_loss           | 79.7     |\n",
      "--------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.44e+03 |\n",
      "|    ep_rew_mean     | 1.39e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 473      |\n",
      "|    iterations      | 513      |\n",
      "|    time_elapsed    | 2217     |\n",
      "|    total_timesteps | 1050624  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.46e+03  |\n",
      "|    ep_rew_mean          | 1.42e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 474       |\n",
      "|    iterations           | 514       |\n",
      "|    time_elapsed         | 2219      |\n",
      "|    total_timesteps      | 1052672   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0383323 |\n",
      "|    clip_fraction        | 0.144     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.55      |\n",
      "|    explained_variance   | 0.908     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 15.9      |\n",
      "|    n_updates            | 21040     |\n",
      "|    policy_gradient_loss | 0.00375   |\n",
      "|    std                  | 0.207     |\n",
      "|    value_loss           | 1.87e+04  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.46e+03    |\n",
      "|    ep_rew_mean          | 1.42e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 474         |\n",
      "|    iterations           | 515         |\n",
      "|    time_elapsed         | 2221        |\n",
      "|    total_timesteps      | 1054720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013816713 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.55        |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.4        |\n",
      "|    n_updates            | 21050       |\n",
      "|    policy_gradient_loss | -0.0036     |\n",
      "|    std                  | 0.207       |\n",
      "|    value_loss           | 2.27e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1055000, episode_reward=59493.16 +/- 3822.07\n",
      "Episode length: 4161.00 +/- 27.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.16e+03    |\n",
      "|    mean_reward          | 5.95e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1055000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017695844 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.56        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 21060       |\n",
      "|    policy_gradient_loss | 0.00254     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 79.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.48e+03 |\n",
      "|    ep_rew_mean     | 1.46e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 473      |\n",
      "|    iterations      | 516      |\n",
      "|    time_elapsed    | 2232     |\n",
      "|    total_timesteps | 1056768  |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.48e+03   |\n",
      "|    ep_rew_mean          | 1.46e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 473        |\n",
      "|    iterations           | 517        |\n",
      "|    time_elapsed         | 2234       |\n",
      "|    total_timesteps      | 1058816    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00952596 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.57       |\n",
      "|    explained_variance   | 0.935      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 74.9       |\n",
      "|    n_updates            | 21070      |\n",
      "|    policy_gradient_loss | 0.00243    |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 1.78e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=21649.08 +/- 68223.56\n",
      "Episode length: 3169.00 +/- 1545.69\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.17e+03   |\n",
      "|    mean_reward          | 2.16e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1060000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06770113 |\n",
      "|    clip_fraction        | 0.367      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.58       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 20.1       |\n",
      "|    n_updates            | 21080      |\n",
      "|    policy_gradient_loss | 0.0196     |\n",
      "|    std                  | 0.205      |\n",
      "|    value_loss           | 59.5       |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.49e+03 |\n",
      "|    ep_rew_mean     | 1.38e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 472      |\n",
      "|    iterations      | 518      |\n",
      "|    time_elapsed    | 2244     |\n",
      "|    total_timesteps | 1060864  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+03    |\n",
      "|    ep_rew_mean          | 1.29e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 2245        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014793454 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.58        |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.9e+06     |\n",
      "|    n_updates            | 21090       |\n",
      "|    policy_gradient_loss | 0.000752    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 2.38e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.49e+03     |\n",
      "|    ep_rew_mean          | 1.29e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 473          |\n",
      "|    iterations           | 520          |\n",
      "|    time_elapsed         | 2247         |\n",
      "|    total_timesteps      | 1064960      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019975058 |\n",
      "|    clip_fraction        | 0.00654      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.58         |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.35e+07     |\n",
      "|    n_updates            | 21100        |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.39e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1065000, episode_reward=30074.89 +/- 70284.24\n",
      "Episode length: 3293.00 +/- 1610.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.29e+03    |\n",
      "|    mean_reward          | 3.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1065000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008173319 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.58        |\n",
      "|    explained_variance   | 0.615       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.79e+04    |\n",
      "|    n_updates            | 21110       |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 5.46e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.51e+03 |\n",
      "|    ep_rew_mean     | 1.33e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 472      |\n",
      "|    iterations      | 521      |\n",
      "|    time_elapsed    | 2257     |\n",
      "|    total_timesteps | 1067008  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.51e+03     |\n",
      "|    ep_rew_mean          | 1.33e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 473          |\n",
      "|    iterations           | 522          |\n",
      "|    time_elapsed         | 2259         |\n",
      "|    total_timesteps      | 1069056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056375503 |\n",
      "|    clip_fraction        | 0.0632       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.58         |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.62e+03     |\n",
      "|    n_updates            | 21120        |\n",
      "|    policy_gradient_loss | -0.00856     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.92e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1070000, episode_reward=54934.13 +/- 3527.28\n",
      "Episode length: 4021.40 +/- 39.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.02e+03     |\n",
      "|    mean_reward          | 5.49e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1070000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055269375 |\n",
      "|    clip_fraction        | 0.0231       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.58         |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.28e+04     |\n",
      "|    n_updates            | 21130        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 2.35e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.53e+03 |\n",
      "|    ep_rew_mean     | 1.33e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 471      |\n",
      "|    iterations      | 523      |\n",
      "|    time_elapsed    | 2270     |\n",
      "|    total_timesteps | 1071104  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.54e+03     |\n",
      "|    ep_rew_mean          | 1.36e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 472          |\n",
      "|    iterations           | 524          |\n",
      "|    time_elapsed         | 2272         |\n",
      "|    total_timesteps      | 1073152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0088543175 |\n",
      "|    clip_fraction        | 0.073        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.58         |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 626          |\n",
      "|    n_updates            | 21140        |\n",
      "|    policy_gradient_loss | -0.00709     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 2.47e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1075000, episode_reward=26050.99 +/- 68408.44\n",
      "Episode length: 3404.00 +/- 1665.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.4e+03      |\n",
      "|    mean_reward          | 2.61e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1075000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030658287 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.58         |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 21150        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.01e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 1.36e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 471      |\n",
      "|    iterations      | 525      |\n",
      "|    time_elapsed    | 2282     |\n",
      "|    total_timesteps | 1075200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57e+03    |\n",
      "|    ep_rew_mean          | 1.4e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 2284        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014397537 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.58        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.6        |\n",
      "|    n_updates            | 21160       |\n",
      "|    policy_gradient_loss | 0.00754     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 784         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57e+03    |\n",
      "|    ep_rew_mean          | 1.4e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 472         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 2286        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004515538 |\n",
      "|    clip_fraction        | 0.0253      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.58        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 21170       |\n",
      "|    policy_gradient_loss | -0.00242    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 1.45e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1080000, episode_reward=69129.23 +/- 2794.82\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 6.91e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1080000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01671296 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.58       |\n",
      "|    explained_variance   | 0.919      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.2       |\n",
      "|    n_updates            | 21180      |\n",
      "|    policy_gradient_loss | 0.00903    |\n",
      "|    std                  | 0.204      |\n",
      "|    value_loss           | 428        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.57e+03 |\n",
      "|    ep_rew_mean     | 1.32e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 470      |\n",
      "|    iterations      | 528      |\n",
      "|    time_elapsed    | 2299     |\n",
      "|    total_timesteps | 1081344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57e+03    |\n",
      "|    ep_rew_mean          | 1.32e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 2301        |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004181006 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.58        |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.26e+06    |\n",
      "|    n_updates            | 21190       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    std                  | 0.204       |\n",
      "|    value_loss           | 1.51e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1085000, episode_reward=54441.73 +/- 4474.29\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 5.44e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1085000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02685046 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.58       |\n",
      "|    explained_variance   | 0.57       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 155        |\n",
      "|    n_updates            | 21200      |\n",
      "|    policy_gradient_loss | -0.00186   |\n",
      "|    std                  | 0.204      |\n",
      "|    value_loss           | 895        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.58e+03 |\n",
      "|    ep_rew_mean     | 1.23e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 468      |\n",
      "|    iterations      | 530      |\n",
      "|    time_elapsed    | 2315     |\n",
      "|    total_timesteps | 1085440  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.58e+03     |\n",
      "|    ep_rew_mean          | 1.23e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 469          |\n",
      "|    iterations           | 531          |\n",
      "|    time_elapsed         | 2317         |\n",
      "|    total_timesteps      | 1087488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047217533 |\n",
      "|    clip_fraction        | 0.0353       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.58         |\n",
      "|    explained_variance   | 0.419        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.34e+06     |\n",
      "|    n_updates            | 21210        |\n",
      "|    policy_gradient_loss | -0.00422     |\n",
      "|    std                  | 0.204        |\n",
      "|    value_loss           | 1.46e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.6e+03     |\n",
      "|    ep_rew_mean          | 1.27e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 469         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 2319        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016157547 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.58        |\n",
      "|    explained_variance   | 0.749       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.1        |\n",
      "|    n_updates            | 21220       |\n",
      "|    policy_gradient_loss | 0.00588     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 313         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1090000, episode_reward=57333.61 +/- 3526.29\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 5.73e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009913022 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.57        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.01e+03    |\n",
      "|    n_updates            | 21230       |\n",
      "|    policy_gradient_loss | 0.00153     |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 2.79e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.6e+03  |\n",
      "|    ep_rew_mean     | 1.27e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 533      |\n",
      "|    time_elapsed    | 2333     |\n",
      "|    total_timesteps | 1091584  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.62e+03    |\n",
      "|    ep_rew_mean          | 1.31e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 2334        |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020617424 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.57        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20          |\n",
      "|    n_updates            | 21240       |\n",
      "|    policy_gradient_loss | 0.0128      |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 91.1        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1095000, episode_reward=56306.31 +/- 3476.96\n",
      "Episode length: 4389.60 +/- 34.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.39e+03     |\n",
      "|    mean_reward          | 5.63e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1095000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025341758 |\n",
      "|    clip_fraction        | 0.0481       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.57         |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 185          |\n",
      "|    n_updates            | 21250        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 1.89e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.62e+03 |\n",
      "|    ep_rew_mean     | 1.31e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 466      |\n",
      "|    iterations      | 535      |\n",
      "|    time_elapsed    | 2347     |\n",
      "|    total_timesteps | 1095680  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.64e+03    |\n",
      "|    ep_rew_mean          | 1.34e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 467         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 2349        |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016113494 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.57        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.3        |\n",
      "|    n_updates            | 21260       |\n",
      "|    policy_gradient_loss | 0.000742    |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 222         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.65e+03   |\n",
      "|    ep_rew_mean          | 1.37e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 467        |\n",
      "|    iterations           | 537        |\n",
      "|    time_elapsed         | 2350       |\n",
      "|    total_timesteps      | 1099776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01572142 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.57       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 117        |\n",
      "|    n_updates            | 21270      |\n",
      "|    policy_gradient_loss | 0.00069    |\n",
      "|    std                  | 0.206      |\n",
      "|    value_loss           | 559        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=48665.42 +/- 2359.12\n",
      "Episode length: 3355.00 +/- 10.99\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.36e+03   |\n",
      "|    mean_reward          | 4.87e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1100000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01905982 |\n",
      "|    clip_fraction        | 0.261      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.57       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 42.7       |\n",
      "|    n_updates            | 21280      |\n",
      "|    policy_gradient_loss | 0.00886    |\n",
      "|    std                  | 0.207      |\n",
      "|    value_loss           | 650        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.65e+03 |\n",
      "|    ep_rew_mean     | 1.37e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 466      |\n",
      "|    iterations      | 538      |\n",
      "|    time_elapsed    | 2360     |\n",
      "|    total_timesteps | 1101824  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.68e+03     |\n",
      "|    ep_rew_mean          | 1.41e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 539          |\n",
      "|    time_elapsed         | 2362         |\n",
      "|    total_timesteps      | 1103872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0153854545 |\n",
      "|    clip_fraction        | 0.204        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.56         |\n",
      "|    explained_variance   | 0.962        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 51.7         |\n",
      "|    n_updates            | 21290        |\n",
      "|    policy_gradient_loss | 0.00802      |\n",
      "|    std                  | 0.206        |\n",
      "|    value_loss           | 242          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1105000, episode_reward=41736.30 +/- 5740.25\n",
      "Episode length: 3259.00 +/- 29.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.26e+03    |\n",
      "|    mean_reward          | 4.17e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1105000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013553698 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.57        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.1        |\n",
      "|    n_updates            | 21300       |\n",
      "|    policy_gradient_loss | 0.00149     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 332         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.68e+03 |\n",
      "|    ep_rew_mean     | 1.3e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 466      |\n",
      "|    iterations      | 540      |\n",
      "|    time_elapsed    | 2372     |\n",
      "|    total_timesteps | 1105920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.68e+03    |\n",
      "|    ep_rew_mean          | 1.3e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 466         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 2374        |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027105201 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.57        |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7e+06     |\n",
      "|    n_updates            | 21310       |\n",
      "|    policy_gradient_loss | 0.00257     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 1.73e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=12534.34 +/- 64918.31\n",
      "Episode length: 2556.80 +/- 1240.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.56e+03    |\n",
      "|    mean_reward          | 1.25e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012407802 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.57        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 21320       |\n",
      "|    policy_gradient_loss | 0.00564     |\n",
      "|    std                  | 0.206       |\n",
      "|    value_loss           | 148         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | 1.33e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 465      |\n",
      "|    iterations      | 542      |\n",
      "|    time_elapsed    | 2382     |\n",
      "|    total_timesteps | 1110016  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.7e+03      |\n",
      "|    ep_rew_mean          | 1.34e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 543          |\n",
      "|    time_elapsed         | 2383         |\n",
      "|    total_timesteps      | 1112064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0138003435 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.58         |\n",
      "|    explained_variance   | 0.996        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 40.6         |\n",
      "|    n_updates            | 21330        |\n",
      "|    policy_gradient_loss | 0.00205      |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 224          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.71e+03     |\n",
      "|    ep_rew_mean          | 1.17e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 544          |\n",
      "|    time_elapsed         | 2385         |\n",
      "|    total_timesteps      | 1114112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075009293 |\n",
      "|    clip_fraction        | 0.0762       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 365          |\n",
      "|    n_updates            | 21340        |\n",
      "|    policy_gradient_loss | -0.00177     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.45e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1115000, episode_reward=31282.76 +/- 5371.54\n",
      "Episode length: 2820.00 +/- 26.05\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 2.82e+03      |\n",
      "|    mean_reward          | 3.13e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 1115000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00026419706 |\n",
      "|    clip_fraction        | 0.00415       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 2.59          |\n",
      "|    explained_variance   | 0.355         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 5.16e+07      |\n",
      "|    n_updates            | 21350         |\n",
      "|    policy_gradient_loss | 0.00108       |\n",
      "|    std                  | 0.205         |\n",
      "|    value_loss           | 4.72e+07      |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.71e+03 |\n",
      "|    ep_rew_mean     | 1.1e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 466      |\n",
      "|    iterations      | 545      |\n",
      "|    time_elapsed    | 2394     |\n",
      "|    total_timesteps | 1116160  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.71e+03     |\n",
      "|    ep_rew_mean          | 1.12e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 466          |\n",
      "|    iterations           | 546          |\n",
      "|    time_elapsed         | 2396         |\n",
      "|    total_timesteps      | 1118208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061678495 |\n",
      "|    clip_fraction        | 0.0184       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.463        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.72e+06     |\n",
      "|    n_updates            | 21360        |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 1.34e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=8349.00 +/- 62280.68\n",
      "Episode length: 2338.60 +/- 1130.39\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.34e+03     |\n",
      "|    mean_reward          | 8.35e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060110176 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.59e+03     |\n",
      "|    n_updates            | 21370        |\n",
      "|    policy_gradient_loss | -0.00754     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 6.09e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.72e+03 |\n",
      "|    ep_rew_mean     | 1.13e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 466      |\n",
      "|    iterations      | 547      |\n",
      "|    time_elapsed    | 2403     |\n",
      "|    total_timesteps | 1120256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.72e+03    |\n",
      "|    ep_rew_mean          | 1.13e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 466         |\n",
      "|    iterations           | 548         |\n",
      "|    time_elapsed         | 2405        |\n",
      "|    total_timesteps      | 1122304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004224998 |\n",
      "|    clip_fraction        | 0.0275      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.78e+03    |\n",
      "|    n_updates            | 21380       |\n",
      "|    policy_gradient_loss | -0.00365    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 2.39e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.73e+03    |\n",
      "|    ep_rew_mean          | 1.15e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 467         |\n",
      "|    iterations           | 549         |\n",
      "|    time_elapsed         | 2407        |\n",
      "|    total_timesteps      | 1124352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006974886 |\n",
      "|    clip_fraction        | 0.0658      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.59        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 21390       |\n",
      "|    policy_gradient_loss | -0.00078    |\n",
      "|    std                  | 0.205       |\n",
      "|    value_loss           | 5.76e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1125000, episode_reward=-55546.56 +/- 76326.83\n",
      "Episode length: 1226.80 +/- 1407.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.23e+03     |\n",
      "|    mean_reward          | -5.55e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1125000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074645504 |\n",
      "|    clip_fraction        | 0.0642       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.59         |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 679          |\n",
      "|    n_updates            | 21400        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 4.75e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.74e+03 |\n",
      "|    ep_rew_mean     | 1.18e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 466      |\n",
      "|    iterations      | 550      |\n",
      "|    time_elapsed    | 2412     |\n",
      "|    total_timesteps | 1126400  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.75e+03     |\n",
      "|    ep_rew_mean          | 1.19e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 467          |\n",
      "|    iterations           | 551          |\n",
      "|    time_elapsed         | 2414         |\n",
      "|    total_timesteps      | 1128448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050388104 |\n",
      "|    clip_fraction        | 0.0462       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.6          |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 621          |\n",
      "|    n_updates            | 21410        |\n",
      "|    policy_gradient_loss | -0.0059      |\n",
      "|    std                  | 0.205        |\n",
      "|    value_loss           | 2.3e+04      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1130000, episode_reward=37973.89 +/- 3829.00\n",
      "Episode length: 2770.80 +/- 10.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.77e+03    |\n",
      "|    mean_reward          | 3.8e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009760394 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.6         |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 21420       |\n",
      "|    policy_gradient_loss | -0.00157    |\n",
      "|    std                  | 0.204       |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.75e+03 |\n",
      "|    ep_rew_mean     | 1.19e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 466      |\n",
      "|    iterations      | 552      |\n",
      "|    time_elapsed    | 2422     |\n",
      "|    total_timesteps | 1130496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.75e+03    |\n",
      "|    ep_rew_mean          | 1.2e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 467         |\n",
      "|    iterations           | 553         |\n",
      "|    time_elapsed         | 2424        |\n",
      "|    total_timesteps      | 1132544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008272892 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.61        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 21430       |\n",
      "|    policy_gradient_loss | 0.00313     |\n",
      "|    std                  | 0.204       |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | 1.21e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 467         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 2426        |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010879278 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.61        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 21440       |\n",
      "|    policy_gradient_loss | -0.00479    |\n",
      "|    std                  | 0.203       |\n",
      "|    value_loss           | 2e+04       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1135000, episode_reward=28765.82 +/- 4672.33\n",
      "Episode length: 2304.60 +/- 32.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 2.88e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1135000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006073389 |\n",
      "|    clip_fraction        | 0.0932      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.62        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96.5        |\n",
      "|    n_updates            | 21450       |\n",
      "|    policy_gradient_loss | 0.00149     |\n",
      "|    std                  | 0.203       |\n",
      "|    value_loss           | 950         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.76e+03 |\n",
      "|    ep_rew_mean     | 1.23e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 555      |\n",
      "|    time_elapsed    | 2433     |\n",
      "|    total_timesteps | 1136640  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | 1.25e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 467         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 2435        |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011692622 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.63        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.9        |\n",
      "|    n_updates            | 21460       |\n",
      "|    policy_gradient_loss | 0.000107    |\n",
      "|    std                  | 0.202       |\n",
      "|    value_loss           | 649         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1140000, episode_reward=-30434.93 +/- 66160.52\n",
      "Episode length: 1517.40 +/- 1179.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.52e+03    |\n",
      "|    mean_reward          | -3.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010852045 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.64        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.8        |\n",
      "|    n_updates            | 21470       |\n",
      "|    policy_gradient_loss | 8.27e-05    |\n",
      "|    std                  | 0.202       |\n",
      "|    value_loss           | 532         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.76e+03 |\n",
      "|    ep_rew_mean     | 1.26e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 557      |\n",
      "|    time_elapsed    | 2440     |\n",
      "|    total_timesteps | 1140736  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.76e+03   |\n",
      "|    ep_rew_mean          | 1.26e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 467        |\n",
      "|    iterations           | 558        |\n",
      "|    time_elapsed         | 2442       |\n",
      "|    total_timesteps      | 1142784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03354003 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.65       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 46.7       |\n",
      "|    n_updates            | 21480      |\n",
      "|    policy_gradient_loss | 0.0125     |\n",
      "|    std                  | 0.201      |\n",
      "|    value_loss           | 1.83e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | 1.27e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 2444        |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011424168 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.65        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.3        |\n",
      "|    n_updates            | 21490       |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 227         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1145000, episode_reward=7140.04 +/- 58475.79\n",
      "Episode length: 2014.20 +/- 971.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.01e+03    |\n",
      "|    mean_reward          | 7.14e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1145000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014690458 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.66        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47          |\n",
      "|    n_updates            | 21500       |\n",
      "|    policy_gradient_loss | 0.000576    |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.77e+03 |\n",
      "|    ep_rew_mean     | 1.28e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 560      |\n",
      "|    time_elapsed    | 2451     |\n",
      "|    total_timesteps | 1146880  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.77e+03    |\n",
      "|    ep_rew_mean          | 1.3e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 2453        |\n",
      "|    total_timesteps      | 1148928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018204303 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.68        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.7        |\n",
      "|    n_updates            | 21510       |\n",
      "|    policy_gradient_loss | 0.000309    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 128         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1150000, episode_reward=31099.59 +/- 3911.38\n",
      "Episode length: 2541.40 +/- 21.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.54e+03    |\n",
      "|    mean_reward          | 3.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012537908 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.69        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.5        |\n",
      "|    n_updates            | 21520       |\n",
      "|    policy_gradient_loss | 0.00373     |\n",
      "|    std                  | 0.2         |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.77e+03 |\n",
      "|    ep_rew_mean     | 1.32e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 562      |\n",
      "|    time_elapsed    | 2460     |\n",
      "|    total_timesteps | 1150976  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.78e+03    |\n",
      "|    ep_rew_mean          | 1.33e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 2462        |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011251577 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.69        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.7        |\n",
      "|    n_updates            | 21530       |\n",
      "|    policy_gradient_loss | -0.000738   |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 156         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1155000, episode_reward=-59626.25 +/- 2838.29\n",
      "Episode length: 2931.00 +/- 13.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.93e+03   |\n",
      "|    mean_reward          | -5.96e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1155000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00876054 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.69       |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.08e+04   |\n",
      "|    n_updates            | 21540      |\n",
      "|    policy_gradient_loss | 0.00289    |\n",
      "|    std                  | 0.199      |\n",
      "|    value_loss           | 1.79e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.78e+03 |\n",
      "|    ep_rew_mean     | 1.33e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 564      |\n",
      "|    time_elapsed    | 2471     |\n",
      "|    total_timesteps | 1155072  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.76e+03   |\n",
      "|    ep_rew_mean          | 1.21e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 467        |\n",
      "|    iterations           | 565        |\n",
      "|    time_elapsed         | 2473       |\n",
      "|    total_timesteps      | 1157120    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02691796 |\n",
      "|    clip_fraction        | 0.15       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.69       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 20.3       |\n",
      "|    n_updates            | 21550      |\n",
      "|    policy_gradient_loss | -0.00111   |\n",
      "|    std                  | 0.199      |\n",
      "|    value_loss           | 188        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | 1.21e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 566         |\n",
      "|    time_elapsed         | 2475        |\n",
      "|    total_timesteps      | 1159168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054260917 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.69        |\n",
      "|    explained_variance   | 0.38        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13e+07    |\n",
      "|    n_updates            | 21560       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 1.5e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=9711.13 +/- 55501.38\n",
      "Episode length: 2288.40 +/- 1110.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.29e+03    |\n",
      "|    mean_reward          | 9.71e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024018656 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.69        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 21570       |\n",
      "|    policy_gradient_loss | 0.0123      |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 78.3        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.77e+03 |\n",
      "|    ep_rew_mean     | 1.23e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 567      |\n",
      "|    time_elapsed    | 2482     |\n",
      "|    total_timesteps | 1161216  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.75e+03    |\n",
      "|    ep_rew_mean          | 1.12e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 2484        |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007704121 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.69        |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.9        |\n",
      "|    n_updates            | 21580       |\n",
      "|    policy_gradient_loss | 0.00378     |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 1.71e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1165000, episode_reward=9524.47 +/- 52719.29\n",
      "Episode length: 2413.20 +/- 1175.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.41e+03    |\n",
      "|    mean_reward          | 9.52e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1165000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015726805 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.69        |\n",
      "|    explained_variance   | 0.482       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.53e+06    |\n",
      "|    n_updates            | 21590       |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    std                  | 0.199       |\n",
      "|    value_loss           | 6.68e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.76e+03 |\n",
      "|    ep_rew_mean     | 1.12e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 569      |\n",
      "|    time_elapsed    | 2491     |\n",
      "|    total_timesteps | 1165312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | 1.12e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 2493        |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014056626 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.69        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.6        |\n",
      "|    n_updates            | 21600       |\n",
      "|    policy_gradient_loss | -0.00305    |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | 1.13e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 2495        |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029730596 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.69        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.2        |\n",
      "|    n_updates            | 21610       |\n",
      "|    policy_gradient_loss | 0.00417     |\n",
      "|    std                  | 0.198       |\n",
      "|    value_loss           | 51          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1170000, episode_reward=38758.17 +/- 810.83\n",
      "Episode length: 3210.40 +/- 19.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.21e+03     |\n",
      "|    mean_reward          | 3.88e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1170000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075739855 |\n",
      "|    clip_fraction        | 0.0864       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.69         |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 319          |\n",
      "|    n_updates            | 21620        |\n",
      "|    policy_gradient_loss | 0.000523     |\n",
      "|    std                  | 0.198        |\n",
      "|    value_loss           | 1.27e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.76e+03 |\n",
      "|    ep_rew_mean     | 1.13e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 572      |\n",
      "|    time_elapsed    | 2504     |\n",
      "|    total_timesteps | 1171456  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.76e+03     |\n",
      "|    ep_rew_mean          | 1.12e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 468          |\n",
      "|    iterations           | 573          |\n",
      "|    time_elapsed         | 2506         |\n",
      "|    total_timesteps      | 1173504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060027586 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.69         |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 133          |\n",
      "|    n_updates            | 21630        |\n",
      "|    policy_gradient_loss | -0.000997    |\n",
      "|    std                  | 0.198        |\n",
      "|    value_loss           | 1.33e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1175000, episode_reward=2593.98 +/- 59038.29\n",
      "Episode length: 2333.60 +/- 1129.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.33e+03    |\n",
      "|    mean_reward          | 2.59e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1175000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016111426 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.69        |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.4        |\n",
      "|    n_updates            | 21640       |\n",
      "|    policy_gradient_loss | -0.00314    |\n",
      "|    std                  | 0.197       |\n",
      "|    value_loss           | 1.85e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.76e+03 |\n",
      "|    ep_rew_mean     | 1.12e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 574      |\n",
      "|    time_elapsed    | 2514     |\n",
      "|    total_timesteps | 1175552  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.73e+03    |\n",
      "|    ep_rew_mean          | 8.61e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 2515        |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017977577 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.7         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40          |\n",
      "|    n_updates            | 21650       |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    std                  | 0.197       |\n",
      "|    value_loss           | 63.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.71e+03     |\n",
      "|    ep_rew_mean          | 7.64e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 468          |\n",
      "|    iterations           | 576          |\n",
      "|    time_elapsed         | 2517         |\n",
      "|    total_timesteps      | 1179648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051762657 |\n",
      "|    clip_fraction        | 0.058        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.71         |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.24e+06     |\n",
      "|    n_updates            | 21660        |\n",
      "|    policy_gradient_loss | -0.00486     |\n",
      "|    std                  | 0.197        |\n",
      "|    value_loss           | 3.09e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1180000, episode_reward=-421.49 +/- 54500.27\n",
      "Episode length: 2063.60 +/- 997.34\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.06e+03     |\n",
      "|    mean_reward          | -421         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1180000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040937206 |\n",
      "|    clip_fraction        | 0.0212       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.71         |\n",
      "|    explained_variance   | 0.447        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+07     |\n",
      "|    n_updates            | 21670        |\n",
      "|    policy_gradient_loss | -0.00348     |\n",
      "|    std                  | 0.197        |\n",
      "|    value_loss           | 1.94e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.7e+03  |\n",
      "|    ep_rew_mean     | 6.44e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 468      |\n",
      "|    iterations      | 577      |\n",
      "|    time_elapsed    | 2524     |\n",
      "|    total_timesteps | 1181696  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.7e+03      |\n",
      "|    ep_rew_mean          | 6.27e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 468          |\n",
      "|    iterations           | 578          |\n",
      "|    time_elapsed         | 2526         |\n",
      "|    total_timesteps      | 1183744      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035253796 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.7          |\n",
      "|    explained_variance   | 0.679        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.51e+06     |\n",
      "|    n_updates            | 21680        |\n",
      "|    policy_gradient_loss | -0.00496     |\n",
      "|    std                  | 0.197        |\n",
      "|    value_loss           | 3.34e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1185000, episode_reward=-9595.90 +/- 51370.37\n",
      "Episode length: 2653.00 +/- 1289.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.65e+03     |\n",
      "|    mean_reward          | -9.6e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1185000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035298127 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.7          |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.31e+03     |\n",
      "|    n_updates            | 21690        |\n",
      "|    policy_gradient_loss | -0.00412     |\n",
      "|    std                  | 0.197        |\n",
      "|    value_loss           | 1.02e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.66e+03 |\n",
      "|    ep_rew_mean     | 3.58e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 467      |\n",
      "|    iterations      | 579      |\n",
      "|    time_elapsed    | 2534     |\n",
      "|    total_timesteps | 1185792  |\n",
      "---------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 2.65e+03      |\n",
      "|    ep_rew_mean          | 2.4e+03       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 468           |\n",
      "|    iterations           | 580           |\n",
      "|    time_elapsed         | 2536          |\n",
      "|    total_timesteps      | 1187840       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00065320515 |\n",
      "|    clip_fraction        | 0.00132       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 2.7           |\n",
      "|    explained_variance   | 0.354         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.03e+06      |\n",
      "|    n_updates            | 21700         |\n",
      "|    policy_gradient_loss | -0.00123      |\n",
      "|    std                  | 0.197         |\n",
      "|    value_loss           | 3.13e+07      |\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.55e+03   |\n",
      "|    ep_rew_mean          | 1.86e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 468        |\n",
      "|    iterations           | 581        |\n",
      "|    time_elapsed         | 2538       |\n",
      "|    total_timesteps      | 1189888    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02505401 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.7        |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.87e+06   |\n",
      "|    n_updates            | 21710      |\n",
      "|    policy_gradient_loss | -8.97e-05  |\n",
      "|    std                  | 0.197      |\n",
      "|    value_loss           | 1.57e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1190000, episode_reward=9681.20 +/- 57838.35\n",
      "Episode length: 2610.40 +/- 1271.38\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.61e+03     |\n",
      "|    mean_reward          | 9.68e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1190000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037849774 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.7          |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.05e+06     |\n",
      "|    n_updates            | 21720        |\n",
      "|    policy_gradient_loss | -0.00407     |\n",
      "|    std                  | 0.197        |\n",
      "|    value_loss           | 2.04e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.54e+03 |\n",
      "|    ep_rew_mean     | 1.57e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 468      |\n",
      "|    iterations      | 582      |\n",
      "|    time_elapsed    | 2546     |\n",
      "|    total_timesteps | 1191936  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.54e+03    |\n",
      "|    ep_rew_mean          | 1.57e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 2548        |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007572903 |\n",
      "|    clip_fraction        | 0.0442      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.7         |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 21730       |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    std                  | 0.197       |\n",
      "|    value_loss           | 1.37e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1195000, episode_reward=-81254.63 +/- 58233.94\n",
      "Episode length: 617.80 +/- 1094.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 618         |\n",
      "|    mean_reward          | -8.13e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1195000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008547295 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 330         |\n",
      "|    n_updates            | 21740       |\n",
      "|    policy_gradient_loss | -0.000382   |\n",
      "|    std                  | 0.197       |\n",
      "|    value_loss           | 3.19e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.5e+03  |\n",
      "|    ep_rew_mean     | 212      |\n",
      "| time/              |          |\n",
      "|    fps             | 468      |\n",
      "|    iterations      | 584      |\n",
      "|    time_elapsed    | 2551     |\n",
      "|    total_timesteps | 1196032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49e+03    |\n",
      "|    ep_rew_mean          | 565         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 469         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 2553        |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025492067 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.56e+06    |\n",
      "|    n_updates            | 21750       |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    std                  | 0.197       |\n",
      "|    value_loss           | 9.55e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=27579.39 +/- 4809.08\n",
      "Episode length: 2645.80 +/- 31.87\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.65e+03     |\n",
      "|    mean_reward          | 2.76e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061091357 |\n",
      "|    clip_fraction        | 0.0661       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.71         |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+07     |\n",
      "|    n_updates            | 21760        |\n",
      "|    policy_gradient_loss | -0.000595    |\n",
      "|    std                  | 0.197        |\n",
      "|    value_loss           | 1.48e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.5e+03  |\n",
      "|    ep_rew_mean     | 1.62e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 468      |\n",
      "|    iterations      | 586      |\n",
      "|    time_elapsed    | 2561     |\n",
      "|    total_timesteps | 1200128  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.45e+03    |\n",
      "|    ep_rew_mean          | 64          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 468         |\n",
      "|    iterations           | 587         |\n",
      "|    time_elapsed         | 2563        |\n",
      "|    total_timesteps      | 1202176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010285163 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.1        |\n",
      "|    n_updates            | 21770       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    std                  | 0.197       |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | -143        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 469         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 2565        |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010388507 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.7         |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.63e+07    |\n",
      "|    n_updates            | 21780       |\n",
      "|    policy_gradient_loss | 0.00288     |\n",
      "|    std                  | 0.197       |\n",
      "|    value_loss           | 2.85e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1205000, episode_reward=-1658.16 +/- 58098.09\n",
      "Episode length: 2000.00 +/- 961.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | -1.66e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1205000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011954124 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.7         |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 21790       |\n",
      "|    policy_gradient_loss | -0.00282    |\n",
      "|    std                  | 0.197       |\n",
      "|    value_loss           | 1.25e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.44e+03 |\n",
      "|    ep_rew_mean     | -688     |\n",
      "| time/              |          |\n",
      "|    fps             | 469      |\n",
      "|    iterations      | 589      |\n",
      "|    time_elapsed    | 2571     |\n",
      "|    total_timesteps | 1206272  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.4e+03      |\n",
      "|    ep_rew_mean          | -2.15e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 469          |\n",
      "|    iterations           | 590          |\n",
      "|    time_elapsed         | 2573         |\n",
      "|    total_timesteps      | 1208320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047108717 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.7          |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.52e+05     |\n",
      "|    n_updates            | 21800        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    std                  | 0.197        |\n",
      "|    value_loss           | 1.73e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1210000, episode_reward=-32173.08 +/- 52564.83\n",
      "Episode length: 1072.20 +/- 1258.07\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.07e+03   |\n",
      "|    mean_reward          | -3.22e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1210000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18352267 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.71       |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.36e+06   |\n",
      "|    n_updates            | 21810      |\n",
      "|    policy_gradient_loss | -0.00722   |\n",
      "|    std                  | 0.197      |\n",
      "|    value_loss           | 1.31e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.32e+03  |\n",
      "|    ep_rew_mean     | -5.59e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 469       |\n",
      "|    iterations      | 591       |\n",
      "|    time_elapsed    | 2578      |\n",
      "|    total_timesteps | 1210368   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.31e+03  |\n",
      "|    ep_rew_mean          | -5.85e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 469       |\n",
      "|    iterations           | 592       |\n",
      "|    time_elapsed         | 2580      |\n",
      "|    total_timesteps      | 1212416   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.2600653 |\n",
      "|    clip_fraction        | 0.145     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.71      |\n",
      "|    explained_variance   | 0.418     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.4e+07   |\n",
      "|    n_updates            | 21820     |\n",
      "|    policy_gradient_loss | 0.062     |\n",
      "|    std                  | 0.196     |\n",
      "|    value_loss           | 2.1e+07   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.3e+03     |\n",
      "|    ep_rew_mean          | -5.88e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 2581        |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013542753 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.72        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78.5        |\n",
      "|    n_updates            | 21830       |\n",
      "|    policy_gradient_loss | 0.000995    |\n",
      "|    std                  | 0.196       |\n",
      "|    value_loss           | 537         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1215000, episode_reward=27295.26 +/- 428.47\n",
      "Episode length: 2104.20 +/- 18.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.1e+03     |\n",
      "|    mean_reward          | 2.73e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1215000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007154165 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 21840       |\n",
      "|    policy_gradient_loss | 0.000362    |\n",
      "|    std                  | 0.196       |\n",
      "|    value_loss           | 1.91e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.29e+03  |\n",
      "|    ep_rew_mean     | -6.07e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 469       |\n",
      "|    iterations      | 594       |\n",
      "|    time_elapsed    | 2588      |\n",
      "|    total_timesteps | 1216512   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.25e+03    |\n",
      "|    ep_rew_mean          | -7.52e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 595         |\n",
      "|    time_elapsed         | 2590        |\n",
      "|    total_timesteps      | 1218560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012263295 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.8        |\n",
      "|    n_updates            | 21850       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    std                  | 0.196       |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=17407.12 +/- 5266.61\n",
      "Episode length: 1876.80 +/- 27.90\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.88e+03    |\n",
      "|    mean_reward          | 1.74e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.103713885 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.99e+06    |\n",
      "|    n_updates            | 21860       |\n",
      "|    policy_gradient_loss | -0.000823   |\n",
      "|    std                  | 0.196       |\n",
      "|    value_loss           | 1.18e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.21e+03  |\n",
      "|    ep_rew_mean     | -9.18e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 470       |\n",
      "|    iterations      | 596       |\n",
      "|    time_elapsed    | 2596      |\n",
      "|    total_timesteps | 1220608   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.15e+03  |\n",
      "|    ep_rew_mean          | -9.23e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 470       |\n",
      "|    iterations           | 597       |\n",
      "|    time_elapsed         | 2598      |\n",
      "|    total_timesteps      | 1222656   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0661422 |\n",
      "|    clip_fraction        | 0.0927    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.71      |\n",
      "|    explained_variance   | 0.39      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.12e+06  |\n",
      "|    n_updates            | 21870     |\n",
      "|    policy_gradient_loss | 0.00612   |\n",
      "|    std                  | 0.196     |\n",
      "|    value_loss           | 1.24e+07  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | -7.17e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 470         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 2600        |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027078044 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+07    |\n",
      "|    n_updates            | 21880       |\n",
      "|    policy_gradient_loss | -0.00144    |\n",
      "|    std                  | 0.196       |\n",
      "|    value_loss           | 1.52e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1225000, episode_reward=17063.02 +/- 4408.61\n",
      "Episode length: 1951.20 +/- 19.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.95e+03    |\n",
      "|    mean_reward          | 1.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1225000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030899052 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.71        |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 21890       |\n",
      "|    policy_gradient_loss | -0.00235    |\n",
      "|    std                  | 0.196       |\n",
      "|    value_loss           | 4.33e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.05e+03  |\n",
      "|    ep_rew_mean     | -5.25e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 470       |\n",
      "|    iterations      | 599       |\n",
      "|    time_elapsed    | 2607      |\n",
      "|    total_timesteps | 1226752   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.02e+03     |\n",
      "|    ep_rew_mean          | -5.25e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 471          |\n",
      "|    iterations           | 600          |\n",
      "|    time_elapsed         | 2608         |\n",
      "|    total_timesteps      | 1228800      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0120200645 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.72         |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 271          |\n",
      "|    n_updates            | 21900        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    std                  | 0.196        |\n",
      "|    value_loss           | 2.26e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=17067.51 +/- 5731.12\n",
      "Episode length: 1990.80 +/- 24.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.99e+03    |\n",
      "|    mean_reward          | 1.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012838884 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.72        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56          |\n",
      "|    n_updates            | 21910       |\n",
      "|    policy_gradient_loss | 0.00061     |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 1.41e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.99e+03  |\n",
      "|    ep_rew_mean     | -5.56e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 470       |\n",
      "|    iterations      | 601       |\n",
      "|    time_elapsed    | 2615      |\n",
      "|    total_timesteps | 1230848   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.96e+03     |\n",
      "|    ep_rew_mean          | -5.98e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 471          |\n",
      "|    iterations           | 602          |\n",
      "|    time_elapsed         | 2617         |\n",
      "|    total_timesteps      | 1232896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071531734 |\n",
      "|    clip_fraction        | 0.151        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.73         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 471          |\n",
      "|    n_updates            | 21920        |\n",
      "|    policy_gradient_loss | 0.0103       |\n",
      "|    std                  | 0.195        |\n",
      "|    value_loss           | 3.29e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -6.66e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 2619        |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016623596 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.73        |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.91e+03    |\n",
      "|    n_updates            | 21930       |\n",
      "|    policy_gradient_loss | -0.000877   |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 6.79e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1235000, episode_reward=12364.45 +/- 3684.09\n",
      "Episode length: 2069.80 +/- 13.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.07e+03   |\n",
      "|    mean_reward          | 1.24e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1235000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04949267 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.74       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 49.5       |\n",
      "|    n_updates            | 21940      |\n",
      "|    policy_gradient_loss | 0.00512    |\n",
      "|    std                  | 0.195      |\n",
      "|    value_loss           | 169        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.91e+03  |\n",
      "|    ep_rew_mean     | -7.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 471       |\n",
      "|    iterations      | 604       |\n",
      "|    time_elapsed    | 2625      |\n",
      "|    total_timesteps | 1236992   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | -8.19e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 471         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 2627        |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008263123 |\n",
      "|    clip_fraction        | 0.46        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.22e+05    |\n",
      "|    n_updates            | 21950       |\n",
      "|    policy_gradient_loss | 0.0164      |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 4.14e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=-10137.65 +/- 48972.17\n",
      "Episode length: 1698.40 +/- 812.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.7e+03      |\n",
      "|    mean_reward          | -1.01e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029132308 |\n",
      "|    clip_fraction        | 0.02         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 295          |\n",
      "|    n_updates            | 21960        |\n",
      "|    policy_gradient_loss | -0.000342    |\n",
      "|    std                  | 0.195        |\n",
      "|    value_loss           | 1.79e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.84e+03 |\n",
      "|    ep_rew_mean     | -1.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 471      |\n",
      "|    iterations      | 606      |\n",
      "|    time_elapsed    | 2633     |\n",
      "|    total_timesteps | 1241088  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.82e+03     |\n",
      "|    ep_rew_mean          | -1.14e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 471          |\n",
      "|    iterations           | 607          |\n",
      "|    time_elapsed         | 2635         |\n",
      "|    total_timesteps      | 1243136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012932438 |\n",
      "|    clip_fraction        | 0.00649      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+07     |\n",
      "|    n_updates            | 21970        |\n",
      "|    policy_gradient_loss | -0.00282     |\n",
      "|    std                  | 0.195        |\n",
      "|    value_loss           | 2.75e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1245000, episode_reward=7382.61 +/- 6703.90\n",
      "Episode length: 1972.00 +/- 20.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.97e+03    |\n",
      "|    mean_reward          | 7.38e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1245000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007599821 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.43e+03    |\n",
      "|    n_updates            | 21980       |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 3.4e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -1.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 471       |\n",
      "|    iterations      | 608       |\n",
      "|    time_elapsed    | 2641      |\n",
      "|    total_timesteps | 1245184   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.77e+03     |\n",
      "|    ep_rew_mean          | -1.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 471          |\n",
      "|    iterations           | 609          |\n",
      "|    time_elapsed         | 2643         |\n",
      "|    total_timesteps      | 1247232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055749277 |\n",
      "|    clip_fraction        | 0.0351       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.39e+06     |\n",
      "|    n_updates            | 21990        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    std                  | 0.195        |\n",
      "|    value_loss           | 1.31e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.75e+03     |\n",
      "|    ep_rew_mean          | -1.3e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 472          |\n",
      "|    iterations           | 610          |\n",
      "|    time_elapsed         | 2645         |\n",
      "|    total_timesteps      | 1249280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076142484 |\n",
      "|    clip_fraction        | 0.0292       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.31         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88e+07     |\n",
      "|    n_updates            | 22000        |\n",
      "|    policy_gradient_loss | -0.000789    |\n",
      "|    std                  | 0.195        |\n",
      "|    value_loss           | 3.2e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=-45899.06 +/- 58644.52\n",
      "Episode length: 1235.00 +/- 946.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.24e+03     |\n",
      "|    mean_reward          | -4.59e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1250000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054415446 |\n",
      "|    clip_fraction        | 0.0257       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.7e+03      |\n",
      "|    n_updates            | 22010        |\n",
      "|    policy_gradient_loss | -0.00394     |\n",
      "|    std                  | 0.195        |\n",
      "|    value_loss           | 4.01e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.71e+03  |\n",
      "|    ep_rew_mean     | -1.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 472       |\n",
      "|    iterations      | 611       |\n",
      "|    time_elapsed    | 2650      |\n",
      "|    total_timesteps | 1251328   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | -1.34e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 472          |\n",
      "|    iterations           | 612          |\n",
      "|    time_elapsed         | 2652         |\n",
      "|    total_timesteps      | 1253376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050984784 |\n",
      "|    clip_fraction        | 0.0216       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.564        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.1e+04      |\n",
      "|    n_updates            | 22020        |\n",
      "|    policy_gradient_loss | -0.00732     |\n",
      "|    std                  | 0.195        |\n",
      "|    value_loss           | 5.88e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1255000, episode_reward=12872.28 +/- 5530.06\n",
      "Episode length: 2046.00 +/- 22.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.05e+03    |\n",
      "|    mean_reward          | 1.29e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1255000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005646145 |\n",
      "|    clip_fraction        | 0.0385      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 22030       |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 6.71e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.71e+03  |\n",
      "|    ep_rew_mean     | -1.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 472       |\n",
      "|    iterations      | 613       |\n",
      "|    time_elapsed    | 2658      |\n",
      "|    total_timesteps | 1255424   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -1.42e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 472         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 2660        |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006823032 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 490         |\n",
      "|    n_updates            | 22040       |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 2.21e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 2662        |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008711754 |\n",
      "|    clip_fraction        | 0.0437      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4e+07     |\n",
      "|    n_updates            | 22050       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 1.38e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=-8493.50 +/- 53598.24\n",
      "Episode length: 1645.60 +/- 785.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.65e+03     |\n",
      "|    mean_reward          | -8.49e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1260000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042704456 |\n",
      "|    clip_fraction        | 0.0459       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.75         |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 302          |\n",
      "|    n_updates            | 22060        |\n",
      "|    policy_gradient_loss | -0.00222     |\n",
      "|    std                  | 0.194        |\n",
      "|    value_loss           | 2.59e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -1.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 472       |\n",
      "|    iterations      | 616       |\n",
      "|    time_elapsed    | 2668      |\n",
      "|    total_timesteps | 1261568   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -1.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 2670        |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009648858 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 280         |\n",
      "|    n_updates            | 22070       |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 1.19e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1265000, episode_reward=21222.63 +/- 4431.94\n",
      "Episode length: 1947.80 +/- 19.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.95e+03    |\n",
      "|    mean_reward          | 2.12e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1265000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019257542 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 566         |\n",
      "|    n_updates            | 22080       |\n",
      "|    policy_gradient_loss | 0.00419     |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 2.73e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -1.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 472       |\n",
      "|    iterations      | 618       |\n",
      "|    time_elapsed    | 2676      |\n",
      "|    total_timesteps | 1265664   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -1.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 2678        |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024084197 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 22090       |\n",
      "|    policy_gradient_loss | 0.00174     |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 1.85e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.64e+03   |\n",
      "|    ep_rew_mean          | -1.43e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 473        |\n",
      "|    iterations           | 620        |\n",
      "|    time_elapsed         | 2680       |\n",
      "|    total_timesteps      | 1269760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01224277 |\n",
      "|    clip_fraction        | 0.244      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.75       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 47.9       |\n",
      "|    n_updates            | 22100      |\n",
      "|    policy_gradient_loss | 0.00371    |\n",
      "|    std                  | 0.194      |\n",
      "|    value_loss           | 353        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1270000, episode_reward=21478.30 +/- 4228.20\n",
      "Episode length: 2066.20 +/- 17.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.07e+03    |\n",
      "|    mean_reward          | 2.15e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007135237 |\n",
      "|    clip_fraction        | 0.0782      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 587         |\n",
      "|    n_updates            | 22110       |\n",
      "|    policy_gradient_loss | -0.00145    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 2.09e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -1.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 473       |\n",
      "|    iterations      | 621       |\n",
      "|    time_elapsed    | 2687      |\n",
      "|    total_timesteps | 1271808   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.62e+03   |\n",
      "|    ep_rew_mean          | -1.47e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 473        |\n",
      "|    iterations           | 622        |\n",
      "|    time_elapsed         | 2689       |\n",
      "|    total_timesteps      | 1273856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09026687 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.76       |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 102        |\n",
      "|    n_updates            | 22120      |\n",
      "|    policy_gradient_loss | 0.0152     |\n",
      "|    std                  | 0.195      |\n",
      "|    value_loss           | 3.32e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1275000, episode_reward=20151.04 +/- 3649.73\n",
      "Episode length: 2027.60 +/- 8.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.03e+03    |\n",
      "|    mean_reward          | 2.02e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1275000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030229911 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.2        |\n",
      "|    n_updates            | 22130       |\n",
      "|    policy_gradient_loss | 0.00132     |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 1.92e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -1.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 473       |\n",
      "|    iterations      | 623       |\n",
      "|    time_elapsed    | 2695      |\n",
      "|    total_timesteps | 1275904   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -1.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 624         |\n",
      "|    time_elapsed         | 2697        |\n",
      "|    total_timesteps      | 1277952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010646108 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.2        |\n",
      "|    n_updates            | 22140       |\n",
      "|    policy_gradient_loss | 0.00214     |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 3.89e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=18455.85 +/- 3133.36\n",
      "Episode length: 2008.60 +/- 8.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.01e+03    |\n",
      "|    mean_reward          | 1.85e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012785828 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 22150       |\n",
      "|    policy_gradient_loss | 0.00455     |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 591         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -1.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 473       |\n",
      "|    iterations      | 625       |\n",
      "|    time_elapsed    | 2704      |\n",
      "|    total_timesteps | 1280000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -1.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 2706        |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007464773 |\n",
      "|    clip_fraction        | 0.0754      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.775       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4e+05     |\n",
      "|    n_updates            | 22160       |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 1.17e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -1.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 474         |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 2708        |\n",
      "|    total_timesteps      | 1284096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012479306 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.4        |\n",
      "|    n_updates            | 22170       |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 2.28e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1285000, episode_reward=11909.13 +/- 4984.78\n",
      "Episode length: 2535.40 +/- 7.42\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.54e+03  |\n",
      "|    mean_reward          | 1.19e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1285000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0214031 |\n",
      "|    clip_fraction        | 0.214     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.76      |\n",
      "|    explained_variance   | 0.999     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 68.2      |\n",
      "|    n_updates            | 22180     |\n",
      "|    policy_gradient_loss | 0.00281   |\n",
      "|    std                  | 0.195     |\n",
      "|    value_loss           | 176       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.67e+03  |\n",
      "|    ep_rew_mean     | -1.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 473       |\n",
      "|    iterations      | 628       |\n",
      "|    time_elapsed    | 2716      |\n",
      "|    total_timesteps | 1286144   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.66e+03    |\n",
      "|    ep_rew_mean          | -1.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 2717        |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023648739 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.7        |\n",
      "|    n_updates            | 22190       |\n",
      "|    policy_gradient_loss | 0.0055      |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 1.8e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1290000, episode_reward=19693.72 +/- 5080.42\n",
      "Episode length: 3696.60 +/- 137.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.7e+03     |\n",
      "|    mean_reward          | 1.97e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010008188 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.72e+03    |\n",
      "|    n_updates            | 22200       |\n",
      "|    policy_gradient_loss | 0.000655    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 2.59e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.66e+03 |\n",
      "|    ep_rew_mean     | -1.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 472      |\n",
      "|    iterations      | 630      |\n",
      "|    time_elapsed    | 2728     |\n",
      "|    total_timesteps | 1290240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.66e+03    |\n",
      "|    ep_rew_mean          | -1.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 2730        |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017118622 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.6        |\n",
      "|    n_updates            | 22210       |\n",
      "|    policy_gradient_loss | 0.00392     |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 486         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.65e+03     |\n",
      "|    ep_rew_mean          | -1.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 473          |\n",
      "|    iterations           | 632          |\n",
      "|    time_elapsed         | 2732         |\n",
      "|    total_timesteps      | 1294336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041944357 |\n",
      "|    clip_fraction        | 0.0563       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51e+03     |\n",
      "|    n_updates            | 22220        |\n",
      "|    policy_gradient_loss | 0.000956     |\n",
      "|    std                  | 0.195        |\n",
      "|    value_loss           | 6.19e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1295000, episode_reward=-6781.77 +/- 54772.91\n",
      "Episode length: 2532.80 +/- 1227.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.53e+03    |\n",
      "|    mean_reward          | -6.78e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1295000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.082198285 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 164         |\n",
      "|    n_updates            | 22230       |\n",
      "|    policy_gradient_loss | 0.00561     |\n",
      "|    std                  | 0.195       |\n",
      "|    value_loss           | 2.07e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -1.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 473       |\n",
      "|    iterations      | 633       |\n",
      "|    time_elapsed    | 2739      |\n",
      "|    total_timesteps | 1296384   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.65e+03   |\n",
      "|    ep_rew_mean          | -1.25e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 473        |\n",
      "|    iterations           | 634        |\n",
      "|    time_elapsed         | 2741       |\n",
      "|    total_timesteps      | 1298432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01574343 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 356        |\n",
      "|    n_updates            | 22240      |\n",
      "|    policy_gradient_loss | -0.000329  |\n",
      "|    std                  | 0.194      |\n",
      "|    value_loss           | 2.32e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=17285.06 +/- 3240.75\n",
      "Episode length: 3064.20 +/- 91.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.06e+03     |\n",
      "|    mean_reward          | 1.73e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1300000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070676543 |\n",
      "|    clip_fraction        | 0.0382       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 450          |\n",
      "|    n_updates            | 22250        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    std                  | 0.194        |\n",
      "|    value_loss           | 2.8e+03      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -1.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 472       |\n",
      "|    iterations      | 635       |\n",
      "|    time_elapsed    | 2750      |\n",
      "|    total_timesteps | 1300480   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.66e+03   |\n",
      "|    ep_rew_mean          | -1.29e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 473        |\n",
      "|    iterations           | 636        |\n",
      "|    time_elapsed         | 2752       |\n",
      "|    total_timesteps      | 1302528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06388304 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 234        |\n",
      "|    n_updates            | 22260      |\n",
      "|    policy_gradient_loss | 0.0165     |\n",
      "|    std                  | 0.194      |\n",
      "|    value_loss           | 650        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.66e+03   |\n",
      "|    ep_rew_mean          | -1.31e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 473        |\n",
      "|    iterations           | 637        |\n",
      "|    time_elapsed         | 2754       |\n",
      "|    total_timesteps      | 1304576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02839771 |\n",
      "|    clip_fraction        | 0.251      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.77       |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 55.1       |\n",
      "|    n_updates            | 22270      |\n",
      "|    policy_gradient_loss | 0.0116     |\n",
      "|    std                  | 0.194      |\n",
      "|    value_loss           | 1.86e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1305000, episode_reward=12180.70 +/- 3470.85\n",
      "Episode length: 2334.60 +/- 18.97\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.33e+03  |\n",
      "|    mean_reward          | 1.22e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1305000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0189678 |\n",
      "|    clip_fraction        | 0.243     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.78      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 85.3      |\n",
      "|    n_updates            | 22280     |\n",
      "|    policy_gradient_loss | 0.00546   |\n",
      "|    std                  | 0.193     |\n",
      "|    value_loss           | 273       |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -1.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 473       |\n",
      "|    iterations      | 638       |\n",
      "|    time_elapsed    | 2762      |\n",
      "|    total_timesteps | 1306624   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -1.34e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 2763        |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014235424 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.3        |\n",
      "|    n_updates            | 22290       |\n",
      "|    policy_gradient_loss | -0.00716    |\n",
      "|    std                  | 0.193       |\n",
      "|    value_loss           | 1.97e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1310000, episode_reward=6608.10 +/- 4336.58\n",
      "Episode length: 2472.20 +/- 15.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.47e+03    |\n",
      "|    mean_reward          | 6.61e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021791158 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.9        |\n",
      "|    n_updates            | 22300       |\n",
      "|    policy_gradient_loss | 0.00129     |\n",
      "|    std                  | 0.193       |\n",
      "|    value_loss           | 187         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -1.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 472       |\n",
      "|    iterations      | 640       |\n",
      "|    time_elapsed    | 2771      |\n",
      "|    total_timesteps | 1310720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -1.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 2773        |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020073602 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.93e+03    |\n",
      "|    n_updates            | 22310       |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 3.93e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -1.48e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 473         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 2775        |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012287516 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.3        |\n",
      "|    n_updates            | 22320       |\n",
      "|    policy_gradient_loss | 0.00383     |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 1.85e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1315000, episode_reward=-15755.93 +/- 48458.40\n",
      "Episode length: 1350.40 +/- 638.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.35e+03    |\n",
      "|    mean_reward          | -1.58e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1315000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007196046 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 22330       |\n",
      "|    policy_gradient_loss | 0.00174     |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 4.39e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -1.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 473       |\n",
      "|    iterations      | 643       |\n",
      "|    time_elapsed    | 2780      |\n",
      "|    total_timesteps | 1316864   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.63e+03  |\n",
      "|    ep_rew_mean          | -1.53e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 474       |\n",
      "|    iterations           | 644       |\n",
      "|    time_elapsed         | 2782      |\n",
      "|    total_timesteps      | 1318912   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0181436 |\n",
      "|    clip_fraction        | 0.192     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.76      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 65.1      |\n",
      "|    n_updates            | 22340     |\n",
      "|    policy_gradient_loss | -0.00158  |\n",
      "|    std                  | 0.194     |\n",
      "|    value_loss           | 542       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1320000, episode_reward=-21382.61 +/- 50540.45\n",
      "Episode length: 1889.20 +/- 903.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.89e+03    |\n",
      "|    mean_reward          | -2.14e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017754719 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.07e+05    |\n",
      "|    n_updates            | 22350       |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 3.33e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -1.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 473       |\n",
      "|    iterations      | 645       |\n",
      "|    time_elapsed    | 2788      |\n",
      "|    total_timesteps | 1320960   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -1.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 474         |\n",
      "|    iterations           | 646         |\n",
      "|    time_elapsed         | 2790        |\n",
      "|    total_timesteps      | 1323008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009194486 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 147         |\n",
      "|    n_updates            | 22360       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 1.03e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1325000, episode_reward=3475.82 +/- 3938.58\n",
      "Episode length: 1906.80 +/- 9.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.91e+03     |\n",
      "|    mean_reward          | 3.48e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1325000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077039865 |\n",
      "|    clip_fraction        | 0.0752       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 238          |\n",
      "|    n_updates            | 22370        |\n",
      "|    policy_gradient_loss | -0.00102     |\n",
      "|    std                  | 0.194        |\n",
      "|    value_loss           | 1.19e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.62e+03  |\n",
      "|    ep_rew_mean     | -1.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 473       |\n",
      "|    iterations      | 647       |\n",
      "|    time_elapsed    | 2796      |\n",
      "|    total_timesteps | 1325056   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -1.42e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 474         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 2798        |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008239503 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 184         |\n",
      "|    n_updates            | 22380       |\n",
      "|    policy_gradient_loss | -0.00304    |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 1.48e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | -1.46e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 474          |\n",
      "|    iterations           | 649          |\n",
      "|    time_elapsed         | 2800         |\n",
      "|    total_timesteps      | 1329152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0114247715 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.76         |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.41e+04     |\n",
      "|    n_updates            | 22390        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    std                  | 0.194        |\n",
      "|    value_loss           | 4e+04        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=6949.14 +/- 3391.54\n",
      "Episode length: 1828.60 +/- 7.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.83e+03    |\n",
      "|    mean_reward          | 6.95e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013844846 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80.9        |\n",
      "|    n_updates            | 22400       |\n",
      "|    policy_gradient_loss | 0.00428     |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.62e+03 |\n",
      "|    ep_rew_mean     | -1.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 474      |\n",
      "|    iterations      | 650      |\n",
      "|    time_elapsed    | 2806     |\n",
      "|    total_timesteps | 1331200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -1.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 474         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 2808        |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012694683 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.75        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.3        |\n",
      "|    n_updates            | 22410       |\n",
      "|    policy_gradient_loss | 0.00244     |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1335000, episode_reward=7754.26 +/- 4213.83\n",
      "Episode length: 2017.00 +/- 4.24\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.02e+03   |\n",
      "|    mean_reward          | 7.75e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1335000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01455948 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.75       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 94.4       |\n",
      "|    n_updates            | 22420      |\n",
      "|    policy_gradient_loss | 0.00287    |\n",
      "|    std                  | 0.194      |\n",
      "|    value_loss           | 221        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.62e+03  |\n",
      "|    ep_rew_mean     | -1.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 474       |\n",
      "|    iterations      | 652       |\n",
      "|    time_elapsed    | 2815      |\n",
      "|    total_timesteps | 1335296   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -1.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 474         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 2816        |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013907659 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 22430       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    std                  | 0.194       |\n",
      "|    value_loss           | 3.29e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 2818        |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025668617 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.76        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.9        |\n",
      "|    n_updates            | 22440       |\n",
      "|    policy_gradient_loss | 0.00212     |\n",
      "|    std                  | 0.193       |\n",
      "|    value_loss           | 1.89e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1340000, episode_reward=8582.04 +/- 4539.09\n",
      "Episode length: 1998.20 +/- 7.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2e+03        |\n",
      "|    mean_reward          | 8.58e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1340000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022546109 |\n",
      "|    clip_fraction        | 0.0168       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.305        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.13e+07     |\n",
      "|    n_updates            | 22450        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    std                  | 0.193        |\n",
      "|    value_loss           | 2.37e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.63e+03 |\n",
      "|    ep_rew_mean     | -1.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 474      |\n",
      "|    iterations      | 655      |\n",
      "|    time_elapsed    | 2825     |\n",
      "|    total_timesteps | 1341440  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | -1.21e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 475          |\n",
      "|    iterations           | 656          |\n",
      "|    time_elapsed         | 2827         |\n",
      "|    total_timesteps      | 1343488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071917223 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.74e+03     |\n",
      "|    n_updates            | 22460        |\n",
      "|    policy_gradient_loss | -0.00462     |\n",
      "|    std                  | 0.193        |\n",
      "|    value_loss           | 4.66e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1345000, episode_reward=12670.84 +/- 124.02\n",
      "Episode length: 1686.60 +/- 4.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.69e+03     |\n",
      "|    mean_reward          | 1.27e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1345000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086690765 |\n",
      "|    clip_fraction        | 0.0969       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.77         |\n",
      "|    explained_variance   | 0.983        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 672          |\n",
      "|    n_updates            | 22470        |\n",
      "|    policy_gradient_loss | 0.000491     |\n",
      "|    std                  | 0.193        |\n",
      "|    value_loss           | 1.93e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.62e+03  |\n",
      "|    ep_rew_mean     | -1.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 474       |\n",
      "|    iterations      | 657       |\n",
      "|    time_elapsed    | 2833      |\n",
      "|    total_timesteps | 1345536   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -1.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 2834        |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010327816 |\n",
      "|    clip_fraction        | 0.0954      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 281         |\n",
      "|    n_updates            | 22480       |\n",
      "|    policy_gradient_loss | -0.00497    |\n",
      "|    std                  | 0.193       |\n",
      "|    value_loss           | 2.06e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -1.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 2836        |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016013738 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.77        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54.6        |\n",
      "|    n_updates            | 22490       |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    std                  | 0.193       |\n",
      "|    value_loss           | 359         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=10507.02 +/- 4984.44\n",
      "Episode length: 1499.60 +/- 20.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.5e+03     |\n",
      "|    mean_reward          | 1.05e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017210256 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.78        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.6        |\n",
      "|    n_updates            | 22500       |\n",
      "|    policy_gradient_loss | -0.00267    |\n",
      "|    std                  | 0.192       |\n",
      "|    value_loss           | 2.29e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -9.36e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 475       |\n",
      "|    iterations      | 660       |\n",
      "|    time_elapsed    | 2842      |\n",
      "|    total_timesteps | 1351680   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -8.57e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 2844        |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027936384 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.8         |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.4        |\n",
      "|    n_updates            | 22510       |\n",
      "|    policy_gradient_loss | 0.00674     |\n",
      "|    std                  | 0.19        |\n",
      "|    value_loss           | 242         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1355000, episode_reward=11139.30 +/- 3265.92\n",
      "Episode length: 1391.00 +/- 11.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.39e+03    |\n",
      "|    mean_reward          | 1.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1355000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016388418 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.81        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 22520       |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    std                  | 0.19        |\n",
      "|    value_loss           | 1.88e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.66e+03  |\n",
      "|    ep_rew_mean     | -7.49e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 475       |\n",
      "|    iterations      | 662       |\n",
      "|    time_elapsed    | 2849      |\n",
      "|    total_timesteps | 1355776   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | -7.77e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 663          |\n",
      "|    time_elapsed         | 2851         |\n",
      "|    total_timesteps      | 1357824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134736635 |\n",
      "|    clip_fraction        | 0.178        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.82         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 56.4         |\n",
      "|    n_updates            | 22530        |\n",
      "|    policy_gradient_loss | 0.00538      |\n",
      "|    std                  | 0.189        |\n",
      "|    value_loss           | 168          |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.65e+03   |\n",
      "|    ep_rew_mean          | -6.77e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 476        |\n",
      "|    iterations           | 664        |\n",
      "|    time_elapsed         | 2852       |\n",
      "|    total_timesteps      | 1359872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02738412 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.83       |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 47.4       |\n",
      "|    n_updates            | 22540      |\n",
      "|    policy_gradient_loss | 0.00522    |\n",
      "|    std                  | 0.189      |\n",
      "|    value_loss           | 1.82e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1360000, episode_reward=11900.28 +/- 2409.18\n",
      "Episode length: 1273.20 +/- 10.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.27e+03    |\n",
      "|    mean_reward          | 1.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028322006 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.85        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.7        |\n",
      "|    n_updates            | 22550       |\n",
      "|    policy_gradient_loss | 0.00339     |\n",
      "|    std                  | 0.189       |\n",
      "|    value_loss           | 2.29e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -5.89e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 665       |\n",
      "|    time_elapsed    | 2857      |\n",
      "|    total_timesteps | 1361920   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -6.27e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 2859        |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013428725 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.85        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.18e+05    |\n",
      "|    n_updates            | 22560       |\n",
      "|    policy_gradient_loss | 0.00635     |\n",
      "|    std                  | 0.188       |\n",
      "|    value_loss           | 3.73e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1365000, episode_reward=8188.02 +/- 3564.92\n",
      "Episode length: 1238.20 +/- 17.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.24e+03    |\n",
      "|    mean_reward          | 8.19e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1365000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021589179 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.86        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 22570       |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    std                  | 0.188       |\n",
      "|    value_loss           | 1.92e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -5.17e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 667       |\n",
      "|    time_elapsed    | 2864      |\n",
      "|    total_timesteps | 1366016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -4.13e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 668         |\n",
      "|    time_elapsed         | 2866        |\n",
      "|    total_timesteps      | 1368064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020729573 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.86        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 22580       |\n",
      "|    policy_gradient_loss | -0.000555   |\n",
      "|    std                  | 0.188       |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1370000, episode_reward=12487.47 +/- 4092.55\n",
      "Episode length: 1270.20 +/- 22.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.27e+03    |\n",
      "|    mean_reward          | 1.25e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010746557 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.86        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47          |\n",
      "|    n_updates            | 22590       |\n",
      "|    policy_gradient_loss | 0.00547     |\n",
      "|    std                  | 0.188       |\n",
      "|    value_loss           | 3.8e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -2.71e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 477       |\n",
      "|    iterations      | 669       |\n",
      "|    time_elapsed    | 2871      |\n",
      "|    total_timesteps | 1370112   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.63e+03   |\n",
      "|    ep_rew_mean          | -2.85e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 477        |\n",
      "|    iterations           | 670        |\n",
      "|    time_elapsed         | 2873       |\n",
      "|    total_timesteps      | 1372160    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02073006 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.85       |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 34         |\n",
      "|    n_updates            | 22600      |\n",
      "|    policy_gradient_loss | 0.0103     |\n",
      "|    std                  | 0.189      |\n",
      "|    value_loss           | 1.36e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -1e+03      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 2874        |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020486545 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.85        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.5        |\n",
      "|    n_updates            | 22610       |\n",
      "|    policy_gradient_loss | 0.00708     |\n",
      "|    std                  | 0.188       |\n",
      "|    value_loss           | 65.4        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1375000, episode_reward=17739.61 +/- 2411.67\n",
      "Episode length: 1494.80 +/- 6.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.49e+03    |\n",
      "|    mean_reward          | 1.77e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1375000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013373531 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.86        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78.2        |\n",
      "|    n_updates            | 22620       |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    std                  | 0.188       |\n",
      "|    value_loss           | 1.88e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.67e+03 |\n",
      "|    ep_rew_mean     | -139     |\n",
      "| time/              |          |\n",
      "|    fps             | 477      |\n",
      "|    iterations      | 672      |\n",
      "|    time_elapsed    | 2880     |\n",
      "|    total_timesteps | 1376256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -1.45e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 2882        |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013038729 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.87        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 22630       |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    std                  | 0.187       |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1380000, episode_reward=15259.12 +/- 3634.34\n",
      "Episode length: 1742.80 +/- 18.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.74e+03    |\n",
      "|    mean_reward          | 1.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008264499 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.88        |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.85e+06    |\n",
      "|    n_updates            | 22640       |\n",
      "|    policy_gradient_loss | 0.0078      |\n",
      "|    std                  | 0.187       |\n",
      "|    value_loss           | 1.15e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -1.46e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 477       |\n",
      "|    iterations      | 674       |\n",
      "|    time_elapsed    | 2888      |\n",
      "|    total_timesteps | 1380352   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.63e+03     |\n",
      "|    ep_rew_mean          | -1.61e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 478          |\n",
      "|    iterations           | 675          |\n",
      "|    time_elapsed         | 2890         |\n",
      "|    total_timesteps      | 1382400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0115982015 |\n",
      "|    clip_fraction        | 0.158        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.88         |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 167          |\n",
      "|    n_updates            | 22650        |\n",
      "|    policy_gradient_loss | -0.0051      |\n",
      "|    std                  | 0.186        |\n",
      "|    value_loss           | 3.38e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.65e+03   |\n",
      "|    ep_rew_mean          | -510       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 478        |\n",
      "|    iterations           | 676        |\n",
      "|    time_elapsed         | 2891       |\n",
      "|    total_timesteps      | 1384448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00743638 |\n",
      "|    clip_fraction        | 0.0948     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.88       |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 88.5       |\n",
      "|    n_updates            | 22660      |\n",
      "|    policy_gradient_loss | -0.00168   |\n",
      "|    std                  | 0.186      |\n",
      "|    value_loss           | 2.4e+04    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1385000, episode_reward=16916.25 +/- 4374.62\n",
      "Episode length: 2203.80 +/- 14.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.2e+03     |\n",
      "|    mean_reward          | 1.69e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1385000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020844787 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.88        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.2        |\n",
      "|    n_updates            | 22670       |\n",
      "|    policy_gradient_loss | -0.000568   |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 509         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.67e+03 |\n",
      "|    ep_rew_mean     | 680      |\n",
      "| time/              |          |\n",
      "|    fps             | 478      |\n",
      "|    iterations      | 677      |\n",
      "|    time_elapsed    | 2899     |\n",
      "|    total_timesteps | 1386496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | 781         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 2900        |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019651528 |\n",
      "|    clip_fraction        | 0.0964      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.88        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 22680       |\n",
      "|    policy_gradient_loss | 0.00168     |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=-62868.19 +/- 104358.79\n",
      "Episode length: 2415.60 +/- 1246.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.42e+03    |\n",
      "|    mean_reward          | -6.29e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029447261 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.88        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 22690       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.68e+03 |\n",
      "|    ep_rew_mean     | 2.06e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 478      |\n",
      "|    iterations      | 679      |\n",
      "|    time_elapsed    | 2908     |\n",
      "|    total_timesteps | 1390592  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.68e+03  |\n",
      "|    ep_rew_mean          | 2.06e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 478       |\n",
      "|    iterations           | 680       |\n",
      "|    time_elapsed         | 2910      |\n",
      "|    total_timesteps      | 1392640   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.2872117 |\n",
      "|    clip_fraction        | 0.369     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.88      |\n",
      "|    explained_variance   | 0.999     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 21.6      |\n",
      "|    n_updates            | 22700     |\n",
      "|    policy_gradient_loss | 0.0257    |\n",
      "|    std                  | 0.187     |\n",
      "|    value_loss           | 80        |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | 2.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 2912        |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014022969 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.88        |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 22710       |\n",
      "|    policy_gradient_loss | 0.0021      |\n",
      "|    std                  | 0.187       |\n",
      "|    value_loss           | 407         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1395000, episode_reward=26483.13 +/- 2876.83\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 2.65e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1395000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017584644 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.88        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.9        |\n",
      "|    n_updates            | 22720       |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    std                  | 0.187       |\n",
      "|    value_loss           | 476         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.7e+03  |\n",
      "|    ep_rew_mean     | 2.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 477      |\n",
      "|    iterations      | 682      |\n",
      "|    time_elapsed    | 2925     |\n",
      "|    total_timesteps | 1396736  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | 2.49e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 2927        |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015011787 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.88        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 160         |\n",
      "|    n_updates            | 22730       |\n",
      "|    policy_gradient_loss | -0.000797   |\n",
      "|    std                  | 0.187       |\n",
      "|    value_loss           | 593         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1400000, episode_reward=27987.75 +/- 9809.47\n",
      "Episode length: 3313.80 +/- 1294.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.31e+03    |\n",
      "|    mean_reward          | 2.8e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019469798 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.88        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.8        |\n",
      "|    n_updates            | 22740       |\n",
      "|    policy_gradient_loss | 0.00497     |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 506         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.74e+03 |\n",
      "|    ep_rew_mean     | 2.58e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 476      |\n",
      "|    iterations      | 684      |\n",
      "|    time_elapsed    | 2937     |\n",
      "|    total_timesteps | 1400832  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | 2.58e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 685         |\n",
      "|    time_elapsed         | 2939        |\n",
      "|    total_timesteps      | 1402880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008548923 |\n",
      "|    clip_fraction        | 0.0887      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.89        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 195         |\n",
      "|    n_updates            | 22750       |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 1.99e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | 1.47e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 2940        |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009996915 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.89        |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.2        |\n",
      "|    n_updates            | 22760       |\n",
      "|    policy_gradient_loss | 0.00795     |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 226         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1405000, episode_reward=3196.26 +/- 55131.69\n",
      "Episode length: 2852.20 +/- 1388.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.85e+03    |\n",
      "|    mean_reward          | 3.2e+03     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1405000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005657812 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.89        |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+07    |\n",
      "|    n_updates            | 22770       |\n",
      "|    policy_gradient_loss | 0.00347     |\n",
      "|    std                  | 0.187       |\n",
      "|    value_loss           | 1.62e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.7e+03  |\n",
      "|    ep_rew_mean     | 1.47e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 477      |\n",
      "|    iterations      | 687      |\n",
      "|    time_elapsed    | 2949     |\n",
      "|    total_timesteps | 1406976  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | 1.06e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 2951        |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019308109 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.9         |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.9        |\n",
      "|    n_updates            | 22780       |\n",
      "|    policy_gradient_loss | 0.00663     |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 138         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1410000, episode_reward=27005.03 +/- 5406.78\n",
      "Episode length: 3924.40 +/- 17.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.92e+03    |\n",
      "|    mean_reward          | 2.7e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024805494 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.55e+03    |\n",
      "|    n_updates            | 22790       |\n",
      "|    policy_gradient_loss | -0.00164    |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 1.52e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.71e+03 |\n",
      "|    ep_rew_mean     | 1.89e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 476      |\n",
      "|    iterations      | 689      |\n",
      "|    time_elapsed    | 2962     |\n",
      "|    total_timesteps | 1411072  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.73e+03     |\n",
      "|    ep_rew_mean          | 3.16e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 690          |\n",
      "|    time_elapsed         | 2964         |\n",
      "|    total_timesteps      | 1413120      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036910903 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.92         |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.22e+03     |\n",
      "|    n_updates            | 22800        |\n",
      "|    policy_gradient_loss | -0.00425     |\n",
      "|    std                  | 0.186        |\n",
      "|    value_loss           | 2.08e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1415000, episode_reward=26958.15 +/- 4343.39\n",
      "Episode length: 3821.00 +/- 9.34\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.82e+03   |\n",
      "|    mean_reward          | 2.7e+04    |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1415000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00498793 |\n",
      "|    clip_fraction        | 0.0518     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.92       |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.4e+03    |\n",
      "|    n_updates            | 22810      |\n",
      "|    policy_gradient_loss | -0.00708   |\n",
      "|    std                  | 0.186      |\n",
      "|    value_loss           | 4.7e+04    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.73e+03 |\n",
      "|    ep_rew_mean     | 3.16e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 475      |\n",
      "|    iterations      | 691      |\n",
      "|    time_elapsed    | 2975     |\n",
      "|    total_timesteps | 1415168  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | 3.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 2977        |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008108578 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 479         |\n",
      "|    n_updates            | 22820       |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 3.96e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | 3.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 2978        |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008333432 |\n",
      "|    clip_fraction        | 0.0552      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 148         |\n",
      "|    n_updates            | 22830       |\n",
      "|    policy_gradient_loss | -0.000814   |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 2.19e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=20902.71 +/- 6955.05\n",
      "Episode length: 2615.00 +/- 975.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.62e+03    |\n",
      "|    mean_reward          | 2.09e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008467633 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 369         |\n",
      "|    n_updates            | 22840       |\n",
      "|    policy_gradient_loss | -0.00181    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 4.02e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.77e+03 |\n",
      "|    ep_rew_mean     | 4.39e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 475      |\n",
      "|    iterations      | 694      |\n",
      "|    time_elapsed    | 2986     |\n",
      "|    total_timesteps | 1421312  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | 4.88e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 2988        |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009343489 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 22850       |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 1.49e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1425000, episode_reward=-19232.58 +/- 49974.88\n",
      "Episode length: 1568.60 +/- 1281.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.57e+03    |\n",
      "|    mean_reward          | -1.92e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1425000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006916174 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.53e+07    |\n",
      "|    n_updates            | 22860       |\n",
      "|    policy_gradient_loss | 0.000519    |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 1.6e+07     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.73e+03 |\n",
      "|    ep_rew_mean     | 4.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 476      |\n",
      "|    iterations      | 696      |\n",
      "|    time_elapsed    | 2994     |\n",
      "|    total_timesteps | 1425408  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.74e+03     |\n",
      "|    ep_rew_mean          | 4.38e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 697          |\n",
      "|    time_elapsed         | 2996         |\n",
      "|    total_timesteps      | 1427456      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045252927 |\n",
      "|    clip_fraction        | 0.0449       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.92         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+06     |\n",
      "|    n_updates            | 22870        |\n",
      "|    policy_gradient_loss | 0.00239      |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 1.53e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | 4.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 2998        |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021886095 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.49e+03    |\n",
      "|    n_updates            | 22880       |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.33e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1430000, episode_reward=11610.68 +/- 34335.63\n",
      "Episode length: 3075.00 +/- 1094.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.08e+03    |\n",
      "|    mean_reward          | 1.16e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030815627 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 22890       |\n",
      "|    policy_gradient_loss | -0.000961   |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.53e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.73e+03 |\n",
      "|    ep_rew_mean     | 4.27e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 476      |\n",
      "|    iterations      | 699      |\n",
      "|    time_elapsed    | 3007     |\n",
      "|    total_timesteps | 1431552  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | 4.3e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 3009        |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015856666 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 355         |\n",
      "|    n_updates            | 22900       |\n",
      "|    policy_gradient_loss | 0.00431     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 5.67e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1435000, episode_reward=-3803.23 +/- 50993.34\n",
      "Episode length: 2727.80 +/- 1331.01\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.73e+03   |\n",
      "|    mean_reward          | -3.8e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1435000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19751373 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.93       |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.98e+06   |\n",
      "|    n_updates            | 22910      |\n",
      "|    policy_gradient_loss | 0.00765    |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 1.41e+07   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.73e+03 |\n",
      "|    ep_rew_mean     | 4.24e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 475      |\n",
      "|    iterations      | 701      |\n",
      "|    time_elapsed    | 3017     |\n",
      "|    total_timesteps | 1435648  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | 4.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 3019        |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023322262 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 87          |\n",
      "|    n_updates            | 22920       |\n",
      "|    policy_gradient_loss | 0.0102      |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 545         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | 4.17e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 3021        |\n",
      "|    total_timesteps      | 1439744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020971127 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.58e+05    |\n",
      "|    n_updates            | 22930       |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 5.41e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=9779.41 +/- 15076.02\n",
      "Episode length: 3627.40 +/- 13.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.63e+03    |\n",
      "|    mean_reward          | 9.78e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018560935 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.1        |\n",
      "|    n_updates            | 22940       |\n",
      "|    policy_gradient_loss | 0.00198     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 443         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.74e+03 |\n",
      "|    ep_rew_mean     | 4.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 475      |\n",
      "|    iterations      | 704      |\n",
      "|    time_elapsed    | 3031     |\n",
      "|    total_timesteps | 1441792  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | 4.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 3033        |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011014711 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71          |\n",
      "|    n_updates            | 22950       |\n",
      "|    policy_gradient_loss | 0.000379    |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 1.74e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1445000, episode_reward=-5081.99 +/- 50283.64\n",
      "Episode length: 2415.60 +/- 1174.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.42e+03     |\n",
      "|    mean_reward          | -5.08e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1445000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0129219275 |\n",
      "|    clip_fraction        | 0.21         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.93         |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 61.3         |\n",
      "|    n_updates            | 22960        |\n",
      "|    policy_gradient_loss | 0.00363      |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 204          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.72e+03 |\n",
      "|    ep_rew_mean     | 2.67e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 475      |\n",
      "|    iterations      | 706      |\n",
      "|    time_elapsed    | 3040     |\n",
      "|    total_timesteps | 1445888  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | 293          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 475          |\n",
      "|    iterations           | 707          |\n",
      "|    time_elapsed         | 3042         |\n",
      "|    total_timesteps      | 1447936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024246364 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.93         |\n",
      "|    explained_variance   | 0.339        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.08e+07     |\n",
      "|    n_updates            | 22970        |\n",
      "|    policy_gradient_loss | -0.00567     |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 2.54e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.68e+03     |\n",
      "|    ep_rew_mean          | -764         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 708          |\n",
      "|    time_elapsed         | 3044         |\n",
      "|    total_timesteps      | 1449984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033317776 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.93         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07e+07     |\n",
      "|    n_updates            | 22980        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 3.56e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1450000, episode_reward=-56656.14 +/- 56530.43\n",
      "Episode length: 1221.20 +/- 853.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.22e+03    |\n",
      "|    mean_reward          | -5.67e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005284461 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.69e+04    |\n",
      "|    n_updates            | 22990       |\n",
      "|    policy_gradient_loss | -0.00907    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.68e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.67e+03  |\n",
      "|    ep_rew_mean     | -1.71e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 709       |\n",
      "|    time_elapsed    | 3049      |\n",
      "|    total_timesteps | 1452032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -3.64e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 3051        |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001640127 |\n",
      "|    clip_fraction        | 0.00674     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.337       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.26e+06    |\n",
      "|    n_updates            | 23000       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 2.13e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1455000, episode_reward=-9719.66 +/- 50232.85\n",
      "Episode length: 1891.20 +/- 1266.59\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.89e+03     |\n",
      "|    mean_reward          | -9.72e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1455000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021685185 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.93         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.93e+07     |\n",
      "|    n_updates            | 23010        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 3.62e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -8.64e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 711       |\n",
      "|    time_elapsed    | 3057      |\n",
      "|    total_timesteps | 1456128   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -8.57e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 712          |\n",
      "|    time_elapsed         | 3059         |\n",
      "|    total_timesteps      | 1458176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022342042 |\n",
      "|    clip_fraction        | 0.0154       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.93         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.88e+07     |\n",
      "|    n_updates            | 23020        |\n",
      "|    policy_gradient_loss | -0.00452     |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 6.36e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=-23024.16 +/- 53317.44\n",
      "Episode length: 1922.40 +/- 1218.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.92e+03     |\n",
      "|    mean_reward          | -2.3e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1460000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063741617 |\n",
      "|    clip_fraction        | 0.0497       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.93         |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+04      |\n",
      "|    n_updates            | 23030        |\n",
      "|    policy_gradient_loss | -0.00686     |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 1.36e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -8.57e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 713       |\n",
      "|    time_elapsed    | 3065      |\n",
      "|    total_timesteps | 1460224   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -1.15e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 714          |\n",
      "|    time_elapsed         | 3067         |\n",
      "|    total_timesteps      | 1462272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051299045 |\n",
      "|    clip_fraction        | 0.0538       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.93         |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.48e+03     |\n",
      "|    n_updates            | 23040        |\n",
      "|    policy_gradient_loss | -0.0054      |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 3.62e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -1.13e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 477          |\n",
      "|    iterations           | 715          |\n",
      "|    time_elapsed         | 3069         |\n",
      "|    total_timesteps      | 1464320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043072556 |\n",
      "|    clip_fraction        | 0.0311       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.93         |\n",
      "|    explained_variance   | 0.253        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.42e+06     |\n",
      "|    n_updates            | 23050        |\n",
      "|    policy_gradient_loss | -0.0056      |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 5.97e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1465000, episode_reward=-2485.06 +/- 49942.40\n",
      "Episode length: 2576.20 +/- 1256.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.58e+03     |\n",
      "|    mean_reward          | -2.49e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1465000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076719103 |\n",
      "|    clip_fraction        | 0.0589       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.93         |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 23060        |\n",
      "|    policy_gradient_loss | -0.00454     |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 4.5e+04      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -1.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 716       |\n",
      "|    time_elapsed    | 3077      |\n",
      "|    total_timesteps | 1466368   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.46e+03   |\n",
      "|    ep_rew_mean          | -1.21e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 476        |\n",
      "|    iterations           | 717        |\n",
      "|    time_elapsed         | 3079       |\n",
      "|    total_timesteps      | 1468416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16363084 |\n",
      "|    clip_fraction        | 0.187      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.93       |\n",
      "|    explained_variance   | 0.348      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.38e+07   |\n",
      "|    n_updates            | 23070      |\n",
      "|    policy_gradient_loss | -0.00377   |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 1.49e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=23895.89 +/- 2783.07\n",
      "Episode length: 3375.60 +/- 14.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.38e+03    |\n",
      "|    mean_reward          | 2.39e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007814687 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 699         |\n",
      "|    n_updates            | 23080       |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 5.95e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.47e+03 |\n",
      "|    ep_rew_mean     | -1.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 475      |\n",
      "|    iterations      | 718      |\n",
      "|    time_elapsed    | 3089     |\n",
      "|    total_timesteps | 1470464  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | -1.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 719          |\n",
      "|    time_elapsed         | 3091         |\n",
      "|    total_timesteps      | 1472512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049609523 |\n",
      "|    clip_fraction        | 0.0539       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.93         |\n",
      "|    explained_variance   | 0.868        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.1e+03      |\n",
      "|    n_updates            | 23090        |\n",
      "|    policy_gradient_loss | -0.00405     |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 7.88e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -1.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 720         |\n",
      "|    time_elapsed         | 3093        |\n",
      "|    total_timesteps      | 1474560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014380291 |\n",
      "|    clip_fraction        | 0.0891      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 421         |\n",
      "|    n_updates            | 23100       |\n",
      "|    policy_gradient_loss | -0.00125    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 2.24e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1475000, episode_reward=23090.03 +/- 3327.72\n",
      "Episode length: 3375.00 +/- 12.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.38e+03   |\n",
      "|    mean_reward          | 2.31e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1475000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00892071 |\n",
      "|    clip_fraction        | 0.188      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.93       |\n",
      "|    explained_variance   | 0.291      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.86e+07   |\n",
      "|    n_updates            | 23110      |\n",
      "|    policy_gradient_loss | 0.00179    |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 2.02e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -1.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 475       |\n",
      "|    iterations      | 721       |\n",
      "|    time_elapsed    | 3103      |\n",
      "|    total_timesteps | 1476608   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | -1.28e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 476          |\n",
      "|    iterations           | 722          |\n",
      "|    time_elapsed         | 3104         |\n",
      "|    total_timesteps      | 1478656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0133731365 |\n",
      "|    clip_fraction        | 0.208        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.94         |\n",
      "|    explained_variance   | 0.898        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 536          |\n",
      "|    n_updates            | 23120        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 3.18e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1480000, episode_reward=18928.81 +/- 2898.73\n",
      "Episode length: 3416.20 +/- 13.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.42e+03    |\n",
      "|    mean_reward          | 1.89e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007843788 |\n",
      "|    clip_fraction        | 0.0926      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 299         |\n",
      "|    n_updates            | 23130       |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 2.25e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -1.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 475       |\n",
      "|    iterations      | 723       |\n",
      "|    time_elapsed    | 3114      |\n",
      "|    total_timesteps | 1480704   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | -1.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 3116        |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011044761 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 300         |\n",
      "|    n_updates            | 23140       |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 978         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -1.43e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 3118        |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013089428 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 225         |\n",
      "|    n_updates            | 23150       |\n",
      "|    policy_gradient_loss | -0.00469    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.9e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1485000, episode_reward=18935.91 +/- 682.40\n",
      "Episode length: 3653.80 +/- 10.11\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.65e+03   |\n",
      "|    mean_reward          | 1.89e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1485000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01568132 |\n",
      "|    clip_fraction        | 0.0948     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.93       |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.29e+06   |\n",
      "|    n_updates            | 23160      |\n",
      "|    policy_gradient_loss | 0.000815   |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 2.41e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -1.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 475       |\n",
      "|    iterations      | 726       |\n",
      "|    time_elapsed    | 3129      |\n",
      "|    total_timesteps | 1486848   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | -1.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 3131        |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024585122 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 775         |\n",
      "|    n_updates            | 23170       |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=20127.91 +/- 3360.16\n",
      "Episode length: 1945.60 +/- 17.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.95e+03    |\n",
      "|    mean_reward          | 2.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041964453 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.1        |\n",
      "|    n_updates            | 23180       |\n",
      "|    policy_gradient_loss | 0.00454     |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 674         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -1.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 475       |\n",
      "|    iterations      | 728       |\n",
      "|    time_elapsed    | 3137      |\n",
      "|    total_timesteps | 1490944   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.5e+03    |\n",
      "|    ep_rew_mean          | -1.3e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 475        |\n",
      "|    iterations           | 729        |\n",
      "|    time_elapsed         | 3139       |\n",
      "|    total_timesteps      | 1492992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11169763 |\n",
      "|    clip_fraction        | 0.281      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.93       |\n",
      "|    explained_variance   | 0.51       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.56e+05   |\n",
      "|    n_updates            | 23190      |\n",
      "|    policy_gradient_loss | 0.017      |\n",
      "|    std                  | 0.186      |\n",
      "|    value_loss           | 4.82e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1495000, episode_reward=-10161.57 +/- 51406.82\n",
      "Episode length: 1591.20 +/- 759.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.59e+03    |\n",
      "|    mean_reward          | -1.02e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1495000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026826117 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 23200       |\n",
      "|    policy_gradient_loss | 0.00149     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 2.35e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.51e+03 |\n",
      "|    ep_rew_mean     | -1.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 475      |\n",
      "|    iterations      | 730      |\n",
      "|    time_elapsed    | 3144     |\n",
      "|    total_timesteps | 1495040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | -1.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 475         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 3146        |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013713142 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 119         |\n",
      "|    n_updates            | 23210       |\n",
      "|    policy_gradient_loss | 0.00479     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 435         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -1.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 3148        |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008509674 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 23220       |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 491         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1500000, episode_reward=-5119.12 +/- 51530.86\n",
      "Episode length: 1670.60 +/- 802.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.67e+03    |\n",
      "|    mean_reward          | -5.12e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034586966 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96          |\n",
      "|    n_updates            | 23230       |\n",
      "|    policy_gradient_loss | 0.00808     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 310         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -1.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 475       |\n",
      "|    iterations      | 733       |\n",
      "|    time_elapsed    | 3154      |\n",
      "|    total_timesteps | 1501184   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.51e+03    |\n",
      "|    ep_rew_mean          | -1.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 3156        |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010274514 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 166         |\n",
      "|    n_updates            | 23240       |\n",
      "|    policy_gradient_loss | -0.00209    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 2.03e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1505000, episode_reward=16544.74 +/- 4739.59\n",
      "Episode length: 2031.20 +/- 14.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.03e+03    |\n",
      "|    mean_reward          | 1.65e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1505000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034707207 |\n",
      "|    clip_fraction        | 0.0941      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.65e+06    |\n",
      "|    n_updates            | 23250       |\n",
      "|    policy_gradient_loss | 4.43e-05    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.7e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -1.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 475       |\n",
      "|    iterations      | 735       |\n",
      "|    time_elapsed    | 3162      |\n",
      "|    total_timesteps | 1505280   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.52e+03   |\n",
      "|    ep_rew_mean          | -1.37e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 476        |\n",
      "|    iterations           | 736        |\n",
      "|    time_elapsed         | 3164       |\n",
      "|    total_timesteps      | 1507328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07124545 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.94       |\n",
      "|    explained_variance   | 0.744      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 121        |\n",
      "|    n_updates            | 23260      |\n",
      "|    policy_gradient_loss | 0.0111     |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 4.74e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -1.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 737         |\n",
      "|    time_elapsed         | 3166        |\n",
      "|    total_timesteps      | 1509376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024830526 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 81.3        |\n",
      "|    n_updates            | 23270       |\n",
      "|    policy_gradient_loss | 0.00409     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 312         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=-8085.13 +/- 54274.86\n",
      "Episode length: 1574.20 +/- 751.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.57e+03    |\n",
      "|    mean_reward          | -8.09e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015259622 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 23280       |\n",
      "|    policy_gradient_loss | -0.00526    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 766         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -1.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 738       |\n",
      "|    time_elapsed    | 3172      |\n",
      "|    total_timesteps | 1511424   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -1.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 3173        |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014364557 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 250         |\n",
      "|    n_updates            | 23290       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 661         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1515000, episode_reward=-30005.70 +/- 2384.71\n",
      "Episode length: 2880.60 +/- 14.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.88e+03    |\n",
      "|    mean_reward          | -3e+04      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1515000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008922943 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 831         |\n",
      "|    n_updates            | 23300       |\n",
      "|    policy_gradient_loss | 0.00158     |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 627         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -1.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 740       |\n",
      "|    time_elapsed    | 3182      |\n",
      "|    total_timesteps | 1515520   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -1.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 741         |\n",
      "|    time_elapsed         | 3184        |\n",
      "|    total_timesteps      | 1517568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026909176 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.71e+07    |\n",
      "|    n_updates            | 23310       |\n",
      "|    policy_gradient_loss | 0.00342     |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 3.2e+07     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -1.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 476         |\n",
      "|    iterations           | 742         |\n",
      "|    time_elapsed         | 3186        |\n",
      "|    total_timesteps      | 1519616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014819143 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.824       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 220         |\n",
      "|    n_updates            | 23320       |\n",
      "|    policy_gradient_loss | 1.42e-05    |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 5.13e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=-77421.85 +/- 28512.34\n",
      "Episode length: 1811.00 +/- 1420.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.81e+03    |\n",
      "|    mean_reward          | -7.74e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021013964 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 114         |\n",
      "|    n_updates            | 23330       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 232         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.55e+03  |\n",
      "|    ep_rew_mean     | -1.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 743       |\n",
      "|    time_elapsed    | 3192      |\n",
      "|    total_timesteps | 1521664   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -2.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 744         |\n",
      "|    time_elapsed         | 3194        |\n",
      "|    total_timesteps      | 1523712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028082173 |\n",
      "|    clip_fraction        | 0.418       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.273       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.14e+07    |\n",
      "|    n_updates            | 23340       |\n",
      "|    policy_gradient_loss | 0.037       |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 4.45e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1525000, episode_reward=-14813.80 +/- 51084.48\n",
      "Episode length: 1684.60 +/- 805.91\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.68e+03      |\n",
      "|    mean_reward          | -1.48e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 1525000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00080624793 |\n",
      "|    clip_fraction        | 0.00342       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 2.94          |\n",
      "|    explained_variance   | 0.327         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.16e+07      |\n",
      "|    n_updates            | 23350         |\n",
      "|    policy_gradient_loss | -0.00242      |\n",
      "|    std                  | 0.184         |\n",
      "|    value_loss           | 5.87e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -2.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 745       |\n",
      "|    time_elapsed    | 3200      |\n",
      "|    total_timesteps | 1525760   |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.5e+03       |\n",
      "|    ep_rew_mean          | -2.75e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 477           |\n",
      "|    iterations           | 746           |\n",
      "|    time_elapsed         | 3202          |\n",
      "|    total_timesteps      | 1527808       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00035199412 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 2.94          |\n",
      "|    explained_variance   | 0.361         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.14e+07      |\n",
      "|    n_updates            | 23360         |\n",
      "|    policy_gradient_loss | -0.00143      |\n",
      "|    std                  | 0.184         |\n",
      "|    value_loss           | 2.95e+07      |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -2.78e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 477         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 3203        |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013056172 |\n",
      "|    clip_fraction        | 0.0484      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.35e+07    |\n",
      "|    n_updates            | 23370       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 6.12e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=-135941.44 +/- 24056.28\n",
      "Episode length: 1716.80 +/- 1341.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.72e+03    |\n",
      "|    mean_reward          | -1.36e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003914187 |\n",
      "|    clip_fraction        | 0.021       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.27e+06    |\n",
      "|    n_updates            | 23380       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 1.54e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -2.91e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 477       |\n",
      "|    iterations      | 748       |\n",
      "|    time_elapsed    | 3209      |\n",
      "|    total_timesteps | 1531904   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | -2.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 477          |\n",
      "|    iterations           | 749          |\n",
      "|    time_elapsed         | 3211         |\n",
      "|    total_timesteps      | 1533952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036476096 |\n",
      "|    clip_fraction        | 0.0206       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.94         |\n",
      "|    explained_variance   | 0.434        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.46e+06     |\n",
      "|    n_updates            | 23390        |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    std                  | 0.184        |\n",
      "|    value_loss           | 1.44e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1535000, episode_reward=2187.02 +/- 3275.69\n",
      "Episode length: 2875.20 +/- 10.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.88e+03     |\n",
      "|    mean_reward          | 2.19e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1535000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059924205 |\n",
      "|    clip_fraction        | 0.0376       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.94         |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 561          |\n",
      "|    n_updates            | 23400        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    std                  | 0.184        |\n",
      "|    value_loss           | 1.49e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -2.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 476       |\n",
      "|    iterations      | 750       |\n",
      "|    time_elapsed    | 3220      |\n",
      "|    total_timesteps | 1536000   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -2.92e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 477          |\n",
      "|    iterations           | 751          |\n",
      "|    time_elapsed         | 3222         |\n",
      "|    total_timesteps      | 1538048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066945776 |\n",
      "|    clip_fraction        | 0.0649       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.94         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16e+03     |\n",
      "|    n_updates            | 23410        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    std                  | 0.184        |\n",
      "|    value_loss           | 6.96e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=-62087.20 +/- 59871.32\n",
      "Episode length: 817.80 +/- 917.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 818          |\n",
      "|    mean_reward          | -6.21e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1540000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039051545 |\n",
      "|    clip_fraction        | 0.032        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.94         |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 608          |\n",
      "|    n_updates            | 23420        |\n",
      "|    policy_gradient_loss | -0.00296     |\n",
      "|    std                  | 0.184        |\n",
      "|    value_loss           | 5.27e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -2.93e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 477       |\n",
      "|    iterations      | 752       |\n",
      "|    time_elapsed    | 3226      |\n",
      "|    total_timesteps | 1540096   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | -3.09e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 477          |\n",
      "|    iterations           | 753          |\n",
      "|    time_elapsed         | 3227         |\n",
      "|    total_timesteps      | 1542144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071279313 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.94         |\n",
      "|    explained_variance   | 0.98         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.35e+03     |\n",
      "|    n_updates            | 23430        |\n",
      "|    policy_gradient_loss | -0.00272     |\n",
      "|    std                  | 0.184        |\n",
      "|    value_loss           | 2.68e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | -3.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 754         |\n",
      "|    time_elapsed         | 3229        |\n",
      "|    total_timesteps      | 1544192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014406607 |\n",
      "|    clip_fraction        | 0.0793      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.05e+05    |\n",
      "|    n_updates            | 23440       |\n",
      "|    policy_gradient_loss | -0.000312   |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 1.58e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1545000, episode_reward=15195.08 +/- 2499.26\n",
      "Episode length: 1847.40 +/- 15.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.85e+03    |\n",
      "|    mean_reward          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1545000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007877687 |\n",
      "|    clip_fraction        | 0.0772      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 331         |\n",
      "|    n_updates            | 23450       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 2.07e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.41e+03  |\n",
      "|    ep_rew_mean     | -3.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 477       |\n",
      "|    iterations      | 755       |\n",
      "|    time_elapsed    | 3236      |\n",
      "|    total_timesteps | 1546240   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -3.27e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 3237        |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013678256 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.94        |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.21e+06    |\n",
      "|    n_updates            | 23460       |\n",
      "|    policy_gradient_loss | 0.00402     |\n",
      "|    std                  | 0.184       |\n",
      "|    value_loss           | 1.65e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1550000, episode_reward=-9193.86 +/- 50228.15\n",
      "Episode length: 1493.00 +/- 712.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.49e+03    |\n",
      "|    mean_reward          | -9.19e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013769509 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.361       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13e+07    |\n",
      "|    n_updates            | 23470       |\n",
      "|    policy_gradient_loss | 0.00311     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.62e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 478       |\n",
      "|    iterations      | 757       |\n",
      "|    time_elapsed    | 3243      |\n",
      "|    total_timesteps | 1550336   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | -3.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 758         |\n",
      "|    time_elapsed         | 3245        |\n",
      "|    total_timesteps      | 1552384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009507828 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 171         |\n",
      "|    n_updates            | 23480       |\n",
      "|    policy_gradient_loss | -1.02e-05   |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.51e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.41e+03   |\n",
      "|    ep_rew_mean          | -3.3e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 478        |\n",
      "|    iterations           | 759        |\n",
      "|    time_elapsed         | 3247       |\n",
      "|    total_timesteps      | 1554432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.36089572 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.93       |\n",
      "|    explained_variance   | 0.396      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.49e+06   |\n",
      "|    n_updates            | 23490      |\n",
      "|    policy_gradient_loss | -0.00408   |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 1.6e+07    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1555000, episode_reward=14377.74 +/- 2065.33\n",
      "Episode length: 1768.80 +/- 11.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.77e+03    |\n",
      "|    mean_reward          | 1.44e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1555000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021107389 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.5        |\n",
      "|    n_updates            | 23500       |\n",
      "|    policy_gradient_loss | 0.00476     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 419         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.4e+03   |\n",
      "|    ep_rew_mean     | -3.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 478       |\n",
      "|    iterations      | 760       |\n",
      "|    time_elapsed    | 3253      |\n",
      "|    total_timesteps | 1556480   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | -3.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 3254        |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022019248 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 171         |\n",
      "|    n_updates            | 23510       |\n",
      "|    policy_gradient_loss | -0.00124    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.61e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1560000, episode_reward=13810.77 +/- 3909.83\n",
      "Episode length: 1676.80 +/- 24.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.68e+03    |\n",
      "|    mean_reward          | 1.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016583622 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 23520       |\n",
      "|    policy_gradient_loss | 0.00472     |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 340         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.38e+03 |\n",
      "|    ep_rew_mean     | -3.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 478      |\n",
      "|    iterations      | 762      |\n",
      "|    time_elapsed    | 3260     |\n",
      "|    total_timesteps | 1560576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 478         |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 3262        |\n",
      "|    total_timesteps      | 1562624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021258818 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64          |\n",
      "|    n_updates            | 23530       |\n",
      "|    policy_gradient_loss | 0.00521     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 233         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.39e+03   |\n",
      "|    ep_rew_mean          | -3.45e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 479        |\n",
      "|    iterations           | 764        |\n",
      "|    time_elapsed         | 3264       |\n",
      "|    total_timesteps      | 1564672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16778946 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.92       |\n",
      "|    explained_variance   | 0.36       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.93e+07   |\n",
      "|    n_updates            | 23540      |\n",
      "|    policy_gradient_loss | 0.00596    |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 3.47e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1565000, episode_reward=14484.45 +/- 3156.63\n",
      "Episode length: 1641.20 +/- 5.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.64e+03     |\n",
      "|    mean_reward          | 1.45e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1565000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035082693 |\n",
      "|    clip_fraction        | 0.0132       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.92         |\n",
      "|    explained_variance   | 0.323        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.39e+07     |\n",
      "|    n_updates            | 23550        |\n",
      "|    policy_gradient_loss | -0.00649     |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 2.33e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.37e+03  |\n",
      "|    ep_rew_mean     | -3.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 479       |\n",
      "|    iterations      | 765       |\n",
      "|    time_elapsed    | 3270      |\n",
      "|    total_timesteps | 1566720   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.36e+03     |\n",
      "|    ep_rew_mean          | -3.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 479          |\n",
      "|    iterations           | 766          |\n",
      "|    time_elapsed         | 3272         |\n",
      "|    total_timesteps      | 1568768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059982333 |\n",
      "|    clip_fraction        | 0.026        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.92         |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.91e+06     |\n",
      "|    n_updates            | 23560        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.185        |\n",
      "|    value_loss           | 2.83e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=10145.24 +/- 3288.18\n",
      "Episode length: 1691.60 +/- 19.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.69e+03    |\n",
      "|    mean_reward          | 1.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.079712115 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.706       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 23570       |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 7.97e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | -3.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 479      |\n",
      "|    iterations      | 767      |\n",
      "|    time_elapsed    | 3277     |\n",
      "|    total_timesteps | 1570816  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.35e+03   |\n",
      "|    ep_rew_mean          | -3.6e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 479        |\n",
      "|    iterations           | 768        |\n",
      "|    time_elapsed         | 3279       |\n",
      "|    total_timesteps      | 1572864    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01299672 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.92       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 59.3       |\n",
      "|    n_updates            | 23580      |\n",
      "|    policy_gradient_loss | 0.00734    |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 281        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | -3.6e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 479         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 3281        |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014614724 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.798       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.6        |\n",
      "|    n_updates            | 23590       |\n",
      "|    policy_gradient_loss | -0.000176   |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.09e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1575000, episode_reward=-10419.97 +/- 56147.65\n",
      "Episode length: 1448.80 +/- 685.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.45e+03    |\n",
      "|    mean_reward          | -1.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1575000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009375175 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 23600       |\n",
      "|    policy_gradient_loss | -0.00122    |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 2e+04       |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -3.61e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 479       |\n",
      "|    iterations      | 770       |\n",
      "|    time_elapsed    | 3286      |\n",
      "|    total_timesteps | 1576960   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.33e+03   |\n",
      "|    ep_rew_mean          | -3.6e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 480        |\n",
      "|    iterations           | 771        |\n",
      "|    time_elapsed         | 3288       |\n",
      "|    total_timesteps      | 1579008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03258885 |\n",
      "|    clip_fraction        | 0.16       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.93       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 71.1       |\n",
      "|    n_updates            | 23610      |\n",
      "|    policy_gradient_loss | 0.00574    |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 276        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=-10345.67 +/- 55757.85\n",
      "Episode length: 1582.40 +/- 750.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.58e+03    |\n",
      "|    mean_reward          | -1.03e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016492927 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.82e+06    |\n",
      "|    n_updates            | 23620       |\n",
      "|    policy_gradient_loss | -0.000535   |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 1.78e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.34e+03 |\n",
      "|    ep_rew_mean     | -3.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 479      |\n",
      "|    iterations      | 772      |\n",
      "|    time_elapsed    | 3294     |\n",
      "|    total_timesteps | 1581056  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.35e+03   |\n",
      "|    ep_rew_mean          | -3.38e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 480        |\n",
      "|    iterations           | 773        |\n",
      "|    time_elapsed         | 3296       |\n",
      "|    total_timesteps      | 1583104    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01752776 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.93       |\n",
      "|    explained_variance   | 0.827      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 157        |\n",
      "|    n_updates            | 23630      |\n",
      "|    policy_gradient_loss | -0.00356   |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 5.04e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1585000, episode_reward=-12549.32 +/- 63020.90\n",
      "Episode length: 1481.00 +/- 698.22\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.48e+03  |\n",
      "|    mean_reward          | -1.25e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 1585000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.523958  |\n",
      "|    clip_fraction        | 0.211     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.93      |\n",
      "|    explained_variance   | 0.352     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.04e+05  |\n",
      "|    n_updates            | 23640     |\n",
      "|    policy_gradient_loss | 0.0138    |\n",
      "|    std                  | 0.185     |\n",
      "|    value_loss           | 1.7e+07   |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.32e+03  |\n",
      "|    ep_rew_mean     | -3.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 480       |\n",
      "|    iterations      | 774       |\n",
      "|    time_elapsed    | 3301      |\n",
      "|    total_timesteps | 1585152   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.34e+03   |\n",
      "|    ep_rew_mean          | -3.44e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 480        |\n",
      "|    iterations           | 775        |\n",
      "|    time_elapsed         | 3303       |\n",
      "|    total_timesteps      | 1587200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06281781 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.92       |\n",
      "|    explained_variance   | 0.359      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.71e+07   |\n",
      "|    n_updates            | 23650      |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    std                  | 0.185      |\n",
      "|    value_loss           | 3.9e+07    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | -3.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 480         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 3305        |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021048408 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.7        |\n",
      "|    n_updates            | 23660       |\n",
      "|    policy_gradient_loss | 0.00695     |\n",
      "|    std                  | 0.186       |\n",
      "|    value_loss           | 3.04e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1590000, episode_reward=19893.08 +/- 145.95\n",
      "Episode length: 1690.20 +/- 6.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.69e+03    |\n",
      "|    mean_reward          | 1.99e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014813158 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.92        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.5        |\n",
      "|    n_updates            | 23670       |\n",
      "|    policy_gradient_loss | 0.00458     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 214         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.35e+03  |\n",
      "|    ep_rew_mean     | -3.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 480       |\n",
      "|    iterations      | 777       |\n",
      "|    time_elapsed    | 3311      |\n",
      "|    total_timesteps | 1591296   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.37e+03  |\n",
      "|    ep_rew_mean          | -3.32e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 480       |\n",
      "|    iterations           | 778       |\n",
      "|    time_elapsed         | 3312      |\n",
      "|    total_timesteps      | 1593344   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1773457 |\n",
      "|    clip_fraction        | 0.134     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 2.93      |\n",
      "|    explained_variance   | 0.353     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.58e+06  |\n",
      "|    n_updates            | 23680     |\n",
      "|    policy_gradient_loss | 8.45e-05  |\n",
      "|    std                  | 0.185     |\n",
      "|    value_loss           | 2.39e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1595000, episode_reward=16373.61 +/- 5678.39\n",
      "Episode length: 1827.00 +/- 14.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.83e+03    |\n",
      "|    mean_reward          | 1.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1595000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012285467 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.93        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 70.3        |\n",
      "|    n_updates            | 23690       |\n",
      "|    policy_gradient_loss | 0.00249     |\n",
      "|    std                  | 0.185       |\n",
      "|    value_loss           | 196         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.4e+03   |\n",
      "|    ep_rew_mean     | -3.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 480       |\n",
      "|    iterations      | 779       |\n",
      "|    time_elapsed    | 3319      |\n",
      "|    total_timesteps | 1595392   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.41e+03     |\n",
      "|    ep_rew_mean          | -2.94e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 481          |\n",
      "|    iterations           | 780          |\n",
      "|    time_elapsed         | 3320         |\n",
      "|    total_timesteps      | 1597440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071714646 |\n",
      "|    clip_fraction        | 0.21         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.94         |\n",
      "|    explained_variance   | 0.994        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 35.6         |\n",
      "|    n_updates            | 23700        |\n",
      "|    policy_gradient_loss | 0.00232      |\n",
      "|    std                  | 0.184        |\n",
      "|    value_loss           | 874          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | -2.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 481         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 3322        |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017273262 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.96        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 23710       |\n",
      "|    policy_gradient_loss | 0.00579     |\n",
      "|    std                  | 0.183       |\n",
      "|    value_loss           | 99          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=21676.48 +/- 887.68\n",
      "Episode length: 1785.60 +/- 8.91\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.79e+03   |\n",
      "|    mean_reward          | 2.17e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1600000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24413705 |\n",
      "|    clip_fraction        | 0.159      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.96       |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.61e+05   |\n",
      "|    n_updates            | 23720      |\n",
      "|    policy_gradient_loss | -0.0075    |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 2.6e+07    |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.39e+03 |\n",
      "|    ep_rew_mean     | -2.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 481      |\n",
      "|    iterations      | 782      |\n",
      "|    time_elapsed    | 3328     |\n",
      "|    total_timesteps | 1601536  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.38e+03    |\n",
      "|    ep_rew_mean          | -3.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 481         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 3330        |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016608188 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.97        |\n",
      "|    explained_variance   | 0.836       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 23730       |\n",
      "|    policy_gradient_loss | 0.00349     |\n",
      "|    std                  | 0.183       |\n",
      "|    value_loss           | 2e+04       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1605000, episode_reward=-153537.83 +/- 3440.14\n",
      "Episode length: 613.00 +/- 420.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 613          |\n",
      "|    mean_reward          | -1.54e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1605000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026950715 |\n",
      "|    clip_fraction        | 0.0201       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.97         |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.81e+07     |\n",
      "|    n_updates            | 23740        |\n",
      "|    policy_gradient_loss | -0.00274     |\n",
      "|    std                  | 0.183        |\n",
      "|    value_loss           | 9.67e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.4e+03   |\n",
      "|    ep_rew_mean     | -3.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 481       |\n",
      "|    iterations      | 784       |\n",
      "|    time_elapsed    | 3334      |\n",
      "|    total_timesteps | 1605632   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.33e+03     |\n",
      "|    ep_rew_mean          | -3.84e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 481          |\n",
      "|    iterations           | 785          |\n",
      "|    time_elapsed         | 3335         |\n",
      "|    total_timesteps      | 1607680      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012696143 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.97         |\n",
      "|    explained_variance   | 0.375        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.79e+07     |\n",
      "|    n_updates            | 23750        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    std                  | 0.183        |\n",
      "|    value_loss           | 5.72e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.26e+03     |\n",
      "|    ep_rew_mean          | -4.46e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 482          |\n",
      "|    iterations           | 786          |\n",
      "|    time_elapsed         | 3337         |\n",
      "|    total_timesteps      | 1609728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010621261 |\n",
      "|    clip_fraction        | 0.0063       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.97         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.2e+07      |\n",
      "|    n_updates            | 23760        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    std                  | 0.183        |\n",
      "|    value_loss           | 7.91e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=20953.14 +/- 2092.23\n",
      "Episode length: 1782.40 +/- 12.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.78e+03     |\n",
      "|    mean_reward          | 2.1e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1610000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052688858 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.97         |\n",
      "|    explained_variance   | 0.342        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.76e+07     |\n",
      "|    n_updates            | 23770        |\n",
      "|    policy_gradient_loss | -0.00471     |\n",
      "|    std                  | 0.183        |\n",
      "|    value_loss           | 9.67e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.27e+03  |\n",
      "|    ep_rew_mean     | -4.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 481       |\n",
      "|    iterations      | 787       |\n",
      "|    time_elapsed    | 3343      |\n",
      "|    total_timesteps | 1611776   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | -4.9e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 482          |\n",
      "|    iterations           | 788          |\n",
      "|    time_elapsed         | 3345         |\n",
      "|    total_timesteps      | 1613824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032165162 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.97         |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.44e+07     |\n",
      "|    n_updates            | 23780        |\n",
      "|    policy_gradient_loss | -0.00137     |\n",
      "|    std                  | 0.183        |\n",
      "|    value_loss           | 4.52e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1615000, episode_reward=20861.65 +/- 2107.81\n",
      "Episode length: 1810.20 +/- 16.82\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.81e+03   |\n",
      "|    mean_reward          | 2.09e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1615000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00625801 |\n",
      "|    clip_fraction        | 0.0618     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.97       |\n",
      "|    explained_variance   | 0.353      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.01e+07   |\n",
      "|    n_updates            | 23790      |\n",
      "|    policy_gradient_loss | -0.00457   |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 6.77e+07   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.23e+03 |\n",
      "|    ep_rew_mean     | -4.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 482      |\n",
      "|    iterations      | 789      |\n",
      "|    time_elapsed    | 3351     |\n",
      "|    total_timesteps | 1615872  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.23e+03   |\n",
      "|    ep_rew_mean          | -4.89e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 482        |\n",
      "|    iterations           | 790        |\n",
      "|    time_elapsed         | 3353       |\n",
      "|    total_timesteps      | 1617920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01230846 |\n",
      "|    clip_fraction        | 0.0538     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.97       |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.38e+03   |\n",
      "|    n_updates            | 23800      |\n",
      "|    policy_gradient_loss | -0.004     |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 7.95e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | -4.89e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 482         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 3355        |\n",
      "|    total_timesteps      | 1619968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007235184 |\n",
      "|    clip_fraction        | 0.0496      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.97        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.8e+03     |\n",
      "|    n_updates            | 23810       |\n",
      "|    policy_gradient_loss | -0.00502    |\n",
      "|    std                  | 0.183       |\n",
      "|    value_loss           | 4.68e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=-12730.25 +/- 71690.41\n",
      "Episode length: 1513.80 +/- 708.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.51e+03    |\n",
      "|    mean_reward          | -1.27e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008196968 |\n",
      "|    clip_fraction        | 0.0363      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.97        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 23820       |\n",
      "|    policy_gradient_loss | -0.00198    |\n",
      "|    std                  | 0.183       |\n",
      "|    value_loss           | 2.22e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.23e+03  |\n",
      "|    ep_rew_mean     | -4.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 482       |\n",
      "|    iterations      | 792       |\n",
      "|    time_elapsed    | 3361      |\n",
      "|    total_timesteps | 1622016   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.23e+03     |\n",
      "|    ep_rew_mean          | -4.98e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 482          |\n",
      "|    iterations           | 793          |\n",
      "|    time_elapsed         | 3363         |\n",
      "|    total_timesteps      | 1624064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032133358 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.97         |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 544          |\n",
      "|    n_updates            | 23830        |\n",
      "|    policy_gradient_loss | -0.00119     |\n",
      "|    std                  | 0.183        |\n",
      "|    value_loss           | 1.16e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1625000, episode_reward=-14995.36 +/- 70709.75\n",
      "Episode length: 1525.20 +/- 713.28\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.53e+03     |\n",
      "|    mean_reward          | -1.5e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1625000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037805748 |\n",
      "|    clip_fraction        | 0.0122       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 2.97         |\n",
      "|    explained_variance   | 0.326        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+06     |\n",
      "|    n_updates            | 23840        |\n",
      "|    policy_gradient_loss | -0.00328     |\n",
      "|    std                  | 0.183        |\n",
      "|    value_loss           | 1.69e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.23e+03  |\n",
      "|    ep_rew_mean     | -5.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 482       |\n",
      "|    iterations      | 794       |\n",
      "|    time_elapsed    | 3368      |\n",
      "|    total_timesteps | 1626112   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | -5.01e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 483         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 3370        |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005311126 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.97        |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.57e+06    |\n",
      "|    n_updates            | 23850       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 0.183       |\n",
      "|    value_loss           | 2.42e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=18983.27 +/- 3538.45\n",
      "Episode length: 1811.00 +/- 9.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.81e+03    |\n",
      "|    mean_reward          | 1.9e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014476213 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.97        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 23860       |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    std                  | 0.183       |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.23e+03  |\n",
      "|    ep_rew_mean     | -5.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 482       |\n",
      "|    iterations      | 796       |\n",
      "|    time_elapsed    | 3376      |\n",
      "|    total_timesteps | 1630208   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -5.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 483         |\n",
      "|    iterations           | 797         |\n",
      "|    time_elapsed         | 3378        |\n",
      "|    total_timesteps      | 1632256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014752816 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.97        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 23870       |\n",
      "|    policy_gradient_loss | -0.00478    |\n",
      "|    std                  | 0.183       |\n",
      "|    value_loss           | 2.01e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.2e+03    |\n",
      "|    ep_rew_mean          | -5.2e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 483        |\n",
      "|    iterations           | 798        |\n",
      "|    time_elapsed         | 3380       |\n",
      "|    total_timesteps      | 1634304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34627098 |\n",
      "|    clip_fraction        | 0.146      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.97       |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.03e+07   |\n",
      "|    n_updates            | 23880      |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    std                  | 0.183      |\n",
      "|    value_loss           | 2.83e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1635000, episode_reward=22358.68 +/- 373.40\n",
      "Episode length: 1696.80 +/- 16.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 2.24e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1635000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020007068 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.98        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 270         |\n",
      "|    n_updates            | 23890       |\n",
      "|    policy_gradient_loss | 0.000892    |\n",
      "|    std                  | 0.182       |\n",
      "|    value_loss           | 2.16e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -5.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 483       |\n",
      "|    iterations      | 799       |\n",
      "|    time_elapsed    | 3386      |\n",
      "|    total_timesteps | 1636352   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.23e+03   |\n",
      "|    ep_rew_mean          | -4.93e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 483        |\n",
      "|    iterations           | 800        |\n",
      "|    time_elapsed         | 3388       |\n",
      "|    total_timesteps      | 1638400    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03147557 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.98       |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.72e+05   |\n",
      "|    n_updates            | 23900      |\n",
      "|    policy_gradient_loss | 0.00124    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 1.7e+04    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1640000, episode_reward=21566.17 +/- 3082.84\n",
      "Episode length: 1726.00 +/- 13.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.73e+03   |\n",
      "|    mean_reward          | 2.16e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1640000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02955968 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 2.99       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 45.8       |\n",
      "|    n_updates            | 23910      |\n",
      "|    policy_gradient_loss | 0.00318    |\n",
      "|    std                  | 0.182      |\n",
      "|    value_loss           | 569        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.22e+03  |\n",
      "|    ep_rew_mean     | -4.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 483       |\n",
      "|    iterations      | 801       |\n",
      "|    time_elapsed    | 3393      |\n",
      "|    total_timesteps | 1640448   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -4.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 483         |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 3395        |\n",
      "|    total_timesteps      | 1642496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015397378 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 2.99        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 23920       |\n",
      "|    policy_gradient_loss | 0.00187     |\n",
      "|    std                  | 0.182       |\n",
      "|    value_loss           | 475         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.22e+03   |\n",
      "|    ep_rew_mean          | -4.53e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 484        |\n",
      "|    iterations           | 803        |\n",
      "|    time_elapsed         | 3397       |\n",
      "|    total_timesteps      | 1644544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05074678 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3          |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 144        |\n",
      "|    n_updates            | 23930      |\n",
      "|    policy_gradient_loss | 0.00524    |\n",
      "|    std                  | 0.181      |\n",
      "|    value_loss           | 387        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1645000, episode_reward=18181.53 +/- 4177.09\n",
      "Episode length: 1677.60 +/- 11.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.68e+03    |\n",
      "|    mean_reward          | 1.82e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1645000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011681363 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.02        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.4        |\n",
      "|    n_updates            | 23940       |\n",
      "|    policy_gradient_loss | 0.00309     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 359         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.23e+03  |\n",
      "|    ep_rew_mean     | -4.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 483       |\n",
      "|    iterations      | 804       |\n",
      "|    time_elapsed    | 3403      |\n",
      "|    total_timesteps | 1646592   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -4.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 484         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 3405        |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021131864 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.03        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 23950       |\n",
      "|    policy_gradient_loss | -0.0062     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.49e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=17965.88 +/- 3384.87\n",
      "Episode length: 1622.60 +/- 5.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.62e+03    |\n",
      "|    mean_reward          | 1.8e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012021311 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.04        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 23960       |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -4.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 483       |\n",
      "|    iterations      | 806       |\n",
      "|    time_elapsed    | 3411      |\n",
      "|    total_timesteps | 1650688   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -4.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 484         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 3412        |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015791241 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.04        |\n",
      "|    explained_variance   | 0.966       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54          |\n",
      "|    n_updates            | 23970       |\n",
      "|    policy_gradient_loss | 0.00336     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.86e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.27e+03     |\n",
      "|    ep_rew_mean          | -4.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 484          |\n",
      "|    iterations           | 808          |\n",
      "|    time_elapsed         | 3414         |\n",
      "|    total_timesteps      | 1654784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033643662 |\n",
      "|    clip_fraction        | 0.0487       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.04         |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02e+07     |\n",
      "|    n_updates            | 23980        |\n",
      "|    policy_gradient_loss | 0.00166      |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 6.24e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1655000, episode_reward=17022.64 +/- 3449.24\n",
      "Episode length: 1561.80 +/- 20.01\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.56e+03     |\n",
      "|    mean_reward          | 1.7e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1655000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077693565 |\n",
      "|    clip_fraction        | 0.0906       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.04         |\n",
      "|    explained_variance   | 0.852        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.96e+03     |\n",
      "|    n_updates            | 23990        |\n",
      "|    policy_gradient_loss | -0.00641     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 2.03e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.26e+03  |\n",
      "|    ep_rew_mean     | -3.93e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 484       |\n",
      "|    iterations      | 809       |\n",
      "|    time_elapsed    | 3420      |\n",
      "|    total_timesteps | 1656832   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | -3.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 484         |\n",
      "|    iterations           | 810         |\n",
      "|    time_elapsed         | 3422        |\n",
      "|    total_timesteps      | 1658880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010271944 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.04        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 525         |\n",
      "|    n_updates            | 24000       |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.2e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1660000, episode_reward=17118.72 +/- 2277.84\n",
      "Episode length: 1510.00 +/- 10.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.51e+03    |\n",
      "|    mean_reward          | 1.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034136795 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.05        |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 24010       |\n",
      "|    policy_gradient_loss | 0.00415     |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 5.17e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.27e+03 |\n",
      "|    ep_rew_mean     | -3.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 484      |\n",
      "|    iterations      | 811      |\n",
      "|    time_elapsed    | 3427     |\n",
      "|    total_timesteps | 1660928  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | -3.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 484         |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 3429        |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025613882 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.05        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 24020       |\n",
      "|    policy_gradient_loss | -2.6e-05    |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 2.15e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1665000, episode_reward=-19465.10 +/- 62528.87\n",
      "Episode length: 1173.60 +/- 541.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.17e+03    |\n",
      "|    mean_reward          | -1.95e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1665000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040534057 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.04        |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 24030       |\n",
      "|    policy_gradient_loss | 0.00594     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 5.53e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -3.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 484       |\n",
      "|    iterations      | 813       |\n",
      "|    time_elapsed    | 3434      |\n",
      "|    total_timesteps | 1665024   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | -3.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 485         |\n",
      "|    iterations           | 814         |\n",
      "|    time_elapsed         | 3436        |\n",
      "|    total_timesteps      | 1667072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016724817 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.04        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.34e+05    |\n",
      "|    n_updates            | 24040       |\n",
      "|    policy_gradient_loss | -0.000219   |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.99e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.25e+03    |\n",
      "|    ep_rew_mean          | -3.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 485         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 3437        |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005487074 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.04        |\n",
      "|    explained_variance   | 0.32        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.87e+07    |\n",
      "|    n_updates            | 24050       |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.72e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1670000, episode_reward=-19502.89 +/- 65564.63\n",
      "Episode length: 1137.00 +/- 519.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.14e+03    |\n",
      "|    mean_reward          | -1.95e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002590394 |\n",
      "|    clip_fraction        | 0.0162      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.04        |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.9e+03     |\n",
      "|    n_updates            | 24060       |\n",
      "|    policy_gradient_loss | -0.000957   |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 6.42e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.26e+03  |\n",
      "|    ep_rew_mean     | -3.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 485       |\n",
      "|    iterations      | 816       |\n",
      "|    time_elapsed    | 3442      |\n",
      "|    total_timesteps | 1671168   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.25e+03     |\n",
      "|    ep_rew_mean          | -3.74e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 485          |\n",
      "|    iterations           | 817          |\n",
      "|    time_elapsed         | 3444         |\n",
      "|    total_timesteps      | 1673216      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047274455 |\n",
      "|    clip_fraction        | 0.0307       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.04         |\n",
      "|    explained_variance   | 0.874        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.28e+04     |\n",
      "|    n_updates            | 24070        |\n",
      "|    policy_gradient_loss | -0.000962    |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 5.87e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1675000, episode_reward=-19950.87 +/- 64608.43\n",
      "Episode length: 1126.00 +/- 516.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.13e+03    |\n",
      "|    mean_reward          | -2e+04      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1675000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006473366 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.04        |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 562         |\n",
      "|    n_updates            | 24080       |\n",
      "|    policy_gradient_loss | -0.000521   |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 5.75e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.26e+03  |\n",
      "|    ep_rew_mean     | -3.61e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 485       |\n",
      "|    iterations      | 818       |\n",
      "|    time_elapsed    | 3448      |\n",
      "|    total_timesteps | 1675264   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | -3.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 486         |\n",
      "|    iterations           | 819         |\n",
      "|    time_elapsed         | 3450        |\n",
      "|    total_timesteps      | 1677312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020760298 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.04        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 155         |\n",
      "|    n_updates            | 24090       |\n",
      "|    policy_gradient_loss | 0.0042      |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.13e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.25e+03  |\n",
      "|    ep_rew_mean          | -3.68e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 486       |\n",
      "|    iterations           | 820       |\n",
      "|    time_elapsed         | 3452      |\n",
      "|    total_timesteps      | 1679360   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1129067 |\n",
      "|    clip_fraction        | 0.282     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.05      |\n",
      "|    explained_variance   | 0.317     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.28e+05  |\n",
      "|    n_updates            | 24100     |\n",
      "|    policy_gradient_loss | 0.0148    |\n",
      "|    std                  | 0.18      |\n",
      "|    value_loss           | 2.61e+07  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1680000, episode_reward=-16605.47 +/- 61644.88\n",
      "Episode length: 1118.40 +/- 513.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.12e+03    |\n",
      "|    mean_reward          | -1.66e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014178026 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.05        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 688         |\n",
      "|    n_updates            | 24110       |\n",
      "|    policy_gradient_loss | 0.0047      |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 965         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.24e+03 |\n",
      "|    ep_rew_mean     | -4e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 486      |\n",
      "|    iterations      | 821      |\n",
      "|    time_elapsed    | 3457     |\n",
      "|    total_timesteps | 1681408  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | -4.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 486         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 3458        |\n",
      "|    total_timesteps      | 1683456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006755889 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.05        |\n",
      "|    explained_variance   | 0.306       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.11e+07    |\n",
      "|    n_updates            | 24120       |\n",
      "|    policy_gradient_loss | -0.000749   |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 6.26e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1685000, episode_reward=-48873.07 +/- 73946.87\n",
      "Episode length: 858.60 +/- 629.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 859         |\n",
      "|    mean_reward          | -4.89e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1685000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015174435 |\n",
      "|    clip_fraction        | 0.0561      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.05        |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.91e+06    |\n",
      "|    n_updates            | 24130       |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.64e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.23e+03  |\n",
      "|    ep_rew_mean     | -4.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 486       |\n",
      "|    iterations      | 823       |\n",
      "|    time_elapsed    | 3462      |\n",
      "|    total_timesteps | 1685504   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | -4.42e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 487          |\n",
      "|    iterations           | 824          |\n",
      "|    time_elapsed         | 3464         |\n",
      "|    total_timesteps      | 1687552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0006415363 |\n",
      "|    clip_fraction        | 0.000293     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.05         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.79e+07     |\n",
      "|    n_updates            | 24140        |\n",
      "|    policy_gradient_loss | -0.00183     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 8.31e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.22e+03     |\n",
      "|    ep_rew_mean          | -4.76e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 487          |\n",
      "|    iterations           | 825          |\n",
      "|    time_elapsed         | 3466         |\n",
      "|    total_timesteps      | 1689600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042963354 |\n",
      "|    clip_fraction        | 0.0179       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.05         |\n",
      "|    explained_variance   | 0.405        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.32e+06     |\n",
      "|    n_updates            | 24150        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 1.73e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1690000, episode_reward=-19746.93 +/- 61101.71\n",
      "Episode length: 1117.40 +/- 510.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.12e+03     |\n",
      "|    mean_reward          | -1.97e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1690000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024455562 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.05         |\n",
      "|    explained_variance   | 0.3          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.44e+07     |\n",
      "|    n_updates            | 24160        |\n",
      "|    policy_gradient_loss | -0.00287     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 7.38e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -5.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 487       |\n",
      "|    iterations      | 826       |\n",
      "|    time_elapsed    | 3471      |\n",
      "|    total_timesteps | 1691648   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.17e+03     |\n",
      "|    ep_rew_mean          | -5.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 487          |\n",
      "|    iterations           | 827          |\n",
      "|    time_elapsed         | 3473         |\n",
      "|    total_timesteps      | 1693696      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054231733 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.05         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.07e+07     |\n",
      "|    n_updates            | 24170        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 1.19e+08     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1695000, episode_reward=-49149.22 +/- 72825.68\n",
      "Episode length: 858.00 +/- 628.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 858         |\n",
      "|    mean_reward          | -4.91e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1695000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007572652 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.05        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.93e+03    |\n",
      "|    n_updates            | 24180       |\n",
      "|    policy_gradient_loss | -0.00602    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.15e+03  |\n",
      "|    ep_rew_mean     | -5.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 487       |\n",
      "|    iterations      | 828       |\n",
      "|    time_elapsed    | 3476      |\n",
      "|    total_timesteps | 1695744   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.16e+03     |\n",
      "|    ep_rew_mean          | -5.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 488          |\n",
      "|    iterations           | 829          |\n",
      "|    time_elapsed         | 3478         |\n",
      "|    total_timesteps      | 1697792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034497548 |\n",
      "|    clip_fraction        | 0.00933      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.05         |\n",
      "|    explained_variance   | 0.338        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.66e+07     |\n",
      "|    n_updates            | 24190        |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 9.07e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -5.79e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 488          |\n",
      "|    iterations           | 830          |\n",
      "|    time_elapsed         | 3480         |\n",
      "|    total_timesteps      | 1699840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039741327 |\n",
      "|    clip_fraction        | 0.022        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.05         |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.68e+03     |\n",
      "|    n_updates            | 24200        |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 2.11e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=-18231.84 +/- 59061.52\n",
      "Episode length: 1133.60 +/- 524.34\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.13e+03     |\n",
      "|    mean_reward          | -1.82e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1700000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057762545 |\n",
      "|    clip_fraction        | 0.0271       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.05         |\n",
      "|    explained_variance   | 0.34         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.11e+07     |\n",
      "|    n_updates            | 24210        |\n",
      "|    policy_gradient_loss | -0.00291     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 6.29e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -5.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 488       |\n",
      "|    iterations      | 831       |\n",
      "|    time_elapsed    | 3485      |\n",
      "|    total_timesteps | 1701888   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -5.82e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 488         |\n",
      "|    iterations           | 832         |\n",
      "|    time_elapsed         | 3487        |\n",
      "|    total_timesteps      | 1703936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009346418 |\n",
      "|    clip_fraction        | 0.0596      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.05        |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 24220       |\n",
      "|    policy_gradient_loss | -0.00306    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 5.93e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1705000, episode_reward=-16532.79 +/- 63149.53\n",
      "Episode length: 1163.40 +/- 532.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.16e+03     |\n",
      "|    mean_reward          | -1.65e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1705000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047122655 |\n",
      "|    clip_fraction        | 0.0543       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.05         |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+03      |\n",
      "|    n_updates            | 24230        |\n",
      "|    policy_gradient_loss | -0.000908    |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 1.66e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.14e+03  |\n",
      "|    ep_rew_mean     | -5.68e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 488       |\n",
      "|    iterations      | 833       |\n",
      "|    time_elapsed    | 3491      |\n",
      "|    total_timesteps | 1705984   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -5.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 488         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 3493        |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009266394 |\n",
      "|    clip_fraction        | 0.0838      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.05        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.06e+04    |\n",
      "|    n_updates            | 24240       |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1710000, episode_reward=-16007.34 +/- 57919.85\n",
      "Episode length: 1097.60 +/- 506.95\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.1e+03    |\n",
      "|    mean_reward          | -1.6e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1710000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23970428 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.05       |\n",
      "|    explained_variance   | 0.356      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.55e+07   |\n",
      "|    n_updates            | 24250      |\n",
      "|    policy_gradient_loss | -0.0176    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 2.26e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.11e+03  |\n",
      "|    ep_rew_mean     | -5.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 488       |\n",
      "|    iterations      | 835       |\n",
      "|    time_elapsed    | 3498      |\n",
      "|    total_timesteps | 1710080   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -5.7e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 3500        |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006878104 |\n",
      "|    clip_fraction        | 0.0905      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.06        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 756         |\n",
      "|    n_updates            | 24260       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 4.97e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -5.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 3501        |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015118385 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.06        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 178         |\n",
      "|    n_updates            | 24270       |\n",
      "|    policy_gradient_loss | 0.00436     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.5e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1715000, episode_reward=13632.78 +/- 1442.68\n",
      "Episode length: 1292.40 +/- 6.92\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.29e+03   |\n",
      "|    mean_reward          | 1.36e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1715000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06127522 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.06       |\n",
      "|    explained_variance   | 0.899      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 111        |\n",
      "|    n_updates            | 24280      |\n",
      "|    policy_gradient_loss | 0.00334    |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 3.17e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.13e+03 |\n",
      "|    ep_rew_mean     | -5.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 489      |\n",
      "|    iterations      | 838      |\n",
      "|    time_elapsed    | 3506     |\n",
      "|    total_timesteps | 1716224  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -5.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 3508        |\n",
      "|    total_timesteps      | 1718272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022009112 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.07        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 24290       |\n",
      "|    policy_gradient_loss | 0.0047      |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 2.11e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1720000, episode_reward=14373.27 +/- 2413.94\n",
      "Episode length: 1236.00 +/- 10.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.24e+03    |\n",
      "|    mean_reward          | 1.44e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016617373 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.07        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 24300       |\n",
      "|    policy_gradient_loss | 0.00604     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 253         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.14e+03  |\n",
      "|    ep_rew_mean     | -4.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 489       |\n",
      "|    iterations      | 840       |\n",
      "|    time_elapsed    | 3513      |\n",
      "|    total_timesteps | 1720320   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -4.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 489         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 3515        |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020637807 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.8        |\n",
      "|    n_updates            | 24310       |\n",
      "|    policy_gradient_loss | 0.00553     |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 274         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -4.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 3517        |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048031777 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.9        |\n",
      "|    n_updates            | 24320       |\n",
      "|    policy_gradient_loss | 0.00531     |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 2.07e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1725000, episode_reward=15865.39 +/- 1039.60\n",
      "Episode length: 1198.80 +/- 14.11\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.2e+03    |\n",
      "|    mean_reward          | 1.59e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1725000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02536944 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.08       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 71         |\n",
      "|    n_updates            | 24330      |\n",
      "|    policy_gradient_loss | 0.00606    |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 171        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.16e+03  |\n",
      "|    ep_rew_mean     | -4.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 490       |\n",
      "|    iterations      | 843       |\n",
      "|    time_elapsed    | 3521      |\n",
      "|    total_timesteps | 1726464   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -3.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 844         |\n",
      "|    time_elapsed         | 3523        |\n",
      "|    total_timesteps      | 1728512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027530499 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.07        |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+07    |\n",
      "|    n_updates            | 24340       |\n",
      "|    policy_gradient_loss | 0.0171      |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 2.58e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1730000, episode_reward=-17417.67 +/- 54856.25\n",
      "Episode length: 960.80 +/- 439.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 961          |\n",
      "|    mean_reward          | -1.74e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1730000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052313404 |\n",
      "|    clip_fraction        | 0.0162       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.07         |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.75e+06     |\n",
      "|    n_updates            | 24350        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    std                  | 0.179        |\n",
      "|    value_loss           | 2.08e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -3.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 490       |\n",
      "|    iterations      | 845       |\n",
      "|    time_elapsed    | 3527      |\n",
      "|    total_timesteps | 1730560   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -3.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 490         |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 3529        |\n",
      "|    total_timesteps      | 1732608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010540072 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.07        |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.24e+03    |\n",
      "|    n_updates            | 24360       |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 1.08e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -3.8e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 491          |\n",
      "|    iterations           | 847          |\n",
      "|    time_elapsed         | 3531         |\n",
      "|    total_timesteps      | 1734656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009853918 |\n",
      "|    clip_fraction        | 0.0084       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.08e+07     |\n",
      "|    n_updates            | 24370        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    std                  | 0.179        |\n",
      "|    value_loss           | 4.47e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1735000, episode_reward=14235.08 +/- 3704.92\n",
      "Episode length: 1181.80 +/- 11.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.18e+03     |\n",
      "|    mean_reward          | 1.42e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1735000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022944876 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.02e+05     |\n",
      "|    n_updates            | 24380        |\n",
      "|    policy_gradient_loss | -0.00256     |\n",
      "|    std                  | 0.179        |\n",
      "|    value_loss           | 2.62e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.11e+03  |\n",
      "|    ep_rew_mean     | -3.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 491       |\n",
      "|    iterations      | 848       |\n",
      "|    time_elapsed    | 3536      |\n",
      "|    total_timesteps | 1736704   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.1e+03      |\n",
      "|    ep_rew_mean          | -3.97e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 491          |\n",
      "|    iterations           | 849          |\n",
      "|    time_elapsed         | 3537         |\n",
      "|    total_timesteps      | 1738752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037018366 |\n",
      "|    clip_fraction        | 0.0249       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.21e+07     |\n",
      "|    n_updates            | 24390        |\n",
      "|    policy_gradient_loss | 0.00109      |\n",
      "|    std                  | 0.179        |\n",
      "|    value_loss           | 3.95e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1740000, episode_reward=14664.73 +/- 2287.00\n",
      "Episode length: 1169.20 +/- 6.37\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.17e+03      |\n",
      "|    mean_reward          | 1.47e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 1740000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00049181585 |\n",
      "|    clip_fraction        | 0.00537       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 3.08          |\n",
      "|    explained_variance   | 0.337         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 6.35e+05      |\n",
      "|    n_updates            | 24400         |\n",
      "|    policy_gradient_loss | -0.000706     |\n",
      "|    std                  | 0.179         |\n",
      "|    value_loss           | 2.45e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.09e+03  |\n",
      "|    ep_rew_mean     | -3.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 491       |\n",
      "|    iterations      | 850       |\n",
      "|    time_elapsed    | 3542      |\n",
      "|    total_timesteps | 1740800   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | -3.83e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 491          |\n",
      "|    iterations           | 851          |\n",
      "|    time_elapsed         | 3544         |\n",
      "|    total_timesteps      | 1742848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036820578 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.831        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.84e+03     |\n",
      "|    n_updates            | 24410        |\n",
      "|    policy_gradient_loss | -0.000279    |\n",
      "|    std                  | 0.179        |\n",
      "|    value_loss           | 6.08e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09e+03    |\n",
      "|    ep_rew_mean          | -3.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 492         |\n",
      "|    iterations           | 852         |\n",
      "|    time_elapsed         | 3546        |\n",
      "|    total_timesteps      | 1744896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006168374 |\n",
      "|    clip_fraction        | 0.0446      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.07        |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.26e+04    |\n",
      "|    n_updates            | 24420       |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 4.88e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1745000, episode_reward=11740.12 +/- 4380.32\n",
      "Episode length: 1176.80 +/- 8.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.18e+03     |\n",
      "|    mean_reward          | 1.17e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1745000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060184104 |\n",
      "|    clip_fraction        | 0.0582       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.07         |\n",
      "|    explained_variance   | 0.844        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.95e+03     |\n",
      "|    n_updates            | 24430        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 2.62e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -4.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 491       |\n",
      "|    iterations      | 853       |\n",
      "|    time_elapsed    | 3551      |\n",
      "|    total_timesteps | 1746944   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.07e+03     |\n",
      "|    ep_rew_mean          | -4.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 492          |\n",
      "|    iterations           | 854          |\n",
      "|    time_elapsed         | 3552         |\n",
      "|    total_timesteps      | 1748992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013427809 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.07         |\n",
      "|    explained_variance   | 0.345        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.96e+06     |\n",
      "|    n_updates            | 24440        |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 2.87e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1750000, episode_reward=-16872.42 +/- 59260.48\n",
      "Episode length: 957.00 +/- 433.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 957          |\n",
      "|    mean_reward          | -1.69e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1750000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064272387 |\n",
      "|    clip_fraction        | 0.0624       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.07         |\n",
      "|    explained_variance   | 0.873        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.12e+03     |\n",
      "|    n_updates            | 24450        |\n",
      "|    policy_gradient_loss | -0.000566    |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 2.24e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.04e+03  |\n",
      "|    ep_rew_mean     | -4.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 492       |\n",
      "|    iterations      | 855       |\n",
      "|    time_elapsed    | 3557      |\n",
      "|    total_timesteps | 1751040   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -4.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 492         |\n",
      "|    iterations           | 856         |\n",
      "|    time_elapsed         | 3559        |\n",
      "|    total_timesteps      | 1753088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019348036 |\n",
      "|    clip_fraction        | 0.0399      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.07        |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.74e+07    |\n",
      "|    n_updates            | 24460       |\n",
      "|    policy_gradient_loss | 0.00127     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.02e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1755000, episode_reward=14483.98 +/- 2096.19\n",
      "Episode length: 1190.20 +/- 10.15\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.19e+03   |\n",
      "|    mean_reward          | 1.45e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1755000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24343075 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.07       |\n",
      "|    explained_variance   | 0.389      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.37e+07   |\n",
      "|    n_updates            | 24470      |\n",
      "|    policy_gradient_loss | 0.00703    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 2.08e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -4.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 492       |\n",
      "|    iterations      | 857       |\n",
      "|    time_elapsed    | 3563      |\n",
      "|    total_timesteps | 1755136   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 979        |\n",
      "|    ep_rew_mean          | -4.51e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 492        |\n",
      "|    iterations           | 858        |\n",
      "|    time_elapsed         | 3565       |\n",
      "|    total_timesteps      | 1757184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24678329 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.07       |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.94e+07   |\n",
      "|    n_updates            | 24480      |\n",
      "|    policy_gradient_loss | -0.0177    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 2.44e+07   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 965         |\n",
      "|    ep_rew_mean          | -4.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 3567        |\n",
      "|    total_timesteps      | 1759232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002413251 |\n",
      "|    clip_fraction        | 0.0626      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.07        |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.49e+07    |\n",
      "|    n_updates            | 24490       |\n",
      "|    policy_gradient_loss | -0.00388    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 5.5e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1760000, episode_reward=14256.67 +/- 3867.05\n",
      "Episode length: 1186.00 +/- 10.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.19e+03     |\n",
      "|    mean_reward          | 1.43e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020876895 |\n",
      "|    clip_fraction        | 0.00908      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.07         |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.14e+07     |\n",
      "|    n_updates            | 24500        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 2.9e+07      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 948       |\n",
      "|    ep_rew_mean     | -4.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 860       |\n",
      "|    time_elapsed    | 3572      |\n",
      "|    total_timesteps | 1761280   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 951         |\n",
      "|    ep_rew_mean          | -4.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 861         |\n",
      "|    time_elapsed         | 3573        |\n",
      "|    total_timesteps      | 1763328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005546108 |\n",
      "|    clip_fraction        | 0.019       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.07        |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.46e+07    |\n",
      "|    n_updates            | 24510       |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.53e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1765000, episode_reward=18540.81 +/- 94.59\n",
      "Episode length: 1251.20 +/- 4.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.25e+03    |\n",
      "|    mean_reward          | 1.85e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1765000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041989423 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.07        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 365         |\n",
      "|    n_updates            | 24520       |\n",
      "|    policy_gradient_loss | 0.00156     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.66e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 947      |\n",
      "|    ep_rew_mean     | -4.7e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 493      |\n",
      "|    iterations      | 862      |\n",
      "|    time_elapsed    | 3578     |\n",
      "|    total_timesteps | 1765376  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 945         |\n",
      "|    ep_rew_mean          | -4.7e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 3580        |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044330105 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.07        |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 302         |\n",
      "|    n_updates            | 24530       |\n",
      "|    policy_gradient_loss | 0.0046      |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 6.95e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 943         |\n",
      "|    ep_rew_mean          | -4.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 864         |\n",
      "|    time_elapsed         | 3582        |\n",
      "|    total_timesteps      | 1769472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045758724 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.4        |\n",
      "|    n_updates            | 24540       |\n",
      "|    policy_gradient_loss | 0.00906     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 750         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1770000, episode_reward=-20191.48 +/- 70546.44\n",
      "Episode length: 1054.40 +/- 474.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.05e+03    |\n",
      "|    mean_reward          | -2.02e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024948886 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 84.5        |\n",
      "|    n_updates            | 24550       |\n",
      "|    policy_gradient_loss | 0.00828     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.32e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 950       |\n",
      "|    ep_rew_mean     | -4.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 865       |\n",
      "|    time_elapsed    | 3586      |\n",
      "|    total_timesteps | 1771520   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 946         |\n",
      "|    ep_rew_mean          | -4.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 3588        |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005275471 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.1e+07     |\n",
      "|    n_updates            | 24560       |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.34e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1775000, episode_reward=17956.95 +/- 1552.86\n",
      "Episode length: 1276.40 +/- 6.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.28e+03    |\n",
      "|    mean_reward          | 1.8e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1775000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005828378 |\n",
      "|    clip_fraction        | 0.0334      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.73e+03    |\n",
      "|    n_updates            | 24570       |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.91e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 950       |\n",
      "|    ep_rew_mean     | -4.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 867       |\n",
      "|    time_elapsed    | 3593      |\n",
      "|    total_timesteps | 1775616   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 937         |\n",
      "|    ep_rew_mean          | -4.27e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 868         |\n",
      "|    time_elapsed         | 3595        |\n",
      "|    total_timesteps      | 1777664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007489834 |\n",
      "|    clip_fraction        | 0.0712      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 745         |\n",
      "|    n_updates            | 24580       |\n",
      "|    policy_gradient_loss | 0.00358     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.72e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 942       |\n",
      "|    ep_rew_mean          | -4.06e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 494       |\n",
      "|    iterations           | 869       |\n",
      "|    time_elapsed         | 3597      |\n",
      "|    total_timesteps      | 1779712   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5274676 |\n",
      "|    clip_fraction        | 0.118     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.08      |\n",
      "|    explained_variance   | 0.344     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.5e+06   |\n",
      "|    n_updates            | 24590     |\n",
      "|    policy_gradient_loss | 0.00541   |\n",
      "|    std                  | 0.179     |\n",
      "|    value_loss           | 2.68e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1780000, episode_reward=18157.12 +/- 3099.07\n",
      "Episode length: 1299.60 +/- 13.28\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.3e+03      |\n",
      "|    mean_reward          | 1.82e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1780000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018085579 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.324        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.29e+06     |\n",
      "|    n_updates            | 24600        |\n",
      "|    policy_gradient_loss | -0.00383     |\n",
      "|    std                  | 0.179        |\n",
      "|    value_loss           | 2.72e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 935       |\n",
      "|    ep_rew_mean     | -3.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 870       |\n",
      "|    time_elapsed    | 3602      |\n",
      "|    total_timesteps | 1781760   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 947          |\n",
      "|    ep_rew_mean          | -3.76e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 871          |\n",
      "|    time_elapsed         | 3604         |\n",
      "|    total_timesteps      | 1783808      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012182298 |\n",
      "|    clip_fraction        | 0.00498      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.21e+06     |\n",
      "|    n_updates            | 24610        |\n",
      "|    policy_gradient_loss | 0.000252     |\n",
      "|    std                  | 0.179        |\n",
      "|    value_loss           | 2.19e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1785000, episode_reward=18575.16 +/- 2359.25\n",
      "Episode length: 1297.00 +/- 6.48\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.3e+03      |\n",
      "|    mean_reward          | 1.86e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1785000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035077836 |\n",
      "|    clip_fraction        | 0.0182       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.75         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 649          |\n",
      "|    n_updates            | 24620        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    std                  | 0.179        |\n",
      "|    value_loss           | 5.13e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 957       |\n",
      "|    ep_rew_mean     | -3.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 872       |\n",
      "|    time_elapsed    | 3609      |\n",
      "|    total_timesteps | 1785856   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 976        |\n",
      "|    ep_rew_mean          | -3.45e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 495        |\n",
      "|    iterations           | 873        |\n",
      "|    time_elapsed         | 3610       |\n",
      "|    total_timesteps      | 1787904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07872376 |\n",
      "|    clip_fraction        | 0.0932     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.08       |\n",
      "|    explained_variance   | 0.358      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.24e+07   |\n",
      "|    n_updates            | 24630      |\n",
      "|    policy_gradient_loss | 0.019      |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 2.73e+07   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 982          |\n",
      "|    ep_rew_mean          | -3.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 495          |\n",
      "|    iterations           | 874          |\n",
      "|    time_elapsed         | 3612         |\n",
      "|    total_timesteps      | 1789952      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032900143 |\n",
      "|    clip_fraction        | 0.0359       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.341        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.22e+06     |\n",
      "|    n_updates            | 24640        |\n",
      "|    policy_gradient_loss | 0.00973      |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 2.18e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1790000, episode_reward=-110145.74 +/- 5176.75\n",
      "Episode length: 809.00 +/- 14.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 809         |\n",
      "|    mean_reward          | -1.1e+05    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012654662 |\n",
      "|    clip_fraction        | 0.0147      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.4e+06     |\n",
      "|    n_updates            | 24650       |\n",
      "|    policy_gradient_loss | 0.00183     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.23e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 959       |\n",
      "|    ep_rew_mean     | -3.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 875       |\n",
      "|    time_elapsed    | 3616      |\n",
      "|    total_timesteps | 1792000   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 954          |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 495          |\n",
      "|    iterations           | 876          |\n",
      "|    time_elapsed         | 3618         |\n",
      "|    total_timesteps      | 1794048      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075937877 |\n",
      "|    clip_fraction        | 0.0965       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.02e+07     |\n",
      "|    n_updates            | 24660        |\n",
      "|    policy_gradient_loss | 0.00662      |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 8.3e+07      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1795000, episode_reward=-110229.49 +/- 4594.80\n",
      "Episode length: 819.00 +/- 13.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 819          |\n",
      "|    mean_reward          | -1.1e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1795000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038926464 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.21e+07     |\n",
      "|    n_updates            | 24670        |\n",
      "|    policy_gradient_loss | -0.00507     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 4.28e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 975       |\n",
      "|    ep_rew_mean     | -3.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 877       |\n",
      "|    time_elapsed    | 3622      |\n",
      "|    total_timesteps | 1796096   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 974         |\n",
      "|    ep_rew_mean          | -3.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 3624        |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009000557 |\n",
      "|    clip_fraction        | 0.0441      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.412       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.81e+07    |\n",
      "|    n_updates            | 24680       |\n",
      "|    policy_gradient_loss | 0.000168    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 5.9e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1800000, episode_reward=-14454.17 +/- 64619.82\n",
      "Episode length: 1054.60 +/- 480.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.05e+03     |\n",
      "|    mean_reward          | -1.45e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016957035 |\n",
      "|    clip_fraction        | 0.00474      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.08         |\n",
      "|    explained_variance   | 0.584        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.93e+06     |\n",
      "|    n_updates            | 24690        |\n",
      "|    policy_gradient_loss | -0.00248     |\n",
      "|    std                  | 0.18         |\n",
      "|    value_loss           | 6.14e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 954       |\n",
      "|    ep_rew_mean     | -3.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 879       |\n",
      "|    time_elapsed    | 3628      |\n",
      "|    total_timesteps | 1800192   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 953         |\n",
      "|    ep_rew_mean          | -3.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 880         |\n",
      "|    time_elapsed         | 3630        |\n",
      "|    total_timesteps      | 1802240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004349484 |\n",
      "|    clip_fraction        | 0.0203      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.37e+07    |\n",
      "|    n_updates            | 24700       |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 2.61e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 964         |\n",
      "|    ep_rew_mean          | -3.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 3632        |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004395384 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.65e+03    |\n",
      "|    n_updates            | 24710       |\n",
      "|    policy_gradient_loss | -0.00367    |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.6e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1805000, episode_reward=17186.31 +/- 3657.73\n",
      "Episode length: 1253.80 +/- 13.60\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.25e+03   |\n",
      "|    mean_reward          | 1.72e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1805000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00858555 |\n",
      "|    clip_fraction        | 0.0752     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.08       |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 839        |\n",
      "|    n_updates            | 24720      |\n",
      "|    policy_gradient_loss | -0.00423   |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 2.84e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 963       |\n",
      "|    ep_rew_mean     | -3.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 882       |\n",
      "|    time_elapsed    | 3637      |\n",
      "|    total_timesteps | 1806336   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 956         |\n",
      "|    ep_rew_mean          | -3.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 883         |\n",
      "|    time_elapsed         | 3639        |\n",
      "|    total_timesteps      | 1808384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012372358 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.09        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 779         |\n",
      "|    n_updates            | 24730       |\n",
      "|    policy_gradient_loss | -0.00201    |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 2.38e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1810000, episode_reward=13737.37 +/- 5566.98\n",
      "Episode length: 1225.00 +/- 15.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.22e+03    |\n",
      "|    mean_reward          | 1.37e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005140192 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.09        |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55e+07    |\n",
      "|    n_updates            | 24740       |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 2.31e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 954       |\n",
      "|    ep_rew_mean     | -3.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 884       |\n",
      "|    time_elapsed    | 3643      |\n",
      "|    total_timesteps | 1810432   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 953         |\n",
      "|    ep_rew_mean          | -3.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 885         |\n",
      "|    time_elapsed         | 3645        |\n",
      "|    total_timesteps      | 1812480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018540345 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.09        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 616         |\n",
      "|    n_updates            | 24750       |\n",
      "|    policy_gradient_loss | 0.00588     |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 1.03e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 952         |\n",
      "|    ep_rew_mean          | -3.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 886         |\n",
      "|    time_elapsed         | 3647        |\n",
      "|    total_timesteps      | 1814528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016175872 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.09        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 480         |\n",
      "|    n_updates            | 24760       |\n",
      "|    policy_gradient_loss | 0.00968     |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 6.58e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1815000, episode_reward=-12812.22 +/- 64654.15\n",
      "Episode length: 1043.00 +/- 477.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.04e+03    |\n",
      "|    mean_reward          | -1.28e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1815000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031537507 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.08        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 24770       |\n",
      "|    policy_gradient_loss | -0.00014    |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 3.23e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 943       |\n",
      "|    ep_rew_mean     | -3.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 497       |\n",
      "|    iterations      | 887       |\n",
      "|    time_elapsed    | 3651      |\n",
      "|    total_timesteps | 1816576   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 943       |\n",
      "|    ep_rew_mean          | -3.69e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 497       |\n",
      "|    iterations           | 888       |\n",
      "|    time_elapsed         | 3653      |\n",
      "|    total_timesteps      | 1818624   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.188849  |\n",
      "|    clip_fraction        | 0.387     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.09      |\n",
      "|    explained_variance   | 0.348     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.76e+07  |\n",
      "|    n_updates            | 24780     |\n",
      "|    policy_gradient_loss | 0.024     |\n",
      "|    std                  | 0.179     |\n",
      "|    value_loss           | 2.36e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1820000, episode_reward=16098.43 +/- 2909.48\n",
      "Episode length: 1302.80 +/- 17.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.3e+03     |\n",
      "|    mean_reward          | 1.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021564886 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.09        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 24790       |\n",
      "|    policy_gradient_loss | 0.00947     |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 772         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 950       |\n",
      "|    ep_rew_mean     | -3.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 497       |\n",
      "|    iterations      | 889       |\n",
      "|    time_elapsed    | 3658      |\n",
      "|    total_timesteps | 1820672   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 947        |\n",
      "|    ep_rew_mean          | -3.66e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 497        |\n",
      "|    iterations           | 890        |\n",
      "|    time_elapsed         | 3660       |\n",
      "|    total_timesteps      | 1822720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02586646 |\n",
      "|    clip_fraction        | 0.275      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.09       |\n",
      "|    explained_variance   | 0.762      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.59e+04   |\n",
      "|    n_updates            | 24800      |\n",
      "|    policy_gradient_loss | 0.0097     |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 5e+04      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 960         |\n",
      "|    ep_rew_mean          | -3.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 891         |\n",
      "|    time_elapsed         | 3662        |\n",
      "|    total_timesteps      | 1824768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030500276 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.1         |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.91e+04    |\n",
      "|    n_updates            | 24810       |\n",
      "|    policy_gradient_loss | 0.0223      |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 2.08e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1825000, episode_reward=17742.67 +/- 2768.06\n",
      "Episode length: 1360.00 +/- 10.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.36e+03    |\n",
      "|    mean_reward          | 1.77e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1825000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004083574 |\n",
      "|    clip_fraction        | 0.0243      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.1         |\n",
      "|    explained_variance   | 0.725       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 24820       |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 4.55e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 964      |\n",
      "|    ep_rew_mean     | -3.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 498      |\n",
      "|    iterations      | 892      |\n",
      "|    time_elapsed    | 3667     |\n",
      "|    total_timesteps | 1826816  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 966         |\n",
      "|    ep_rew_mean          | -3.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 3669        |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017923985 |\n",
      "|    clip_fraction        | 0.0883      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+05    |\n",
      "|    n_updates            | 24830       |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 1.99e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1830000, episode_reward=17133.12 +/- 3882.24\n",
      "Episode length: 1377.20 +/- 11.37\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.38e+03     |\n",
      "|    mean_reward          | 1.71e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1830000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034331637 |\n",
      "|    clip_fraction        | 0.024        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.11         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.5e+07      |\n",
      "|    n_updates            | 24840        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    std                  | 0.179        |\n",
      "|    value_loss           | 2.5e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 975       |\n",
      "|    ep_rew_mean     | -3.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 498       |\n",
      "|    iterations      | 894       |\n",
      "|    time_elapsed    | 3674      |\n",
      "|    total_timesteps | 1830912   |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 977           |\n",
      "|    ep_rew_mean          | -3.45e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 498           |\n",
      "|    iterations           | 895           |\n",
      "|    time_elapsed         | 3676          |\n",
      "|    total_timesteps      | 1832960       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00043672725 |\n",
      "|    clip_fraction        | 0.00112       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 3.11          |\n",
      "|    explained_variance   | 0.352         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.68e+07      |\n",
      "|    n_updates            | 24850         |\n",
      "|    policy_gradient_loss | -0.00114      |\n",
      "|    std                  | 0.179         |\n",
      "|    value_loss           | 2.79e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=1835000, episode_reward=-13345.01 +/- 61452.76\n",
      "Episode length: 1125.80 +/- 521.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.13e+03     |\n",
      "|    mean_reward          | -1.33e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1835000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060311817 |\n",
      "|    clip_fraction        | 0.0335       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.11         |\n",
      "|    explained_variance   | 0.813        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+03     |\n",
      "|    n_updates            | 24860        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    std                  | 0.178        |\n",
      "|    value_loss           | 1.6e+04      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 993      |\n",
      "|    ep_rew_mean     | -3.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 498      |\n",
      "|    iterations      | 896      |\n",
      "|    time_elapsed    | 3680     |\n",
      "|    total_timesteps | 1835008  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1e+03      |\n",
      "|    ep_rew_mean          | -3.26e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 498        |\n",
      "|    iterations           | 897        |\n",
      "|    time_elapsed         | 3682       |\n",
      "|    total_timesteps      | 1837056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01086889 |\n",
      "|    clip_fraction        | 0.142      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.11       |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 450        |\n",
      "|    n_updates            | 24870      |\n",
      "|    policy_gradient_loss | -0.00329   |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 4.1e+04    |\n",
      "----------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.01e+03      |\n",
      "|    ep_rew_mean          | -3.13e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 499           |\n",
      "|    iterations           | 898           |\n",
      "|    time_elapsed         | 3684          |\n",
      "|    total_timesteps      | 1839104       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00084565143 |\n",
      "|    clip_fraction        | 0.00264       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 3.11          |\n",
      "|    explained_variance   | 0.373         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.24e+07      |\n",
      "|    n_updates            | 24880         |\n",
      "|    policy_gradient_loss | -0.00182      |\n",
      "|    std                  | 0.178         |\n",
      "|    value_loss           | 1.65e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=15015.97 +/- 4080.75\n",
      "Episode length: 1364.80 +/- 21.61\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.36e+03     |\n",
      "|    mean_reward          | 1.5e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046021705 |\n",
      "|    clip_fraction        | 0.00625      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.11         |\n",
      "|    explained_variance   | 0.415        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.6e+06      |\n",
      "|    n_updates            | 24890        |\n",
      "|    policy_gradient_loss | 0.000185     |\n",
      "|    std                  | 0.178        |\n",
      "|    value_loss           | 1.6e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -3.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 899       |\n",
      "|    time_elapsed    | 3689      |\n",
      "|    total_timesteps | 1841152   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -3.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 3691        |\n",
      "|    total_timesteps      | 1843200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015392956 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.696       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79e+03    |\n",
      "|    n_updates            | 24900       |\n",
      "|    policy_gradient_loss | -0.00384    |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 6.8e+05     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1845000, episode_reward=14264.15 +/- 3510.99\n",
      "Episode length: 1310.00 +/- 10.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.31e+03    |\n",
      "|    mean_reward          | 1.43e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1845000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016796947 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 500         |\n",
      "|    n_updates            | 24910       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 2.01e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 901       |\n",
      "|    time_elapsed    | 3696      |\n",
      "|    total_timesteps | 1845248   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -3.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 902         |\n",
      "|    time_elapsed         | 3698        |\n",
      "|    total_timesteps      | 1847296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019957472 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 210         |\n",
      "|    n_updates            | 24920       |\n",
      "|    policy_gradient_loss | 0.00334     |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 1.54e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.01e+03   |\n",
      "|    ep_rew_mean          | -3.36e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 499        |\n",
      "|    iterations           | 903        |\n",
      "|    time_elapsed         | 3700       |\n",
      "|    total_timesteps      | 1849344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03286451 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.12       |\n",
      "|    explained_variance   | 0.923      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 156        |\n",
      "|    n_updates            | 24930      |\n",
      "|    policy_gradient_loss | 0.00408    |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 3.93e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1850000, episode_reward=15189.70 +/- 4647.54\n",
      "Episode length: 1344.60 +/- 4.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.34e+03    |\n",
      "|    mean_reward          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006932957 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.18e+07    |\n",
      "|    n_updates            | 24940       |\n",
      "|    policy_gradient_loss | 0.000509    |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 5.55e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 904       |\n",
      "|    time_elapsed    | 3705      |\n",
      "|    total_timesteps | 1851392   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -3.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 3706        |\n",
      "|    total_timesteps      | 1853440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005368206 |\n",
      "|    clip_fraction        | 0.0305      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.44e+03    |\n",
      "|    n_updates            | 24950       |\n",
      "|    policy_gradient_loss | -0.00514    |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 5.12e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1855000, episode_reward=15042.21 +/- 2930.27\n",
      "Episode length: 1312.40 +/- 11.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.31e+03    |\n",
      "|    mean_reward          | 1.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1855000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008521482 |\n",
      "|    clip_fraction        | 0.0583      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 24960       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 1.22e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.04e+03  |\n",
      "|    ep_rew_mean     | -3.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 906       |\n",
      "|    time_elapsed    | 3711      |\n",
      "|    total_timesteps | 1855488   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -3.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 907         |\n",
      "|    time_elapsed         | 3713        |\n",
      "|    total_timesteps      | 1857536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007801806 |\n",
      "|    clip_fraction        | 0.082       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.12        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.56e+03    |\n",
      "|    n_updates            | 24970       |\n",
      "|    policy_gradient_loss | -0.00627    |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 2.37e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -3.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 908         |\n",
      "|    time_elapsed         | 3715        |\n",
      "|    total_timesteps      | 1859584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010473078 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.12        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 254         |\n",
      "|    n_updates            | 24980       |\n",
      "|    policy_gradient_loss | -0.000386   |\n",
      "|    std                  | 0.177       |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1860000, episode_reward=8424.30 +/- 6013.93\n",
      "Episode length: 1268.60 +/- 16.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.27e+03    |\n",
      "|    mean_reward          | 8.42e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027013697 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 54          |\n",
      "|    n_updates            | 24990       |\n",
      "|    policy_gradient_loss | 0.0207      |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 238         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.05e+03  |\n",
      "|    ep_rew_mean     | -2.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 909       |\n",
      "|    time_elapsed    | 3720      |\n",
      "|    total_timesteps | 1861632   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -2.53e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 910         |\n",
      "|    time_elapsed         | 3722        |\n",
      "|    total_timesteps      | 1863680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015175419 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+04    |\n",
      "|    n_updates            | 25000       |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 3.95e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1865000, episode_reward=-19337.80 +/- 57791.42\n",
      "Episode length: 912.60 +/- 411.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 913         |\n",
      "|    mean_reward          | -1.93e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1865000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.115974724 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.1         |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 25010       |\n",
      "|    policy_gradient_loss | 0.00674     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.35e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -2.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 911       |\n",
      "|    time_elapsed    | 3726      |\n",
      "|    total_timesteps | 1865728   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -2.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 3728        |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026049664 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.09        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 25020       |\n",
      "|    policy_gradient_loss | 0.00159     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.08e+03   |\n",
      "|    ep_rew_mean          | -2.16e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 501        |\n",
      "|    iterations           | 913        |\n",
      "|    time_elapsed         | 3730       |\n",
      "|    total_timesteps      | 1869824    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02654147 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.08       |\n",
      "|    explained_variance   | 0.782      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.89e+04   |\n",
      "|    n_updates            | 25030      |\n",
      "|    policy_gradient_loss | -0.0011    |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 6.48e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1870000, episode_reward=-16073.19 +/- 57251.86\n",
      "Episode length: 885.40 +/- 399.27\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 885        |\n",
      "|    mean_reward          | -1.61e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1870000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02606643 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.09       |\n",
      "|    explained_variance   | 0.975      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 80.8       |\n",
      "|    n_updates            | 25040      |\n",
      "|    policy_gradient_loss | 0.0041     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 1.61e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.08e+03  |\n",
      "|    ep_rew_mean     | -2.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 914       |\n",
      "|    time_elapsed    | 3734      |\n",
      "|    total_timesteps | 1871872   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -2.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 915         |\n",
      "|    time_elapsed         | 3735        |\n",
      "|    total_timesteps      | 1873920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018798072 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.09        |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+05    |\n",
      "|    n_updates            | 25050       |\n",
      "|    policy_gradient_loss | 0.00532     |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 6.43e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1875000, episode_reward=13812.33 +/- 149.19\n",
      "Episode length: 1119.00 +/- 5.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.12e+03    |\n",
      "|    mean_reward          | 1.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1875000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019108005 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.09        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 25060       |\n",
      "|    policy_gradient_loss | 0.0045      |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 3.77e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.08e+03  |\n",
      "|    ep_rew_mean     | -2.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 916       |\n",
      "|    time_elapsed    | 3740      |\n",
      "|    total_timesteps | 1875968   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.08e+03   |\n",
      "|    ep_rew_mean          | -2.09e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 501        |\n",
      "|    iterations           | 917        |\n",
      "|    time_elapsed         | 3742       |\n",
      "|    total_timesteps      | 1878016    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01128074 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.08       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 53.9       |\n",
      "|    n_updates            | 25070      |\n",
      "|    policy_gradient_loss | 0.00219    |\n",
      "|    std                  | 0.18       |\n",
      "|    value_loss           | 1.39e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1880000, episode_reward=-18631.47 +/- 50904.09\n",
      "Episode length: 941.00 +/- 432.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 941         |\n",
      "|    mean_reward          | -1.86e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023378432 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.09        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 485         |\n",
      "|    n_updates            | 25080       |\n",
      "|    policy_gradient_loss | 0.00122     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 1.61e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.08e+03  |\n",
      "|    ep_rew_mean     | -2.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 918       |\n",
      "|    time_elapsed    | 3746      |\n",
      "|    total_timesteps | 1880064   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -2.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 919         |\n",
      "|    time_elapsed         | 3748        |\n",
      "|    total_timesteps      | 1882112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018049274 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.1         |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.6        |\n",
      "|    n_updates            | 25090       |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    std                  | 0.18        |\n",
      "|    value_loss           | 4.84e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -2.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 3750        |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016434267 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.37e+06    |\n",
      "|    n_updates            | 25100       |\n",
      "|    policy_gradient_loss | 0.000303    |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 1.75e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1885000, episode_reward=9095.50 +/- 4172.52\n",
      "Episode length: 1101.60 +/- 12.96\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.1e+03      |\n",
      "|    mean_reward          | 9.1e+03      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1885000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057735885 |\n",
      "|    clip_fraction        | 0.0549       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.11         |\n",
      "|    explained_variance   | 0.818        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.53e+03     |\n",
      "|    n_updates            | 25110        |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    std                  | 0.179        |\n",
      "|    value_loss           | 1.99e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -2.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 921       |\n",
      "|    time_elapsed    | 3754      |\n",
      "|    total_timesteps | 1886208   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -1.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 3756        |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017548397 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.11        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 243         |\n",
      "|    n_updates            | 25120       |\n",
      "|    policy_gradient_loss | 0.00404     |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 1.25e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1890000, episode_reward=11070.52 +/- 3768.59\n",
      "Episode length: 1103.20 +/- 9.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.1e+03     |\n",
      "|    mean_reward          | 1.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1890000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020333752 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.12        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 25130       |\n",
      "|    policy_gradient_loss | 0.00371     |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 862         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.08e+03  |\n",
      "|    ep_rew_mean     | -1.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 923       |\n",
      "|    time_elapsed    | 3760      |\n",
      "|    total_timesteps | 1890304   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -1.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 3762        |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020407535 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.12        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.1        |\n",
      "|    n_updates            | 25140       |\n",
      "|    policy_gradient_loss | 0.00784     |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 2.76e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -1.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 3764        |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020799426 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.13        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.4        |\n",
      "|    n_updates            | 25150       |\n",
      "|    policy_gradient_loss | 0.0026      |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 7.33e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1895000, episode_reward=13790.06 +/- 157.43\n",
      "Episode length: 1157.60 +/- 9.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.16e+03    |\n",
      "|    mean_reward          | 1.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1895000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029518686 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.13        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.8        |\n",
      "|    n_updates            | 25160       |\n",
      "|    policy_gradient_loss | 0.00602     |\n",
      "|    std                  | 0.179       |\n",
      "|    value_loss           | 305         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.09e+03  |\n",
      "|    ep_rew_mean     | -1.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 926       |\n",
      "|    time_elapsed    | 3769      |\n",
      "|    total_timesteps | 1896448   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | -1.45e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 927          |\n",
      "|    time_elapsed         | 3771         |\n",
      "|    total_timesteps      | 1898496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131296255 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.12         |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 166          |\n",
      "|    n_updates            | 25170        |\n",
      "|    policy_gradient_loss | 0.00481      |\n",
      "|    std                  | 0.178        |\n",
      "|    value_loss           | 1.37e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1900000, episode_reward=12001.85 +/- 2527.88\n",
      "Episode length: 1127.40 +/- 5.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.13e+03    |\n",
      "|    mean_reward          | 1.2e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015283791 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.12        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.1        |\n",
      "|    n_updates            | 25180       |\n",
      "|    policy_gradient_loss | 0.00058     |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 6.2e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.1e+03   |\n",
      "|    ep_rew_mean     | -1.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 928       |\n",
      "|    time_elapsed    | 3775      |\n",
      "|    total_timesteps | 1900544   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.11e+03   |\n",
      "|    ep_rew_mean          | -1.06e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 929        |\n",
      "|    time_elapsed         | 3777       |\n",
      "|    total_timesteps      | 1902592    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03293623 |\n",
      "|    clip_fraction        | 0.353      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.12       |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.34e+07   |\n",
      "|    n_updates            | 25190      |\n",
      "|    policy_gradient_loss | 0.0123     |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 2.62e+07   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.11e+03     |\n",
      "|    ep_rew_mean          | -9.37e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 930          |\n",
      "|    time_elapsed         | 3779         |\n",
      "|    total_timesteps      | 1904640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065213973 |\n",
      "|    clip_fraction        | 0.0237       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.12         |\n",
      "|    explained_variance   | 0.767        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 834          |\n",
      "|    n_updates            | 25200        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    std                  | 0.178        |\n",
      "|    value_loss           | 4.35e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1905000, episode_reward=12411.61 +/- 3226.87\n",
      "Episode length: 1168.60 +/- 11.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.17e+03     |\n",
      "|    mean_reward          | 1.24e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1905000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047498727 |\n",
      "|    clip_fraction        | 0.0653       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.12         |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 253          |\n",
      "|    n_updates            | 25210        |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    std                  | 0.178        |\n",
      "|    value_loss           | 7.06e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -7.92e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 931       |\n",
      "|    time_elapsed    | 3784      |\n",
      "|    total_timesteps | 1906688   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -5.71e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 932         |\n",
      "|    time_elapsed         | 3785        |\n",
      "|    total_timesteps      | 1908736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025602378 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.12        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.39e+04    |\n",
      "|    n_updates            | 25220       |\n",
      "|    policy_gradient_loss | 0.00631     |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 8.8e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1910000, episode_reward=8646.57 +/- 5252.61\n",
      "Episode length: 1187.00 +/- 4.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.19e+03    |\n",
      "|    mean_reward          | 8.65e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018995097 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.12        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65          |\n",
      "|    n_updates            | 25230       |\n",
      "|    policy_gradient_loss | 0.00965     |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 4.15e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -4.69e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 933       |\n",
      "|    time_elapsed    | 3790      |\n",
      "|    total_timesteps | 1910784   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.14e+03   |\n",
      "|    ep_rew_mean          | -2.1e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 934        |\n",
      "|    time_elapsed         | 3792       |\n",
      "|    total_timesteps      | 1912832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02026181 |\n",
      "|    clip_fraction        | 0.218      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.11       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 57.3       |\n",
      "|    n_updates            | 25240      |\n",
      "|    policy_gradient_loss | 0.00931    |\n",
      "|    std                  | 0.179      |\n",
      "|    value_loss           | 560        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -2.03e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 3794        |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015089645 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.12        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 25250       |\n",
      "|    policy_gradient_loss | -2.16e-05   |\n",
      "|    std                  | 0.178       |\n",
      "|    value_loss           | 456         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1915000, episode_reward=11365.68 +/- 3168.16\n",
      "Episode length: 1186.60 +/- 9.77\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.19e+03   |\n",
      "|    mean_reward          | 1.14e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1915000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03516418 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.13       |\n",
      "|    explained_variance   | 0.989      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 77.6       |\n",
      "|    n_updates            | 25260      |\n",
      "|    policy_gradient_loss | 0.00705    |\n",
      "|    std                  | 0.178      |\n",
      "|    value_loss           | 1.49e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.14e+03  |\n",
      "|    ep_rew_mean     | -2.16e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 936       |\n",
      "|    time_elapsed    | 3799      |\n",
      "|    total_timesteps | 1916928   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -2.24e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 3800        |\n",
      "|    total_timesteps      | 1918976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020200942 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.14        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.1        |\n",
      "|    n_updates            | 25270       |\n",
      "|    policy_gradient_loss | 0.00393     |\n",
      "|    std                  | 0.177       |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1920000, episode_reward=14622.49 +/- 2193.69\n",
      "Episode length: 1318.20 +/- 7.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.32e+03    |\n",
      "|    mean_reward          | 1.46e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029306522 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.16        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.6        |\n",
      "|    n_updates            | 25280       |\n",
      "|    policy_gradient_loss | -0.000395   |\n",
      "|    std                  | 0.175       |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.13e+03  |\n",
      "|    ep_rew_mean     | -3.73e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 938       |\n",
      "|    time_elapsed    | 3805      |\n",
      "|    total_timesteps | 1921024   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.13e+03     |\n",
      "|    ep_rew_mean          | -3.78e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 939          |\n",
      "|    time_elapsed         | 3807         |\n",
      "|    total_timesteps      | 1923072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053117527 |\n",
      "|    clip_fraction        | 0.0725       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.17         |\n",
      "|    explained_variance   | 0.29         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.42e+07     |\n",
      "|    n_updates            | 25290        |\n",
      "|    policy_gradient_loss | -0.00153     |\n",
      "|    std                  | 0.175        |\n",
      "|    value_loss           | 4.05e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1925000, episode_reward=11100.53 +/- 5164.76\n",
      "Episode length: 1323.20 +/- 9.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.32e+03    |\n",
      "|    mean_reward          | 1.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1925000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005622764 |\n",
      "|    clip_fraction        | 0.0254      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.17        |\n",
      "|    explained_variance   | 0.747       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.37e+03    |\n",
      "|    n_updates            | 25300       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    std                  | 0.175       |\n",
      "|    value_loss           | 5.63e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.14e+03  |\n",
      "|    ep_rew_mean     | -3.88e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 940       |\n",
      "|    time_elapsed    | 3812      |\n",
      "|    total_timesteps | 1925120   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -3.91e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 941         |\n",
      "|    time_elapsed         | 3814        |\n",
      "|    total_timesteps      | 1927168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007815287 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.17        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 376         |\n",
      "|    n_updates            | 25310       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    std                  | 0.175       |\n",
      "|    value_loss           | 3.48e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -4.04e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 942         |\n",
      "|    time_elapsed         | 3816        |\n",
      "|    total_timesteps      | 1929216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009308118 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.18        |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 201         |\n",
      "|    n_updates            | 25320       |\n",
      "|    policy_gradient_loss | -0.000858   |\n",
      "|    std                  | 0.175       |\n",
      "|    value_loss           | 3.36e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1930000, episode_reward=11985.43 +/- 3048.90\n",
      "Episode length: 1293.20 +/- 14.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.29e+03    |\n",
      "|    mean_reward          | 1.2e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022719614 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.18        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.2        |\n",
      "|    n_updates            | 25330       |\n",
      "|    policy_gradient_loss | 0.00167     |\n",
      "|    std                  | 0.175       |\n",
      "|    value_loss           | 1.99e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.15e+03  |\n",
      "|    ep_rew_mean     | -2.44e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 943       |\n",
      "|    time_elapsed    | 3821      |\n",
      "|    total_timesteps | 1931264   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -2.6e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 944         |\n",
      "|    time_elapsed         | 3823        |\n",
      "|    total_timesteps      | 1933312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026977114 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.18        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.2        |\n",
      "|    n_updates            | 25340       |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    std                  | 0.174       |\n",
      "|    value_loss           | 3.76e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1935000, episode_reward=-12156.34 +/- 54293.93\n",
      "Episode length: 1071.60 +/- 497.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.07e+03    |\n",
      "|    mean_reward          | -1.22e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1935000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018172776 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.18        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 86.9        |\n",
      "|    n_updates            | 25350       |\n",
      "|    policy_gradient_loss | -0.00159    |\n",
      "|    std                  | 0.174       |\n",
      "|    value_loss           | 9.01e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.15e+03 |\n",
      "|    ep_rew_mean     | -3.5e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 945      |\n",
      "|    time_elapsed    | 3827     |\n",
      "|    total_timesteps | 1935360  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -3.47e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 3829        |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020003304 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.18        |\n",
      "|    explained_variance   | 0.322       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.94e+06    |\n",
      "|    n_updates            | 25360       |\n",
      "|    policy_gradient_loss | 0.00691     |\n",
      "|    std                  | 0.174       |\n",
      "|    value_loss           | 1.27e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14e+03    |\n",
      "|    ep_rew_mean          | -3.83e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 947         |\n",
      "|    time_elapsed         | 3831        |\n",
      "|    total_timesteps      | 1939456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005210528 |\n",
      "|    clip_fraction        | 0.0777      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.19        |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.12e+03    |\n",
      "|    n_updates            | 25370       |\n",
      "|    policy_gradient_loss | -0.00677    |\n",
      "|    std                  | 0.174       |\n",
      "|    value_loss           | 1.1e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1940000, episode_reward=11366.11 +/- 5137.90\n",
      "Episode length: 1338.40 +/- 16.64\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.34e+03   |\n",
      "|    mean_reward          | 1.14e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1940000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22646819 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.19       |\n",
      "|    explained_variance   | 0.326      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.63e+06   |\n",
      "|    n_updates            | 25380      |\n",
      "|    policy_gradient_loss | 0.00247    |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 1.76e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.14e+03  |\n",
      "|    ep_rew_mean     | -3.79e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 948       |\n",
      "|    time_elapsed    | 3836      |\n",
      "|    total_timesteps | 1941504   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -2.56e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 3838        |\n",
      "|    total_timesteps      | 1943552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013753479 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.19        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 711         |\n",
      "|    n_updates            | 25390       |\n",
      "|    policy_gradient_loss | -0.00421    |\n",
      "|    std                  | 0.174       |\n",
      "|    value_loss           | 1.6e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1945000, episode_reward=14734.37 +/- 2969.38\n",
      "Episode length: 1337.20 +/- 8.01\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.34e+03   |\n",
      "|    mean_reward          | 1.47e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1945000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04609036 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.2        |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 46.7       |\n",
      "|    n_updates            | 25400      |\n",
      "|    policy_gradient_loss | 0.0136     |\n",
      "|    std                  | 0.174      |\n",
      "|    value_loss           | 1.98e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.15e+03  |\n",
      "|    ep_rew_mean     | -1.06e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 950       |\n",
      "|    time_elapsed    | 3843      |\n",
      "|    total_timesteps | 1945600   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -1.16e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 3845        |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017847577 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.21        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.6        |\n",
      "|    n_updates            | 25410       |\n",
      "|    policy_gradient_loss | 0.00497     |\n",
      "|    std                  | 0.174       |\n",
      "|    value_loss           | 1.43e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -1.19e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 3847        |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051586173 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.21        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.8        |\n",
      "|    n_updates            | 25420       |\n",
      "|    policy_gradient_loss | 0.00948     |\n",
      "|    std                  | 0.173       |\n",
      "|    value_loss           | 146         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1950000, episode_reward=15996.44 +/- 3135.90\n",
      "Episode length: 1597.80 +/- 5.38\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.6e+03    |\n",
      "|    mean_reward          | 1.6e+04    |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1950000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02201953 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.22       |\n",
      "|    explained_variance   | 0.976      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 45.3       |\n",
      "|    n_updates            | 25430      |\n",
      "|    policy_gradient_loss | 0.00661    |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 3.75e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.15e+03  |\n",
      "|    ep_rew_mean     | -1.18e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 953       |\n",
      "|    time_elapsed    | 3853      |\n",
      "|    total_timesteps | 1951744   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.16e+03   |\n",
      "|    ep_rew_mean          | -261       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 506        |\n",
      "|    iterations           | 954        |\n",
      "|    time_elapsed         | 3854       |\n",
      "|    total_timesteps      | 1953792    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09183968 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.23       |\n",
      "|    explained_variance   | 0.738      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.11e+03   |\n",
      "|    n_updates            | 25440      |\n",
      "|    policy_gradient_loss | 0.00647    |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 7.67e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1955000, episode_reward=11946.72 +/- 4975.25\n",
      "Episode length: 2147.20 +/- 14.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.15e+03    |\n",
      "|    mean_reward          | 1.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1955000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038964316 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 25450       |\n",
      "|    policy_gradient_loss | 0.0131      |\n",
      "|    std                  | 0.17        |\n",
      "|    value_loss           | 243         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.17e+03 |\n",
      "|    ep_rew_mean     | -207     |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 955      |\n",
      "|    time_elapsed    | 3861     |\n",
      "|    total_timesteps | 1955840  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 3863        |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013870209 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.25        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48          |\n",
      "|    n_updates            | 25460       |\n",
      "|    policy_gradient_loss | 0.00318     |\n",
      "|    std                  | 0.17        |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | 1.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 957         |\n",
      "|    time_elapsed         | 3865        |\n",
      "|    total_timesteps      | 1959936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026515434 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.23        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.7        |\n",
      "|    n_updates            | 25470       |\n",
      "|    policy_gradient_loss | 0.00343     |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 75.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1960000, episode_reward=16097.75 +/- 2214.45\n",
      "Episode length: 1350.80 +/- 8.82\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.35e+03   |\n",
      "|    mean_reward          | 1.61e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1960000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03445007 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.21       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 24         |\n",
      "|    n_updates            | 25480      |\n",
      "|    policy_gradient_loss | 0.00221    |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 185        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.18e+03 |\n",
      "|    ep_rew_mean     | 1.03e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 958      |\n",
      "|    time_elapsed    | 3870     |\n",
      "|    total_timesteps | 1961984  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -2.48e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 959         |\n",
      "|    time_elapsed         | 3872        |\n",
      "|    total_timesteps      | 1964032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026983831 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.2         |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.3        |\n",
      "|    n_updates            | 25490       |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 7.17e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1965000, episode_reward=17782.47 +/- 1637.14\n",
      "Episode length: 1452.60 +/- 5.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.45e+03    |\n",
      "|    mean_reward          | 1.78e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1965000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016846102 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.2         |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.91e+07    |\n",
      "|    n_updates            | 25500       |\n",
      "|    policy_gradient_loss | 0.0149      |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 6.55e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.19e+03  |\n",
      "|    ep_rew_mean     | -2.43e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 960       |\n",
      "|    time_elapsed    | 3877      |\n",
      "|    total_timesteps | 1966080   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.19e+03     |\n",
      "|    ep_rew_mean          | -803         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 961          |\n",
      "|    time_elapsed         | 3879         |\n",
      "|    total_timesteps      | 1968128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038951887 |\n",
      "|    clip_fraction        | 0.0104       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.2          |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.68e+03     |\n",
      "|    n_updates            | 25510        |\n",
      "|    policy_gradient_loss | -0.00555     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 4.14e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1970000, episode_reward=19462.53 +/- 1610.44\n",
      "Episode length: 1580.20 +/- 3.66\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.58e+03     |\n",
      "|    mean_reward          | 1.95e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1970000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040928004 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.2          |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.71e+03     |\n",
      "|    n_updates            | 25520        |\n",
      "|    policy_gradient_loss | -0.00747     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 1.93e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.2e+03  |\n",
      "|    ep_rew_mean     | 650      |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 962      |\n",
      "|    time_elapsed    | 3885     |\n",
      "|    total_timesteps | 1970176  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | 653          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 963          |\n",
      "|    time_elapsed         | 3887         |\n",
      "|    total_timesteps      | 1972224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036786732 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.2          |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17e+03     |\n",
      "|    n_updates            | 25530        |\n",
      "|    policy_gradient_loss | -0.00101     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 2.6e+04      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | 677          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 964          |\n",
      "|    time_elapsed         | 3889         |\n",
      "|    total_timesteps      | 1974272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022274684 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.2          |\n",
      "|    explained_variance   | 0.978        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 413          |\n",
      "|    n_updates            | 25540        |\n",
      "|    policy_gradient_loss | -0.000613    |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 1.12e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=1975000, episode_reward=19642.81 +/- 978.69\n",
      "Episode length: 1576.00 +/- 8.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.58e+03    |\n",
      "|    mean_reward          | 1.96e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1975000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032209598 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.2         |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94.8        |\n",
      "|    n_updates            | 25550       |\n",
      "|    policy_gradient_loss | 0.00254     |\n",
      "|    std                  | 0.173       |\n",
      "|    value_loss           | 1.96e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.21e+03 |\n",
      "|    ep_rew_mean     | 653      |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 965      |\n",
      "|    time_elapsed    | 3894     |\n",
      "|    total_timesteps | 1976320  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | 635         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 3896        |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008575473 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.2         |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 467         |\n",
      "|    n_updates            | 25560       |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 1.58e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1980000, episode_reward=16042.95 +/- 4478.23\n",
      "Episode length: 1447.00 +/- 18.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.45e+03    |\n",
      "|    mean_reward          | 1.6e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041928872 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.5        |\n",
      "|    n_updates            | 25570       |\n",
      "|    policy_gradient_loss | 0.00895     |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.21e+03 |\n",
      "|    ep_rew_mean     | 697      |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 967      |\n",
      "|    time_elapsed    | 3901     |\n",
      "|    total_timesteps | 1980416  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 747         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 968         |\n",
      "|    time_elapsed         | 3903        |\n",
      "|    total_timesteps      | 1982464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047460597 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.21        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 25580       |\n",
      "|    policy_gradient_loss | 0.00762     |\n",
      "|    std                  | 0.173       |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.22e+03    |\n",
      "|    ep_rew_mean          | 905         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 969         |\n",
      "|    time_elapsed         | 3905        |\n",
      "|    total_timesteps      | 1984512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020920014 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.21        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.6        |\n",
      "|    n_updates            | 25590       |\n",
      "|    policy_gradient_loss | 0.00141     |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 216         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1985000, episode_reward=18846.98 +/- 1454.78\n",
      "Episode length: 1664.00 +/- 7.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.66e+03    |\n",
      "|    mean_reward          | 1.88e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1985000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014655411 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.21        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 74.4        |\n",
      "|    n_updates            | 25600       |\n",
      "|    policy_gradient_loss | 0.00307     |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 1.52e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.23e+03 |\n",
      "|    ep_rew_mean     | 902      |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 970      |\n",
      "|    time_elapsed    | 3911     |\n",
      "|    total_timesteps | 1986560  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | 917         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 3913        |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019663054 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.4        |\n",
      "|    n_updates            | 25610       |\n",
      "|    policy_gradient_loss | 0.00794     |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 9.24e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1990000, episode_reward=-3979.46 +/- 6150.01\n",
      "Episode length: 2477.20 +/- 19.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.48e+03    |\n",
      "|    mean_reward          | -3.98e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1990000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011620433 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.5        |\n",
      "|    n_updates            | 25620       |\n",
      "|    policy_gradient_loss | 0.000945    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 329         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.24e+03 |\n",
      "|    ep_rew_mean     | 952      |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 972      |\n",
      "|    time_elapsed    | 3921     |\n",
      "|    total_timesteps | 1990656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.26e+03    |\n",
      "|    ep_rew_mean          | -75.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 3922        |\n",
      "|    total_timesteps      | 1992704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004219189 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.37e+03    |\n",
      "|    n_updates            | 25630       |\n",
      "|    policy_gradient_loss | 0.00237     |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 1.97e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.27e+03     |\n",
      "|    ep_rew_mean          | -3.37e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 974          |\n",
      "|    time_elapsed         | 3924         |\n",
      "|    total_timesteps      | 1994752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004088476 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.22         |\n",
      "|    explained_variance   | 0.274        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.3e+03      |\n",
      "|    n_updates            | 25640        |\n",
      "|    policy_gradient_loss | -0.000957    |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 1.85e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1995000, episode_reward=-61130.42 +/- 35891.42\n",
      "Episode length: 1958.40 +/- 934.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.96e+03     |\n",
      "|    mean_reward          | -6.11e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1995000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027232482 |\n",
      "|    clip_fraction        | 0.0102       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.22         |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.27e+07     |\n",
      "|    n_updates            | 25650        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 7.33e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.27e+03  |\n",
      "|    ep_rew_mean     | -4.46e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 975       |\n",
      "|    time_elapsed    | 3931      |\n",
      "|    total_timesteps | 1996800   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.27e+03    |\n",
      "|    ep_rew_mean          | -4.32e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 3933        |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004194714 |\n",
      "|    clip_fraction        | 0.0535      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.47e+06    |\n",
      "|    n_updates            | 25660       |\n",
      "|    policy_gradient_loss | -0.00155    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 1.85e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2000000, episode_reward=12106.76 +/- 5146.30\n",
      "Episode length: 2472.80 +/- 18.04\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.47e+03     |\n",
      "|    mean_reward          | 1.21e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2000000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051045157 |\n",
      "|    clip_fraction        | 0.0116       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.22         |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 963          |\n",
      "|    n_updates            | 25670        |\n",
      "|    policy_gradient_loss | -0.00292     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 1.58e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.29e+03  |\n",
      "|    ep_rew_mean     | -5.38e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 977       |\n",
      "|    time_elapsed    | 3940      |\n",
      "|    total_timesteps | 2000896   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | -5.27e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 978         |\n",
      "|    time_elapsed         | 3942        |\n",
      "|    total_timesteps      | 2002944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002673911 |\n",
      "|    clip_fraction        | 0.0139      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02e+07    |\n",
      "|    n_updates            | 25680       |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 1.83e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.3e+03    |\n",
      "|    ep_rew_mean          | -5.18e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 508        |\n",
      "|    iterations           | 979        |\n",
      "|    time_elapsed         | 3944       |\n",
      "|    total_timesteps      | 2004992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00539063 |\n",
      "|    clip_fraction        | 0.071      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.22       |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.36e+04   |\n",
      "|    n_updates            | 25690      |\n",
      "|    policy_gradient_loss | -0.00597   |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 9.29e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2005000, episode_reward=14009.55 +/- 135.06\n",
      "Episode length: 2289.60 +/- 5.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.29e+03    |\n",
      "|    mean_reward          | 1.4e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2005000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008341193 |\n",
      "|    clip_fraction        | 0.0985      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 25700       |\n",
      "|    policy_gradient_loss | -0.00414    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 750         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.31e+03  |\n",
      "|    ep_rew_mean     | -5.05e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 980       |\n",
      "|    time_elapsed    | 3951      |\n",
      "|    total_timesteps | 2007040   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | -5.01e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 3953        |\n",
      "|    total_timesteps      | 2009088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010105398 |\n",
      "|    clip_fraction        | 0.0927      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 546         |\n",
      "|    n_updates            | 25710       |\n",
      "|    policy_gradient_loss | -0.00379    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 1.2e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2010000, episode_reward=-11403.07 +/- 59195.92\n",
      "Episode length: 1489.80 +/- 703.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.49e+03    |\n",
      "|    mean_reward          | -1.14e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010444786 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.9        |\n",
      "|    n_updates            | 25720       |\n",
      "|    policy_gradient_loss | 0.00165     |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 4.55e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.33e+03  |\n",
      "|    ep_rew_mean     | -6.02e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 982       |\n",
      "|    time_elapsed    | 3958      |\n",
      "|    total_timesteps | 2011136   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.33e+03     |\n",
      "|    ep_rew_mean          | -7.12e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 983          |\n",
      "|    time_elapsed         | 3960         |\n",
      "|    total_timesteps      | 2013184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055070305 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.22         |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.24e+07     |\n",
      "|    n_updates            | 25730        |\n",
      "|    policy_gradient_loss | 0.00213      |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 1.92e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2015000, episode_reward=-14236.77 +/- 57266.44\n",
      "Episode length: 1511.60 +/- 715.86\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 1.51e+03      |\n",
      "|    mean_reward          | -1.42e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 2015000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00028147863 |\n",
      "|    clip_fraction        | 0.00229       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 3.22          |\n",
      "|    explained_variance   | 0.37          |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.9e+06       |\n",
      "|    n_updates            | 25740         |\n",
      "|    policy_gradient_loss | -0.000281     |\n",
      "|    std                  | 0.172         |\n",
      "|    value_loss           | 2.23e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -8.44e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 984       |\n",
      "|    time_elapsed    | 3966      |\n",
      "|    total_timesteps | 2015232   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.34e+03     |\n",
      "|    ep_rew_mean          | -1.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 985          |\n",
      "|    time_elapsed         | 3968         |\n",
      "|    total_timesteps      | 2017280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030910554 |\n",
      "|    clip_fraction        | 0.0108       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.22         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.45e+07     |\n",
      "|    n_updates            | 25750        |\n",
      "|    policy_gradient_loss | -0.00438     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 4.9e+07      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.34e+03     |\n",
      "|    ep_rew_mean          | -1.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 986          |\n",
      "|    time_elapsed         | 3970         |\n",
      "|    total_timesteps      | 2019328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015080324 |\n",
      "|    clip_fraction        | 0.0147       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.22         |\n",
      "|    explained_variance   | 0.347        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.19e+07     |\n",
      "|    n_updates            | 25760        |\n",
      "|    policy_gradient_loss | -7.69e-05    |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 3.81e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2020000, episode_reward=-10913.02 +/- 58660.58\n",
      "Episode length: 1610.20 +/- 763.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.61e+03    |\n",
      "|    mean_reward          | -1.09e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003341942 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.3e+07     |\n",
      "|    n_updates            | 25770       |\n",
      "|    policy_gradient_loss | -0.00221    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 4.11e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -1.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 987       |\n",
      "|    time_elapsed    | 3975      |\n",
      "|    total_timesteps | 2021376   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.36e+03     |\n",
      "|    ep_rew_mean          | -1.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 988          |\n",
      "|    time_elapsed         | 3977         |\n",
      "|    total_timesteps      | 2023424      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037059528 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.22         |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12e+06     |\n",
      "|    n_updates            | 25780        |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 2.38e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2025000, episode_reward=14450.12 +/- 5996.20\n",
      "Episode length: 2061.20 +/- 9.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.06e+03     |\n",
      "|    mean_reward          | 1.45e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2025000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041992087 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.22         |\n",
      "|    explained_variance   | 0.302        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.72e+06     |\n",
      "|    n_updates            | 25790        |\n",
      "|    policy_gradient_loss | -0.00244     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 3.27e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.35e+03  |\n",
      "|    ep_rew_mean     | -1.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 989       |\n",
      "|    time_elapsed    | 3984      |\n",
      "|    total_timesteps | 2025472   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | -1.96e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 3986        |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011984274 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.61e+06    |\n",
      "|    n_updates            | 25800       |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 3.4e+07     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.37e+03     |\n",
      "|    ep_rew_mean          | -2.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 991          |\n",
      "|    time_elapsed         | 3987         |\n",
      "|    total_timesteps      | 2029568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045513604 |\n",
      "|    clip_fraction        | 0.0142       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.23         |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.44e+07     |\n",
      "|    n_updates            | 25810        |\n",
      "|    policy_gradient_loss | -0.00731     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 2.91e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2030000, episode_reward=-19986.79 +/- 1536.14\n",
      "Episode length: 2513.00 +/- 3.41\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.51e+03     |\n",
      "|    mean_reward          | -2e+04       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2030000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026617586 |\n",
      "|    clip_fraction        | 0.00576      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.22         |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.02e+07     |\n",
      "|    n_updates            | 25820        |\n",
      "|    policy_gradient_loss | -0.00136     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 2.02e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.37e+03  |\n",
      "|    ep_rew_mean     | -2.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 992       |\n",
      "|    time_elapsed    | 3995      |\n",
      "|    total_timesteps | 2031616   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | -2.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 993         |\n",
      "|    time_elapsed         | 3997        |\n",
      "|    total_timesteps      | 2033664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004131944 |\n",
      "|    clip_fraction        | 0.0301      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.35        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.29e+07    |\n",
      "|    n_updates            | 25830       |\n",
      "|    policy_gradient_loss | -0.0034     |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 2.69e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2035000, episode_reward=-25491.19 +/- 2286.86\n",
      "Episode length: 2476.20 +/- 10.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.48e+03    |\n",
      "|    mean_reward          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2035000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005957706 |\n",
      "|    clip_fraction        | 0.0216      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.23        |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.89e+05    |\n",
      "|    n_updates            | 25840       |\n",
      "|    policy_gradient_loss | -0.00498    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 2.24e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.38e+03  |\n",
      "|    ep_rew_mean     | -2.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 994       |\n",
      "|    time_elapsed    | 4005      |\n",
      "|    total_timesteps | 2035712   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.4e+03      |\n",
      "|    ep_rew_mean          | -2.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 995          |\n",
      "|    time_elapsed         | 4007         |\n",
      "|    total_timesteps      | 2037760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0082537895 |\n",
      "|    clip_fraction        | 0.0274       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.23         |\n",
      "|    explained_variance   | 0.601        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.3e+06      |\n",
      "|    n_updates            | 25850        |\n",
      "|    policy_gradient_loss | -0.00314     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 7.13e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | -2.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 4009        |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013403634 |\n",
      "|    clip_fraction        | 0.0482      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.23        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.72e+06    |\n",
      "|    n_updates            | 25860       |\n",
      "|    policy_gradient_loss | -0.00431    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 6.14e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2040000, episode_reward=-13518.05 +/- 3781.16\n",
      "Episode length: 2477.80 +/- 12.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.48e+03     |\n",
      "|    mean_reward          | -1.35e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2040000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067273267 |\n",
      "|    clip_fraction        | 0.0751       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.23         |\n",
      "|    explained_variance   | 0.974        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 496          |\n",
      "|    n_updates            | 25870        |\n",
      "|    policy_gradient_loss | -0.0028      |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 1.31e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.42e+03  |\n",
      "|    ep_rew_mean     | -2.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 997       |\n",
      "|    time_elapsed    | 4016      |\n",
      "|    total_timesteps | 2041856   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | -2.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 4018        |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007337954 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.23        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 25880       |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 2.58e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2045000, episode_reward=-29375.66 +/- 3500.38\n",
      "Episode length: 2412.20 +/- 12.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.41e+03    |\n",
      "|    mean_reward          | -2.94e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2045000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007984526 |\n",
      "|    clip_fraction        | 0.0843      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.23        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 555         |\n",
      "|    n_updates            | 25890       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 7.08e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -2.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 999       |\n",
      "|    time_elapsed    | 4026      |\n",
      "|    total_timesteps | 2045952   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | -2.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1000         |\n",
      "|    time_elapsed         | 4028         |\n",
      "|    total_timesteps      | 2048000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038346746 |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.23         |\n",
      "|    explained_variance   | 0.335        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.16e+07     |\n",
      "|    n_updates            | 25900        |\n",
      "|    policy_gradient_loss | -0.00281     |\n",
      "|    std                  | 0.171        |\n",
      "|    value_loss           | 2.71e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2050000, episode_reward=3532.17 +/- 4382.89\n",
      "Episode length: 2367.40 +/- 17.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.37e+03     |\n",
      "|    mean_reward          | 3.53e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2050000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095780995 |\n",
      "|    clip_fraction        | 0.0442       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.23         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.49e+03     |\n",
      "|    n_updates            | 25910        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    std                  | 0.171        |\n",
      "|    value_loss           | 1.29e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -2.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1001      |\n",
      "|    time_elapsed    | 4035      |\n",
      "|    total_timesteps | 2050048   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | -2.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1002        |\n",
      "|    time_elapsed         | 4037        |\n",
      "|    total_timesteps      | 2052096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005413111 |\n",
      "|    clip_fraction        | 0.0485      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11e+07    |\n",
      "|    n_updates            | 25920       |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 1.45e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | -2.77e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1003        |\n",
      "|    time_elapsed         | 4039        |\n",
      "|    total_timesteps      | 2054144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004018942 |\n",
      "|    clip_fraction        | 0.00752     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.06e+05    |\n",
      "|    n_updates            | 25930       |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 1.38e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2055000, episode_reward=27120.23 +/- 2436.71\n",
      "Episode length: 2399.80 +/- 10.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.4e+03     |\n",
      "|    mean_reward          | 2.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2055000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004053928 |\n",
      "|    clip_fraction        | 0.0272      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.61e+07    |\n",
      "|    n_updates            | 25940       |\n",
      "|    policy_gradient_loss | 0.000553    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 5.55e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -2.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 1004      |\n",
      "|    time_elapsed    | 4046      |\n",
      "|    total_timesteps | 2056192   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -3.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 4048        |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006701838 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.692       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+06    |\n",
      "|    n_updates            | 25950       |\n",
      "|    policy_gradient_loss | -0.00138    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 2.91e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2060000, episode_reward=25115.30 +/- 4409.63\n",
      "Episode length: 2381.60 +/- 5.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.38e+03     |\n",
      "|    mean_reward          | 2.51e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2060000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029544644 |\n",
      "|    clip_fraction        | 0.0332       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.24         |\n",
      "|    explained_variance   | 0.309        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.93e+07     |\n",
      "|    n_updates            | 25960        |\n",
      "|    policy_gradient_loss | -0.00092     |\n",
      "|    std                  | 0.171        |\n",
      "|    value_loss           | 1.11e+08     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -3.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1006      |\n",
      "|    time_elapsed    | 4056      |\n",
      "|    total_timesteps | 2060288   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | -3.27e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 4058         |\n",
      "|    total_timesteps      | 2062336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050256914 |\n",
      "|    clip_fraction        | 0.0413       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.24         |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.51e+03     |\n",
      "|    n_updates            | 25970        |\n",
      "|    policy_gradient_loss | -0.00355     |\n",
      "|    std                  | 0.171        |\n",
      "|    value_loss           | 2.19e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -3.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1008         |\n",
      "|    time_elapsed         | 4059         |\n",
      "|    total_timesteps      | 2064384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142807895 |\n",
      "|    clip_fraction        | 0.107        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.24         |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 762          |\n",
      "|    n_updates            | 25980        |\n",
      "|    policy_gradient_loss | 1.08e-06     |\n",
      "|    std                  | 0.171        |\n",
      "|    value_loss           | 1.39e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2065000, episode_reward=1061.18 +/- 5007.17\n",
      "Episode length: 2545.00 +/- 17.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.54e+03    |\n",
      "|    mean_reward          | 1.06e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2065000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005815584 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 651         |\n",
      "|    n_updates            | 25990       |\n",
      "|    policy_gradient_loss | -0.000201   |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 4.07e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -3.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1009      |\n",
      "|    time_elapsed    | 4067      |\n",
      "|    total_timesteps | 2066432   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53e+03    |\n",
      "|    ep_rew_mean          | -3.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 4069        |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006753182 |\n",
      "|    clip_fraction        | 0.088       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.44e+03    |\n",
      "|    n_updates            | 26000       |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 4.05e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2070000, episode_reward=21595.44 +/- 3994.81\n",
      "Episode length: 2605.40 +/- 14.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.61e+03    |\n",
      "|    mean_reward          | 2.16e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005070994 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.39e+07    |\n",
      "|    n_updates            | 26010       |\n",
      "|    policy_gradient_loss | -0.000136   |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 7.05e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.55e+03  |\n",
      "|    ep_rew_mean     | -3.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1011      |\n",
      "|    time_elapsed    | 4077      |\n",
      "|    total_timesteps | 2070528   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | -3.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1012         |\n",
      "|    time_elapsed         | 4079         |\n",
      "|    total_timesteps      | 2072576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047947867 |\n",
      "|    clip_fraction        | 0.042        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.24         |\n",
      "|    explained_variance   | 0.945        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 655          |\n",
      "|    n_updates            | 26020        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    std                  | 0.171        |\n",
      "|    value_loss           | 2.78e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -3.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1013        |\n",
      "|    time_elapsed         | 4081        |\n",
      "|    total_timesteps      | 2074624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010232899 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.383       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.93e+06    |\n",
      "|    n_updates            | 26030       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 2.17e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2075000, episode_reward=28743.21 +/- 789.92\n",
      "Episode length: 2592.00 +/- 11.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.59e+03    |\n",
      "|    mean_reward          | 2.87e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2075000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012125927 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 274         |\n",
      "|    n_updates            | 26040       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -3.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1014      |\n",
      "|    time_elapsed    | 4089      |\n",
      "|    total_timesteps | 2076672   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.59e+03     |\n",
      "|    ep_rew_mean          | -3.64e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1015         |\n",
      "|    time_elapsed         | 4091         |\n",
      "|    total_timesteps      | 2078720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055695875 |\n",
      "|    clip_fraction        | 0.0679       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.24         |\n",
      "|    explained_variance   | 0.928        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 797          |\n",
      "|    n_updates            | 26050        |\n",
      "|    policy_gradient_loss | -0.00066     |\n",
      "|    std                  | 0.171        |\n",
      "|    value_loss           | 3.77e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2080000, episode_reward=28632.63 +/- 396.25\n",
      "Episode length: 2498.60 +/- 17.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.5e+03     |\n",
      "|    mean_reward          | 2.86e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006823562 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 740         |\n",
      "|    n_updates            | 26060       |\n",
      "|    policy_gradient_loss | 0.00175     |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 3.62e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -3.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1016      |\n",
      "|    time_elapsed    | 4099      |\n",
      "|    total_timesteps | 2080768   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -3.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1017        |\n",
      "|    time_elapsed         | 4101        |\n",
      "|    total_timesteps      | 2082816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020532943 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.23        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.1        |\n",
      "|    n_updates            | 26070       |\n",
      "|    policy_gradient_loss | 0.00762     |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 3.74e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | -3.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1018        |\n",
      "|    time_elapsed         | 4102        |\n",
      "|    total_timesteps      | 2084864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028726496 |\n",
      "|    clip_fraction        | 0.466       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.79e+05    |\n",
      "|    n_updates            | 26080       |\n",
      "|    policy_gradient_loss | 0.023       |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 6.32e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2085000, episode_reward=25072.31 +/- 3951.59\n",
      "Episode length: 2553.00 +/- 13.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.55e+03    |\n",
      "|    mean_reward          | 2.51e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2085000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024443526 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.18e+03    |\n",
      "|    n_updates            | 26090       |\n",
      "|    policy_gradient_loss | -0.000498   |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 1.71e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -3.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1019      |\n",
      "|    time_elapsed    | 4110      |\n",
      "|    total_timesteps | 2086912   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.64e+03   |\n",
      "|    ep_rew_mean          | -3.49e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 507        |\n",
      "|    iterations           | 1020       |\n",
      "|    time_elapsed         | 4112       |\n",
      "|    total_timesteps      | 2088960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05763333 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.22       |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.24e+06   |\n",
      "|    n_updates            | 26100      |\n",
      "|    policy_gradient_loss | 0.0107     |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 1.57e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2090000, episode_reward=29352.35 +/- 2258.19\n",
      "Episode length: 2510.60 +/- 11.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.51e+03    |\n",
      "|    mean_reward          | 2.94e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007066055 |\n",
      "|    clip_fraction        | 0.0554      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.737       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.18e+04    |\n",
      "|    n_updates            | 26110       |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 6.63e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -3.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1021      |\n",
      "|    time_elapsed    | 4120      |\n",
      "|    total_timesteps | 2091008   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.65e+03     |\n",
      "|    ep_rew_mean          | -3.46e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 1022         |\n",
      "|    time_elapsed         | 4122         |\n",
      "|    total_timesteps      | 2093056      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051699285 |\n",
      "|    clip_fraction        | 0.0427       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.22         |\n",
      "|    explained_variance   | 0.814        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 965          |\n",
      "|    n_updates            | 26120        |\n",
      "|    policy_gradient_loss | -0.000672    |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 1.71e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2095000, episode_reward=27417.59 +/- 3063.55\n",
      "Episode length: 2246.00 +/- 10.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.25e+03    |\n",
      "|    mean_reward          | 2.74e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2095000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009679846 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 317         |\n",
      "|    n_updates            | 26130       |\n",
      "|    policy_gradient_loss | -0.00178    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 2.28e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -3.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1023      |\n",
      "|    time_elapsed    | 4129      |\n",
      "|    total_timesteps | 2095104   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.66e+03    |\n",
      "|    ep_rew_mean          | -3.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1024        |\n",
      "|    time_elapsed         | 4131        |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011316464 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.3        |\n",
      "|    n_updates            | 26140       |\n",
      "|    policy_gradient_loss | -0.00411    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 2.51e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -3.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1025        |\n",
      "|    time_elapsed         | 4133        |\n",
      "|    total_timesteps      | 2099200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015881175 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 196         |\n",
      "|    n_updates            | 26150       |\n",
      "|    policy_gradient_loss | 0.000511    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 946         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2100000, episode_reward=32344.29 +/- 3877.71\n",
      "Episode length: 2466.40 +/- 10.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.47e+03    |\n",
      "|    mean_reward          | 3.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012295239 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.21        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.4        |\n",
      "|    n_updates            | 26160       |\n",
      "|    policy_gradient_loss | 0.000982    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 6.01e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.68e+03  |\n",
      "|    ep_rew_mean     | -3.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1026      |\n",
      "|    time_elapsed    | 4141      |\n",
      "|    total_timesteps | 2101248   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.68e+03    |\n",
      "|    ep_rew_mean          | -3.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1027        |\n",
      "|    time_elapsed         | 4142        |\n",
      "|    total_timesteps      | 2103296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022009606 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.21        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 57.5        |\n",
      "|    n_updates            | 26170       |\n",
      "|    policy_gradient_loss | 0.0119      |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 7.25e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2105000, episode_reward=31835.02 +/- 2197.29\n",
      "Episode length: 2367.40 +/- 10.09\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.37e+03   |\n",
      "|    mean_reward          | 3.18e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2105000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00857418 |\n",
      "|    clip_fraction        | 0.0502     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.21       |\n",
      "|    explained_variance   | 0.604      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.15e+05   |\n",
      "|    n_updates            | 26180      |\n",
      "|    policy_gradient_loss | 0.000411   |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 2.2e+06    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -3.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1028      |\n",
      "|    time_elapsed    | 4150      |\n",
      "|    total_timesteps | 2105344   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -3.5e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1029        |\n",
      "|    time_elapsed         | 4152        |\n",
      "|    total_timesteps      | 2107392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003099951 |\n",
      "|    clip_fraction        | 0.0226      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.21        |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.87e+06    |\n",
      "|    n_updates            | 26190       |\n",
      "|    policy_gradient_loss | -0.0073     |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 2.29e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.7e+03      |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 1030         |\n",
      "|    time_elapsed         | 4154         |\n",
      "|    total_timesteps      | 2109440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076494967 |\n",
      "|    clip_fraction        | 0.0651       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.21         |\n",
      "|    explained_variance   | 0.919        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.47e+03     |\n",
      "|    n_updates            | 26200        |\n",
      "|    policy_gradient_loss | -0.00232     |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 1.08e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2110000, episode_reward=33322.20 +/- 1486.09\n",
      "Episode length: 2376.00 +/- 13.64\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.38e+03   |\n",
      "|    mean_reward          | 3.33e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2110000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00848953 |\n",
      "|    clip_fraction        | 0.0562     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.21       |\n",
      "|    explained_variance   | 0.922      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 69.5       |\n",
      "|    n_updates            | 26210      |\n",
      "|    policy_gradient_loss | -0.00276   |\n",
      "|    std                  | 0.172      |\n",
      "|    value_loss           | 1.68e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.72e+03  |\n",
      "|    ep_rew_mean     | -3.43e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1031      |\n",
      "|    time_elapsed    | 4161      |\n",
      "|    total_timesteps | 2111488   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.72e+03     |\n",
      "|    ep_rew_mean          | -3.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 1032         |\n",
      "|    time_elapsed         | 4163         |\n",
      "|    total_timesteps      | 2113536      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071069803 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.21         |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.93e+06     |\n",
      "|    n_updates            | 26220        |\n",
      "|    policy_gradient_loss | 0.00127      |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 1.64e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2115000, episode_reward=31996.56 +/- 3065.58\n",
      "Episode length: 2389.00 +/- 18.59\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.39e+03     |\n",
      "|    mean_reward          | 3.2e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2115000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058387415 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.21         |\n",
      "|    explained_variance   | 0.72         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.06e+03     |\n",
      "|    n_updates            | 26230        |\n",
      "|    policy_gradient_loss | -5.86e-05    |\n",
      "|    std                  | 0.172        |\n",
      "|    value_loss           | 4.48e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -3.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1033      |\n",
      "|    time_elapsed    | 4170      |\n",
      "|    total_timesteps | 2115584   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | -3.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1034        |\n",
      "|    time_elapsed         | 4172        |\n",
      "|    total_timesteps      | 2117632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011031896 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 656         |\n",
      "|    n_updates            | 26240       |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 5.85e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | -3.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 4174        |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053948455 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.1        |\n",
      "|    n_updates            | 26250       |\n",
      "|    policy_gradient_loss | 0.00505     |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 2.54e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2120000, episode_reward=34457.76 +/- 4170.16\n",
      "Episode length: 2641.00 +/- 15.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.64e+03    |\n",
      "|    mean_reward          | 3.45e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012508992 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.22        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 279         |\n",
      "|    n_updates            | 26260       |\n",
      "|    policy_gradient_loss | -0.00518    |\n",
      "|    std                  | 0.172       |\n",
      "|    value_loss           | 1.78e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.77e+03  |\n",
      "|    ep_rew_mean     | -3.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1036      |\n",
      "|    time_elapsed    | 4182      |\n",
      "|    total_timesteps | 2121728   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | -3.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1037        |\n",
      "|    time_elapsed         | 4184        |\n",
      "|    total_timesteps      | 2123776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011322304 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.23        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.3        |\n",
      "|    n_updates            | 26270       |\n",
      "|    policy_gradient_loss | -0.000602   |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 721         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2125000, episode_reward=35467.23 +/- 3791.27\n",
      "Episode length: 2606.60 +/- 11.89\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.61e+03   |\n",
      "|    mean_reward          | 3.55e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2125000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16228342 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.23       |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 72.5       |\n",
      "|    n_updates            | 26280      |\n",
      "|    policy_gradient_loss | 0.00894    |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 866        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.77e+03  |\n",
      "|    ep_rew_mean     | -3.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1038      |\n",
      "|    time_elapsed    | 4192      |\n",
      "|    total_timesteps | 2125824   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.78e+03    |\n",
      "|    ep_rew_mean          | -3.43e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1039        |\n",
      "|    time_elapsed         | 4194        |\n",
      "|    total_timesteps      | 2127872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011750251 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.23        |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.5e+06     |\n",
      "|    n_updates            | 26290       |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 1.9e+07     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -3.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1040        |\n",
      "|    time_elapsed         | 4196        |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013220845 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.23        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 470         |\n",
      "|    n_updates            | 26300       |\n",
      "|    policy_gradient_loss | 0.000294    |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 4.31e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2130000, episode_reward=34128.76 +/- 2153.88\n",
      "Episode length: 2510.60 +/- 19.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.51e+03    |\n",
      "|    mean_reward          | 3.41e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039298162 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 82.5        |\n",
      "|    n_updates            | 26310       |\n",
      "|    policy_gradient_loss | 0.00936     |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -3.52e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1041      |\n",
      "|    time_elapsed    | 4204      |\n",
      "|    total_timesteps | 2131968   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.79e+03     |\n",
      "|    ep_rew_mean          | -3.49e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 1042         |\n",
      "|    time_elapsed         | 4206         |\n",
      "|    total_timesteps      | 2134016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055974773 |\n",
      "|    clip_fraction        | 0.0825       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.24         |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.15e+06     |\n",
      "|    n_updates            | 26320        |\n",
      "|    policy_gradient_loss | -0.000353    |\n",
      "|    std                  | 0.171        |\n",
      "|    value_loss           | 1.82e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2135000, episode_reward=26629.65 +/- 4289.55\n",
      "Episode length: 2420.80 +/- 14.58\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.42e+03  |\n",
      "|    mean_reward          | 2.66e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 2135000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.009597  |\n",
      "|    clip_fraction        | 0.0744    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.24      |\n",
      "|    explained_variance   | 0.643     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 8.02e+05  |\n",
      "|    n_updates            | 26330     |\n",
      "|    policy_gradient_loss | -0.000298 |\n",
      "|    std                  | 0.171     |\n",
      "|    value_loss           | 9.61e+05  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -3.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1043      |\n",
      "|    time_elapsed    | 4213      |\n",
      "|    total_timesteps | 2136064   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.8e+03     |\n",
      "|    ep_rew_mean          | -3.6e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 4215        |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006421064 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.48e+06    |\n",
      "|    n_updates            | 26340       |\n",
      "|    policy_gradient_loss | 0.0016      |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 1.9e+07     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2140000, episode_reward=30672.59 +/- 2778.16\n",
      "Episode length: 2491.00 +/- 14.27\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.49e+03   |\n",
      "|    mean_reward          | 3.07e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2140000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00766939 |\n",
      "|    clip_fraction        | 0.0445     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.24       |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 871        |\n",
      "|    n_updates            | 26350      |\n",
      "|    policy_gradient_loss | 0.000968   |\n",
      "|    std                  | 0.171      |\n",
      "|    value_loss           | 4.76e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.8e+03  |\n",
      "|    ep_rew_mean     | -3.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 1045     |\n",
      "|    time_elapsed    | 4223     |\n",
      "|    total_timesteps | 2140160  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.81e+03     |\n",
      "|    ep_rew_mean          | -3.68e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 1046         |\n",
      "|    time_elapsed         | 4225         |\n",
      "|    total_timesteps      | 2142208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048932917 |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.24         |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 373          |\n",
      "|    n_updates            | 26360        |\n",
      "|    policy_gradient_loss | -0.00477     |\n",
      "|    std                  | 0.171        |\n",
      "|    value_loss           | 1.01e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.82e+03     |\n",
      "|    ep_rew_mean          | -3.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 1047         |\n",
      "|    time_elapsed         | 4226         |\n",
      "|    total_timesteps      | 2144256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069570215 |\n",
      "|    clip_fraction        | 0.0711       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.24         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.93e+06     |\n",
      "|    n_updates            | 26370        |\n",
      "|    policy_gradient_loss | 0.00362      |\n",
      "|    std                  | 0.171        |\n",
      "|    value_loss           | 1.14e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2145000, episode_reward=28681.57 +/- 3302.46\n",
      "Episode length: 2570.60 +/- 12.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.57e+03    |\n",
      "|    mean_reward          | 2.87e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2145000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008122845 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 26380       |\n",
      "|    policy_gradient_loss | 0.00183     |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.83e+03 |\n",
      "|    ep_rew_mean     | -3.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 1048     |\n",
      "|    time_elapsed    | 4234     |\n",
      "|    total_timesteps | 2146304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.84e+03    |\n",
      "|    ep_rew_mean          | -3.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1049        |\n",
      "|    time_elapsed         | 4236        |\n",
      "|    total_timesteps      | 2148352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008380609 |\n",
      "|    clip_fraction        | 0.0527      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.24        |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.72e+07    |\n",
      "|    n_updates            | 26390       |\n",
      "|    policy_gradient_loss | -0.000301   |\n",
      "|    std                  | 0.171       |\n",
      "|    value_loss           | 5.79e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2150000, episode_reward=32469.47 +/- 4255.58\n",
      "Episode length: 2541.20 +/- 23.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.54e+03    |\n",
      "|    mean_reward          | 3.25e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024939634 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.25        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 26400       |\n",
      "|    policy_gradient_loss | 0.0054      |\n",
      "|    std                  | 0.17        |\n",
      "|    value_loss           | 1e+03       |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.85e+03  |\n",
      "|    ep_rew_mean     | -3.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1050      |\n",
      "|    time_elapsed    | 4244      |\n",
      "|    total_timesteps | 2150400   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -3.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1051        |\n",
      "|    time_elapsed         | 4246        |\n",
      "|    total_timesteps      | 2152448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008505516 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.25        |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.61e+04    |\n",
      "|    n_updates            | 26410       |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    std                  | 0.17        |\n",
      "|    value_loss           | 1.9e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -3.66e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 4248        |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018629774 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.26        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 26420       |\n",
      "|    policy_gradient_loss | 0.000765    |\n",
      "|    std                  | 0.17        |\n",
      "|    value_loss           | 1.14e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2155000, episode_reward=36203.77 +/- 1510.93\n",
      "Episode length: 2681.60 +/- 4.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.68e+03    |\n",
      "|    mean_reward          | 3.62e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2155000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004164219 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.26        |\n",
      "|    explained_variance   | 0.335       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.83e+05    |\n",
      "|    n_updates            | 26430       |\n",
      "|    policy_gradient_loss | -0.00374    |\n",
      "|    std                  | 0.17        |\n",
      "|    value_loss           | 1.81e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.86e+03  |\n",
      "|    ep_rew_mean     | -3.65e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1053      |\n",
      "|    time_elapsed    | 4256      |\n",
      "|    total_timesteps | 2156544   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.87e+03     |\n",
      "|    ep_rew_mean          | -3.64e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 1054         |\n",
      "|    time_elapsed         | 4258         |\n",
      "|    total_timesteps      | 2158592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031505357 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.26         |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 26440        |\n",
      "|    policy_gradient_loss | -0.000327    |\n",
      "|    std                  | 0.17         |\n",
      "|    value_loss           | 1.03e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2160000, episode_reward=32401.04 +/- 3602.11\n",
      "Episode length: 2645.60 +/- 18.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.65e+03    |\n",
      "|    mean_reward          | 3.24e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013321874 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.26        |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 515         |\n",
      "|    n_updates            | 26450       |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    std                  | 0.17        |\n",
      "|    value_loss           | 4.02e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.87e+03  |\n",
      "|    ep_rew_mean     | -3.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1055      |\n",
      "|    time_elapsed    | 4266      |\n",
      "|    total_timesteps | 2160640   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.88e+03   |\n",
      "|    ep_rew_mean          | -3.62e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 506        |\n",
      "|    iterations           | 1056       |\n",
      "|    time_elapsed         | 4268       |\n",
      "|    total_timesteps      | 2162688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01116758 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.26       |\n",
      "|    explained_variance   | 0.855      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 272        |\n",
      "|    n_updates            | 26460      |\n",
      "|    policy_gradient_loss | 0.00156    |\n",
      "|    std                  | 0.17       |\n",
      "|    value_loss           | 5.11e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.89e+03    |\n",
      "|    ep_rew_mean          | -3.62e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1057        |\n",
      "|    time_elapsed         | 4270        |\n",
      "|    total_timesteps      | 2164736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008622209 |\n",
      "|    clip_fraction        | 0.0589      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.26        |\n",
      "|    explained_variance   | 0.85        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.09e+03    |\n",
      "|    n_updates            | 26470       |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    std                  | 0.169       |\n",
      "|    value_loss           | 9.54e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2165000, episode_reward=16087.12 +/- 5715.59\n",
      "Episode length: 2712.60 +/- 22.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.71e+03    |\n",
      "|    mean_reward          | 1.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2165000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026175661 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.26        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.2        |\n",
      "|    n_updates            | 26480       |\n",
      "|    policy_gradient_loss | -0.00147    |\n",
      "|    std                  | 0.169       |\n",
      "|    value_loss           | 3.93e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -3.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1058      |\n",
      "|    time_elapsed    | 4278      |\n",
      "|    total_timesteps | 2166784   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.88e+03   |\n",
      "|    ep_rew_mean          | -3.77e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 506        |\n",
      "|    iterations           | 1059       |\n",
      "|    time_elapsed         | 4280       |\n",
      "|    total_timesteps      | 2168832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17086652 |\n",
      "|    clip_fraction        | 0.127      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.26       |\n",
      "|    explained_variance   | 0.302      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.56e+06   |\n",
      "|    n_updates            | 26490      |\n",
      "|    policy_gradient_loss | 0.00191    |\n",
      "|    std                  | 0.169      |\n",
      "|    value_loss           | 2.08e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2170000, episode_reward=22973.55 +/- 3258.48\n",
      "Episode length: 2551.00 +/- 9.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.55e+03    |\n",
      "|    mean_reward          | 2.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015487036 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.26        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 211         |\n",
      "|    n_updates            | 26500       |\n",
      "|    policy_gradient_loss | 0.00617     |\n",
      "|    std                  | 0.169       |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -3.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1060      |\n",
      "|    time_elapsed    | 4288      |\n",
      "|    total_timesteps | 2170880   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | -3.75e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1061        |\n",
      "|    time_elapsed         | 4290        |\n",
      "|    total_timesteps      | 2172928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027611922 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 26510       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    std                  | 0.169       |\n",
      "|    value_loss           | 403         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | -3.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1062        |\n",
      "|    time_elapsed         | 4292        |\n",
      "|    total_timesteps      | 2174976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014147462 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.6        |\n",
      "|    n_updates            | 26520       |\n",
      "|    policy_gradient_loss | -0.000211   |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 331         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2175000, episode_reward=-4206.48 +/- 67546.23\n",
      "Episode length: 2064.40 +/- 987.74\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.06e+03  |\n",
      "|    mean_reward          | -4.21e+03 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 2175000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0265407 |\n",
      "|    clip_fraction        | 0.226     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.3       |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 90.6      |\n",
      "|    n_updates            | 26530     |\n",
      "|    policy_gradient_loss | 0.00686   |\n",
      "|    std                  | 0.168     |\n",
      "|    value_loss           | 186       |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.91e+03  |\n",
      "|    ep_rew_mean     | -3.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1063      |\n",
      "|    time_elapsed    | 4299      |\n",
      "|    total_timesteps | 2177024   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.92e+03    |\n",
      "|    ep_rew_mean          | -3.72e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1064        |\n",
      "|    time_elapsed         | 4300        |\n",
      "|    total_timesteps      | 2179072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016289867 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.1        |\n",
      "|    n_updates            | 26540       |\n",
      "|    policy_gradient_loss | 0.00356     |\n",
      "|    std                  | 0.169       |\n",
      "|    value_loss           | 1.75e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2180000, episode_reward=32507.68 +/- 1617.35\n",
      "Episode length: 2571.20 +/- 10.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.57e+03    |\n",
      "|    mean_reward          | 3.25e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024552263 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 542         |\n",
      "|    n_updates            | 26550       |\n",
      "|    policy_gradient_loss | 0.00409     |\n",
      "|    std                  | 0.169       |\n",
      "|    value_loss           | 3.07e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.92e+03  |\n",
      "|    ep_rew_mean     | -3.71e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1065      |\n",
      "|    time_elapsed    | 4308      |\n",
      "|    total_timesteps | 2181120   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.93e+03   |\n",
      "|    ep_rew_mean          | -3.69e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 506        |\n",
      "|    iterations           | 1066       |\n",
      "|    time_elapsed         | 4310       |\n",
      "|    total_timesteps      | 2183168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01660442 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.32       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 47.9       |\n",
      "|    n_updates            | 26560      |\n",
      "|    policy_gradient_loss | 0.00413    |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 113        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2185000, episode_reward=33814.25 +/- 1634.11\n",
      "Episode length: 2575.60 +/- 15.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.58e+03    |\n",
      "|    mean_reward          | 3.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2185000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006518812 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 290         |\n",
      "|    n_updates            | 26570       |\n",
      "|    policy_gradient_loss | -0.00442    |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 2.93e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -3.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1067      |\n",
      "|    time_elapsed    | 4318      |\n",
      "|    total_timesteps | 2185216   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.93e+03    |\n",
      "|    ep_rew_mean          | -3.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1068        |\n",
      "|    time_elapsed         | 4320        |\n",
      "|    total_timesteps      | 2187264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013736825 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.2        |\n",
      "|    n_updates            | 26580       |\n",
      "|    policy_gradient_loss | 0.0188      |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.93e+03    |\n",
      "|    ep_rew_mean          | -3.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1069        |\n",
      "|    time_elapsed         | 4322        |\n",
      "|    total_timesteps      | 2189312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016313687 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 26590       |\n",
      "|    policy_gradient_loss | 0.00981     |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2190000, episode_reward=31324.35 +/- 3170.34\n",
      "Episode length: 2494.20 +/- 18.69\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.49e+03   |\n",
      "|    mean_reward          | 3.13e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2190000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01084693 |\n",
      "|    clip_fraction        | 0.0441     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.333      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2e+07      |\n",
      "|    n_updates            | 26600      |\n",
      "|    policy_gradient_loss | 0.000474   |\n",
      "|    std                  | 0.168      |\n",
      "|    value_loss           | 2.08e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -3.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1070      |\n",
      "|    time_elapsed    | 4330      |\n",
      "|    total_timesteps | 2191360   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.93e+03    |\n",
      "|    ep_rew_mean          | -3.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1071        |\n",
      "|    time_elapsed         | 4332        |\n",
      "|    total_timesteps      | 2193408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020333262 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 431         |\n",
      "|    n_updates            | 26610       |\n",
      "|    policy_gradient_loss | -0.00532    |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 9.74e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2195000, episode_reward=23129.31 +/- 4594.08\n",
      "Episode length: 2419.00 +/- 11.19\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.42e+03    |\n",
      "|    mean_reward          | 2.31e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2195000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018520407 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 26620       |\n",
      "|    policy_gradient_loss | 0.00617     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -3.19e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1072      |\n",
      "|    time_elapsed    | 4339      |\n",
      "|    total_timesteps | 2195456   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -3.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1073        |\n",
      "|    time_elapsed         | 4341        |\n",
      "|    total_timesteps      | 2197504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004007533 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.4         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38e+06    |\n",
      "|    n_updates            | 26630       |\n",
      "|    policy_gradient_loss | -0.000332   |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 9.03e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -3.19e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1074        |\n",
      "|    time_elapsed         | 4343        |\n",
      "|    total_timesteps      | 2199552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020126808 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.6        |\n",
      "|    n_updates            | 26640       |\n",
      "|    policy_gradient_loss | 0.00402     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 4.66e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2200000, episode_reward=22569.53 +/- 3177.11\n",
      "Episode length: 2706.20 +/- 5.38\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.71e+03   |\n",
      "|    mean_reward          | 2.26e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2200000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02722307 |\n",
      "|    clip_fraction        | 0.283      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 231        |\n",
      "|    n_updates            | 26650      |\n",
      "|    policy_gradient_loss | 0.0191     |\n",
      "|    std                  | 0.166      |\n",
      "|    value_loss           | 111        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -3.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1075      |\n",
      "|    time_elapsed    | 4351      |\n",
      "|    total_timesteps | 2201600   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -3.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1076        |\n",
      "|    time_elapsed         | 4353        |\n",
      "|    total_timesteps      | 2203648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012950551 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 26660       |\n",
      "|    policy_gradient_loss | 0.00877     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 116         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2205000, episode_reward=17464.22 +/- 5043.53\n",
      "Episode length: 1975.00 +/- 18.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.98e+03    |\n",
      "|    mean_reward          | 1.75e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2205000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029835975 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 26670       |\n",
      "|    policy_gradient_loss | 0.00664     |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 1.3e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.95e+03  |\n",
      "|    ep_rew_mean     | -3.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1077      |\n",
      "|    time_elapsed    | 4360      |\n",
      "|    total_timesteps | 2205696   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -2.94e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1078        |\n",
      "|    time_elapsed         | 4361        |\n",
      "|    total_timesteps      | 2207744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019160617 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 26680       |\n",
      "|    policy_gradient_loss | 0.00924     |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 211         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.95e+03     |\n",
      "|    ep_rew_mean          | -2.82e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 1079         |\n",
      "|    time_elapsed         | 4363         |\n",
      "|    total_timesteps      | 2209792      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074236076 |\n",
      "|    clip_fraction        | 0.202        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.998        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 23           |\n",
      "|    n_updates            | 26690        |\n",
      "|    policy_gradient_loss | 0.00487      |\n",
      "|    std                  | 0.168        |\n",
      "|    value_loss           | 169          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2210000, episode_reward=18583.22 +/- 4178.59\n",
      "Episode length: 1669.00 +/- 13.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.67e+03    |\n",
      "|    mean_reward          | 1.86e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035322193 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.6        |\n",
      "|    n_updates            | 26700       |\n",
      "|    policy_gradient_loss | 0.018       |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 151         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.95e+03  |\n",
      "|    ep_rew_mean     | -2.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1080      |\n",
      "|    time_elapsed    | 4369      |\n",
      "|    total_timesteps | 2211840   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | -2.56e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1081        |\n",
      "|    time_elapsed         | 4371        |\n",
      "|    total_timesteps      | 2213888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015667703 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 26710       |\n",
      "|    policy_gradient_loss | 0.00166     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 2.05e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2215000, episode_reward=17111.46 +/- 4532.41\n",
      "Episode length: 1761.20 +/- 16.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.76e+03    |\n",
      "|    mean_reward          | 1.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2215000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021760665 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68          |\n",
      "|    n_updates            | 26720       |\n",
      "|    policy_gradient_loss | 0.012       |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 85.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.97e+03  |\n",
      "|    ep_rew_mean     | -2.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1082      |\n",
      "|    time_elapsed    | 4377      |\n",
      "|    total_timesteps | 2215936   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.98e+03    |\n",
      "|    ep_rew_mean          | -2.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1083        |\n",
      "|    time_elapsed         | 4379        |\n",
      "|    total_timesteps      | 2217984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015136413 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91.4        |\n",
      "|    n_updates            | 26730       |\n",
      "|    policy_gradient_loss | 0.0034      |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 2.82e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2220000, episode_reward=18058.68 +/- 3238.62\n",
      "Episode length: 2613.80 +/- 8.06\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.61e+03   |\n",
      "|    mean_reward          | 1.81e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2220000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04077603 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.951      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16         |\n",
      "|    n_updates            | 26740      |\n",
      "|    policy_gradient_loss | -0.00212   |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 1.06e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.99e+03  |\n",
      "|    ep_rew_mean     | -2.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1084      |\n",
      "|    time_elapsed    | 4387      |\n",
      "|    total_timesteps | 2220032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.99e+03    |\n",
      "|    ep_rew_mean          | -1.86e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1085        |\n",
      "|    time_elapsed         | 4389        |\n",
      "|    total_timesteps      | 2222080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018001271 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 26750       |\n",
      "|    policy_gradient_loss | 0.00121     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 150         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -1.76e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1086        |\n",
      "|    time_elapsed         | 4391        |\n",
      "|    total_timesteps      | 2224128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035447776 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.6        |\n",
      "|    n_updates            | 26760       |\n",
      "|    policy_gradient_loss | 0.00601     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 297         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2225000, episode_reward=20382.51 +/- 3516.30\n",
      "Episode length: 1790.20 +/- 10.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.79e+03    |\n",
      "|    mean_reward          | 2.04e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2225000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025018584 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.7        |\n",
      "|    n_updates            | 26770       |\n",
      "|    policy_gradient_loss | 0.00603     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 3.26e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.01e+03  |\n",
      "|    ep_rew_mean     | -1.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1087      |\n",
      "|    time_elapsed    | 4397      |\n",
      "|    total_timesteps | 2226176   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | -1.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1088        |\n",
      "|    time_elapsed         | 4399        |\n",
      "|    total_timesteps      | 2228224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009078991 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.1        |\n",
      "|    n_updates            | 26780       |\n",
      "|    policy_gradient_loss | 0.00692     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 81.8        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2230000, episode_reward=20179.25 +/- 3534.58\n",
      "Episode length: 1765.20 +/- 13.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.77e+03    |\n",
      "|    mean_reward          | 2.02e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020425282 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.4        |\n",
      "|    n_updates            | 26790       |\n",
      "|    policy_gradient_loss | 0.000475    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 77.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.01e+03  |\n",
      "|    ep_rew_mean     | -1.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1089      |\n",
      "|    time_elapsed    | 4405      |\n",
      "|    total_timesteps | 2230272   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -1.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1090        |\n",
      "|    time_elapsed         | 4407        |\n",
      "|    total_timesteps      | 2232320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046973176 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.5        |\n",
      "|    n_updates            | 26800       |\n",
      "|    policy_gradient_loss | 0.00433     |\n",
      "|    std                  | 0.164       |\n",
      "|    value_loss           | 65.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.03e+03    |\n",
      "|    ep_rew_mean          | -1.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1091        |\n",
      "|    time_elapsed         | 4409        |\n",
      "|    total_timesteps      | 2234368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038167145 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.2        |\n",
      "|    n_updates            | 26810       |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 77.7        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2235000, episode_reward=19758.30 +/- 5153.09\n",
      "Episode length: 2944.20 +/- 8.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.94e+03     |\n",
      "|    mean_reward          | 1.98e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2235000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025298242 |\n",
      "|    clip_fraction        | 0.0546       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 190          |\n",
      "|    n_updates            | 26820        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 3.2e+03      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.02e+03  |\n",
      "|    ep_rew_mean     | -1.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1092      |\n",
      "|    time_elapsed    | 4418      |\n",
      "|    total_timesteps | 2236416   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.99e+03    |\n",
      "|    ep_rew_mean          | -1.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1093        |\n",
      "|    time_elapsed         | 4419        |\n",
      "|    total_timesteps      | 2238464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005500645 |\n",
      "|    clip_fraction        | 0.0179      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.2e+07     |\n",
      "|    n_updates            | 26830       |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 2.01e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2240000, episode_reward=15224.79 +/- 3724.32\n",
      "Episode length: 2917.60 +/- 6.65\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.92e+03   |\n",
      "|    mean_reward          | 1.52e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2240000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04517234 |\n",
      "|    clip_fraction        | 0.0327     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.36       |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.01e+07   |\n",
      "|    n_updates            | 26840      |\n",
      "|    policy_gradient_loss | 0.00698    |\n",
      "|    std                  | 0.165      |\n",
      "|    value_loss           | 2.95e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.99e+03  |\n",
      "|    ep_rew_mean     | -1.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1094      |\n",
      "|    time_elapsed    | 4428      |\n",
      "|    total_timesteps | 2240512   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -1.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1095        |\n",
      "|    time_elapsed         | 4430        |\n",
      "|    total_timesteps      | 2242560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006648738 |\n",
      "|    clip_fraction        | 0.0252      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+04    |\n",
      "|    n_updates            | 26850       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.03e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | -1.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1096        |\n",
      "|    time_elapsed         | 4432        |\n",
      "|    total_timesteps      | 2244608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008058833 |\n",
      "|    clip_fraction        | 0.0741      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 719         |\n",
      "|    n_updates            | 26860       |\n",
      "|    policy_gradient_loss | -0.00207    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 4.09e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2245000, episode_reward=18500.39 +/- 5014.72\n",
      "Episode length: 2833.20 +/- 101.27\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.83e+03    |\n",
      "|    mean_reward          | 1.85e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2245000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012111539 |\n",
      "|    clip_fraction        | 0.0934      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 330         |\n",
      "|    n_updates            | 26870       |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 5.84e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.01e+03  |\n",
      "|    ep_rew_mean     | -1.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1097      |\n",
      "|    time_elapsed    | 4441      |\n",
      "|    total_timesteps | 2246656   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -1.12e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1098        |\n",
      "|    time_elapsed         | 4443        |\n",
      "|    total_timesteps      | 2248704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041497543 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.4        |\n",
      "|    n_updates            | 26880       |\n",
      "|    policy_gradient_loss | 0.00167     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.22e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2250000, episode_reward=18454.56 +/- 4957.69\n",
      "Episode length: 2848.80 +/- 24.62\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.85e+03   |\n",
      "|    mean_reward          | 1.85e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2250000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03487275 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.36       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 151        |\n",
      "|    n_updates            | 26890      |\n",
      "|    policy_gradient_loss | 0.00109    |\n",
      "|    std                  | 0.165      |\n",
      "|    value_loss           | 1.16e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.02e+03  |\n",
      "|    ep_rew_mean     | -1.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1099      |\n",
      "|    time_elapsed    | 4451      |\n",
      "|    total_timesteps | 2250752   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.04e+03   |\n",
      "|    ep_rew_mean          | -1.02e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1100       |\n",
      "|    time_elapsed         | 4453       |\n",
      "|    total_timesteps      | 2252800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00990078 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.35       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 23.1       |\n",
      "|    n_updates            | 26900      |\n",
      "|    policy_gradient_loss | 0.00347    |\n",
      "|    std                  | 0.166      |\n",
      "|    value_loss           | 358        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.04e+03    |\n",
      "|    ep_rew_mean          | -1.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1101        |\n",
      "|    time_elapsed         | 4455        |\n",
      "|    total_timesteps      | 2254848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016945783 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68          |\n",
      "|    n_updates            | 26910       |\n",
      "|    policy_gradient_loss | 0.00308     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 385         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2255000, episode_reward=-15646.18 +/- 60237.22\n",
      "Episode length: 1930.80 +/- 922.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.93e+03    |\n",
      "|    mean_reward          | -1.56e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2255000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015878726 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27          |\n",
      "|    n_updates            | 26920       |\n",
      "|    policy_gradient_loss | 0.00898     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.04e+03 |\n",
      "|    ep_rew_mean     | -1e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1102     |\n",
      "|    time_elapsed    | 4461     |\n",
      "|    total_timesteps | 2256896  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.04e+03   |\n",
      "|    ep_rew_mean          | -7.4e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 506        |\n",
      "|    iterations           | 1103       |\n",
      "|    time_elapsed         | 4463       |\n",
      "|    total_timesteps      | 2258944    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02403202 |\n",
      "|    clip_fraction        | 0.227      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.2       |\n",
      "|    n_updates            | 26930      |\n",
      "|    policy_gradient_loss | 0.00132    |\n",
      "|    std                  | 0.166      |\n",
      "|    value_loss           | 353        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2260000, episode_reward=14512.44 +/- 3378.36\n",
      "Episode length: 2440.80 +/- 10.68\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.44e+03   |\n",
      "|    mean_reward          | 1.45e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2260000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07083968 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.32       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 36.3       |\n",
      "|    n_updates            | 26940      |\n",
      "|    policy_gradient_loss | 0.00485    |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 1.02e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.05e+03  |\n",
      "|    ep_rew_mean     | -7.16e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1104      |\n",
      "|    time_elapsed    | 4471      |\n",
      "|    total_timesteps | 2260992   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -3.88e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1105        |\n",
      "|    time_elapsed         | 4473        |\n",
      "|    total_timesteps      | 2263040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039555598 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.79e+03    |\n",
      "|    n_updates            | 26950       |\n",
      "|    policy_gradient_loss | 0.0145      |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 2.74e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2265000, episode_reward=13200.05 +/- 3052.42\n",
      "Episode length: 2769.20 +/- 29.32\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.77e+03  |\n",
      "|    mean_reward          | 1.32e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 2265000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8025478 |\n",
      "|    clip_fraction        | 0.337     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.3       |\n",
      "|    explained_variance   | 0.333     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.33e+07  |\n",
      "|    n_updates            | 26960     |\n",
      "|    policy_gradient_loss | 0.0139    |\n",
      "|    std                  | 0.167     |\n",
      "|    value_loss           | 2.27e+07  |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.02e+03 |\n",
      "|    ep_rew_mean     | -4e+03   |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1106     |\n",
      "|    time_elapsed    | 4481     |\n",
      "|    total_timesteps | 2265088  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -4e+03      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1107        |\n",
      "|    time_elapsed         | 4483        |\n",
      "|    total_timesteps      | 2267136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024455817 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+05     |\n",
      "|    n_updates            | 26970       |\n",
      "|    policy_gradient_loss | 0.000549    |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 2.1e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -3.46e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1108        |\n",
      "|    time_elapsed         | 4485        |\n",
      "|    total_timesteps      | 2269184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044290625 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 26980       |\n",
      "|    policy_gradient_loss | 0.0043      |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 183         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2270000, episode_reward=12609.38 +/- 3794.87\n",
      "Episode length: 2321.40 +/- 11.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.32e+03     |\n",
      "|    mean_reward          | 1.26e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2270000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039610127 |\n",
      "|    clip_fraction        | 0.345        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.29         |\n",
      "|    explained_variance   | 0.354        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.89e+07     |\n",
      "|    n_updates            | 26990        |\n",
      "|    policy_gradient_loss | 0.0191       |\n",
      "|    std                  | 0.168        |\n",
      "|    value_loss           | 3.4e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2e+03     |\n",
      "|    ep_rew_mean     | -3.51e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1109      |\n",
      "|    time_elapsed    | 4492      |\n",
      "|    total_timesteps | 2271232   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | -3.96e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1110        |\n",
      "|    time_elapsed         | 4494        |\n",
      "|    total_timesteps      | 2273280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006683356 |\n",
      "|    clip_fraction        | 0.0563      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57e+03    |\n",
      "|    n_updates            | 27000       |\n",
      "|    policy_gradient_loss | -0.00372    |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 1.32e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2275000, episode_reward=14868.35 +/- 281.14\n",
      "Episode length: 2302.00 +/- 5.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 1.49e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2275000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002866005 |\n",
      "|    clip_fraction        | 0.0229      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.394       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.24e+07    |\n",
      "|    n_updates            | 27010       |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 2.25e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.97e+03  |\n",
      "|    ep_rew_mean     | -4.08e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1111      |\n",
      "|    time_elapsed    | 4502      |\n",
      "|    total_timesteps | 2275328   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | -4.28e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1112        |\n",
      "|    time_elapsed         | 4503        |\n",
      "|    total_timesteps      | 2277376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007213148 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 317         |\n",
      "|    n_updates            | 27020       |\n",
      "|    policy_gradient_loss | -0.0032     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 2.71e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | -3.79e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1113        |\n",
      "|    time_elapsed         | 4505        |\n",
      "|    total_timesteps      | 2279424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008453195 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 225         |\n",
      "|    n_updates            | 27030       |\n",
      "|    policy_gradient_loss | -0.000503   |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 1.21e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2280000, episode_reward=8954.36 +/- 3919.79\n",
      "Episode length: 2423.80 +/- 17.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.42e+03    |\n",
      "|    mean_reward          | 8.95e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021958042 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 27040       |\n",
      "|    policy_gradient_loss | 0.00163     |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 594         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.97e+03  |\n",
      "|    ep_rew_mean     | -3.86e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1114      |\n",
      "|    time_elapsed    | 4513      |\n",
      "|    total_timesteps | 2281472   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.98e+03    |\n",
      "|    ep_rew_mean          | -3.86e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1115        |\n",
      "|    time_elapsed         | 4515        |\n",
      "|    total_timesteps      | 2283520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014113822 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 250         |\n",
      "|    n_updates            | 27050       |\n",
      "|    policy_gradient_loss | 0.000995    |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2285000, episode_reward=11074.40 +/- 3594.75\n",
      "Episode length: 2430.40 +/- 12.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.43e+03    |\n",
      "|    mean_reward          | 1.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2285000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003920005 |\n",
      "|    clip_fraction        | 0.0432      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.64e+07    |\n",
      "|    n_updates            | 27060       |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 2.25e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.97e+03  |\n",
      "|    ep_rew_mean     | -4.47e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1116      |\n",
      "|    time_elapsed    | 4522      |\n",
      "|    total_timesteps | 2285568   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.97e+03    |\n",
      "|    ep_rew_mean          | -4.52e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1117        |\n",
      "|    time_elapsed         | 4524        |\n",
      "|    total_timesteps      | 2287616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014273519 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.7        |\n",
      "|    n_updates            | 27070       |\n",
      "|    policy_gradient_loss | 0.0042      |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 6.75e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.98e+03    |\n",
      "|    ep_rew_mean          | -4.63e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1118        |\n",
      "|    time_elapsed         | 4526        |\n",
      "|    total_timesteps      | 2289664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008368025 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.5e+04     |\n",
      "|    n_updates            | 27080       |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    std                  | 0.168       |\n",
      "|    value_loss           | 2.26e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2290000, episode_reward=17107.71 +/- 1576.20\n",
      "Episode length: 2451.00 +/- 7.13\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.45e+03     |\n",
      "|    mean_reward          | 1.71e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2290000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068815514 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.3          |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.86e+03     |\n",
      "|    n_updates            | 27090        |\n",
      "|    policy_gradient_loss | -0.00609     |\n",
      "|    std                  | 0.168        |\n",
      "|    value_loss           | 3.97e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.99e+03  |\n",
      "|    ep_rew_mean     | -4.83e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1119      |\n",
      "|    time_elapsed    | 4534      |\n",
      "|    total_timesteps | 2291712   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.99e+03    |\n",
      "|    ep_rew_mean          | -4.95e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1120        |\n",
      "|    time_elapsed         | 4535        |\n",
      "|    total_timesteps      | 2293760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049833607 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.1        |\n",
      "|    n_updates            | 27100       |\n",
      "|    policy_gradient_loss | 0.00578     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 643         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2295000, episode_reward=16637.89 +/- 1196.05\n",
      "Episode length: 2632.20 +/- 25.08\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.63e+03   |\n",
      "|    mean_reward          | 1.66e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2295000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03503284 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.31       |\n",
      "|    explained_variance   | 0.978      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 259        |\n",
      "|    n_updates            | 27110      |\n",
      "|    policy_gradient_loss | 0.0033     |\n",
      "|    std                  | 0.167      |\n",
      "|    value_loss           | 4.66e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.99e+03  |\n",
      "|    ep_rew_mean     | -4.95e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1121      |\n",
      "|    time_elapsed    | 4544      |\n",
      "|    total_timesteps | 2295808   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -4.95e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1122        |\n",
      "|    time_elapsed         | 4545        |\n",
      "|    total_timesteps      | 2297856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022897312 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 27120       |\n",
      "|    policy_gradient_loss | 0.00388     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 295         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -5.18e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1123        |\n",
      "|    time_elapsed         | 4547        |\n",
      "|    total_timesteps      | 2299904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015863664 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 250         |\n",
      "|    n_updates            | 27130       |\n",
      "|    policy_gradient_loss | 0.000435    |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 9.85e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2300000, episode_reward=-19364.12 +/- 60847.38\n",
      "Episode length: 2004.40 +/- 958.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | -1.94e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022813592 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.7        |\n",
      "|    n_updates            | 27140       |\n",
      "|    policy_gradient_loss | 0.00914     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 289         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2e+03     |\n",
      "|    ep_rew_mean     | -5.75e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1124      |\n",
      "|    time_elapsed    | 4554      |\n",
      "|    total_timesteps | 2301952   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -5.12e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1125        |\n",
      "|    time_elapsed         | 4556        |\n",
      "|    total_timesteps      | 2304000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015556639 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.72e+05    |\n",
      "|    n_updates            | 27150       |\n",
      "|    policy_gradient_loss | 0.0031      |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 4.6e+06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2305000, episode_reward=-21161.31 +/- 61365.59\n",
      "Episode length: 1995.60 +/- 952.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | -2.12e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2305000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004460538 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.82e+03    |\n",
      "|    n_updates            | 27160       |\n",
      "|    policy_gradient_loss | 0.00181     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 1.62e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.01e+03  |\n",
      "|    ep_rew_mean     | -4.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1126      |\n",
      "|    time_elapsed    | 4562      |\n",
      "|    total_timesteps | 2306048   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.02e+03     |\n",
      "|    ep_rew_mean          | -4.55e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 1127         |\n",
      "|    time_elapsed         | 4564         |\n",
      "|    total_timesteps      | 2308096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023269344 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.777        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.93e+04     |\n",
      "|    n_updates            | 27170        |\n",
      "|    policy_gradient_loss | -0.00456     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 1.27e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2310000, episode_reward=8623.02 +/- 2617.02\n",
      "Episode length: 2507.20 +/- 19.49\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.51e+03     |\n",
      "|    mean_reward          | 8.62e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2310000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024749632 |\n",
      "|    clip_fraction        | 0.00981      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.85e+04     |\n",
      "|    n_updates            | 27180        |\n",
      "|    policy_gradient_loss | -0.00363     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 4.07e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.01e+03  |\n",
      "|    ep_rew_mean     | -5.86e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1128      |\n",
      "|    time_elapsed    | 4572      |\n",
      "|    total_timesteps | 2310144   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.01e+03     |\n",
      "|    ep_rew_mean          | -6.41e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 1129         |\n",
      "|    time_elapsed         | 4574         |\n",
      "|    total_timesteps      | 2312192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017547283 |\n",
      "|    clip_fraction        | 0.0082       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+07      |\n",
      "|    n_updates            | 27190        |\n",
      "|    policy_gradient_loss | -0.00307     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 2.1e+07      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.03e+03    |\n",
      "|    ep_rew_mean          | -5.5e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1130        |\n",
      "|    time_elapsed         | 4576        |\n",
      "|    total_timesteps      | 2314240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003504293 |\n",
      "|    clip_fraction        | 0.0259      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.677       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.84e+03    |\n",
      "|    n_updates            | 27200       |\n",
      "|    policy_gradient_loss | -0.00347    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 2.55e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2315000, episode_reward=10080.83 +/- 3703.40\n",
      "Episode length: 2633.40 +/- 15.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.63e+03    |\n",
      "|    mean_reward          | 1.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2315000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006802613 |\n",
      "|    clip_fraction        | 0.0502      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.22e+03    |\n",
      "|    n_updates            | 27210       |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 9.29e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.03e+03 |\n",
      "|    ep_rew_mean     | -5.5e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1131     |\n",
      "|    time_elapsed    | 4584     |\n",
      "|    total_timesteps | 2316288  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.03e+03   |\n",
      "|    ep_rew_mean          | -5.71e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1132       |\n",
      "|    time_elapsed         | 4585       |\n",
      "|    total_timesteps      | 2318336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00909097 |\n",
      "|    clip_fraction        | 0.126      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 139        |\n",
      "|    n_updates            | 27220      |\n",
      "|    policy_gradient_loss | -0.00067   |\n",
      "|    std                  | 0.166      |\n",
      "|    value_loss           | 758        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2320000, episode_reward=7812.21 +/- 1711.17\n",
      "Episode length: 2686.40 +/- 9.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.69e+03    |\n",
      "|    mean_reward          | 7.81e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006419971 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 358         |\n",
      "|    n_updates            | 27230       |\n",
      "|    policy_gradient_loss | 0.00114     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 5.78e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.03e+03  |\n",
      "|    ep_rew_mean     | -5.92e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1133      |\n",
      "|    time_elapsed    | 4594      |\n",
      "|    total_timesteps | 2320384   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.03e+03     |\n",
      "|    ep_rew_mean          | -6.25e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 1134         |\n",
      "|    time_elapsed         | 4595         |\n",
      "|    total_timesteps      | 2322432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052637365 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.56e+03     |\n",
      "|    n_updates            | 27240        |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 1.73e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -6.4e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1135        |\n",
      "|    time_elapsed         | 4597        |\n",
      "|    total_timesteps      | 2324480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014093959 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 27250       |\n",
      "|    policy_gradient_loss | 0.00509     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 1.3e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2325000, episode_reward=-20685.59 +/- 61319.02\n",
      "Episode length: 1736.60 +/- 822.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.74e+03    |\n",
      "|    mean_reward          | -2.07e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2325000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027463103 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 720         |\n",
      "|    n_updates            | 27260       |\n",
      "|    policy_gradient_loss | 0.00756     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.02e+03  |\n",
      "|    ep_rew_mean     | -6.57e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1136      |\n",
      "|    time_elapsed    | 4603      |\n",
      "|    total_timesteps | 2326528   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.04e+03    |\n",
      "|    ep_rew_mean          | -5.53e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1137        |\n",
      "|    time_elapsed         | 4605        |\n",
      "|    total_timesteps      | 2328576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009999616 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 27270       |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 540         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2330000, episode_reward=15477.93 +/- 2420.77\n",
      "Episode length: 2005.00 +/- 8.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.00e+03    |\n",
      "|    mean_reward          | 1.55e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011882606 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.4        |\n",
      "|    n_updates            | 27280       |\n",
      "|    policy_gradient_loss | 0.00891     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 3.43e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2e+03     |\n",
      "|    ep_rew_mean     | -7.59e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1138      |\n",
      "|    time_elapsed    | 4612      |\n",
      "|    total_timesteps | 2330624   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -6.52e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1139        |\n",
      "|    time_elapsed         | 4614        |\n",
      "|    total_timesteps      | 2332672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029232293 |\n",
      "|    clip_fraction        | 0.0817      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.348       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.6e+06     |\n",
      "|    n_updates            | 27290       |\n",
      "|    policy_gradient_loss | 0.00511     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 2.22e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -7.17e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1140        |\n",
      "|    time_elapsed         | 4615        |\n",
      "|    total_timesteps      | 2334720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007052124 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 162         |\n",
      "|    n_updates            | 27300       |\n",
      "|    policy_gradient_loss | 0.00143     |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 913         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2335000, episode_reward=13788.58 +/- 2300.77\n",
      "Episode length: 2437.20 +/- 11.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.44e+03    |\n",
      "|    mean_reward          | 1.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2335000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007904335 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.11e+03    |\n",
      "|    n_updates            | 27310       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 3.71e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.02e+03  |\n",
      "|    ep_rew_mean     | -7.02e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1141      |\n",
      "|    time_elapsed    | 4623      |\n",
      "|    total_timesteps | 2336768   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -7.02e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1142        |\n",
      "|    time_elapsed         | 4625        |\n",
      "|    total_timesteps      | 2338816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009907018 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 199         |\n",
      "|    n_updates            | 27320       |\n",
      "|    policy_gradient_loss | -0.000645   |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 2.27e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2340000, episode_reward=16266.32 +/- 2993.18\n",
      "Episode length: 2472.00 +/- 15.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.47e+03    |\n",
      "|    mean_reward          | 1.63e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005200209 |\n",
      "|    clip_fraction        | 0.0672      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 568         |\n",
      "|    n_updates            | 27330       |\n",
      "|    policy_gradient_loss | -0.000899   |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 3.81e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.03e+03  |\n",
      "|    ep_rew_mean     | -5.88e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1143      |\n",
      "|    time_elapsed    | 4632      |\n",
      "|    total_timesteps | 2340864   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.03e+03    |\n",
      "|    ep_rew_mean          | -5.96e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1144        |\n",
      "|    time_elapsed         | 4634        |\n",
      "|    total_timesteps      | 2342912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003577386 |\n",
      "|    clip_fraction        | 0.0194      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 27340       |\n",
      "|    policy_gradient_loss | -0.000116   |\n",
      "|    std                  | 0.167       |\n",
      "|    value_loss           | 6.87e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -5.11e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1145        |\n",
      "|    time_elapsed         | 4636        |\n",
      "|    total_timesteps      | 2344960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009386994 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 27350       |\n",
      "|    policy_gradient_loss | -0.00205    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 732         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2345000, episode_reward=-11220.27 +/- 63985.87\n",
      "Episode length: 2102.40 +/- 1008.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.1e+03     |\n",
      "|    mean_reward          | -1.12e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2345000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010275783 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 246         |\n",
      "|    n_updates            | 27360       |\n",
      "|    policy_gradient_loss | -0.00321    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 2.2e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.02e+03  |\n",
      "|    ep_rew_mean     | -5.11e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1146      |\n",
      "|    time_elapsed    | 4643      |\n",
      "|    total_timesteps | 2347008   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.02e+03   |\n",
      "|    ep_rew_mean          | -2.43e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1147       |\n",
      "|    time_elapsed         | 4645       |\n",
      "|    total_timesteps      | 2349056    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01766669 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.35       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 101        |\n",
      "|    n_updates            | 27370      |\n",
      "|    policy_gradient_loss | 0.00845    |\n",
      "|    std                  | 0.166      |\n",
      "|    value_loss           | 260        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2350000, episode_reward=25433.52 +/- 2903.62\n",
      "Episode length: 2110.40 +/- 13.09\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.11e+03     |\n",
      "|    mean_reward          | 2.54e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2350000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066194786 |\n",
      "|    clip_fraction        | 0.0667       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 200          |\n",
      "|    n_updates            | 27380        |\n",
      "|    policy_gradient_loss | -0.000492    |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 1.65e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.02e+03  |\n",
      "|    ep_rew_mean     | -2.57e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1148      |\n",
      "|    time_elapsed    | 4652      |\n",
      "|    total_timesteps | 2351104   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2e+03      |\n",
      "|    ep_rew_mean          | -2.64e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1149       |\n",
      "|    time_elapsed         | 4654       |\n",
      "|    total_timesteps      | 2353152    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01045008 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.36       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 187        |\n",
      "|    n_updates            | 27390      |\n",
      "|    policy_gradient_loss | 0.00405    |\n",
      "|    std                  | 0.165      |\n",
      "|    value_loss           | 387        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2355000, episode_reward=20199.91 +/- 3440.84\n",
      "Episode length: 1950.80 +/- 16.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.95e+03    |\n",
      "|    mean_reward          | 2.02e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2355000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023171764 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 27400       |\n",
      "|    policy_gradient_loss | 0.00775     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.99e+03  |\n",
      "|    ep_rew_mean     | -2.97e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1150      |\n",
      "|    time_elapsed    | 4660      |\n",
      "|    total_timesteps | 2355200   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.98e+03  |\n",
      "|    ep_rew_mean          | -3.06e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 505       |\n",
      "|    iterations           | 1151      |\n",
      "|    time_elapsed         | 4662      |\n",
      "|    total_timesteps      | 2357248   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.046492  |\n",
      "|    clip_fraction        | 0.37      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.35      |\n",
      "|    explained_variance   | 0.4       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.3e+07   |\n",
      "|    n_updates            | 27410     |\n",
      "|    policy_gradient_loss | 0.0273    |\n",
      "|    std                  | 0.166     |\n",
      "|    value_loss           | 1.95e+07  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.96e+03    |\n",
      "|    ep_rew_mean          | -4.06e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1152        |\n",
      "|    time_elapsed         | 4664        |\n",
      "|    total_timesteps      | 2359296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012016432 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.9        |\n",
      "|    n_updates            | 27420       |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.48e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2360000, episode_reward=25719.09 +/- 2983.39\n",
      "Episode length: 2123.20 +/- 9.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.12e+03    |\n",
      "|    mean_reward          | 2.57e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012544047 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34e+06    |\n",
      "|    n_updates            | 27430       |\n",
      "|    policy_gradient_loss | 0.00305     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.2e+07     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.96e+03 |\n",
      "|    ep_rew_mean     | -4e+03   |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1153     |\n",
      "|    time_elapsed    | 4671     |\n",
      "|    total_timesteps | 2361344  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.96e+03    |\n",
      "|    ep_rew_mean          | -4.03e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1154        |\n",
      "|    time_elapsed         | 4672        |\n",
      "|    total_timesteps      | 2363392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007866944 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.62e+04    |\n",
      "|    n_updates            | 27440       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 2.94e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2365000, episode_reward=25587.68 +/- 2877.91\n",
      "Episode length: 2153.80 +/- 14.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.15e+03    |\n",
      "|    mean_reward          | 2.56e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2365000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016968861 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 207         |\n",
      "|    n_updates            | 27450       |\n",
      "|    policy_gradient_loss | 0.000782    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 5.08e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.98e+03  |\n",
      "|    ep_rew_mean     | -2.37e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1155      |\n",
      "|    time_elapsed    | 4679      |\n",
      "|    total_timesteps | 2365440   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.98e+03    |\n",
      "|    ep_rew_mean          | -2.28e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1156        |\n",
      "|    time_elapsed         | 4681        |\n",
      "|    total_timesteps      | 2367488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017698355 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 300         |\n",
      "|    n_updates            | 27460       |\n",
      "|    policy_gradient_loss | 0.00444     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.53e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.98e+03    |\n",
      "|    ep_rew_mean          | -2.4e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1157        |\n",
      "|    time_elapsed         | 4683        |\n",
      "|    total_timesteps      | 2369536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026073202 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 27470       |\n",
      "|    policy_gradient_loss | -0.00234    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 506         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2370000, episode_reward=23298.34 +/- 811.04\n",
      "Episode length: 1799.40 +/- 10.40\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.8e+03    |\n",
      "|    mean_reward          | 2.33e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2370000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01014777 |\n",
      "|    clip_fraction        | 0.117      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.36       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 230        |\n",
      "|    n_updates            | 27480      |\n",
      "|    policy_gradient_loss | -0.00601   |\n",
      "|    std                  | 0.165      |\n",
      "|    value_loss           | 1.01e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.97e+03  |\n",
      "|    ep_rew_mean     | -3.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1158      |\n",
      "|    time_elapsed    | 4689      |\n",
      "|    total_timesteps | 2371584   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.96e+03     |\n",
      "|    ep_rew_mean          | -3.47e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 1159         |\n",
      "|    time_elapsed         | 4691         |\n",
      "|    total_timesteps      | 2373632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019974043 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.334        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.52e+07     |\n",
      "|    n_updates            | 27490        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 1.32e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2375000, episode_reward=-20678.67 +/- 84974.31\n",
      "Episode length: 1533.00 +/- 707.03\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.53e+03     |\n",
      "|    mean_reward          | -2.07e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2375000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057843635 |\n",
      "|    clip_fraction        | 0.064        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.4e+04      |\n",
      "|    n_updates            | 27500        |\n",
      "|    policy_gradient_loss | -0.00975     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 7.96e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -4.47e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1160      |\n",
      "|    time_elapsed    | 4697      |\n",
      "|    total_timesteps | 2375680   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.93e+03     |\n",
      "|    ep_rew_mean          | -4.63e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 1161         |\n",
      "|    time_elapsed         | 4699         |\n",
      "|    total_timesteps      | 2377728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016171716 |\n",
      "|    clip_fraction        | 0.00986      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6e+06        |\n",
      "|    n_updates            | 27510        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 1.16e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.91e+03    |\n",
      "|    ep_rew_mean          | -5.81e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1162        |\n",
      "|    time_elapsed         | 4700        |\n",
      "|    total_timesteps      | 2379776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007352674 |\n",
      "|    clip_fraction        | 0.0463      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.65e+03    |\n",
      "|    n_updates            | 27520       |\n",
      "|    policy_gradient_loss | -0.00395    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 2.13e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2380000, episode_reward=-19948.33 +/- 83135.89\n",
      "Episode length: 1601.40 +/- 742.92\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6e+03      |\n",
      "|    mean_reward          | -1.99e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2380000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035113469 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.68e+07     |\n",
      "|    n_updates            | 27530        |\n",
      "|    policy_gradient_loss | -0.00164     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 1.48e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -4.17e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1163      |\n",
      "|    time_elapsed    | 4706      |\n",
      "|    total_timesteps | 2381824   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.92e+03     |\n",
      "|    ep_rew_mean          | -4.26e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 1164         |\n",
      "|    time_elapsed         | 4708         |\n",
      "|    total_timesteps      | 2383872      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077009406 |\n",
      "|    clip_fraction        | 0.0574       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.714        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.93e+03     |\n",
      "|    n_updates            | 27540        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 3.1e+04      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2385000, episode_reward=20922.16 +/- 2225.93\n",
      "Episode length: 2293.00 +/- 13.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.29e+03     |\n",
      "|    mean_reward          | 2.09e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2385000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060207406 |\n",
      "|    clip_fraction        | 0.0574       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.857        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.38e+03     |\n",
      "|    n_updates            | 27550        |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 2.91e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.92e+03  |\n",
      "|    ep_rew_mean     | -4.19e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1165      |\n",
      "|    time_elapsed    | 4715      |\n",
      "|    total_timesteps | 2385920   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.9e+03      |\n",
      "|    ep_rew_mean          | -5.48e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 1166         |\n",
      "|    time_elapsed         | 4717         |\n",
      "|    total_timesteps      | 2387968      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077474825 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.22e+03     |\n",
      "|    n_updates            | 27560        |\n",
      "|    policy_gradient_loss | -0.00658     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 5.12e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2390000, episode_reward=20466.59 +/- 4364.56\n",
      "Episode length: 1947.00 +/- 7.24\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.95e+03   |\n",
      "|    mean_reward          | 2.05e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2390000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28027076 |\n",
      "|    clip_fraction        | 0.125      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.36       |\n",
      "|    explained_variance   | 0.363      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.14e+06   |\n",
      "|    n_updates            | 27570      |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    std                  | 0.165      |\n",
      "|    value_loss           | 3.16e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.9e+03   |\n",
      "|    ep_rew_mean     | -5.53e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1167      |\n",
      "|    time_elapsed    | 4723      |\n",
      "|    total_timesteps | 2390016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.89e+03    |\n",
      "|    ep_rew_mean          | -6.43e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1168        |\n",
      "|    time_elapsed         | 4725        |\n",
      "|    total_timesteps      | 2392064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016963568 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 256         |\n",
      "|    n_updates            | 27580       |\n",
      "|    policy_gradient_loss | -0.00259    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 2.07e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.88e+03     |\n",
      "|    ep_rew_mean          | -7.29e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 1169         |\n",
      "|    time_elapsed         | 4727         |\n",
      "|    total_timesteps      | 2394112      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031720842 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02e+06     |\n",
      "|    n_updates            | 27590        |\n",
      "|    policy_gradient_loss | 0.000781     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 1.02e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2395000, episode_reward=18575.33 +/- 3302.34\n",
      "Episode length: 2407.80 +/- 18.21\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.41e+03     |\n",
      "|    mean_reward          | 1.86e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2395000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066318577 |\n",
      "|    clip_fraction        | 0.0329       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+07     |\n",
      "|    n_updates            | 27600        |\n",
      "|    policy_gradient_loss | 0.000948     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 1.35e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.87e+03  |\n",
      "|    ep_rew_mean     | -8.45e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1170      |\n",
      "|    time_elapsed    | 4735      |\n",
      "|    total_timesteps | 2396160   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.87e+03     |\n",
      "|    ep_rew_mean          | -8.52e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 1171         |\n",
      "|    time_elapsed         | 4736         |\n",
      "|    total_timesteps      | 2398208      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040452434 |\n",
      "|    clip_fraction        | 0.0118       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.483        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+07     |\n",
      "|    n_updates            | 27610        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 1.27e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2400000, episode_reward=-16689.90 +/- 75796.29\n",
      "Episode length: 1992.00 +/- 944.07\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.99e+03   |\n",
      "|    mean_reward          | -1.67e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2400000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00721656 |\n",
      "|    clip_fraction        | 0.0423     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.36       |\n",
      "|    explained_variance   | 0.75       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.8e+03    |\n",
      "|    n_updates            | 27620      |\n",
      "|    policy_gradient_loss | -0.00034   |\n",
      "|    std                  | 0.165      |\n",
      "|    value_loss           | 5.46e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.87e+03  |\n",
      "|    ep_rew_mean     | -8.43e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1172      |\n",
      "|    time_elapsed    | 4743      |\n",
      "|    total_timesteps | 2400256   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.88e+03    |\n",
      "|    ep_rew_mean          | -8.43e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1173        |\n",
      "|    time_elapsed         | 4745        |\n",
      "|    total_timesteps      | 2402304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010229537 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.778       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 27630       |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 6.86e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.88e+03    |\n",
      "|    ep_rew_mean          | -8.42e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1174        |\n",
      "|    time_elapsed         | 4747        |\n",
      "|    total_timesteps      | 2404352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008376857 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 27640       |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 3.25e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2405000, episode_reward=23688.66 +/- 3060.00\n",
      "Episode length: 1904.80 +/- 10.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.9e+03     |\n",
      "|    mean_reward          | 2.37e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2405000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011669502 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 27650       |\n",
      "|    policy_gradient_loss | -0.00574    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.99e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.84e+03 |\n",
      "|    ep_rew_mean     | -1.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 1175     |\n",
      "|    time_elapsed    | 4753     |\n",
      "|    total_timesteps | 2406400  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.84e+03     |\n",
      "|    ep_rew_mean          | -1.21e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 1176         |\n",
      "|    time_elapsed         | 4755         |\n",
      "|    total_timesteps      | 2408448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066141933 |\n",
      "|    clip_fraction        | 0.0669       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.37         |\n",
      "|    explained_variance   | 0.343        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.27e+07     |\n",
      "|    n_updates            | 27660        |\n",
      "|    policy_gradient_loss | 0.00839      |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 5.51e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2410000, episode_reward=21266.01 +/- 4313.24\n",
      "Episode length: 1808.20 +/- 8.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.81e+03    |\n",
      "|    mean_reward          | 2.13e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030699626 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.3        |\n",
      "|    n_updates            | 27670       |\n",
      "|    policy_gradient_loss | -0.00295    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 690         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.84e+03 |\n",
      "|    ep_rew_mean     | -1.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 1177     |\n",
      "|    time_elapsed    | 4761     |\n",
      "|    total_timesteps | 2410496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.84e+03    |\n",
      "|    ep_rew_mean          | -1.2e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1178        |\n",
      "|    time_elapsed         | 4763        |\n",
      "|    total_timesteps      | 2412544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011074331 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 331         |\n",
      "|    n_updates            | 27680       |\n",
      "|    policy_gradient_loss | 0.00144     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.42e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | -1.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1179        |\n",
      "|    time_elapsed         | 4765        |\n",
      "|    total_timesteps      | 2414592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030715099 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 137         |\n",
      "|    n_updates            | 27690       |\n",
      "|    policy_gradient_loss | 0.00766     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 909         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2415000, episode_reward=-12894.95 +/- 67638.55\n",
      "Episode length: 1457.00 +/- 684.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.46e+03   |\n",
      "|    mean_reward          | -1.29e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2415000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44274762 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.38       |\n",
      "|    explained_variance   | 0.388      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.11e+07   |\n",
      "|    n_updates            | 27700      |\n",
      "|    policy_gradient_loss | -0.0218    |\n",
      "|    std                  | 0.164      |\n",
      "|    value_loss           | 2.9e+07    |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.82e+03  |\n",
      "|    ep_rew_mean     | -1.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1180      |\n",
      "|    time_elapsed    | 4770      |\n",
      "|    total_timesteps | 2416640   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | -1.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1181        |\n",
      "|    time_elapsed         | 4772        |\n",
      "|    total_timesteps      | 2418688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030070323 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02e+03    |\n",
      "|    n_updates            | 27710       |\n",
      "|    policy_gradient_loss | 0.00743     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 3.98e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2420000, episode_reward=20428.40 +/- 2767.03\n",
      "Episode length: 1664.00 +/- 17.26\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.66e+03   |\n",
      "|    mean_reward          | 2.04e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2420000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02732892 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.37       |\n",
      "|    explained_variance   | 0.925      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 227        |\n",
      "|    n_updates            | 27720      |\n",
      "|    policy_gradient_loss | 0.00121    |\n",
      "|    std                  | 0.165      |\n",
      "|    value_loss           | 2.47e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.83e+03  |\n",
      "|    ep_rew_mean     | -1.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1182      |\n",
      "|    time_elapsed    | 4778      |\n",
      "|    total_timesteps | 2420736   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | -1.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1183        |\n",
      "|    time_elapsed         | 4779        |\n",
      "|    total_timesteps      | 2422784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014416709 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 305         |\n",
      "|    n_updates            | 27730       |\n",
      "|    policy_gradient_loss | 0.00135     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 2.21e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.82e+03    |\n",
      "|    ep_rew_mean          | -1.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1184        |\n",
      "|    time_elapsed         | 4781        |\n",
      "|    total_timesteps      | 2424832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005587046 |\n",
      "|    clip_fraction        | 0.0771      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.42e+06    |\n",
      "|    n_updates            | 27740       |\n",
      "|    policy_gradient_loss | 0.00664     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.1e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2425000, episode_reward=21698.10 +/- 3508.61\n",
      "Episode length: 1701.20 +/- 7.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 2.17e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2425000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016958812 |\n",
      "|    clip_fraction        | 0.0794      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 672         |\n",
      "|    n_updates            | 27750       |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.09e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.81e+03 |\n",
      "|    ep_rew_mean     | -1.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 1185     |\n",
      "|    time_elapsed    | 4787     |\n",
      "|    total_timesteps | 2426880  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.8e+03      |\n",
      "|    ep_rew_mean          | -1.19e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 1186         |\n",
      "|    time_elapsed         | 4789         |\n",
      "|    total_timesteps      | 2428928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029432138 |\n",
      "|    clip_fraction        | 0.0195       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.38         |\n",
      "|    explained_variance   | 0.329        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+07     |\n",
      "|    n_updates            | 27760        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 1.65e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2430000, episode_reward=22525.62 +/- 2023.57\n",
      "Episode length: 1699.00 +/- 10.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 2.25e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007837375 |\n",
      "|    clip_fraction        | 0.0521      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.94e+03    |\n",
      "|    n_updates            | 27770       |\n",
      "|    policy_gradient_loss | -0.00528    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 3.24e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.78e+03  |\n",
      "|    ep_rew_mean     | -1.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1187      |\n",
      "|    time_elapsed    | 4795      |\n",
      "|    total_timesteps | 2430976   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | -1.27e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1188        |\n",
      "|    time_elapsed         | 4797        |\n",
      "|    total_timesteps      | 2433024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007349555 |\n",
      "|    clip_fraction        | 0.0725      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 650         |\n",
      "|    n_updates            | 27780       |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 3.18e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2435000, episode_reward=20054.13 +/- 3818.98\n",
      "Episode length: 1696.80 +/- 12.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.7e+03      |\n",
      "|    mean_reward          | 2.01e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2435000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035089243 |\n",
      "|    clip_fraction        | 0.0739       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.38         |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.55e+06     |\n",
      "|    n_updates            | 27790        |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 1.21e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -1.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 1189      |\n",
      "|    time_elapsed    | 4803      |\n",
      "|    total_timesteps | 2435072   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.74e+03    |\n",
      "|    ep_rew_mean          | -1.25e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1190        |\n",
      "|    time_elapsed         | 4805        |\n",
      "|    total_timesteps      | 2437120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011553964 |\n",
      "|    clip_fraction        | 0.052       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69e+03    |\n",
      "|    n_updates            | 27800       |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 3.36e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | -1.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1191        |\n",
      "|    time_elapsed         | 4806        |\n",
      "|    total_timesteps      | 2439168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019124437 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 27810       |\n",
      "|    policy_gradient_loss | 0.00648     |\n",
      "|    std                  | 0.164       |\n",
      "|    value_loss           | 665         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2440000, episode_reward=-11784.91 +/- 68263.08\n",
      "Episode length: 1318.60 +/- 614.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.32e+03    |\n",
      "|    mean_reward          | -1.18e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016173298 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 171         |\n",
      "|    n_updates            | 27820       |\n",
      "|    policy_gradient_loss | -0.00283    |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 3.65e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -1.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1192      |\n",
      "|    time_elapsed    | 4811      |\n",
      "|    total_timesteps | 2441216   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | -9.89e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1193        |\n",
      "|    time_elapsed         | 4813        |\n",
      "|    total_timesteps      | 2443264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053148378 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 330         |\n",
      "|    n_updates            | 27830       |\n",
      "|    policy_gradient_loss | 0.0094      |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 2.71e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2445000, episode_reward=21810.85 +/- 833.33\n",
      "Episode length: 1565.20 +/- 9.89\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.57e+03   |\n",
      "|    mean_reward          | 2.18e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2445000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23957707 |\n",
      "|    clip_fraction        | 0.182      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 0.389      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.53e+07   |\n",
      "|    n_updates            | 27840      |\n",
      "|    policy_gradient_loss | -0.0201    |\n",
      "|    std                  | 0.163      |\n",
      "|    value_loss           | 2.44e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -9.88e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1194      |\n",
      "|    time_elapsed    | 4819      |\n",
      "|    total_timesteps | 2445312   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.72e+03  |\n",
      "|    ep_rew_mean          | -9.81e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 507       |\n",
      "|    iterations           | 1195      |\n",
      "|    time_elapsed         | 4821      |\n",
      "|    total_timesteps      | 2447360   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.2815116 |\n",
      "|    clip_fraction        | 0.202     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.41      |\n",
      "|    explained_variance   | 0.395     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.21e+07  |\n",
      "|    n_updates            | 27850     |\n",
      "|    policy_gradient_loss | -0.0197   |\n",
      "|    std                  | 0.163     |\n",
      "|    value_loss           | 2.37e+07  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.67e+03   |\n",
      "|    ep_rew_mean          | -1.14e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 507        |\n",
      "|    iterations           | 1196       |\n",
      "|    time_elapsed         | 4823       |\n",
      "|    total_timesteps      | 2449408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03184127 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.41       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 61.1       |\n",
      "|    n_updates            | 27860      |\n",
      "|    policy_gradient_loss | 0.00167    |\n",
      "|    std                  | 0.163      |\n",
      "|    value_loss           | 292        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2450000, episode_reward=-12916.97 +/- 67395.75\n",
      "Episode length: 1261.40 +/- 586.31\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.26e+03   |\n",
      "|    mean_reward          | -1.29e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2450000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15238267 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.41       |\n",
      "|    explained_variance   | 0.39       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.77e+06   |\n",
      "|    n_updates            | 27870      |\n",
      "|    policy_gradient_loss | 0.0248     |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.32e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.65e+03  |\n",
      "|    ep_rew_mean     | -1.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1197      |\n",
      "|    time_elapsed    | 4827      |\n",
      "|    total_timesteps | 2451456   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.65e+03   |\n",
      "|    ep_rew_mean          | -1.12e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 507        |\n",
      "|    iterations           | 1198       |\n",
      "|    time_elapsed         | 4829       |\n",
      "|    total_timesteps      | 2453504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22244948 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.41       |\n",
      "|    explained_variance   | 0.394      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.37e+07   |\n",
      "|    n_updates            | 27880      |\n",
      "|    policy_gradient_loss | 0.00059    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.17e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2455000, episode_reward=20131.60 +/- 3029.43\n",
      "Episode length: 1684.40 +/- 9.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.68e+03    |\n",
      "|    mean_reward          | 2.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2455000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041443624 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 27890       |\n",
      "|    policy_gradient_loss | 0.00561     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 378         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.61e+03  |\n",
      "|    ep_rew_mean     | -1.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1199      |\n",
      "|    time_elapsed    | 4835      |\n",
      "|    total_timesteps | 2455552   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.6e+03   |\n",
      "|    ep_rew_mean          | -1.28e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 508       |\n",
      "|    iterations           | 1200      |\n",
      "|    time_elapsed         | 4837      |\n",
      "|    total_timesteps      | 2457600   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.6385807 |\n",
      "|    clip_fraction        | 0.216     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.43      |\n",
      "|    explained_variance   | 0.394     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.6e+06   |\n",
      "|    n_updates            | 27900     |\n",
      "|    policy_gradient_loss | -0.00403  |\n",
      "|    std                  | 0.161     |\n",
      "|    value_loss           | 2.4e+07   |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.6e+03    |\n",
      "|    ep_rew_mean          | -1.26e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 508        |\n",
      "|    iterations           | 1201       |\n",
      "|    time_elapsed         | 4839       |\n",
      "|    total_timesteps      | 2459648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02861156 |\n",
      "|    clip_fraction        | 0.369      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.43       |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 212        |\n",
      "|    n_updates            | 27910      |\n",
      "|    policy_gradient_loss | 0.0203     |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 2.29e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2460000, episode_reward=-13233.84 +/- 72032.02\n",
      "Episode length: 1954.40 +/- 927.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.95e+03    |\n",
      "|    mean_reward          | -1.32e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038729314 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.43        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 142         |\n",
      "|    n_updates            | 27920       |\n",
      "|    policy_gradient_loss | 0.00997     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.38e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -1.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1202      |\n",
      "|    time_elapsed    | 4846      |\n",
      "|    total_timesteps | 2461696   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | -1.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1203        |\n",
      "|    time_elapsed         | 4847        |\n",
      "|    total_timesteps      | 2463744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036508486 |\n",
      "|    clip_fraction        | 0.545       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.78e+06    |\n",
      "|    n_updates            | 27930       |\n",
      "|    policy_gradient_loss | 0.0373      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 2.44e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2465000, episode_reward=23130.94 +/- 2493.18\n",
      "Episode length: 2316.60 +/- 10.25\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.32e+03     |\n",
      "|    mean_reward          | 2.31e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2465000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020706896 |\n",
      "|    clip_fraction        | 0.00674      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.42         |\n",
      "|    explained_variance   | 0.461        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.44e+07     |\n",
      "|    n_updates            | 27940        |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 1.23e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -1.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 1204      |\n",
      "|    time_elapsed    | 4855      |\n",
      "|    total_timesteps | 2465792   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.5e+03     |\n",
      "|    ep_rew_mean          | -1.6e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1205        |\n",
      "|    time_elapsed         | 4857        |\n",
      "|    total_timesteps      | 2467840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006416297 |\n",
      "|    clip_fraction        | 0.0397      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.87e+06    |\n",
      "|    n_updates            | 27950       |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 3.33e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.5e+03      |\n",
      "|    ep_rew_mean          | -1.59e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1206         |\n",
      "|    time_elapsed         | 4858         |\n",
      "|    total_timesteps      | 2469888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027395992 |\n",
      "|    clip_fraction        | 0.0165       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.42         |\n",
      "|    explained_variance   | 0.482        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.68e+06     |\n",
      "|    n_updates            | 27960        |\n",
      "|    policy_gradient_loss | -0.0039      |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 2.2e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2470000, episode_reward=-4807.65 +/- 57254.54\n",
      "Episode length: 2083.20 +/- 166.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.08e+03     |\n",
      "|    mean_reward          | -4.81e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2470000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050737374 |\n",
      "|    clip_fraction        | 0.037        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.42         |\n",
      "|    explained_variance   | 0.709        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.25e+03     |\n",
      "|    n_updates            | 27970        |\n",
      "|    policy_gradient_loss | -0.00201     |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 5.35e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.49e+03  |\n",
      "|    ep_rew_mean     | -1.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 1207      |\n",
      "|    time_elapsed    | 4865      |\n",
      "|    total_timesteps | 2471936   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.49e+03   |\n",
      "|    ep_rew_mean          | -1.57e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 508        |\n",
      "|    iterations           | 1208       |\n",
      "|    time_elapsed         | 4867       |\n",
      "|    total_timesteps      | 2473984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01286227 |\n",
      "|    clip_fraction        | 0.0964     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.42       |\n",
      "|    explained_variance   | 0.795      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 889        |\n",
      "|    n_updates            | 27980      |\n",
      "|    policy_gradient_loss | -0.00387   |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 3.64e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2475000, episode_reward=-13890.54 +/- 69944.23\n",
      "Episode length: 1899.80 +/- 902.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.9e+03      |\n",
      "|    mean_reward          | -1.39e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2475000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074144793 |\n",
      "|    clip_fraction        | 0.0715       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.42         |\n",
      "|    explained_variance   | 0.869        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 515          |\n",
      "|    n_updates            | 27990        |\n",
      "|    policy_gradient_loss | 0.000442     |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 2.86e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -1.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 1209      |\n",
      "|    time_elapsed    | 4874      |\n",
      "|    total_timesteps | 2476032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -1.82e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1210        |\n",
      "|    time_elapsed         | 4875        |\n",
      "|    total_timesteps      | 2478080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010800213 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.33e+07    |\n",
      "|    n_updates            | 28000       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 3.65e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2480000, episode_reward=-48379.02 +/- 89679.09\n",
      "Episode length: 1449.00 +/- 1099.82\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.45e+03     |\n",
      "|    mean_reward          | -4.84e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067205857 |\n",
      "|    clip_fraction        | 0.0262       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.42         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.13e+07     |\n",
      "|    n_updates            | 28010        |\n",
      "|    policy_gradient_loss | -0.0082      |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 2.42e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -1.94e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 1211      |\n",
      "|    time_elapsed    | 4881      |\n",
      "|    total_timesteps | 2480128   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.46e+03     |\n",
      "|    ep_rew_mean          | -1.94e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1212         |\n",
      "|    time_elapsed         | 4883         |\n",
      "|    total_timesteps      | 2482176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069229174 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.42         |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.13e+07     |\n",
      "|    n_updates            | 28020        |\n",
      "|    policy_gradient_loss | 0.000463     |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 2.5e+07      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | -1.93e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 508        |\n",
      "|    iterations           | 1213       |\n",
      "|    time_elapsed         | 4884       |\n",
      "|    total_timesteps      | 2484224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02266836 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.42       |\n",
      "|    explained_variance   | 0.923      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 740        |\n",
      "|    n_updates            | 28030      |\n",
      "|    policy_gradient_loss | -0.00619   |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 4.54e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2485000, episode_reward=20822.31 +/- 3191.10\n",
      "Episode length: 2426.20 +/- 27.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.43e+03    |\n",
      "|    mean_reward          | 2.08e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2485000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013733482 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 28040       |\n",
      "|    policy_gradient_loss | 0.00245     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 4.65e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.4e+03   |\n",
      "|    ep_rew_mean     | -2.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 1214      |\n",
      "|    time_elapsed    | 4892      |\n",
      "|    total_timesteps | 2486272   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.41e+03     |\n",
      "|    ep_rew_mean          | -2.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1215         |\n",
      "|    time_elapsed         | 4894         |\n",
      "|    total_timesteps      | 2488320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048803394 |\n",
      "|    clip_fraction        | 0.0511       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.72e+07     |\n",
      "|    n_updates            | 28050        |\n",
      "|    policy_gradient_loss | -0.000622    |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 6.2e+07      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2490000, episode_reward=-84166.77 +/- 88410.95\n",
      "Episode length: 859.60 +/- 932.15\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 860         |\n",
      "|    mean_reward          | -8.42e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004026647 |\n",
      "|    clip_fraction        | 0.0225      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.71e+03    |\n",
      "|    n_updates            | 28060       |\n",
      "|    policy_gradient_loss | -0.000838   |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 8.41e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.4e+03   |\n",
      "|    ep_rew_mean     | -2.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 1216      |\n",
      "|    time_elapsed    | 4898      |\n",
      "|    total_timesteps | 2490368   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | -2.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1217        |\n",
      "|    time_elapsed         | 4900        |\n",
      "|    total_timesteps      | 2492416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027754702 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.65e+03    |\n",
      "|    n_updates            | 28070       |\n",
      "|    policy_gradient_loss | 0.000478    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.31e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | -2.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1218        |\n",
      "|    time_elapsed         | 4901        |\n",
      "|    total_timesteps      | 2494464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056911726 |\n",
      "|    clip_fraction        | 0.0778      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.378       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.23e+07    |\n",
      "|    n_updates            | 28080       |\n",
      "|    policy_gradient_loss | 0.00671     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 4.92e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2495000, episode_reward=-17916.20 +/- 73627.55\n",
      "Episode length: 1458.80 +/- 677.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.46e+03    |\n",
      "|    mean_reward          | -1.79e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2495000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008964699 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 28090       |\n",
      "|    policy_gradient_loss | 0.00478     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.89e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.39e+03  |\n",
      "|    ep_rew_mean     | -2.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 1219      |\n",
      "|    time_elapsed    | 4907      |\n",
      "|    total_timesteps | 2496512   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | -2.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1220        |\n",
      "|    time_elapsed         | 4909        |\n",
      "|    total_timesteps      | 2498560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028199378 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+05    |\n",
      "|    n_updates            | 28100       |\n",
      "|    policy_gradient_loss | 0.02        |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 7.05e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2500000, episode_reward=22516.79 +/- 2493.27\n",
      "Episode length: 2302.80 +/- 6.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.3e+03     |\n",
      "|    mean_reward          | 2.25e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051726937 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.1        |\n",
      "|    n_updates            | 28110       |\n",
      "|    policy_gradient_loss | 0.0158      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 488         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.37e+03  |\n",
      "|    ep_rew_mean     | -2.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 1221      |\n",
      "|    time_elapsed    | 4916      |\n",
      "|    total_timesteps | 2500608   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | -2.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1222        |\n",
      "|    time_elapsed         | 4918        |\n",
      "|    total_timesteps      | 2502656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008535988 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+07    |\n",
      "|    n_updates            | 28120       |\n",
      "|    policy_gradient_loss | 0.00685     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 4.28e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | -2.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1223        |\n",
      "|    time_elapsed         | 4920        |\n",
      "|    total_timesteps      | 2504704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017930869 |\n",
      "|    clip_fraction        | 0.0864      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.07e+03    |\n",
      "|    n_updates            | 28130       |\n",
      "|    policy_gradient_loss | -0.00319    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 3.24e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2505000, episode_reward=-51594.02 +/- 92451.46\n",
      "Episode length: 1512.40 +/- 1155.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.51e+03   |\n",
      "|    mean_reward          | -5.16e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2505000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03190456 |\n",
      "|    clip_fraction        | 0.0808     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.41       |\n",
      "|    explained_variance   | 0.387      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.76e+07   |\n",
      "|    n_updates            | 28140      |\n",
      "|    policy_gradient_loss | 0.00191    |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 2.78e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.36e+03  |\n",
      "|    ep_rew_mean     | -2.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 508       |\n",
      "|    iterations      | 1224      |\n",
      "|    time_elapsed    | 4925      |\n",
      "|    total_timesteps | 2506752   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | -2.88e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1225        |\n",
      "|    time_elapsed         | 4927        |\n",
      "|    total_timesteps      | 2508800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008528741 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.544       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 198         |\n",
      "|    n_updates            | 28150       |\n",
      "|    policy_gradient_loss | -0.000764   |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 3.75e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2510000, episode_reward=-89381.88 +/- 90195.89\n",
      "Episode length: 998.40 +/- 1097.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 998        |\n",
      "|    mean_reward          | -8.94e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2510000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03673817 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.41       |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 89.4       |\n",
      "|    n_updates            | 28160      |\n",
      "|    policy_gradient_loss | 0.00971    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 547        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.35e+03  |\n",
      "|    ep_rew_mean     | -3.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1226      |\n",
      "|    time_elapsed    | 4931      |\n",
      "|    total_timesteps | 2510848   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.35e+03  |\n",
      "|    ep_rew_mean          | -3.13e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 509       |\n",
      "|    iterations           | 1227      |\n",
      "|    time_elapsed         | 4933      |\n",
      "|    total_timesteps      | 2512896   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7204009 |\n",
      "|    clip_fraction        | 0.222     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.4       |\n",
      "|    explained_variance   | 0.388     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.29e+07  |\n",
      "|    n_updates            | 28170     |\n",
      "|    policy_gradient_loss | 0.0164    |\n",
      "|    std                  | 0.162     |\n",
      "|    value_loss           | 5.19e+07  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.35e+03     |\n",
      "|    ep_rew_mean          | -3.14e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 509          |\n",
      "|    iterations           | 1228         |\n",
      "|    time_elapsed         | 4935         |\n",
      "|    total_timesteps      | 2514944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052746264 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.64         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.36e+05     |\n",
      "|    n_updates            | 28180        |\n",
      "|    policy_gradient_loss | -0.00434     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 1.47e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2515000, episode_reward=-19206.76 +/- 72046.23\n",
      "Episode length: 1502.00 +/- 700.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.5e+03     |\n",
      "|    mean_reward          | -1.92e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2515000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011016661 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 28190       |\n",
      "|    policy_gradient_loss | 0.000117    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.62e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.37e+03  |\n",
      "|    ep_rew_mean     | -3.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1229      |\n",
      "|    time_elapsed    | 4940      |\n",
      "|    total_timesteps | 2516992   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.37e+03   |\n",
      "|    ep_rew_mean          | -3.05e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 509        |\n",
      "|    iterations           | 1230       |\n",
      "|    time_elapsed         | 4942       |\n",
      "|    total_timesteps      | 2519040    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03415834 |\n",
      "|    clip_fraction        | 0.377      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.41       |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 88.4       |\n",
      "|    n_updates            | 28200      |\n",
      "|    policy_gradient_loss | 0.0186     |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 1.96e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2520000, episode_reward=20790.33 +/- 2604.44\n",
      "Episode length: 1869.00 +/- 11.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.87e+03    |\n",
      "|    mean_reward          | 2.08e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030813526 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.9        |\n",
      "|    n_updates            | 28210       |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 201         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.37e+03  |\n",
      "|    ep_rew_mean     | -3.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1231      |\n",
      "|    time_elapsed    | 4949      |\n",
      "|    total_timesteps | 2521088   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | -3.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1232        |\n",
      "|    time_elapsed         | 4950        |\n",
      "|    total_timesteps      | 2523136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038187344 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 28220       |\n",
      "|    policy_gradient_loss | 0.0227      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 6.39e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2525000, episode_reward=24605.18 +/- 4545.26\n",
      "Episode length: 2523.20 +/- 12.62\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.52e+03   |\n",
      "|    mean_reward          | 2.46e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2525000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01649628 |\n",
      "|    clip_fraction        | 0.0891     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 0.303      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.73e+06   |\n",
      "|    n_updates            | 28230      |\n",
      "|    policy_gradient_loss | 0.00641    |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 2.34e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.36e+03  |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1233      |\n",
      "|    time_elapsed    | 4958      |\n",
      "|    total_timesteps | 2525184   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.37e+03   |\n",
      "|    ep_rew_mean          | -3.02e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 509        |\n",
      "|    iterations           | 1234       |\n",
      "|    time_elapsed         | 4960       |\n",
      "|    total_timesteps      | 2527232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01853747 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 0.904      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.15e+03   |\n",
      "|    n_updates            | 28240      |\n",
      "|    policy_gradient_loss | 0.00281    |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 1.96e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | -3.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1235        |\n",
      "|    time_elapsed         | 4962        |\n",
      "|    total_timesteps      | 2529280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014520771 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 297         |\n",
      "|    n_updates            | 28250       |\n",
      "|    policy_gradient_loss | -0.000592   |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.18e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2530000, episode_reward=23783.64 +/- 2663.01\n",
      "Episode length: 2197.80 +/- 9.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.2e+03     |\n",
      "|    mean_reward          | 2.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012238085 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 135         |\n",
      "|    n_updates            | 28260       |\n",
      "|    policy_gradient_loss | 0.00344     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 316         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.38e+03  |\n",
      "|    ep_rew_mean     | -3.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1236      |\n",
      "|    time_elapsed    | 4969      |\n",
      "|    total_timesteps | 2531328   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.38e+03     |\n",
      "|    ep_rew_mean          | -2.99e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 509          |\n",
      "|    iterations           | 1237         |\n",
      "|    time_elapsed         | 4971         |\n",
      "|    total_timesteps      | 2533376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0127387475 |\n",
      "|    clip_fraction        | 0.0716       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.4          |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.04e+07     |\n",
      "|    n_updates            | 28270        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 2.71e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2535000, episode_reward=20191.91 +/- 4675.50\n",
      "Episode length: 2044.40 +/- 11.06\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.04e+03   |\n",
      "|    mean_reward          | 2.02e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2535000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01976147 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 0.701      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 209        |\n",
      "|    n_updates            | 28280      |\n",
      "|    policy_gradient_loss | 0.00306    |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 5.31e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.39e+03  |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1238      |\n",
      "|    time_elapsed    | 4978      |\n",
      "|    total_timesteps | 2535424   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.39e+03     |\n",
      "|    ep_rew_mean          | -3.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 509          |\n",
      "|    iterations           | 1239         |\n",
      "|    time_elapsed         | 4980         |\n",
      "|    total_timesteps      | 2537472      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061422735 |\n",
      "|    clip_fraction        | 0.0718       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.322        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.63e+06     |\n",
      "|    n_updates            | 28290        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 1.79e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.4e+03    |\n",
      "|    ep_rew_mean          | -3e+04     |\n",
      "| time/                   |            |\n",
      "|    fps                  | 509        |\n",
      "|    iterations           | 1240       |\n",
      "|    time_elapsed         | 4981       |\n",
      "|    total_timesteps      | 2539520    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03438781 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.41       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 134        |\n",
      "|    n_updates            | 28300      |\n",
      "|    policy_gradient_loss | 0.0102     |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 457        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2540000, episode_reward=-48487.97 +/- 94063.97\n",
      "Episode length: 1492.80 +/- 1135.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.49e+03    |\n",
      "|    mean_reward          | -4.85e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006296276 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 910         |\n",
      "|    n_updates            | 28310       |\n",
      "|    policy_gradient_loss | -0.00258    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.89e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | -3e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1241     |\n",
      "|    time_elapsed    | 4987     |\n",
      "|    total_timesteps | 2541568  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | -3e+04      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1242        |\n",
      "|    time_elapsed         | 4989        |\n",
      "|    total_timesteps      | 2543616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040881567 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.893       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 28320       |\n",
      "|    policy_gradient_loss | 0.0064      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 2.03e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2545000, episode_reward=-50723.54 +/- 88554.68\n",
      "Episode length: 1604.20 +/- 1231.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | -5.07e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2545000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033821855 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 28330       |\n",
      "|    policy_gradient_loss | 0.0148      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 2.21e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | -3e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1243     |\n",
      "|    time_elapsed    | 4994     |\n",
      "|    total_timesteps | 2545664  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | -3.01e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1244        |\n",
      "|    time_elapsed         | 4996        |\n",
      "|    total_timesteps      | 2547712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009893676 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 28340       |\n",
      "|    policy_gradient_loss | 0.0226      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 9.64e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -2.82e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1245        |\n",
      "|    time_elapsed         | 4998        |\n",
      "|    total_timesteps      | 2549760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020036325 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.5        |\n",
      "|    n_updates            | 28350       |\n",
      "|    policy_gradient_loss | 0.00561     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 392         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2550000, episode_reward=-15249.20 +/- 71620.65\n",
      "Episode length: 2024.00 +/- 961.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.02e+03    |\n",
      "|    mean_reward          | -1.52e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008208515 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 327         |\n",
      "|    n_updates            | 28360       |\n",
      "|    policy_gradient_loss | 0.00782     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.45e+03  |\n",
      "|    ep_rew_mean     | -2.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1246      |\n",
      "|    time_elapsed    | 5005      |\n",
      "|    total_timesteps | 2551808   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | -2.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1247        |\n",
      "|    time_elapsed         | 5007        |\n",
      "|    total_timesteps      | 2553856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009201259 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 319         |\n",
      "|    n_updates            | 28370       |\n",
      "|    policy_gradient_loss | 0.00248     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 775         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2555000, episode_reward=-52274.50 +/- 88936.01\n",
      "Episode length: 1149.20 +/- 854.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.15e+03    |\n",
      "|    mean_reward          | -5.23e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2555000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047095723 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 28380       |\n",
      "|    policy_gradient_loss | 0.00767     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 218         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1248      |\n",
      "|    time_elapsed    | 5011      |\n",
      "|    total_timesteps | 2555904   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | -2.64e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1249        |\n",
      "|    time_elapsed         | 5013        |\n",
      "|    total_timesteps      | 2557952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042016543 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 28390       |\n",
      "|    policy_gradient_loss | 0.0132      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2560000, episode_reward=-20221.00 +/- 71128.19\n",
      "Episode length: 2092.60 +/- 993.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.09e+03    |\n",
      "|    mean_reward          | -2.02e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063572496 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 24.1        |\n",
      "|    n_updates            | 28400       |\n",
      "|    policy_gradient_loss | 0.0196      |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 87.1        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 509       |\n",
      "|    iterations      | 1250      |\n",
      "|    time_elapsed    | 5020      |\n",
      "|    total_timesteps | 2560000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -2.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1251        |\n",
      "|    time_elapsed         | 5022        |\n",
      "|    total_timesteps      | 2562048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025864435 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 28410       |\n",
      "|    policy_gradient_loss | 0.0194      |\n",
      "|    std                  | 0.164       |\n",
      "|    value_loss           | 86.4        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.47e+03   |\n",
      "|    ep_rew_mean          | -2.46e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 510        |\n",
      "|    iterations           | 1252       |\n",
      "|    time_elapsed         | 5023       |\n",
      "|    total_timesteps      | 2564096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02278481 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.38       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 16.3       |\n",
      "|    n_updates            | 28420      |\n",
      "|    policy_gradient_loss | 0.0175     |\n",
      "|    std                  | 0.164      |\n",
      "|    value_loss           | 190        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2565000, episode_reward=-19932.77 +/- 70199.14\n",
      "Episode length: 1249.60 +/- 576.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.25e+03    |\n",
      "|    mean_reward          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2565000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.079776324 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 117         |\n",
      "|    n_updates            | 28430       |\n",
      "|    policy_gradient_loss | 0.0118      |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.01e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.45e+03  |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1253      |\n",
      "|    time_elapsed    | 5028      |\n",
      "|    total_timesteps | 2566144   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.46e+03   |\n",
      "|    ep_rew_mean          | -2.57e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 510        |\n",
      "|    iterations           | 1254       |\n",
      "|    time_elapsed         | 5030       |\n",
      "|    total_timesteps      | 2568192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.40396246 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.35       |\n",
      "|    explained_variance   | 0.337      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.33e+06   |\n",
      "|    n_updates            | 28440      |\n",
      "|    policy_gradient_loss | 0.00209    |\n",
      "|    std                  | 0.165      |\n",
      "|    value_loss           | 2.44e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2570000, episode_reward=-15385.57 +/- 68380.94\n",
      "Episode length: 1279.80 +/- 597.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.28e+03    |\n",
      "|    mean_reward          | -1.54e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021858726 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 28450       |\n",
      "|    policy_gradient_loss | 0.00251     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 273         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.45e+03  |\n",
      "|    ep_rew_mean     | -2.79e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1255      |\n",
      "|    time_elapsed    | 5035      |\n",
      "|    total_timesteps | 2570240   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.45e+03   |\n",
      "|    ep_rew_mean          | -2.92e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 510        |\n",
      "|    iterations           | 1256       |\n",
      "|    time_elapsed         | 5037       |\n",
      "|    total_timesteps      | 2572288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03569854 |\n",
      "|    clip_fraction        | 0.403      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.46e+06   |\n",
      "|    n_updates            | 28460      |\n",
      "|    policy_gradient_loss | 0.0241     |\n",
      "|    std                  | 0.166      |\n",
      "|    value_loss           | 3.53e+07   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -3.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1257        |\n",
      "|    time_elapsed         | 5039        |\n",
      "|    total_timesteps      | 2574336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004432239 |\n",
      "|    clip_fraction        | 0.0221      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.49e+07    |\n",
      "|    n_updates            | 28470       |\n",
      "|    policy_gradient_loss | -0.00576    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 3.63e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2575000, episode_reward=-114853.97 +/- 28833.72\n",
      "Episode length: 805.40 +/- 578.84\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 805          |\n",
      "|    mean_reward          | -1.15e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2575000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050159777 |\n",
      "|    clip_fraction        | 0.0289       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.16e+07     |\n",
      "|    n_updates            | 28480        |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 4.28e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -3.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 510       |\n",
      "|    iterations      | 1258      |\n",
      "|    time_elapsed    | 5042      |\n",
      "|    total_timesteps | 2576384   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | -3.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 511          |\n",
      "|    iterations           | 1259         |\n",
      "|    time_elapsed         | 5044         |\n",
      "|    total_timesteps      | 2578432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036037536 |\n",
      "|    clip_fraction        | 0.015        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.93         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.34e+04     |\n",
      "|    n_updates            | 28490        |\n",
      "|    policy_gradient_loss | -0.00368     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 1.22e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2580000, episode_reward=-49804.76 +/- 86095.17\n",
      "Episode length: 1057.80 +/- 789.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.06e+03    |\n",
      "|    mean_reward          | -4.98e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001513304 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.27e+07    |\n",
      "|    n_updates            | 28500       |\n",
      "|    policy_gradient_loss | -0.00491    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 1.72e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -3.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 511       |\n",
      "|    iterations      | 1260      |\n",
      "|    time_elapsed    | 5049      |\n",
      "|    total_timesteps | 2580480   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -3.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1261        |\n",
      "|    time_elapsed         | 5050        |\n",
      "|    total_timesteps      | 2582528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004092722 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69e+03    |\n",
      "|    n_updates            | 28510       |\n",
      "|    policy_gradient_loss | -0.0066     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 4.71e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | -3.26e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 511          |\n",
      "|    iterations           | 1262         |\n",
      "|    time_elapsed         | 5052         |\n",
      "|    total_timesteps      | 2584576      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049375966 |\n",
      "|    clip_fraction        | 0.0342       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.964        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 546          |\n",
      "|    n_updates            | 28520        |\n",
      "|    policy_gradient_loss | -0.00187     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 1.55e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2585000, episode_reward=-16772.69 +/- 68846.10\n",
      "Episode length: 1377.40 +/- 643.75\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.38e+03    |\n",
      "|    mean_reward          | -1.68e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2585000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005640686 |\n",
      "|    clip_fraction        | 0.0461      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 861         |\n",
      "|    n_updates            | 28530       |\n",
      "|    policy_gradient_loss | -0.00149    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 5.49e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 511       |\n",
      "|    iterations      | 1263      |\n",
      "|    time_elapsed    | 5057      |\n",
      "|    total_timesteps | 2586624   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.44e+03    |\n",
      "|    ep_rew_mean          | -3.27e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1264        |\n",
      "|    time_elapsed         | 5059        |\n",
      "|    total_timesteps      | 2588672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008681548 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.308       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.51e+06    |\n",
      "|    n_updates            | 28540       |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 2.52e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2590000, episode_reward=-48223.37 +/- 83969.91\n",
      "Episode length: 1025.40 +/- 765.81\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.03e+03    |\n",
      "|    mean_reward          | -4.82e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015332486 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 306         |\n",
      "|    n_updates            | 28550       |\n",
      "|    policy_gradient_loss | -0.000702   |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 3.82e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.42e+03  |\n",
      "|    ep_rew_mean     | -3.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 511       |\n",
      "|    iterations      | 1265      |\n",
      "|    time_elapsed    | 5064      |\n",
      "|    total_timesteps | 2590720   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | -3.59e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 511          |\n",
      "|    iterations           | 1266         |\n",
      "|    time_elapsed         | 5065         |\n",
      "|    total_timesteps      | 2592768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054198457 |\n",
      "|    clip_fraction        | 0.0297       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.358        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.42e+07     |\n",
      "|    n_updates            | 28560        |\n",
      "|    policy_gradient_loss | -0.00148     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 6.68e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | -3.69e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1267         |\n",
      "|    time_elapsed         | 5067         |\n",
      "|    total_timesteps      | 2594816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014256483 |\n",
      "|    clip_fraction        | 0.00454      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.406        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.06e+07     |\n",
      "|    n_updates            | 28570        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 3.33e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2595000, episode_reward=-13884.95 +/- 66281.89\n",
      "Episode length: 1341.20 +/- 623.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.34e+03     |\n",
      "|    mean_reward          | -1.39e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2595000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071921456 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.42         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.55e+06     |\n",
      "|    n_updates            | 28580        |\n",
      "|    policy_gradient_loss | -0.000792    |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 1.61e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -3.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 511       |\n",
      "|    iterations      | 1268      |\n",
      "|    time_elapsed    | 5072      |\n",
      "|    total_timesteps | 2596864   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.44e+03     |\n",
      "|    ep_rew_mean          | -3.7e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1269         |\n",
      "|    time_elapsed         | 5074         |\n",
      "|    total_timesteps      | 2598912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155964475 |\n",
      "|    clip_fraction        | 0.0493       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+07      |\n",
      "|    n_updates            | 28590        |\n",
      "|    policy_gradient_loss | 0.00103      |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 1.67e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2600000, episode_reward=-123954.17 +/- 31745.66\n",
      "Episode length: 684.20 +/- 557.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 684          |\n",
      "|    mean_reward          | -1.24e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044559725 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+07      |\n",
      "|    n_updates            | 28600        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 3.2e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -3.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 512       |\n",
      "|    iterations      | 1270      |\n",
      "|    time_elapsed    | 5078      |\n",
      "|    total_timesteps | 2600960   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.43e+03     |\n",
      "|    ep_rew_mean          | -3.81e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 512          |\n",
      "|    iterations           | 1271         |\n",
      "|    time_elapsed         | 5079         |\n",
      "|    total_timesteps      | 2603008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065495013 |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11e+06     |\n",
      "|    n_updates            | 28610        |\n",
      "|    policy_gradient_loss | -0.00255     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 1.68e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2605000, episode_reward=-41380.84 +/- 69609.14\n",
      "Episode length: 658.80 +/- 547.53\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 659        |\n",
      "|    mean_reward          | -4.14e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2605000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00490605 |\n",
      "|    clip_fraction        | 0.0232     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.11e+04   |\n",
      "|    n_updates            | 28620      |\n",
      "|    policy_gradient_loss | -0.0033    |\n",
      "|    std                  | 0.166      |\n",
      "|    value_loss           | 8.7e+04    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -3.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 512       |\n",
      "|    iterations      | 1272      |\n",
      "|    time_elapsed    | 5083      |\n",
      "|    total_timesteps | 2605056   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | -3.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1273        |\n",
      "|    time_elapsed         | 5085        |\n",
      "|    total_timesteps      | 2607104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009263992 |\n",
      "|    clip_fraction        | 0.0509      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.25e+03    |\n",
      "|    n_updates            | 28630       |\n",
      "|    policy_gradient_loss | -0.00371    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 4.3e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | -3.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1274        |\n",
      "|    time_elapsed         | 5087        |\n",
      "|    total_timesteps      | 2609152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003911779 |\n",
      "|    clip_fraction        | 0.0222      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.406       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.41e+06    |\n",
      "|    n_updates            | 28640       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 1.29e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2610000, episode_reward=16157.26 +/- 5519.02\n",
      "Episode length: 1394.80 +/- 421.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.39e+03    |\n",
      "|    mean_reward          | 1.62e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003190927 |\n",
      "|    clip_fraction        | 0.0228      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.445       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.74e+07    |\n",
      "|    n_updates            | 28650       |\n",
      "|    policy_gradient_loss | -0.00488    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 1.42e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.44e+03 |\n",
      "|    ep_rew_mean     | -3.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1275     |\n",
      "|    time_elapsed    | 5092     |\n",
      "|    total_timesteps | 2611200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -3.61e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1276        |\n",
      "|    time_elapsed         | 5094        |\n",
      "|    total_timesteps      | 2613248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013563919 |\n",
      "|    clip_fraction        | 0.092       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+06    |\n",
      "|    n_updates            | 28660       |\n",
      "|    policy_gradient_loss | 0.0067      |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 1.72e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2615000, episode_reward=-41855.00 +/- 70787.36\n",
      "Episode length: 818.40 +/- 588.01\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 818          |\n",
      "|    mean_reward          | -4.19e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2615000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045408113 |\n",
      "|    clip_fraction        | 0.0711       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17e+07     |\n",
      "|    n_updates            | 28670        |\n",
      "|    policy_gradient_loss | 0.00496      |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 1.81e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -3.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 513       |\n",
      "|    iterations      | 1277      |\n",
      "|    time_elapsed    | 5097      |\n",
      "|    total_timesteps | 2615296   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.42e+03     |\n",
      "|    ep_rew_mean          | -3.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 1278         |\n",
      "|    time_elapsed         | 5099         |\n",
      "|    total_timesteps      | 2617344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029949513 |\n",
      "|    clip_fraction        | 0.0194       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05e+04     |\n",
      "|    n_updates            | 28680        |\n",
      "|    policy_gradient_loss | -0.00593     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 8.52e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.41e+03     |\n",
      "|    ep_rew_mean          | -3.38e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 1279         |\n",
      "|    time_elapsed         | 5101         |\n",
      "|    total_timesteps      | 2619392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071768924 |\n",
      "|    clip_fraction        | 0.0423       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.16e+03     |\n",
      "|    n_updates            | 28690        |\n",
      "|    policy_gradient_loss | -0.00326     |\n",
      "|    std                  | 0.166        |\n",
      "|    value_loss           | 6.87e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2620000, episode_reward=-66785.70 +/- 68970.69\n",
      "Episode length: 723.20 +/- 542.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 723         |\n",
      "|    mean_reward          | -6.68e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012041388 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 399         |\n",
      "|    n_updates            | 28700       |\n",
      "|    policy_gradient_loss | 0.00164     |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 1.95e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.41e+03  |\n",
      "|    ep_rew_mean     | -3.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 513       |\n",
      "|    iterations      | 1280      |\n",
      "|    time_elapsed    | 5105      |\n",
      "|    total_timesteps | 2621440   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.4e+03    |\n",
      "|    ep_rew_mean          | -3.05e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 513        |\n",
      "|    iterations           | 1281       |\n",
      "|    time_elapsed         | 5106       |\n",
      "|    total_timesteps      | 2623488    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02073766 |\n",
      "|    clip_fraction        | 0.145      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 971        |\n",
      "|    n_updates            | 28710      |\n",
      "|    policy_gradient_loss | 0.00257    |\n",
      "|    std                  | 0.166      |\n",
      "|    value_loss           | 8.28e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2625000, episode_reward=-65165.12 +/- 99637.76\n",
      "Episode length: 1126.20 +/- 359.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.13e+03    |\n",
      "|    mean_reward          | -6.52e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2625000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022178069 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 289         |\n",
      "|    n_updates            | 28720       |\n",
      "|    policy_gradient_loss | 0.00648     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.4e+03   |\n",
      "|    ep_rew_mean     | -2.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 513       |\n",
      "|    iterations      | 1282      |\n",
      "|    time_elapsed    | 5111      |\n",
      "|    total_timesteps | 2625536   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | -2.8e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 1283        |\n",
      "|    time_elapsed         | 5113        |\n",
      "|    total_timesteps      | 2627584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.121843815 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.84e+06    |\n",
      "|    n_updates            | 28730       |\n",
      "|    policy_gradient_loss | -0.00855    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 2.32e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.38e+03   |\n",
      "|    ep_rew_mean          | -2.99e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 514        |\n",
      "|    iterations           | 1284       |\n",
      "|    time_elapsed         | 5115       |\n",
      "|    total_timesteps      | 2629632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01390039 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 146        |\n",
      "|    n_updates            | 28740      |\n",
      "|    policy_gradient_loss | 0.0054     |\n",
      "|    std                  | 0.165      |\n",
      "|    value_loss           | 1.62e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2630000, episode_reward=-12692.69 +/- 61742.92\n",
      "Episode length: 1264.40 +/- 332.79\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.26e+03  |\n",
      "|    mean_reward          | -1.27e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 2630000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3501703 |\n",
      "|    clip_fraction        | 0.153     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.34      |\n",
      "|    explained_variance   | 0.372     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.52e+07  |\n",
      "|    n_updates            | 28750     |\n",
      "|    policy_gradient_loss | -0.00527  |\n",
      "|    std                  | 0.165     |\n",
      "|    value_loss           | 2.52e+07  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.36e+03  |\n",
      "|    ep_rew_mean     | -2.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 513       |\n",
      "|    iterations      | 1285      |\n",
      "|    time_elapsed    | 5120      |\n",
      "|    total_timesteps | 2631680   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.33e+03  |\n",
      "|    ep_rew_mean          | -3.15e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 514       |\n",
      "|    iterations           | 1286      |\n",
      "|    time_elapsed         | 5121      |\n",
      "|    total_timesteps      | 2633728   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0990708 |\n",
      "|    clip_fraction        | 0.109     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.34      |\n",
      "|    explained_variance   | 0.4       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.25e+07  |\n",
      "|    n_updates            | 28760     |\n",
      "|    policy_gradient_loss | 0.0104    |\n",
      "|    std                  | 0.166     |\n",
      "|    value_loss           | 2.51e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2635000, episode_reward=-19517.46 +/- 69213.99\n",
      "Episode length: 1180.60 +/- 546.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.18e+03    |\n",
      "|    mean_reward          | -1.95e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2635000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003514951 |\n",
      "|    clip_fraction        | 0.0209      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.17e+07    |\n",
      "|    n_updates            | 28770       |\n",
      "|    policy_gradient_loss | -0.00107    |\n",
      "|    std                  | 0.166       |\n",
      "|    value_loss           | 4.25e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.35e+03  |\n",
      "|    ep_rew_mean     | -2.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 514       |\n",
      "|    iterations      | 1287      |\n",
      "|    time_elapsed    | 5126      |\n",
      "|    total_timesteps | 2635776   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.34e+03     |\n",
      "|    ep_rew_mean          | -2.88e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 514          |\n",
      "|    iterations           | 1288         |\n",
      "|    time_elapsed         | 5128         |\n",
      "|    total_timesteps      | 2637824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057392623 |\n",
      "|    clip_fraction        | 0.0571       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.16e+03     |\n",
      "|    n_updates            | 28780        |\n",
      "|    policy_gradient_loss | -0.00334     |\n",
      "|    std                  | 0.165        |\n",
      "|    value_loss           | 3.46e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.35e+03    |\n",
      "|    ep_rew_mean          | -2.71e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1289        |\n",
      "|    time_elapsed         | 5130        |\n",
      "|    total_timesteps      | 2639872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011216444 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 945         |\n",
      "|    n_updates            | 28790       |\n",
      "|    policy_gradient_loss | -0.00224    |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 2.71e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2640000, episode_reward=-147174.65 +/- 18968.01\n",
      "Episode length: 156.60 +/- 120.76\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 157        |\n",
      "|    mean_reward          | -1.47e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2640000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02224112 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 261        |\n",
      "|    n_updates            | 28800      |\n",
      "|    policy_gradient_loss | -0.00307   |\n",
      "|    std                  | 0.165      |\n",
      "|    value_loss           | 1.41e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.33e+03  |\n",
      "|    ep_rew_mean     | -2.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 514       |\n",
      "|    iterations      | 1290      |\n",
      "|    time_elapsed    | 5132      |\n",
      "|    total_timesteps | 2641920   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | -2.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1291        |\n",
      "|    time_elapsed         | 5134        |\n",
      "|    total_timesteps      | 2643968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024861034 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 28810       |\n",
      "|    policy_gradient_loss | 0.00843     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 438         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2645000, episode_reward=-56066.38 +/- 85099.65\n",
      "Episode length: 792.60 +/- 567.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 793         |\n",
      "|    mean_reward          | -5.61e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2645000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038414273 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.4        |\n",
      "|    n_updates            | 28820       |\n",
      "|    policy_gradient_loss | 0.02        |\n",
      "|    std                  | 0.164       |\n",
      "|    value_loss           | 176         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.34e+03  |\n",
      "|    ep_rew_mean     | -2.39e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 514       |\n",
      "|    iterations      | 1292      |\n",
      "|    time_elapsed    | 5138      |\n",
      "|    total_timesteps | 2646016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32e+03    |\n",
      "|    ep_rew_mean          | -2.4e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 1293        |\n",
      "|    time_elapsed         | 5139        |\n",
      "|    total_timesteps      | 2648064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037667755 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76          |\n",
      "|    n_updates            | 28830       |\n",
      "|    policy_gradient_loss | 0.00525     |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 1.7e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2650000, episode_reward=12133.13 +/- 2998.23\n",
      "Episode length: 1136.20 +/- 5.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.14e+03    |\n",
      "|    mean_reward          | 1.21e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059484653 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 48.3        |\n",
      "|    n_updates            | 28840       |\n",
      "|    policy_gradient_loss | 0.0166      |\n",
      "|    std                  | 0.165       |\n",
      "|    value_loss           | 145         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.3e+03   |\n",
      "|    ep_rew_mean     | -2.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 515       |\n",
      "|    iterations      | 1294      |\n",
      "|    time_elapsed    | 5144      |\n",
      "|    total_timesteps | 2650112   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.31e+03  |\n",
      "|    ep_rew_mean          | -2.26e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 515       |\n",
      "|    iterations           | 1295      |\n",
      "|    time_elapsed         | 5146      |\n",
      "|    total_timesteps      | 2652160   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.029634  |\n",
      "|    clip_fraction        | 0.258     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.33      |\n",
      "|    explained_variance   | 0.989     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.07e+04  |\n",
      "|    n_updates            | 28850     |\n",
      "|    policy_gradient_loss | 0.00547   |\n",
      "|    std                  | 0.164     |\n",
      "|    value_loss           | 2.95e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.27e+03   |\n",
      "|    ep_rew_mean          | -2.44e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 515        |\n",
      "|    iterations           | 1296       |\n",
      "|    time_elapsed         | 5148       |\n",
      "|    total_timesteps      | 2654208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01429786 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 34.2       |\n",
      "|    n_updates            | 28860      |\n",
      "|    policy_gradient_loss | 0.00584    |\n",
      "|    std                  | 0.164      |\n",
      "|    value_loss           | 165        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2655000, episode_reward=10673.96 +/- 2107.33\n",
      "Episode length: 1107.20 +/- 20.29\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.11e+03   |\n",
      "|    mean_reward          | 1.07e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2655000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24163152 |\n",
      "|    clip_fraction        | 0.262      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.342      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.38e+07   |\n",
      "|    n_updates            | 28870      |\n",
      "|    policy_gradient_loss | 0.0123     |\n",
      "|    std                  | 0.164      |\n",
      "|    value_loss           | 2.38e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -2.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 515       |\n",
      "|    iterations      | 1297      |\n",
      "|    time_elapsed    | 5152      |\n",
      "|    total_timesteps | 2656256   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.22e+03   |\n",
      "|    ep_rew_mean          | -2.37e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 515        |\n",
      "|    iterations           | 1298       |\n",
      "|    time_elapsed         | 5154       |\n",
      "|    total_timesteps      | 2658304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14581682 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.401      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.2e+06    |\n",
      "|    n_updates            | 28880      |\n",
      "|    policy_gradient_loss | 0.004      |\n",
      "|    std                  | 0.164      |\n",
      "|    value_loss           | 2.47e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2660000, episode_reward=-25299.25 +/- 69729.49\n",
      "Episode length: 958.00 +/- 426.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 958         |\n",
      "|    mean_reward          | -2.53e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024095114 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.26e+04    |\n",
      "|    n_updates            | 28890       |\n",
      "|    policy_gradient_loss | 0.000465    |\n",
      "|    std                  | 0.164       |\n",
      "|    value_loss           | 2.48e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -2.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 515       |\n",
      "|    iterations      | 1299      |\n",
      "|    time_elapsed    | 5158      |\n",
      "|    total_timesteps | 2660352   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.16e+03  |\n",
      "|    ep_rew_mean          | -2.58e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 515       |\n",
      "|    iterations           | 1300      |\n",
      "|    time_elapsed         | 5160      |\n",
      "|    total_timesteps      | 2662400   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5402552 |\n",
      "|    clip_fraction        | 0.234     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.34      |\n",
      "|    explained_variance   | 0.367     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.31e+07  |\n",
      "|    n_updates            | 28900     |\n",
      "|    policy_gradient_loss | 0.00214   |\n",
      "|    std                  | 0.164     |\n",
      "|    value_loss           | 2.62e+07  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.15e+03    |\n",
      "|    ep_rew_mean          | -2.59e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 1301        |\n",
      "|    time_elapsed         | 5162        |\n",
      "|    total_timesteps      | 2664448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019308766 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 113         |\n",
      "|    n_updates            | 28910       |\n",
      "|    policy_gradient_loss | 0.00252     |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 247         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2665000, episode_reward=-60177.92 +/- 89056.30\n",
      "Episode length: 772.60 +/- 545.11\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 773        |\n",
      "|    mean_reward          | -6.02e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2665000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05073656 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.36       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 35.6       |\n",
      "|    n_updates            | 28920      |\n",
      "|    policy_gradient_loss | 0.0122     |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 109        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.11e+03  |\n",
      "|    ep_rew_mean     | -2.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 516       |\n",
      "|    iterations      | 1302      |\n",
      "|    time_elapsed    | 5165      |\n",
      "|    total_timesteps | 2666496   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 1303        |\n",
      "|    time_elapsed         | 5167        |\n",
      "|    total_timesteps      | 2668544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019339833 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.46e+07    |\n",
      "|    n_updates            | 28930       |\n",
      "|    policy_gradient_loss | 0.0103      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 4.36e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2670000, episode_reward=11819.29 +/- 3545.44\n",
      "Episode length: 1007.80 +/- 235.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.01e+03     |\n",
      "|    mean_reward          | 1.18e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2670000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024264436 |\n",
      "|    clip_fraction        | 0.00996      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.44e+07     |\n",
      "|    n_updates            | 28940        |\n",
      "|    policy_gradient_loss | -0.0048      |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 5.81e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.04e+03 |\n",
      "|    ep_rew_mean     | -3.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 516      |\n",
      "|    iterations      | 1304     |\n",
      "|    time_elapsed    | 5171     |\n",
      "|    total_timesteps | 2670592  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.04e+03     |\n",
      "|    ep_rew_mean          | -3.33e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 516          |\n",
      "|    iterations           | 1305         |\n",
      "|    time_elapsed         | 5173         |\n",
      "|    total_timesteps      | 2672640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050799437 |\n",
      "|    clip_fraction        | 0.0175       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.348        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.56e+07     |\n",
      "|    n_updates            | 28950        |\n",
      "|    policy_gradient_loss | -0.00189     |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 2.85e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 976         |\n",
      "|    ep_rew_mean          | -3.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 1306        |\n",
      "|    time_elapsed         | 5175        |\n",
      "|    total_timesteps      | 2674688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009135823 |\n",
      "|    clip_fraction        | 0.061       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.96e+03    |\n",
      "|    n_updates            | 28960       |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 6.74e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2675000, episode_reward=-57805.93 +/- 85991.81\n",
      "Episode length: 797.20 +/- 566.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 797         |\n",
      "|    mean_reward          | -5.78e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2675000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008059424 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.368       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.52e+07    |\n",
      "|    n_updates            | 28970       |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.59e+08    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 958       |\n",
      "|    ep_rew_mean     | -3.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 516       |\n",
      "|    iterations      | 1307      |\n",
      "|    time_elapsed    | 5179      |\n",
      "|    total_timesteps | 2676736   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 936       |\n",
      "|    ep_rew_mean          | -3.86e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 517       |\n",
      "|    iterations           | 1308      |\n",
      "|    time_elapsed         | 5181      |\n",
      "|    total_timesteps      | 2678784   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.0307932 |\n",
      "|    clip_fraction        | 0.319     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.36      |\n",
      "|    explained_variance   | 0.392     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.34e+07  |\n",
      "|    n_updates            | 28980     |\n",
      "|    policy_gradient_loss | 0.0509    |\n",
      "|    std                  | 0.162     |\n",
      "|    value_loss           | 2.75e+07  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2680000, episode_reward=-68564.74 +/- 74172.91\n",
      "Episode length: 524.40 +/- 322.12\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 524           |\n",
      "|    mean_reward          | -6.86e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 2680000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00087870826 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 3.35          |\n",
      "|    explained_variance   | 0.369         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.65e+07      |\n",
      "|    n_updates            | 28990         |\n",
      "|    policy_gradient_loss | -0.001        |\n",
      "|    std                  | 0.162         |\n",
      "|    value_loss           | 3.72e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 924       |\n",
      "|    ep_rew_mean     | -4.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 517       |\n",
      "|    iterations      | 1309      |\n",
      "|    time_elapsed    | 5184      |\n",
      "|    total_timesteps | 2680832   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 917          |\n",
      "|    ep_rew_mean          | -3.85e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 517          |\n",
      "|    iterations           | 1310         |\n",
      "|    time_elapsed         | 5186         |\n",
      "|    total_timesteps      | 2682880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015398132 |\n",
      "|    clip_fraction        | 0.00229      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.429        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.14e+07     |\n",
      "|    n_updates            | 29000        |\n",
      "|    policy_gradient_loss | -0.00283     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 2.76e+07     |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 883           |\n",
      "|    ep_rew_mean          | -4.09e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 517           |\n",
      "|    iterations           | 1311          |\n",
      "|    time_elapsed         | 5188          |\n",
      "|    total_timesteps      | 2684928       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094738114 |\n",
      "|    clip_fraction        | 0.00254       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 3.35          |\n",
      "|    explained_variance   | 0.363         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.21e+07      |\n",
      "|    n_updates            | 29010         |\n",
      "|    policy_gradient_loss | -0.00285      |\n",
      "|    std                  | 0.162         |\n",
      "|    value_loss           | 4.37e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=2685000, episode_reward=-89770.70 +/- 54343.07\n",
      "Episode length: 496.60 +/- 326.12\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 497          |\n",
      "|    mean_reward          | -8.98e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2685000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015435648 |\n",
      "|    clip_fraction        | 0.013        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37e+07     |\n",
      "|    n_updates            | 29020        |\n",
      "|    policy_gradient_loss | -0.00524     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 7.86e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 865       |\n",
      "|    ep_rew_mean     | -4.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 517       |\n",
      "|    iterations      | 1312      |\n",
      "|    time_elapsed    | 5191      |\n",
      "|    total_timesteps | 2686976   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 821          |\n",
      "|    ep_rew_mean          | -4.42e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 517          |\n",
      "|    iterations           | 1313         |\n",
      "|    time_elapsed         | 5192         |\n",
      "|    total_timesteps      | 2689024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016181259 |\n",
      "|    clip_fraction        | 0.00967      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.355        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.33e+07     |\n",
      "|    n_updates            | 29030        |\n",
      "|    policy_gradient_loss | -0.00502     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 7.14e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2690000, episode_reward=-42214.87 +/- 67909.28\n",
      "Episode length: 627.20 +/- 230.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 627          |\n",
      "|    mean_reward          | -4.22e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2690000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059274775 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.427        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.42e+07     |\n",
      "|    n_updates            | 29040        |\n",
      "|    policy_gradient_loss | -0.00436     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 4.33e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 789       |\n",
      "|    ep_rew_mean     | -4.69e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 517       |\n",
      "|    iterations      | 1314      |\n",
      "|    time_elapsed    | 5196      |\n",
      "|    total_timesteps | 2691072   |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 757           |\n",
      "|    ep_rew_mean          | -5.03e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 518           |\n",
      "|    iterations           | 1315          |\n",
      "|    time_elapsed         | 5198          |\n",
      "|    total_timesteps      | 2693120       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00046512033 |\n",
      "|    clip_fraction        | 0.000488      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 3.35          |\n",
      "|    explained_variance   | 0.342         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.54e+07      |\n",
      "|    n_updates            | 29050         |\n",
      "|    policy_gradient_loss | -0.000818     |\n",
      "|    std                  | 0.162         |\n",
      "|    value_loss           | 8.58e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=2695000, episode_reward=-60388.45 +/- 42629.41\n",
      "Episode length: 509.40 +/- 279.39\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 509          |\n",
      "|    mean_reward          | -6.04e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2695000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047781705 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.392        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.64e+07     |\n",
      "|    n_updates            | 29060        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 5.26e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 745       |\n",
      "|    ep_rew_mean     | -5.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 518       |\n",
      "|    iterations      | 1316      |\n",
      "|    time_elapsed    | 5201      |\n",
      "|    total_timesteps | 2695168   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 716         |\n",
      "|    ep_rew_mean          | -5.44e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1317        |\n",
      "|    time_elapsed         | 5203        |\n",
      "|    total_timesteps      | 2697216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006122854 |\n",
      "|    clip_fraction        | 0.0366      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.01e+05    |\n",
      "|    n_updates            | 29070       |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.22e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 697          |\n",
      "|    ep_rew_mean          | -5.74e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 518          |\n",
      "|    iterations           | 1318         |\n",
      "|    time_elapsed         | 5204         |\n",
      "|    total_timesteps      | 2699264      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013033699 |\n",
      "|    clip_fraction        | 0.0281       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.38         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.77e+07     |\n",
      "|    n_updates            | 29080        |\n",
      "|    policy_gradient_loss | 0.000229     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 6.48e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2700000, episode_reward=-68684.35 +/- 74489.98\n",
      "Episode length: 544.60 +/- 199.58\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 545          |\n",
      "|    mean_reward          | -6.87e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2700000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029475316 |\n",
      "|    clip_fraction        | 0.00977      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.369        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.39e+07     |\n",
      "|    n_updates            | 29090        |\n",
      "|    policy_gradient_loss | -0.0035      |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 8.69e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 700       |\n",
      "|    ep_rew_mean     | -5.92e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 518       |\n",
      "|    iterations      | 1319      |\n",
      "|    time_elapsed    | 5208      |\n",
      "|    total_timesteps | 2701312   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 702          |\n",
      "|    ep_rew_mean          | -5.74e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 518          |\n",
      "|    iterations           | 1320         |\n",
      "|    time_elapsed         | 5209         |\n",
      "|    total_timesteps      | 2703360      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027871937 |\n",
      "|    clip_fraction        | 0.0229       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.4          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.2e+07      |\n",
      "|    n_updates            | 29100        |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 3.49e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2705000, episode_reward=-70787.25 +/- 68123.36\n",
      "Episode length: 534.20 +/- 211.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 534         |\n",
      "|    mean_reward          | -7.08e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2705000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003749417 |\n",
      "|    clip_fraction        | 0.0172      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.499       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.56e+06    |\n",
      "|    n_updates            | 29110       |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 7.85e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 685       |\n",
      "|    ep_rew_mean     | -5.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 518       |\n",
      "|    iterations      | 1321      |\n",
      "|    time_elapsed    | 5213      |\n",
      "|    total_timesteps | 2705408   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 668         |\n",
      "|    ep_rew_mean          | -6.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 1322        |\n",
      "|    time_elapsed         | 5214        |\n",
      "|    total_timesteps      | 2707456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004353122 |\n",
      "|    clip_fraction        | 0.0202      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.3e+06     |\n",
      "|    n_updates            | 29120       |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.62e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 661          |\n",
      "|    ep_rew_mean          | -6.2e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 519          |\n",
      "|    iterations           | 1323         |\n",
      "|    time_elapsed         | 5216         |\n",
      "|    total_timesteps      | 2709504      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050143097 |\n",
      "|    clip_fraction        | 0.0186       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.27e+07     |\n",
      "|    n_updates            | 29130        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 2.29e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2710000, episode_reward=-58270.82 +/- 61708.73\n",
      "Episode length: 632.80 +/- 297.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 633         |\n",
      "|    mean_reward          | -5.83e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003686553 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.767       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.58e+04    |\n",
      "|    n_updates            | 29140       |\n",
      "|    policy_gradient_loss | -0.00743    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 7.65e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 650       |\n",
      "|    ep_rew_mean     | -6.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 519       |\n",
      "|    iterations      | 1324      |\n",
      "|    time_elapsed    | 5220      |\n",
      "|    total_timesteps | 2711552   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 633          |\n",
      "|    ep_rew_mean          | -6.67e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 519          |\n",
      "|    iterations           | 1325         |\n",
      "|    time_elapsed         | 5222         |\n",
      "|    total_timesteps      | 2713600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048595862 |\n",
      "|    clip_fraction        | 0.0215       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+07     |\n",
      "|    n_updates            | 29150        |\n",
      "|    policy_gradient_loss | -0.00488     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 4.91e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2715000, episode_reward=-35292.39 +/- 27780.47\n",
      "Episode length: 854.80 +/- 255.29\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 855          |\n",
      "|    mean_reward          | -3.53e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2715000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016991768 |\n",
      "|    clip_fraction        | 0.00405      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.379        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.92e+06     |\n",
      "|    n_updates            | 29160        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 2.69e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 624       |\n",
      "|    ep_rew_mean     | -6.89e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 519       |\n",
      "|    iterations      | 1326      |\n",
      "|    time_elapsed    | 5225      |\n",
      "|    total_timesteps | 2715648   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 606         |\n",
      "|    ep_rew_mean          | -7.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 1327        |\n",
      "|    time_elapsed         | 5227        |\n",
      "|    total_timesteps      | 2717696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003832244 |\n",
      "|    clip_fraction        | 0.0211      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.59e+07    |\n",
      "|    n_updates            | 29170       |\n",
      "|    policy_gradient_loss | -0.00524    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 5.51e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 593         |\n",
      "|    ep_rew_mean          | -7.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1328        |\n",
      "|    time_elapsed         | 5229        |\n",
      "|    total_timesteps      | 2719744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004467522 |\n",
      "|    clip_fraction        | 0.0214      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+07    |\n",
      "|    n_updates            | 29180       |\n",
      "|    policy_gradient_loss | -0.00398    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 5.72e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2720000, episode_reward=-98559.45 +/- 33738.85\n",
      "Episode length: 497.20 +/- 331.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 497         |\n",
      "|    mean_reward          | -9.86e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003662635 |\n",
      "|    clip_fraction        | 0.0235      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+07    |\n",
      "|    n_updates            | 29190       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.09e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 592       |\n",
      "|    ep_rew_mean     | -7.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1329      |\n",
      "|    time_elapsed    | 5232      |\n",
      "|    total_timesteps | 2721792   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 591          |\n",
      "|    ep_rew_mean          | -7.25e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 1330         |\n",
      "|    time_elapsed         | 5234         |\n",
      "|    total_timesteps      | 2723840      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058431504 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.02e+04     |\n",
      "|    n_updates            | 29200        |\n",
      "|    policy_gradient_loss | -0.00262     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 1.25e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2725000, episode_reward=-37137.76 +/- 62809.54\n",
      "Episode length: 818.00 +/- 374.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 818         |\n",
      "|    mean_reward          | -3.71e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2725000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006019585 |\n",
      "|    clip_fraction        | 0.0448      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.95e+03    |\n",
      "|    n_updates            | 29210       |\n",
      "|    policy_gradient_loss | -0.00241    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 5.1e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 573       |\n",
      "|    ep_rew_mean     | -7.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1331      |\n",
      "|    time_elapsed    | 5238      |\n",
      "|    total_timesteps | 2725888   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 575          |\n",
      "|    ep_rew_mean          | -7.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 1332         |\n",
      "|    time_elapsed         | 5240         |\n",
      "|    total_timesteps      | 2727936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028121253 |\n",
      "|    clip_fraction        | 0.0123       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.337        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.74e+07     |\n",
      "|    n_updates            | 29220        |\n",
      "|    policy_gradient_loss | -0.0017      |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 7.91e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 574          |\n",
      "|    ep_rew_mean          | -7.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 1333         |\n",
      "|    time_elapsed         | 5242         |\n",
      "|    total_timesteps      | 2729984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043409895 |\n",
      "|    clip_fraction        | 0.021        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.07e+07     |\n",
      "|    n_updates            | 29230        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 4.06e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2730000, episode_reward=-49230.11 +/- 73654.76\n",
      "Episode length: 744.60 +/- 330.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 745         |\n",
      "|    mean_reward          | -4.92e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003584248 |\n",
      "|    clip_fraction        | 0.0158      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.45e+07    |\n",
      "|    n_updates            | 29240       |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 4e+07       |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 583       |\n",
      "|    ep_rew_mean     | -7.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1334      |\n",
      "|    time_elapsed    | 5245      |\n",
      "|    total_timesteps | 2732032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 595         |\n",
      "|    ep_rew_mean          | -6.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1335        |\n",
      "|    time_elapsed         | 5247        |\n",
      "|    total_timesteps      | 2734080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004033024 |\n",
      "|    clip_fraction        | 0.025       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.526       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.95e+06    |\n",
      "|    n_updates            | 29250       |\n",
      "|    policy_gradient_loss | -0.00581    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 8.97e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2735000, episode_reward=-45543.54 +/- 37897.58\n",
      "Episode length: 456.60 +/- 92.36\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 457          |\n",
      "|    mean_reward          | -4.55e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2735000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075109038 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.06e+07     |\n",
      "|    n_updates            | 29260        |\n",
      "|    policy_gradient_loss | -0.00263     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 6.79e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 583       |\n",
      "|    ep_rew_mean     | -6.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 1336      |\n",
      "|    time_elapsed    | 5250      |\n",
      "|    total_timesteps | 2736128   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 575         |\n",
      "|    ep_rew_mean          | -6.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1337        |\n",
      "|    time_elapsed         | 5252        |\n",
      "|    total_timesteps      | 2738176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020309178 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.411       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.96e+07    |\n",
      "|    n_updates            | 29270       |\n",
      "|    policy_gradient_loss | -0.000922   |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.8e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2740000, episode_reward=-98735.39 +/- 66768.20\n",
      "Episode length: 548.00 +/- 403.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 548          |\n",
      "|    mean_reward          | -9.87e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2740000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033076536 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.363        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+07     |\n",
      "|    n_updates            | 29280        |\n",
      "|    policy_gradient_loss | -0.000329    |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 3.36e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 580      |\n",
      "|    ep_rew_mean     | -6.9e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 521      |\n",
      "|    iterations      | 1338     |\n",
      "|    time_elapsed    | 5255     |\n",
      "|    total_timesteps | 2740224  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 581        |\n",
      "|    ep_rew_mean          | -6.8e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 521        |\n",
      "|    iterations           | 1339       |\n",
      "|    time_elapsed         | 5257       |\n",
      "|    total_timesteps      | 2742272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03496187 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.05e+03   |\n",
      "|    n_updates            | 29290      |\n",
      "|    policy_gradient_loss | 0.00334    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 3.42e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 582         |\n",
      "|    ep_rew_mean          | -6.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1340        |\n",
      "|    time_elapsed         | 5259        |\n",
      "|    total_timesteps      | 2744320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022683721 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.97e+07    |\n",
      "|    n_updates            | 29300       |\n",
      "|    policy_gradient_loss | 0.017       |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 8.91e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2745000, episode_reward=-18700.12 +/- 60993.20\n",
      "Episode length: 652.60 +/- 316.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 653          |\n",
      "|    mean_reward          | -1.87e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2745000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094169155 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.609        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.8e+03      |\n",
      "|    n_updates            | 29310        |\n",
      "|    policy_gradient_loss | 2.97e-05     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 2.8e+04      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 585       |\n",
      "|    ep_rew_mean     | -6.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 1341      |\n",
      "|    time_elapsed    | 5262      |\n",
      "|    total_timesteps | 2746368   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 595         |\n",
      "|    ep_rew_mean          | -6.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 1342        |\n",
      "|    time_elapsed         | 5264        |\n",
      "|    total_timesteps      | 2748416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005818487 |\n",
      "|    clip_fraction        | 0.0311      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.668       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.9e+04     |\n",
      "|    n_updates            | 29320       |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.69e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2750000, episode_reward=-11619.63 +/- 49748.35\n",
      "Episode length: 714.40 +/- 221.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 714         |\n",
      "|    mean_reward          | -1.16e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043544658 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.22e+06    |\n",
      "|    n_updates            | 29330       |\n",
      "|    policy_gradient_loss | 0.00289     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 8.74e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 603       |\n",
      "|    ep_rew_mean     | -6.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 522       |\n",
      "|    iterations      | 1343      |\n",
      "|    time_elapsed    | 5268      |\n",
      "|    total_timesteps | 2750464   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 611          |\n",
      "|    ep_rew_mean          | -6.09e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 522          |\n",
      "|    iterations           | 1344         |\n",
      "|    time_elapsed         | 5269         |\n",
      "|    total_timesteps      | 2752512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047720736 |\n",
      "|    clip_fraction        | 0.0243       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.393        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.52e+07     |\n",
      "|    n_updates            | 29340        |\n",
      "|    policy_gradient_loss | -9.12e-05    |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 4.79e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 617         |\n",
      "|    ep_rew_mean          | -6e+04      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 1345        |\n",
      "|    time_elapsed         | 5271        |\n",
      "|    total_timesteps      | 2754560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008687479 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.433       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.99e+07    |\n",
      "|    n_updates            | 29350       |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 4.75e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2755000, episode_reward=-64721.91 +/- 66213.70\n",
      "Episode length: 451.80 +/- 260.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 452         |\n",
      "|    mean_reward          | -6.47e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2755000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029393284 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 214         |\n",
      "|    n_updates            | 29360       |\n",
      "|    policy_gradient_loss | 0.000491    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 628       |\n",
      "|    ep_rew_mean     | -5.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 522       |\n",
      "|    iterations      | 1346      |\n",
      "|    time_elapsed    | 5274      |\n",
      "|    total_timesteps | 2756608   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 637         |\n",
      "|    ep_rew_mean          | -5.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 1347        |\n",
      "|    time_elapsed         | 5276        |\n",
      "|    total_timesteps      | 2758656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007385272 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.688       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+06    |\n",
      "|    n_updates            | 29370       |\n",
      "|    policy_gradient_loss | 0.00369     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.55e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2760000, episode_reward=-19093.22 +/- 66129.78\n",
      "Episode length: 792.20 +/- 190.81\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 792          |\n",
      "|    mean_reward          | -1.91e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2760000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045254603 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.44         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.31e+07     |\n",
      "|    n_updates            | 29380        |\n",
      "|    policy_gradient_loss | -0.00278     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 3.05e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 644       |\n",
      "|    ep_rew_mean     | -5.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 522       |\n",
      "|    iterations      | 1348      |\n",
      "|    time_elapsed    | 5280      |\n",
      "|    total_timesteps | 2760704   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 651          |\n",
      "|    ep_rew_mean          | -5.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 523          |\n",
      "|    iterations           | 1349         |\n",
      "|    time_elapsed         | 5282         |\n",
      "|    total_timesteps      | 2762752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064040786 |\n",
      "|    clip_fraction        | 0.0365       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6e+06        |\n",
      "|    n_updates            | 29390        |\n",
      "|    policy_gradient_loss | -0.00476     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 1.78e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 651         |\n",
      "|    ep_rew_mean          | -5.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 1350        |\n",
      "|    time_elapsed         | 5284        |\n",
      "|    total_timesteps      | 2764800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006636357 |\n",
      "|    clip_fraction        | 0.0704      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.71        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.17e+03    |\n",
      "|    n_updates            | 29400       |\n",
      "|    policy_gradient_loss | -0.00519    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 4.69e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2765000, episode_reward=-45372.74 +/- 69192.90\n",
      "Episode length: 573.40 +/- 315.50\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 573        |\n",
      "|    mean_reward          | -4.54e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2765000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18925807 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.369      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.46e+06   |\n",
      "|    n_updates            | 29410      |\n",
      "|    policy_gradient_loss | 0.00765    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.2e+07    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 660       |\n",
      "|    ep_rew_mean     | -5.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 523       |\n",
      "|    iterations      | 1351      |\n",
      "|    time_elapsed    | 5287      |\n",
      "|    total_timesteps | 2766848   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 663         |\n",
      "|    ep_rew_mean          | -5.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 1352        |\n",
      "|    time_elapsed         | 5289        |\n",
      "|    total_timesteps      | 2768896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012070157 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 839         |\n",
      "|    n_updates            | 29420       |\n",
      "|    policy_gradient_loss | -0.000924   |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.34e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2770000, episode_reward=11659.68 +/- 3076.97\n",
      "Episode length: 912.40 +/- 13.92\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 912         |\n",
      "|    mean_reward          | 1.17e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004662241 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.62e+06    |\n",
      "|    n_updates            | 29430       |\n",
      "|    policy_gradient_loss | -0.000175   |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3e+07       |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 668       |\n",
      "|    ep_rew_mean     | -4.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 523       |\n",
      "|    iterations      | 1353      |\n",
      "|    time_elapsed    | 5293      |\n",
      "|    total_timesteps | 2770944   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 672         |\n",
      "|    ep_rew_mean          | -4.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 1354        |\n",
      "|    time_elapsed         | 5295        |\n",
      "|    total_timesteps      | 2772992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008423046 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.776       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+03    |\n",
      "|    n_updates            | 29440       |\n",
      "|    policy_gradient_loss | -0.00323    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.29e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2775000, episode_reward=-20339.62 +/- 61369.53\n",
      "Episode length: 674.00 +/- 325.68\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 674          |\n",
      "|    mean_reward          | -2.03e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2775000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057697743 |\n",
      "|    clip_fraction        | 0.0431       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.403        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.45e+06     |\n",
      "|    n_updates            | 29450        |\n",
      "|    policy_gradient_loss | -0.0043      |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 1.47e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 668       |\n",
      "|    ep_rew_mean     | -4.86e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 523       |\n",
      "|    iterations      | 1355      |\n",
      "|    time_elapsed    | 5298      |\n",
      "|    total_timesteps | 2775040   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 667         |\n",
      "|    ep_rew_mean          | -4.81e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 1356        |\n",
      "|    time_elapsed         | 5300        |\n",
      "|    total_timesteps      | 2777088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013497214 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.703       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.4e+03     |\n",
      "|    n_updates            | 29460       |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 8.49e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 669        |\n",
      "|    ep_rew_mean          | -4.66e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 524        |\n",
      "|    iterations           | 1357       |\n",
      "|    time_elapsed         | 5302       |\n",
      "|    total_timesteps      | 2779136    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01054647 |\n",
      "|    clip_fraction        | 0.0985     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.32       |\n",
      "|    explained_variance   | 0.476      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.32e+07   |\n",
      "|    n_updates            | 29470      |\n",
      "|    policy_gradient_loss | 0.00845    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 8.37e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2780000, episode_reward=11631.69 +/- 4442.72\n",
      "Episode length: 827.60 +/- 141.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 828         |\n",
      "|    mean_reward          | 1.16e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002320265 |\n",
      "|    clip_fraction        | 0.0115      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.71e+06    |\n",
      "|    n_updates            | 29480       |\n",
      "|    policy_gradient_loss | -0.000792   |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.58e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 671       |\n",
      "|    ep_rew_mean     | -4.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 524       |\n",
      "|    iterations      | 1358      |\n",
      "|    time_elapsed    | 5305      |\n",
      "|    total_timesteps | 2781184   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 665          |\n",
      "|    ep_rew_mean          | -4.29e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 524          |\n",
      "|    iterations           | 1359         |\n",
      "|    time_elapsed         | 5307         |\n",
      "|    total_timesteps      | 2783232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016212235 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.43         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.68e+06     |\n",
      "|    n_updates            | 29490        |\n",
      "|    policy_gradient_loss | -0.00521     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 3.14e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2785000, episode_reward=-20207.00 +/- 60700.61\n",
      "Episode length: 690.40 +/- 316.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 690         |\n",
      "|    mean_reward          | -2.02e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2785000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005887056 |\n",
      "|    clip_fraction        | 0.0408      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+04    |\n",
      "|    n_updates            | 29500       |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.28e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 679      |\n",
      "|    ep_rew_mean     | -4.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 524      |\n",
      "|    iterations      | 1360     |\n",
      "|    time_elapsed    | 5311     |\n",
      "|    total_timesteps | 2785280  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 670        |\n",
      "|    ep_rew_mean          | -4.18e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 524        |\n",
      "|    iterations           | 1361       |\n",
      "|    time_elapsed         | 5313       |\n",
      "|    total_timesteps      | 2787328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.20783705 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.368      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.41e+07   |\n",
      "|    n_updates            | 29510      |\n",
      "|    policy_gradient_loss | -0.00191   |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.15e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 670        |\n",
      "|    ep_rew_mean          | -4.24e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 524        |\n",
      "|    iterations           | 1362       |\n",
      "|    time_elapsed         | 5315       |\n",
      "|    total_timesteps      | 2789376    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18637118 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.32       |\n",
      "|    explained_variance   | 0.399      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.37e+06   |\n",
      "|    n_updates            | 29520      |\n",
      "|    policy_gradient_loss | -0.0092    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.3e+07    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2790000, episode_reward=11329.47 +/- 3478.16\n",
      "Episode length: 1098.20 +/- 25.10\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.1e+03    |\n",
      "|    mean_reward          | 1.13e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2790000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.31921577 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.32       |\n",
      "|    explained_variance   | 0.411      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.04e+07   |\n",
      "|    n_updates            | 29530      |\n",
      "|    policy_gradient_loss | -0.00764   |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.26e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 671       |\n",
      "|    ep_rew_mean     | -4.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 524       |\n",
      "|    iterations      | 1363      |\n",
      "|    time_elapsed    | 5319      |\n",
      "|    total_timesteps | 2791424   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 689         |\n",
      "|    ep_rew_mean          | -3.93e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 1364        |\n",
      "|    time_elapsed         | 5321        |\n",
      "|    total_timesteps      | 2793472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013707431 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 706         |\n",
      "|    n_updates            | 29540       |\n",
      "|    policy_gradient_loss | -0.00075    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 5.6e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2795000, episode_reward=-67510.73 +/- 49498.89\n",
      "Episode length: 858.00 +/- 389.73\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 858        |\n",
      "|    mean_reward          | -6.75e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2795000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30239746 |\n",
      "|    clip_fraction        | 0.205      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.397      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.59e+07   |\n",
      "|    n_updates            | 29550      |\n",
      "|    policy_gradient_loss | -0.0129    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.28e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 698       |\n",
      "|    ep_rew_mean     | -3.81e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 524       |\n",
      "|    iterations      | 1365      |\n",
      "|    time_elapsed    | 5325      |\n",
      "|    total_timesteps | 2795520   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 707         |\n",
      "|    ep_rew_mean          | -3.55e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1366        |\n",
      "|    time_elapsed         | 5327        |\n",
      "|    total_timesteps      | 2797568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033213083 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 333         |\n",
      "|    n_updates            | 29560       |\n",
      "|    policy_gradient_loss | 0.0143      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.48e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 715         |\n",
      "|    ep_rew_mean          | -3.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1367        |\n",
      "|    time_elapsed         | 5329        |\n",
      "|    total_timesteps      | 2799616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010843287 |\n",
      "|    clip_fraction        | 0.0949      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.46e+04    |\n",
      "|    n_updates            | 29570       |\n",
      "|    policy_gradient_loss | -0.00369    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.86e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2800000, episode_reward=-119734.25 +/- 39845.70\n",
      "Episode length: 471.60 +/- 460.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 472         |\n",
      "|    mean_reward          | -1.2e+05    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038265646 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 93.2        |\n",
      "|    n_updates            | 29580       |\n",
      "|    policy_gradient_loss | 0.0279      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.92e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 709       |\n",
      "|    ep_rew_mean     | -3.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 525       |\n",
      "|    iterations      | 1368      |\n",
      "|    time_elapsed    | 5332      |\n",
      "|    total_timesteps | 2801664   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 718         |\n",
      "|    ep_rew_mean          | -3.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1369        |\n",
      "|    time_elapsed         | 5333        |\n",
      "|    total_timesteps      | 2803712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011009113 |\n",
      "|    clip_fraction        | 0.353       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+07     |\n",
      "|    n_updates            | 29590       |\n",
      "|    policy_gradient_loss | 0.0129      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.69e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2805000, episode_reward=-51865.37 +/- 82572.35\n",
      "Episode length: 689.40 +/- 484.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 689         |\n",
      "|    mean_reward          | -5.19e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2805000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035552844 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 239         |\n",
      "|    n_updates            | 29600       |\n",
      "|    policy_gradient_loss | 0.00465     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.68e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 732       |\n",
      "|    ep_rew_mean     | -3.38e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 525       |\n",
      "|    iterations      | 1370      |\n",
      "|    time_elapsed    | 5337      |\n",
      "|    total_timesteps | 2805760   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 738         |\n",
      "|    ep_rew_mean          | -3.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1371        |\n",
      "|    time_elapsed         | 5339        |\n",
      "|    total_timesteps      | 2807808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016303571 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 313         |\n",
      "|    n_updates            | 29610       |\n",
      "|    policy_gradient_loss | 0.00414     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.71e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 762        |\n",
      "|    ep_rew_mean          | -3.08e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 526        |\n",
      "|    iterations           | 1372       |\n",
      "|    time_elapsed         | 5341       |\n",
      "|    total_timesteps      | 2809856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17588922 |\n",
      "|    clip_fraction        | 0.388      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 64.3       |\n",
      "|    n_updates            | 29620      |\n",
      "|    policy_gradient_loss | 0.0202     |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 300        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2810000, episode_reward=-19764.38 +/- 69760.86\n",
      "Episode length: 965.40 +/- 431.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 965         |\n",
      "|    mean_reward          | -1.98e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.055661388 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.35e+06    |\n",
      "|    n_updates            | 29630       |\n",
      "|    policy_gradient_loss | 0.000566    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 6.14e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 754       |\n",
      "|    ep_rew_mean     | -3.22e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 526       |\n",
      "|    iterations      | 1373      |\n",
      "|    time_elapsed    | 5345      |\n",
      "|    total_timesteps | 2811904   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 756         |\n",
      "|    ep_rew_mean          | -3.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1374        |\n",
      "|    time_elapsed         | 5347        |\n",
      "|    total_timesteps      | 2813952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017197207 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.409       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.15e+07    |\n",
      "|    n_updates            | 29640       |\n",
      "|    policy_gradient_loss | 0.0206      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 8.57e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2815000, episode_reward=-24498.14 +/- 69099.79\n",
      "Episode length: 812.40 +/- 371.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 812         |\n",
      "|    mean_reward          | -2.45e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2815000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028431661 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 29650       |\n",
      "|    policy_gradient_loss | 0.0067      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 373         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 785       |\n",
      "|    ep_rew_mean     | -3.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 526       |\n",
      "|    iterations      | 1375      |\n",
      "|    time_elapsed    | 5350      |\n",
      "|    total_timesteps | 2816000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 798         |\n",
      "|    ep_rew_mean          | -3e+04      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1376        |\n",
      "|    time_elapsed         | 5352        |\n",
      "|    total_timesteps      | 2818048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010379894 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.486       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.09e+06    |\n",
      "|    n_updates            | 29660       |\n",
      "|    policy_gradient_loss | 0.0332      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 3.33e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2820000, episode_reward=-90605.17 +/- 83413.16\n",
      "Episode length: 423.40 +/- 393.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 423         |\n",
      "|    mean_reward          | -9.06e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017141879 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 217         |\n",
      "|    n_updates            | 29670       |\n",
      "|    policy_gradient_loss | 0.00049     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 799      |\n",
      "|    ep_rew_mean     | -3e+04   |\n",
      "| time/              |          |\n",
      "|    fps             | 526      |\n",
      "|    iterations      | 1377     |\n",
      "|    time_elapsed    | 5355     |\n",
      "|    total_timesteps | 2820096  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 808         |\n",
      "|    ep_rew_mean          | -2.85e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1378        |\n",
      "|    time_elapsed         | 5357        |\n",
      "|    total_timesteps      | 2822144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012705461 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02e+03    |\n",
      "|    n_updates            | 29680       |\n",
      "|    policy_gradient_loss | 0.00119     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 2.78e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 814        |\n",
      "|    ep_rew_mean          | -2.86e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 526        |\n",
      "|    iterations           | 1379       |\n",
      "|    time_elapsed         | 5359       |\n",
      "|    total_timesteps      | 2824192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.47413254 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.33e+07   |\n",
      "|    n_updates            | 29690      |\n",
      "|    policy_gradient_loss | -0.00674   |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 3.72e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2825000, episode_reward=-56670.96 +/- 85860.47\n",
      "Episode length: 716.40 +/- 521.32\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 716        |\n",
      "|    mean_reward          | -5.67e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2825000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26931417 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.35       |\n",
      "|    explained_variance   | 0.483      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.8e+06    |\n",
      "|    n_updates            | 29700      |\n",
      "|    policy_gradient_loss | -0.00835   |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 6.62e+06   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 823      |\n",
      "|    ep_rew_mean     | -2.7e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 527      |\n",
      "|    iterations      | 1380     |\n",
      "|    time_elapsed    | 5362     |\n",
      "|    total_timesteps | 2826240  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 828         |\n",
      "|    ep_rew_mean          | -2.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 1381        |\n",
      "|    time_elapsed         | 5364        |\n",
      "|    total_timesteps      | 2828288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012490418 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.3e+03     |\n",
      "|    n_updates            | 29710       |\n",
      "|    policy_gradient_loss | -0.000867   |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 3.45e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2830000, episode_reward=13181.85 +/- 3024.27\n",
      "Episode length: 939.60 +/- 18.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 940         |\n",
      "|    mean_reward          | 1.32e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012883135 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 554         |\n",
      "|    n_updates            | 29720       |\n",
      "|    policy_gradient_loss | 0.00211     |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 2.64e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 826      |\n",
      "|    ep_rew_mean     | -2.6e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 527      |\n",
      "|    iterations      | 1382     |\n",
      "|    time_elapsed    | 5368     |\n",
      "|    total_timesteps | 2830336  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 827        |\n",
      "|    ep_rew_mean          | -2.48e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 527        |\n",
      "|    iterations           | 1383       |\n",
      "|    time_elapsed         | 5370       |\n",
      "|    total_timesteps      | 2832384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03576597 |\n",
      "|    clip_fraction        | 0.245      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.36       |\n",
      "|    explained_variance   | 0.814      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.87e+03   |\n",
      "|    n_updates            | 29730      |\n",
      "|    policy_gradient_loss | 0.0084     |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 1.09e+05   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 832       |\n",
      "|    ep_rew_mean          | -2.32e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 527       |\n",
      "|    iterations           | 1384      |\n",
      "|    time_elapsed         | 5372      |\n",
      "|    total_timesteps      | 2834432   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.3275133 |\n",
      "|    clip_fraction        | 0.175     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.35      |\n",
      "|    explained_variance   | 0.399     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.57e+07  |\n",
      "|    n_updates            | 29740     |\n",
      "|    policy_gradient_loss | -0.00309  |\n",
      "|    std                  | 0.16      |\n",
      "|    value_loss           | 2.4e+07   |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2835000, episode_reward=10604.15 +/- 3427.11\n",
      "Episode length: 674.20 +/- 42.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 674         |\n",
      "|    mean_reward          | 1.06e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2835000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028642029 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 203         |\n",
      "|    n_updates            | 29750       |\n",
      "|    policy_gradient_loss | 0.0149      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 458         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 820       |\n",
      "|    ep_rew_mean     | -2.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 527       |\n",
      "|    iterations      | 1385      |\n",
      "|    time_elapsed    | 5375      |\n",
      "|    total_timesteps | 2836480   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 801       |\n",
      "|    ep_rew_mean          | -2.46e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 527       |\n",
      "|    iterations           | 1386      |\n",
      "|    time_elapsed         | 5377      |\n",
      "|    total_timesteps      | 2838528   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5672294 |\n",
      "|    clip_fraction        | 0.229     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.35      |\n",
      "|    explained_variance   | 0.4       |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.27e+07  |\n",
      "|    n_updates            | 29760     |\n",
      "|    policy_gradient_loss | -0.0138   |\n",
      "|    std                  | 0.161     |\n",
      "|    value_loss           | 4.56e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2840000, episode_reward=-53850.50 +/- 74767.35\n",
      "Episode length: 453.60 +/- 305.23\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 454        |\n",
      "|    mean_reward          | -5.39e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2840000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.68346083 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.36       |\n",
      "|    explained_variance   | 0.412      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.35e+06   |\n",
      "|    n_updates            | 29770      |\n",
      "|    policy_gradient_loss | 0.00445    |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 2.23e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 809       |\n",
      "|    ep_rew_mean     | -2.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 527       |\n",
      "|    iterations      | 1387      |\n",
      "|    time_elapsed    | 5380      |\n",
      "|    total_timesteps | 2840576   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 807         |\n",
      "|    ep_rew_mean          | -2.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1388        |\n",
      "|    time_elapsed         | 5382        |\n",
      "|    total_timesteps      | 2842624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026176374 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 29780       |\n",
      "|    policy_gradient_loss | 0.0109      |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 810        |\n",
      "|    ep_rew_mean          | -2.37e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 528        |\n",
      "|    iterations           | 1389       |\n",
      "|    time_elapsed         | 5384       |\n",
      "|    total_timesteps      | 2844672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.86304545 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.37       |\n",
      "|    explained_variance   | 0.403      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.32e+07   |\n",
      "|    n_updates            | 29790      |\n",
      "|    policy_gradient_loss | 0.0059     |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 2.48e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2845000, episode_reward=13564.84 +/- 2911.52\n",
      "Episode length: 881.00 +/- 150.23\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 881        |\n",
      "|    mean_reward          | 1.36e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2845000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14757012 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.37       |\n",
      "|    explained_variance   | 0.778      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 251        |\n",
      "|    n_updates            | 29800      |\n",
      "|    policy_gradient_loss | 0.025      |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 5.19e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 821       |\n",
      "|    ep_rew_mean     | -2.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 528       |\n",
      "|    iterations      | 1390      |\n",
      "|    time_elapsed    | 5388      |\n",
      "|    total_timesteps | 2846720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 809         |\n",
      "|    ep_rew_mean          | -2.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1391        |\n",
      "|    time_elapsed         | 5390        |\n",
      "|    total_timesteps      | 2848768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015881859 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 435         |\n",
      "|    n_updates            | 29810       |\n",
      "|    policy_gradient_loss | 0.00157     |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 3.83e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2850000, episode_reward=-25048.63 +/- 73501.31\n",
      "Episode length: 540.20 +/- 216.66\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 540       |\n",
      "|    mean_reward          | -2.5e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 2850000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.8193447 |\n",
      "|    clip_fraction        | 0.125     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.36      |\n",
      "|    explained_variance   | 0.416     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.41e+07  |\n",
      "|    n_updates            | 29820     |\n",
      "|    policy_gradient_loss | -0.00636  |\n",
      "|    std                  | 0.16      |\n",
      "|    value_loss           | 2.83e+07  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 818       |\n",
      "|    ep_rew_mean     | -2.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 528       |\n",
      "|    iterations      | 1392      |\n",
      "|    time_elapsed    | 5393      |\n",
      "|    total_timesteps | 2850816   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 815         |\n",
      "|    ep_rew_mean          | -2.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1393        |\n",
      "|    time_elapsed         | 5395        |\n",
      "|    total_timesteps      | 2852864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028115667 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 122         |\n",
      "|    n_updates            | 29830       |\n",
      "|    policy_gradient_loss | 0.0187      |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 403         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 819         |\n",
      "|    ep_rew_mean          | -2.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1394        |\n",
      "|    time_elapsed         | 5397        |\n",
      "|    total_timesteps      | 2854912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024472486 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.772       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 256         |\n",
      "|    n_updates            | 29840       |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 4.82e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2855000, episode_reward=-27081.18 +/- 68697.81\n",
      "Episode length: 541.40 +/- 216.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 541         |\n",
      "|    mean_reward          | -2.71e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2855000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009169215 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.92e+07    |\n",
      "|    n_updates            | 29850       |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 2.86e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 816      |\n",
      "|    ep_rew_mean     | -2.2e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 529      |\n",
      "|    iterations      | 1395     |\n",
      "|    time_elapsed    | 5400     |\n",
      "|    total_timesteps | 2856960  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 819        |\n",
      "|    ep_rew_mean          | -2.19e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 529        |\n",
      "|    iterations           | 1396       |\n",
      "|    time_elapsed         | 5402       |\n",
      "|    total_timesteps      | 2859008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02192355 |\n",
      "|    clip_fraction        | 0.231      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.454      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 253        |\n",
      "|    n_updates            | 29860      |\n",
      "|    policy_gradient_loss | 0.00074    |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 6.11e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2860000, episode_reward=13581.64 +/- 2974.76\n",
      "Episode length: 927.20 +/- 138.75\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 927        |\n",
      "|    mean_reward          | 1.36e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2860000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.22437379 |\n",
      "|    clip_fraction        | 0.396      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 85.2       |\n",
      "|    n_updates            | 29870      |\n",
      "|    policy_gradient_loss | 0.015      |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 373        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 812       |\n",
      "|    ep_rew_mean     | -2.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1397      |\n",
      "|    time_elapsed    | 5406      |\n",
      "|    total_timesteps | 2861056   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 820        |\n",
      "|    ep_rew_mean          | -1.95e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 529        |\n",
      "|    iterations           | 1398       |\n",
      "|    time_elapsed         | 5408       |\n",
      "|    total_timesteps      | 2863104    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25753778 |\n",
      "|    clip_fraction        | 0.151      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.425      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.14e+06   |\n",
      "|    n_updates            | 29880      |\n",
      "|    policy_gradient_loss | 0.00863    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.63e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2865000, episode_reward=9722.28 +/- 3741.64\n",
      "Episode length: 702.60 +/- 26.73\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 703        |\n",
      "|    mean_reward          | 9.72e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2865000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12509766 |\n",
      "|    clip_fraction        | 0.211      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 328        |\n",
      "|    n_updates            | 29890      |\n",
      "|    policy_gradient_loss | 0.00928    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.71e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 812       |\n",
      "|    ep_rew_mean     | -2.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1399      |\n",
      "|    time_elapsed    | 5411      |\n",
      "|    total_timesteps | 2865152   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 810         |\n",
      "|    ep_rew_mean          | -2.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1400        |\n",
      "|    time_elapsed         | 5413        |\n",
      "|    total_timesteps      | 2867200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024299745 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.05e+06    |\n",
      "|    n_updates            | 29900       |\n",
      "|    policy_gradient_loss | 0.00891     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 5.47e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 813        |\n",
      "|    ep_rew_mean          | -2.01e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 529        |\n",
      "|    iterations           | 1401       |\n",
      "|    time_elapsed         | 5415       |\n",
      "|    total_timesteps      | 2869248    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03507825 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.32       |\n",
      "|    explained_variance   | 0.478      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.14e+05   |\n",
      "|    n_updates            | 29910      |\n",
      "|    policy_gradient_loss | 0.00542    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 1.6e+05    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2870000, episode_reward=7460.77 +/- 5036.08\n",
      "Episode length: 640.40 +/- 5.68\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 640        |\n",
      "|    mean_reward          | 7.46e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2870000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17566349 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.32       |\n",
      "|    explained_variance   | 0.776      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.36e+04   |\n",
      "|    n_updates            | 29920      |\n",
      "|    policy_gradient_loss | 0.0116     |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 1.09e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 789       |\n",
      "|    ep_rew_mean     | -2.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1402      |\n",
      "|    time_elapsed    | 5418      |\n",
      "|    total_timesteps | 2871296   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 790         |\n",
      "|    ep_rew_mean          | -2.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1403        |\n",
      "|    time_elapsed         | 5420        |\n",
      "|    total_timesteps      | 2873344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007377671 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.379       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.67e+07    |\n",
      "|    n_updates            | 29930       |\n",
      "|    policy_gradient_loss | 0.00963     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 5.93e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2875000, episode_reward=-65001.18 +/- 92146.28\n",
      "Episode length: 427.60 +/- 259.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 428         |\n",
      "|    mean_reward          | -6.5e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2875000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018576689 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.699       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 971         |\n",
      "|    n_updates            | 29940       |\n",
      "|    policy_gradient_loss | 0.0207      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 5.5e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 792       |\n",
      "|    ep_rew_mean     | -2.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1404      |\n",
      "|    time_elapsed    | 5423      |\n",
      "|    total_timesteps | 2875392   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 768         |\n",
      "|    ep_rew_mean          | -2.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1405        |\n",
      "|    time_elapsed         | 5425        |\n",
      "|    total_timesteps      | 2877440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033311132 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.642       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 280         |\n",
      "|    n_updates            | 29950       |\n",
      "|    policy_gradient_loss | 0.0267      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.42e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 767       |\n",
      "|    ep_rew_mean          | -2.12e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 530       |\n",
      "|    iterations           | 1406      |\n",
      "|    time_elapsed         | 5427      |\n",
      "|    total_timesteps      | 2879488   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.7164719 |\n",
      "|    clip_fraction        | 0.248     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.31      |\n",
      "|    explained_variance   | 0.382     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.64e+07  |\n",
      "|    n_updates            | 29960     |\n",
      "|    policy_gradient_loss | -0.0124   |\n",
      "|    std                  | 0.162     |\n",
      "|    value_loss           | 3.06e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=2880000, episode_reward=9058.63 +/- 4268.52\n",
      "Episode length: 668.40 +/- 9.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 668         |\n",
      "|    mean_reward          | 9.06e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033727042 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.475       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.48e+03    |\n",
      "|    n_updates            | 29970       |\n",
      "|    policy_gradient_loss | 0.00431     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 8.25e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 746       |\n",
      "|    ep_rew_mean     | -2.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1407      |\n",
      "|    time_elapsed    | 5430      |\n",
      "|    total_timesteps | 2881536   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 734         |\n",
      "|    ep_rew_mean          | -2.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1408        |\n",
      "|    time_elapsed         | 5432        |\n",
      "|    total_timesteps      | 2883584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016110918 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.12e+05    |\n",
      "|    n_updates            | 29980       |\n",
      "|    policy_gradient_loss | 0.00193     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 6.06e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2885000, episode_reward=-13514.72 +/- 54268.55\n",
      "Episode length: 792.80 +/- 141.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 793         |\n",
      "|    mean_reward          | -1.35e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2885000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035246726 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 257         |\n",
      "|    n_updates            | 29990       |\n",
      "|    policy_gradient_loss | 0.0128      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 9.89e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 743       |\n",
      "|    ep_rew_mean     | -1.84e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1409      |\n",
      "|    time_elapsed    | 5436      |\n",
      "|    total_timesteps | 2885632   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 748         |\n",
      "|    ep_rew_mean          | -1.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 1410        |\n",
      "|    time_elapsed         | 5438        |\n",
      "|    total_timesteps      | 2887680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010458006 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 30000       |\n",
      "|    policy_gradient_loss | 0.00325     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 5.22e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 748         |\n",
      "|    ep_rew_mean          | -1.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 1411        |\n",
      "|    time_elapsed         | 5439        |\n",
      "|    total_timesteps      | 2889728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024729291 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 246         |\n",
      "|    n_updates            | 30010       |\n",
      "|    policy_gradient_loss | 0.00526     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.98e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2890000, episode_reward=9537.32 +/- 66044.51\n",
      "Episode length: 2652.60 +/- 1917.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.65e+03   |\n",
      "|    mean_reward          | 9.54e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2890000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07338169 |\n",
      "|    clip_fraction        | 0.38       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.31       |\n",
      "|    explained_variance   | 0.726      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 235        |\n",
      "|    n_updates            | 30020      |\n",
      "|    policy_gradient_loss | 0.0281     |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.37e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 781       |\n",
      "|    ep_rew_mean     | -1.45e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1412      |\n",
      "|    time_elapsed    | 5448      |\n",
      "|    total_timesteps | 2891776   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 781         |\n",
      "|    ep_rew_mean          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1413        |\n",
      "|    time_elapsed         | 5450        |\n",
      "|    total_timesteps      | 2893824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020709373 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 174         |\n",
      "|    n_updates            | 30030       |\n",
      "|    policy_gradient_loss | 0.0161      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.97e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2895000, episode_reward=-10908.62 +/- 38242.19\n",
      "Episode length: 743.20 +/- 45.07\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 743        |\n",
      "|    mean_reward          | -1.09e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2895000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.18492231 |\n",
      "|    clip_fraction        | 0.533      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.3        |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 74.4       |\n",
      "|    n_updates            | 30040      |\n",
      "|    policy_gradient_loss | 0.0538     |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.09e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 777       |\n",
      "|    ep_rew_mean     | -1.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1414      |\n",
      "|    time_elapsed    | 5453      |\n",
      "|    total_timesteps | 2895872   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 765       |\n",
      "|    ep_rew_mean          | -1.57e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 531       |\n",
      "|    iterations           | 1415      |\n",
      "|    time_elapsed         | 5455      |\n",
      "|    total_timesteps      | 2897920   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.4504662 |\n",
      "|    clip_fraction        | 0.222     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.3       |\n",
      "|    explained_variance   | 0.38      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.61e+06  |\n",
      "|    n_updates            | 30050     |\n",
      "|    policy_gradient_loss | 0.0242    |\n",
      "|    std                  | 0.162     |\n",
      "|    value_loss           | 3.07e+07  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 764         |\n",
      "|    ep_rew_mean          | -1.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 531         |\n",
      "|    iterations           | 1416        |\n",
      "|    time_elapsed         | 5457        |\n",
      "|    total_timesteps      | 2899968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037732974 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.3        |\n",
      "|    n_updates            | 30060       |\n",
      "|    policy_gradient_loss | 0.00583     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.31e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2900000, episode_reward=42899.07 +/- 49008.67\n",
      "Episode length: 3496.60 +/- 1224.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.5e+03     |\n",
      "|    mean_reward          | 4.29e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.066590816 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 129         |\n",
      "|    n_updates            | 30070       |\n",
      "|    policy_gradient_loss | 0.0304      |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 2.05e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 759       |\n",
      "|    ep_rew_mean     | -1.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1417      |\n",
      "|    time_elapsed    | 5467      |\n",
      "|    total_timesteps | 2902016   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 781        |\n",
      "|    ep_rew_mean          | -1.29e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 530        |\n",
      "|    iterations           | 1418       |\n",
      "|    time_elapsed         | 5469       |\n",
      "|    total_timesteps      | 2904064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01293982 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.27       |\n",
      "|    explained_variance   | 0.352      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 7.82e+06   |\n",
      "|    n_updates            | 30080      |\n",
      "|    policy_gradient_loss | -0.00187   |\n",
      "|    std                  | 0.163      |\n",
      "|    value_loss           | 1.02e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2905000, episode_reward=49955.67 +/- 2072.67\n",
      "Episode length: 3419.60 +/- 16.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.42e+03    |\n",
      "|    mean_reward          | 5e+04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2905000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010412017 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 323         |\n",
      "|    n_updates            | 30090       |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 3.02e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 800       |\n",
      "|    ep_rew_mean     | -1.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1419      |\n",
      "|    time_elapsed    | 5479      |\n",
      "|    total_timesteps | 2906112   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 796          |\n",
      "|    ep_rew_mean          | -1.28e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 1420         |\n",
      "|    time_elapsed         | 5481         |\n",
      "|    total_timesteps      | 2908160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058278693 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.27         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 624          |\n",
      "|    n_updates            | 30100        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    std                  | 0.163        |\n",
      "|    value_loss           | 2.13e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2910000, episode_reward=35810.31 +/- 3916.36\n",
      "Episode length: 2563.00 +/- 9.23\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.56e+03   |\n",
      "|    mean_reward          | 3.58e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2910000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05161505 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.27       |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 429        |\n",
      "|    n_updates            | 30110      |\n",
      "|    policy_gradient_loss | 0.00734    |\n",
      "|    std                  | 0.163      |\n",
      "|    value_loss           | 2.08e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 817       |\n",
      "|    ep_rew_mean     | -1.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1421      |\n",
      "|    time_elapsed    | 5489      |\n",
      "|    total_timesteps | 2910208   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 832         |\n",
      "|    ep_rew_mean          | -1.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1422        |\n",
      "|    time_elapsed         | 5491        |\n",
      "|    total_timesteps      | 2912256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022687508 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 254         |\n",
      "|    n_updates            | 30120       |\n",
      "|    policy_gradient_loss | 0.000507    |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 839         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 836         |\n",
      "|    ep_rew_mean          | -1.34e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1423        |\n",
      "|    time_elapsed         | 5492        |\n",
      "|    total_timesteps      | 2914304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021678036 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 333         |\n",
      "|    n_updates            | 30130       |\n",
      "|    policy_gradient_loss | 0.00173     |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 2.59e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2915000, episode_reward=37562.93 +/- 3787.79\n",
      "Episode length: 2489.00 +/- 9.06\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.49e+03     |\n",
      "|    mean_reward          | 3.76e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2915000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032696724 |\n",
      "|    clip_fraction        | 0.0479       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.27         |\n",
      "|    explained_variance   | 0.373        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+07     |\n",
      "|    n_updates            | 30140        |\n",
      "|    policy_gradient_loss | 0.000713     |\n",
      "|    std                  | 0.163        |\n",
      "|    value_loss           | 2.2e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 836       |\n",
      "|    ep_rew_mean     | -1.34e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1424      |\n",
      "|    time_elapsed    | 5500      |\n",
      "|    total_timesteps | 2916352   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 860         |\n",
      "|    ep_rew_mean          | -1.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1425        |\n",
      "|    time_elapsed         | 5502        |\n",
      "|    total_timesteps      | 2918400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009235926 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 688         |\n",
      "|    n_updates            | 30150       |\n",
      "|    policy_gradient_loss | -0.00193    |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 3.81e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2920000, episode_reward=35867.03 +/- 2809.54\n",
      "Episode length: 2441.00 +/- 11.51\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.44e+03  |\n",
      "|    mean_reward          | 3.59e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 2920000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0195635 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.27      |\n",
      "|    explained_variance   | 0.891     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 126       |\n",
      "|    n_updates            | 30160     |\n",
      "|    policy_gradient_loss | 0.00448   |\n",
      "|    std                  | 0.163     |\n",
      "|    value_loss           | 3.17e+04  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 870       |\n",
      "|    ep_rew_mean     | -1.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1426      |\n",
      "|    time_elapsed    | 5510      |\n",
      "|    total_timesteps | 2920448   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 886         |\n",
      "|    ep_rew_mean          | -1.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1427        |\n",
      "|    time_elapsed         | 5512        |\n",
      "|    total_timesteps      | 2922496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019594606 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.346       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.85e+06    |\n",
      "|    n_updates            | 30170       |\n",
      "|    policy_gradient_loss | 0.00266     |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 3.09e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 897         |\n",
      "|    ep_rew_mean          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1428        |\n",
      "|    time_elapsed         | 5513        |\n",
      "|    total_timesteps      | 2924544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020201791 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 282         |\n",
      "|    n_updates            | 30180       |\n",
      "|    policy_gradient_loss | 0.000204    |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2925000, episode_reward=35078.33 +/- 1352.90\n",
      "Episode length: 2396.20 +/- 8.08\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.4e+03      |\n",
      "|    mean_reward          | 3.51e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2925000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066417833 |\n",
      "|    clip_fraction        | 0.16         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.28         |\n",
      "|    explained_variance   | 0.327        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1e+07        |\n",
      "|    n_updates            | 30190        |\n",
      "|    policy_gradient_loss | 0.000933     |\n",
      "|    std                  | 0.163        |\n",
      "|    value_loss           | 1.62e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 915       |\n",
      "|    ep_rew_mean     | -1.36e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1429      |\n",
      "|    time_elapsed    | 5521      |\n",
      "|    total_timesteps | 2926592   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 920         |\n",
      "|    ep_rew_mean          | -1.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1430        |\n",
      "|    time_elapsed         | 5523        |\n",
      "|    total_timesteps      | 2928640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008523471 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.669       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.32e+03    |\n",
      "|    n_updates            | 30200       |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 1.32e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2930000, episode_reward=38174.63 +/- 4275.79\n",
      "Episode length: 2709.40 +/- 13.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.71e+03    |\n",
      "|    mean_reward          | 3.82e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036045305 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 30210       |\n",
      "|    policy_gradient_loss | 0.009       |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.51e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 948       |\n",
      "|    ep_rew_mean     | -1.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1431      |\n",
      "|    time_elapsed    | 5531      |\n",
      "|    total_timesteps | 2930688   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 943         |\n",
      "|    ep_rew_mean          | -1.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1432        |\n",
      "|    time_elapsed         | 5533        |\n",
      "|    total_timesteps      | 2932736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014350673 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 264         |\n",
      "|    n_updates            | 30220       |\n",
      "|    policy_gradient_loss | -0.000113   |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.07e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 965         |\n",
      "|    ep_rew_mean          | -1.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1433        |\n",
      "|    time_elapsed         | 5535        |\n",
      "|    total_timesteps      | 2934784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009624504 |\n",
      "|    clip_fraction        | 0.0644      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.367       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.5e+06     |\n",
      "|    n_updates            | 30230       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.93e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2935000, episode_reward=36109.98 +/- 2971.80\n",
      "Episode length: 2586.20 +/- 9.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.59e+03    |\n",
      "|    mean_reward          | 3.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2935000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008277647 |\n",
      "|    clip_fraction        | 0.0483      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.691       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.44e+03    |\n",
      "|    n_updates            | 30240       |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 7.33e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 982       |\n",
      "|    ep_rew_mean     | -1.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1434      |\n",
      "|    time_elapsed    | 5543      |\n",
      "|    total_timesteps | 2936832   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 982         |\n",
      "|    ep_rew_mean          | -1.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1435        |\n",
      "|    time_elapsed         | 5545        |\n",
      "|    total_timesteps      | 2938880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005390956 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 780         |\n",
      "|    n_updates            | 30250       |\n",
      "|    policy_gradient_loss | 0.00379     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 4.73e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2940000, episode_reward=18617.09 +/- 30775.83\n",
      "Episode length: 2240.60 +/- 592.84\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.24e+03   |\n",
      "|    mean_reward          | 1.86e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2940000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03585309 |\n",
      "|    clip_fraction        | 0.441      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.28       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 90.9       |\n",
      "|    n_updates            | 30260      |\n",
      "|    policy_gradient_loss | 0.0739     |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 359        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 993       |\n",
      "|    ep_rew_mean     | -1.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1436      |\n",
      "|    time_elapsed    | 5552      |\n",
      "|    total_timesteps | 2940928   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -1.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1437        |\n",
      "|    time_elapsed         | 5554        |\n",
      "|    total_timesteps      | 2942976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024952305 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.2        |\n",
      "|    n_updates            | 30270       |\n",
      "|    policy_gradient_loss | 0.00924     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 392         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2945000, episode_reward=24702.24 +/- 284.12\n",
      "Episode length: 2219.20 +/- 13.01\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.22e+03    |\n",
      "|    mean_reward          | 2.47e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2945000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013729289 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 393         |\n",
      "|    n_updates            | 30280       |\n",
      "|    policy_gradient_loss | 0.00683     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.02e+03  |\n",
      "|    ep_rew_mean     | -1.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1438      |\n",
      "|    time_elapsed    | 5561      |\n",
      "|    total_timesteps | 2945024   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.03e+03   |\n",
      "|    ep_rew_mean          | -1.04e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 529        |\n",
      "|    iterations           | 1439       |\n",
      "|    time_elapsed         | 5563       |\n",
      "|    total_timesteps      | 2947072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16337433 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.27       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 58.4       |\n",
      "|    n_updates            | 30290      |\n",
      "|    policy_gradient_loss | 0.0233     |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 425        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -8.51e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1440        |\n",
      "|    time_elapsed         | 5565        |\n",
      "|    total_timesteps      | 2949120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022727322 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 30300       |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    std                  | 0.163       |\n",
      "|    value_loss           | 349         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2950000, episode_reward=19471.61 +/- 3993.93\n",
      "Episode length: 1886.60 +/- 22.13\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.89e+03   |\n",
      "|    mean_reward          | 1.95e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2950000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01371401 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.27       |\n",
      "|    explained_variance   | 0.871      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 105        |\n",
      "|    n_updates            | 30310      |\n",
      "|    policy_gradient_loss | 0.00712    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.3e+04    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.06e+03  |\n",
      "|    ep_rew_mean     | -9.55e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1441      |\n",
      "|    time_elapsed    | 5571      |\n",
      "|    total_timesteps | 2951168   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.07e+03   |\n",
      "|    ep_rew_mean          | -1.05e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 529        |\n",
      "|    iterations           | 1442       |\n",
      "|    time_elapsed         | 5573       |\n",
      "|    total_timesteps      | 2953216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05167009 |\n",
      "|    clip_fraction        | 0.209      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.27       |\n",
      "|    explained_variance   | 0.345      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 9.46e+06   |\n",
      "|    n_updates            | 30320      |\n",
      "|    policy_gradient_loss | 0.0238     |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 1.51e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2955000, episode_reward=-43857.94 +/- 82295.55\n",
      "Episode length: 1350.40 +/- 667.27\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.35e+03     |\n",
      "|    mean_reward          | -4.39e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2955000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035387836 |\n",
      "|    clip_fraction        | 0.0341       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.27         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.24e+07     |\n",
      "|    n_updates            | 30330        |\n",
      "|    policy_gradient_loss | -0.00404     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 1.59e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -1.25e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1443      |\n",
      "|    time_elapsed    | 5578      |\n",
      "|    total_timesteps | 2955264   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08e+03    |\n",
      "|    ep_rew_mean          | -1.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1444        |\n",
      "|    time_elapsed         | 5580        |\n",
      "|    total_timesteps      | 2957312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001392602 |\n",
      "|    clip_fraction        | 0.00591     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.78e+07    |\n",
      "|    n_updates            | 30340       |\n",
      "|    policy_gradient_loss | -0.00326    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.19e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.09e+03      |\n",
      "|    ep_rew_mean          | -1.14e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 530           |\n",
      "|    iterations           | 1445          |\n",
      "|    time_elapsed         | 5582          |\n",
      "|    total_timesteps      | 2959360       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072230375 |\n",
      "|    clip_fraction        | 0.00137       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 3.27          |\n",
      "|    explained_variance   | 0.403         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.48e+04      |\n",
      "|    n_updates            | 30350         |\n",
      "|    policy_gradient_loss | -0.000556     |\n",
      "|    std                  | 0.162         |\n",
      "|    value_loss           | 1.26e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=2960000, episode_reward=21346.33 +/- 3727.76\n",
      "Episode length: 1935.60 +/- 50.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.94e+03    |\n",
      "|    mean_reward          | 2.13e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003777577 |\n",
      "|    clip_fraction        | 0.0213      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.05e+04    |\n",
      "|    n_updates            | 30360       |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 9.02e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.09e+03  |\n",
      "|    ep_rew_mean     | -1.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1446      |\n",
      "|    time_elapsed    | 5588      |\n",
      "|    total_timesteps | 2961408   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.11e+03   |\n",
      "|    ep_rew_mean          | -1.25e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 530        |\n",
      "|    iterations           | 1447       |\n",
      "|    time_elapsed         | 5590       |\n",
      "|    total_timesteps      | 2963456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00743437 |\n",
      "|    clip_fraction        | 0.0751     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.27       |\n",
      "|    explained_variance   | 0.884      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.28e+03   |\n",
      "|    n_updates            | 30370      |\n",
      "|    policy_gradient_loss | -0.00981   |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 5.65e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2965000, episode_reward=-3269.14 +/- 34221.38\n",
      "Episode length: 1879.60 +/- 613.71\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.88e+03     |\n",
      "|    mean_reward          | -3.27e+03    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 2965000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026760467 |\n",
      "|    clip_fraction        | 0.00859      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.27         |\n",
      "|    explained_variance   | 0.378        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.34e+06     |\n",
      "|    n_updates            | 30380        |\n",
      "|    policy_gradient_loss | -0.00103     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 1.57e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -1.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1448      |\n",
      "|    time_elapsed    | 5596      |\n",
      "|    total_timesteps | 2965504   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12e+03     |\n",
      "|    ep_rew_mean          | -1.24e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 1449         |\n",
      "|    time_elapsed         | 5598         |\n",
      "|    total_timesteps      | 2967552      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056654625 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.27         |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+03     |\n",
      "|    n_updates            | 30390        |\n",
      "|    policy_gradient_loss | -0.0026      |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 2e+04        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.14e+03     |\n",
      "|    ep_rew_mean          | -1.05e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 1450         |\n",
      "|    time_elapsed         | 5600         |\n",
      "|    total_timesteps      | 2969600      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036579114 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.27         |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.15e+03     |\n",
      "|    n_updates            | 30400        |\n",
      "|    policy_gradient_loss | -0.00128     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 1.74e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2970000, episode_reward=21165.11 +/- 2507.17\n",
      "Episode length: 1887.40 +/- 52.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.89e+03    |\n",
      "|    mean_reward          | 2.12e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005877589 |\n",
      "|    clip_fraction        | 0.051       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 849         |\n",
      "|    n_updates            | 30410       |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.6e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.15e+03  |\n",
      "|    ep_rew_mean     | -1.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1451      |\n",
      "|    time_elapsed    | 5606      |\n",
      "|    total_timesteps | 2971648   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | -1.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1452        |\n",
      "|    time_elapsed         | 5608        |\n",
      "|    total_timesteps      | 2973696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008809571 |\n",
      "|    clip_fraction        | 0.0542      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 664         |\n",
      "|    n_updates            | 30420       |\n",
      "|    policy_gradient_loss | -0.005      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.84e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=2975000, episode_reward=-2140.50 +/- 44904.58\n",
      "Episode length: 1655.80 +/- 233.73\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.66e+03    |\n",
      "|    mean_reward          | -2.14e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2975000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009660639 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 771         |\n",
      "|    n_updates            | 30430       |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 4.41e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.17e+03  |\n",
      "|    ep_rew_mean     | -1.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1453      |\n",
      "|    time_elapsed    | 5614      |\n",
      "|    total_timesteps | 2975744   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -1.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1454        |\n",
      "|    time_elapsed         | 5616        |\n",
      "|    total_timesteps      | 2977792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015121527 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.27        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 173         |\n",
      "|    n_updates            | 30440       |\n",
      "|    policy_gradient_loss | 0.00607     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.2e+03     |\n",
      "|    ep_rew_mean          | -1e+04      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1455        |\n",
      "|    time_elapsed         | 5618        |\n",
      "|    total_timesteps      | 2979840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011399871 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 130         |\n",
      "|    n_updates            | 30450       |\n",
      "|    policy_gradient_loss | 0.00622     |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.67e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2980000, episode_reward=-1981.92 +/- 42279.09\n",
      "Episode length: 1652.80 +/- 231.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.65e+03    |\n",
      "|    mean_reward          | -1.98e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016037868 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 30460       |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 2.92e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -1.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1456      |\n",
      "|    time_elapsed    | 5624      |\n",
      "|    total_timesteps | 2981888   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.22e+03     |\n",
      "|    ep_rew_mean          | -1.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 1457         |\n",
      "|    time_elapsed         | 5625         |\n",
      "|    total_timesteps      | 2983936      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016228638 |\n",
      "|    clip_fraction        | 0.00752      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.28         |\n",
      "|    explained_variance   | 0.36         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+07     |\n",
      "|    n_updates            | 30470        |\n",
      "|    policy_gradient_loss | 0.000271     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 2.76e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2985000, episode_reward=-22909.44 +/- 79581.58\n",
      "Episode length: 1385.80 +/- 636.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.39e+03    |\n",
      "|    mean_reward          | -2.29e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2985000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005874764 |\n",
      "|    clip_fraction        | 0.0421      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 966         |\n",
      "|    n_updates            | 30480       |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 6.47e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.23e+03  |\n",
      "|    ep_rew_mean     | -1.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1458      |\n",
      "|    time_elapsed    | 5631      |\n",
      "|    total_timesteps | 2985984   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.24e+03     |\n",
      "|    ep_rew_mean          | -1.09e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 1459         |\n",
      "|    time_elapsed         | 5632         |\n",
      "|    total_timesteps      | 2988032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0109994095 |\n",
      "|    clip_fraction        | 0.0769       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.28         |\n",
      "|    explained_variance   | 0.965        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 248          |\n",
      "|    n_updates            | 30490        |\n",
      "|    policy_gradient_loss | -0.000248    |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 2.59e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2990000, episode_reward=24561.67 +/- 3035.76\n",
      "Episode length: 2419.20 +/- 10.93\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.42e+03   |\n",
      "|    mean_reward          | 2.46e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 2990000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01869101 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.29       |\n",
      "|    explained_variance   | 0.387      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.31e+05   |\n",
      "|    n_updates            | 30500      |\n",
      "|    policy_gradient_loss | 0.00661    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 1.43e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.25e+03  |\n",
      "|    ep_rew_mean     | -1.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 530       |\n",
      "|    iterations      | 1460      |\n",
      "|    time_elapsed    | 5640      |\n",
      "|    total_timesteps | 2990080   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.27e+03     |\n",
      "|    ep_rew_mean          | -1.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 1461         |\n",
      "|    time_elapsed         | 5642         |\n",
      "|    total_timesteps      | 2992128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074973414 |\n",
      "|    clip_fraction        | 0.0682       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.29         |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.49e+03     |\n",
      "|    n_updates            | 30510        |\n",
      "|    policy_gradient_loss | -0.00885     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 4.35e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29e+03    |\n",
      "|    ep_rew_mean          | -8.88e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1462        |\n",
      "|    time_elapsed         | 5644        |\n",
      "|    total_timesteps      | 2994176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015350711 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.28        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 163         |\n",
      "|    n_updates            | 30520       |\n",
      "|    policy_gradient_loss | -0.00094    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.75e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2995000, episode_reward=34972.67 +/- 3521.76\n",
      "Episode length: 2967.40 +/- 8.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.97e+03    |\n",
      "|    mean_reward          | 3.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2995000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016302027 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 30530       |\n",
      "|    policy_gradient_loss | 0.0133      |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.29e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.3e+03  |\n",
      "|    ep_rew_mean     | -8.6e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 530      |\n",
      "|    iterations      | 1463     |\n",
      "|    time_elapsed    | 5652     |\n",
      "|    total_timesteps | 2996224  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.3e+03      |\n",
      "|    ep_rew_mean          | -8.6e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 530          |\n",
      "|    iterations           | 1464         |\n",
      "|    time_elapsed         | 5654         |\n",
      "|    total_timesteps      | 2998272      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039375625 |\n",
      "|    clip_fraction        | 0.0515       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.29         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.15e+06     |\n",
      "|    n_updates            | 30540        |\n",
      "|    policy_gradient_loss | 0.000124     |\n",
      "|    std                  | 0.162        |\n",
      "|    value_loss           | 1.89e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3000000, episode_reward=-14458.88 +/- 83074.71\n",
      "Episode length: 2284.00 +/- 1084.56\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.28e+03    |\n",
      "|    mean_reward          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028325418 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.85e+03    |\n",
      "|    n_updates            | 30550       |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 1.26e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.33e+03  |\n",
      "|    ep_rew_mean     | -8.33e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1465      |\n",
      "|    time_elapsed    | 5661      |\n",
      "|    total_timesteps | 3000320   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.34e+03    |\n",
      "|    ep_rew_mean          | -9.98e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1466        |\n",
      "|    time_elapsed         | 5663        |\n",
      "|    total_timesteps      | 3002368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008407525 |\n",
      "|    clip_fraction        | 0.0546      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.22e+04    |\n",
      "|    n_updates            | 30560       |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 4.44e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.34e+03   |\n",
      "|    ep_rew_mean          | -9.98e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 530        |\n",
      "|    iterations           | 1467       |\n",
      "|    time_elapsed         | 5665       |\n",
      "|    total_timesteps      | 3004416    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.30176842 |\n",
      "|    clip_fraction        | 0.0778     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.29       |\n",
      "|    explained_variance   | 0.381      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.34e+07   |\n",
      "|    n_updates            | 30570      |\n",
      "|    policy_gradient_loss | 0.00954    |\n",
      "|    std                  | 0.162      |\n",
      "|    value_loss           | 2.97e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3005000, episode_reward=26594.37 +/- 3368.21\n",
      "Episode length: 2801.40 +/- 12.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.8e+03     |\n",
      "|    mean_reward          | 2.66e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3005000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004706044 |\n",
      "|    clip_fraction        | 0.0788      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 530         |\n",
      "|    n_updates            | 30580       |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    std                  | 0.162       |\n",
      "|    value_loss           | 3.64e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.36e+03 |\n",
      "|    ep_rew_mean     | -9.7e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 529      |\n",
      "|    iterations      | 1468     |\n",
      "|    time_elapsed    | 5674     |\n",
      "|    total_timesteps | 3006464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | -9.46e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 530         |\n",
      "|    iterations           | 1469        |\n",
      "|    time_elapsed         | 5675        |\n",
      "|    total_timesteps      | 3008512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007445515 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 269         |\n",
      "|    n_updates            | 30590       |\n",
      "|    policy_gradient_loss | 0.00113     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3010000, episode_reward=26304.60 +/- 3104.17\n",
      "Episode length: 2850.00 +/- 7.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.85e+03    |\n",
      "|    mean_reward          | 2.63e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015197994 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 193         |\n",
      "|    n_updates            | 30600       |\n",
      "|    policy_gradient_loss | -0.000339   |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 2.96e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.4e+03   |\n",
      "|    ep_rew_mean     | -7.44e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1470      |\n",
      "|    time_elapsed    | 5684      |\n",
      "|    total_timesteps | 3010560   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.41e+03    |\n",
      "|    ep_rew_mean          | -7.08e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1471        |\n",
      "|    time_elapsed         | 5686        |\n",
      "|    total_timesteps      | 3012608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012959763 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 30610       |\n",
      "|    policy_gradient_loss | 0.00249     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 601         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -6.91e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1472        |\n",
      "|    time_elapsed         | 5688        |\n",
      "|    total_timesteps      | 3014656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002668435 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.39        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.86e+07    |\n",
      "|    n_updates            | 30620       |\n",
      "|    policy_gradient_loss | 7.18e-05    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.91e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3015000, episode_reward=26079.33 +/- 5229.60\n",
      "Episode length: 2883.00 +/- 14.07\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.88e+03   |\n",
      "|    mean_reward          | 2.61e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3015000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00842681 |\n",
      "|    clip_fraction        | 0.0876     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.29       |\n",
      "|    explained_variance   | 0.906      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.89e+03   |\n",
      "|    n_updates            | 30630      |\n",
      "|    policy_gradient_loss | -0.00407   |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 4.17e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.45e+03  |\n",
      "|    ep_rew_mean     | -6.79e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1473      |\n",
      "|    time_elapsed    | 5696      |\n",
      "|    total_timesteps | 3016704   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | -6.79e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1474        |\n",
      "|    time_elapsed         | 5698        |\n",
      "|    total_timesteps      | 3018752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006416722 |\n",
      "|    clip_fraction        | 0.0882      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.96e+03    |\n",
      "|    n_updates            | 30640       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.08e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3020000, episode_reward=23530.05 +/- 4902.96\n",
      "Episode length: 2765.20 +/- 133.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.77e+03    |\n",
      "|    mean_reward          | 2.35e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020285662 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 499         |\n",
      "|    n_updates            | 30650       |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.85e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.47e+03 |\n",
      "|    ep_rew_mean     | -6.8e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 529      |\n",
      "|    iterations      | 1475     |\n",
      "|    time_elapsed    | 5707     |\n",
      "|    total_timesteps | 3020800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -6.63e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1476        |\n",
      "|    time_elapsed         | 5708        |\n",
      "|    total_timesteps      | 3022848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013465926 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 299         |\n",
      "|    n_updates            | 30660       |\n",
      "|    policy_gradient_loss | 0.00421     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 2.5e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49e+03    |\n",
      "|    ep_rew_mean          | -6.67e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1477        |\n",
      "|    time_elapsed         | 5710        |\n",
      "|    total_timesteps      | 3024896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006846961 |\n",
      "|    clip_fraction        | 0.0847      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.84e+05    |\n",
      "|    n_updates            | 30670       |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.95e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3025000, episode_reward=28386.78 +/- 2590.01\n",
      "Episode length: 2819.40 +/- 14.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.82e+03    |\n",
      "|    mean_reward          | 2.84e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3025000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003525721 |\n",
      "|    clip_fraction        | 0.0125      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.61e+03    |\n",
      "|    n_updates            | 30680       |\n",
      "|    policy_gradient_loss | -0.00256    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.07e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.5e+03  |\n",
      "|    ep_rew_mean     | -4.8e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 529      |\n",
      "|    iterations      | 1478     |\n",
      "|    time_elapsed    | 5719     |\n",
      "|    total_timesteps | 3026944  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.51e+03     |\n",
      "|    ep_rew_mean          | -5.63e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 529          |\n",
      "|    iterations           | 1479         |\n",
      "|    time_elapsed         | 5721         |\n",
      "|    total_timesteps      | 3028992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069520716 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.3          |\n",
      "|    explained_variance   | 0.883        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 529          |\n",
      "|    n_updates            | 30690        |\n",
      "|    policy_gradient_loss | -0.0042      |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 8.88e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3030000, episode_reward=-13763.18 +/- 87292.59\n",
      "Episode length: 2294.20 +/- 1088.67\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.29e+03     |\n",
      "|    mean_reward          | -1.38e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3030000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021487973 |\n",
      "|    clip_fraction        | 0.0347       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.3          |\n",
      "|    explained_variance   | 0.346        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+07     |\n",
      "|    n_updates            | 30700        |\n",
      "|    policy_gradient_loss | 0.000675     |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 1.23e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -5.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1480      |\n",
      "|    time_elapsed    | 5728      |\n",
      "|    total_timesteps | 3031040   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -6.22e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1481        |\n",
      "|    time_elapsed         | 5730        |\n",
      "|    total_timesteps      | 3033088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008459054 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+05    |\n",
      "|    n_updates            | 30710       |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 3.36e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3035000, episode_reward=18016.70 +/- 1424.51\n",
      "Episode length: 1890.40 +/- 12.01\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.89e+03   |\n",
      "|    mean_reward          | 1.8e+04    |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3035000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00999413 |\n",
      "|    clip_fraction        | 0.0588     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.3        |\n",
      "|    explained_variance   | 0.385      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.14e+07   |\n",
      "|    n_updates            | 30720      |\n",
      "|    policy_gradient_loss | 0.000227   |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 1.03e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.55e+03  |\n",
      "|    ep_rew_mean     | -6.13e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1482      |\n",
      "|    time_elapsed    | 5736      |\n",
      "|    total_timesteps | 3035136   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | -7.8e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 529          |\n",
      "|    iterations           | 1483         |\n",
      "|    time_elapsed         | 5738         |\n",
      "|    total_timesteps      | 3037184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0147283375 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.3          |\n",
      "|    explained_variance   | 0.986        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 213          |\n",
      "|    n_updates            | 30730        |\n",
      "|    policy_gradient_loss | 0.000773     |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 871          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | -9.38e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 529          |\n",
      "|    iterations           | 1484         |\n",
      "|    time_elapsed         | 5740         |\n",
      "|    total_timesteps      | 3039232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057305032 |\n",
      "|    clip_fraction        | 0.0903       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.3          |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3e+07        |\n",
      "|    n_updates            | 30740        |\n",
      "|    policy_gradient_loss | -0.00345     |\n",
      "|    std                  | 0.161        |\n",
      "|    value_loss           | 2.66e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3040000, episode_reward=27378.33 +/- 3801.82\n",
      "Episode length: 2891.80 +/- 12.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.89e+03    |\n",
      "|    mean_reward          | 2.74e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004054037 |\n",
      "|    clip_fraction        | 0.00913     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.89e+06    |\n",
      "|    n_updates            | 30750       |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 2.18e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -1.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 529       |\n",
      "|    iterations      | 1485      |\n",
      "|    time_elapsed    | 5748      |\n",
      "|    total_timesteps | 3041280   |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.58e+03      |\n",
      "|    ep_rew_mean          | -1.01e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 529           |\n",
      "|    iterations           | 1486          |\n",
      "|    time_elapsed         | 5750          |\n",
      "|    total_timesteps      | 3043328       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00072659855 |\n",
      "|    clip_fraction        | 0.00142       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 3.3           |\n",
      "|    explained_variance   | 0.452         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 7.3e+06       |\n",
      "|    n_updates            | 30760         |\n",
      "|    policy_gradient_loss | -0.00129      |\n",
      "|    std                  | 0.161         |\n",
      "|    value_loss           | 1.53e+07      |\n",
      "-------------------------------------------\n",
      "Eval num_timesteps=3045000, episode_reward=32428.38 +/- 2930.17\n",
      "Episode length: 2849.60 +/- 13.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.85e+03    |\n",
      "|    mean_reward          | 3.24e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3045000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002731083 |\n",
      "|    clip_fraction        | 0.0281      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.49e+03    |\n",
      "|    n_updates            | 30770       |\n",
      "|    policy_gradient_loss | -0.00385    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 4.52e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -9.98e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 528       |\n",
      "|    iterations      | 1487      |\n",
      "|    time_elapsed    | 5759      |\n",
      "|    total_timesteps | 3045376   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -9.87e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1488        |\n",
      "|    time_elapsed         | 5761        |\n",
      "|    total_timesteps      | 3047424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008349594 |\n",
      "|    clip_fraction        | 0.0545      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.18e+03    |\n",
      "|    n_updates            | 30780       |\n",
      "|    policy_gradient_loss | -0.0029     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 3.91e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -9.87e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 529         |\n",
      "|    iterations           | 1489        |\n",
      "|    time_elapsed         | 5762        |\n",
      "|    total_timesteps      | 3049472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016427979 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 286         |\n",
      "|    n_updates            | 30790       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 1.91e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3050000, episode_reward=31552.93 +/- 4249.83\n",
      "Episode length: 2949.00 +/- 8.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.95e+03    |\n",
      "|    mean_reward          | 3.16e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011412997 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 317         |\n",
      "|    n_updates            | 30800       |\n",
      "|    policy_gradient_loss | 0.00232     |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 1.2e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -1.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 528       |\n",
      "|    iterations      | 1490      |\n",
      "|    time_elapsed    | 5771      |\n",
      "|    total_timesteps | 3051520   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.58e+03   |\n",
      "|    ep_rew_mean          | -1.07e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 528        |\n",
      "|    iterations           | 1491       |\n",
      "|    time_elapsed         | 5773       |\n",
      "|    total_timesteps      | 3053568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01752456 |\n",
      "|    clip_fraction        | 0.157      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.31       |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 282        |\n",
      "|    n_updates            | 30810      |\n",
      "|    policy_gradient_loss | 0.00219    |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 3.23e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3055000, episode_reward=2360.79 +/- 98179.56\n",
      "Episode length: 3382.00 +/- 1630.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.38e+03    |\n",
      "|    mean_reward          | 2.36e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3055000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023331966 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.67e+04    |\n",
      "|    n_updates            | 30820       |\n",
      "|    policy_gradient_loss | -0.000664   |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 8.89e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.61e+03  |\n",
      "|    ep_rew_mean     | -8.68e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 528       |\n",
      "|    iterations      | 1492      |\n",
      "|    time_elapsed    | 5783      |\n",
      "|    total_timesteps | 3055616   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -8.68e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1493        |\n",
      "|    time_elapsed         | 5785        |\n",
      "|    total_timesteps      | 3057664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019697964 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 224         |\n",
      "|    n_updates            | 30830       |\n",
      "|    policy_gradient_loss | 0.000746    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.02e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -8.68e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1494        |\n",
      "|    time_elapsed         | 5787        |\n",
      "|    total_timesteps      | 3059712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018329212 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 103         |\n",
      "|    n_updates            | 30840       |\n",
      "|    policy_gradient_loss | 0.00417     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 782         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3060000, episode_reward=68590.68 +/- 4568.70\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.86e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008683752 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 771         |\n",
      "|    n_updates            | 30850       |\n",
      "|    policy_gradient_loss | -0.00128    |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 1.1e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -8.72e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 527       |\n",
      "|    iterations      | 1495      |\n",
      "|    time_elapsed    | 5800      |\n",
      "|    total_timesteps | 3061760   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.64e+03    |\n",
      "|    ep_rew_mean          | -8.72e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 528         |\n",
      "|    iterations           | 1496        |\n",
      "|    time_elapsed         | 5802        |\n",
      "|    total_timesteps      | 3063808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008504238 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 245         |\n",
      "|    n_updates            | 30860       |\n",
      "|    policy_gradient_loss | 0.00345     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 3.28e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3065000, episode_reward=72402.80 +/- 2399.15\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 7.24e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3065000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04044584 |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.31       |\n",
      "|    explained_variance   | 0.9        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 124        |\n",
      "|    n_updates            | 30870      |\n",
      "|    policy_gradient_loss | 0.0342     |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 859        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -8.15e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 527       |\n",
      "|    iterations      | 1497      |\n",
      "|    time_elapsed    | 5816      |\n",
      "|    total_timesteps | 3065856   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.69e+03    |\n",
      "|    ep_rew_mean          | -8.15e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 527         |\n",
      "|    iterations           | 1498        |\n",
      "|    time_elapsed         | 5818        |\n",
      "|    total_timesteps      | 3067904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013288222 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 686         |\n",
      "|    n_updates            | 30880       |\n",
      "|    policy_gradient_loss | 0.0107      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 2.65e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.73e+03   |\n",
      "|    ep_rew_mean          | -7.73e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 527        |\n",
      "|    iterations           | 1499       |\n",
      "|    time_elapsed         | 5819       |\n",
      "|    total_timesteps      | 3069952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01412506 |\n",
      "|    clip_fraction        | 0.302      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.3        |\n",
      "|    explained_variance   | 0.99       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 111        |\n",
      "|    n_updates            | 30890      |\n",
      "|    policy_gradient_loss | 0.00944    |\n",
      "|    std                  | 0.161      |\n",
      "|    value_loss           | 404        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3070000, episode_reward=72528.26 +/- 3601.42\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.25e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025838464 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 30900       |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 3.22e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -7.73e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 526       |\n",
      "|    iterations      | 1500      |\n",
      "|    time_elapsed    | 5833      |\n",
      "|    total_timesteps | 3072000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | -7.73e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1501        |\n",
      "|    time_elapsed         | 5835        |\n",
      "|    total_timesteps      | 3074048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037394688 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 30910       |\n",
      "|    policy_gradient_loss | 0.00676     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 409         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3075000, episode_reward=71015.54 +/- 3791.24\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3075000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021999417 |\n",
      "|    clip_fraction        | 0.578       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51          |\n",
      "|    n_updates            | 30920       |\n",
      "|    policy_gradient_loss | 0.139       |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 455         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.77e+03  |\n",
      "|    ep_rew_mean     | -7.15e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 525       |\n",
      "|    iterations      | 1502      |\n",
      "|    time_elapsed    | 5848      |\n",
      "|    total_timesteps | 3076096   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | -7.15e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 526         |\n",
      "|    iterations           | 1503        |\n",
      "|    time_elapsed         | 5850        |\n",
      "|    total_timesteps      | 3078144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010228746 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.8        |\n",
      "|    n_updates            | 30930       |\n",
      "|    policy_gradient_loss | 0.00326     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 389         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3080000, episode_reward=50902.59 +/- 4016.34\n",
      "Episode length: 4043.80 +/- 10.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.04e+03    |\n",
      "|    mean_reward          | 5.09e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011723805 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 30940       |\n",
      "|    policy_gradient_loss | 0.00969     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 185         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.81e+03  |\n",
      "|    ep_rew_mean     | -7.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 525       |\n",
      "|    iterations      | 1504      |\n",
      "|    time_elapsed    | 5862      |\n",
      "|    total_timesteps | 3080192   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | -7.41e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1505        |\n",
      "|    time_elapsed         | 5864        |\n",
      "|    total_timesteps      | 3082240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012763968 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.29        |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 537         |\n",
      "|    n_updates            | 30950       |\n",
      "|    policy_gradient_loss | 0.00251     |\n",
      "|    std                  | 0.161       |\n",
      "|    value_loss           | 8.4e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.83e+03   |\n",
      "|    ep_rew_mean          | -7.23e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 525        |\n",
      "|    iterations           | 1506       |\n",
      "|    time_elapsed         | 5866       |\n",
      "|    total_timesteps      | 3084288    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01659001 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.29       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 323        |\n",
      "|    n_updates            | 30960      |\n",
      "|    policy_gradient_loss | -0.0021    |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 1.58e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3085000, episode_reward=31882.95 +/- 2757.08\n",
      "Episode length: 3026.60 +/- 11.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.03e+03    |\n",
      "|    mean_reward          | 3.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3085000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008147677 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 358         |\n",
      "|    n_updates            | 30970       |\n",
      "|    policy_gradient_loss | -0.000252   |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 1.99e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.86e+03  |\n",
      "|    ep_rew_mean     | -7.02e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 525       |\n",
      "|    iterations      | 1507      |\n",
      "|    time_elapsed    | 5875      |\n",
      "|    total_timesteps | 3086336   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.88e+03    |\n",
      "|    ep_rew_mean          | -6.18e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1508        |\n",
      "|    time_elapsed         | 5876        |\n",
      "|    total_timesteps      | 3088384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009289808 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 277         |\n",
      "|    n_updates            | 30980       |\n",
      "|    policy_gradient_loss | 0.00104     |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 2.91e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3090000, episode_reward=47259.98 +/- 4628.97\n",
      "Episode length: 4116.40 +/- 5.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.12e+03    |\n",
      "|    mean_reward          | 4.73e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006805511 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 850         |\n",
      "|    n_updates            | 30990       |\n",
      "|    policy_gradient_loss | 0.00372     |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 3.01e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.84e+03  |\n",
      "|    ep_rew_mean     | -7.46e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 524       |\n",
      "|    iterations      | 1509      |\n",
      "|    time_elapsed    | 5888      |\n",
      "|    total_timesteps | 3090432   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.85e+03    |\n",
      "|    ep_rew_mean          | -8.42e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 1510        |\n",
      "|    time_elapsed         | 5890        |\n",
      "|    total_timesteps      | 3092480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010782361 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.356       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.21e+07    |\n",
      "|    n_updates            | 31000       |\n",
      "|    policy_gradient_loss | 0.00243     |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 1.23e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.82e+03    |\n",
      "|    ep_rew_mean          | -1.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 525         |\n",
      "|    iterations           | 1511        |\n",
      "|    time_elapsed         | 5892        |\n",
      "|    total_timesteps      | 3094528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008017499 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+07    |\n",
      "|    n_updates            | 31010       |\n",
      "|    policy_gradient_loss | 0.00244     |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 1.41e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3095000, episode_reward=36061.95 +/- 6038.69\n",
      "Episode length: 4134.20 +/- 10.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.13e+03    |\n",
      "|    mean_reward          | 3.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3095000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002137233 |\n",
      "|    clip_fraction        | 0.0108      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.95e+06    |\n",
      "|    n_updates            | 31020       |\n",
      "|    policy_gradient_loss | -0.00504    |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 3.33e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.82e+03  |\n",
      "|    ep_rew_mean     | -9.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 524       |\n",
      "|    iterations      | 1512      |\n",
      "|    time_elapsed    | 5903      |\n",
      "|    total_timesteps | 3096576   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.82e+03   |\n",
      "|    ep_rew_mean          | -9.61e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 524        |\n",
      "|    iterations           | 1513       |\n",
      "|    time_elapsed         | 5905       |\n",
      "|    total_timesteps      | 3098624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02527878 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.3        |\n",
      "|    explained_variance   | 0.969      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.81e+03   |\n",
      "|    n_updates            | 31030      |\n",
      "|    policy_gradient_loss | 0.00463    |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 3.11e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3100000, episode_reward=64356.78 +/- 2211.98\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 6.44e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3100000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01354953 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.3        |\n",
      "|    explained_variance   | 0.864      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 938        |\n",
      "|    n_updates            | 31040      |\n",
      "|    policy_gradient_loss | -0.00405   |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 2.9e+03    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.83e+03  |\n",
      "|    ep_rew_mean     | -9.54e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 523       |\n",
      "|    iterations      | 1514      |\n",
      "|    time_elapsed    | 5919      |\n",
      "|    total_timesteps | 3100672   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.82e+03    |\n",
      "|    ep_rew_mean          | -1.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 524         |\n",
      "|    iterations           | 1515        |\n",
      "|    time_elapsed         | 5921        |\n",
      "|    total_timesteps      | 3102720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044858888 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 134         |\n",
      "|    n_updates            | 31050       |\n",
      "|    policy_gradient_loss | 0.0213      |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 2.02e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.85e+03  |\n",
      "|    ep_rew_mean          | -8.73e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 524       |\n",
      "|    iterations           | 1516      |\n",
      "|    time_elapsed         | 5922      |\n",
      "|    total_timesteps      | 3104768   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.1222736 |\n",
      "|    clip_fraction        | 0.583     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.31      |\n",
      "|    explained_variance   | 0.401     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.97e+06  |\n",
      "|    n_updates            | 31060     |\n",
      "|    policy_gradient_loss | 0.0521    |\n",
      "|    std                  | 0.16      |\n",
      "|    value_loss           | 1.4e+07   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3105000, episode_reward=51918.27 +/- 2968.06\n",
      "Episode length: 4394.20 +/- 7.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.39e+03    |\n",
      "|    mean_reward          | 5.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3105000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010701792 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 158         |\n",
      "|    n_updates            | 31070       |\n",
      "|    policy_gradient_loss | 0.00187     |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 1.27e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.85e+03  |\n",
      "|    ep_rew_mean     | -8.73e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 523       |\n",
      "|    iterations      | 1517      |\n",
      "|    time_elapsed    | 5935      |\n",
      "|    total_timesteps | 3106816   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.86e+03    |\n",
      "|    ep_rew_mean          | -9.48e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 523         |\n",
      "|    iterations           | 1518        |\n",
      "|    time_elapsed         | 5937        |\n",
      "|    total_timesteps      | 3108864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018759014 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 277         |\n",
      "|    n_updates            | 31080       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 617         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3110000, episode_reward=67852.38 +/- 3863.43\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 6.79e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3110000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052409805 |\n",
      "|    clip_fraction        | 0.048        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.31         |\n",
      "|    explained_variance   | 0.331        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.87e+03     |\n",
      "|    n_updates            | 31090        |\n",
      "|    policy_gradient_loss | -0.00536     |\n",
      "|    std                  | 0.16         |\n",
      "|    value_loss           | 8.73e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.86e+03  |\n",
      "|    ep_rew_mean     | -9.48e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 522       |\n",
      "|    iterations      | 1519      |\n",
      "|    time_elapsed    | 5950      |\n",
      "|    total_timesteps | 3110912   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.87e+03    |\n",
      "|    ep_rew_mean          | -8.45e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 1520        |\n",
      "|    time_elapsed         | 5952        |\n",
      "|    total_timesteps      | 3112960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008581487 |\n",
      "|    clip_fraction        | 0.0387      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.19e+03    |\n",
      "|    n_updates            | 31100       |\n",
      "|    policy_gradient_loss | -0.00361    |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 4.68e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3115000, episode_reward=38393.60 +/- 4595.19\n",
      "Episode length: 3567.80 +/- 13.66\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.57e+03    |\n",
      "|    mean_reward          | 3.84e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3115000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008761622 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 31110       |\n",
      "|    policy_gradient_loss | -0.00675    |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 3.12e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -8.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 522       |\n",
      "|    iterations      | 1521      |\n",
      "|    time_elapsed    | 5962      |\n",
      "|    total_timesteps | 3115008   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.88e+03    |\n",
      "|    ep_rew_mean          | -8.41e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 1522        |\n",
      "|    time_elapsed         | 5964        |\n",
      "|    total_timesteps      | 3117056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011306774 |\n",
      "|    clip_fraction        | 0.0987      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 256         |\n",
      "|    n_updates            | 31120       |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 2.31e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.88e+03  |\n",
      "|    ep_rew_mean          | -8.41e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 522       |\n",
      "|    iterations           | 1523      |\n",
      "|    time_elapsed         | 5966      |\n",
      "|    total_timesteps      | 3119104   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0655556 |\n",
      "|    clip_fraction        | 0.252     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.31      |\n",
      "|    explained_variance   | 0.962     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 184       |\n",
      "|    n_updates            | 31130     |\n",
      "|    policy_gradient_loss | 0.00886   |\n",
      "|    std                  | 0.16      |\n",
      "|    value_loss           | 553       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3120000, episode_reward=68552.38 +/- 848.06\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.86e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008814322 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.715       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.16e+03    |\n",
      "|    n_updates            | 31140       |\n",
      "|    policy_gradient_loss | -0.00496    |\n",
      "|    std                  | 0.16        |\n",
      "|    value_loss           | 4.81e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -7.83e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 1524      |\n",
      "|    time_elapsed    | 5980      |\n",
      "|    total_timesteps | 3121152   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.93e+03    |\n",
      "|    ep_rew_mean          | -7.83e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 522         |\n",
      "|    iterations           | 1525        |\n",
      "|    time_elapsed         | 5982        |\n",
      "|    total_timesteps      | 3123200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019197019 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 31150       |\n",
      "|    policy_gradient_loss | 0.00521     |\n",
      "|    std                  | 0.159       |\n",
      "|    value_loss           | 759         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3125000, episode_reward=59518.11 +/- 3100.06\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 5.95e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3125000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03131254 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.31       |\n",
      "|    explained_variance   | 0.917      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 150        |\n",
      "|    n_updates            | 31160      |\n",
      "|    policy_gradient_loss | 0.00451    |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 836        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.95e+03  |\n",
      "|    ep_rew_mean     | -7.62e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 1526      |\n",
      "|    time_elapsed    | 5996      |\n",
      "|    total_timesteps | 3125248   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | -7.62e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1527        |\n",
      "|    time_elapsed         | 5997        |\n",
      "|    total_timesteps      | 3127296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009743279 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+03    |\n",
      "|    n_updates            | 31170       |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    std                  | 0.159       |\n",
      "|    value_loss           | 4.6e+03     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.98e+03     |\n",
      "|    ep_rew_mean          | -7.38e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 1528         |\n",
      "|    time_elapsed         | 5999         |\n",
      "|    total_timesteps      | 3129344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104953125 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.32         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 113          |\n",
      "|    n_updates            | 31180        |\n",
      "|    policy_gradient_loss | 0.00159      |\n",
      "|    std                  | 0.159        |\n",
      "|    value_loss           | 503          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3130000, episode_reward=-3554.70 +/- 91826.12\n",
      "Episode length: 4023.20 +/- 1953.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.02e+03    |\n",
      "|    mean_reward          | -3.55e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014641419 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 143         |\n",
      "|    n_updates            | 31190       |\n",
      "|    policy_gradient_loss | 0.0158      |\n",
      "|    std                  | 0.159       |\n",
      "|    value_loss           | 2.1e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.98e+03  |\n",
      "|    ep_rew_mean     | -7.38e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1529      |\n",
      "|    time_elapsed    | 6011      |\n",
      "|    total_timesteps | 3131392   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -6.58e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1530        |\n",
      "|    time_elapsed         | 6013        |\n",
      "|    total_timesteps      | 3133440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017131764 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 366         |\n",
      "|    n_updates            | 31200       |\n",
      "|    policy_gradient_loss | -0.00446    |\n",
      "|    std                  | 0.159       |\n",
      "|    value_loss           | 701         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3135000, episode_reward=46856.79 +/- 2924.66\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 4.69e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3135000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022091389 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 189         |\n",
      "|    n_updates            | 31210       |\n",
      "|    policy_gradient_loss | 0.00929     |\n",
      "|    std                  | 0.159       |\n",
      "|    value_loss           | 1.35e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.02e+03  |\n",
      "|    ep_rew_mean     | -4.46e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1531      |\n",
      "|    time_elapsed    | 6026      |\n",
      "|    total_timesteps | 3135488   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -4.66e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1532        |\n",
      "|    time_elapsed         | 6028        |\n",
      "|    total_timesteps      | 3137536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018047946 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.2        |\n",
      "|    n_updates            | 31220       |\n",
      "|    policy_gradient_loss | 0.00877     |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 264         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | -6.94e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1533        |\n",
      "|    time_elapsed         | 6030        |\n",
      "|    total_timesteps      | 3139584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026997868 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.2        |\n",
      "|    n_updates            | 31230       |\n",
      "|    policy_gradient_loss | 0.00427     |\n",
      "|    std                  | 0.159       |\n",
      "|    value_loss           | 644         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3140000, episode_reward=16718.40 +/- 3559.04\n",
      "Episode length: 3118.40 +/- 11.71\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.12e+03   |\n",
      "|    mean_reward          | 1.67e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3140000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.37886924 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.399      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.04e+07   |\n",
      "|    n_updates            | 31240      |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    std                  | 0.159      |\n",
      "|    value_loss           | 3.06e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.02e+03  |\n",
      "|    ep_rew_mean     | -6.89e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1534      |\n",
      "|    time_elapsed    | 6039      |\n",
      "|    total_timesteps | 3141632   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -6.89e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1535        |\n",
      "|    time_elapsed         | 6041        |\n",
      "|    total_timesteps      | 3143680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014833197 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 31250       |\n",
      "|    policy_gradient_loss | 0.00272     |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 257         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3145000, episode_reward=-28417.08 +/- 77422.97\n",
      "Episode length: 2053.20 +/- 968.26\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.05e+03   |\n",
      "|    mean_reward          | -2.84e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3145000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02105974 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.35       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 20.5       |\n",
      "|    n_updates            | 31260      |\n",
      "|    policy_gradient_loss | 0.0252     |\n",
      "|    std                  | 0.158      |\n",
      "|    value_loss           | 224        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.02e+03  |\n",
      "|    ep_rew_mean     | -7.07e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1536      |\n",
      "|    time_elapsed    | 6048      |\n",
      "|    total_timesteps | 3145728   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.03e+03    |\n",
      "|    ep_rew_mean          | -7.28e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1537        |\n",
      "|    time_elapsed         | 6050        |\n",
      "|    total_timesteps      | 3147776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030193351 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.85e+05    |\n",
      "|    n_updates            | 31270       |\n",
      "|    policy_gradient_loss | 0.000797    |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 1.66e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.02e+03    |\n",
      "|    ep_rew_mean          | -9.91e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1538        |\n",
      "|    time_elapsed         | 6052        |\n",
      "|    total_timesteps      | 3149824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008027875 |\n",
      "|    clip_fraction        | 0.0815      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 179         |\n",
      "|    n_updates            | 31280       |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 727         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3150000, episode_reward=14599.51 +/- 5621.01\n",
      "Episode length: 2998.60 +/- 315.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3e+03       |\n",
      "|    mean_reward          | 1.46e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002074808 |\n",
      "|    clip_fraction        | 0.0413      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.31e+07    |\n",
      "|    n_updates            | 31290       |\n",
      "|    policy_gradient_loss | -0.00152    |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 3.96e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.03e+03  |\n",
      "|    ep_rew_mean     | -1.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1539      |\n",
      "|    time_elapsed    | 6061      |\n",
      "|    total_timesteps | 3151872   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.04e+03     |\n",
      "|    ep_rew_mean          | -1.06e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 520          |\n",
      "|    iterations           | 1540         |\n",
      "|    time_elapsed         | 6063         |\n",
      "|    total_timesteps      | 3153920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012575799 |\n",
      "|    clip_fraction        | 0.00381      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.377        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.3e+07      |\n",
      "|    n_updates            | 31300        |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    std                  | 0.158        |\n",
      "|    value_loss           | 3.03e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3155000, episode_reward=-314920.96 +/- 172343.15\n",
      "Episode length: 2499.00 +/- 133.85\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.5e+03      |\n",
      "|    mean_reward          | -3.15e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3155000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029575052 |\n",
      "|    clip_fraction        | 0.00937      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.774        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.45e+04     |\n",
      "|    n_updates            | 31310        |\n",
      "|    policy_gradient_loss | -0.00308     |\n",
      "|    std                  | 0.158        |\n",
      "|    value_loss           | 1.48e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.04e+03  |\n",
      "|    ep_rew_mean     | -1.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 519       |\n",
      "|    iterations      | 1541      |\n",
      "|    time_elapsed    | 6070      |\n",
      "|    total_timesteps | 3155968   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.04e+03    |\n",
      "|    ep_rew_mean          | -9.75e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1542        |\n",
      "|    time_elapsed         | 6072        |\n",
      "|    total_timesteps      | 3158016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010096192 |\n",
      "|    clip_fraction        | 0.0859      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.24e+03    |\n",
      "|    n_updates            | 31320       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 1.91e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3160000, episode_reward=4137.62 +/- 4019.78\n",
      "Episode length: 2032.20 +/- 19.61\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.03e+03     |\n",
      "|    mean_reward          | 4.14e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057324907 |\n",
      "|    clip_fraction        | 0.0371       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.36         |\n",
      "|    explained_variance   | 0.929        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.51e+03     |\n",
      "|    n_updates            | 31330        |\n",
      "|    policy_gradient_loss | -0.00478     |\n",
      "|    std                  | 0.158        |\n",
      "|    value_loss           | 4.74e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.05e+03  |\n",
      "|    ep_rew_mean     | -7.85e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 519       |\n",
      "|    iterations      | 1543      |\n",
      "|    time_elapsed    | 6079      |\n",
      "|    total_timesteps | 3160064   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.06e+03  |\n",
      "|    ep_rew_mean          | -7.13e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 519       |\n",
      "|    iterations           | 1544      |\n",
      "|    time_elapsed         | 6081      |\n",
      "|    total_timesteps      | 3162112   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.935257  |\n",
      "|    clip_fraction        | 0.539     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.35      |\n",
      "|    explained_variance   | 0.934     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 75.5      |\n",
      "|    n_updates            | 31340     |\n",
      "|    policy_gradient_loss | 0.0982    |\n",
      "|    std                  | 0.159     |\n",
      "|    value_loss           | 3.01e+04  |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.04e+03  |\n",
      "|    ep_rew_mean          | -7.37e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 520       |\n",
      "|    iterations           | 1545      |\n",
      "|    time_elapsed         | 6083      |\n",
      "|    total_timesteps      | 3164160   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.1738994 |\n",
      "|    clip_fraction        | 0.349     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.34      |\n",
      "|    explained_variance   | 0.863     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 543       |\n",
      "|    n_updates            | 31350     |\n",
      "|    policy_gradient_loss | 0.0121    |\n",
      "|    std                  | 0.159     |\n",
      "|    value_loss           | 6.12e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3165000, episode_reward=8219.43 +/- 3090.99\n",
      "Episode length: 1047.40 +/- 8.73\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.05e+03   |\n",
      "|    mean_reward          | 8.22e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3165000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06702315 |\n",
      "|    clip_fraction        | 0.287      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.955      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 56.4       |\n",
      "|    n_updates            | 31360      |\n",
      "|    policy_gradient_loss | 0.0166     |\n",
      "|    std                  | 0.16       |\n",
      "|    value_loss           | 2.13e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.04e+03  |\n",
      "|    ep_rew_mean     | -6.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1546      |\n",
      "|    time_elapsed    | 6087      |\n",
      "|    total_timesteps | 3166208   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.03e+03    |\n",
      "|    ep_rew_mean          | -6.57e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1547        |\n",
      "|    time_elapsed         | 6089        |\n",
      "|    total_timesteps      | 3168256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039245695 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.9        |\n",
      "|    n_updates            | 31370       |\n",
      "|    policy_gradient_loss | 0.0211      |\n",
      "|    std                  | 0.159       |\n",
      "|    value_loss           | 3.05e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3170000, episode_reward=5653.07 +/- 4041.23\n",
      "Episode length: 1028.80 +/- 3.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.03e+03    |\n",
      "|    mean_reward          | 5.65e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019591589 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 31380       |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 3.05e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2e+03     |\n",
      "|    ep_rew_mean     | -6.95e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1548      |\n",
      "|    time_elapsed    | 6093      |\n",
      "|    total_timesteps | 3170304   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.99e+03    |\n",
      "|    ep_rew_mean          | -7.15e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1549        |\n",
      "|    time_elapsed         | 6095        |\n",
      "|    total_timesteps      | 3172352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012469309 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.1        |\n",
      "|    n_updates            | 31390       |\n",
      "|    policy_gradient_loss | 0.0104      |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 213         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.98e+03    |\n",
      "|    ep_rew_mean          | -7.37e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1550        |\n",
      "|    time_elapsed         | 6097        |\n",
      "|    total_timesteps      | 3174400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.066989526 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 105         |\n",
      "|    n_updates            | 31400       |\n",
      "|    policy_gradient_loss | 0.0209      |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 2.97e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3175000, episode_reward=6557.94 +/- 5211.93\n",
      "Episode length: 1097.20 +/- 8.30\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.1e+03    |\n",
      "|    mean_reward          | 6.56e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3175000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12632826 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.363      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.7e+07    |\n",
      "|    n_updates            | 31410      |\n",
      "|    policy_gradient_loss | -0.00642   |\n",
      "|    std                  | 0.156      |\n",
      "|    value_loss           | 1.79e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.96e+03  |\n",
      "|    ep_rew_mean     | -9.51e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1551      |\n",
      "|    time_elapsed    | 6101      |\n",
      "|    total_timesteps | 3176448   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.94e+03   |\n",
      "|    ep_rew_mean          | -1.02e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 520        |\n",
      "|    iterations           | 1552       |\n",
      "|    time_elapsed         | 6103       |\n",
      "|    total_timesteps      | 3178496    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.23814082 |\n",
      "|    clip_fraction        | 0.327      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.497      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.92e+05   |\n",
      "|    n_updates            | 31420      |\n",
      "|    policy_gradient_loss | 0.000608   |\n",
      "|    std                  | 0.156      |\n",
      "|    value_loss           | 6.43e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3180000, episode_reward=-37001.11 +/- 83298.66\n",
      "Episode length: 896.20 +/- 385.11\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 896        |\n",
      "|    mean_reward          | -3.7e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3180000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.26821294 |\n",
      "|    clip_fraction        | 0.119      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.39       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.42e+07   |\n",
      "|    n_updates            | 31430      |\n",
      "|    policy_gradient_loss | 0.00384    |\n",
      "|    std                  | 0.157      |\n",
      "|    value_loss           | 4.09e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -1.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1553      |\n",
      "|    time_elapsed    | 6107      |\n",
      "|    total_timesteps | 3180544   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.93e+03  |\n",
      "|    ep_rew_mean          | -9.65e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 520       |\n",
      "|    iterations           | 1554      |\n",
      "|    time_elapsed         | 6109      |\n",
      "|    total_timesteps      | 3182592   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0805506 |\n",
      "|    clip_fraction        | 0.302     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.32      |\n",
      "|    explained_variance   | 0.971     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 45.2      |\n",
      "|    n_updates            | 31440     |\n",
      "|    policy_gradient_loss | 0.00981   |\n",
      "|    std                  | 0.158     |\n",
      "|    value_loss           | 2.1e+04   |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.91e+03    |\n",
      "|    ep_rew_mean          | -9.78e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1555        |\n",
      "|    time_elapsed         | 6111        |\n",
      "|    total_timesteps      | 3184640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028442603 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.8        |\n",
      "|    n_updates            | 31450       |\n",
      "|    policy_gradient_loss | 0.00549     |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 3.11e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3185000, episode_reward=9362.78 +/- 3781.37\n",
      "Episode length: 1201.20 +/- 10.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.2e+03     |\n",
      "|    mean_reward          | 9.36e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3185000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019052684 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.3         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 52.7        |\n",
      "|    n_updates            | 31460       |\n",
      "|    policy_gradient_loss | -0.000873   |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.91e+03  |\n",
      "|    ep_rew_mean     | -8.67e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 1556      |\n",
      "|    time_elapsed    | 6116      |\n",
      "|    total_timesteps | 3186688   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.89e+03    |\n",
      "|    ep_rew_mean          | -8.54e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1557        |\n",
      "|    time_elapsed         | 6118        |\n",
      "|    total_timesteps      | 3188736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016971726 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 31470       |\n",
      "|    policy_gradient_loss | 0.00648     |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 188         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3190000, episode_reward=9990.90 +/- 6840.68\n",
      "Episode length: 1284.20 +/- 11.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.28e+03    |\n",
      "|    mean_reward          | 9.99e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020570124 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.2        |\n",
      "|    n_updates            | 31480       |\n",
      "|    policy_gradient_loss | 0.00622     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 147         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -6.77e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 1558      |\n",
      "|    time_elapsed    | 6123      |\n",
      "|    total_timesteps | 3190784   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.87e+03    |\n",
      "|    ep_rew_mean          | -7.11e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1559        |\n",
      "|    time_elapsed         | 6124        |\n",
      "|    total_timesteps      | 3192832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010457923 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 115         |\n",
      "|    n_updates            | 31490       |\n",
      "|    policy_gradient_loss | 0.00103     |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 1.96e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.86e+03    |\n",
      "|    ep_rew_mean          | -7.22e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1560        |\n",
      "|    time_elapsed         | 6126        |\n",
      "|    total_timesteps      | 3194880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039554894 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71.7        |\n",
      "|    n_updates            | 31500       |\n",
      "|    policy_gradient_loss | 0.0077      |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 198         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3195000, episode_reward=25075.64 +/- 114.05\n",
      "Episode length: 2128.60 +/- 5.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.13e+03    |\n",
      "|    mean_reward          | 2.51e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3195000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010846772 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 31510       |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.86e+03  |\n",
      "|    ep_rew_mean     | -7.92e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 1561      |\n",
      "|    time_elapsed    | 6133      |\n",
      "|    total_timesteps | 3196928   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.87e+03     |\n",
      "|    ep_rew_mean          | -7.14e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 1562         |\n",
      "|    time_elapsed         | 6135         |\n",
      "|    total_timesteps      | 3198976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004929614 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.283        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.61e+06     |\n",
      "|    n_updates            | 31520        |\n",
      "|    policy_gradient_loss | -0.000917    |\n",
      "|    std                  | 0.157        |\n",
      "|    value_loss           | 2.01e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3200000, episode_reward=21265.71 +/- 5029.07\n",
      "Episode length: 2174.40 +/- 14.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.17e+03     |\n",
      "|    mean_reward          | 2.13e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042826873 |\n",
      "|    clip_fraction        | 0.0133       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.727        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 31530        |\n",
      "|    policy_gradient_loss | -0.00349     |\n",
      "|    std                  | 0.157        |\n",
      "|    value_loss           | 5.46e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.86e+03  |\n",
      "|    ep_rew_mean     | -7.24e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 521       |\n",
      "|    iterations      | 1563      |\n",
      "|    time_elapsed    | 6142      |\n",
      "|    total_timesteps | 3201024   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.86e+03     |\n",
      "|    ep_rew_mean          | -7.21e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 521          |\n",
      "|    iterations           | 1564         |\n",
      "|    time_elapsed         | 6144         |\n",
      "|    total_timesteps      | 3203072      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0118641155 |\n",
      "|    clip_fraction        | 0.105        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.959        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 369          |\n",
      "|    n_updates            | 31540        |\n",
      "|    policy_gradient_loss | -0.00892     |\n",
      "|    std                  | 0.157        |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3205000, episode_reward=-88559.43 +/- 4723.21\n",
      "Episode length: 4031.40 +/- 59.72\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.03e+03   |\n",
      "|    mean_reward          | -8.86e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3205000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02075633 |\n",
      "|    clip_fraction        | 0.155      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.863      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 408        |\n",
      "|    n_updates            | 31550      |\n",
      "|    policy_gradient_loss | -0.00138   |\n",
      "|    std                  | 0.157      |\n",
      "|    value_loss           | 3.1e+04    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.85e+03  |\n",
      "|    ep_rew_mean     | -7.03e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1565      |\n",
      "|    time_elapsed    | 6155      |\n",
      "|    total_timesteps | 3205120   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.85e+03   |\n",
      "|    ep_rew_mean          | -7.05e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 520        |\n",
      "|    iterations           | 1566       |\n",
      "|    time_elapsed         | 6157       |\n",
      "|    total_timesteps      | 3207168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02656443 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.34       |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 165        |\n",
      "|    n_updates            | 31560      |\n",
      "|    policy_gradient_loss | 0.00685    |\n",
      "|    std                  | 0.157      |\n",
      "|    value_loss           | 1.05e+03   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.86e+03    |\n",
      "|    ep_rew_mean          | -6.89e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 521         |\n",
      "|    iterations           | 1567        |\n",
      "|    time_elapsed         | 6159        |\n",
      "|    total_timesteps      | 3209216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015027837 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 31570       |\n",
      "|    policy_gradient_loss | 0.00453     |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 496         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3210000, episode_reward=42328.84 +/- 3026.84\n",
      "Episode length: 3293.40 +/- 357.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.29e+03    |\n",
      "|    mean_reward          | 4.23e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033487886 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.1e+05     |\n",
      "|    n_updates            | 31580       |\n",
      "|    policy_gradient_loss | 0.00322     |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 2.96e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.87e+03  |\n",
      "|    ep_rew_mean     | -6.76e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1568      |\n",
      "|    time_elapsed    | 6169      |\n",
      "|    total_timesteps | 3211264   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.87e+03    |\n",
      "|    ep_rew_mean          | -6.76e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1569        |\n",
      "|    time_elapsed         | 6171        |\n",
      "|    total_timesteps      | 3213312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024211314 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.33e+05    |\n",
      "|    n_updates            | 31590       |\n",
      "|    policy_gradient_loss | 0.00579     |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 3.39e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3215000, episode_reward=42442.93 +/- 5545.64\n",
      "Episode length: 3199.40 +/- 51.46\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.2e+03      |\n",
      "|    mean_reward          | 4.24e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3215000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034801702 |\n",
      "|    clip_fraction        | 0.0461       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.34         |\n",
      "|    explained_variance   | 0.754        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 583          |\n",
      "|    n_updates            | 31600        |\n",
      "|    policy_gradient_loss | 0.000752     |\n",
      "|    std                  | 0.157        |\n",
      "|    value_loss           | 6.58e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.89e+03  |\n",
      "|    ep_rew_mean     | -6.62e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 520       |\n",
      "|    iterations      | 1570      |\n",
      "|    time_elapsed    | 6180      |\n",
      "|    total_timesteps | 3215360   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.9e+03     |\n",
      "|    ep_rew_mean          | -6.38e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1571        |\n",
      "|    time_elapsed         | 6182        |\n",
      "|    total_timesteps      | 3217408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012558787 |\n",
      "|    clip_fraction        | 0.0692      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 216         |\n",
      "|    n_updates            | 31610       |\n",
      "|    policy_gradient_loss | -0.000498   |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 1.55e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.92e+03    |\n",
      "|    ep_rew_mean          | -5.37e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 520         |\n",
      "|    iterations           | 1572        |\n",
      "|    time_elapsed         | 6184        |\n",
      "|    total_timesteps      | 3219456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010933537 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.43e+05    |\n",
      "|    n_updates            | 31620       |\n",
      "|    policy_gradient_loss | 0.00352     |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 3.41e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3220000, episode_reward=78943.35 +/- 4967.80\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.89e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013143208 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 31630       |\n",
      "|    policy_gradient_loss | 0.00166     |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 716         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.92e+03  |\n",
      "|    ep_rew_mean     | -5.37e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 519       |\n",
      "|    iterations      | 1573      |\n",
      "|    time_elapsed    | 6197      |\n",
      "|    total_timesteps | 3221504   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.92e+03   |\n",
      "|    ep_rew_mean          | -5.37e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 519        |\n",
      "|    iterations           | 1574       |\n",
      "|    time_elapsed         | 6199       |\n",
      "|    total_timesteps      | 3223552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06266949 |\n",
      "|    clip_fraction        | 0.274      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.33       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 46.3       |\n",
      "|    n_updates            | 31640      |\n",
      "|    policy_gradient_loss | 0.0137     |\n",
      "|    std                  | 0.157      |\n",
      "|    value_loss           | 165        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3225000, episode_reward=83667.70 +/- 4648.13\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.37e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3225000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009505261 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 390         |\n",
      "|    n_updates            | 31650       |\n",
      "|    policy_gradient_loss | 0.00162     |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.94e+03  |\n",
      "|    ep_rew_mean     | -4.94e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 519       |\n",
      "|    iterations      | 1575      |\n",
      "|    time_elapsed    | 6213      |\n",
      "|    total_timesteps | 3225600   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.94e+03    |\n",
      "|    ep_rew_mean          | -4.94e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 519         |\n",
      "|    iterations           | 1576        |\n",
      "|    time_elapsed         | 6215        |\n",
      "|    total_timesteps      | 3227648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005772209 |\n",
      "|    clip_fraction        | 0.0801      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 544         |\n",
      "|    n_updates            | 31660       |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 4.51e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.98e+03   |\n",
      "|    ep_rew_mean          | -3.39e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 519        |\n",
      "|    iterations           | 1577       |\n",
      "|    time_elapsed         | 6216       |\n",
      "|    total_timesteps      | 3229696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03491334 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.32       |\n",
      "|    explained_variance   | 0.812      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 29.6       |\n",
      "|    n_updates            | 31670      |\n",
      "|    policy_gradient_loss | 0.0354     |\n",
      "|    std                  | 0.157      |\n",
      "|    value_loss           | 169        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3230000, episode_reward=84112.46 +/- 4366.12\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 8.41e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3230000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035801614 |\n",
      "|    clip_fraction        | 0.132        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.33         |\n",
      "|    explained_variance   | 0.859        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 529          |\n",
      "|    n_updates            | 31680        |\n",
      "|    policy_gradient_loss | 0.00381      |\n",
      "|    std                  | 0.157        |\n",
      "|    value_loss           | 6.18e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.98e+03  |\n",
      "|    ep_rew_mean     | -3.39e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 518       |\n",
      "|    iterations      | 1578      |\n",
      "|    time_elapsed    | 6230      |\n",
      "|    total_timesteps | 3231744   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.98e+03    |\n",
      "|    ep_rew_mean          | -3.39e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1579        |\n",
      "|    time_elapsed         | 6232        |\n",
      "|    total_timesteps      | 3233792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059885383 |\n",
      "|    clip_fraction        | 0.416       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.9        |\n",
      "|    n_updates            | 31690       |\n",
      "|    policy_gradient_loss | 0.0337      |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 77.5        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3235000, episode_reward=82854.33 +/- 3971.54\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.29e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3235000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021836549 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.4        |\n",
      "|    n_updates            | 31700       |\n",
      "|    policy_gradient_loss | 0.00769     |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 309         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.01e+03  |\n",
      "|    ep_rew_mean     | -2.77e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 518       |\n",
      "|    iterations      | 1580      |\n",
      "|    time_elapsed    | 6245      |\n",
      "|    total_timesteps | 3235840   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.01e+03    |\n",
      "|    ep_rew_mean          | -2.77e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1581        |\n",
      "|    time_elapsed         | 6247        |\n",
      "|    total_timesteps      | 3237888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025373379 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 31710       |\n",
      "|    policy_gradient_loss | -0.00143    |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 7.37e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.05e+03    |\n",
      "|    ep_rew_mean          | -2.19e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 518         |\n",
      "|    iterations           | 1582        |\n",
      "|    time_elapsed         | 6249        |\n",
      "|    total_timesteps      | 3239936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024212774 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 31720       |\n",
      "|    policy_gradient_loss | 0.0168      |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 152         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3240000, episode_reward=87082.99 +/- 3133.31\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3240000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030118607 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 31730       |\n",
      "|    policy_gradient_loss | 0.0201      |\n",
      "|    std                  | 0.158       |\n",
      "|    value_loss           | 6.69e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.05e+03  |\n",
      "|    ep_rew_mean     | -2.19e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 517       |\n",
      "|    iterations      | 1583      |\n",
      "|    time_elapsed    | 6263      |\n",
      "|    total_timesteps | 3241984   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.08e+03   |\n",
      "|    ep_rew_mean          | -813       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 517        |\n",
      "|    iterations           | 1584       |\n",
      "|    time_elapsed         | 6265       |\n",
      "|    total_timesteps      | 3244032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03257241 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.31       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14.7       |\n",
      "|    n_updates            | 31740      |\n",
      "|    policy_gradient_loss | 0.0112     |\n",
      "|    std                  | 0.158      |\n",
      "|    value_loss           | 67.5       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3245000, episode_reward=80585.23 +/- 3971.95\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 8.06e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3245000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010295857 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.31        |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.28e+05    |\n",
      "|    n_updates            | 31750       |\n",
      "|    policy_gradient_loss | -0.00121    |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 3.98e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.08e+03 |\n",
      "|    ep_rew_mean     | -813     |\n",
      "| time/              |          |\n",
      "|    fps             | 517      |\n",
      "|    iterations      | 1585     |\n",
      "|    time_elapsed    | 6278     |\n",
      "|    total_timesteps | 3246080  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.1e+03     |\n",
      "|    ep_rew_mean          | -178        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 517         |\n",
      "|    iterations           | 1586        |\n",
      "|    time_elapsed         | 6280        |\n",
      "|    total_timesteps      | 3248128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013303047 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 31760       |\n",
      "|    policy_gradient_loss | 0.00671     |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 58.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3250000, episode_reward=71367.58 +/- 2626.59\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.14e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008878391 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.53e+06    |\n",
      "|    n_updates            | 31770       |\n",
      "|    policy_gradient_loss | -8.33e-05   |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 4.62e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.12e+03 |\n",
      "|    ep_rew_mean     | 1.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 516      |\n",
      "|    iterations      | 1587     |\n",
      "|    time_elapsed    | 6294     |\n",
      "|    total_timesteps | 3250176  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | 1.15e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 1588        |\n",
      "|    time_elapsed         | 6295        |\n",
      "|    total_timesteps      | 3252224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023093328 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.32        |\n",
      "|    explained_variance   | 0.673       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.8        |\n",
      "|    n_updates            | 31780       |\n",
      "|    policy_gradient_loss | 0.00373     |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 3.27e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.14e+03    |\n",
      "|    ep_rew_mean          | 2.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 1589        |\n",
      "|    time_elapsed         | 6297        |\n",
      "|    total_timesteps      | 3254272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.059361365 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.33        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.1        |\n",
      "|    n_updates            | 31790       |\n",
      "|    policy_gradient_loss | 0.0102      |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 68.2        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3255000, episode_reward=72933.08 +/- 4019.04\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.29e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3255000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009090304 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.5        |\n",
      "|    n_updates            | 31800       |\n",
      "|    policy_gradient_loss | 0.000833    |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 3.4e+04     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.14e+03 |\n",
      "|    ep_rew_mean     | 2.09e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 515      |\n",
      "|    iterations      | 1590     |\n",
      "|    time_elapsed    | 6311     |\n",
      "|    total_timesteps | 3256320  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.17e+03    |\n",
      "|    ep_rew_mean          | 3.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 516         |\n",
      "|    iterations           | 1591        |\n",
      "|    time_elapsed         | 6313        |\n",
      "|    total_timesteps      | 3258368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008944998 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.7        |\n",
      "|    n_updates            | 31810       |\n",
      "|    policy_gradient_loss | 0.0189      |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 91.6        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3260000, episode_reward=79126.92 +/- 3799.84\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.91e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008128675 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.34        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.5        |\n",
      "|    n_updates            | 31820       |\n",
      "|    policy_gradient_loss | -0.00569    |\n",
      "|    std                  | 0.157       |\n",
      "|    value_loss           | 405         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.17e+03 |\n",
      "|    ep_rew_mean     | 3.29e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 515      |\n",
      "|    iterations      | 1592     |\n",
      "|    time_elapsed    | 6326     |\n",
      "|    total_timesteps | 3260416  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.19e+03     |\n",
      "|    ep_rew_mean          | 3.8e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 515          |\n",
      "|    iterations           | 1593         |\n",
      "|    time_elapsed         | 6328         |\n",
      "|    total_timesteps      | 3262464      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073203947 |\n",
      "|    clip_fraction        | 0.145        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 50           |\n",
      "|    n_updates            | 31830        |\n",
      "|    policy_gradient_loss | -0.00379     |\n",
      "|    std                  | 0.157        |\n",
      "|    value_loss           | 218          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.19e+03    |\n",
      "|    ep_rew_mean          | 3.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 515         |\n",
      "|    iterations           | 1594        |\n",
      "|    time_elapsed         | 6330        |\n",
      "|    total_timesteps      | 3264512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010453822 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.5        |\n",
      "|    n_updates            | 31840       |\n",
      "|    policy_gradient_loss | 0.00502     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 277         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3265000, episode_reward=72412.41 +/- 6572.81\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.24e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3265000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029680818 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.35        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98          |\n",
      "|    n_updates            | 31850       |\n",
      "|    policy_gradient_loss | 0.00376     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 335         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.21e+03 |\n",
      "|    ep_rew_mean     | 3.44e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 514      |\n",
      "|    iterations      | 1595     |\n",
      "|    time_elapsed    | 6344     |\n",
      "|    total_timesteps | 3266560  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.21e+03     |\n",
      "|    ep_rew_mean          | 3.44e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 515          |\n",
      "|    iterations           | 1596         |\n",
      "|    time_elapsed         | 6345         |\n",
      "|    total_timesteps      | 3268608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053142635 |\n",
      "|    clip_fraction        | 0.254        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.35         |\n",
      "|    explained_variance   | 0.398        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.17e+07     |\n",
      "|    n_updates            | 31860        |\n",
      "|    policy_gradient_loss | 0.000465     |\n",
      "|    std                  | 0.156        |\n",
      "|    value_loss           | 1.02e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3270000, episode_reward=74955.82 +/- 4612.26\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 7.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017015085 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 31870       |\n",
      "|    policy_gradient_loss | 0.00265     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 160         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.21e+03 |\n",
      "|    ep_rew_mean     | 3.44e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 514      |\n",
      "|    iterations      | 1597     |\n",
      "|    time_elapsed    | 6359     |\n",
      "|    total_timesteps | 3270656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.24e+03    |\n",
      "|    ep_rew_mean          | 3.9e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1598        |\n",
      "|    time_elapsed         | 6361        |\n",
      "|    total_timesteps      | 3272704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030226182 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 152         |\n",
      "|    n_updates            | 31880       |\n",
      "|    policy_gradient_loss | 0.00983     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 425         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.24e+03    |\n",
      "|    ep_rew_mean          | 3.9e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1599        |\n",
      "|    time_elapsed         | 6363        |\n",
      "|    total_timesteps      | 3274752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007260837 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.9e+03     |\n",
      "|    n_updates            | 31890       |\n",
      "|    policy_gradient_loss | -0.000436   |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 4.77e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3275000, episode_reward=59301.35 +/- 3241.05\n",
      "Episode length: 4637.20 +/- 11.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.64e+03    |\n",
      "|    mean_reward          | 5.93e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3275000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028536182 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.1        |\n",
      "|    n_updates            | 31900       |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 158         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.25e+03 |\n",
      "|    ep_rew_mean     | 4.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1600     |\n",
      "|    time_elapsed    | 6375     |\n",
      "|    total_timesteps | 3276800  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.27e+03    |\n",
      "|    ep_rew_mean          | 4.26e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 514         |\n",
      "|    iterations           | 1601        |\n",
      "|    time_elapsed         | 6377        |\n",
      "|    total_timesteps      | 3278848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011080718 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 31910       |\n",
      "|    policy_gradient_loss | -0.000353   |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 3.24e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3280000, episode_reward=66407.94 +/- 3931.93\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012163177 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 161         |\n",
      "|    n_updates            | 31920       |\n",
      "|    policy_gradient_loss | -0.000888   |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 533         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.27e+03 |\n",
      "|    ep_rew_mean     | 4.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1602     |\n",
      "|    time_elapsed    | 6391     |\n",
      "|    total_timesteps | 3280896  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.29e+03    |\n",
      "|    ep_rew_mean          | 4.61e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 1603        |\n",
      "|    time_elapsed         | 6393        |\n",
      "|    total_timesteps      | 3282944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017323397 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34          |\n",
      "|    n_updates            | 31930       |\n",
      "|    policy_gradient_loss | 0.00597     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.29e+03    |\n",
      "|    ep_rew_mean          | 3.96e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 1604        |\n",
      "|    time_elapsed         | 6394        |\n",
      "|    total_timesteps      | 3284992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013238897 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.4        |\n",
      "|    n_updates            | 31940       |\n",
      "|    policy_gradient_loss | 0.00382     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3285000, episode_reward=31821.73 +/- 2775.44\n",
      "Episode length: 3211.20 +/- 9.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.21e+03    |\n",
      "|    mean_reward          | 3.18e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3285000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006090247 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.7e+06     |\n",
      "|    n_updates            | 31950       |\n",
      "|    policy_gradient_loss | -0.000987   |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 1e+07       |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.27e+03 |\n",
      "|    ep_rew_mean     | 3.48e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 513      |\n",
      "|    iterations      | 1605     |\n",
      "|    time_elapsed    | 6404     |\n",
      "|    total_timesteps | 3287040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.27e+03    |\n",
      "|    ep_rew_mean          | 3.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 513         |\n",
      "|    iterations           | 1606        |\n",
      "|    time_elapsed         | 6406        |\n",
      "|    total_timesteps      | 3289088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005697924 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.36        |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.06e+06    |\n",
      "|    n_updates            | 31960       |\n",
      "|    policy_gradient_loss | -0.000992   |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 8.85e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3290000, episode_reward=33993.74 +/- 3698.36\n",
      "Episode length: 3206.00 +/- 9.59\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.21e+03    |\n",
      "|    mean_reward          | 3.4e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038717266 |\n",
      "|    clip_fraction        | 0.376       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.37        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.59        |\n",
      "|    n_updates            | 31970       |\n",
      "|    policy_gradient_loss | 0.0345      |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 81.1        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.25e+03 |\n",
      "|    ep_rew_mean     | 3.16e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1607     |\n",
      "|    time_elapsed    | 6415     |\n",
      "|    total_timesteps | 3291136  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.23e+03   |\n",
      "|    ep_rew_mean          | 2.91e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 513        |\n",
      "|    iterations           | 1608       |\n",
      "|    time_elapsed         | 6417       |\n",
      "|    total_timesteps      | 3293184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12771808 |\n",
      "|    clip_fraction        | 0.679      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.38       |\n",
      "|    explained_variance   | 0.787      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.95e+03   |\n",
      "|    n_updates            | 31980      |\n",
      "|    policy_gradient_loss | 0.119      |\n",
      "|    std                  | 0.155      |\n",
      "|    value_loss           | 3.13e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3295000, episode_reward=24883.95 +/- 3712.35\n",
      "Episode length: 3104.40 +/- 7.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.1e+03     |\n",
      "|    mean_reward          | 2.49e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3295000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004133966 |\n",
      "|    clip_fraction        | 0.0345      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.3e+03     |\n",
      "|    n_updates            | 31990       |\n",
      "|    policy_gradient_loss | -0.00448    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 1.99e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.2e+03  |\n",
      "|    ep_rew_mean     | 2.52e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1609     |\n",
      "|    time_elapsed    | 6426     |\n",
      "|    total_timesteps | 3295232  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2e+03     |\n",
      "|    ep_rew_mean          | 2.52e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1610        |\n",
      "|    time_elapsed         | 6428        |\n",
      "|    total_timesteps      | 3297280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014129257 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 341         |\n",
      "|    n_updates            | 32000       |\n",
      "|    policy_gradient_loss | -0.00638    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 3.05e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.19e+03     |\n",
      "|    ep_rew_mean          | 1.39e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 513          |\n",
      "|    iterations           | 1611         |\n",
      "|    time_elapsed         | 6430         |\n",
      "|    total_timesteps      | 3299328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041214246 |\n",
      "|    clip_fraction        | 0.0714       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.39         |\n",
      "|    explained_variance   | 0.828        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.17e+03     |\n",
      "|    n_updates            | 32010        |\n",
      "|    policy_gradient_loss | -4.55e-05    |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 5.49e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3300000, episode_reward=38275.02 +/- 4832.75\n",
      "Episode length: 3490.20 +/- 11.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.49e+03     |\n",
      "|    mean_reward          | 3.83e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3300000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040983036 |\n",
      "|    clip_fraction        | 0.0312       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.39         |\n",
      "|    explained_variance   | 0.495        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.29e+07     |\n",
      "|    n_updates            | 32020        |\n",
      "|    policy_gradient_loss | -0.00721     |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 1.28e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.22e+03 |\n",
      "|    ep_rew_mean     | 2.36e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 512      |\n",
      "|    iterations      | 1612     |\n",
      "|    time_elapsed    | 6440     |\n",
      "|    total_timesteps | 3301376  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.22e+03    |\n",
      "|    ep_rew_mean          | 2.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1613        |\n",
      "|    time_elapsed         | 6442        |\n",
      "|    total_timesteps      | 3303424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005801347 |\n",
      "|    clip_fraction        | 0.0398      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.38        |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.17e+03    |\n",
      "|    n_updates            | 32030       |\n",
      "|    policy_gradient_loss | -0.00606    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 3.76e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3305000, episode_reward=61492.54 +/- 3129.89\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.15e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3305000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010388414 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 233         |\n",
      "|    n_updates            | 32040       |\n",
      "|    policy_gradient_loss | -0.00598    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 1.27e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.22e+03 |\n",
      "|    ep_rew_mean     | 2.49e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1614     |\n",
      "|    time_elapsed    | 6456     |\n",
      "|    total_timesteps | 3305472  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.22e+03   |\n",
      "|    ep_rew_mean          | 2.49e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 512        |\n",
      "|    iterations           | 1615       |\n",
      "|    time_elapsed         | 6457       |\n",
      "|    total_timesteps      | 3307520    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00809982 |\n",
      "|    clip_fraction        | 0.129      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.39       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 230        |\n",
      "|    n_updates            | 32050      |\n",
      "|    policy_gradient_loss | -0.00034   |\n",
      "|    std                  | 0.155      |\n",
      "|    value_loss           | 1.6e+03    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.23e+03    |\n",
      "|    ep_rew_mean          | 2.59e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 512         |\n",
      "|    iterations           | 1616        |\n",
      "|    time_elapsed         | 6459        |\n",
      "|    total_timesteps      | 3309568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016710635 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 191         |\n",
      "|    n_updates            | 32060       |\n",
      "|    policy_gradient_loss | -0.000133   |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 594         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3310000, episode_reward=59434.49 +/- 6665.06\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 5.94e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017789956 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.38e+04    |\n",
      "|    n_updates            | 32070       |\n",
      "|    policy_gradient_loss | 0.0141      |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 9.31e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.23e+03 |\n",
      "|    ep_rew_mean     | 2.59e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1617     |\n",
      "|    time_elapsed    | 6473     |\n",
      "|    total_timesteps | 3311616  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.24e+03    |\n",
      "|    ep_rew_mean          | 2.7e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1618        |\n",
      "|    time_elapsed         | 6475        |\n",
      "|    total_timesteps      | 3313664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010199407 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 327         |\n",
      "|    n_updates            | 32080       |\n",
      "|    policy_gradient_loss | 0.00578     |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 866         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3315000, episode_reward=38393.98 +/- 3982.01\n",
      "Episode length: 3625.20 +/- 13.20\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.63e+03   |\n",
      "|    mean_reward          | 3.84e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3315000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03026431 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 151        |\n",
      "|    n_updates            | 32090      |\n",
      "|    policy_gradient_loss | 0.000757   |\n",
      "|    std                  | 0.155      |\n",
      "|    value_loss           | 611        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.26e+03 |\n",
      "|    ep_rew_mean     | 2.93e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1619     |\n",
      "|    time_elapsed    | 6485     |\n",
      "|    total_timesteps | 3315712  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 2.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1620        |\n",
      "|    time_elapsed         | 6487        |\n",
      "|    total_timesteps      | 3317760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016486878 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 102         |\n",
      "|    n_updates            | 32100       |\n",
      "|    policy_gradient_loss | -0.00187    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 275         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.28e+03    |\n",
      "|    ep_rew_mean          | 3.98e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1621        |\n",
      "|    time_elapsed         | 6489        |\n",
      "|    total_timesteps      | 3319808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015889328 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 32110       |\n",
      "|    policy_gradient_loss | -0.00947    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 267         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3320000, episode_reward=29884.99 +/- 3690.42\n",
      "Episode length: 3613.00 +/- 17.82\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.61e+03     |\n",
      "|    mean_reward          | 2.99e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3320000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0091827195 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.39         |\n",
      "|    explained_variance   | 0.86         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 102          |\n",
      "|    n_updates            | 32120        |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 7.15e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.29e+03 |\n",
      "|    ep_rew_mean     | 4.97e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 511      |\n",
      "|    iterations      | 1622     |\n",
      "|    time_elapsed    | 6499     |\n",
      "|    total_timesteps | 3321856  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.29e+03    |\n",
      "|    ep_rew_mean          | 5e+03       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 511         |\n",
      "|    iterations           | 1623        |\n",
      "|    time_elapsed         | 6501        |\n",
      "|    total_timesteps      | 3323904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024187528 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23          |\n",
      "|    n_updates            | 32130       |\n",
      "|    policy_gradient_loss | -0.00214    |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 206         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3325000, episode_reward=31036.99 +/- 2972.92\n",
      "Episode length: 4147.80 +/- 3.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.15e+03    |\n",
      "|    mean_reward          | 3.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3325000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015636306 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 99.2        |\n",
      "|    n_updates            | 32140       |\n",
      "|    policy_gradient_loss | 0.00132     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 244         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.29e+03 |\n",
      "|    ep_rew_mean     | 5e+03    |\n",
      "| time/              |          |\n",
      "|    fps             | 510      |\n",
      "|    iterations      | 1624     |\n",
      "|    time_elapsed    | 6513     |\n",
      "|    total_timesteps | 3325952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.32e+03    |\n",
      "|    ep_rew_mean          | 6.65e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1625        |\n",
      "|    time_elapsed         | 6515        |\n",
      "|    total_timesteps      | 3328000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012638161 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 28.1        |\n",
      "|    n_updates            | 32150       |\n",
      "|    policy_gradient_loss | 0.00542     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 102         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3330000, episode_reward=29162.30 +/- 860.85\n",
      "Episode length: 3284.20 +/- 10.68\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.28e+03     |\n",
      "|    mean_reward          | 2.92e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3330000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023851362 |\n",
      "|    clip_fraction        | 0.0293       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.39         |\n",
      "|    explained_variance   | 0.397        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 990          |\n",
      "|    n_updates            | 32160        |\n",
      "|    policy_gradient_loss | 0.00141      |\n",
      "|    std                  | 0.156        |\n",
      "|    value_loss           | 5.96e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.34e+03 |\n",
      "|    ep_rew_mean     | 6.74e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 510      |\n",
      "|    iterations      | 1626     |\n",
      "|    time_elapsed    | 6524     |\n",
      "|    total_timesteps | 3330048  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.34e+03     |\n",
      "|    ep_rew_mean          | 6.74e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 1627         |\n",
      "|    time_elapsed         | 6526         |\n",
      "|    total_timesteps      | 3332096      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036857107 |\n",
      "|    clip_fraction        | 0.0107       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.39         |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 32170        |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    std                  | 0.156        |\n",
      "|    value_loss           | 3e+04        |\n",
      "------------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.34e+03  |\n",
      "|    ep_rew_mean          | 6.66e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 510       |\n",
      "|    iterations           | 1628      |\n",
      "|    time_elapsed         | 6528      |\n",
      "|    total_timesteps      | 3334144   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0318562 |\n",
      "|    clip_fraction        | 0.261     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.39      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 126       |\n",
      "|    n_updates            | 32180     |\n",
      "|    policy_gradient_loss | 0.00296   |\n",
      "|    std                  | 0.156     |\n",
      "|    value_loss           | 246       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3335000, episode_reward=21889.40 +/- 3453.11\n",
      "Episode length: 2833.00 +/- 13.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.83e+03    |\n",
      "|    mean_reward          | 2.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3335000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020827346 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 32190       |\n",
      "|    policy_gradient_loss | 0.0126      |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 3.12e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.36e+03 |\n",
      "|    ep_rew_mean     | 6.4e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 510      |\n",
      "|    iterations      | 1629     |\n",
      "|    time_elapsed    | 6537     |\n",
      "|    total_timesteps | 3336192  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.36e+03    |\n",
      "|    ep_rew_mean          | 6.4e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1630        |\n",
      "|    time_elapsed         | 6538        |\n",
      "|    total_timesteps      | 3338240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013993848 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.791       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.29e+06    |\n",
      "|    n_updates            | 32200       |\n",
      "|    policy_gradient_loss | 0.00523     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 1.02e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3340000, episode_reward=19827.47 +/- 4666.91\n",
      "Episode length: 2982.00 +/- 10.41\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.98e+03   |\n",
      "|    mean_reward          | 1.98e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3340000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04137237 |\n",
      "|    clip_fraction        | 0.164      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.39       |\n",
      "|    explained_variance   | 0.995      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 257        |\n",
      "|    n_updates            | 32210      |\n",
      "|    policy_gradient_loss | 0.000774   |\n",
      "|    std                  | 0.156      |\n",
      "|    value_loss           | 499        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.36e+03 |\n",
      "|    ep_rew_mean     | 6.4e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 510      |\n",
      "|    iterations      | 1631     |\n",
      "|    time_elapsed    | 6547     |\n",
      "|    total_timesteps | 3340288  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | 7.55e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1632        |\n",
      "|    time_elapsed         | 6549        |\n",
      "|    total_timesteps      | 3342336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004807926 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.01e+04    |\n",
      "|    n_updates            | 32220       |\n",
      "|    policy_gradient_loss | 0.00102     |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 1.1e+05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | 7.53e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1633        |\n",
      "|    time_elapsed         | 6551        |\n",
      "|    total_timesteps      | 3344384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002327449 |\n",
      "|    clip_fraction        | 0.0104      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.92e+03    |\n",
      "|    n_updates            | 32230       |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    std                  | 0.156       |\n",
      "|    value_loss           | 7.89e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3345000, episode_reward=19917.01 +/- 1467.33\n",
      "Episode length: 2919.00 +/- 13.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.92e+03     |\n",
      "|    mean_reward          | 1.99e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3345000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040261117 |\n",
      "|    clip_fraction        | 0.0238       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.39         |\n",
      "|    explained_variance   | 0.909        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 986          |\n",
      "|    n_updates            | 32240        |\n",
      "|    policy_gradient_loss | -0.00116     |\n",
      "|    std                  | 0.156        |\n",
      "|    value_loss           | 5.16e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.38e+03 |\n",
      "|    ep_rew_mean     | 8.15e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 510      |\n",
      "|    iterations      | 1634     |\n",
      "|    time_elapsed    | 6560     |\n",
      "|    total_timesteps | 3346432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.37e+03    |\n",
      "|    ep_rew_mean          | 8.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1635        |\n",
      "|    time_elapsed         | 6562        |\n",
      "|    total_timesteps      | 3348480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023391124 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.6        |\n",
      "|    n_updates            | 32250       |\n",
      "|    policy_gradient_loss | 0.00688     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 3.12e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3350000, episode_reward=24165.03 +/- 1816.80\n",
      "Episode length: 2759.40 +/- 6.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.76e+03    |\n",
      "|    mean_reward          | 2.42e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035503946 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 11.5        |\n",
      "|    n_updates            | 32260       |\n",
      "|    policy_gradient_loss | 0.018       |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 3.32e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.37e+03 |\n",
      "|    ep_rew_mean     | 8.03e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1636     |\n",
      "|    time_elapsed    | 6570     |\n",
      "|    total_timesteps | 3350528  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.36e+03   |\n",
      "|    ep_rew_mean          | 7.36e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 510        |\n",
      "|    iterations           | 1637       |\n",
      "|    time_elapsed         | 6572       |\n",
      "|    total_timesteps      | 3352576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01445341 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 25.6       |\n",
      "|    n_updates            | 32270      |\n",
      "|    policy_gradient_loss | 0.0073     |\n",
      "|    std                  | 0.155      |\n",
      "|    value_loss           | 86.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | 6.93e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 510         |\n",
      "|    iterations           | 1638        |\n",
      "|    time_elapsed         | 6574        |\n",
      "|    total_timesteps      | 3354624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010333911 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.471       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.09e+03    |\n",
      "|    n_updates            | 32280       |\n",
      "|    policy_gradient_loss | 0.00299     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 4.93e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3355000, episode_reward=20969.72 +/- 2238.23\n",
      "Episode length: 2765.80 +/- 7.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.77e+03    |\n",
      "|    mean_reward          | 2.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3355000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016875537 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.8        |\n",
      "|    n_updates            | 32290       |\n",
      "|    policy_gradient_loss | 0.00403     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 399         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.31e+03 |\n",
      "|    ep_rew_mean     | 6.51e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1639     |\n",
      "|    time_elapsed    | 6582     |\n",
      "|    total_timesteps | 3356672  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.31e+03     |\n",
      "|    ep_rew_mean          | 6.32e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 510          |\n",
      "|    iterations           | 1640         |\n",
      "|    time_elapsed         | 6584         |\n",
      "|    total_timesteps      | 3358720      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073906607 |\n",
      "|    clip_fraction        | 0.0743       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+04     |\n",
      "|    n_updates            | 32300        |\n",
      "|    policy_gradient_loss | -0.000429    |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 4.42e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3360000, episode_reward=-60383.72 +/- 19328.88\n",
      "Episode length: 2768.60 +/- 8.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.77e+03    |\n",
      "|    mean_reward          | -6.04e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005451265 |\n",
      "|    clip_fraction        | 0.0258      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.88e+03    |\n",
      "|    n_updates            | 32310       |\n",
      "|    policy_gradient_loss | 0.000608    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 6.19e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.31e+03 |\n",
      "|    ep_rew_mean     | 6.32e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1641     |\n",
      "|    time_elapsed    | 6592     |\n",
      "|    total_timesteps | 3360768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.29e+03    |\n",
      "|    ep_rew_mean          | 6.02e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1642        |\n",
      "|    time_elapsed         | 6594        |\n",
      "|    total_timesteps      | 3362816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010946023 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.2        |\n",
      "|    n_updates            | 32320       |\n",
      "|    policy_gradient_loss | -0.00288    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 236         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.29e+03  |\n",
      "|    ep_rew_mean          | 6.04e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 510       |\n",
      "|    iterations           | 1643      |\n",
      "|    time_elapsed         | 6596      |\n",
      "|    total_timesteps      | 3364864   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0036116 |\n",
      "|    clip_fraction        | 0.0685    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.41      |\n",
      "|    explained_variance   | 0.956     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.62e+04  |\n",
      "|    n_updates            | 32330     |\n",
      "|    policy_gradient_loss | 0.00187   |\n",
      "|    std                  | 0.155     |\n",
      "|    value_loss           | 4.22e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3365000, episode_reward=19143.37 +/- 3983.11\n",
      "Episode length: 2730.40 +/- 7.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.73e+03    |\n",
      "|    mean_reward          | 1.91e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3365000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025405578 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17.8        |\n",
      "|    n_updates            | 32340       |\n",
      "|    policy_gradient_loss | 0.00518     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 140         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.29e+03 |\n",
      "|    ep_rew_mean     | 6.11e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1644     |\n",
      "|    time_elapsed    | 6605     |\n",
      "|    total_timesteps | 3366912  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.3e+03     |\n",
      "|    ep_rew_mean          | 6.08e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1645        |\n",
      "|    time_elapsed         | 6606        |\n",
      "|    total_timesteps      | 3368960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012631356 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.58e+03    |\n",
      "|    n_updates            | 32350       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 6.82e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3370000, episode_reward=-13781.25 +/- 2939.47\n",
      "Episode length: 2827.80 +/- 6.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.83e+03    |\n",
      "|    mean_reward          | -1.38e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009359454 |\n",
      "|    clip_fraction        | 0.0781      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.06e+04    |\n",
      "|    n_updates            | 32360       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 1.42e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.32e+03 |\n",
      "|    ep_rew_mean     | 8.19e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1646     |\n",
      "|    time_elapsed    | 6615     |\n",
      "|    total_timesteps | 3371008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.32e+03    |\n",
      "|    ep_rew_mean          | 8.19e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1647        |\n",
      "|    time_elapsed         | 6617        |\n",
      "|    total_timesteps      | 3373056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022941664 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.13e+04    |\n",
      "|    n_updates            | 32370       |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 6.11e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3375000, episode_reward=21151.14 +/- 3857.28\n",
      "Episode length: 3606.80 +/- 19.19\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.61e+03   |\n",
      "|    mean_reward          | 2.12e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3375000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01980222 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 36.9       |\n",
      "|    n_updates            | 32380      |\n",
      "|    policy_gradient_loss | 0.00462    |\n",
      "|    std                  | 0.155      |\n",
      "|    value_loss           | 131        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.32e+03 |\n",
      "|    ep_rew_mean     | 8.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1648     |\n",
      "|    time_elapsed    | 6627     |\n",
      "|    total_timesteps | 3375104  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.32e+03    |\n",
      "|    ep_rew_mean          | 8.21e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1649        |\n",
      "|    time_elapsed         | 6629        |\n",
      "|    total_timesteps      | 3377152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003616314 |\n",
      "|    clip_fraction        | 0.0494      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+03    |\n",
      "|    n_updates            | 32390       |\n",
      "|    policy_gradient_loss | -0.00516    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 3.99e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.32e+03    |\n",
      "|    ep_rew_mean          | 8.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1650        |\n",
      "|    time_elapsed         | 6631        |\n",
      "|    total_timesteps      | 3379200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014616896 |\n",
      "|    clip_fraction        | 0.0429      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+04    |\n",
      "|    n_updates            | 32400       |\n",
      "|    policy_gradient_loss | -0.00141    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 7.44e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3380000, episode_reward=20277.28 +/- 2948.94\n",
      "Episode length: 2842.80 +/- 12.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.84e+03    |\n",
      "|    mean_reward          | 2.03e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008001938 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.517       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.7e+04     |\n",
      "|    n_updates            | 32410       |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 2.34e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.32e+03 |\n",
      "|    ep_rew_mean     | 8.05e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 509      |\n",
      "|    iterations      | 1651     |\n",
      "|    time_elapsed    | 6640     |\n",
      "|    total_timesteps | 3381248  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.33e+03    |\n",
      "|    ep_rew_mean          | 9.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1652        |\n",
      "|    time_elapsed         | 6641        |\n",
      "|    total_timesteps      | 3383296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018134933 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 32420       |\n",
      "|    policy_gradient_loss | 0.00189     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 827         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3385000, episode_reward=21072.50 +/- 5940.16\n",
      "Episode length: 3393.00 +/- 46.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.39e+03     |\n",
      "|    mean_reward          | 2.11e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3385000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046668677 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.946        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 172          |\n",
      "|    n_updates            | 32430        |\n",
      "|    policy_gradient_loss | -0.00113     |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 2.55e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.34e+03 |\n",
      "|    ep_rew_mean     | 1.07e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1653     |\n",
      "|    time_elapsed    | 6651     |\n",
      "|    total_timesteps | 3385344  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.35e+03     |\n",
      "|    ep_rew_mean          | 1.24e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 509          |\n",
      "|    iterations           | 1654         |\n",
      "|    time_elapsed         | 6653         |\n",
      "|    total_timesteps      | 3387392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027408788 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 603          |\n",
      "|    n_updates            | 32440        |\n",
      "|    policy_gradient_loss | -0.000106    |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 9.3e+03      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.35e+03     |\n",
      "|    ep_rew_mean          | 1.24e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 509          |\n",
      "|    iterations           | 1655         |\n",
      "|    time_elapsed         | 6655         |\n",
      "|    total_timesteps      | 3389440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033362885 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.26e+03     |\n",
      "|    n_updates            | 32450        |\n",
      "|    policy_gradient_loss | -0.00497     |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 1.02e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3390000, episode_reward=-139406.60 +/- 3893.34\n",
      "Episode length: 3053.60 +/- 15.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.05e+03    |\n",
      "|    mean_reward          | -1.39e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010275159 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 610         |\n",
      "|    n_updates            | 32460       |\n",
      "|    policy_gradient_loss | -0.00158    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.35e+03 |\n",
      "|    ep_rew_mean     | 1.1e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1656     |\n",
      "|    time_elapsed    | 6664     |\n",
      "|    total_timesteps | 3391488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.35e+03    |\n",
      "|    ep_rew_mean          | 1.1e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 509         |\n",
      "|    iterations           | 1657        |\n",
      "|    time_elapsed         | 6666        |\n",
      "|    total_timesteps      | 3393536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005518304 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.2e+07     |\n",
      "|    n_updates            | 32470       |\n",
      "|    policy_gradient_loss | -0.00331    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 3.12e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3395000, episode_reward=14561.96 +/- 4436.38\n",
      "Episode length: 2982.60 +/- 12.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.98e+03     |\n",
      "|    mean_reward          | 1.46e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3395000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028313305 |\n",
      "|    clip_fraction        | 0.00552      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.75e+04     |\n",
      "|    n_updates            | 32480        |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 1.99e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.36e+03 |\n",
      "|    ep_rew_mean     | 1.1e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1658     |\n",
      "|    time_elapsed    | 6675     |\n",
      "|    total_timesteps | 3395584  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.38e+03     |\n",
      "|    ep_rew_mean          | 1.13e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1659         |\n",
      "|    time_elapsed         | 6677         |\n",
      "|    total_timesteps      | 3397632      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040964535 |\n",
      "|    clip_fraction        | 0.035        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.29e+03     |\n",
      "|    n_updates            | 32490        |\n",
      "|    policy_gradient_loss | -0.000346    |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 4.97e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | 1.13e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1660        |\n",
      "|    time_elapsed         | 6679        |\n",
      "|    total_timesteps      | 3399680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004040491 |\n",
      "|    clip_fraction        | 0.0287      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.09e+03    |\n",
      "|    n_updates            | 32500       |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 1.11e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3400000, episode_reward=19393.26 +/- 3160.34\n",
      "Episode length: 2917.40 +/- 9.31\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.92e+03     |\n",
      "|    mean_reward          | 1.94e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3400000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051051565 |\n",
      "|    clip_fraction        | 0.0398       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.41         |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 32510        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 2.72e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.4e+03  |\n",
      "|    ep_rew_mean     | 1.13e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1661     |\n",
      "|    time_elapsed    | 6687     |\n",
      "|    total_timesteps | 3401728  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+03    |\n",
      "|    ep_rew_mean          | 1.15e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1662        |\n",
      "|    time_elapsed         | 6689        |\n",
      "|    total_timesteps      | 3403776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013821149 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.19e+04    |\n",
      "|    n_updates            | 32520       |\n",
      "|    policy_gradient_loss | -0.00272    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 1.51e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3405000, episode_reward=19109.05 +/- 4168.12\n",
      "Episode length: 2874.80 +/- 14.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.87e+03    |\n",
      "|    mean_reward          | 1.91e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3405000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006066762 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 32530       |\n",
      "|    policy_gradient_loss | -0.0042     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 2.01e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.43e+03 |\n",
      "|    ep_rew_mean     | 1.17e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1663     |\n",
      "|    time_elapsed    | 6698     |\n",
      "|    total_timesteps | 3405824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.43e+03    |\n",
      "|    ep_rew_mean          | 1.17e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1664        |\n",
      "|    time_elapsed         | 6700        |\n",
      "|    total_timesteps      | 3407872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006847301 |\n",
      "|    clip_fraction        | 0.063       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.1e+03     |\n",
      "|    n_updates            | 32540       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 5.12e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.45e+03    |\n",
      "|    ep_rew_mean          | 1.07e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1665        |\n",
      "|    time_elapsed         | 6702        |\n",
      "|    total_timesteps      | 3409920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010013325 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46          |\n",
      "|    n_updates            | 32550       |\n",
      "|    policy_gradient_loss | 0.00253     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 299         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3410000, episode_reward=21294.83 +/- 4919.06\n",
      "Episode length: 2268.60 +/- 12.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.27e+03    |\n",
      "|    mean_reward          | 2.13e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001873375 |\n",
      "|    clip_fraction        | 0.0395      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.33e+07    |\n",
      "|    n_updates            | 32560       |\n",
      "|    policy_gradient_loss | -0.00111    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 1.7e+07     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.46e+03 |\n",
      "|    ep_rew_mean     | 1.08e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1666     |\n",
      "|    time_elapsed    | 6709     |\n",
      "|    total_timesteps | 3411968  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.47e+03    |\n",
      "|    ep_rew_mean          | 1.1e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1667        |\n",
      "|    time_elapsed         | 6711        |\n",
      "|    total_timesteps      | 3414016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010079568 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 282         |\n",
      "|    n_updates            | 32570       |\n",
      "|    policy_gradient_loss | 0.00233     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 2.53e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3415000, episode_reward=-17997.74 +/- 82596.31\n",
      "Episode length: 1697.40 +/- 791.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | -1.8e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3415000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012792841 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61.2        |\n",
      "|    n_updates            | 32580       |\n",
      "|    policy_gradient_loss | 0.00081     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 174         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.48e+03 |\n",
      "|    ep_rew_mean     | 1.13e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1668     |\n",
      "|    time_elapsed    | 6717     |\n",
      "|    total_timesteps | 3416064  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.48e+03    |\n",
      "|    ep_rew_mean          | 1.15e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1669        |\n",
      "|    time_elapsed         | 6719        |\n",
      "|    total_timesteps      | 3418112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011198133 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 32590       |\n",
      "|    policy_gradient_loss | 0.00986     |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 2.21e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3420000, episode_reward=25796.76 +/- 3720.36\n",
      "Episode length: 2144.60 +/- 9.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.14e+03    |\n",
      "|    mean_reward          | 2.58e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016826356 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.73e+04    |\n",
      "|    n_updates            | 32600       |\n",
      "|    policy_gradient_loss | 0.00303     |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 6.69e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.49e+03 |\n",
      "|    ep_rew_mean     | 1.16e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1670     |\n",
      "|    time_elapsed    | 6726     |\n",
      "|    total_timesteps | 3420160  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.5e+03    |\n",
      "|    ep_rew_mean          | 1.18e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 508        |\n",
      "|    iterations           | 1671       |\n",
      "|    time_elapsed         | 6727       |\n",
      "|    total_timesteps      | 3422208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02311571 |\n",
      "|    clip_fraction        | 0.162      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 55.2       |\n",
      "|    n_updates            | 32610      |\n",
      "|    policy_gradient_loss | 0.00309    |\n",
      "|    std                  | 0.154      |\n",
      "|    value_loss           | 230        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.52e+03   |\n",
      "|    ep_rew_mean          | 1.2e+04    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 508        |\n",
      "|    iterations           | 1672       |\n",
      "|    time_elapsed         | 6729       |\n",
      "|    total_timesteps      | 3424256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14948618 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 58.6       |\n",
      "|    n_updates            | 32620      |\n",
      "|    policy_gradient_loss | 0.00633    |\n",
      "|    std                  | 0.155      |\n",
      "|    value_loss           | 342        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3425000, episode_reward=22698.67 +/- 3532.10\n",
      "Episode length: 2866.40 +/- 11.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.87e+03    |\n",
      "|    mean_reward          | 2.27e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3425000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008563748 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 250         |\n",
      "|    n_updates            | 32630       |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 1.41e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.52e+03 |\n",
      "|    ep_rew_mean     | 1.2e+04  |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1673     |\n",
      "|    time_elapsed    | 6738     |\n",
      "|    total_timesteps | 3426304  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 1.13e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1674        |\n",
      "|    time_elapsed         | 6740        |\n",
      "|    total_timesteps      | 3428352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012060634 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 78.2        |\n",
      "|    n_updates            | 32640       |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 561         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3430000, episode_reward=24715.10 +/- 4344.16\n",
      "Episode length: 2713.40 +/- 15.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.71e+03     |\n",
      "|    mean_reward          | 2.47e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3430000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059418874 |\n",
      "|    clip_fraction        | 0.0937       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.4          |\n",
      "|    explained_variance   | 0.48         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+07     |\n",
      "|    n_updates            | 32650        |\n",
      "|    policy_gradient_loss | -0.00485     |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 1.17e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.56e+03 |\n",
      "|    ep_rew_mean     | 1.34e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1675     |\n",
      "|    time_elapsed    | 6748     |\n",
      "|    total_timesteps | 3430400  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.56e+03     |\n",
      "|    ep_rew_mean          | 1.34e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1676         |\n",
      "|    time_elapsed         | 6750         |\n",
      "|    total_timesteps      | 3432448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042131147 |\n",
      "|    clip_fraction        | 0.029        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.4          |\n",
      "|    explained_variance   | 0.906        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.19e+05     |\n",
      "|    n_updates            | 32660        |\n",
      "|    policy_gradient_loss | -0.0038      |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 1.59e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.58e+03    |\n",
      "|    ep_rew_mean          | 1.34e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1677        |\n",
      "|    time_elapsed         | 6752        |\n",
      "|    total_timesteps      | 3434496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020376213 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 72.9        |\n",
      "|    n_updates            | 32670       |\n",
      "|    policy_gradient_loss | 0.000738    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 454         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3435000, episode_reward=22501.81 +/- 5967.45\n",
      "Episode length: 2643.80 +/- 14.55\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.64e+03     |\n",
      "|    mean_reward          | 2.25e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3435000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053265076 |\n",
      "|    clip_fraction        | 0.0897       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.39         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.91e+03     |\n",
      "|    n_updates            | 32680        |\n",
      "|    policy_gradient_loss | 0.00352      |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 1.48e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.59e+03 |\n",
      "|    ep_rew_mean     | 1.22e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1678     |\n",
      "|    time_elapsed    | 6760     |\n",
      "|    total_timesteps | 3436544  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.62e+03    |\n",
      "|    ep_rew_mean          | 1.47e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1679        |\n",
      "|    time_elapsed         | 6762        |\n",
      "|    total_timesteps      | 3438592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008916266 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4e+07     |\n",
      "|    n_updates            | 32690       |\n",
      "|    policy_gradient_loss | 0.00657     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 2.38e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3440000, episode_reward=18629.04 +/- 4459.89\n",
      "Episode length: 2617.40 +/- 12.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.62e+03    |\n",
      "|    mean_reward          | 1.86e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003949361 |\n",
      "|    clip_fraction        | 0.0775      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.39        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.04e+03    |\n",
      "|    n_updates            | 32700       |\n",
      "|    policy_gradient_loss | 0.00279     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 2.18e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.62e+03 |\n",
      "|    ep_rew_mean     | 1.47e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1680     |\n",
      "|    time_elapsed    | 6770     |\n",
      "|    total_timesteps | 3440640  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.63e+03   |\n",
      "|    ep_rew_mean          | 1.49e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 508        |\n",
      "|    iterations           | 1681       |\n",
      "|    time_elapsed         | 6772       |\n",
      "|    total_timesteps      | 3442688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04155695 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 22.7       |\n",
      "|    n_updates            | 32710      |\n",
      "|    policy_gradient_loss | 0.0105     |\n",
      "|    std                  | 0.155      |\n",
      "|    value_loss           | 78.2       |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.65e+03   |\n",
      "|    ep_rew_mean          | 1.51e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 508        |\n",
      "|    iterations           | 1682       |\n",
      "|    time_elapsed         | 6774       |\n",
      "|    total_timesteps      | 3444736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00418541 |\n",
      "|    clip_fraction        | 0.11       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 0.946      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 227        |\n",
      "|    n_updates            | 32720      |\n",
      "|    policy_gradient_loss | 0.0012     |\n",
      "|    std                  | 0.155      |\n",
      "|    value_loss           | 3.12e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3445000, episode_reward=-20928.38 +/- 6564.16\n",
      "Episode length: 3369.20 +/- 2.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.37e+03    |\n",
      "|    mean_reward          | -2.09e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3445000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003776598 |\n",
      "|    clip_fraction        | 0.0456      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 454         |\n",
      "|    n_updates            | 32730       |\n",
      "|    policy_gradient_loss | -0.00318    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 9.4e+04     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.65e+03 |\n",
      "|    ep_rew_mean     | 1.51e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 508      |\n",
      "|    iterations      | 1683     |\n",
      "|    time_elapsed    | 6784     |\n",
      "|    total_timesteps | 3446784  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.67e+03    |\n",
      "|    ep_rew_mean          | 1.49e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 508         |\n",
      "|    iterations           | 1684        |\n",
      "|    time_elapsed         | 6785        |\n",
      "|    total_timesteps      | 3448832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008005314 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 32740       |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3450000, episode_reward=21664.71 +/- 2341.76\n",
      "Episode length: 2952.40 +/- 14.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.95e+03     |\n",
      "|    mean_reward          | 2.17e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3450000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030288296 |\n",
      "|    clip_fraction        | 0.0349       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.4          |\n",
      "|    explained_variance   | 0.608        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 217          |\n",
      "|    n_updates            | 32750        |\n",
      "|    policy_gradient_loss | -0.00366     |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 1.31e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.69e+03 |\n",
      "|    ep_rew_mean     | 1.48e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 1685     |\n",
      "|    time_elapsed    | 6794     |\n",
      "|    total_timesteps | 3450880  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.7e+03      |\n",
      "|    ep_rew_mean          | 1.45e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1686         |\n",
      "|    time_elapsed         | 6796         |\n",
      "|    total_timesteps      | 3452928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058735316 |\n",
      "|    clip_fraction        | 0.0602       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.4          |\n",
      "|    explained_variance   | 0.879        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 332          |\n",
      "|    n_updates            | 32760        |\n",
      "|    policy_gradient_loss | -0.00652     |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 4.51e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.7e+03      |\n",
      "|    ep_rew_mean          | 1.45e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 508          |\n",
      "|    iterations           | 1687         |\n",
      "|    time_elapsed         | 6798         |\n",
      "|    total_timesteps      | 3454976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016744247 |\n",
      "|    clip_fraction        | 0.0296       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.4          |\n",
      "|    explained_variance   | 0.602        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.52e+06     |\n",
      "|    n_updates            | 32770        |\n",
      "|    policy_gradient_loss | 0.0019       |\n",
      "|    std                  | 0.155        |\n",
      "|    value_loss           | 5.35e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3455000, episode_reward=20999.04 +/- 4736.07\n",
      "Episode length: 3723.80 +/- 11.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.72e+03    |\n",
      "|    mean_reward          | 2.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3455000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013329363 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 85.5        |\n",
      "|    n_updates            | 32780       |\n",
      "|    policy_gradient_loss | 0.00241     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 636         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.72e+03 |\n",
      "|    ep_rew_mean     | 1.45e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 1688     |\n",
      "|    time_elapsed    | 6809     |\n",
      "|    total_timesteps | 3457024  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.73e+03   |\n",
      "|    ep_rew_mean          | 1.44e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 507        |\n",
      "|    iterations           | 1689       |\n",
      "|    time_elapsed         | 6811       |\n",
      "|    total_timesteps      | 3459072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01393223 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.4        |\n",
      "|    explained_variance   | 0.801      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.71e+03   |\n",
      "|    n_updates            | 32790      |\n",
      "|    policy_gradient_loss | 0.0139     |\n",
      "|    std                  | 0.154      |\n",
      "|    value_loss           | 6.32e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3460000, episode_reward=17086.13 +/- 3809.08\n",
      "Episode length: 3370.40 +/- 12.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.37e+03    |\n",
      "|    mean_reward          | 1.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003083992 |\n",
      "|    clip_fraction        | 0.0296      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.82        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.62e+05    |\n",
      "|    n_updates            | 32800       |\n",
      "|    policy_gradient_loss | -1.38e-05   |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 1.21e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.75e+03 |\n",
      "|    ep_rew_mean     | 1.44e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 1690     |\n",
      "|    time_elapsed    | 6821     |\n",
      "|    total_timesteps | 3461120  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | 1.44e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1691        |\n",
      "|    time_elapsed         | 6822        |\n",
      "|    total_timesteps      | 3463168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012216785 |\n",
      "|    clip_fraction        | 0.0343      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.97e+04    |\n",
      "|    n_updates            | 32810       |\n",
      "|    policy_gradient_loss | 0.00203     |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 5.6e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3465000, episode_reward=27251.93 +/- 920.37\n",
      "Episode length: 3616.80 +/- 10.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.62e+03    |\n",
      "|    mean_reward          | 2.73e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3465000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004275889 |\n",
      "|    clip_fraction        | 0.0262      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.26e+03    |\n",
      "|    n_updates            | 32820       |\n",
      "|    policy_gradient_loss | -0.00312    |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 2.47e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.76e+03 |\n",
      "|    ep_rew_mean     | 1.44e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 1692     |\n",
      "|    time_elapsed    | 6833     |\n",
      "|    total_timesteps | 3465216  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.78e+03    |\n",
      "|    ep_rew_mean          | 1.45e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 1693        |\n",
      "|    time_elapsed         | 6835        |\n",
      "|    total_timesteps      | 3467264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020262375 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.4        |\n",
      "|    n_updates            | 32830       |\n",
      "|    policy_gradient_loss | 0.00717     |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 75          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.8e+03    |\n",
      "|    ep_rew_mean          | 1.47e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 507        |\n",
      "|    iterations           | 1694       |\n",
      "|    time_elapsed         | 6837       |\n",
      "|    total_timesteps      | 3469312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07377595 |\n",
      "|    clip_fraction        | 0.592      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.42       |\n",
      "|    explained_variance   | 0.936      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.11e+04   |\n",
      "|    n_updates            | 32840      |\n",
      "|    policy_gradient_loss | 0.0299     |\n",
      "|    std                  | 0.154      |\n",
      "|    value_loss           | 2.38e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3470000, episode_reward=42164.28 +/- 2151.87\n",
      "Episode length: 4874.80 +/- 15.25\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.87e+03    |\n",
      "|    mean_reward          | 4.22e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009706179 |\n",
      "|    clip_fraction        | 0.062       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+04    |\n",
      "|    n_updates            | 32850       |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 8.23e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.8e+03  |\n",
      "|    ep_rew_mean     | 1.47e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 1695     |\n",
      "|    time_elapsed    | 6850     |\n",
      "|    total_timesteps | 3471360  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.82e+03     |\n",
      "|    ep_rew_mean          | 1.48e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 1696         |\n",
      "|    time_elapsed         | 6852         |\n",
      "|    total_timesteps      | 3473408      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150014805 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.42         |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 31.4         |\n",
      "|    n_updates            | 32860        |\n",
      "|    policy_gradient_loss | 0.00172      |\n",
      "|    std                  | 0.154        |\n",
      "|    value_loss           | 151          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3475000, episode_reward=46851.56 +/- 5834.27\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 4.69e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3475000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034845031 |\n",
      "|    clip_fraction        | 0.0666       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.42         |\n",
      "|    explained_variance   | 0.982        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 284          |\n",
      "|    n_updates            | 32870        |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    std                  | 0.154        |\n",
      "|    value_loss           | 3.55e+03     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.82e+03 |\n",
      "|    ep_rew_mean     | 1.48e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 1697     |\n",
      "|    time_elapsed    | 6866     |\n",
      "|    total_timesteps | 3475456  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.85e+03    |\n",
      "|    ep_rew_mean          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1698        |\n",
      "|    time_elapsed         | 6867        |\n",
      "|    total_timesteps      | 3477504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007126162 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66          |\n",
      "|    n_updates            | 32880       |\n",
      "|    policy_gradient_loss | 0.00405     |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 416         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.85e+03    |\n",
      "|    ep_rew_mean          | 1.52e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 1699        |\n",
      "|    time_elapsed         | 6869        |\n",
      "|    total_timesteps      | 3479552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004289562 |\n",
      "|    clip_fraction        | 0.0312      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 188         |\n",
      "|    n_updates            | 32890       |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 5.31e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3480000, episode_reward=33357.62 +/- 3966.38\n",
      "Episode length: 3302.40 +/- 7.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.3e+03      |\n",
      "|    mean_reward          | 3.34e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3480000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076393755 |\n",
      "|    clip_fraction        | 0.0896       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.43         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 118          |\n",
      "|    n_updates            | 32900        |\n",
      "|    policy_gradient_loss | 0.00236      |\n",
      "|    std                  | 0.154        |\n",
      "|    value_loss           | 948          |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.87e+03 |\n",
      "|    ep_rew_mean     | 1.54e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 506      |\n",
      "|    iterations      | 1700     |\n",
      "|    time_elapsed    | 6879     |\n",
      "|    total_timesteps | 3481600  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.88e+03     |\n",
      "|    ep_rew_mean          | 1.55e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 1701         |\n",
      "|    time_elapsed         | 6881         |\n",
      "|    total_timesteps      | 3483648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072538005 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.43         |\n",
      "|    explained_variance   | 0.829        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.23e+04     |\n",
      "|    n_updates            | 32910        |\n",
      "|    policy_gradient_loss | 0.00349      |\n",
      "|    std                  | 0.154        |\n",
      "|    value_loss           | 2.21e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3485000, episode_reward=43977.93 +/- 4762.24\n",
      "Episode length: 4970.00 +/- 60.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.97e+03     |\n",
      "|    mean_reward          | 4.4e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3485000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051886905 |\n",
      "|    clip_fraction        | 0.0148       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.43         |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.78e+04     |\n",
      "|    n_updates            | 32920        |\n",
      "|    policy_gradient_loss | -0.00143     |\n",
      "|    std                  | 0.154        |\n",
      "|    value_loss           | 4.35e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.88e+03 |\n",
      "|    ep_rew_mean     | 1.55e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1702     |\n",
      "|    time_elapsed    | 6895     |\n",
      "|    total_timesteps | 3485696  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.9e+03    |\n",
      "|    ep_rew_mean          | 1.66e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1703       |\n",
      "|    time_elapsed         | 6897       |\n",
      "|    total_timesteps      | 3487744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01312045 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.43       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 40.4       |\n",
      "|    n_updates            | 32930      |\n",
      "|    policy_gradient_loss | 0.00345    |\n",
      "|    std                  | 0.153      |\n",
      "|    value_loss           | 312        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.9e+03     |\n",
      "|    ep_rew_mean          | 1.66e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1704        |\n",
      "|    time_elapsed         | 6898        |\n",
      "|    total_timesteps      | 3489792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016023254 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.43        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 132         |\n",
      "|    n_updates            | 32940       |\n",
      "|    policy_gradient_loss | 0.00488     |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 3.22e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3490000, episode_reward=-9073.62 +/- 34394.48\n",
      "Episode length: 4094.80 +/- 24.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.09e+03    |\n",
      "|    mean_reward          | -9.07e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017249681 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.44        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 329         |\n",
      "|    n_updates            | 32950       |\n",
      "|    policy_gradient_loss | -0.000953   |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 683         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.91e+03 |\n",
      "|    ep_rew_mean     | 1.67e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1705     |\n",
      "|    time_elapsed    | 6910     |\n",
      "|    total_timesteps | 3491840  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.92e+03    |\n",
      "|    ep_rew_mean          | 1.67e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1706        |\n",
      "|    time_elapsed         | 6912        |\n",
      "|    total_timesteps      | 3493888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023518324 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.44        |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.1        |\n",
      "|    n_updates            | 32960       |\n",
      "|    policy_gradient_loss | 0.019       |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 3.3e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3495000, episode_reward=27726.84 +/- 3297.27\n",
      "Episode length: 3380.60 +/- 14.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.38e+03    |\n",
      "|    mean_reward          | 2.77e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3495000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008077558 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.96        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.1        |\n",
      "|    n_updates            | 32970       |\n",
      "|    policy_gradient_loss | 0.00325     |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 3.48e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.93e+03 |\n",
      "|    ep_rew_mean     | 1.67e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1707     |\n",
      "|    time_elapsed    | 6922     |\n",
      "|    total_timesteps | 3495936  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.93e+03     |\n",
      "|    ep_rew_mean          | 1.67e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 1708         |\n",
      "|    time_elapsed         | 6924         |\n",
      "|    total_timesteps      | 3497984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070027825 |\n",
      "|    clip_fraction        | 0.0732       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 144          |\n",
      "|    n_updates            | 32980        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    std                  | 0.152        |\n",
      "|    value_loss           | 3.27e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3500000, episode_reward=33784.35 +/- 2922.56\n",
      "Episode length: 3604.60 +/- 8.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.6e+03      |\n",
      "|    mean_reward          | 3.38e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3500000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083164945 |\n",
      "|    clip_fraction        | 0.257        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.46         |\n",
      "|    explained_variance   | 0.999        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 32           |\n",
      "|    n_updates            | 32990        |\n",
      "|    policy_gradient_loss | 0.017        |\n",
      "|    std                  | 0.152        |\n",
      "|    value_loss           | 65.7         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.94e+03 |\n",
      "|    ep_rew_mean     | 1.66e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1709     |\n",
      "|    time_elapsed    | 6934     |\n",
      "|    total_timesteps | 3500032  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.94e+03    |\n",
      "|    ep_rew_mean          | 1.66e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1710        |\n",
      "|    time_elapsed         | 6936        |\n",
      "|    total_timesteps      | 3502080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015138894 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.46        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 33000       |\n",
      "|    policy_gradient_loss | 0.00177     |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 736         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.95e+03    |\n",
      "|    ep_rew_mean          | 1.67e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1711        |\n",
      "|    time_elapsed         | 6938        |\n",
      "|    total_timesteps      | 3504128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013637381 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.46        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.5        |\n",
      "|    n_updates            | 33010       |\n",
      "|    policy_gradient_loss | -0.000644   |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 189         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3505000, episode_reward=22987.69 +/- 3769.20\n",
      "Episode length: 3195.60 +/- 8.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.2e+03     |\n",
      "|    mean_reward          | 2.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3505000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016121902 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.9        |\n",
      "|    n_updates            | 33020       |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 62.4        |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.96e+03 |\n",
      "|    ep_rew_mean     | 1.68e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1712     |\n",
      "|    time_elapsed    | 6947     |\n",
      "|    total_timesteps | 3506176  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.97e+03   |\n",
      "|    ep_rew_mean          | 1.67e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 1713       |\n",
      "|    time_elapsed         | 6949       |\n",
      "|    total_timesteps      | 3508224    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01018606 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.44       |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 386        |\n",
      "|    n_updates            | 33030      |\n",
      "|    policy_gradient_loss | -0.00271   |\n",
      "|    std                  | 0.153      |\n",
      "|    value_loss           | 3.19e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3510000, episode_reward=25911.53 +/- 3846.06\n",
      "Episode length: 3505.40 +/- 9.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.51e+03     |\n",
      "|    mean_reward          | 2.59e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3510000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067930007 |\n",
      "|    clip_fraction        | 0.116        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.44         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 81.4         |\n",
      "|    n_updates            | 33040        |\n",
      "|    policy_gradient_loss | 0.000922     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 631          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.96e+03 |\n",
      "|    ep_rew_mean     | 1.67e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1714     |\n",
      "|    time_elapsed    | 6959     |\n",
      "|    total_timesteps | 3510272  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.96e+03    |\n",
      "|    ep_rew_mean          | 1.67e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1715        |\n",
      "|    time_elapsed         | 6961        |\n",
      "|    total_timesteps      | 3512320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018243873 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.44        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 238         |\n",
      "|    n_updates            | 33050       |\n",
      "|    policy_gradient_loss | 0.00303     |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 404         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.97e+03    |\n",
      "|    ep_rew_mean          | 1.66e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1716        |\n",
      "|    time_elapsed         | 6963        |\n",
      "|    total_timesteps      | 3514368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051703453 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.44        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 17          |\n",
      "|    n_updates            | 33060       |\n",
      "|    policy_gradient_loss | 0.0139      |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 45.6        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3515000, episode_reward=23416.55 +/- 3764.19\n",
      "Episode length: 2416.40 +/- 6.62\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.42e+03     |\n",
      "|    mean_reward          | 2.34e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3515000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0110848015 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.44         |\n",
      "|    explained_variance   | 0.975        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 75.3         |\n",
      "|    n_updates            | 33070        |\n",
      "|    policy_gradient_loss | 0.000604     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 2.68e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.97e+03 |\n",
      "|    ep_rew_mean     | 1.65e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1717     |\n",
      "|    time_elapsed    | 6971     |\n",
      "|    total_timesteps | 3516416  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.94e+03    |\n",
      "|    ep_rew_mean          | 1.61e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1718        |\n",
      "|    time_elapsed         | 6973        |\n",
      "|    total_timesteps      | 3518464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016047478 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 515         |\n",
      "|    n_updates            | 33080       |\n",
      "|    policy_gradient_loss | 0.00448     |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 2.33e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3520000, episode_reward=22190.32 +/- 5521.52\n",
      "Episode length: 2257.20 +/- 17.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.26e+03    |\n",
      "|    mean_reward          | 2.22e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042120807 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 311         |\n",
      "|    n_updates            | 33090       |\n",
      "|    policy_gradient_loss | 0.00825     |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 1.07e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.91e+03 |\n",
      "|    ep_rew_mean     | 1.56e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1719     |\n",
      "|    time_elapsed    | 6980     |\n",
      "|    total_timesteps | 3520512  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.91e+03    |\n",
      "|    ep_rew_mean          | 1.56e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1720        |\n",
      "|    time_elapsed         | 6982        |\n",
      "|    total_timesteps      | 3522560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010911872 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.43        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 257         |\n",
      "|    n_updates            | 33100       |\n",
      "|    policy_gradient_loss | -0.000708   |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 505         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.89e+03    |\n",
      "|    ep_rew_mean          | 1.5e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1721        |\n",
      "|    time_elapsed         | 6984        |\n",
      "|    total_timesteps      | 3524608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017436512 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16          |\n",
      "|    n_updates            | 33110       |\n",
      "|    policy_gradient_loss | 0.00492     |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 49.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3525000, episode_reward=19358.32 +/- 4902.02\n",
      "Episode length: 3078.00 +/- 12.71\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.08e+03   |\n",
      "|    mean_reward          | 1.94e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3525000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02043616 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.42       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.1       |\n",
      "|    n_updates            | 33120      |\n",
      "|    policy_gradient_loss | -0.000693  |\n",
      "|    std                  | 0.154      |\n",
      "|    value_loss           | 1.87e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.86e+03 |\n",
      "|    ep_rew_mean     | 1.45e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1722     |\n",
      "|    time_elapsed    | 6993     |\n",
      "|    total_timesteps | 3526656  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.84e+03    |\n",
      "|    ep_rew_mean          | 1.41e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1723        |\n",
      "|    time_elapsed         | 6995        |\n",
      "|    total_timesteps      | 3528704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011083157 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 207         |\n",
      "|    n_updates            | 33130       |\n",
      "|    policy_gradient_loss | 0.000692    |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 571         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3530000, episode_reward=23205.02 +/- 4315.35\n",
      "Episode length: 2146.00 +/- 14.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.15e+03    |\n",
      "|    mean_reward          | 2.32e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025566885 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 20.6        |\n",
      "|    n_updates            | 33140       |\n",
      "|    policy_gradient_loss | 0.0049      |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 91.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.83e+03 |\n",
      "|    ep_rew_mean     | 1.45e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1724     |\n",
      "|    time_elapsed    | 7002     |\n",
      "|    total_timesteps | 3530752  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.82e+03    |\n",
      "|    ep_rew_mean          | 1.43e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1725        |\n",
      "|    time_elapsed         | 7003        |\n",
      "|    total_timesteps      | 3532800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017949643 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.2        |\n",
      "|    n_updates            | 33150       |\n",
      "|    policy_gradient_loss | 0.000108    |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 1.36e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.8e+03     |\n",
      "|    ep_rew_mean          | 1.41e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1726        |\n",
      "|    time_elapsed         | 7005        |\n",
      "|    total_timesteps      | 3534848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035428487 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.4         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 15.5        |\n",
      "|    n_updates            | 33160       |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 98.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3535000, episode_reward=25239.66 +/- 3573.79\n",
      "Episode length: 2118.60 +/- 12.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.12e+03    |\n",
      "|    mean_reward          | 2.52e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3535000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014328867 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.84e+04    |\n",
      "|    n_updates            | 33170       |\n",
      "|    policy_gradient_loss | 0.00212     |\n",
      "|    std                  | 0.155       |\n",
      "|    value_loss           | 8.7e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.79e+03 |\n",
      "|    ep_rew_mean     | 1.39e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1727     |\n",
      "|    time_elapsed    | 7012     |\n",
      "|    total_timesteps | 3536896  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.78e+03    |\n",
      "|    ep_rew_mean          | 1.35e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1728        |\n",
      "|    time_elapsed         | 7014        |\n",
      "|    total_timesteps      | 3538944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016640078 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.41        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79          |\n",
      "|    n_updates            | 33180       |\n",
      "|    policy_gradient_loss | 0.00487     |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 101         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3540000, episode_reward=25286.32 +/- 4401.94\n",
      "Episode length: 2332.80 +/- 11.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.33e+03    |\n",
      "|    mean_reward          | 2.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014215974 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 209         |\n",
      "|    n_updates            | 33190       |\n",
      "|    policy_gradient_loss | -0.000877   |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 2.28e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.78e+03 |\n",
      "|    ep_rew_mean     | 1.35e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1729     |\n",
      "|    time_elapsed    | 7021     |\n",
      "|    total_timesteps | 3540992  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.75e+03    |\n",
      "|    ep_rew_mean          | 1.37e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1730        |\n",
      "|    time_elapsed         | 7023        |\n",
      "|    total_timesteps      | 3543040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022540012 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.42        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66          |\n",
      "|    n_updates            | 33200       |\n",
      "|    policy_gradient_loss | 0.014       |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 208         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3545000, episode_reward=25371.24 +/- 3472.24\n",
      "Episode length: 2300.60 +/- 10.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.3e+03    |\n",
      "|    mean_reward          | 2.54e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3545000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06271327 |\n",
      "|    clip_fraction        | 0.223      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.42       |\n",
      "|    explained_variance   | 0.979      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 78         |\n",
      "|    n_updates            | 33210      |\n",
      "|    policy_gradient_loss | -0.000101  |\n",
      "|    std                  | 0.154      |\n",
      "|    value_loss           | 7.67e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.72e+03 |\n",
      "|    ep_rew_mean     | 1.33e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1731     |\n",
      "|    time_elapsed    | 7030     |\n",
      "|    total_timesteps | 3545088  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.7e+03      |\n",
      "|    ep_rew_mean          | 1.3e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1732         |\n",
      "|    time_elapsed         | 7032         |\n",
      "|    total_timesteps      | 3547136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0093025975 |\n",
      "|    clip_fraction        | 0.13         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.42         |\n",
      "|    explained_variance   | 0.988        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 45.2         |\n",
      "|    n_updates            | 33220        |\n",
      "|    policy_gradient_loss | -0.00511     |\n",
      "|    std                  | 0.154        |\n",
      "|    value_loss           | 3.58e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.69e+03    |\n",
      "|    ep_rew_mean          | 1.31e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1733        |\n",
      "|    time_elapsed         | 7034        |\n",
      "|    total_timesteps      | 3549184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.049037285 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.43        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.5        |\n",
      "|    n_updates            | 33230       |\n",
      "|    policy_gradient_loss | 0.0353      |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 84.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3550000, episode_reward=32043.65 +/- 5276.91\n",
      "Episode length: 2468.80 +/- 12.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.47e+03    |\n",
      "|    mean_reward          | 3.2e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013206703 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.43        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.33e+04    |\n",
      "|    n_updates            | 33240       |\n",
      "|    policy_gradient_loss | -0.000862   |\n",
      "|    std                  | 0.154       |\n",
      "|    value_loss           | 3.88e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.68e+03 |\n",
      "|    ep_rew_mean     | 1.29e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1734     |\n",
      "|    time_elapsed    | 7042     |\n",
      "|    total_timesteps | 3551232  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.68e+03   |\n",
      "|    ep_rew_mean          | 1.37e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 1735       |\n",
      "|    time_elapsed         | 7044       |\n",
      "|    total_timesteps      | 3553280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00982118 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.43       |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.8       |\n",
      "|    n_updates            | 33250      |\n",
      "|    policy_gradient_loss | 0.000405   |\n",
      "|    std                  | 0.153      |\n",
      "|    value_loss           | 79.5       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3555000, episode_reward=37155.94 +/- 236.89\n",
      "Episode length: 2329.40 +/- 9.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.33e+03    |\n",
      "|    mean_reward          | 3.72e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3555000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012747038 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.9        |\n",
      "|    n_updates            | 33260       |\n",
      "|    policy_gradient_loss | 0.00183     |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 139         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.67e+03 |\n",
      "|    ep_rew_mean     | 1.44e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1736     |\n",
      "|    time_elapsed    | 7051     |\n",
      "|    total_timesteps | 3555328  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.67e+03    |\n",
      "|    ep_rew_mean          | 1.44e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1737        |\n",
      "|    time_elapsed         | 7053        |\n",
      "|    total_timesteps      | 3557376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048926007 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.4        |\n",
      "|    n_updates            | 33270       |\n",
      "|    policy_gradient_loss | 0.0205      |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 4.23e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.66e+03   |\n",
      "|    ep_rew_mean          | 1.3e+04    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 1738       |\n",
      "|    time_elapsed         | 7055       |\n",
      "|    total_timesteps      | 3559424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02519213 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.45       |\n",
      "|    explained_variance   | 0.988      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.5e+04    |\n",
      "|    n_updates            | 33280      |\n",
      "|    policy_gradient_loss | 5.49e-05   |\n",
      "|    std                  | 0.153      |\n",
      "|    value_loss           | 4.41e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3560000, episode_reward=30638.48 +/- 2053.78\n",
      "Episode length: 2307.20 +/- 11.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.31e+03    |\n",
      "|    mean_reward          | 3.06e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056733344 |\n",
      "|    clip_fraction        | 0.506       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.95e+06    |\n",
      "|    n_updates            | 33290       |\n",
      "|    policy_gradient_loss | 0.0189      |\n",
      "|    std                  | 0.153       |\n",
      "|    value_loss           | 2.31e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.65e+03 |\n",
      "|    ep_rew_mean     | 1.14e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1739     |\n",
      "|    time_elapsed    | 7062     |\n",
      "|    total_timesteps | 3561472  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.64e+03     |\n",
      "|    ep_rew_mean          | 1.08e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1740         |\n",
      "|    time_elapsed         | 7064         |\n",
      "|    total_timesteps      | 3563520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010509085 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.376        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.01e+07     |\n",
      "|    n_updates            | 33300        |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 2.74e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3565000, episode_reward=33558.42 +/- 3635.84\n",
      "Episode length: 2275.00 +/- 17.33\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.28e+03     |\n",
      "|    mean_reward          | 3.36e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3565000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0013461547 |\n",
      "|    clip_fraction        | 0.00503      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.98e+06     |\n",
      "|    n_updates            | 33310        |\n",
      "|    policy_gradient_loss | -0.00408     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 2.65e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.63e+03 |\n",
      "|    ep_rew_mean     | 9.18e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1741     |\n",
      "|    time_elapsed    | 7071     |\n",
      "|    total_timesteps | 3565568  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.62e+03     |\n",
      "|    ep_rew_mean          | 9.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1742         |\n",
      "|    time_elapsed         | 7073         |\n",
      "|    total_timesteps      | 3567616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032361606 |\n",
      "|    clip_fraction        | 0.00806      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.454        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.51e+07     |\n",
      "|    n_updates            | 33320        |\n",
      "|    policy_gradient_loss | -0.00577     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 2.64e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.6e+03      |\n",
      "|    ep_rew_mean          | 7.57e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1743         |\n",
      "|    time_elapsed         | 7075         |\n",
      "|    total_timesteps      | 3569664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015714385 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.76e+03     |\n",
      "|    n_updates            | 33330        |\n",
      "|    policy_gradient_loss | -0.00109     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 5.91e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3570000, episode_reward=35906.81 +/- 2358.78\n",
      "Episode length: 2229.20 +/- 6.24\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.23e+03     |\n",
      "|    mean_reward          | 3.59e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3570000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008067684 |\n",
      "|    clip_fraction        | 0.00112      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79e+07     |\n",
      "|    n_updates            | 33340        |\n",
      "|    policy_gradient_loss | -0.00181     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 2.65e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.58e+03 |\n",
      "|    ep_rew_mean     | 7.57e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1744     |\n",
      "|    time_elapsed    | 7082     |\n",
      "|    total_timesteps | 3571712  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.57e+03     |\n",
      "|    ep_rew_mean          | 5.97e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1745         |\n",
      "|    time_elapsed         | 7084         |\n",
      "|    total_timesteps      | 3573760      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017156564 |\n",
      "|    clip_fraction        | 0.00566      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.15e+03     |\n",
      "|    n_updates            | 33350        |\n",
      "|    policy_gradient_loss | -0.00317     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 7.84e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3575000, episode_reward=36985.33 +/- 2159.83\n",
      "Episode length: 2300.00 +/- 12.92\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.3e+03      |\n",
      "|    mean_reward          | 3.7e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3575000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017510199 |\n",
      "|    clip_fraction        | 0.00718      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33e+07     |\n",
      "|    n_updates            | 33360        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 2.58e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.56e+03 |\n",
      "|    ep_rew_mean     | 6.02e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1746     |\n",
      "|    time_elapsed    | 7091     |\n",
      "|    total_timesteps | 3575808  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.56e+03     |\n",
      "|    ep_rew_mean          | 6.22e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1747         |\n",
      "|    time_elapsed         | 7093         |\n",
      "|    total_timesteps      | 3577856      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033130366 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.52e+03     |\n",
      "|    n_updates            | 33370        |\n",
      "|    policy_gradient_loss | -0.00358     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 8e+04        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.55e+03     |\n",
      "|    ep_rew_mean          | 6.28e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1748         |\n",
      "|    time_elapsed         | 7095         |\n",
      "|    total_timesteps      | 3579904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042837765 |\n",
      "|    clip_fraction        | 0.0214       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.55e+03     |\n",
      "|    n_updates            | 33380        |\n",
      "|    policy_gradient_loss | -0.00515     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 3.89e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3580000, episode_reward=33965.58 +/- 3049.50\n",
      "Episode length: 2157.60 +/- 11.29\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.16e+03     |\n",
      "|    mean_reward          | 3.4e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3580000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068018725 |\n",
      "|    clip_fraction        | 0.0608       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.958        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.79e+03     |\n",
      "|    n_updates            | 33390        |\n",
      "|    policy_gradient_loss | -0.00693     |\n",
      "|    std                  | 0.153        |\n",
      "|    value_loss           | 2.16e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.55e+03 |\n",
      "|    ep_rew_mean     | 6.93e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1749     |\n",
      "|    time_elapsed    | 7102     |\n",
      "|    total_timesteps | 3581952  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | 7.03e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1750        |\n",
      "|    time_elapsed         | 7104        |\n",
      "|    total_timesteps      | 3584000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012861272 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 696         |\n",
      "|    n_updates            | 33400       |\n",
      "|    policy_gradient_loss | -0.000827   |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 2.51e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3585000, episode_reward=32397.11 +/- 3453.86\n",
      "Episode length: 2094.20 +/- 11.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.09e+03    |\n",
      "|    mean_reward          | 3.24e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3585000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013724537 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.46        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 136         |\n",
      "|    n_updates            | 33410       |\n",
      "|    policy_gradient_loss | 0.00693     |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 1.06e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.52e+03 |\n",
      "|    ep_rew_mean     | 7.08e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1751     |\n",
      "|    time_elapsed    | 7111     |\n",
      "|    total_timesteps | 3586048  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.51e+03   |\n",
      "|    ep_rew_mean          | 6.04e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 1752       |\n",
      "|    time_elapsed         | 7113       |\n",
      "|    total_timesteps      | 3588096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03068217 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.45       |\n",
      "|    explained_variance   | 0.972      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 120        |\n",
      "|    n_updates            | 33420      |\n",
      "|    policy_gradient_loss | 0.00589    |\n",
      "|    std                  | 0.152      |\n",
      "|    value_loss           | 3.82e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3590000, episode_reward=30823.44 +/- 3309.94\n",
      "Episode length: 1989.00 +/- 12.88\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.99e+03   |\n",
      "|    mean_reward          | 3.08e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3590000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02122616 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.45       |\n",
      "|    explained_variance   | 0.389      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.38e+07   |\n",
      "|    n_updates            | 33430      |\n",
      "|    policy_gradient_loss | 0.00704    |\n",
      "|    std                  | 0.152      |\n",
      "|    value_loss           | 2.57e+07   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.48e+03 |\n",
      "|    ep_rew_mean     | 4.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1753     |\n",
      "|    time_elapsed    | 7119     |\n",
      "|    total_timesteps | 3590144  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.46e+03     |\n",
      "|    ep_rew_mean          | 1.34e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1754         |\n",
      "|    time_elapsed         | 7121         |\n",
      "|    total_timesteps      | 3592192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003609043 |\n",
      "|    clip_fraction        | 0.000635     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.01e+07     |\n",
      "|    n_updates            | 33440        |\n",
      "|    policy_gradient_loss | -0.0013      |\n",
      "|    std                  | 0.152        |\n",
      "|    value_loss           | 3.32e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.46e+03     |\n",
      "|    ep_rew_mean          | -195         |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1755         |\n",
      "|    time_elapsed         | 7123         |\n",
      "|    total_timesteps      | 3594240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004583458 |\n",
      "|    clip_fraction        | 0.000342     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.399        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.9e+07      |\n",
      "|    n_updates            | 33450        |\n",
      "|    policy_gradient_loss | -0.00192     |\n",
      "|    std                  | 0.152        |\n",
      "|    value_loss           | 5.36e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3595000, episode_reward=31576.59 +/- 3660.46\n",
      "Episode length: 2002.60 +/- 6.65\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2e+03        |\n",
      "|    mean_reward          | 3.16e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3595000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048193596 |\n",
      "|    clip_fraction        | 0.0242       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.444        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.49e+06     |\n",
      "|    n_updates            | 33460        |\n",
      "|    policy_gradient_loss | -0.00346     |\n",
      "|    std                  | 0.152        |\n",
      "|    value_loss           | 2.86e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.44e+03  |\n",
      "|    ep_rew_mean     | -1.02e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 1756      |\n",
      "|    time_elapsed    | 7130      |\n",
      "|    total_timesteps | 3596288   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | -948        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1757        |\n",
      "|    time_elapsed         | 7131        |\n",
      "|    total_timesteps      | 3598336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010216966 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.55e+07    |\n",
      "|    n_updates            | 33470       |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 2.63e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3600000, episode_reward=-10610.68 +/- 85933.15\n",
      "Episode length: 1546.80 +/- 716.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.55e+03     |\n",
      "|    mean_reward          | -1.06e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3600000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018769298 |\n",
      "|    clip_fraction        | 0.00273      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.45         |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.17e+03     |\n",
      "|    n_updates            | 33480        |\n",
      "|    policy_gradient_loss | -0.00057     |\n",
      "|    std                  | 0.152        |\n",
      "|    value_loss           | 3.31e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.43e+03 |\n",
      "|    ep_rew_mean     | -859     |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1758     |\n",
      "|    time_elapsed    | 7137     |\n",
      "|    total_timesteps | 3600384  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.43e+03   |\n",
      "|    ep_rew_mean          | -709       |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 1759       |\n",
      "|    time_elapsed         | 7139       |\n",
      "|    total_timesteps      | 3602432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00793065 |\n",
      "|    clip_fraction        | 0.0556     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.45       |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.2e+03    |\n",
      "|    n_updates            | 33490      |\n",
      "|    policy_gradient_loss | -0.00609   |\n",
      "|    std                  | 0.152      |\n",
      "|    value_loss           | 1.4e+04    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+03    |\n",
      "|    ep_rew_mean          | -379        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1760        |\n",
      "|    time_elapsed         | 7141        |\n",
      "|    total_timesteps      | 3604480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008433877 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.45        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 939         |\n",
      "|    n_updates            | 33500       |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    std                  | 0.152       |\n",
      "|    value_loss           | 2.81e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3605000, episode_reward=26631.75 +/- 3492.80\n",
      "Episode length: 1746.00 +/- 9.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.75e+03    |\n",
      "|    mean_reward          | 2.66e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3605000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012309169 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.46        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 609         |\n",
      "|    n_updates            | 33510       |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    std                  | 0.151       |\n",
      "|    value_loss           | 2.7e+03     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.4e+03  |\n",
      "|    ep_rew_mean     | -330     |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1761     |\n",
      "|    time_elapsed    | 7147     |\n",
      "|    total_timesteps | 3606528  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | -125        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1762        |\n",
      "|    time_elapsed         | 7149        |\n",
      "|    total_timesteps      | 3608576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026321307 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.47        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 33520       |\n",
      "|    policy_gradient_loss | 0.00357     |\n",
      "|    std                  | 0.151       |\n",
      "|    value_loss           | 436         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3610000, episode_reward=26509.65 +/- 3466.33\n",
      "Episode length: 1903.80 +/- 12.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.9e+03     |\n",
      "|    mean_reward          | 2.65e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017410478 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.49        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.37e+04    |\n",
      "|    n_updates            | 33530       |\n",
      "|    policy_gradient_loss | 0.00279     |\n",
      "|    std                  | 0.151       |\n",
      "|    value_loss           | 3.56e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.39e+03 |\n",
      "|    ep_rew_mean     | -182     |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1763     |\n",
      "|    time_elapsed    | 7155     |\n",
      "|    total_timesteps | 3610624  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | -31.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1764        |\n",
      "|    time_elapsed         | 7157        |\n",
      "|    total_timesteps      | 3612672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016101327 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.49        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 33540       |\n",
      "|    policy_gradient_loss | 0.00545     |\n",
      "|    std                  | 0.151       |\n",
      "|    value_loss           | 3.41e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | 132         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1765        |\n",
      "|    time_elapsed         | 7159        |\n",
      "|    total_timesteps      | 3614720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022845697 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.49        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.4        |\n",
      "|    n_updates            | 33550       |\n",
      "|    policy_gradient_loss | 0.00275     |\n",
      "|    std                  | 0.15        |\n",
      "|    value_loss           | 423         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3615000, episode_reward=35352.30 +/- 328.75\n",
      "Episode length: 2107.60 +/- 14.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.11e+03    |\n",
      "|    mean_reward          | 3.54e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3615000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017784312 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.5         |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 94          |\n",
      "|    n_updates            | 33560       |\n",
      "|    policy_gradient_loss | 1.08e-05    |\n",
      "|    std                  | 0.15        |\n",
      "|    value_loss           | 304         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.37e+03 |\n",
      "|    ep_rew_mean     | 611      |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1766     |\n",
      "|    time_elapsed    | 7165     |\n",
      "|    total_timesteps | 3616768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.37e+03    |\n",
      "|    ep_rew_mean          | 711         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1767        |\n",
      "|    time_elapsed         | 7167        |\n",
      "|    total_timesteps      | 3618816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017404411 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.51        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.9        |\n",
      "|    n_updates            | 33570       |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    std                  | 0.15        |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3620000, episode_reward=-62477.30 +/- 116692.23\n",
      "Episode length: 1685.60 +/- 665.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.69e+03    |\n",
      "|    mean_reward          | -6.25e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3620000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008711333 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.51        |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 477         |\n",
      "|    n_updates            | 33580       |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    std                  | 0.15        |\n",
      "|    value_loss           | 3.02e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.36e+03 |\n",
      "|    ep_rew_mean     | 814      |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1768     |\n",
      "|    time_elapsed    | 7173     |\n",
      "|    total_timesteps | 3620864  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.36e+03    |\n",
      "|    ep_rew_mean          | 906         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1769        |\n",
      "|    time_elapsed         | 7175        |\n",
      "|    total_timesteps      | 3622912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011719353 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.52        |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 104         |\n",
      "|    n_updates            | 33590       |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    std                  | 0.149       |\n",
      "|    value_loss           | 1.09e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.35e+03    |\n",
      "|    ep_rew_mean          | 1.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1770        |\n",
      "|    time_elapsed         | 7177        |\n",
      "|    total_timesteps      | 3624960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027122188 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.53        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 256         |\n",
      "|    n_updates            | 33600       |\n",
      "|    policy_gradient_loss | 0.00589     |\n",
      "|    std                  | 0.148       |\n",
      "|    value_loss           | 636         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3625000, episode_reward=33966.36 +/- 4354.87\n",
      "Episode length: 2415.40 +/- 17.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.42e+03    |\n",
      "|    mean_reward          | 3.4e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3625000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021522377 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.53        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.5        |\n",
      "|    n_updates            | 33610       |\n",
      "|    policy_gradient_loss | 0.00577     |\n",
      "|    std                  | 0.149       |\n",
      "|    value_loss           | 5.01e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.35e+03 |\n",
      "|    ep_rew_mean     | 1.18e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1771     |\n",
      "|    time_elapsed    | 7184     |\n",
      "|    total_timesteps | 3627008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.36e+03    |\n",
      "|    ep_rew_mean          | 2.8e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1772        |\n",
      "|    time_elapsed         | 7186        |\n",
      "|    total_timesteps      | 3629056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016117314 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.54        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 33620       |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    std                  | 0.148       |\n",
      "|    value_loss           | 58.2        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3630000, episode_reward=30147.57 +/- 4723.06\n",
      "Episode length: 2160.20 +/- 13.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.16e+03    |\n",
      "|    mean_reward          | 3.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021227973 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.57        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.5        |\n",
      "|    n_updates            | 33630       |\n",
      "|    policy_gradient_loss | 0.00297     |\n",
      "|    std                  | 0.147       |\n",
      "|    value_loss           | 200         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.35e+03 |\n",
      "|    ep_rew_mean     | 3.03e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1773     |\n",
      "|    time_elapsed    | 7193     |\n",
      "|    total_timesteps | 3631104  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | 3.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1774        |\n",
      "|    time_elapsed         | 7195        |\n",
      "|    total_timesteps      | 3633152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018477995 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 53.5        |\n",
      "|    n_updates            | 33640       |\n",
      "|    policy_gradient_loss | -0.00231    |\n",
      "|    std                  | 0.147       |\n",
      "|    value_loss           | 4.6e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3635000, episode_reward=27552.64 +/- 1788.13\n",
      "Episode length: 3165.80 +/- 8.61\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.17e+03   |\n",
      "|    mean_reward          | 2.76e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3635000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02177697 |\n",
      "|    clip_fraction        | 0.208      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.57       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.6       |\n",
      "|    n_updates            | 33650      |\n",
      "|    policy_gradient_loss | 0.00129    |\n",
      "|    std                  | 0.147      |\n",
      "|    value_loss           | 212        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.34e+03 |\n",
      "|    ep_rew_mean     | 3.36e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1775     |\n",
      "|    time_elapsed    | 7204     |\n",
      "|    total_timesteps | 3635200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | 3.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1776        |\n",
      "|    time_elapsed         | 7206        |\n",
      "|    total_timesteps      | 3637248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019907568 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.57        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 33660       |\n",
      "|    policy_gradient_loss | 0.005       |\n",
      "|    std                  | 0.146       |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | 3.48e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1777        |\n",
      "|    time_elapsed         | 7208        |\n",
      "|    total_timesteps      | 3639296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007631696 |\n",
      "|    clip_fraction        | 0.0994      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 262         |\n",
      "|    n_updates            | 33670       |\n",
      "|    policy_gradient_loss | -0.000339   |\n",
      "|    std                  | 0.146       |\n",
      "|    value_loss           | 5.92e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3640000, episode_reward=23224.25 +/- 6148.80\n",
      "Episode length: 3164.40 +/- 22.65\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.16e+03    |\n",
      "|    mean_reward          | 2.32e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014962464 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.5        |\n",
      "|    n_updates            | 33680       |\n",
      "|    policy_gradient_loss | 0.00543     |\n",
      "|    std                  | 0.146       |\n",
      "|    value_loss           | 118         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.34e+03 |\n",
      "|    ep_rew_mean     | 3.47e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1778     |\n",
      "|    time_elapsed    | 7218     |\n",
      "|    total_timesteps | 3641344  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.34e+03   |\n",
      "|    ep_rew_mean          | 4.67e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 1779       |\n",
      "|    time_elapsed         | 7219       |\n",
      "|    total_timesteps      | 3643392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00676971 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.59       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 136        |\n",
      "|    n_updates            | 33690      |\n",
      "|    policy_gradient_loss | 0.0037     |\n",
      "|    std                  | 0.146      |\n",
      "|    value_loss           | 1.84e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3645000, episode_reward=21533.83 +/- 3729.01\n",
      "Episode length: 3198.40 +/- 29.49\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.2e+03    |\n",
      "|    mean_reward          | 2.15e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3645000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02056965 |\n",
      "|    clip_fraction        | 0.114      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.58       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 70         |\n",
      "|    n_updates            | 33700      |\n",
      "|    policy_gradient_loss | -0.000575  |\n",
      "|    std                  | 0.147      |\n",
      "|    value_loss           | 449        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.35e+03 |\n",
      "|    ep_rew_mean     | 4.63e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1780     |\n",
      "|    time_elapsed    | 7229     |\n",
      "|    total_timesteps | 3645440  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.35e+03    |\n",
      "|    ep_rew_mean          | 4.63e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1781        |\n",
      "|    time_elapsed         | 7231        |\n",
      "|    total_timesteps      | 3647488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003788939 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.57        |\n",
      "|    explained_variance   | 0.459       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.96e+04    |\n",
      "|    n_updates            | 33710       |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    std                  | 0.147       |\n",
      "|    value_loss           | 2.35e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.35e+03    |\n",
      "|    ep_rew_mean          | 4.7e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1782        |\n",
      "|    time_elapsed         | 7233        |\n",
      "|    total_timesteps      | 3649536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010660438 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.57        |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+03    |\n",
      "|    n_updates            | 33720       |\n",
      "|    policy_gradient_loss | -0.00211    |\n",
      "|    std                  | 0.147       |\n",
      "|    value_loss           | 1.42e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3650000, episode_reward=34203.46 +/- 3105.50\n",
      "Episode length: 3608.00 +/- 25.85\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.61e+03   |\n",
      "|    mean_reward          | 3.42e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3650000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00528654 |\n",
      "|    clip_fraction        | 0.0398     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.57       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.71e+03   |\n",
      "|    n_updates            | 33730      |\n",
      "|    policy_gradient_loss | -0.00314   |\n",
      "|    std                  | 0.147      |\n",
      "|    value_loss           | 2.31e+04   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.35e+03 |\n",
      "|    ep_rew_mean     | 4.7e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1783     |\n",
      "|    time_elapsed    | 7243     |\n",
      "|    total_timesteps | 3651584  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.37e+03   |\n",
      "|    ep_rew_mean          | 4.83e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 1784       |\n",
      "|    time_elapsed         | 7245       |\n",
      "|    total_timesteps      | 3653632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01317716 |\n",
      "|    clip_fraction        | 0.106      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.56       |\n",
      "|    explained_variance   | 0.982      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 165        |\n",
      "|    n_updates            | 33740      |\n",
      "|    policy_gradient_loss | 0.00279    |\n",
      "|    std                  | 0.147      |\n",
      "|    value_loss           | 1.89e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3655000, episode_reward=36267.82 +/- 4326.09\n",
      "Episode length: 3571.80 +/- 19.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.57e+03    |\n",
      "|    mean_reward          | 3.63e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3655000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015168275 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.56        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 69.6        |\n",
      "|    n_updates            | 33750       |\n",
      "|    policy_gradient_loss | 0.00619     |\n",
      "|    std                  | 0.147       |\n",
      "|    value_loss           | 2.22e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.38e+03 |\n",
      "|    ep_rew_mean     | 4.85e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1785     |\n",
      "|    time_elapsed    | 7255     |\n",
      "|    total_timesteps | 3655680  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.4e+03      |\n",
      "|    ep_rew_mean          | 5.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1786         |\n",
      "|    time_elapsed         | 7257         |\n",
      "|    total_timesteps      | 3657728      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032890618 |\n",
      "|    clip_fraction        | 0.0828       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.57         |\n",
      "|    explained_variance   | 0.976        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 308          |\n",
      "|    n_updates            | 33760        |\n",
      "|    policy_gradient_loss | 0.000907     |\n",
      "|    std                  | 0.147        |\n",
      "|    value_loss           | 5.4e+03      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.4e+03     |\n",
      "|    ep_rew_mean          | 5.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1787        |\n",
      "|    time_elapsed         | 7259        |\n",
      "|    total_timesteps      | 3659776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015784666 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.57        |\n",
      "|    explained_variance   | 0.6         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.25e+03    |\n",
      "|    n_updates            | 33770       |\n",
      "|    policy_gradient_loss | 0.000665    |\n",
      "|    std                  | 0.147       |\n",
      "|    value_loss           | 1.47e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3660000, episode_reward=41072.70 +/- 4389.02\n",
      "Episode length: 3808.80 +/- 11.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.81e+03    |\n",
      "|    mean_reward          | 4.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018626995 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.57        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.3        |\n",
      "|    n_updates            | 33780       |\n",
      "|    policy_gradient_loss | 0.00935     |\n",
      "|    std                  | 0.146       |\n",
      "|    value_loss           | 215         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.41e+03 |\n",
      "|    ep_rew_mean     | 5.14e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1788     |\n",
      "|    time_elapsed    | 7270     |\n",
      "|    total_timesteps | 3661824  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.41e+03    |\n",
      "|    ep_rew_mean          | 5.14e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1789        |\n",
      "|    time_elapsed         | 7272        |\n",
      "|    total_timesteps      | 3663872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011921806 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.57        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 391         |\n",
      "|    n_updates            | 33790       |\n",
      "|    policy_gradient_loss | -0.00136    |\n",
      "|    std                  | 0.145       |\n",
      "|    value_loss           | 2.88e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3665000, episode_reward=41251.21 +/- 2368.03\n",
      "Episode length: 3725.20 +/- 34.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.73e+03    |\n",
      "|    mean_reward          | 4.13e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3665000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025731534 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 33800       |\n",
      "|    policy_gradient_loss | 0.00536     |\n",
      "|    std                  | 0.145       |\n",
      "|    value_loss           | 252         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.43e+03 |\n",
      "|    ep_rew_mean     | 5.22e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1790     |\n",
      "|    time_elapsed    | 7282     |\n",
      "|    total_timesteps | 3665920  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.43e+03    |\n",
      "|    ep_rew_mean          | 5.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1791        |\n",
      "|    time_elapsed         | 7284        |\n",
      "|    total_timesteps      | 3667968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016377514 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.8        |\n",
      "|    n_updates            | 33810       |\n",
      "|    policy_gradient_loss | 0.00612     |\n",
      "|    std                  | 0.145       |\n",
      "|    value_loss           | 382         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3670000, episode_reward=46082.47 +/- 1513.90\n",
      "Episode length: 3801.00 +/- 44.13\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.8e+03     |\n",
      "|    mean_reward          | 4.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012132625 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.59        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 33820       |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    std                  | 0.145       |\n",
      "|    value_loss           | 549         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.42e+03 |\n",
      "|    ep_rew_mean     | 4.35e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1792     |\n",
      "|    time_elapsed    | 7295     |\n",
      "|    total_timesteps | 3670016  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.42e+03     |\n",
      "|    ep_rew_mean          | 4.35e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1793         |\n",
      "|    time_elapsed         | 7297         |\n",
      "|    total_timesteps      | 3672064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057873093 |\n",
      "|    clip_fraction        | 0.0872       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.59         |\n",
      "|    explained_variance   | 0.344        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.51e+06     |\n",
      "|    n_updates            | 33830        |\n",
      "|    policy_gradient_loss | 0.000573     |\n",
      "|    std                  | 0.145        |\n",
      "|    value_loss           | 3.22e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | 3.99e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1794        |\n",
      "|    time_elapsed         | 7299        |\n",
      "|    total_timesteps      | 3674112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015141671 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 210         |\n",
      "|    n_updates            | 33840       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 647         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3675000, episode_reward=-117285.00 +/- 130592.87\n",
      "Episode length: 2064.40 +/- 1492.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.06e+03    |\n",
      "|    mean_reward          | -1.17e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3675000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005552633 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.238       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02e+06    |\n",
      "|    n_updates            | 33850       |\n",
      "|    policy_gradient_loss | 0.00574     |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 3.99e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.44e+03 |\n",
      "|    ep_rew_mean     | 3.99e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1795     |\n",
      "|    time_elapsed    | 7306     |\n",
      "|    total_timesteps | 3676160  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.47e+03    |\n",
      "|    ep_rew_mean          | 4.41e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1796        |\n",
      "|    time_elapsed         | 7307        |\n",
      "|    total_timesteps      | 3678208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015727105 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 168         |\n",
      "|    n_updates            | 33860       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 528         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3680000, episode_reward=-95734.41 +/- 100866.61\n",
      "Episode length: 1867.60 +/- 1272.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.87e+03    |\n",
      "|    mean_reward          | -9.57e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015221559 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91          |\n",
      "|    n_updates            | 33870       |\n",
      "|    policy_gradient_loss | 0.00213     |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 1.31e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.47e+03 |\n",
      "|    ep_rew_mean     | 4.41e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1797     |\n",
      "|    time_elapsed    | 7314     |\n",
      "|    total_timesteps | 3680256  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.47e+03    |\n",
      "|    ep_rew_mean          | 4.66e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1798        |\n",
      "|    time_elapsed         | 7316        |\n",
      "|    total_timesteps      | 3682304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008481112 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.61        |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 722         |\n",
      "|    n_updates            | 33880       |\n",
      "|    policy_gradient_loss | -0.00392    |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 2.57e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.47e+03    |\n",
      "|    ep_rew_mean          | 6.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1799        |\n",
      "|    time_elapsed         | 7318        |\n",
      "|    total_timesteps      | 3684352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020907909 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.61        |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 92.1        |\n",
      "|    n_updates            | 33890       |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    std                  | 0.144       |\n",
      "|    value_loss           | 3.09e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3685000, episode_reward=-19838.08 +/- 91170.72\n",
      "Episode length: 2896.60 +/- 1022.81\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.9e+03    |\n",
      "|    mean_reward          | -1.98e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3685000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01802004 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.61       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 55.6       |\n",
      "|    n_updates            | 33900      |\n",
      "|    policy_gradient_loss | -0.00494   |\n",
      "|    std                  | 0.143      |\n",
      "|    value_loss           | 456        |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.47e+03 |\n",
      "|    ep_rew_mean     | 6.09e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1800     |\n",
      "|    time_elapsed    | 7326     |\n",
      "|    total_timesteps | 3686400  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.47e+03     |\n",
      "|    ep_rew_mean          | 6.09e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1801         |\n",
      "|    time_elapsed         | 7328         |\n",
      "|    total_timesteps      | 3688448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052030487 |\n",
      "|    clip_fraction        | 0.0465       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.61         |\n",
      "|    explained_variance   | 0.984        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 414          |\n",
      "|    n_updates            | 33910        |\n",
      "|    policy_gradient_loss | -0.00129     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 4.1e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3690000, episode_reward=-125879.81 +/- 73293.59\n",
      "Episode length: 1299.40 +/- 1012.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.3e+03     |\n",
      "|    mean_reward          | -1.26e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3690000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035051964 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.61        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.2        |\n",
      "|    n_updates            | 33920       |\n",
      "|    policy_gradient_loss | 0.00607     |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 186         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.43e+03 |\n",
      "|    ep_rew_mean     | 2.8e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1802     |\n",
      "|    time_elapsed    | 7333     |\n",
      "|    total_timesteps | 3690496  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | 175         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1803        |\n",
      "|    time_elapsed         | 7335        |\n",
      "|    total_timesteps      | 3692544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005810743 |\n",
      "|    clip_fraction        | 0.0791      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.377       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6e+07       |\n",
      "|    n_updates            | 33930       |\n",
      "|    policy_gradient_loss | -0.000449   |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 6.35e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39e+03    |\n",
      "|    ep_rew_mean          | 339         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1804        |\n",
      "|    time_elapsed         | 7337        |\n",
      "|    total_timesteps      | 3694592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001736802 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.422       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.99e+07    |\n",
      "|    n_updates            | 33940       |\n",
      "|    policy_gradient_loss | -0.00382    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 5.84e+07    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3695000, episode_reward=-46401.36 +/- 86267.87\n",
      "Episode length: 1599.60 +/- 648.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.6e+03      |\n",
      "|    mean_reward          | -4.64e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3695000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039808173 |\n",
      "|    clip_fraction        | 0.012        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.6          |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+04     |\n",
      "|    n_updates            | 33950        |\n",
      "|    policy_gradient_loss | -0.00331     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 4.51e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.37e+03 |\n",
      "|    ep_rew_mean     | -1.1e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1805     |\n",
      "|    time_elapsed    | 7343     |\n",
      "|    total_timesteps | 3696640  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.35e+03     |\n",
      "|    ep_rew_mean          | -4.59e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1806         |\n",
      "|    time_elapsed         | 7344         |\n",
      "|    total_timesteps      | 3698688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009970326 |\n",
      "|    clip_fraction        | 0.00396      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.6          |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.03e+07     |\n",
      "|    n_updates            | 33960        |\n",
      "|    policy_gradient_loss | -0.00376     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 3e+07        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3700000, episode_reward=-85190.59 +/- 89663.72\n",
      "Episode length: 1334.00 +/- 658.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.33e+03     |\n",
      "|    mean_reward          | -8.52e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3700000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009056669 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.6          |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.18e+07     |\n",
      "|    n_updates            | 33970        |\n",
      "|    policy_gradient_loss | -0.00443     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 7.61e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.34e+03  |\n",
      "|    ep_rew_mean     | -4.55e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1807      |\n",
      "|    time_elapsed    | 7349      |\n",
      "|    total_timesteps | 3700736   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.33e+03    |\n",
      "|    ep_rew_mean          | -4.65e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1808        |\n",
      "|    time_elapsed         | 7351        |\n",
      "|    total_timesteps      | 3702784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004448293 |\n",
      "|    clip_fraction        | 0.0263      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.96e+03    |\n",
      "|    n_updates            | 33980       |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 5.61e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.28e+03    |\n",
      "|    ep_rew_mean          | -6.56e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1809        |\n",
      "|    time_elapsed         | 7353        |\n",
      "|    total_timesteps      | 3704832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007499706 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.2e+03     |\n",
      "|    n_updates            | 33990       |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 5.57e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3705000, episode_reward=-51246.33 +/- 91923.39\n",
      "Episode length: 1523.00 +/- 595.86\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.52e+03     |\n",
      "|    mean_reward          | -5.12e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3705000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038665528 |\n",
      "|    clip_fraction        | 0.0601       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.61         |\n",
      "|    explained_variance   | 0.352        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.2e+07      |\n",
      "|    n_updates            | 34000        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 3.36e+07     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.26e+03 |\n",
      "|    ep_rew_mean     | -6.8e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1810     |\n",
      "|    time_elapsed    | 7359     |\n",
      "|    total_timesteps | 3706880  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.25e+03    |\n",
      "|    ep_rew_mean          | -6.15e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1811        |\n",
      "|    time_elapsed         | 7361        |\n",
      "|    total_timesteps      | 3708928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002290528 |\n",
      "|    clip_fraction        | 0.00396     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.61        |\n",
      "|    explained_variance   | 0.743       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+05    |\n",
      "|    n_updates            | 34010       |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 2.69e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3710000, episode_reward=23609.38 +/- 5358.40\n",
      "Episode length: 1947.20 +/- 29.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.95e+03    |\n",
      "|    mean_reward          | 2.36e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011203442 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.79e+03    |\n",
      "|    n_updates            | 34020       |\n",
      "|    policy_gradient_loss | -0.00466    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.47e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.23e+03  |\n",
      "|    ep_rew_mean     | -6.28e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1812      |\n",
      "|    time_elapsed    | 7367      |\n",
      "|    total_timesteps | 3710976   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.22e+03   |\n",
      "|    ep_rew_mean          | -6.4e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 1813       |\n",
      "|    time_elapsed         | 7369       |\n",
      "|    total_timesteps      | 3713024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00801453 |\n",
      "|    clip_fraction        | 0.0707     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.6        |\n",
      "|    explained_variance   | 0.926      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 519        |\n",
      "|    n_updates            | 34030      |\n",
      "|    policy_gradient_loss | -0.00105   |\n",
      "|    std                  | 0.143      |\n",
      "|    value_loss           | 1.43e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3715000, episode_reward=23011.29 +/- 3701.25\n",
      "Episode length: 1999.80 +/- 15.50\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2e+03       |\n",
      "|    mean_reward          | 2.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3715000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010531366 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.61        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 523         |\n",
      "|    n_updates            | 34040       |\n",
      "|    policy_gradient_loss | -0.00233    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 5.39e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.18e+03  |\n",
      "|    ep_rew_mean     | -8.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1814      |\n",
      "|    time_elapsed    | 7376      |\n",
      "|    total_timesteps | 3715072   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.17e+03    |\n",
      "|    ep_rew_mean          | -8.37e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1815        |\n",
      "|    time_elapsed         | 7377        |\n",
      "|    total_timesteps      | 3717120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017715577 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.61        |\n",
      "|    explained_variance   | 0.277       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.23e+07    |\n",
      "|    n_updates            | 34050       |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 2.99e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.14e+03    |\n",
      "|    ep_rew_mean          | -1.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1816        |\n",
      "|    time_elapsed         | 7379        |\n",
      "|    total_timesteps      | 3719168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012344934 |\n",
      "|    clip_fraction        | 0.0992      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.61        |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 465         |\n",
      "|    n_updates            | 34060       |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 5.15e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3720000, episode_reward=25225.21 +/- 2913.57\n",
      "Episode length: 2044.40 +/- 11.22\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.04e+03   |\n",
      "|    mean_reward          | 2.52e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3720000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.44414783 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.62       |\n",
      "|    explained_variance   | 0.373      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 6.4e+06    |\n",
      "|    n_updates            | 34070      |\n",
      "|    policy_gradient_loss | 0.0212     |\n",
      "|    std                  | 0.143      |\n",
      "|    value_loss           | 3.37e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.12e+03  |\n",
      "|    ep_rew_mean     | -1.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1817      |\n",
      "|    time_elapsed    | 7386      |\n",
      "|    total_timesteps | 3721216   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | -1.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1818        |\n",
      "|    time_elapsed         | 7388        |\n",
      "|    total_timesteps      | 3723264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019429237 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.984       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 374         |\n",
      "|    n_updates            | 34080       |\n",
      "|    policy_gradient_loss | -0.00199    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3725000, episode_reward=23022.54 +/- 5395.71\n",
      "Episode length: 2312.00 +/- 8.67\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.31e+03    |\n",
      "|    mean_reward          | 2.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3725000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017420797 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 131         |\n",
      "|    n_updates            | 34090       |\n",
      "|    policy_gradient_loss | -0.00129    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 3.22e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.11e+03  |\n",
      "|    ep_rew_mean     | -1.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1819      |\n",
      "|    time_elapsed    | 7395      |\n",
      "|    total_timesteps | 3725312   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.1e+03    |\n",
      "|    ep_rew_mean          | -1.08e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 1820       |\n",
      "|    time_elapsed         | 7397       |\n",
      "|    total_timesteps      | 3727360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01901191 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.62       |\n",
      "|    explained_variance   | 0.958      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.8e+04    |\n",
      "|    n_updates            | 34100      |\n",
      "|    policy_gradient_loss | 0.000822   |\n",
      "|    std                  | 0.142      |\n",
      "|    value_loss           | 2.53e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.1e+03     |\n",
      "|    ep_rew_mean          | -1.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1821        |\n",
      "|    time_elapsed         | 7399        |\n",
      "|    total_timesteps      | 3729408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018393718 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.63        |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.29e+05    |\n",
      "|    n_updates            | 34110       |\n",
      "|    policy_gradient_loss | -0.00072    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 2.21e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3730000, episode_reward=26242.06 +/- 2135.56\n",
      "Episode length: 2063.00 +/- 9.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.06e+03    |\n",
      "|    mean_reward          | 2.62e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017286338 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.63        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 123         |\n",
      "|    n_updates            | 34120       |\n",
      "|    policy_gradient_loss | 0.0061      |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 421         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.1e+03   |\n",
      "|    ep_rew_mean     | -1.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1822      |\n",
      "|    time_elapsed    | 7405      |\n",
      "|    total_timesteps | 3731456   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.09e+03    |\n",
      "|    ep_rew_mean          | -1.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1823        |\n",
      "|    time_elapsed         | 7407        |\n",
      "|    total_timesteps      | 3733504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010776824 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 89          |\n",
      "|    n_updates            | 34130       |\n",
      "|    policy_gradient_loss | 0.000607    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 7.3e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3735000, episode_reward=24700.50 +/- 3798.98\n",
      "Episode length: 1967.00 +/- 10.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.97e+03    |\n",
      "|    mean_reward          | 2.47e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3735000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044801164 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.65e+04    |\n",
      "|    n_updates            | 34140       |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 1.2e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.09e+03  |\n",
      "|    ep_rew_mean     | -1.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1824      |\n",
      "|    time_elapsed    | 7414      |\n",
      "|    total_timesteps | 3735552   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | -1.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1825        |\n",
      "|    time_elapsed         | 7416        |\n",
      "|    total_timesteps      | 3737600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020909887 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 41.1        |\n",
      "|    n_updates            | 34150       |\n",
      "|    policy_gradient_loss | 0.00466     |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 439         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | -1.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1826        |\n",
      "|    time_elapsed         | 7418        |\n",
      "|    total_timesteps      | 3739648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012926416 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.8        |\n",
      "|    n_updates            | 34160       |\n",
      "|    policy_gradient_loss | 0.00398     |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.22e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3740000, episode_reward=18259.64 +/- 2638.20\n",
      "Episode length: 2751.40 +/- 11.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.75e+03    |\n",
      "|    mean_reward          | 1.83e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013739115 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.59        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.5        |\n",
      "|    n_updates            | 34170       |\n",
      "|    policy_gradient_loss | 0.000757    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.31e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.08e+03  |\n",
      "|    ep_rew_mean     | -1.11e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1827      |\n",
      "|    time_elapsed    | 7426      |\n",
      "|    total_timesteps | 3741696   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | -1.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1828        |\n",
      "|    time_elapsed         | 7428        |\n",
      "|    total_timesteps      | 3743744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008777462 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 55.3        |\n",
      "|    n_updates            | 34180       |\n",
      "|    policy_gradient_loss | 0.00648     |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 639         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3745000, episode_reward=17597.15 +/- 5043.97\n",
      "Episode length: 2423.40 +/- 12.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.42e+03    |\n",
      "|    mean_reward          | 1.76e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3745000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017213352 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 49.4        |\n",
      "|    n_updates            | 34190       |\n",
      "|    policy_gradient_loss | 0.00364     |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 973         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.09e+03  |\n",
      "|    ep_rew_mean     | -1.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1829      |\n",
      "|    time_elapsed    | 7435      |\n",
      "|    total_timesteps | 3745792   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | -1.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1830        |\n",
      "|    time_elapsed         | 7437        |\n",
      "|    total_timesteps      | 3747840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009530173 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 253         |\n",
      "|    n_updates            | 34200       |\n",
      "|    policy_gradient_loss | 0.00182     |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.2e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.09e+03    |\n",
      "|    ep_rew_mean          | -1.13e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1831        |\n",
      "|    time_elapsed         | 7439        |\n",
      "|    total_timesteps      | 3749888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010308056 |\n",
      "|    clip_fraction        | 0.0654      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.58        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 121         |\n",
      "|    n_updates            | 34210       |\n",
      "|    policy_gradient_loss | -0.00133    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 2.42e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3750000, episode_reward=19689.51 +/- 3831.89\n",
      "Episode length: 2381.80 +/- 15.59\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.38e+03     |\n",
      "|    mean_reward          | 1.97e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3750000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071101934 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.58         |\n",
      "|    explained_variance   | 0.903        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.4e+04      |\n",
      "|    n_updates            | 34220        |\n",
      "|    policy_gradient_loss | -0.000229    |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 2.66e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.08e+03  |\n",
      "|    ep_rew_mean     | -1.14e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1832      |\n",
      "|    time_elapsed    | 7446      |\n",
      "|    total_timesteps | 3751936   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.08e+03   |\n",
      "|    ep_rew_mean          | -1.14e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 1833       |\n",
      "|    time_elapsed         | 7448       |\n",
      "|    total_timesteps      | 3753984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03036784 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.59       |\n",
      "|    explained_variance   | 0.906      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.6       |\n",
      "|    n_updates            | 34230      |\n",
      "|    policy_gradient_loss | 0.0111     |\n",
      "|    std                  | 0.142      |\n",
      "|    value_loss           | 2.66e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3755000, episode_reward=29123.52 +/- 3524.47\n",
      "Episode length: 3138.20 +/- 14.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.14e+03    |\n",
      "|    mean_reward          | 2.91e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3755000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015811402 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96.6        |\n",
      "|    n_updates            | 34240       |\n",
      "|    policy_gradient_loss | -0.00325    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 550         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.09e+03  |\n",
      "|    ep_rew_mean     | -1.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1834      |\n",
      "|    time_elapsed    | 7457      |\n",
      "|    total_timesteps | 3756032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.1e+03     |\n",
      "|    ep_rew_mean          | -1.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1835        |\n",
      "|    time_elapsed         | 7459        |\n",
      "|    total_timesteps      | 3758080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013287741 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.5        |\n",
      "|    n_updates            | 34250       |\n",
      "|    policy_gradient_loss | 0.00631     |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 837         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3760000, episode_reward=28146.60 +/- 4898.17\n",
      "Episode length: 4133.80 +/- 11.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.13e+03    |\n",
      "|    mean_reward          | 2.81e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014065003 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 190         |\n",
      "|    n_updates            | 34260       |\n",
      "|    policy_gradient_loss | -0.00646    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.1e+03   |\n",
      "|    ep_rew_mean     | -1.15e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1836      |\n",
      "|    time_elapsed    | 7471      |\n",
      "|    total_timesteps | 3760128   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.11e+03    |\n",
      "|    ep_rew_mean          | -1.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1837        |\n",
      "|    time_elapsed         | 7473        |\n",
      "|    total_timesteps      | 3762176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037491392 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.9        |\n",
      "|    n_updates            | 34270       |\n",
      "|    policy_gradient_loss | 0.0114      |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 73.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.11e+03    |\n",
      "|    ep_rew_mean          | -1.16e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1838        |\n",
      "|    time_elapsed         | 7475        |\n",
      "|    total_timesteps      | 3764224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026101064 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 212         |\n",
      "|    n_updates            | 34280       |\n",
      "|    policy_gradient_loss | 0.00616     |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 1.32e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3765000, episode_reward=17693.12 +/- 6341.51\n",
      "Episode length: 1873.40 +/- 18.46\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.87e+03     |\n",
      "|    mean_reward          | 1.77e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3765000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051508653 |\n",
      "|    clip_fraction        | 0.0625       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.59         |\n",
      "|    explained_variance   | 0.991        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 119          |\n",
      "|    n_updates            | 34290        |\n",
      "|    policy_gradient_loss | 0.000769     |\n",
      "|    std                  | 0.142        |\n",
      "|    value_loss           | 1.77e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.11e+03  |\n",
      "|    ep_rew_mean     | -1.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1839      |\n",
      "|    time_elapsed    | 7481      |\n",
      "|    total_timesteps | 3766272   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.1e+03    |\n",
      "|    ep_rew_mean          | -1.19e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 1840       |\n",
      "|    time_elapsed         | 7483       |\n",
      "|    total_timesteps      | 3768320    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01734082 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.59       |\n",
      "|    explained_variance   | 0.98       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 70.4       |\n",
      "|    n_updates            | 34300      |\n",
      "|    policy_gradient_loss | 0.0218     |\n",
      "|    std                  | 0.142      |\n",
      "|    value_loss           | 2.85e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3770000, episode_reward=18627.43 +/- 3226.09\n",
      "Episode length: 1837.60 +/- 9.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.84e+03    |\n",
      "|    mean_reward          | 1.86e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024070133 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.6         |\n",
      "|    explained_variance   | 0.977       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.35e+03    |\n",
      "|    n_updates            | 34310       |\n",
      "|    policy_gradient_loss | 0.00219     |\n",
      "|    std                  | 0.141       |\n",
      "|    value_loss           | 1.45e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.1e+03   |\n",
      "|    ep_rew_mean     | -9.18e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1841      |\n",
      "|    time_elapsed    | 7489      |\n",
      "|    total_timesteps | 3770368   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.1e+03      |\n",
      "|    ep_rew_mean          | -9.18e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1842         |\n",
      "|    time_elapsed         | 7491         |\n",
      "|    total_timesteps      | 3772416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097571425 |\n",
      "|    clip_fraction        | 0.148        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.61         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 33.2         |\n",
      "|    n_updates            | 34320        |\n",
      "|    policy_gradient_loss | -0.00179     |\n",
      "|    std                  | 0.141        |\n",
      "|    value_loss           | 407          |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.11e+03    |\n",
      "|    ep_rew_mean          | -7.77e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1843        |\n",
      "|    time_elapsed         | 7493        |\n",
      "|    total_timesteps      | 3774464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051840063 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.61        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.1        |\n",
      "|    n_updates            | 34330       |\n",
      "|    policy_gradient_loss | 0.0181      |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 59.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3775000, episode_reward=15665.45 +/- 3866.60\n",
      "Episode length: 1861.00 +/- 11.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.86e+03    |\n",
      "|    mean_reward          | 1.57e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3775000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010142516 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.61        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 229         |\n",
      "|    n_updates            | 34340       |\n",
      "|    policy_gradient_loss | 0.00429     |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 1e+03       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.11e+03  |\n",
      "|    ep_rew_mean     | -6.37e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1844      |\n",
      "|    time_elapsed    | 7499      |\n",
      "|    total_timesteps | 3776512   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.11e+03    |\n",
      "|    ep_rew_mean          | -6.52e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1845        |\n",
      "|    time_elapsed         | 7501        |\n",
      "|    total_timesteps      | 3778560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017232925 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.7        |\n",
      "|    n_updates            | 34350       |\n",
      "|    policy_gradient_loss | 0.0031      |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 282         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3780000, episode_reward=15946.14 +/- 1465.69\n",
      "Episode length: 2590.80 +/- 5.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.59e+03    |\n",
      "|    mean_reward          | 1.59e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017981473 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.61        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.4        |\n",
      "|    n_updates            | 34360       |\n",
      "|    policy_gradient_loss | 0.00642     |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 338         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.11e+03  |\n",
      "|    ep_rew_mean     | -5.26e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1846      |\n",
      "|    time_elapsed    | 7509      |\n",
      "|    total_timesteps | 3780608   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | -5.49e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1847        |\n",
      "|    time_elapsed         | 7511        |\n",
      "|    total_timesteps      | 3782656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016836278 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 34370       |\n",
      "|    policy_gradient_loss | -0.000604   |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.13e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | -4.03e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1848        |\n",
      "|    time_elapsed         | 7513        |\n",
      "|    total_timesteps      | 3784704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009525078 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 138         |\n",
      "|    n_updates            | 34380       |\n",
      "|    policy_gradient_loss | -0.00188    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.06e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3785000, episode_reward=3866.97 +/- 1687.31\n",
      "Episode length: 3565.20 +/- 343.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.57e+03    |\n",
      "|    mean_reward          | 3.87e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3785000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013109006 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.5        |\n",
      "|    n_updates            | 34390       |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 1.52e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.12e+03  |\n",
      "|    ep_rew_mean     | -4.03e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1849      |\n",
      "|    time_elapsed    | 7523      |\n",
      "|    total_timesteps | 3786752   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.13e+03    |\n",
      "|    ep_rew_mean          | -4.28e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1850        |\n",
      "|    time_elapsed         | 7525        |\n",
      "|    total_timesteps      | 3788800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008805253 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.63        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 106         |\n",
      "|    n_updates            | 34400       |\n",
      "|    policy_gradient_loss | -3.73e-05   |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 325         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3790000, episode_reward=2759.66 +/- 4533.88\n",
      "Episode length: 3019.20 +/- 12.64\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.02e+03    |\n",
      "|    mean_reward          | 2.76e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032996997 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.63        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 34410       |\n",
      "|    policy_gradient_loss | 0.0149      |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 624         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.14e+03  |\n",
      "|    ep_rew_mean     | -4.59e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1851      |\n",
      "|    time_elapsed    | 7534      |\n",
      "|    total_timesteps | 3790848   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.14e+03     |\n",
      "|    ep_rew_mean          | -4.59e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1852         |\n",
      "|    time_elapsed         | 7536         |\n",
      "|    total_timesteps      | 3792896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083858855 |\n",
      "|    clip_fraction        | 0.0859       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.63         |\n",
      "|    explained_variance   | 0.902        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 160          |\n",
      "|    n_updates            | 34420        |\n",
      "|    policy_gradient_loss | 0.00135      |\n",
      "|    std                  | 0.142        |\n",
      "|    value_loss           | 6.31e+03     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.14e+03    |\n",
      "|    ep_rew_mean          | -4.59e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1853        |\n",
      "|    time_elapsed         | 7538        |\n",
      "|    total_timesteps      | 3794944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014423278 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.5        |\n",
      "|    n_updates            | 34430       |\n",
      "|    policy_gradient_loss | 0.00275     |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 74.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3795000, episode_reward=11536.16 +/- 3173.85\n",
      "Episode length: 2446.60 +/- 9.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.45e+03    |\n",
      "|    mean_reward          | 1.15e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3795000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009712594 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 648         |\n",
      "|    n_updates            | 34440       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.17e+03  |\n",
      "|    ep_rew_mean     | -4.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1854      |\n",
      "|    time_elapsed    | 7545      |\n",
      "|    total_timesteps | 3796992   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.17e+03    |\n",
      "|    ep_rew_mean          | -4.89e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1855        |\n",
      "|    time_elapsed         | 7547        |\n",
      "|    total_timesteps      | 3799040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013872283 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 177         |\n",
      "|    n_updates            | 34450       |\n",
      "|    policy_gradient_loss | 0.00765     |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 2.71e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3800000, episode_reward=11924.12 +/- 3106.28\n",
      "Episode length: 2372.60 +/- 9.29\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.37e+03    |\n",
      "|    mean_reward          | 1.19e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009041684 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.91e+03    |\n",
      "|    n_updates            | 34460       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.65e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.16e+03  |\n",
      "|    ep_rew_mean     | -7.72e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1856      |\n",
      "|    time_elapsed    | 7555      |\n",
      "|    total_timesteps | 3801088   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.16e+03     |\n",
      "|    ep_rew_mean          | -6.36e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1857         |\n",
      "|    time_elapsed         | 7557         |\n",
      "|    total_timesteps      | 3803136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030627302 |\n",
      "|    clip_fraction        | 0.0183       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.63         |\n",
      "|    explained_variance   | 0.364        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.36e+07     |\n",
      "|    n_updates            | 34470        |\n",
      "|    policy_gradient_loss | -0.00369     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 4.53e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3805000, episode_reward=13844.35 +/- 3169.79\n",
      "Episode length: 2389.60 +/- 8.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.39e+03     |\n",
      "|    mean_reward          | 1.38e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3805000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037066578 |\n",
      "|    clip_fraction        | 0.00811      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.63         |\n",
      "|    explained_variance   | 0.935        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.03e+04     |\n",
      "|    n_updates            | 34480        |\n",
      "|    policy_gradient_loss | -0.00352     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 1.35e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.15e+03  |\n",
      "|    ep_rew_mean     | -6.02e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1858      |\n",
      "|    time_elapsed    | 7564      |\n",
      "|    total_timesteps | 3805184   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.16e+03     |\n",
      "|    ep_rew_mean          | -4.72e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1859         |\n",
      "|    time_elapsed         | 7566         |\n",
      "|    total_timesteps      | 3807232      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068028625 |\n",
      "|    clip_fraction        | 0.0224       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.63         |\n",
      "|    explained_variance   | 0.428        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.82e+06     |\n",
      "|    n_updates            | 34490        |\n",
      "|    policy_gradient_loss | -0.00444     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 2.32e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.17e+03     |\n",
      "|    ep_rew_mean          | -4.08e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1860         |\n",
      "|    time_elapsed         | 7568         |\n",
      "|    total_timesteps      | 3809280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045417957 |\n",
      "|    clip_fraction        | 0.0135       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.62         |\n",
      "|    explained_variance   | 0.949        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79e+04     |\n",
      "|    n_updates            | 34500        |\n",
      "|    policy_gradient_loss | -0.00396     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 9.43e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3810000, episode_reward=14833.84 +/- 3035.71\n",
      "Episode length: 2524.80 +/- 12.75\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 2.52e+03      |\n",
      "|    mean_reward          | 1.48e+04      |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 3810000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00062543276 |\n",
      "|    clip_fraction        | 0.000537      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 3.62          |\n",
      "|    explained_variance   | 0.355         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 9.9e+05       |\n",
      "|    n_updates            | 34510         |\n",
      "|    policy_gradient_loss | -0.000613     |\n",
      "|    std                  | 0.143         |\n",
      "|    value_loss           | 1.09e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.17e+03  |\n",
      "|    ep_rew_mean     | -4.08e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1861      |\n",
      "|    time_elapsed    | 7576      |\n",
      "|    total_timesteps | 3811328   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.18e+03     |\n",
      "|    ep_rew_mean          | -2.78e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1862         |\n",
      "|    time_elapsed         | 7578         |\n",
      "|    total_timesteps      | 3813376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067790323 |\n",
      "|    clip_fraction        | 0.0439       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.62         |\n",
      "|    explained_variance   | 0.981        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.05e+03     |\n",
      "|    n_updates            | 34520        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 7.01e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3815000, episode_reward=16460.16 +/- 1503.79\n",
      "Episode length: 2492.60 +/- 10.58\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.49e+03    |\n",
      "|    mean_reward          | 1.65e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3815000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005022109 |\n",
      "|    clip_fraction        | 0.0522      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.12e+03    |\n",
      "|    n_updates            | 34530       |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.06e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.19e+03 |\n",
      "|    ep_rew_mean     | -1.4e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 1863     |\n",
      "|    time_elapsed    | 7585     |\n",
      "|    total_timesteps | 3815424  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2e+03     |\n",
      "|    ep_rew_mean          | -1.48e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1864        |\n",
      "|    time_elapsed         | 7587        |\n",
      "|    total_timesteps      | 3817472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005939164 |\n",
      "|    clip_fraction        | 0.0536      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.02e+03    |\n",
      "|    n_updates            | 34540       |\n",
      "|    policy_gradient_loss | -0.00475    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 4.17e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2e+03     |\n",
      "|    ep_rew_mean          | -1.48e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1865        |\n",
      "|    time_elapsed         | 7589        |\n",
      "|    total_timesteps      | 3819520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002838823 |\n",
      "|    clip_fraction        | 0.0324      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.63        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 34550       |\n",
      "|    policy_gradient_loss | -0.00237    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 2.55e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3820000, episode_reward=13106.92 +/- 2695.98\n",
      "Episode length: 2437.20 +/- 14.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.44e+03    |\n",
      "|    mean_reward          | 1.31e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006906239 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 374         |\n",
      "|    n_updates            | 34560       |\n",
      "|    policy_gradient_loss | 0.0027      |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 1.04e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.19e+03  |\n",
      "|    ep_rew_mean     | -3.84e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1866      |\n",
      "|    time_elapsed    | 7597      |\n",
      "|    total_timesteps | 3821568   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2e+03     |\n",
      "|    ep_rew_mean          | -3.99e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1867        |\n",
      "|    time_elapsed         | 7598        |\n",
      "|    total_timesteps      | 3823616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009805253 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.153       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.44e+07    |\n",
      "|    n_updates            | 34570       |\n",
      "|    policy_gradient_loss | 0.00434     |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 2.69e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3825000, episode_reward=-44385.43 +/- 73446.53\n",
      "Episode length: 2354.80 +/- 1119.41\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.35e+03     |\n",
      "|    mean_reward          | -4.44e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3825000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054014227 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.62         |\n",
      "|    explained_variance   | 0.897        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.06e+03     |\n",
      "|    n_updates            | 34580        |\n",
      "|    policy_gradient_loss | -0.00378     |\n",
      "|    std                  | 0.143        |\n",
      "|    value_loss           | 5.6e+04      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.2e+03   |\n",
      "|    ep_rew_mean     | -4.19e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 1868      |\n",
      "|    time_elapsed    | 7606      |\n",
      "|    total_timesteps | 3825664   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2e+03     |\n",
      "|    ep_rew_mean          | -4.32e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1869        |\n",
      "|    time_elapsed         | 7608        |\n",
      "|    total_timesteps      | 3827712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011017095 |\n",
      "|    clip_fraction        | 0.0611      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 639         |\n",
      "|    n_updates            | 34590       |\n",
      "|    policy_gradient_loss | -0.00432    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 2.75e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2e+03     |\n",
      "|    ep_rew_mean          | -4.52e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1870        |\n",
      "|    time_elapsed         | 7610        |\n",
      "|    total_timesteps      | 3829760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011446121 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.62        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 83.6        |\n",
      "|    n_updates            | 34600       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    std                  | 0.143       |\n",
      "|    value_loss           | 852         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3830000, episode_reward=16539.77 +/- 2353.53\n",
      "Episode length: 1591.00 +/- 7.29\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.59e+03   |\n",
      "|    mean_reward          | 1.65e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3830000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04578869 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.62       |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 200        |\n",
      "|    n_updates            | 34610      |\n",
      "|    policy_gradient_loss | 0.000382   |\n",
      "|    std                  | 0.142      |\n",
      "|    value_loss           | 1.46e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.19e+03  |\n",
      "|    ep_rew_mean     | -4.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1871      |\n",
      "|    time_elapsed    | 7615      |\n",
      "|    total_timesteps | 3831808   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.19e+03   |\n",
      "|    ep_rew_mean          | -4.8e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 1872       |\n",
      "|    time_elapsed         | 7617       |\n",
      "|    total_timesteps      | 3833856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02547494 |\n",
      "|    clip_fraction        | 0.286      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.63       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 40.6       |\n",
      "|    n_updates            | 34620      |\n",
      "|    policy_gradient_loss | 0.0124     |\n",
      "|    std                  | 0.142      |\n",
      "|    value_loss           | 154        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3835000, episode_reward=13540.65 +/- 5178.13\n",
      "Episode length: 1703.60 +/- 11.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 1.35e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3835000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017912433 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.63        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 34630       |\n",
      "|    policy_gradient_loss | 0.000335    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 245         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.19e+03  |\n",
      "|    ep_rew_mean     | -4.97e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1873      |\n",
      "|    time_elapsed    | 7623      |\n",
      "|    total_timesteps | 3835904   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.18e+03    |\n",
      "|    ep_rew_mean          | -5.26e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1874        |\n",
      "|    time_elapsed         | 7625        |\n",
      "|    total_timesteps      | 3837952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011125216 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.64        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73          |\n",
      "|    n_updates            | 34640       |\n",
      "|    policy_gradient_loss | -0.000546   |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 2.85e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3840000, episode_reward=15292.49 +/- 3121.81\n",
      "Episode length: 1700.60 +/- 7.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 1.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3840000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031543788 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.64        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.5        |\n",
      "|    n_updates            | 34650       |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 1.39e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.17e+03  |\n",
      "|    ep_rew_mean     | -5.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1875      |\n",
      "|    time_elapsed    | 7631      |\n",
      "|    total_timesteps | 3840000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.16e+03    |\n",
      "|    ep_rew_mean          | -5.58e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1876        |\n",
      "|    time_elapsed         | 7633        |\n",
      "|    total_timesteps      | 3842048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023325013 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.64        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.5        |\n",
      "|    n_updates            | 34660       |\n",
      "|    policy_gradient_loss | 0.00798     |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.14e+03    |\n",
      "|    ep_rew_mean          | -8.62e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1877        |\n",
      "|    time_elapsed         | 7635        |\n",
      "|    total_timesteps      | 3844096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016398698 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.64        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 27.8        |\n",
      "|    n_updates            | 34670       |\n",
      "|    policy_gradient_loss | 0.00305     |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 105         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3845000, episode_reward=16702.13 +/- 2474.56\n",
      "Episode length: 1636.20 +/- 11.21\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.64e+03   |\n",
      "|    mean_reward          | 1.67e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3845000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00437917 |\n",
      "|    clip_fraction        | 0.0545     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.65       |\n",
      "|    explained_variance   | 0.364      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.75e+06   |\n",
      "|    n_updates            | 34680      |\n",
      "|    policy_gradient_loss | 0.00333    |\n",
      "|    std                  | 0.142      |\n",
      "|    value_loss           | 4.9e+07    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.12e+03  |\n",
      "|    ep_rew_mean     | -1.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1878      |\n",
      "|    time_elapsed    | 7640      |\n",
      "|    total_timesteps | 3846144   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.1e+03      |\n",
      "|    ep_rew_mean          | -1.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1879         |\n",
      "|    time_elapsed         | 7642         |\n",
      "|    total_timesteps      | 3848192      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.666075e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.65         |\n",
      "|    explained_variance   | 0.424        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+07     |\n",
      "|    n_updates            | 34690        |\n",
      "|    policy_gradient_loss | -0.000656    |\n",
      "|    std                  | 0.142        |\n",
      "|    value_loss           | 2.46e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3850000, episode_reward=16350.99 +/- 2740.56\n",
      "Episode length: 1620.80 +/- 8.42\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.62e+03     |\n",
      "|    mean_reward          | 1.64e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3850000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033502628 |\n",
      "|    clip_fraction        | 0.00962      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.65         |\n",
      "|    explained_variance   | 0.944        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.95e+04     |\n",
      "|    n_updates            | 34700        |\n",
      "|    policy_gradient_loss | -0.00261     |\n",
      "|    std                  | 0.142        |\n",
      "|    value_loss           | 6.68e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.06e+03  |\n",
      "|    ep_rew_mean     | -1.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1880      |\n",
      "|    time_elapsed    | 7648      |\n",
      "|    total_timesteps | 3850240   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.05e+03     |\n",
      "|    ep_rew_mean          | -1.28e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1881         |\n",
      "|    time_elapsed         | 7650         |\n",
      "|    total_timesteps      | 3852288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014166206 |\n",
      "|    clip_fraction        | 0.01         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.65         |\n",
      "|    explained_variance   | 0.234        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.28e+07     |\n",
      "|    n_updates            | 34710        |\n",
      "|    policy_gradient_loss | -0.00419     |\n",
      "|    std                  | 0.142        |\n",
      "|    value_loss           | 3.01e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.02e+03     |\n",
      "|    ep_rew_mean          | -1.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1882         |\n",
      "|    time_elapsed         | 7652         |\n",
      "|    total_timesteps      | 3854336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077474625 |\n",
      "|    clip_fraction        | 0.0607       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.65         |\n",
      "|    explained_variance   | 0.955        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.48e+03     |\n",
      "|    n_updates            | 34720        |\n",
      "|    policy_gradient_loss | -0.00719     |\n",
      "|    std                  | 0.142        |\n",
      "|    value_loss           | 3.53e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3855000, episode_reward=13746.81 +/- 4479.91\n",
      "Episode length: 1587.60 +/- 10.38\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.59e+03    |\n",
      "|    mean_reward          | 1.37e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3855000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007449789 |\n",
      "|    clip_fraction        | 0.041       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.65        |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 351         |\n",
      "|    n_updates            | 34730       |\n",
      "|    policy_gradient_loss | -0.00456    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 3.96e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.98e+03  |\n",
      "|    ep_rew_mean     | -1.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1883      |\n",
      "|    time_elapsed    | 7657      |\n",
      "|    total_timesteps | 3856384   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.94e+03   |\n",
      "|    ep_rew_mean          | -1.59e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 1884       |\n",
      "|    time_elapsed         | 7659       |\n",
      "|    total_timesteps      | 3858432    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.32465053 |\n",
      "|    clip_fraction        | 0.0655     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.65       |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.96e+07   |\n",
      "|    n_updates            | 34740      |\n",
      "|    policy_gradient_loss | -0.00963   |\n",
      "|    std                  | 0.142      |\n",
      "|    value_loss           | 3.55e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3860000, episode_reward=15629.87 +/- 3547.89\n",
      "Episode length: 1572.60 +/- 13.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.57e+03    |\n",
      "|    mean_reward          | 1.56e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009673367 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.65        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 208         |\n",
      "|    n_updates            | 34750       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 1.25e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.92e+03  |\n",
      "|    ep_rew_mean     | -1.62e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1885      |\n",
      "|    time_elapsed    | 7665      |\n",
      "|    total_timesteps | 3860480   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.92e+03   |\n",
      "|    ep_rew_mean          | -1.44e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 1886       |\n",
      "|    time_elapsed         | 7666       |\n",
      "|    total_timesteps      | 3862528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01906204 |\n",
      "|    clip_fraction        | 0.14       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.65       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 170        |\n",
      "|    n_updates            | 34760      |\n",
      "|    policy_gradient_loss | -0.00048   |\n",
      "|    std                  | 0.142      |\n",
      "|    value_loss           | 2.54e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.87e+03    |\n",
      "|    ep_rew_mean          | -1.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1887        |\n",
      "|    time_elapsed         | 7668        |\n",
      "|    total_timesteps      | 3864576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016256873 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.65        |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 355         |\n",
      "|    n_updates            | 34770       |\n",
      "|    policy_gradient_loss | 0.00405     |\n",
      "|    std                  | 0.141       |\n",
      "|    value_loss           | 5.04e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3865000, episode_reward=15823.68 +/- 1584.40\n",
      "Episode length: 1391.20 +/- 4.07\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.39e+03    |\n",
      "|    mean_reward          | 1.58e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3865000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019653168 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.65        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.8        |\n",
      "|    n_updates            | 34780       |\n",
      "|    policy_gradient_loss | 0.00478     |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 433         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.85e+03  |\n",
      "|    ep_rew_mean     | -1.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1888      |\n",
      "|    time_elapsed    | 7673      |\n",
      "|    total_timesteps | 3866624   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.82e+03  |\n",
      "|    ep_rew_mean          | -1.5e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 504       |\n",
      "|    iterations           | 1889      |\n",
      "|    time_elapsed         | 7675      |\n",
      "|    total_timesteps      | 3868672   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0176225 |\n",
      "|    clip_fraction        | 0.196     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.64      |\n",
      "|    explained_variance   | 0.969     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 56.8      |\n",
      "|    n_updates            | 34790     |\n",
      "|    policy_gradient_loss | 0.00598   |\n",
      "|    std                  | 0.142     |\n",
      "|    value_loss           | 5.56e+03  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=3870000, episode_reward=-27862.69 +/- 82386.89\n",
      "Episode length: 1090.40 +/- 488.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.09e+03    |\n",
      "|    mean_reward          | -2.79e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3870000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011939185 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.64        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 66.8        |\n",
      "|    n_updates            | 34800       |\n",
      "|    policy_gradient_loss | 0.000895    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 2.53e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.81e+03  |\n",
      "|    ep_rew_mean     | -1.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 1890      |\n",
      "|    time_elapsed    | 7680      |\n",
      "|    total_timesteps | 3870720   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.82e+03    |\n",
      "|    ep_rew_mean          | -1.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1891        |\n",
      "|    time_elapsed         | 7682        |\n",
      "|    total_timesteps      | 3872768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002609857 |\n",
      "|    clip_fraction        | 0.0182      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.64        |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.67e+06    |\n",
      "|    n_updates            | 34810       |\n",
      "|    policy_gradient_loss | 0.000528    |\n",
      "|    std                  | 0.142       |\n",
      "|    value_loss           | 2.91e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | -1.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1892        |\n",
      "|    time_elapsed         | 7683        |\n",
      "|    total_timesteps      | 3874816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009652478 |\n",
      "|    clip_fraction        | 0.0968      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.65        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 205         |\n",
      "|    n_updates            | 34820       |\n",
      "|    policy_gradient_loss | -0.00132    |\n",
      "|    std                  | 0.141       |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3875000, episode_reward=13597.63 +/- 4393.54\n",
      "Episode length: 1293.80 +/- 15.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.29e+03    |\n",
      "|    mean_reward          | 1.36e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3875000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014441144 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.66        |\n",
      "|    explained_variance   | 0.852       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 34830       |\n",
      "|    policy_gradient_loss | 0.00205     |\n",
      "|    std                  | 0.141       |\n",
      "|    value_loss           | 1.53e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.82e+03  |\n",
      "|    ep_rew_mean     | -1.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 1893      |\n",
      "|    time_elapsed    | 7688      |\n",
      "|    total_timesteps | 3876864   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.81e+03    |\n",
      "|    ep_rew_mean          | -8.94e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1894        |\n",
      "|    time_elapsed         | 7690        |\n",
      "|    total_timesteps      | 3878912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012372731 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.67        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 96.6        |\n",
      "|    n_updates            | 34840       |\n",
      "|    policy_gradient_loss | 0.0033      |\n",
      "|    std                  | 0.14        |\n",
      "|    value_loss           | 274         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3880000, episode_reward=15535.33 +/- 739.18\n",
      "Episode length: 1267.60 +/- 7.66\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.27e+03   |\n",
      "|    mean_reward          | 1.55e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3880000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01372116 |\n",
      "|    clip_fraction        | 0.131      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.69       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 521        |\n",
      "|    n_updates            | 34850      |\n",
      "|    policy_gradient_loss | -0.00107   |\n",
      "|    std                  | 0.14       |\n",
      "|    value_loss           | 2.36e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.81e+03  |\n",
      "|    ep_rew_mean     | -5.55e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 1895      |\n",
      "|    time_elapsed    | 7695      |\n",
      "|    total_timesteps | 3880960   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.8e+03     |\n",
      "|    ep_rew_mean          | -5.63e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1896        |\n",
      "|    time_elapsed         | 7697        |\n",
      "|    total_timesteps      | 3883008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027103133 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.7         |\n",
      "|    explained_variance   | 0.98        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.4        |\n",
      "|    n_updates            | 34860       |\n",
      "|    policy_gradient_loss | 0.00342     |\n",
      "|    std                  | 0.139       |\n",
      "|    value_loss           | 1.16e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3885000, episode_reward=-30575.87 +/- 81040.24\n",
      "Episode length: 996.20 +/- 441.16\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 996        |\n",
      "|    mean_reward          | -3.06e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3885000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01622434 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.72       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 39         |\n",
      "|    n_updates            | 34870      |\n",
      "|    policy_gradient_loss | 0.00225    |\n",
      "|    std                  | 0.137      |\n",
      "|    value_loss           | 6.66e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.8e+03   |\n",
      "|    ep_rew_mean     | -3.98e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 1897      |\n",
      "|    time_elapsed    | 7701      |\n",
      "|    total_timesteps | 3885056   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.79e+03    |\n",
      "|    ep_rew_mean          | -4.2e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1898        |\n",
      "|    time_elapsed         | 7703        |\n",
      "|    total_timesteps      | 3887104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015692348 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.74        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 47.3        |\n",
      "|    n_updates            | 34880       |\n",
      "|    policy_gradient_loss | 0.0052      |\n",
      "|    std                  | 0.137       |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.76e+03    |\n",
      "|    ep_rew_mean          | -6.4e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1899        |\n",
      "|    time_elapsed         | 7705        |\n",
      "|    total_timesteps      | 3889152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019464534 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.73        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.3        |\n",
      "|    n_updates            | 34890       |\n",
      "|    policy_gradient_loss | 0.00366     |\n",
      "|    std                  | 0.137       |\n",
      "|    value_loss           | 2.81e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3890000, episode_reward=-20966.72 +/- 70628.68\n",
      "Episode length: 972.00 +/- 438.22\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 972       |\n",
      "|    mean_reward          | -2.1e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3890000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.3653276 |\n",
      "|    clip_fraction        | 0.283     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.73      |\n",
      "|    explained_variance   | 0.367     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.72e+07  |\n",
      "|    n_updates            | 34900     |\n",
      "|    policy_gradient_loss | 0.00655   |\n",
      "|    std                  | 0.136     |\n",
      "|    value_loss           | 3.36e+07  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.77e+03 |\n",
      "|    ep_rew_mean     | -4.5e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1900     |\n",
      "|    time_elapsed    | 7709     |\n",
      "|    total_timesteps | 3891200  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.75e+03    |\n",
      "|    ep_rew_mean          | -4.77e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1901        |\n",
      "|    time_elapsed         | 7711        |\n",
      "|    total_timesteps      | 3893248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021395557 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.75        |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 99.4        |\n",
      "|    n_updates            | 34910       |\n",
      "|    policy_gradient_loss | -0.000932   |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 2.7e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3895000, episode_reward=-21623.66 +/- 68505.49\n",
      "Episode length: 977.00 +/- 440.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 977         |\n",
      "|    mean_reward          | -2.16e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3895000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010753747 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.78        |\n",
      "|    explained_variance   | 0.616       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.99e+05    |\n",
      "|    n_updates            | 34920       |\n",
      "|    policy_gradient_loss | 0.009       |\n",
      "|    std                  | 0.135       |\n",
      "|    value_loss           | 1.72e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.75e+03  |\n",
      "|    ep_rew_mean     | -2.82e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 1902      |\n",
      "|    time_elapsed    | 7715      |\n",
      "|    total_timesteps | 3895296   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.74e+03   |\n",
      "|    ep_rew_mean          | -2.98e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1903       |\n",
      "|    time_elapsed         | 7717       |\n",
      "|    total_timesteps      | 3897344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01997155 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.78       |\n",
      "|    explained_variance   | 0.944      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 55         |\n",
      "|    n_updates            | 34930      |\n",
      "|    policy_gradient_loss | 0.000905   |\n",
      "|    std                  | 0.134      |\n",
      "|    value_loss           | 3.09e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | -3.09e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1904        |\n",
      "|    time_elapsed         | 7719        |\n",
      "|    total_timesteps      | 3899392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013938032 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.8         |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.2        |\n",
      "|    n_updates            | 34940       |\n",
      "|    policy_gradient_loss | 0.00276     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 1.09e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3900000, episode_reward=15444.40 +/- 3352.24\n",
      "Episode length: 1246.80 +/- 9.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.25e+03    |\n",
      "|    mean_reward          | 1.54e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011036558 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.82        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 34950       |\n",
      "|    policy_gradient_loss | 0.0059      |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 78.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.71e+03  |\n",
      "|    ep_rew_mean     | -3.24e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1905      |\n",
      "|    time_elapsed    | 7724      |\n",
      "|    total_timesteps | 3901440   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7e+03     |\n",
      "|    ep_rew_mean          | -3.26e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1906        |\n",
      "|    time_elapsed         | 7725        |\n",
      "|    total_timesteps      | 3903488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016270075 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.83        |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 58.2        |\n",
      "|    n_updates            | 34960       |\n",
      "|    policy_gradient_loss | -0.000188   |\n",
      "|    std                  | 0.133       |\n",
      "|    value_loss           | 3.09e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3905000, episode_reward=15660.41 +/- 2337.09\n",
      "Episode length: 1282.20 +/- 8.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.28e+03    |\n",
      "|    mean_reward          | 1.57e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3905000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015914213 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.83        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 34970       |\n",
      "|    policy_gradient_loss | 0.00988     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 98          |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.69e+03  |\n",
      "|    ep_rew_mean     | -3.31e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1907      |\n",
      "|    time_elapsed    | 7730      |\n",
      "|    total_timesteps | 3905536   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -3.5e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1908        |\n",
      "|    time_elapsed         | 7732        |\n",
      "|    total_timesteps      | 3907584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016773611 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.82        |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.5        |\n",
      "|    n_updates            | 34980       |\n",
      "|    policy_gradient_loss | 0.0015      |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 2.05e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | -3.54e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1909        |\n",
      "|    time_elapsed         | 7734        |\n",
      "|    total_timesteps      | 3909632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022417285 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.82        |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.25e+03    |\n",
      "|    n_updates            | 34990       |\n",
      "|    policy_gradient_loss | -0.0024     |\n",
      "|    std                  | 0.134       |\n",
      "|    value_loss           | 5.01e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3910000, episode_reward=18175.42 +/- 2905.57\n",
      "Episode length: 1477.60 +/- 14.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.48e+03    |\n",
      "|    mean_reward          | 1.82e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027593616 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.82        |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 100         |\n",
      "|    n_updates            | 35000       |\n",
      "|    policy_gradient_loss | -0.0027     |\n",
      "|    std                  | 0.133       |\n",
      "|    value_loss           | 2.4e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -3.34e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1910      |\n",
      "|    time_elapsed    | 7739      |\n",
      "|    total_timesteps | 3911680   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | -3.38e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1911        |\n",
      "|    time_elapsed         | 7741        |\n",
      "|    total_timesteps      | 3913728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015940778 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.83        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37          |\n",
      "|    n_updates            | 35010       |\n",
      "|    policy_gradient_loss | -0.00308    |\n",
      "|    std                  | 0.133       |\n",
      "|    value_loss           | 165         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3915000, episode_reward=20619.33 +/- 3169.31\n",
      "Episode length: 2137.80 +/- 4.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.14e+03    |\n",
      "|    mean_reward          | 2.06e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3915000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008993186 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.85        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.3        |\n",
      "|    n_updates            | 35020       |\n",
      "|    policy_gradient_loss | -0.00088    |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 2.51e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -5.07e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1912      |\n",
      "|    time_elapsed    | 7748      |\n",
      "|    total_timesteps | 3915776   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.59e+03   |\n",
      "|    ep_rew_mean          | -5.19e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1913       |\n",
      "|    time_elapsed         | 7750       |\n",
      "|    total_timesteps      | 3917824    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.55210435 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.85       |\n",
      "|    explained_variance   | 0.366      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.17e+07   |\n",
      "|    n_updates            | 35030      |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    std                  | 0.132      |\n",
      "|    value_loss           | 2.62e+07   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -5.27e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1914        |\n",
      "|    time_elapsed         | 7752        |\n",
      "|    total_timesteps      | 3919872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026007734 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.86        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 35040       |\n",
      "|    policy_gradient_loss | 0.00858     |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 1.84e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3920000, episode_reward=-14525.64 +/- 62685.65\n",
      "Episode length: 1090.00 +/- 502.28\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.09e+03  |\n",
      "|    mean_reward          | -1.45e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 3920000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.719648  |\n",
      "|    clip_fraction        | 0.379     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.86      |\n",
      "|    explained_variance   | 0.976     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 56.9      |\n",
      "|    n_updates            | 35050     |\n",
      "|    policy_gradient_loss | 0.0725    |\n",
      "|    std                  | 0.132     |\n",
      "|    value_loss           | 764       |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -5.35e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1915      |\n",
      "|    time_elapsed    | 7757      |\n",
      "|    total_timesteps | 3921920   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -5.29e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1916        |\n",
      "|    time_elapsed         | 7758        |\n",
      "|    total_timesteps      | 3923968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028373841 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.87        |\n",
      "|    explained_variance   | 0.561       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.8        |\n",
      "|    n_updates            | 35060       |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 5.47e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3925000, episode_reward=24916.82 +/- 3877.39\n",
      "Episode length: 2489.80 +/- 7.19\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.49e+03   |\n",
      "|    mean_reward          | 2.49e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3925000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15750417 |\n",
      "|    clip_fraction        | 0.362      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.88       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 25.4       |\n",
      "|    n_updates            | 35070      |\n",
      "|    policy_gradient_loss | 0.0188     |\n",
      "|    std                  | 0.131      |\n",
      "|    value_loss           | 113        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -5.18e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1917      |\n",
      "|    time_elapsed    | 7766      |\n",
      "|    total_timesteps | 3926016   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.57e+03   |\n",
      "|    ep_rew_mean          | -5.18e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1918       |\n",
      "|    time_elapsed         | 7768       |\n",
      "|    total_timesteps      | 3928064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08217463 |\n",
      "|    clip_fraction        | 0.319      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.9        |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 128        |\n",
      "|    n_updates            | 35080      |\n",
      "|    policy_gradient_loss | 0.032      |\n",
      "|    std                  | 0.131      |\n",
      "|    value_loss           | 491        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3930000, episode_reward=26687.75 +/- 2582.26\n",
      "Episode length: 2542.20 +/- 6.49\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.54e+03    |\n",
      "|    mean_reward          | 2.67e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023809928 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.9         |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 400         |\n",
      "|    n_updates            | 35090       |\n",
      "|    policy_gradient_loss | 0.0116      |\n",
      "|    std                  | 0.131       |\n",
      "|    value_loss           | 1.22e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -5.93e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1919      |\n",
      "|    time_elapsed    | 7776      |\n",
      "|    total_timesteps | 3930112   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | -5.9e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 1920         |\n",
      "|    time_elapsed         | 7778         |\n",
      "|    total_timesteps      | 3932160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038293037 |\n",
      "|    clip_fraction        | 0.163        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.9          |\n",
      "|    explained_variance   | 0.505        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.07e+03     |\n",
      "|    n_updates            | 35100        |\n",
      "|    policy_gradient_loss | 0.0139       |\n",
      "|    std                  | 0.131        |\n",
      "|    value_loss           | 4.32e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | -5.82e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1921        |\n",
      "|    time_elapsed         | 7780        |\n",
      "|    total_timesteps      | 3934208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009305871 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.9         |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 35110       |\n",
      "|    policy_gradient_loss | -0.00266    |\n",
      "|    std                  | 0.131       |\n",
      "|    value_loss           | 2.08e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3935000, episode_reward=23341.81 +/- 3701.42\n",
      "Episode length: 2580.80 +/- 11.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.58e+03    |\n",
      "|    mean_reward          | 2.33e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3935000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018851275 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.9         |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 73.2        |\n",
      "|    n_updates            | 35120       |\n",
      "|    policy_gradient_loss | 0.00435     |\n",
      "|    std                  | 0.131       |\n",
      "|    value_loss           | 1.75e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.59e+03  |\n",
      "|    ep_rew_mean     | -5.86e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1922      |\n",
      "|    time_elapsed    | 7788      |\n",
      "|    total_timesteps | 3936256   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.59e+03   |\n",
      "|    ep_rew_mean          | -5.86e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1923       |\n",
      "|    time_elapsed         | 7790       |\n",
      "|    total_timesteps      | 3938304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02252534 |\n",
      "|    clip_fraction        | 0.176      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.89       |\n",
      "|    explained_variance   | 0.993      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 86.5       |\n",
      "|    n_updates            | 35130      |\n",
      "|    policy_gradient_loss | 0.00321    |\n",
      "|    std                  | 0.131      |\n",
      "|    value_loss           | 303        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3940000, episode_reward=20093.84 +/- 2891.67\n",
      "Episode length: 2636.00 +/- 9.47\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.64e+03    |\n",
      "|    mean_reward          | 2.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017104711 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.89        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.4        |\n",
      "|    n_updates            | 35140       |\n",
      "|    policy_gradient_loss | 0.0108      |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 123         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -5.77e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1924      |\n",
      "|    time_elapsed    | 7798      |\n",
      "|    total_timesteps | 3940352   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.59e+03    |\n",
      "|    ep_rew_mean          | -5.78e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1925        |\n",
      "|    time_elapsed         | 7799        |\n",
      "|    total_timesteps      | 3942400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031992078 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.88        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.8        |\n",
      "|    n_updates            | 35150       |\n",
      "|    policy_gradient_loss | 0.00905     |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 191         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.6e+03     |\n",
      "|    ep_rew_mean          | -5.75e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1926        |\n",
      "|    time_elapsed         | 7801        |\n",
      "|    total_timesteps      | 3944448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010245206 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.88        |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 67.9        |\n",
      "|    n_updates            | 35160       |\n",
      "|    policy_gradient_loss | -0.0031     |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 4.32e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3945000, episode_reward=26727.00 +/- 1909.28\n",
      "Episode length: 2708.20 +/- 4.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.71e+03    |\n",
      "|    mean_reward          | 2.67e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3945000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020104341 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.88        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.4        |\n",
      "|    n_updates            | 35170       |\n",
      "|    policy_gradient_loss | 0.00814     |\n",
      "|    std                  | 0.131       |\n",
      "|    value_loss           | 221         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.59e+03 |\n",
      "|    ep_rew_mean     | -5.6e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1927     |\n",
      "|    time_elapsed    | 7810     |\n",
      "|    total_timesteps | 3946496  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.59e+03   |\n",
      "|    ep_rew_mean          | -5.6e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1928       |\n",
      "|    time_elapsed         | 7811       |\n",
      "|    total_timesteps      | 3948544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07592332 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.89       |\n",
      "|    explained_variance   | 0.985      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 63.2       |\n",
      "|    n_updates            | 35180      |\n",
      "|    policy_gradient_loss | 0.014      |\n",
      "|    std                  | 0.131      |\n",
      "|    value_loss           | 2.64e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3950000, episode_reward=-86561.79 +/- 4079.37\n",
      "Episode length: 3018.40 +/- 11.11\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.02e+03   |\n",
      "|    mean_reward          | -8.66e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3950000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04866623 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.89       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 30.5       |\n",
      "|    n_updates            | 35190      |\n",
      "|    policy_gradient_loss | 0.00276    |\n",
      "|    std                  | 0.132      |\n",
      "|    value_loss           | 127        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -5.49e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1929      |\n",
      "|    time_elapsed    | 7820      |\n",
      "|    total_timesteps | 3950592   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -5.8e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1930        |\n",
      "|    time_elapsed         | 7822        |\n",
      "|    total_timesteps      | 3952640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024875272 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.88        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.3        |\n",
      "|    n_updates            | 35200       |\n",
      "|    policy_gradient_loss | 0.026       |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 96          |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.55e+03     |\n",
      "|    ep_rew_mean          | -5.79e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 1931         |\n",
      "|    time_elapsed         | 7824         |\n",
      "|    total_timesteps      | 3954688      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056691216 |\n",
      "|    clip_fraction        | 0.055        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.88         |\n",
      "|    explained_variance   | 0.832        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.53e+05     |\n",
      "|    n_updates            | 35210        |\n",
      "|    policy_gradient_loss | -0.00451     |\n",
      "|    std                  | 0.132        |\n",
      "|    value_loss           | 3.01e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3955000, episode_reward=-84320.59 +/- 26466.26\n",
      "Episode length: 2370.00 +/- 1143.02\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.37e+03    |\n",
      "|    mean_reward          | -8.43e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3955000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001073448 |\n",
      "|    clip_fraction        | 0.000342    |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.88        |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.22e+03    |\n",
      "|    n_updates            | 35220       |\n",
      "|    policy_gradient_loss | -7.94e-05   |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 4.64e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -5.74e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1932      |\n",
      "|    time_elapsed    | 7832      |\n",
      "|    total_timesteps | 3956736   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | -5.74e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 1933         |\n",
      "|    time_elapsed         | 7833         |\n",
      "|    total_timesteps      | 3958784      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007221245 |\n",
      "|    clip_fraction        | 0.000928     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.88         |\n",
      "|    explained_variance   | 0.383        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11e+07     |\n",
      "|    n_updates            | 35230        |\n",
      "|    policy_gradient_loss | -0.00118     |\n",
      "|    std                  | 0.132        |\n",
      "|    value_loss           | 2.26e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3960000, episode_reward=15492.94 +/- 4448.62\n",
      "Episode length: 2229.00 +/- 13.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.23e+03     |\n",
      "|    mean_reward          | 1.55e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3960000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067903586 |\n",
      "|    clip_fraction        | 0.051        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.88         |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 35240        |\n",
      "|    policy_gradient_loss | -0.00651     |\n",
      "|    std                  | 0.132        |\n",
      "|    value_loss           | 3.82e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -5.92e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1934      |\n",
      "|    time_elapsed    | 7841      |\n",
      "|    total_timesteps | 3960832   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | -4.68e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1935        |\n",
      "|    time_elapsed         | 7842        |\n",
      "|    total_timesteps      | 3962880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011203237 |\n",
      "|    clip_fraction        | 0.0565      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.88        |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.71e+05    |\n",
      "|    n_updates            | 35250       |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    std                  | 0.132       |\n",
      "|    value_loss           | 4.65e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.58e+03     |\n",
      "|    ep_rew_mean          | -5.74e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 1936         |\n",
      "|    time_elapsed         | 7844         |\n",
      "|    total_timesteps      | 3964928      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056455145 |\n",
      "|    clip_fraction        | 0.0273       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.88         |\n",
      "|    explained_variance   | 0.766        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.39e+03     |\n",
      "|    n_updates            | 35260        |\n",
      "|    policy_gradient_loss | -0.00253     |\n",
      "|    std                  | 0.132        |\n",
      "|    value_loss           | 1.26e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3965000, episode_reward=10211.62 +/- 4221.42\n",
      "Episode length: 2246.20 +/- 10.78\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.25e+03     |\n",
      "|    mean_reward          | 1.02e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 3965000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039505195 |\n",
      "|    clip_fraction        | 0.0258       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.88         |\n",
      "|    explained_variance   | 0.825        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.58e+06     |\n",
      "|    n_updates            | 35270        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    std                  | 0.132        |\n",
      "|    value_loss           | 2.18e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.58e+03  |\n",
      "|    ep_rew_mean     | -5.12e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1937      |\n",
      "|    time_elapsed    | 7851      |\n",
      "|    total_timesteps | 3966976   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.56e+03     |\n",
      "|    ep_rew_mean          | -4.96e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 1938         |\n",
      "|    time_elapsed         | 7853         |\n",
      "|    total_timesteps      | 3969024      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056183087 |\n",
      "|    clip_fraction        | 0.0278       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.87         |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.04e+03     |\n",
      "|    n_updates            | 35280        |\n",
      "|    policy_gradient_loss | -0.00267     |\n",
      "|    std                  | 0.132        |\n",
      "|    value_loss           | 3.3e+05      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=3970000, episode_reward=10027.10 +/- 2944.71\n",
      "Episode length: 2578.00 +/- 9.01\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.58e+03   |\n",
      "|    mean_reward          | 1e+04      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3970000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.17212483 |\n",
      "|    clip_fraction        | 0.39       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.88       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 37.3       |\n",
      "|    n_updates            | 35290      |\n",
      "|    policy_gradient_loss | 0.00801    |\n",
      "|    std                  | 0.132      |\n",
      "|    value_loss           | 2.06e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -5.04e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1939      |\n",
      "|    time_elapsed    | 7861      |\n",
      "|    total_timesteps | 3971072   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.52e+03  |\n",
      "|    ep_rew_mean          | -6.57e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 505       |\n",
      "|    iterations           | 1940      |\n",
      "|    time_elapsed         | 7863      |\n",
      "|    total_timesteps      | 3973120   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.2576613 |\n",
      "|    clip_fraction        | 0.634     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.88      |\n",
      "|    explained_variance   | 0.998     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 42.8      |\n",
      "|    n_updates            | 35300     |\n",
      "|    policy_gradient_loss | 0.0431    |\n",
      "|    std                  | 0.132     |\n",
      "|    value_loss           | 536       |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3975000, episode_reward=16868.50 +/- 3417.78\n",
      "Episode length: 1480.00 +/- 18.94\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.48e+03   |\n",
      "|    mean_reward          | 1.69e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3975000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.34187084 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.87       |\n",
      "|    explained_variance   | 0.354      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.06e+07   |\n",
      "|    n_updates            | 35310      |\n",
      "|    policy_gradient_loss | -0.0151    |\n",
      "|    std                  | 0.132      |\n",
      "|    value_loss           | 2.24e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.53e+03  |\n",
      "|    ep_rew_mean     | -4.49e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1941      |\n",
      "|    time_elapsed    | 7868      |\n",
      "|    total_timesteps | 3975168   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -4.4e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1942        |\n",
      "|    time_elapsed         | 7870        |\n",
      "|    total_timesteps      | 3977216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018735819 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.88        |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 990         |\n",
      "|    n_updates            | 35320       |\n",
      "|    policy_gradient_loss | 0.0181      |\n",
      "|    std                  | 0.131       |\n",
      "|    value_loss           | 2.34e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -4.34e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1943        |\n",
      "|    time_elapsed         | 7872        |\n",
      "|    total_timesteps      | 3979264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.068075344 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.88        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 10.8        |\n",
      "|    n_updates            | 35330       |\n",
      "|    policy_gradient_loss | 0.0136      |\n",
      "|    std                  | 0.131       |\n",
      "|    value_loss           | 83.9        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=3980000, episode_reward=20789.97 +/- 2940.93\n",
      "Episode length: 2028.00 +/- 12.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.03e+03    |\n",
      "|    mean_reward          | 2.08e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3980000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013524488 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.87        |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.1e+05     |\n",
      "|    n_updates            | 35340       |\n",
      "|    policy_gradient_loss | 0.0222      |\n",
      "|    std                  | 0.131       |\n",
      "|    value_loss           | 3.13e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.51e+03 |\n",
      "|    ep_rew_mean     | -5.7e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1944     |\n",
      "|    time_elapsed    | 7879     |\n",
      "|    total_timesteps | 3981312  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.51e+03   |\n",
      "|    ep_rew_mean          | -5.64e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1945       |\n",
      "|    time_elapsed         | 7880       |\n",
      "|    total_timesteps      | 3983360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.25323904 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.88       |\n",
      "|    explained_variance   | 0.411      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 27.5       |\n",
      "|    n_updates            | 35350      |\n",
      "|    policy_gradient_loss | -0.0121    |\n",
      "|    std                  | 0.131      |\n",
      "|    value_loss           | 1.87e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3985000, episode_reward=20008.21 +/- 2847.85\n",
      "Episode length: 1970.60 +/- 5.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.97e+03    |\n",
      "|    mean_reward          | 2e+04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3985000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016748825 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.89        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 40.9        |\n",
      "|    n_updates            | 35360       |\n",
      "|    policy_gradient_loss | 0.00966     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 110         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.51e+03  |\n",
      "|    ep_rew_mean     | -5.57e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1946      |\n",
      "|    time_elapsed    | 7887      |\n",
      "|    total_timesteps | 3985408   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -5.51e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1947        |\n",
      "|    time_elapsed         | 7889        |\n",
      "|    total_timesteps      | 3987456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023059994 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.9         |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.8        |\n",
      "|    n_updates            | 35370       |\n",
      "|    policy_gradient_loss | 0.0141      |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 82.4        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -5.46e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1948        |\n",
      "|    time_elapsed         | 7891        |\n",
      "|    total_timesteps      | 3989504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031392366 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.91        |\n",
      "|    explained_variance   | 0.761       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 18.4        |\n",
      "|    n_updates            | 35380       |\n",
      "|    policy_gradient_loss | 0.00177     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 3.82e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=3990000, episode_reward=17245.96 +/- 5213.94\n",
      "Episode length: 1851.00 +/- 9.32\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.85e+03   |\n",
      "|    mean_reward          | 1.72e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 3990000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01935198 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.92       |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 19.4       |\n",
      "|    n_updates            | 35390      |\n",
      "|    policy_gradient_loss | 0.000562   |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 2.52e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -5.47e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1949      |\n",
      "|    time_elapsed    | 7897      |\n",
      "|    total_timesteps | 3991552   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.53e+03   |\n",
      "|    ep_rew_mean          | -5.45e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1950       |\n",
      "|    time_elapsed         | 7899       |\n",
      "|    total_timesteps      | 3993600    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09129857 |\n",
      "|    clip_fraction        | 0.38       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.93       |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 17.6       |\n",
      "|    n_updates            | 35400      |\n",
      "|    policy_gradient_loss | 0.046      |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 5.04e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=3995000, episode_reward=17090.42 +/- 4278.30\n",
      "Episode length: 1911.60 +/- 16.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.91e+03    |\n",
      "|    mean_reward          | 1.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 3995000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012911128 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 25.3        |\n",
      "|    n_updates            | 35410       |\n",
      "|    policy_gradient_loss | 0.0115      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 134         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | -5.4e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1951     |\n",
      "|    time_elapsed    | 7905     |\n",
      "|    total_timesteps | 3995648  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -4.03e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1952        |\n",
      "|    time_elapsed         | 7907        |\n",
      "|    total_timesteps      | 3997696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015354351 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.6        |\n",
      "|    n_updates            | 35420       |\n",
      "|    policy_gradient_loss | 0.00241     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 155         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | -2.54e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1953        |\n",
      "|    time_elapsed         | 7909        |\n",
      "|    total_timesteps      | 3999744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016385783 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.91        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.6        |\n",
      "|    n_updates            | 35430       |\n",
      "|    policy_gradient_loss | -0.00352    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 130         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4000000, episode_reward=22779.26 +/- 3814.86\n",
      "Episode length: 2401.00 +/- 11.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.4e+03     |\n",
      "|    mean_reward          | 2.28e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022367116 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.91        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 42.1        |\n",
      "|    n_updates            | 35440       |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 104         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.54e+03  |\n",
      "|    ep_rew_mean     | -2.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1954      |\n",
      "|    time_elapsed    | 7916      |\n",
      "|    total_timesteps | 4001792   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.53e+03   |\n",
      "|    ep_rew_mean          | -3.78e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1955       |\n",
      "|    time_elapsed         | 7918       |\n",
      "|    total_timesteps      | 4003840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.24779996 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.91       |\n",
      "|    explained_variance   | 0.352      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.08e+07   |\n",
      "|    n_updates            | 35450      |\n",
      "|    policy_gradient_loss | -0.00542   |\n",
      "|    std                  | 0.13       |\n",
      "|    value_loss           | 1.82e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4005000, episode_reward=22970.95 +/- 5127.49\n",
      "Episode length: 2536.80 +/- 14.50\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.54e+03  |\n",
      "|    mean_reward          | 2.3e+04   |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4005000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5209913 |\n",
      "|    clip_fraction        | 0.138     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.91      |\n",
      "|    explained_variance   | 0.425     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 6.97e+06  |\n",
      "|    n_updates            | 35460     |\n",
      "|    policy_gradient_loss | -0.0159   |\n",
      "|    std                  | 0.13      |\n",
      "|    value_loss           | 2.03e+07  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -1.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1956      |\n",
      "|    time_elapsed    | 7926      |\n",
      "|    total_timesteps | 4005888   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -1.49e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1957        |\n",
      "|    time_elapsed         | 7928        |\n",
      "|    total_timesteps      | 4007936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015609847 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.92        |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 316         |\n",
      "|    n_updates            | 35470       |\n",
      "|    policy_gradient_loss | 0.00343     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.43e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | -1.43e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1958        |\n",
      "|    time_elapsed         | 7930        |\n",
      "|    total_timesteps      | 4009984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.053772904 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.92        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 248         |\n",
      "|    n_updates            | 35480       |\n",
      "|    policy_gradient_loss | 0.0122      |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 2.33e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4010000, episode_reward=21687.12 +/- 3780.40\n",
      "Episode length: 1976.00 +/- 8.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.98e+03    |\n",
      "|    mean_reward          | 2.17e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.077686995 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 46.1        |\n",
      "|    n_updates            | 35490       |\n",
      "|    policy_gradient_loss | 0.0307      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 95.7        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -1.32e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 1959      |\n",
      "|    time_elapsed    | 7937      |\n",
      "|    total_timesteps | 4012032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.57e+03    |\n",
      "|    ep_rew_mean          | -1.23e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1960        |\n",
      "|    time_elapsed         | 7938        |\n",
      "|    total_timesteps      | 4014080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023200216 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30.9        |\n",
      "|    n_updates            | 35500       |\n",
      "|    policy_gradient_loss | 0.0106      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 209         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4015000, episode_reward=22760.75 +/- 724.37\n",
      "Episode length: 1775.20 +/- 8.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.78e+03    |\n",
      "|    mean_reward          | 2.28e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4015000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.051937617 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.1        |\n",
      "|    n_updates            | 35510       |\n",
      "|    policy_gradient_loss | -0.00248    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 4.85e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.59e+03 |\n",
      "|    ep_rew_mean     | 875      |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1961     |\n",
      "|    time_elapsed    | 7944     |\n",
      "|    total_timesteps | 4016128  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.59e+03  |\n",
      "|    ep_rew_mean          | -15       |\n",
      "| time/                   |           |\n",
      "|    fps                  | 505       |\n",
      "|    iterations           | 1962      |\n",
      "|    time_elapsed         | 7946      |\n",
      "|    total_timesteps      | 4018176   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.7839322 |\n",
      "|    clip_fraction        | 0.428     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.93      |\n",
      "|    explained_variance   | 0.999     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 21.4      |\n",
      "|    n_updates            | 35520     |\n",
      "|    policy_gradient_loss | 0.0491    |\n",
      "|    std                  | 0.13      |\n",
      "|    value_loss           | 106       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4020000, episode_reward=33048.94 +/- 1610.22\n",
      "Episode length: 3681.80 +/- 7.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.68e+03    |\n",
      "|    mean_reward          | 3.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027279332 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.92        |\n",
      "|    explained_variance   | 0.372       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.24e+06    |\n",
      "|    n_updates            | 35530       |\n",
      "|    policy_gradient_loss | 0.00967     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.46e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.61e+03 |\n",
      "|    ep_rew_mean     | 60       |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1963     |\n",
      "|    time_elapsed    | 7957     |\n",
      "|    total_timesteps | 4020224  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | 60          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1964        |\n",
      "|    time_elapsed         | 7959        |\n",
      "|    total_timesteps      | 4022272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009189193 |\n",
      "|    clip_fraction        | 0.0699      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.92        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 823         |\n",
      "|    n_updates            | 35540       |\n",
      "|    policy_gradient_loss | -0.00148    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.22e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | 14.7        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1965        |\n",
      "|    time_elapsed         | 7961        |\n",
      "|    total_timesteps      | 4024320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010060702 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.92        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 962         |\n",
      "|    n_updates            | 35550       |\n",
      "|    policy_gradient_loss | -0.0035     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 2.51e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4025000, episode_reward=33704.04 +/- 872.16\n",
      "Episode length: 3818.00 +/- 11.45\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.82e+03    |\n",
      "|    mean_reward          | 3.37e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4025000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017565634 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.92        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 410         |\n",
      "|    n_updates            | 35560       |\n",
      "|    policy_gradient_loss | -0.00875    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.91e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.63e+03 |\n",
      "|    ep_rew_mean     | 14.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 505      |\n",
      "|    iterations      | 1966     |\n",
      "|    time_elapsed    | 7971     |\n",
      "|    total_timesteps | 4026368  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | 35.8        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 1967        |\n",
      "|    time_elapsed         | 7973        |\n",
      "|    total_timesteps      | 4028416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011198197 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.92        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 145         |\n",
      "|    n_updates            | 35570       |\n",
      "|    policy_gradient_loss | 0.000451    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 602         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4030000, episode_reward=35342.85 +/- 4697.41\n",
      "Episode length: 3491.00 +/- 15.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.49e+03    |\n",
      "|    mean_reward          | 3.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017165376 |\n",
      "|    clip_fraction        | 0.0751      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.92        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 730         |\n",
      "|    n_updates            | 35580       |\n",
      "|    policy_gradient_loss | 0.00451     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 3.64e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.67e+03 |\n",
      "|    ep_rew_mean     | 167      |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1968     |\n",
      "|    time_elapsed    | 7983     |\n",
      "|    total_timesteps | 4030464  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67e+03    |\n",
      "|    ep_rew_mean          | 167         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1969        |\n",
      "|    time_elapsed         | 7985        |\n",
      "|    total_timesteps      | 4032512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010236691 |\n",
      "|    clip_fraction        | 0.0786      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 275         |\n",
      "|    n_updates            | 35590       |\n",
      "|    policy_gradient_loss | -0.00133    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.39e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.7e+03    |\n",
      "|    ep_rew_mean          | 369        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 1970       |\n",
      "|    time_elapsed         | 7987       |\n",
      "|    total_timesteps      | 4034560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05390969 |\n",
      "|    clip_fraction        | 0.36       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.93       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 25.3       |\n",
      "|    n_updates            | 35600      |\n",
      "|    policy_gradient_loss | 0.0266     |\n",
      "|    std                  | 0.13       |\n",
      "|    value_loss           | 64.8       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4035000, episode_reward=-51837.85 +/- 3753.04\n",
      "Episode length: 3856.00 +/- 4.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.86e+03    |\n",
      "|    mean_reward          | -5.18e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4035000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014683068 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65.7        |\n",
      "|    n_updates            | 35610       |\n",
      "|    policy_gradient_loss | 0.0146      |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.7e+03  |\n",
      "|    ep_rew_mean     | 369      |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1971     |\n",
      "|    time_elapsed    | 7998     |\n",
      "|    total_timesteps | 4036608  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.72e+03    |\n",
      "|    ep_rew_mean          | 201         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1972        |\n",
      "|    time_elapsed         | 8000        |\n",
      "|    total_timesteps      | 4038656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011706033 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 19.3        |\n",
      "|    n_updates            | 35620       |\n",
      "|    policy_gradient_loss | 0.0183      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 79.5        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4040000, episode_reward=-29624.48 +/- 2579.97\n",
      "Episode length: 3730.00 +/- 12.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.73e+03    |\n",
      "|    mean_reward          | -2.96e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006477411 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.752       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.31e+06    |\n",
      "|    n_updates            | 35630       |\n",
      "|    policy_gradient_loss | -0.00076    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.58e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.73e+03 |\n",
      "|    ep_rew_mean     | 360      |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1973     |\n",
      "|    time_elapsed    | 8011     |\n",
      "|    total_timesteps | 4040704  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.73e+03    |\n",
      "|    ep_rew_mean          | 360         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1974        |\n",
      "|    time_elapsed         | 8012        |\n",
      "|    total_timesteps      | 4042752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005412113 |\n",
      "|    clip_fraction        | 0.0426      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34e+04    |\n",
      "|    n_updates            | 35640       |\n",
      "|    policy_gradient_loss | -0.00587    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.33e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.76e+03   |\n",
      "|    ep_rew_mean          | -30.9      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 1975       |\n",
      "|    time_elapsed         | 8014       |\n",
      "|    total_timesteps      | 4044800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01946674 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.94       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 61.4       |\n",
      "|    n_updates            | 35650      |\n",
      "|    policy_gradient_loss | 0.00297    |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 194        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4045000, episode_reward=-25693.11 +/- 5998.38\n",
      "Episode length: 4062.60 +/- 14.57\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.06e+03     |\n",
      "|    mean_reward          | -2.57e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4045000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044551915 |\n",
      "|    clip_fraction        | 0.0641       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.904        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.89e+04     |\n",
      "|    n_updates            | 35660        |\n",
      "|    policy_gradient_loss | -0.00415     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.82e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.76e+03 |\n",
      "|    ep_rew_mean     | -30.9    |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 1976     |\n",
      "|    time_elapsed    | 8026     |\n",
      "|    total_timesteps | 4046848  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.78e+03    |\n",
      "|    ep_rew_mean          | 1.72e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 1977        |\n",
      "|    time_elapsed         | 8028        |\n",
      "|    total_timesteps      | 4048896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013417043 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 33.2        |\n",
      "|    n_updates            | 35670       |\n",
      "|    policy_gradient_loss | 0.00986     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 360         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4050000, episode_reward=-79565.10 +/- 3041.89\n",
      "Episode length: 4033.20 +/- 12.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.03e+03    |\n",
      "|    mean_reward          | -7.96e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011292822 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.4e+03     |\n",
      "|    n_updates            | 35680       |\n",
      "|    policy_gradient_loss | 0.00972     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 629         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.79e+03 |\n",
      "|    ep_rew_mean     | 1.87e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1978     |\n",
      "|    time_elapsed    | 8039     |\n",
      "|    total_timesteps | 4050944  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.79e+03   |\n",
      "|    ep_rew_mean          | 2.05e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 1979       |\n",
      "|    time_elapsed         | 8041       |\n",
      "|    total_timesteps      | 4052992    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05232392 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.93       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 14.6       |\n",
      "|    n_updates            | 35690      |\n",
      "|    policy_gradient_loss | 0.0207     |\n",
      "|    std                  | 0.13       |\n",
      "|    value_loss           | 202        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4055000, episode_reward=21754.41 +/- 2900.03\n",
      "Episode length: 2951.20 +/- 13.29\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.95e+03   |\n",
      "|    mean_reward          | 2.18e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4055000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15156114 |\n",
      "|    clip_fraction        | 0.386      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.92       |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 8.18       |\n",
      "|    n_updates            | 35700      |\n",
      "|    policy_gradient_loss | 0.0304     |\n",
      "|    std                  | 0.13       |\n",
      "|    value_loss           | 4.22e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.8e+03  |\n",
      "|    ep_rew_mean     | 2.17e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1980     |\n",
      "|    time_elapsed    | 8050     |\n",
      "|    total_timesteps | 4055040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.82e+03    |\n",
      "|    ep_rew_mean          | 2.29e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1981        |\n",
      "|    time_elapsed         | 8051        |\n",
      "|    total_timesteps      | 4057088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016146757 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 234         |\n",
      "|    n_updates            | 35710       |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 5.18e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.83e+03     |\n",
      "|    ep_rew_mean          | 2.33e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1982         |\n",
      "|    time_elapsed         | 8053         |\n",
      "|    total_timesteps      | 4059136      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055854097 |\n",
      "|    clip_fraction        | 0.127        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.92         |\n",
      "|    explained_variance   | 0.891        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.02e+03     |\n",
      "|    n_updates            | 35720        |\n",
      "|    policy_gradient_loss | -0.00133     |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 5.23e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4060000, episode_reward=8229.02 +/- 3525.45\n",
      "Episode length: 2183.20 +/- 10.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.18e+03    |\n",
      "|    mean_reward          | 8.23e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.113071635 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.3        |\n",
      "|    n_updates            | 35730       |\n",
      "|    policy_gradient_loss | 0.0126      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 9.74e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.83e+03 |\n",
      "|    ep_rew_mean     | 2.34e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1983     |\n",
      "|    time_elapsed    | 8060     |\n",
      "|    total_timesteps | 4061184  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.84e+03    |\n",
      "|    ep_rew_mean          | 2.22e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1984        |\n",
      "|    time_elapsed         | 8062        |\n",
      "|    total_timesteps      | 4063232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017548867 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.3        |\n",
      "|    n_updates            | 35740       |\n",
      "|    policy_gradient_loss | 0.00135     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 2.19e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4065000, episode_reward=-1887.97 +/- 3184.79\n",
      "Episode length: 2205.20 +/- 7.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.21e+03    |\n",
      "|    mean_reward          | -1.89e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4065000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005189724 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.567       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 35750       |\n",
      "|    policy_gradient_loss | 0.000711    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 9.25e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.85e+03 |\n",
      "|    ep_rew_mean     | 2.02e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1985     |\n",
      "|    time_elapsed    | 8069     |\n",
      "|    total_timesteps | 4065280  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.86e+03     |\n",
      "|    ep_rew_mean          | 1.86e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1986         |\n",
      "|    time_elapsed         | 8071         |\n",
      "|    total_timesteps      | 4067328      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024837677 |\n",
      "|    clip_fraction        | 0.166        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.93         |\n",
      "|    explained_variance   | 0.598        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.6e+06      |\n",
      "|    n_updates            | 35760        |\n",
      "|    policy_gradient_loss | 0.00249      |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 3.18e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.87e+03     |\n",
      "|    ep_rew_mean          | 1.86e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 1987         |\n",
      "|    time_elapsed         | 8073         |\n",
      "|    total_timesteps      | 4069376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030211343 |\n",
      "|    clip_fraction        | 0.0218       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.93         |\n",
      "|    explained_variance   | 0.74         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.53e+05     |\n",
      "|    n_updates            | 35770        |\n",
      "|    policy_gradient_loss | -0.00099     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.01e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4070000, episode_reward=17632.57 +/- 818.85\n",
      "Episode length: 3361.00 +/- 4.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.36e+03     |\n",
      "|    mean_reward          | 1.76e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4070000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063968757 |\n",
      "|    clip_fraction        | 0.0321       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.93         |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.24e+03     |\n",
      "|    n_updates            | 35780        |\n",
      "|    policy_gradient_loss | -0.0033      |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 2.12e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.87e+03 |\n",
      "|    ep_rew_mean     | 1.86e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1988     |\n",
      "|    time_elapsed    | 8083     |\n",
      "|    total_timesteps | 4071424  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.89e+03    |\n",
      "|    ep_rew_mean          | 1.92e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1989        |\n",
      "|    time_elapsed         | 8085        |\n",
      "|    total_timesteps      | 4073472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008323767 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 112         |\n",
      "|    n_updates            | 35790       |\n",
      "|    policy_gradient_loss | -0.00609    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 812         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4075000, episode_reward=-51407.44 +/- 2939.94\n",
      "Episode length: 3698.40 +/- 15.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.7e+03     |\n",
      "|    mean_reward          | -5.14e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4075000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007132771 |\n",
      "|    clip_fraction        | 0.0276      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38e+03    |\n",
      "|    n_updates            | 35800       |\n",
      "|    policy_gradient_loss | -0.000818   |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.08e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.91e+03 |\n",
      "|    ep_rew_mean     | 1.13e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1990     |\n",
      "|    time_elapsed    | 8095     |\n",
      "|    total_timesteps | 4075520  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.91e+03     |\n",
      "|    ep_rew_mean          | 1.13e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 1991         |\n",
      "|    time_elapsed         | 8097         |\n",
      "|    total_timesteps      | 4077568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049906154 |\n",
      "|    clip_fraction        | 0.0395       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.93         |\n",
      "|    explained_variance   | 0.728        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.53e+05     |\n",
      "|    n_updates            | 35810        |\n",
      "|    policy_gradient_loss | -0.000826    |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 8.07e+05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.93e+03    |\n",
      "|    ep_rew_mean          | 1.32e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1992        |\n",
      "|    time_elapsed         | 8099        |\n",
      "|    total_timesteps      | 4079616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015911248 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.93        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 50.4        |\n",
      "|    n_updates            | 35820       |\n",
      "|    policy_gradient_loss | 0.0036      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 159         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4080000, episode_reward=22506.29 +/- 3724.39\n",
      "Episode length: 2842.60 +/- 14.72\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.84e+03     |\n",
      "|    mean_reward          | 2.25e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056669945 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.882        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.88e+03     |\n",
      "|    n_updates            | 35830        |\n",
      "|    policy_gradient_loss | 0.00141      |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.52e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.94e+03 |\n",
      "|    ep_rew_mean     | 1.21e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1993     |\n",
      "|    time_elapsed    | 8108     |\n",
      "|    total_timesteps | 4081664  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.95e+03    |\n",
      "|    ep_rew_mean          | 1.13e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1994        |\n",
      "|    time_elapsed         | 8109        |\n",
      "|    total_timesteps      | 4083712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001957852 |\n",
      "|    clip_fraction        | 0.00298     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.491       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.05e+03    |\n",
      "|    n_updates            | 35840       |\n",
      "|    policy_gradient_loss | -0.00169    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 2.15e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4085000, episode_reward=-71789.12 +/- 3470.87\n",
      "Episode length: 3816.20 +/- 7.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.82e+03    |\n",
      "|    mean_reward          | -7.18e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4085000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005081373 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.19e+04    |\n",
      "|    n_updates            | 35850       |\n",
      "|    policy_gradient_loss | -0.000601   |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.03e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.95e+03 |\n",
      "|    ep_rew_mean     | 1.13e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 503      |\n",
      "|    iterations      | 1995     |\n",
      "|    time_elapsed    | 8120     |\n",
      "|    total_timesteps | 4085760  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.98e+03    |\n",
      "|    ep_rew_mean          | 3.24e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1996        |\n",
      "|    time_elapsed         | 8122        |\n",
      "|    total_timesteps      | 4087808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014755575 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 65          |\n",
      "|    n_updates            | 35860       |\n",
      "|    policy_gradient_loss | 0.00101     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 348         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2e+03       |\n",
      "|    ep_rew_mean          | 3.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 1997        |\n",
      "|    time_elapsed         | 8124        |\n",
      "|    total_timesteps      | 4089856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002593561 |\n",
      "|    clip_fraction        | 0.039       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.27e+03    |\n",
      "|    n_updates            | 35870       |\n",
      "|    policy_gradient_loss | -0.00407    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 8.49e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4090000, episode_reward=44930.35 +/- 2777.12\n",
      "Episode length: 4229.60 +/- 11.88\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.23e+03     |\n",
      "|    mean_reward          | 4.49e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4090000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047258306 |\n",
      "|    clip_fraction        | 0.0343       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.54e+03     |\n",
      "|    n_updates            | 35880        |\n",
      "|    policy_gradient_loss | -0.00266     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 5.39e+04     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2e+03    |\n",
      "|    ep_rew_mean     | 3.27e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 1998     |\n",
      "|    time_elapsed    | 8136     |\n",
      "|    total_timesteps | 4091904  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.03e+03   |\n",
      "|    ep_rew_mean          | 3.3e+03    |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 1999       |\n",
      "|    time_elapsed         | 8138       |\n",
      "|    total_timesteps      | 4093952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06685428 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.94       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 43.8       |\n",
      "|    n_updates            | 35890      |\n",
      "|    policy_gradient_loss | 0.00767    |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 211        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4095000, episode_reward=60089.86 +/- 3850.64\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.01e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4095000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017496154 |\n",
      "|    clip_fraction        | 0.437       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.69e+03    |\n",
      "|    n_updates            | 35900       |\n",
      "|    policy_gradient_loss | 0.0273      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.19e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.03e+03 |\n",
      "|    ep_rew_mean     | 3.3e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 8152     |\n",
      "|    total_timesteps | 4096000  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.05e+03   |\n",
      "|    ep_rew_mean          | 3.47e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 2001       |\n",
      "|    time_elapsed         | 8153       |\n",
      "|    total_timesteps      | 4098048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01973353 |\n",
      "|    clip_fraction        | 0.216      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.94       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 82.4       |\n",
      "|    n_updates            | 35910      |\n",
      "|    policy_gradient_loss | -0.00418   |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 223        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4100000, episode_reward=25898.27 +/- 3791.94\n",
      "Episode length: 3865.00 +/- 9.10\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.86e+03     |\n",
      "|    mean_reward          | 2.59e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4100000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025336072 |\n",
      "|    clip_fraction        | 0.0232       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.915        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 576          |\n",
      "|    n_updates            | 35920        |\n",
      "|    policy_gradient_loss | -0.00305     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.03e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.05e+03 |\n",
      "|    ep_rew_mean     | 3.47e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 2002     |\n",
      "|    time_elapsed    | 8164     |\n",
      "|    total_timesteps | 4100096  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.08e+03    |\n",
      "|    ep_rew_mean          | 3.44e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 2003        |\n",
      "|    time_elapsed         | 8166        |\n",
      "|    total_timesteps      | 4102144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004646807 |\n",
      "|    clip_fraction        | 0.0278      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.73e+03    |\n",
      "|    n_updates            | 35930       |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 4.4e+03     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.09e+03    |\n",
      "|    ep_rew_mean          | 3.27e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 2004        |\n",
      "|    time_elapsed         | 8168        |\n",
      "|    total_timesteps      | 4104192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013639368 |\n",
      "|    clip_fraction        | 0.0984      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.9         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.02e+05    |\n",
      "|    n_updates            | 35940       |\n",
      "|    policy_gradient_loss | 0.00769     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.86e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4105000, episode_reward=29371.20 +/- 1685.54\n",
      "Episode length: 3285.80 +/- 1.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.29e+03    |\n",
      "|    mean_reward          | 2.94e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4105000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005182766 |\n",
      "|    clip_fraction        | 0.0438      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.24e+06    |\n",
      "|    n_updates            | 35950       |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.4e+06     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.1e+03  |\n",
      "|    ep_rew_mean     | 3.38e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 502      |\n",
      "|    iterations      | 2005     |\n",
      "|    time_elapsed    | 8178     |\n",
      "|    total_timesteps | 4106240  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.12e+03     |\n",
      "|    ep_rew_mean          | 3.48e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 502          |\n",
      "|    iterations           | 2006         |\n",
      "|    time_elapsed         | 8180         |\n",
      "|    total_timesteps      | 4108288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033007944 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.36e+04     |\n",
      "|    n_updates            | 35960        |\n",
      "|    policy_gradient_loss | -0.00522     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 4e+04        |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4110000, episode_reward=6637.64 +/- 70450.90\n",
      "Episode length: 3065.60 +/- 1489.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.07e+03    |\n",
      "|    mean_reward          | 6.64e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006373401 |\n",
      "|    clip_fraction        | 0.0614      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.82e+03    |\n",
      "|    n_updates            | 35970       |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 6.87e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.12e+03 |\n",
      "|    ep_rew_mean     | 3.48e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 2007     |\n",
      "|    time_elapsed    | 8189     |\n",
      "|    total_timesteps | 4110336  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.14e+03    |\n",
      "|    ep_rew_mean          | 3.68e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 2008        |\n",
      "|    time_elapsed         | 8191        |\n",
      "|    total_timesteps      | 4112384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047234092 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.6        |\n",
      "|    n_updates            | 35980       |\n",
      "|    policy_gradient_loss | 0.0153      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 85          |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.14e+03    |\n",
      "|    ep_rew_mean          | 3.68e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 2009        |\n",
      "|    time_elapsed         | 8193        |\n",
      "|    total_timesteps      | 4114432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007003653 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 35990       |\n",
      "|    policy_gradient_loss | 0.00612     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 4.45e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4115000, episode_reward=-39508.41 +/- 3914.32\n",
      "Episode length: 4056.00 +/- 8.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.06e+03    |\n",
      "|    mean_reward          | -3.95e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4115000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023060251 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.986       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 80.9        |\n",
      "|    n_updates            | 36000       |\n",
      "|    policy_gradient_loss | 0.00256     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 193         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.16e+03 |\n",
      "|    ep_rew_mean     | 3.82e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 2010     |\n",
      "|    time_elapsed    | 8204     |\n",
      "|    total_timesteps | 4116480  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.16e+03     |\n",
      "|    ep_rew_mean          | 3.82e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2011         |\n",
      "|    time_elapsed         | 8206         |\n",
      "|    total_timesteps      | 4118528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024291629 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.12e+05     |\n",
      "|    n_updates            | 36010        |\n",
      "|    policy_gradient_loss | 0.000561     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.12e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4120000, episode_reward=-7597.11 +/- 3864.70\n",
      "Episode length: 3619.00 +/- 13.61\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.62e+03     |\n",
      "|    mean_reward          | -7.6e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4120000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043690456 |\n",
      "|    clip_fraction        | 0.0322       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 335          |\n",
      "|    n_updates            | 36020        |\n",
      "|    policy_gradient_loss | -0.00206     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.6e+03      |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.19e+03 |\n",
      "|    ep_rew_mean     | 4.01e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 2012     |\n",
      "|    time_elapsed    | 8216     |\n",
      "|    total_timesteps | 4120576  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.21e+03    |\n",
      "|    ep_rew_mean          | 4.11e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2013        |\n",
      "|    time_elapsed         | 8218        |\n",
      "|    total_timesteps      | 4122624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002090617 |\n",
      "|    clip_fraction        | 0.027       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 146         |\n",
      "|    n_updates            | 36030       |\n",
      "|    policy_gradient_loss | -0.00172    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 4.21e+04    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.21e+03     |\n",
      "|    ep_rew_mean          | 4.11e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2014         |\n",
      "|    time_elapsed         | 8220         |\n",
      "|    total_timesteps      | 4124672      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061053447 |\n",
      "|    clip_fraction        | 0.062        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 36040        |\n",
      "|    policy_gradient_loss | 0.000771     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 6.66e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4125000, episode_reward=25821.41 +/- 2621.66\n",
      "Episode length: 3047.00 +/- 13.16\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.05e+03     |\n",
      "|    mean_reward          | 2.58e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4125000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062518455 |\n",
      "|    clip_fraction        | 0.155        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.987        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 69.4         |\n",
      "|    n_updates            | 36050        |\n",
      "|    policy_gradient_loss | 0.00982      |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 229          |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.23e+03 |\n",
      "|    ep_rew_mean     | 4.02e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 2015     |\n",
      "|    time_elapsed    | 8229     |\n",
      "|    total_timesteps | 4126720  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.25e+03     |\n",
      "|    ep_rew_mean          | 4.12e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2016         |\n",
      "|    time_elapsed         | 8231         |\n",
      "|    total_timesteps      | 4128768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032057855 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 576          |\n",
      "|    n_updates            | 36060        |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 8.18e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4130000, episode_reward=24792.24 +/- 1111.19\n",
      "Episode length: 2760.40 +/- 8.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.76e+03    |\n",
      "|    mean_reward          | 2.48e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008322372 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 183         |\n",
      "|    n_updates            | 36070       |\n",
      "|    policy_gradient_loss | -0.0041     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.51e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.25e+03 |\n",
      "|    ep_rew_mean     | 4.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 2017     |\n",
      "|    time_elapsed    | 8239     |\n",
      "|    total_timesteps | 4130816  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26e+03    |\n",
      "|    ep_rew_mean          | 4.07e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2018        |\n",
      "|    time_elapsed         | 8241        |\n",
      "|    total_timesteps      | 4132864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023346107 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.2        |\n",
      "|    n_updates            | 36080       |\n",
      "|    policy_gradient_loss | -0.00299    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 291         |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.28e+03     |\n",
      "|    ep_rew_mean          | 4.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2019         |\n",
      "|    time_elapsed         | 8243         |\n",
      "|    total_timesteps      | 4134912      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051463237 |\n",
      "|    clip_fraction        | 0.0352       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.86e+03     |\n",
      "|    n_updates            | 36090        |\n",
      "|    policy_gradient_loss | -0.00335     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.15e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4135000, episode_reward=-58840.83 +/- 2847.50\n",
      "Episode length: 3744.80 +/- 14.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.74e+03    |\n",
      "|    mean_reward          | -5.88e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4135000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018090636 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.41e+03    |\n",
      "|    n_updates            | 36100       |\n",
      "|    policy_gradient_loss | -0.000768   |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 4.11e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.28e+03 |\n",
      "|    ep_rew_mean     | 4.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 2020     |\n",
      "|    time_elapsed    | 8254     |\n",
      "|    total_timesteps | 4136960  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.3e+03      |\n",
      "|    ep_rew_mean          | 3.39e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2021         |\n",
      "|    time_elapsed         | 8256         |\n",
      "|    total_timesteps      | 4139008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0131855225 |\n",
      "|    clip_fraction        | 0.113        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.985        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 234          |\n",
      "|    n_updates            | 36110        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 915          |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4140000, episode_reward=-32266.06 +/- 4190.06\n",
      "Episode length: 3520.80 +/- 13.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.52e+03     |\n",
      "|    mean_reward          | -3.23e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4140000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051989676 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.835        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.2e+05      |\n",
      "|    n_updates            | 36120        |\n",
      "|    policy_gradient_loss | 0.00732      |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 7.08e+05     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.3e+03  |\n",
      "|    ep_rew_mean     | 3.39e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 500      |\n",
      "|    iterations      | 2022     |\n",
      "|    time_elapsed    | 8266     |\n",
      "|    total_timesteps | 4141056  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.32e+03     |\n",
      "|    ep_rew_mean          | 2.48e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2023         |\n",
      "|    time_elapsed         | 8268         |\n",
      "|    total_timesteps      | 4143104      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056669484 |\n",
      "|    clip_fraction        | 0.0368       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33e+04     |\n",
      "|    n_updates            | 36130        |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 4.76e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4145000, episode_reward=-286254.66 +/- 3146.00\n",
      "Episode length: 1853.20 +/- 5.91\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.85e+03  |\n",
      "|    mean_reward          | -2.86e+05 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4145000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 3.0207171 |\n",
      "|    clip_fraction        | 0.593     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.95      |\n",
      "|    explained_variance   | 0.872     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 9.55e+05  |\n",
      "|    n_updates            | 36140     |\n",
      "|    policy_gradient_loss | 0.0881    |\n",
      "|    std                  | 0.129     |\n",
      "|    value_loss           | 1.67e+06  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.34e+03  |\n",
      "|    ep_rew_mean     | -1.12e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 2024      |\n",
      "|    time_elapsed    | 8274      |\n",
      "|    total_timesteps | 4145152   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | -4.54e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2025        |\n",
      "|    time_elapsed         | 8276        |\n",
      "|    total_timesteps      | 4147200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005805334 |\n",
      "|    clip_fraction        | 0.0783      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.391       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+07    |\n",
      "|    n_updates            | 36150       |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 7.14e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | -7.19e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2026        |\n",
      "|    time_elapsed         | 8278        |\n",
      "|    total_timesteps      | 4149248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004356996 |\n",
      "|    clip_fraction        | 0.0142      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.389       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.77e+07    |\n",
      "|    n_updates            | 36160       |\n",
      "|    policy_gradient_loss | -0.00355    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 7.36e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4150000, episode_reward=-40318.61 +/- 3001.83\n",
      "Episode length: 1858.80 +/- 10.19\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.86e+03     |\n",
      "|    mean_reward          | -4.03e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4150000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057690246 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.395        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.71e+07     |\n",
      "|    n_updates            | 36170        |\n",
      "|    policy_gradient_loss | -0.000907    |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 6.01e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.36e+03  |\n",
      "|    ep_rew_mean     | -5.89e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 2027      |\n",
      "|    time_elapsed    | 8284      |\n",
      "|    total_timesteps | 4151296   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.36e+03    |\n",
      "|    ep_rew_mean          | -6.11e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2028        |\n",
      "|    time_elapsed         | 8286        |\n",
      "|    total_timesteps      | 4153344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004077985 |\n",
      "|    clip_fraction        | 0.0373      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.68        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.25e+06    |\n",
      "|    n_updates            | 36180       |\n",
      "|    policy_gradient_loss | 0.000495    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 3.37e+06    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4155000, episode_reward=-29966.06 +/- 2833.26\n",
      "Episode length: 1953.80 +/- 10.51\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.95e+03    |\n",
      "|    mean_reward          | -3e+04      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4155000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008579992 |\n",
      "|    clip_fraction        | 0.0908      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+04    |\n",
      "|    n_updates            | 36190       |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 9.71e+05    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.35e+03 |\n",
      "|    ep_rew_mean     | -6.4e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 501      |\n",
      "|    iterations      | 2029     |\n",
      "|    time_elapsed    | 8292     |\n",
      "|    total_timesteps | 4155392  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.36e+03     |\n",
      "|    ep_rew_mean          | -6.75e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2030         |\n",
      "|    time_elapsed         | 8294         |\n",
      "|    total_timesteps      | 4157440      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052989777 |\n",
      "|    clip_fraction        | 0.0393       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.91e+05     |\n",
      "|    n_updates            | 36200        |\n",
      "|    policy_gradient_loss | -0.00242     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.63e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.37e+03     |\n",
      "|    ep_rew_mean          | -6.75e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2031         |\n",
      "|    time_elapsed         | 8296         |\n",
      "|    total_timesteps      | 4159488      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043472913 |\n",
      "|    clip_fraction        | 0.0747       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.47e+06     |\n",
      "|    n_updates            | 36210        |\n",
      "|    policy_gradient_loss | -0.000985    |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 2.71e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4160000, episode_reward=25232.37 +/- 2920.57\n",
      "Episode length: 3001.80 +/- 6.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3e+03        |\n",
      "|    mean_reward          | 2.52e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4160000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040519834 |\n",
      "|    clip_fraction        | 0.0748       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.97         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 542          |\n",
      "|    n_updates            | 36220        |\n",
      "|    policy_gradient_loss | -0.00362     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.1e+05      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.38e+03  |\n",
      "|    ep_rew_mean     | -6.74e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 2032      |\n",
      "|    time_elapsed    | 8305      |\n",
      "|    total_timesteps | 4161536   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.38e+03     |\n",
      "|    ep_rew_mean          | -6.74e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2033         |\n",
      "|    time_elapsed         | 8307         |\n",
      "|    total_timesteps      | 4163584      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034107682 |\n",
      "|    clip_fraction        | 0.0185       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.57e+03     |\n",
      "|    n_updates            | 36230        |\n",
      "|    policy_gradient_loss | -0.00294     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 4.34e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4165000, episode_reward=29602.75 +/- 2866.90\n",
      "Episode length: 3372.60 +/- 7.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.37e+03    |\n",
      "|    mean_reward          | 2.96e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4165000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005148533 |\n",
      "|    clip_fraction        | 0.071       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 577         |\n",
      "|    n_updates            | 36240       |\n",
      "|    policy_gradient_loss | 0.00284     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.81e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.38e+03 |\n",
      "|    ep_rew_mean     | -6.8e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 500      |\n",
      "|    iterations      | 2034     |\n",
      "|    time_elapsed    | 8316     |\n",
      "|    total_timesteps | 4165632  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | -5.99e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2035        |\n",
      "|    time_elapsed         | 8318        |\n",
      "|    total_timesteps      | 4167680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026561223 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 581         |\n",
      "|    n_updates            | 36250       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.05e+05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | -5.91e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2036        |\n",
      "|    time_elapsed         | 8320        |\n",
      "|    total_timesteps      | 4169728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008451219 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 218         |\n",
      "|    n_updates            | 36260       |\n",
      "|    policy_gradient_loss | -0.000319   |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 7.47e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4170000, episode_reward=-38009.08 +/- 2617.02\n",
      "Episode length: 3134.60 +/- 4.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.13e+03    |\n",
      "|    mean_reward          | -3.8e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016151395 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 126         |\n",
      "|    n_updates            | 36270       |\n",
      "|    policy_gradient_loss | 0.00498     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.29e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.38e+03  |\n",
      "|    ep_rew_mean     | -5.91e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 2037      |\n",
      "|    time_elapsed    | 8329      |\n",
      "|    total_timesteps | 4171776   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.35e+03    |\n",
      "|    ep_rew_mean          | -8.75e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2038        |\n",
      "|    time_elapsed         | 8331        |\n",
      "|    total_timesteps      | 4173824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012118263 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 76.6        |\n",
      "|    n_updates            | 36280       |\n",
      "|    policy_gradient_loss | 0.00696     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 701         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4175000, episode_reward=33177.47 +/- 4122.70\n",
      "Episode length: 3273.40 +/- 8.59\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.27e+03   |\n",
      "|    mean_reward          | 3.32e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4175000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00822454 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.95       |\n",
      "|    explained_variance   | 0.335      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.71e+06   |\n",
      "|    n_updates            | 36290      |\n",
      "|    policy_gradient_loss | -0.000573  |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 3.62e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.34e+03  |\n",
      "|    ep_rew_mean     | -9.75e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 2039      |\n",
      "|    time_elapsed    | 8341      |\n",
      "|    total_timesteps | 4175872   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.34e+03     |\n",
      "|    ep_rew_mean          | -9.72e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 500          |\n",
      "|    iterations           | 2040         |\n",
      "|    time_elapsed         | 8343         |\n",
      "|    total_timesteps      | 4177920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011474709 |\n",
      "|    clip_fraction        | 0.00601      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.52         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.73e+06     |\n",
      "|    n_updates            | 36300        |\n",
      "|    policy_gradient_loss | -0.00252     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.32e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | -9.72e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2041        |\n",
      "|    time_elapsed         | 8344        |\n",
      "|    total_timesteps      | 4179968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005889656 |\n",
      "|    clip_fraction        | 0.0562      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.89e+03    |\n",
      "|    n_updates            | 36310       |\n",
      "|    policy_gradient_loss | -0.0087     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.46e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4180000, episode_reward=37780.84 +/- 4386.61\n",
      "Episode length: 3248.60 +/- 15.37\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.25e+03    |\n",
      "|    mean_reward          | 3.78e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4180000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013581747 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.52e+03    |\n",
      "|    n_updates            | 36320       |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 2.35e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.34e+03  |\n",
      "|    ep_rew_mean     | -9.68e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 2042      |\n",
      "|    time_elapsed    | 8354      |\n",
      "|    total_timesteps | 4182016   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34e+03    |\n",
      "|    ep_rew_mean          | -9.68e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2043        |\n",
      "|    time_elapsed         | 8356        |\n",
      "|    total_timesteps      | 4184064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008780982 |\n",
      "|    clip_fraction        | 0.0662      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 625         |\n",
      "|    n_updates            | 36330       |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 5.86e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4185000, episode_reward=38051.60 +/- 4415.56\n",
      "Episode length: 3371.40 +/- 9.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.37e+03    |\n",
      "|    mean_reward          | 3.81e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4185000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004039605 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 370         |\n",
      "|    n_updates            | 36340       |\n",
      "|    policy_gradient_loss | 0.000333    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 2.18e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.36e+03  |\n",
      "|    ep_rew_mean     | -9.39e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 2044      |\n",
      "|    time_elapsed    | 8366      |\n",
      "|    total_timesteps | 4186112   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.36e+03    |\n",
      "|    ep_rew_mean          | -9.14e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2045        |\n",
      "|    time_elapsed         | 8368        |\n",
      "|    total_timesteps      | 4188160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003823678 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.78e+03    |\n",
      "|    n_updates            | 36350       |\n",
      "|    policy_gradient_loss | -0.00396    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.06e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4190000, episode_reward=47797.77 +/- 3193.99\n",
      "Episode length: 4210.60 +/- 3.26\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.21e+03     |\n",
      "|    mean_reward          | 4.78e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4190000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071027963 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 740          |\n",
      "|    n_updates            | 36360        |\n",
      "|    policy_gradient_loss | -0.00338     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 3.59e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.36e+03  |\n",
      "|    ep_rew_mean     | -9.14e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 2046      |\n",
      "|    time_elapsed    | 8379      |\n",
      "|    total_timesteps | 4190208   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | -9.62e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2047        |\n",
      "|    time_elapsed         | 8381        |\n",
      "|    total_timesteps      | 4192256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012904381 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 171         |\n",
      "|    n_updates            | 36370       |\n",
      "|    policy_gradient_loss | 0.0037      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 877         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.38e+03    |\n",
      "|    ep_rew_mean          | -8.61e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2048        |\n",
      "|    time_elapsed         | 8383        |\n",
      "|    total_timesteps      | 4194304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005475303 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.456       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.95e+07    |\n",
      "|    n_updates            | 36380       |\n",
      "|    policy_gradient_loss | -0.00223    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.15e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4195000, episode_reward=-31225.36 +/- 2984.38\n",
      "Episode length: 4464.00 +/- 5.10\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 4.46e+03   |\n",
      "|    mean_reward          | -3.12e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4195000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03047951 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.95       |\n",
      "|    explained_variance   | 0.649      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 283        |\n",
      "|    n_updates            | 36390      |\n",
      "|    policy_gradient_loss | 0.00653    |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 3.13e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.38e+03  |\n",
      "|    ep_rew_mean     | -8.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 2049      |\n",
      "|    time_elapsed    | 8396      |\n",
      "|    total_timesteps | 4196352   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | -7.08e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 2050        |\n",
      "|    time_elapsed         | 8398        |\n",
      "|    total_timesteps      | 4198400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013773122 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 259         |\n",
      "|    n_updates            | 36400       |\n",
      "|    policy_gradient_loss | 0.00294     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.15e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4200000, episode_reward=58541.07 +/- 3506.99\n",
      "Episode length: 4834.00 +/- 5.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.83e+03     |\n",
      "|    mean_reward          | 5.85e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029419176 |\n",
      "|    clip_fraction        | 0.17         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.667        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.72e+06     |\n",
      "|    n_updates            | 36410        |\n",
      "|    policy_gradient_loss | 0.00358      |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.89e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.42e+03  |\n",
      "|    ep_rew_mean     | -7.08e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 2051      |\n",
      "|    time_elapsed    | 8411      |\n",
      "|    total_timesteps | 4200448   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.42e+03    |\n",
      "|    ep_rew_mean          | -6.78e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 2052        |\n",
      "|    time_elapsed         | 8413        |\n",
      "|    total_timesteps      | 4202496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031424627 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 36420       |\n",
      "|    policy_gradient_loss | 0.00339     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 883         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.42e+03     |\n",
      "|    ep_rew_mean          | -6.78e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 499          |\n",
      "|    iterations           | 2053         |\n",
      "|    time_elapsed         | 8415         |\n",
      "|    total_timesteps      | 4204544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066373274 |\n",
      "|    clip_fraction        | 0.201        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.14e+03     |\n",
      "|    n_updates            | 36430        |\n",
      "|    policy_gradient_loss | 0.0134       |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 8.5e+03      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4205000, episode_reward=32913.65 +/- 3221.23\n",
      "Episode length: 3459.00 +/- 5.10\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.46e+03    |\n",
      "|    mean_reward          | 3.29e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4205000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024284981 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.3        |\n",
      "|    n_updates            | 36440       |\n",
      "|    policy_gradient_loss | -0.000112   |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 205         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.41e+03  |\n",
      "|    ep_rew_mean     | -6.84e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 2054      |\n",
      "|    time_elapsed    | 8425      |\n",
      "|    total_timesteps | 4206592   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.41e+03     |\n",
      "|    ep_rew_mean          | -6.84e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 499          |\n",
      "|    iterations           | 2055         |\n",
      "|    time_elapsed         | 8426         |\n",
      "|    total_timesteps      | 4208640      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034773587 |\n",
      "|    clip_fraction        | 0.0302       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.367        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.14e+06     |\n",
      "|    n_updates            | 36450        |\n",
      "|    policy_gradient_loss | -0.000422    |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 2.57e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4210000, episode_reward=39073.53 +/- 3682.13\n",
      "Episode length: 3535.40 +/- 13.11\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.54e+03    |\n",
      "|    mean_reward          | 3.91e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010808224 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 141         |\n",
      "|    n_updates            | 36460       |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 383         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.42e+03  |\n",
      "|    ep_rew_mean     | -6.45e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 2056      |\n",
      "|    time_elapsed    | 8437      |\n",
      "|    total_timesteps | 4210688   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.44e+03    |\n",
      "|    ep_rew_mean          | -6.38e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 2057        |\n",
      "|    time_elapsed         | 8438        |\n",
      "|    total_timesteps      | 4212736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010443311 |\n",
      "|    clip_fraction        | 0.0814      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.47e+03    |\n",
      "|    n_updates            | 36470       |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 5.39e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.44e+03   |\n",
      "|    ep_rew_mean          | -6.38e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 499        |\n",
      "|    iterations           | 2058       |\n",
      "|    time_elapsed         | 8440       |\n",
      "|    total_timesteps      | 4214784    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01159922 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.95       |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 278        |\n",
      "|    n_updates            | 36480      |\n",
      "|    policy_gradient_loss | -0.00145   |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 2.83e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4215000, episode_reward=33865.85 +/- 3907.78\n",
      "Episode length: 3558.60 +/- 10.54\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.56e+03   |\n",
      "|    mean_reward          | 3.39e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4215000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01075522 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.95       |\n",
      "|    explained_variance   | 0.882      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 322        |\n",
      "|    n_updates            | 36490      |\n",
      "|    policy_gradient_loss | 0.00674    |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 1.91e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.45e+03  |\n",
      "|    ep_rew_mean     | -6.66e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 498       |\n",
      "|    iterations      | 2059      |\n",
      "|    time_elapsed    | 8450      |\n",
      "|    total_timesteps | 4216832   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.45e+03     |\n",
      "|    ep_rew_mean          | -6.66e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 499          |\n",
      "|    iterations           | 2060         |\n",
      "|    time_elapsed         | 8452         |\n",
      "|    total_timesteps      | 4218880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053379224 |\n",
      "|    clip_fraction        | 0.0657       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.382        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.34e+04     |\n",
      "|    n_updates            | 36500        |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 3.26e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4220000, episode_reward=13353.01 +/- 73068.59\n",
      "Episode length: 3819.60 +/- 1869.81\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.82e+03   |\n",
      "|    mean_reward          | 1.34e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4220000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00767952 |\n",
      "|    clip_fraction        | 0.0691     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.95       |\n",
      "|    explained_variance   | 0.97       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 291        |\n",
      "|    n_updates            | 36510      |\n",
      "|    policy_gradient_loss | -0.000182  |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 1.84e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.47e+03  |\n",
      "|    ep_rew_mean     | -6.44e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 498       |\n",
      "|    iterations      | 2061      |\n",
      "|    time_elapsed    | 8463      |\n",
      "|    total_timesteps | 4220928   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.51e+03    |\n",
      "|    ep_rew_mean          | -4.71e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2062        |\n",
      "|    time_elapsed         | 8465        |\n",
      "|    total_timesteps      | 4222976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008493583 |\n",
      "|    clip_fraction        | 0.0792      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.39e+04    |\n",
      "|    n_updates            | 36520       |\n",
      "|    policy_gradient_loss | 0.0012      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 3.12e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4225000, episode_reward=43286.09 +/- 1893.13\n",
      "Episode length: 3812.00 +/- 5.25\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.81e+03     |\n",
      "|    mean_reward          | 4.33e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4225000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073597515 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.83         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+03     |\n",
      "|    n_updates            | 36530        |\n",
      "|    policy_gradient_loss | -0.00121     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 2.48e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.51e+03  |\n",
      "|    ep_rew_mean     | -4.71e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 498       |\n",
      "|    iterations      | 2063      |\n",
      "|    time_elapsed    | 8476      |\n",
      "|    total_timesteps | 4225024   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.53e+03   |\n",
      "|    ep_rew_mean          | -5.28e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 498        |\n",
      "|    iterations           | 2064       |\n",
      "|    time_elapsed         | 8478       |\n",
      "|    total_timesteps      | 4227072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02137849 |\n",
      "|    clip_fraction        | 0.314      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.95       |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 145        |\n",
      "|    n_updates            | 36540      |\n",
      "|    policy_gradient_loss | 0.0127     |\n",
      "|    std                  | 0.13       |\n",
      "|    value_loss           | 578        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.53e+03    |\n",
      "|    ep_rew_mean          | -5.28e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2065        |\n",
      "|    time_elapsed         | 8479        |\n",
      "|    total_timesteps      | 4229120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004817469 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.78        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.38e+04    |\n",
      "|    n_updates            | 36550       |\n",
      "|    policy_gradient_loss | 0.00515     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 2e+05       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4230000, episode_reward=26738.66 +/- 3247.02\n",
      "Episode length: 3384.60 +/- 10.31\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.38e+03    |\n",
      "|    mean_reward          | 2.67e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017611783 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 36560       |\n",
      "|    policy_gradient_loss | 0.0148      |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 424         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.55e+03 |\n",
      "|    ep_rew_mean     | -5.2e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 498      |\n",
      "|    iterations      | 2066     |\n",
      "|    time_elapsed    | 8489     |\n",
      "|    total_timesteps | 4231168  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.56e+03    |\n",
      "|    ep_rew_mean          | -5.15e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2067        |\n",
      "|    time_elapsed         | 8491        |\n",
      "|    total_timesteps      | 4233216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017785106 |\n",
      "|    clip_fraction        | 0.0746      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 282         |\n",
      "|    n_updates            | 36570       |\n",
      "|    policy_gradient_loss | 0.00352     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 2.49e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4235000, episode_reward=23231.54 +/- 4880.54\n",
      "Episode length: 2832.80 +/- 16.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.83e+03    |\n",
      "|    mean_reward          | 2.32e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4235000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008319296 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.7        |\n",
      "|    n_updates            | 36580       |\n",
      "|    policy_gradient_loss | 0.00348     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 3.68e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.57e+03  |\n",
      "|    ep_rew_mean     | -8.76e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 498       |\n",
      "|    iterations      | 2068      |\n",
      "|    time_elapsed    | 8500      |\n",
      "|    total_timesteps | 4235264   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.57e+03     |\n",
      "|    ep_rew_mean          | -9.43e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 498          |\n",
      "|    iterations           | 2069         |\n",
      "|    time_elapsed         | 8502         |\n",
      "|    total_timesteps      | 4237312      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027721203 |\n",
      "|    clip_fraction        | 0.0408       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.366        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.62e+07     |\n",
      "|    n_updates            | 36590        |\n",
      "|    policy_gradient_loss | 0.00103      |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 8.18e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57e+03    |\n",
      "|    ep_rew_mean          | -9.43e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2070        |\n",
      "|    time_elapsed         | 8503        |\n",
      "|    total_timesteps      | 4239360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004316628 |\n",
      "|    clip_fraction        | 0.0244      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.527       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.15e+07    |\n",
      "|    n_updates            | 36600       |\n",
      "|    policy_gradient_loss | -0.00307    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.04e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4240000, episode_reward=25017.05 +/- 3552.75\n",
      "Episode length: 2861.20 +/- 16.24\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.86e+03   |\n",
      "|    mean_reward          | 2.5e+04    |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4240000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00540013 |\n",
      "|    clip_fraction        | 0.0254     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.94       |\n",
      "|    explained_variance   | 0.469      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 4.9e+07    |\n",
      "|    n_updates            | 36610      |\n",
      "|    policy_gradient_loss | -0.00416   |\n",
      "|    std                  | 0.13       |\n",
      "|    value_loss           | 3.86e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.59e+03  |\n",
      "|    ep_rew_mean     | -1.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 498       |\n",
      "|    iterations      | 2071      |\n",
      "|    time_elapsed    | 8512      |\n",
      "|    total_timesteps | 4241408   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.6e+03     |\n",
      "|    ep_rew_mean          | -1.67e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2072        |\n",
      "|    time_elapsed         | 8514        |\n",
      "|    total_timesteps      | 4243456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010880433 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.63e+07    |\n",
      "|    n_updates            | 36620       |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 3.35e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4245000, episode_reward=19435.00 +/- 4518.97\n",
      "Episode length: 2848.80 +/- 10.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.85e+03    |\n",
      "|    mean_reward          | 1.94e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4245000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004950375 |\n",
      "|    clip_fraction        | 0.0497      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.418       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.47e+07    |\n",
      "|    n_updates            | 36630       |\n",
      "|    policy_gradient_loss | 0.00227     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 8.4e+07     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.6e+03   |\n",
      "|    ep_rew_mean     | -1.75e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 498       |\n",
      "|    iterations      | 2073      |\n",
      "|    time_elapsed    | 8522      |\n",
      "|    total_timesteps | 4245504   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.61e+03    |\n",
      "|    ep_rew_mean          | -1.75e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2074        |\n",
      "|    time_elapsed         | 8524        |\n",
      "|    total_timesteps      | 4247552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010564772 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.524       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.51e+03    |\n",
      "|    n_updates            | 36640       |\n",
      "|    policy_gradient_loss | -0.00441    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.12e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.61e+03  |\n",
      "|    ep_rew_mean          | -1.75e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 498       |\n",
      "|    iterations           | 2075      |\n",
      "|    time_elapsed         | 8526      |\n",
      "|    total_timesteps      | 4249600   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.005967  |\n",
      "|    clip_fraction        | 0.0565    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.94      |\n",
      "|    explained_variance   | 0.976     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 505       |\n",
      "|    n_updates            | 36650     |\n",
      "|    policy_gradient_loss | -0.00707  |\n",
      "|    std                  | 0.13      |\n",
      "|    value_loss           | 7.15e+03  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4250000, episode_reward=26333.57 +/- 4198.52\n",
      "Episode length: 3432.80 +/- 14.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.43e+03    |\n",
      "|    mean_reward          | 2.63e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010411793 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 261         |\n",
      "|    n_updates            | 36660       |\n",
      "|    policy_gradient_loss | 0.00379     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.62e+03  |\n",
      "|    ep_rew_mean     | -1.76e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 498       |\n",
      "|    iterations      | 2076      |\n",
      "|    time_elapsed    | 8536      |\n",
      "|    total_timesteps | 4251648   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.63e+03    |\n",
      "|    ep_rew_mean          | -1.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2077        |\n",
      "|    time_elapsed         | 8538        |\n",
      "|    total_timesteps      | 4253696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027306847 |\n",
      "|    clip_fraction        | 0.0799      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.44e+04    |\n",
      "|    n_updates            | 36670       |\n",
      "|    policy_gradient_loss | 0.00526     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.14e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4255000, episode_reward=56949.14 +/- 1592.36\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 5.69e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4255000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065905675 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.881        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+04     |\n",
      "|    n_updates            | 36680        |\n",
      "|    policy_gradient_loss | -0.00351     |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 7.43e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.63e+03  |\n",
      "|    ep_rew_mean     | -1.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 497       |\n",
      "|    iterations      | 2078      |\n",
      "|    time_elapsed    | 8552      |\n",
      "|    total_timesteps | 4255744   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.64e+03    |\n",
      "|    ep_rew_mean          | -1.73e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 2079        |\n",
      "|    time_elapsed         | 8553        |\n",
      "|    total_timesteps      | 4257792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012176679 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 36690       |\n",
      "|    policy_gradient_loss | 0.0199      |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 135         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.65e+03   |\n",
      "|    ep_rew_mean          | -2.03e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 497        |\n",
      "|    iterations           | 2080       |\n",
      "|    time_elapsed         | 8555       |\n",
      "|    total_timesteps      | 4259840    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00623055 |\n",
      "|    clip_fraction        | 0.0624     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.94       |\n",
      "|    explained_variance   | 0.925      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 145        |\n",
      "|    n_updates            | 36700      |\n",
      "|    policy_gradient_loss | 0.00269    |\n",
      "|    std                  | 0.13       |\n",
      "|    value_loss           | 9.09e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4260000, episode_reward=27174.95 +/- 3974.51\n",
      "Episode length: 2821.40 +/- 7.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.82e+03     |\n",
      "|    mean_reward          | 2.72e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4260000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031506438 |\n",
      "|    clip_fraction        | 0.023        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.391        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.5e+07      |\n",
      "|    n_updates            | 36710        |\n",
      "|    policy_gradient_loss | 0.000547     |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 6.63e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.65e+03  |\n",
      "|    ep_rew_mean     | -2.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 497       |\n",
      "|    iterations      | 2081      |\n",
      "|    time_elapsed    | 8564      |\n",
      "|    total_timesteps | 4261888   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.66e+03    |\n",
      "|    ep_rew_mean          | -2.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 2082        |\n",
      "|    time_elapsed         | 8566        |\n",
      "|    total_timesteps      | 4263936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007332864 |\n",
      "|    clip_fraction        | 0.0365      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.392       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.41e+07    |\n",
      "|    n_updates            | 36720       |\n",
      "|    policy_gradient_loss | -0.0092     |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 6.8e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4265000, episode_reward=35216.76 +/- 3345.68\n",
      "Episode length: 3554.40 +/- 9.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.55e+03    |\n",
      "|    mean_reward          | 3.52e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4265000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015348285 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 284         |\n",
      "|    n_updates            | 36730       |\n",
      "|    policy_gradient_loss | -0.00117    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.23e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.66e+03  |\n",
      "|    ep_rew_mean     | -2.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 497       |\n",
      "|    iterations      | 2083      |\n",
      "|    time_elapsed    | 8576      |\n",
      "|    total_timesteps | 4265984   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.66e+03    |\n",
      "|    ep_rew_mean          | -2.35e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 2084        |\n",
      "|    time_elapsed         | 8578        |\n",
      "|    total_timesteps      | 4268032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010081341 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 35.7        |\n",
      "|    n_updates            | 36740       |\n",
      "|    policy_gradient_loss | 0.0284      |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 173         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4270000, episode_reward=36044.33 +/- 3658.10\n",
      "Episode length: 3214.00 +/- 14.03\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 3.21e+03   |\n",
      "|    mean_reward          | 3.6e+04    |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4270000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08694211 |\n",
      "|    clip_fraction        | 0.2        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.94       |\n",
      "|    explained_variance   | 0.763      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.19e+04   |\n",
      "|    n_updates            | 36750      |\n",
      "|    policy_gradient_loss | 0.0126     |\n",
      "|    std                  | 0.13       |\n",
      "|    value_loss           | 1.56e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.68e+03  |\n",
      "|    ep_rew_mean     | -2.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 497       |\n",
      "|    iterations      | 2085      |\n",
      "|    time_elapsed    | 8587      |\n",
      "|    total_timesteps | 4270080   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.69e+03     |\n",
      "|    ep_rew_mean          | -2.22e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 497          |\n",
      "|    iterations           | 2086         |\n",
      "|    time_elapsed         | 8589         |\n",
      "|    total_timesteps      | 4272128      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059399744 |\n",
      "|    clip_fraction        | 0.0455       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.809        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.67e+06     |\n",
      "|    n_updates            | 36760        |\n",
      "|    policy_gradient_loss | 0.0027       |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 1.14e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.71e+03     |\n",
      "|    ep_rew_mean          | -2.09e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 497          |\n",
      "|    iterations           | 2087         |\n",
      "|    time_elapsed         | 8591         |\n",
      "|    total_timesteps      | 4274176      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0042884033 |\n",
      "|    clip_fraction        | 0.0153       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.866        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.48e+04     |\n",
      "|    n_updates            | 36770        |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 6.12e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4275000, episode_reward=24055.52 +/- 3098.56\n",
      "Episode length: 2827.20 +/- 12.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.83e+03    |\n",
      "|    mean_reward          | 2.41e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4275000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016429573 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34e+05    |\n",
      "|    n_updates            | 36780       |\n",
      "|    policy_gradient_loss | -0.00216    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 1.8e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.71e+03  |\n",
      "|    ep_rew_mean     | -2.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 497       |\n",
      "|    iterations      | 2088      |\n",
      "|    time_elapsed    | 8599      |\n",
      "|    total_timesteps | 4276224   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.71e+03    |\n",
      "|    ep_rew_mean          | -2.12e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 2089        |\n",
      "|    time_elapsed         | 8601        |\n",
      "|    total_timesteps      | 4278272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014222406 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.811       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.38e+06    |\n",
      "|    n_updates            | 36790       |\n",
      "|    policy_gradient_loss | -0.00047    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 9.24e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4280000, episode_reward=39615.11 +/- 4582.06\n",
      "Episode length: 3259.60 +/- 11.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.26e+03    |\n",
      "|    mean_reward          | 3.96e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007608996 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.94        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 358         |\n",
      "|    n_updates            | 36800       |\n",
      "|    policy_gradient_loss | -0.00695    |\n",
      "|    std                  | 0.13        |\n",
      "|    value_loss           | 4.32e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.72e+03  |\n",
      "|    ep_rew_mean     | -2.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 497       |\n",
      "|    iterations      | 2090      |\n",
      "|    time_elapsed    | 8611      |\n",
      "|    total_timesteps | 4280320   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.73e+03     |\n",
      "|    ep_rew_mean          | -2.11e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 497          |\n",
      "|    iterations           | 2091         |\n",
      "|    time_elapsed         | 8613         |\n",
      "|    total_timesteps      | 4282368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061871475 |\n",
      "|    clip_fraction        | 0.0421       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.969        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.18e+03     |\n",
      "|    n_updates            | 36810        |\n",
      "|    policy_gradient_loss | 0.000133     |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 2.55e+04     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.73e+03     |\n",
      "|    ep_rew_mean          | -2.11e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 497          |\n",
      "|    iterations           | 2092         |\n",
      "|    time_elapsed         | 8615         |\n",
      "|    total_timesteps      | 4284416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0020570578 |\n",
      "|    clip_fraction        | 0.0221       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.94         |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+03     |\n",
      "|    n_updates            | 36820        |\n",
      "|    policy_gradient_loss | -0.00184     |\n",
      "|    std                  | 0.13         |\n",
      "|    value_loss           | 2.69e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4285000, episode_reward=51562.77 +/- 3018.03\n",
      "Episode length: 4212.80 +/- 8.70\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 4.21e+03  |\n",
      "|    mean_reward          | 5.16e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4285000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0249989 |\n",
      "|    clip_fraction        | 0.295     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.94      |\n",
      "|    explained_variance   | 0.999     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 28.7      |\n",
      "|    n_updates            | 36830     |\n",
      "|    policy_gradient_loss | 0.0148    |\n",
      "|    std                  | 0.13      |\n",
      "|    value_loss           | 93.4      |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.74e+03 |\n",
      "|    ep_rew_mean     | -2.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 496      |\n",
      "|    iterations      | 2093     |\n",
      "|    time_elapsed    | 8626     |\n",
      "|    total_timesteps | 4286464  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.75e+03     |\n",
      "|    ep_rew_mean          | -2.09e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 497          |\n",
      "|    iterations           | 2094         |\n",
      "|    time_elapsed         | 8628         |\n",
      "|    total_timesteps      | 4288512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049321637 |\n",
      "|    clip_fraction        | 0.0577       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.979        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.67e+03     |\n",
      "|    n_updates            | 36840        |\n",
      "|    policy_gradient_loss | -0.00347     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.61e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4290000, episode_reward=53583.36 +/- 3578.06\n",
      "Episode length: 4280.60 +/- 12.44\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.28e+03     |\n",
      "|    mean_reward          | 5.36e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4290000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019340564 |\n",
      "|    clip_fraction        | 0.0128       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 416          |\n",
      "|    n_updates            | 36850        |\n",
      "|    policy_gradient_loss | -0.00174     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 3.18e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.75e+03  |\n",
      "|    ep_rew_mean     | -2.09e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 2095      |\n",
      "|    time_elapsed    | 8640      |\n",
      "|    total_timesteps | 4290560   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.77e+03    |\n",
      "|    ep_rew_mean          | -2.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2096        |\n",
      "|    time_elapsed         | 8642        |\n",
      "|    total_timesteps      | 4292608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023257973 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 151         |\n",
      "|    n_updates            | 36860       |\n",
      "|    policy_gradient_loss | 0.00252     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 455         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.77e+03    |\n",
      "|    ep_rew_mean          | -2.07e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2097        |\n",
      "|    time_elapsed         | 8644        |\n",
      "|    total_timesteps      | 4294656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012338862 |\n",
      "|    clip_fraction        | 0.0443      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.95        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 156         |\n",
      "|    n_updates            | 36870       |\n",
      "|    policy_gradient_loss | 0.00142     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 3.71e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4295000, episode_reward=69302.71 +/- 3124.18\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 5e+03        |\n",
      "|    mean_reward          | 6.93e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4295000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036819354 |\n",
      "|    clip_fraction        | 0.0245       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 277          |\n",
      "|    n_updates            | 36880        |\n",
      "|    policy_gradient_loss | -0.00188     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 4.38e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.8e+03   |\n",
      "|    ep_rew_mean     | -2.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 2098      |\n",
      "|    time_elapsed    | 8658      |\n",
      "|    total_timesteps | 4296704   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.8e+03      |\n",
      "|    ep_rew_mean          | -2.07e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 496          |\n",
      "|    iterations           | 2099         |\n",
      "|    time_elapsed         | 8659         |\n",
      "|    total_timesteps      | 4298752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0021715849 |\n",
      "|    clip_fraction        | 0.0379       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.885        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.19e+06     |\n",
      "|    n_updates            | 36890        |\n",
      "|    policy_gradient_loss | -0.00306     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.68e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4300000, episode_reward=64910.37 +/- 3425.19\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 5e+03      |\n",
      "|    mean_reward          | 6.49e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4300000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02802888 |\n",
      "|    clip_fraction        | 0.334      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.95       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 22.7       |\n",
      "|    n_updates            | 36900      |\n",
      "|    policy_gradient_loss | 0.0236     |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 131        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.81e+03  |\n",
      "|    ep_rew_mean     | -2.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2100      |\n",
      "|    time_elapsed    | 8673      |\n",
      "|    total_timesteps | 4300800   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.81e+03     |\n",
      "|    ep_rew_mean          | -2.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 495          |\n",
      "|    iterations           | 2101         |\n",
      "|    time_elapsed         | 8675         |\n",
      "|    total_timesteps      | 4302848      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036232832 |\n",
      "|    clip_fraction        | 0.0526       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.95         |\n",
      "|    explained_variance   | 0.973        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 734          |\n",
      "|    n_updates            | 36910        |\n",
      "|    policy_gradient_loss | 0.000102     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 8.78e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.81e+03   |\n",
      "|    ep_rew_mean          | -2.04e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 2102       |\n",
      "|    time_elapsed         | 8677       |\n",
      "|    total_timesteps      | 4304896    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06613086 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.96       |\n",
      "|    explained_variance   | 0.977      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 35.1       |\n",
      "|    n_updates            | 36920      |\n",
      "|    policy_gradient_loss | 0.00869    |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 207        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4305000, episode_reward=69085.27 +/- 3994.20\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 6.91e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4305000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006543546 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.96        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.71e+03    |\n",
      "|    n_updates            | 36930       |\n",
      "|    policy_gradient_loss | 0.0152      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.33e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.79e+03  |\n",
      "|    ep_rew_mean     | -2.12e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2103      |\n",
      "|    time_elapsed    | 8691      |\n",
      "|    total_timesteps | 4306944   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.79e+03    |\n",
      "|    ep_rew_mean          | -2.12e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2104        |\n",
      "|    time_elapsed         | 8693        |\n",
      "|    total_timesteps      | 4308992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001733296 |\n",
      "|    clip_fraction        | 0.0155      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.96        |\n",
      "|    explained_variance   | 0.375       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+07    |\n",
      "|    n_updates            | 36940       |\n",
      "|    policy_gradient_loss | -0.00329    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 2.42e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4310000, episode_reward=25804.82 +/- 1018.81\n",
      "Episode length: 5000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 5e+03       |\n",
      "|    mean_reward          | 2.58e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004824683 |\n",
      "|    clip_fraction        | 0.0972      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.96        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 157         |\n",
      "|    n_updates            | 36950       |\n",
      "|    policy_gradient_loss | 0.00312     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 796         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.79e+03 |\n",
      "|    ep_rew_mean     | -2.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 495      |\n",
      "|    iterations      | 2105     |\n",
      "|    time_elapsed    | 8706     |\n",
      "|    total_timesteps | 4311040  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.79e+03    |\n",
      "|    ep_rew_mean          | -2.1e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2106        |\n",
      "|    time_elapsed         | 8708        |\n",
      "|    total_timesteps      | 4313088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010878788 |\n",
      "|    clip_fraction        | 0.0917      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.96        |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 36960       |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 9.54e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4315000, episode_reward=39149.97 +/- 2817.47\n",
      "Episode length: 3622.00 +/- 5.22\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.62e+03    |\n",
      "|    mean_reward          | 3.91e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4315000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009598503 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.97        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 341         |\n",
      "|    n_updates            | 36970       |\n",
      "|    policy_gradient_loss | 0.00324     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.79e+03 |\n",
      "|    ep_rew_mean     | -2.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 494      |\n",
      "|    iterations      | 2107     |\n",
      "|    time_elapsed    | 8719     |\n",
      "|    total_timesteps | 4315136  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.79e+03   |\n",
      "|    ep_rew_mean          | -2.07e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 495        |\n",
      "|    iterations           | 2108       |\n",
      "|    time_elapsed         | 8720       |\n",
      "|    total_timesteps      | 4317184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01818614 |\n",
      "|    clip_fraction        | 0.184      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.97       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 38.9       |\n",
      "|    n_updates            | 36980      |\n",
      "|    policy_gradient_loss | 0.00401    |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 470        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.78e+03    |\n",
      "|    ep_rew_mean          | -2.08e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2109        |\n",
      "|    time_elapsed         | 8722        |\n",
      "|    total_timesteps      | 4319232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012000655 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 219         |\n",
      "|    n_updates            | 36990       |\n",
      "|    policy_gradient_loss | 0.0034      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.06e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4320000, episode_reward=33390.43 +/- 3290.71\n",
      "Episode length: 3364.80 +/- 9.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.36e+03    |\n",
      "|    mean_reward          | 3.34e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4320000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017199058 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 37000       |\n",
      "|    policy_gradient_loss | -0.000884   |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 2.6e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.78e+03  |\n",
      "|    ep_rew_mean     | -2.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2110      |\n",
      "|    time_elapsed    | 8732      |\n",
      "|    total_timesteps | 4321280   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.78e+03   |\n",
      "|    ep_rew_mean          | -2.03e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 494        |\n",
      "|    iterations           | 2111       |\n",
      "|    time_elapsed         | 8734       |\n",
      "|    total_timesteps      | 4323328    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05635143 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.98       |\n",
      "|    explained_variance   | 0.994      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 50.4       |\n",
      "|    n_updates            | 37010      |\n",
      "|    policy_gradient_loss | 0.00193    |\n",
      "|    std                  | 0.128      |\n",
      "|    value_loss           | 233        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4325000, episode_reward=22109.44 +/- 4456.27\n",
      "Episode length: 3287.80 +/- 15.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.29e+03    |\n",
      "|    mean_reward          | 2.21e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4325000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012442783 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.8        |\n",
      "|    n_updates            | 37020       |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 393         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.77e+03  |\n",
      "|    ep_rew_mean     | -2.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2112      |\n",
      "|    time_elapsed    | 8744      |\n",
      "|    total_timesteps | 4325376   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.77e+03   |\n",
      "|    ep_rew_mean          | -2.05e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 494        |\n",
      "|    iterations           | 2113       |\n",
      "|    time_elapsed         | 8745       |\n",
      "|    total_timesteps      | 4327424    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03744837 |\n",
      "|    clip_fraction        | 0.123      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.98       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 75.8       |\n",
      "|    n_updates            | 37030      |\n",
      "|    policy_gradient_loss | 0.0068     |\n",
      "|    std                  | 0.128      |\n",
      "|    value_loss           | 487        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.77e+03    |\n",
      "|    ep_rew_mean          | -2.05e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2114        |\n",
      "|    time_elapsed         | 8747        |\n",
      "|    total_timesteps      | 4329472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032976426 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.8        |\n",
      "|    n_updates            | 37040       |\n",
      "|    policy_gradient_loss | 0.00227     |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 3.1e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4330000, episode_reward=30659.81 +/- 3966.90\n",
      "Episode length: 3197.40 +/- 8.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.2e+03     |\n",
      "|    mean_reward          | 3.07e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014358324 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77.5        |\n",
      "|    n_updates            | 37050       |\n",
      "|    policy_gradient_loss | 0.00567     |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 284         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.78e+03  |\n",
      "|    ep_rew_mean     | -2.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2115      |\n",
      "|    time_elapsed    | 8757      |\n",
      "|    total_timesteps | 4331520   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.79e+03    |\n",
      "|    ep_rew_mean          | -2.06e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2116        |\n",
      "|    time_elapsed         | 8759        |\n",
      "|    total_timesteps      | 4333568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008675216 |\n",
      "|    clip_fraction        | 0.0833      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 187         |\n",
      "|    n_updates            | 37060       |\n",
      "|    policy_gradient_loss | 0.00662     |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 4.34e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4335000, episode_reward=20445.15 +/- 3788.24\n",
      "Episode length: 3145.00 +/- 15.28\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.14e+03    |\n",
      "|    mean_reward          | 2.04e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4335000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011385032 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 75.6        |\n",
      "|    n_updates            | 37070       |\n",
      "|    policy_gradient_loss | -0.000288   |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 1.7e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.79e+03  |\n",
      "|    ep_rew_mean     | -2.06e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2117      |\n",
      "|    time_elapsed    | 8768      |\n",
      "|    total_timesteps | 4335616   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.79e+03    |\n",
      "|    ep_rew_mean          | -2.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2118        |\n",
      "|    time_elapsed         | 8770        |\n",
      "|    total_timesteps      | 4337664     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030303113 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 37080       |\n",
      "|    policy_gradient_loss | 0.0132      |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.79e+03    |\n",
      "|    ep_rew_mean          | -2.04e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2119        |\n",
      "|    time_elapsed         | 8772        |\n",
      "|    total_timesteps      | 4339712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020148514 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 44.3        |\n",
      "|    n_updates            | 37090       |\n",
      "|    policy_gradient_loss | 0.0131      |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 1.07e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4340000, episode_reward=30371.90 +/- 5283.16\n",
      "Episode length: 3031.80 +/- 13.96\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.03e+03     |\n",
      "|    mean_reward          | 3.04e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4340000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059857173 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.98         |\n",
      "|    explained_variance   | 0.927        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 123          |\n",
      "|    n_updates            | 37100        |\n",
      "|    policy_gradient_loss | -0.000565    |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 9.5e+03      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.8e+03   |\n",
      "|    ep_rew_mean     | -2.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2120      |\n",
      "|    time_elapsed    | 8781      |\n",
      "|    total_timesteps | 4341760   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.8e+03    |\n",
      "|    ep_rew_mean          | -2.03e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 494        |\n",
      "|    iterations           | 2121       |\n",
      "|    time_elapsed         | 8783       |\n",
      "|    total_timesteps      | 4343808    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06491551 |\n",
      "|    clip_fraction        | 0.436      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.98       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 62.4       |\n",
      "|    n_updates            | 37110      |\n",
      "|    policy_gradient_loss | 0.0297     |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 159        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4345000, episode_reward=28986.79 +/- 714.02\n",
      "Episode length: 3149.40 +/- 11.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.15e+03    |\n",
      "|    mean_reward          | 2.9e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4345000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005705932 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.97        |\n",
      "|    explained_variance   | 0.674       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.28e+05    |\n",
      "|    n_updates            | 37120       |\n",
      "|    policy_gradient_loss | 0.00265     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.57e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.81e+03  |\n",
      "|    ep_rew_mean     | -2.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2122      |\n",
      "|    time_elapsed    | 8792      |\n",
      "|    total_timesteps | 4345856   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.81e+03     |\n",
      "|    ep_rew_mean          | -2.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2123         |\n",
      "|    time_elapsed         | 8794         |\n",
      "|    total_timesteps      | 4347904      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0017627756 |\n",
      "|    clip_fraction        | 0.00596      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.97         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.2e+03      |\n",
      "|    n_updates            | 37130        |\n",
      "|    policy_gradient_loss | -0.00162     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.59e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.82e+03    |\n",
      "|    ep_rew_mean          | -2e+04      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2124        |\n",
      "|    time_elapsed         | 8796        |\n",
      "|    total_timesteps      | 4349952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039319675 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 21.3        |\n",
      "|    n_updates            | 37140       |\n",
      "|    policy_gradient_loss | 0.0146      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 69.3        |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4350000, episode_reward=4484.31 +/- 4241.78\n",
      "Episode length: 2799.00 +/- 20.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.8e+03     |\n",
      "|    mean_reward          | 4.48e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009416074 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.683       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.88e+05    |\n",
      "|    n_updates            | 37150       |\n",
      "|    policy_gradient_loss | 0.00232     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.53e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.82e+03  |\n",
      "|    ep_rew_mean     | -2.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2125      |\n",
      "|    time_elapsed    | 8804      |\n",
      "|    total_timesteps | 4352000   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.81e+03    |\n",
      "|    ep_rew_mean          | -2.03e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2126        |\n",
      "|    time_elapsed         | 8806        |\n",
      "|    total_timesteps      | 4354048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005022725 |\n",
      "|    clip_fraction        | 0.0582      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.46e+03    |\n",
      "|    n_updates            | 37160       |\n",
      "|    policy_gradient_loss | -0.00142    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 5.61e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4355000, episode_reward=-28539.36 +/- 5811.23\n",
      "Episode length: 3385.20 +/- 13.53\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 3.39e+03    |\n",
      "|    mean_reward          | -2.85e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4355000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009903601 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.45e+03    |\n",
      "|    n_updates            | 37170       |\n",
      "|    policy_gradient_loss | 0.00276     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 4.09e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.8e+03   |\n",
      "|    ep_rew_mean     | -1.96e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2127      |\n",
      "|    time_elapsed    | 8816      |\n",
      "|    total_timesteps | 4356096   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.8e+03      |\n",
      "|    ep_rew_mean          | -2.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2128         |\n",
      "|    time_elapsed         | 8818         |\n",
      "|    total_timesteps      | 4358144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046000686 |\n",
      "|    clip_fraction        | 0.0466       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.764        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.97e+05     |\n",
      "|    n_updates            | 37180        |\n",
      "|    policy_gradient_loss | -0.00207     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.56e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4360000, episode_reward=26432.15 +/- 3126.40\n",
      "Episode length: 3158.80 +/- 7.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.16e+03     |\n",
      "|    mean_reward          | 2.64e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4360000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037310978 |\n",
      "|    clip_fraction        | 0.0129       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.708        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.29e+06     |\n",
      "|    n_updates            | 37190        |\n",
      "|    policy_gradient_loss | -0.0031      |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 3.71e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.8e+03   |\n",
      "|    ep_rew_mean     | -2.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2129      |\n",
      "|    time_elapsed    | 8827      |\n",
      "|    total_timesteps | 4360192   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.8e+03      |\n",
      "|    ep_rew_mean          | -2.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2130         |\n",
      "|    time_elapsed         | 8829         |\n",
      "|    total_timesteps      | 4362240      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048624137 |\n",
      "|    clip_fraction        | 0.0705       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.989        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 543          |\n",
      "|    n_updates            | 37200        |\n",
      "|    policy_gradient_loss | -0.00392     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 2.41e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.81e+03     |\n",
      "|    ep_rew_mean          | -2.04e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2131         |\n",
      "|    time_elapsed         | 8831         |\n",
      "|    total_timesteps      | 4364288      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027890173 |\n",
      "|    clip_fraction        | 0.0106       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.695        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.65e+03     |\n",
      "|    n_updates            | 37210        |\n",
      "|    policy_gradient_loss | -0.00427     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 3.37e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4365000, episode_reward=32843.68 +/- 5087.43\n",
      "Episode length: 3177.20 +/- 10.55\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.18e+03     |\n",
      "|    mean_reward          | 3.28e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4365000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023791755 |\n",
      "|    clip_fraction        | 0.00713      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.45e+04     |\n",
      "|    n_updates            | 37220        |\n",
      "|    policy_gradient_loss | -0.000568    |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 3.83e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.81e+03  |\n",
      "|    ep_rew_mean     | -2.04e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2132      |\n",
      "|    time_elapsed    | 8840      |\n",
      "|    total_timesteps | 4366336   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.81e+03    |\n",
      "|    ep_rew_mean          | -2.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2133        |\n",
      "|    time_elapsed         | 8842        |\n",
      "|    total_timesteps      | 4368384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033901937 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.4        |\n",
      "|    n_updates            | 37230       |\n",
      "|    policy_gradient_loss | 0.0105      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 84.3        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4370000, episode_reward=32778.64 +/- 1406.48\n",
      "Episode length: 3048.00 +/- 8.69\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 3.05e+03     |\n",
      "|    mean_reward          | 3.28e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4370000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048559867 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.66e+03     |\n",
      "|    n_updates            | 37240        |\n",
      "|    policy_gradient_loss | 0.00403      |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 4.28e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.81e+03  |\n",
      "|    ep_rew_mean     | -2.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2134      |\n",
      "|    time_elapsed    | 8851      |\n",
      "|    total_timesteps | 4370432   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.81e+03     |\n",
      "|    ep_rew_mean          | -2.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 493          |\n",
      "|    iterations           | 2135         |\n",
      "|    time_elapsed         | 8853         |\n",
      "|    total_timesteps      | 4372480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050980924 |\n",
      "|    clip_fraction        | 0.0491       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.956        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 728          |\n",
      "|    n_updates            | 37250        |\n",
      "|    policy_gradient_loss | -0.00176     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 3.07e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.81e+03   |\n",
      "|    ep_rew_mean          | -2.01e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 494        |\n",
      "|    iterations           | 2136       |\n",
      "|    time_elapsed         | 8855       |\n",
      "|    total_timesteps      | 4374528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04786152 |\n",
      "|    clip_fraction        | 0.203      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.99       |\n",
      "|    explained_variance   | 0.924      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 443        |\n",
      "|    n_updates            | 37260      |\n",
      "|    policy_gradient_loss | 0.00275    |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 2.7e+05    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4375000, episode_reward=-43358.95 +/- 3300.03\n",
      "Episode length: 4344.00 +/- 5.76\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 4.34e+03     |\n",
      "|    mean_reward          | -4.34e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4375000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0040120697 |\n",
      "|    clip_fraction        | 0.0217       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.918        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.15e+03     |\n",
      "|    n_updates            | 37270        |\n",
      "|    policy_gradient_loss | -0.000502    |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 3.57e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.8e+03   |\n",
      "|    ep_rew_mean     | -2.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2137      |\n",
      "|    time_elapsed    | 8867      |\n",
      "|    total_timesteps | 4376576   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.8e+03      |\n",
      "|    ep_rew_mean          | -2.01e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 493          |\n",
      "|    iterations           | 2138         |\n",
      "|    time_elapsed         | 8869         |\n",
      "|    total_timesteps      | 4378624      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075732837 |\n",
      "|    clip_fraction        | 0.0413       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 139          |\n",
      "|    n_updates            | 37280        |\n",
      "|    policy_gradient_loss | -0.00135     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 8.05e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4380000, episode_reward=18210.80 +/- 3111.04\n",
      "Episode length: 2443.00 +/- 6.78\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.44e+03    |\n",
      "|    mean_reward          | 1.82e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044788495 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.2        |\n",
      "|    n_updates            | 37290       |\n",
      "|    policy_gradient_loss | 0.00182     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 73.6        |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.79e+03  |\n",
      "|    ep_rew_mean     | -1.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2139      |\n",
      "|    time_elapsed    | 8876      |\n",
      "|    total_timesteps | 4380672   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.78e+03    |\n",
      "|    ep_rew_mean          | -1.98e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 2140        |\n",
      "|    time_elapsed         | 8878        |\n",
      "|    total_timesteps      | 4382720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007078167 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.26e+03    |\n",
      "|    n_updates            | 37300       |\n",
      "|    policy_gradient_loss | 0.00364     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 5.94e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.78e+03     |\n",
      "|    ep_rew_mean          | -1.99e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 493          |\n",
      "|    iterations           | 2141         |\n",
      "|    time_elapsed         | 8880         |\n",
      "|    total_timesteps      | 4384768      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070615364 |\n",
      "|    clip_fraction        | 0.0356       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.98         |\n",
      "|    explained_variance   | 0.669        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.92e+05     |\n",
      "|    n_updates            | 37310        |\n",
      "|    policy_gradient_loss | -0.00685     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 8.26e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4385000, episode_reward=24430.17 +/- 263.11\n",
      "Episode length: 2800.20 +/- 11.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.8e+03     |\n",
      "|    mean_reward          | 2.44e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4385000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004366678 |\n",
      "|    clip_fraction        | 0.031       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 446         |\n",
      "|    n_updates            | 37320       |\n",
      "|    policy_gradient_loss | -0.00424    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 6.76e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.77e+03  |\n",
      "|    ep_rew_mean     | -1.99e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2142      |\n",
      "|    time_elapsed    | 8888      |\n",
      "|    total_timesteps | 4386816   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | -1.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 2143        |\n",
      "|    time_elapsed         | 8890        |\n",
      "|    total_timesteps      | 4388864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008427121 |\n",
      "|    clip_fraction        | 0.0476      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.965       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 733         |\n",
      "|    n_updates            | 37330       |\n",
      "|    policy_gradient_loss | -0.000511   |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 7.12e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4390000, episode_reward=18605.21 +/- 3271.45\n",
      "Episode length: 2849.80 +/- 11.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.85e+03    |\n",
      "|    mean_reward          | 1.86e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4390000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009669557 |\n",
      "|    clip_fraction        | 0.0922      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 976         |\n",
      "|    n_updates            | 37340       |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 3.84e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.76e+03  |\n",
      "|    ep_rew_mean     | -2.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2144      |\n",
      "|    time_elapsed    | 8899      |\n",
      "|    total_timesteps | 4390912   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.76e+03    |\n",
      "|    ep_rew_mean          | -2.01e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 2145        |\n",
      "|    time_elapsed         | 8901        |\n",
      "|    total_timesteps      | 4392960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006423421 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.973       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 327         |\n",
      "|    n_updates            | 37350       |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 3.06e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4395000, episode_reward=26366.70 +/- 3684.24\n",
      "Episode length: 2789.20 +/- 11.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.79e+03    |\n",
      "|    mean_reward          | 2.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4395000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042351604 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.2        |\n",
      "|    n_updates            | 37360       |\n",
      "|    policy_gradient_loss | 0.00203     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 172         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.74e+03  |\n",
      "|    ep_rew_mean     | -2.02e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2146      |\n",
      "|    time_elapsed    | 8909      |\n",
      "|    total_timesteps | 4395008   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.74e+03    |\n",
      "|    ep_rew_mean          | -2.02e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 2147        |\n",
      "|    time_elapsed         | 8911        |\n",
      "|    total_timesteps      | 4397056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024323992 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.97        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 125         |\n",
      "|    n_updates            | 37370       |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.17e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.7e+03     |\n",
      "|    ep_rew_mean          | -2.18e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 2148        |\n",
      "|    time_elapsed         | 8913        |\n",
      "|    total_timesteps      | 4399104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016284993 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 120         |\n",
      "|    n_updates            | 37380       |\n",
      "|    policy_gradient_loss | 0.00112     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 7.55e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4400000, episode_reward=23415.18 +/- 2501.42\n",
      "Episode length: 2706.00 +/- 8.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.71e+03    |\n",
      "|    mean_reward          | 2.34e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029759409 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.319       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.86e+06    |\n",
      "|    n_updates            | 37390       |\n",
      "|    policy_gradient_loss | 0.0113      |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.95e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.7e+03   |\n",
      "|    ep_rew_mean     | -2.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2149      |\n",
      "|    time_elapsed    | 8921      |\n",
      "|    total_timesteps | 4401152   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.7e+03     |\n",
      "|    ep_rew_mean          | -2.17e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 2150        |\n",
      "|    time_elapsed         | 8923        |\n",
      "|    total_timesteps      | 4403200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007113776 |\n",
      "|    clip_fraction        | 0.06        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 806         |\n",
      "|    n_updates            | 37400       |\n",
      "|    policy_gradient_loss | -0.000541   |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 4.91e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4405000, episode_reward=20188.37 +/- 3926.10\n",
      "Episode length: 2692.40 +/- 32.04\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.69e+03    |\n",
      "|    mean_reward          | 2.02e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4405000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018065998 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 91          |\n",
      "|    n_updates            | 37410       |\n",
      "|    policy_gradient_loss | 0.00164     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 360         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.7e+03   |\n",
      "|    ep_rew_mean     | -2.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2151      |\n",
      "|    time_elapsed    | 8931      |\n",
      "|    total_timesteps | 4405248   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.64e+03   |\n",
      "|    ep_rew_mean          | -1.98e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 493        |\n",
      "|    iterations           | 2152       |\n",
      "|    time_elapsed         | 8933       |\n",
      "|    total_timesteps      | 4407296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01039182 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.99       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 140        |\n",
      "|    n_updates            | 37420      |\n",
      "|    policy_gradient_loss | -0.00254   |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 919        |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.64e+03     |\n",
      "|    ep_rew_mean          | -1.98e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 493          |\n",
      "|    iterations           | 2153         |\n",
      "|    time_elapsed         | 8935         |\n",
      "|    total_timesteps      | 4409344      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071060723 |\n",
      "|    clip_fraction        | 0.066        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.578        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.32e+03     |\n",
      "|    n_updates            | 37430        |\n",
      "|    policy_gradient_loss | -0.000809    |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 1.24e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4410000, episode_reward=17059.93 +/- 4116.06\n",
      "Episode length: 2608.20 +/- 12.34\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.61e+03    |\n",
      "|    mean_reward          | 1.71e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020172294 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 43.6        |\n",
      "|    n_updates            | 37440       |\n",
      "|    policy_gradient_loss | 0.0154      |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 171         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.63e+03  |\n",
      "|    ep_rew_mean     | -1.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2154      |\n",
      "|    time_elapsed    | 8943      |\n",
      "|    total_timesteps | 4411392   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.61e+03  |\n",
      "|    ep_rew_mean          | -1.03e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 493       |\n",
      "|    iterations           | 2155      |\n",
      "|    time_elapsed         | 8945      |\n",
      "|    total_timesteps      | 4413440   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3196968 |\n",
      "|    clip_fraction        | 0.229     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.99      |\n",
      "|    explained_variance   | 0.923     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 205       |\n",
      "|    n_updates            | 37450     |\n",
      "|    policy_gradient_loss | 0.00894   |\n",
      "|    std                  | 0.128     |\n",
      "|    value_loss           | 1.01e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4415000, episode_reward=13212.94 +/- 8421.07\n",
      "Episode length: 2115.80 +/- 769.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.12e+03    |\n",
      "|    mean_reward          | 1.32e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4415000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015161154 |\n",
      "|    clip_fraction        | 0.16        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 334         |\n",
      "|    n_updates            | 37460       |\n",
      "|    policy_gradient_loss | 0.00859     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 2.7e+04     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.61e+03  |\n",
      "|    ep_rew_mean     | -1.03e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2156      |\n",
      "|    time_elapsed    | 8951      |\n",
      "|    total_timesteps | 4415488   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.62e+03    |\n",
      "|    ep_rew_mean          | -1e+04      |\n",
      "| time/                   |             |\n",
      "|    fps                  | 493         |\n",
      "|    iterations           | 2157        |\n",
      "|    time_elapsed         | 8953        |\n",
      "|    total_timesteps      | 4417536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027268589 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 61          |\n",
      "|    n_updates            | 37470       |\n",
      "|    policy_gradient_loss | 0.00394     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 219         |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.62e+03  |\n",
      "|    ep_rew_mean          | -9.67e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 493       |\n",
      "|    iterations           | 2158      |\n",
      "|    time_elapsed         | 8955      |\n",
      "|    total_timesteps      | 4419584   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.32508   |\n",
      "|    clip_fraction        | 0.295     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 3.98      |\n",
      "|    explained_variance   | 0.994     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 64.6      |\n",
      "|    n_updates            | 37480     |\n",
      "|    policy_gradient_loss | 0.0103    |\n",
      "|    std                  | 0.129     |\n",
      "|    value_loss           | 436       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4420000, episode_reward=-263549.12 +/- 217830.17\n",
      "Episode length: 1396.00 +/- 672.85\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.4e+03    |\n",
      "|    mean_reward          | -2.64e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4420000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11858453 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.99       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 49.8       |\n",
      "|    n_updates            | 37490      |\n",
      "|    policy_gradient_loss | 0.019      |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 452        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.6e+03   |\n",
      "|    ep_rew_mean     | -1.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2159      |\n",
      "|    time_elapsed    | 8960      |\n",
      "|    total_timesteps | 4421632   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.57e+03   |\n",
      "|    ep_rew_mean          | -1.44e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 493        |\n",
      "|    iterations           | 2160       |\n",
      "|    time_elapsed         | 8962       |\n",
      "|    total_timesteps      | 4423680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.39309955 |\n",
      "|    clip_fraction        | 0.681      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.99       |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.18e+07   |\n",
      "|    n_updates            | 37500      |\n",
      "|    policy_gradient_loss | 0.229      |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 5.19e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4425000, episode_reward=-123541.36 +/- 3751.15\n",
      "Episode length: 1111.00 +/- 8.90\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.11e+03     |\n",
      "|    mean_reward          | -1.24e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4425000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0008560398 |\n",
      "|    clip_fraction        | 0.00342      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.385        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.54e+06     |\n",
      "|    n_updates            | 37510        |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 2.6e+07      |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.52e+03 |\n",
      "|    ep_rew_mean     | -1.5e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 493      |\n",
      "|    iterations      | 2161     |\n",
      "|    time_elapsed    | 8967     |\n",
      "|    total_timesteps | 4425728  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.53e+03     |\n",
      "|    ep_rew_mean          | -1.51e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 493          |\n",
      "|    iterations           | 2162         |\n",
      "|    time_elapsed         | 8969         |\n",
      "|    total_timesteps      | 4427776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068263104 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.439        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.33e+07     |\n",
      "|    n_updates            | 37520        |\n",
      "|    policy_gradient_loss | -0.00643     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 2.56e+07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.49e+03     |\n",
      "|    ep_rew_mean          | -1.81e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 493          |\n",
      "|    iterations           | 2163         |\n",
      "|    time_elapsed         | 8970         |\n",
      "|    total_timesteps      | 4429824      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009813446 |\n",
      "|    clip_fraction        | 0.0022       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.61e+07     |\n",
      "|    n_updates            | 37530        |\n",
      "|    policy_gradient_loss | -0.00273     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 4.32e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4430000, episode_reward=-119068.74 +/- 209.60\n",
      "Episode length: 1131.40 +/- 8.45\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.13e+03     |\n",
      "|    mean_reward          | -1.19e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4430000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035919535 |\n",
      "|    clip_fraction        | 0.0246       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.45         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.71e+07     |\n",
      "|    n_updates            | 37540        |\n",
      "|    policy_gradient_loss | -0.00246     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 4.68e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.46e+03  |\n",
      "|    ep_rew_mean     | -1.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2164      |\n",
      "|    time_elapsed    | 8975      |\n",
      "|    total_timesteps | 4431872   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.4e+03      |\n",
      "|    ep_rew_mean          | -2.23e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 493          |\n",
      "|    iterations           | 2165         |\n",
      "|    time_elapsed         | 8977         |\n",
      "|    total_timesteps      | 4433920      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025638475 |\n",
      "|    clip_fraction        | 0.0253       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.472        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.2e+06      |\n",
      "|    n_updates            | 37550        |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 2.42e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4435000, episode_reward=-96203.60 +/- 50445.27\n",
      "Episode length: 1025.40 +/- 232.74\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.03e+03     |\n",
      "|    mean_reward          | -9.62e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4435000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069094133 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.455        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+07     |\n",
      "|    n_updates            | 37560        |\n",
      "|    policy_gradient_loss | -0.00215     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 4.71e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.37e+03  |\n",
      "|    ep_rew_mean     | -2.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 493       |\n",
      "|    iterations      | 2166      |\n",
      "|    time_elapsed    | 8981      |\n",
      "|    total_timesteps | 4435968   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.32e+03     |\n",
      "|    ep_rew_mean          | -2.68e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2167         |\n",
      "|    time_elapsed         | 8983         |\n",
      "|    total_timesteps      | 4438016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052307704 |\n",
      "|    clip_fraction        | 0.054        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.471        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.11e+07     |\n",
      "|    n_updates            | 37570        |\n",
      "|    policy_gradient_loss | 0.000509     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 2.54e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4440000, episode_reward=-106101.15 +/- 55663.04\n",
      "Episode length: 1080.60 +/- 262.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.08e+03    |\n",
      "|    mean_reward          | -1.06e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008310618 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.95e+07    |\n",
      "|    n_updates            | 37580       |\n",
      "|    policy_gradient_loss | 0.00183     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 4.66e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.3e+03   |\n",
      "|    ep_rew_mean     | -2.87e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2168      |\n",
      "|    time_elapsed    | 8987      |\n",
      "|    total_timesteps | 4440064   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.28e+03    |\n",
      "|    ep_rew_mean          | -2.87e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2169        |\n",
      "|    time_elapsed         | 8989        |\n",
      "|    total_timesteps      | 4442112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008676596 |\n",
      "|    clip_fraction        | 0.0707      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.439       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.71e+06    |\n",
      "|    n_updates            | 37590       |\n",
      "|    policy_gradient_loss | 0.00107     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 5.38e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.25e+03    |\n",
      "|    ep_rew_mean          | -3.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2170        |\n",
      "|    time_elapsed         | 8991        |\n",
      "|    total_timesteps      | 4444160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007632203 |\n",
      "|    clip_fraction        | 0.0361      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.23e+04    |\n",
      "|    n_updates            | 37600       |\n",
      "|    policy_gradient_loss | -0.00302    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.77e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4445000, episode_reward=-180452.71 +/- 6538.07\n",
      "Episode length: 1405.80 +/- 9.83\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.41e+03     |\n",
      "|    mean_reward          | -1.8e+05     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4445000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0028413828 |\n",
      "|    clip_fraction        | 0.0173       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.98         |\n",
      "|    explained_variance   | 0.389        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.61e+07     |\n",
      "|    n_updates            | 37610        |\n",
      "|    policy_gradient_loss | -0.00399     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 8.31e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.2e+03   |\n",
      "|    ep_rew_mean     | -3.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2171      |\n",
      "|    time_elapsed    | 8996      |\n",
      "|    total_timesteps | 4446208   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.18e+03     |\n",
      "|    ep_rew_mean          | -3.71e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2172         |\n",
      "|    time_elapsed         | 8998         |\n",
      "|    total_timesteps      | 4448256      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038648404 |\n",
      "|    clip_fraction        | 0.0254       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.98         |\n",
      "|    explained_variance   | 0.404        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.7e+07      |\n",
      "|    n_updates            | 37620        |\n",
      "|    policy_gradient_loss | -0.00499     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 5.63e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4450000, episode_reward=-220726.06 +/- 2805.55\n",
      "Episode length: 1526.40 +/- 5.12\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.53e+03    |\n",
      "|    mean_reward          | -2.21e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006420162 |\n",
      "|    clip_fraction        | 0.0862      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.86e+06    |\n",
      "|    n_updates            | 37630       |\n",
      "|    policy_gradient_loss | 0.00246     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 2.58e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.15e+03  |\n",
      "|    ep_rew_mean     | -3.63e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2173      |\n",
      "|    time_elapsed    | 9004      |\n",
      "|    total_timesteps | 4450304   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.15e+03    |\n",
      "|    ep_rew_mean          | -3.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2174        |\n",
      "|    time_elapsed         | 9006        |\n",
      "|    total_timesteps      | 4452352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008802028 |\n",
      "|    clip_fraction        | 0.0637      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.42e+07    |\n",
      "|    n_updates            | 37640       |\n",
      "|    policy_gradient_loss | -0.000649   |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 4.71e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.12e+03    |\n",
      "|    ep_rew_mean          | -3.23e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2175        |\n",
      "|    time_elapsed         | 9007        |\n",
      "|    total_timesteps      | 4454400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005397076 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.385       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.45e+04    |\n",
      "|    n_updates            | 37650       |\n",
      "|    policy_gradient_loss | -0.000712   |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 5.75e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4455000, episode_reward=-377382.99 +/- 87550.29\n",
      "Episode length: 1725.00 +/- 89.95\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.72e+03     |\n",
      "|    mean_reward          | -3.77e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4455000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034362138 |\n",
      "|    clip_fraction        | 0.0167       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.98         |\n",
      "|    explained_variance   | 0.413        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.34e+07     |\n",
      "|    n_updates            | 37660        |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 4.61e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.11e+03  |\n",
      "|    ep_rew_mean     | -3.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2176      |\n",
      "|    time_elapsed    | 9013      |\n",
      "|    total_timesteps | 4456448   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.1e+03      |\n",
      "|    ep_rew_mean          | -3.45e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2177         |\n",
      "|    time_elapsed         | 9015         |\n",
      "|    total_timesteps      | 4458496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041742744 |\n",
      "|    clip_fraction        | 0.0363       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.98         |\n",
      "|    explained_variance   | 0.925        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+04     |\n",
      "|    n_updates            | 37670        |\n",
      "|    policy_gradient_loss | -0.00163     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 6.31e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4460000, episode_reward=-25041.21 +/- 3821.96\n",
      "Episode length: 1556.60 +/- 8.73\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.56e+03     |\n",
      "|    mean_reward          | -2.5e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4460000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051946947 |\n",
      "|    clip_fraction        | 0.0418       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.98         |\n",
      "|    explained_variance   | 0.387        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.82e+07     |\n",
      "|    n_updates            | 37680        |\n",
      "|    policy_gradient_loss | -0.00226     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 5.02e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.07e+03  |\n",
      "|    ep_rew_mean     | -3.66e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2178      |\n",
      "|    time_elapsed    | 9021      |\n",
      "|    total_timesteps | 4460544   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.06e+03    |\n",
      "|    ep_rew_mean          | -3.68e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2179        |\n",
      "|    time_elapsed         | 9023        |\n",
      "|    total_timesteps      | 4462592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004824754 |\n",
      "|    clip_fraction        | 0.0392      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.19e+07    |\n",
      "|    n_updates            | 37690       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 3.52e+07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.05e+03    |\n",
      "|    ep_rew_mean          | -3.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2180        |\n",
      "|    time_elapsed         | 9025        |\n",
      "|    total_timesteps      | 4464640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005884655 |\n",
      "|    clip_fraction        | 0.0652      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.88e+04    |\n",
      "|    n_updates            | 37700       |\n",
      "|    policy_gradient_loss | -0.00115    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.95e+05    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4465000, episode_reward=10368.44 +/- 4282.06\n",
      "Episode length: 1578.60 +/- 11.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.58e+03    |\n",
      "|    mean_reward          | 1.04e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4465000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015874319 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.98        |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.69e+07    |\n",
      "|    n_updates            | 37710       |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 2.67e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 2.03e+03  |\n",
      "|    ep_rew_mean     | -3.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2181      |\n",
      "|    time_elapsed    | 9030      |\n",
      "|    total_timesteps | 4466688   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2.02e+03     |\n",
      "|    ep_rew_mean          | -3.31e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2182         |\n",
      "|    time_elapsed         | 9032         |\n",
      "|    total_timesteps      | 4468736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061496724 |\n",
      "|    clip_fraction        | 0.0389       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+04     |\n",
      "|    n_updates            | 37720        |\n",
      "|    policy_gradient_loss | -0.00303     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 8.58e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4470000, episode_reward=13227.08 +/- 4664.23\n",
      "Episode length: 1774.80 +/- 15.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.77e+03    |\n",
      "|    mean_reward          | 1.32e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010428941 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.61e+05    |\n",
      "|    n_updates            | 37730       |\n",
      "|    policy_gradient_loss | 0.00038     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 2.39e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.02e+03 |\n",
      "|    ep_rew_mean     | -3.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 494      |\n",
      "|    iterations      | 2183     |\n",
      "|    time_elapsed    | 9038     |\n",
      "|    total_timesteps | 4470784  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 2e+03        |\n",
      "|    ep_rew_mean          | -3.32e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 494          |\n",
      "|    iterations           | 2184         |\n",
      "|    time_elapsed         | 9040         |\n",
      "|    total_timesteps      | 4472832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038313079 |\n",
      "|    clip_fraction        | 0.0699       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 3.99         |\n",
      "|    explained_variance   | 0.952        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 439          |\n",
      "|    n_updates            | 37740        |\n",
      "|    policy_gradient_loss | 0.000792     |\n",
      "|    std                  | 0.129        |\n",
      "|    value_loss           | 2.25e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.99e+03    |\n",
      "|    ep_rew_mean          | -3.31e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2185        |\n",
      "|    time_elapsed         | 9042        |\n",
      "|    total_timesteps      | 4474880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007661842 |\n",
      "|    clip_fraction        | 0.0816      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.57e+03    |\n",
      "|    n_updates            | 37750       |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.96e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4475000, episode_reward=12075.33 +/- 5483.98\n",
      "Episode length: 1600.00 +/- 522.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.6e+03     |\n",
      "|    mean_reward          | 1.21e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4475000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013307106 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 329         |\n",
      "|    n_updates            | 37760       |\n",
      "|    policy_gradient_loss | 0.00059     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 1.12e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.97e+03 |\n",
      "|    ep_rew_mean     | -3.3e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 494      |\n",
      "|    iterations      | 2186     |\n",
      "|    time_elapsed    | 9047     |\n",
      "|    total_timesteps | 4476928  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.95e+03   |\n",
      "|    ep_rew_mean          | -3.32e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 494        |\n",
      "|    iterations           | 2187       |\n",
      "|    time_elapsed         | 9049       |\n",
      "|    total_timesteps      | 4478976    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01614682 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 3.99       |\n",
      "|    explained_variance   | 0.964      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.02e+03   |\n",
      "|    n_updates            | 37770      |\n",
      "|    policy_gradient_loss | 0.00132    |\n",
      "|    std                  | 0.129      |\n",
      "|    value_loss           | 6.75e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4480000, episode_reward=16518.92 +/- 3721.65\n",
      "Episode length: 2169.20 +/- 11.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.17e+03    |\n",
      "|    mean_reward          | 1.65e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006306463 |\n",
      "|    clip_fraction        | 0.05        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 356         |\n",
      "|    n_updates            | 37780       |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 6.42e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.93e+03  |\n",
      "|    ep_rew_mean     | -3.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2188      |\n",
      "|    time_elapsed    | 9056      |\n",
      "|    total_timesteps | 4481024   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.91e+03    |\n",
      "|    ep_rew_mean          | -3.37e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2189        |\n",
      "|    time_elapsed         | 9058        |\n",
      "|    total_timesteps      | 4483072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008293903 |\n",
      "|    clip_fraction        | 0.0665      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.987       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 609         |\n",
      "|    n_updates            | 37790       |\n",
      "|    policy_gradient_loss | -0.00192    |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 4.95e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4485000, episode_reward=13091.62 +/- 4521.46\n",
      "Episode length: 1704.00 +/- 20.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.7e+03     |\n",
      "|    mean_reward          | 1.31e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4485000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018797943 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 118         |\n",
      "|    n_updates            | 37800       |\n",
      "|    policy_gradient_loss | 0.00564     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 855         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.88e+03  |\n",
      "|    ep_rew_mean     | -3.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2190      |\n",
      "|    time_elapsed    | 9064      |\n",
      "|    total_timesteps | 4485120   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.82e+03    |\n",
      "|    ep_rew_mean          | -3.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 494         |\n",
      "|    iterations           | 2191        |\n",
      "|    time_elapsed         | 9066        |\n",
      "|    total_timesteps      | 4487168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017059162 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 37810       |\n",
      "|    policy_gradient_loss | 0.00657     |\n",
      "|    std                  | 0.129       |\n",
      "|    value_loss           | 521         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83e+03    |\n",
      "|    ep_rew_mean          | -3.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2192        |\n",
      "|    time_elapsed         | 9068        |\n",
      "|    total_timesteps      | 4489216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017111551 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 3.99        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 90.4        |\n",
      "|    n_updates            | 37820       |\n",
      "|    policy_gradient_loss | 0.00586     |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 445         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4490000, episode_reward=15423.02 +/- 4423.14\n",
      "Episode length: 1401.40 +/- 14.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4e+03     |\n",
      "|    mean_reward          | 1.54e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016579546 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4           |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 51.8        |\n",
      "|    n_updates            | 37830       |\n",
      "|    policy_gradient_loss | 0.0052      |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 202         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.79e+03  |\n",
      "|    ep_rew_mean     | -3.27e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 494       |\n",
      "|    iterations      | 2193      |\n",
      "|    time_elapsed    | 9073      |\n",
      "|    total_timesteps | 4491264   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77e+03    |\n",
      "|    ep_rew_mean          | -3.28e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2194        |\n",
      "|    time_elapsed         | 9075        |\n",
      "|    total_timesteps      | 4493312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022061441 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.02        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 37840       |\n",
      "|    policy_gradient_loss | 0.00575     |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 5.41e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4495000, episode_reward=10760.18 +/- 3144.89\n",
      "Episode length: 1304.00 +/- 6.63\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.3e+03    |\n",
      "|    mean_reward          | 1.08e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4495000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01737276 |\n",
      "|    clip_fraction        | 0.228      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.02       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 40.1       |\n",
      "|    n_updates            | 37850      |\n",
      "|    policy_gradient_loss | 0.00307    |\n",
      "|    std                  | 0.127      |\n",
      "|    value_loss           | 254        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.73e+03  |\n",
      "|    ep_rew_mean     | -3.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2195      |\n",
      "|    time_elapsed    | 9080      |\n",
      "|    total_timesteps | 4495360   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.72e+03   |\n",
      "|    ep_rew_mean          | -3.3e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 495        |\n",
      "|    iterations           | 2196       |\n",
      "|    time_elapsed         | 9082       |\n",
      "|    total_timesteps      | 4497408    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01417046 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.02       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 93         |\n",
      "|    n_updates            | 37860      |\n",
      "|    policy_gradient_loss | 0.0015     |\n",
      "|    std                  | 0.128      |\n",
      "|    value_loss           | 342        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.69e+03   |\n",
      "|    ep_rew_mean          | -3.32e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 495        |\n",
      "|    iterations           | 2197       |\n",
      "|    time_elapsed         | 9083       |\n",
      "|    total_timesteps      | 4499456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01404541 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.02       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.6       |\n",
      "|    n_updates            | 37870      |\n",
      "|    policy_gradient_loss | 0.00291    |\n",
      "|    std                  | 0.127      |\n",
      "|    value_loss           | 163        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4500000, episode_reward=14918.53 +/- 3886.18\n",
      "Episode length: 1405.00 +/- 10.68\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.40e+03     |\n",
      "|    mean_reward          | 1.49e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4500000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030526256 |\n",
      "|    clip_fraction        | 0.136        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.03         |\n",
      "|    explained_variance   | 0.749        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.91e+05     |\n",
      "|    n_updates            | 37880        |\n",
      "|    policy_gradient_loss | 0.00306      |\n",
      "|    std                  | 0.127        |\n",
      "|    value_loss           | 1.45e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.67e+03  |\n",
      "|    ep_rew_mean     | -3.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2198      |\n",
      "|    time_elapsed    | 9089      |\n",
      "|    total_timesteps | 4501504   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.65e+03    |\n",
      "|    ep_rew_mean          | -3.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2199        |\n",
      "|    time_elapsed         | 9090        |\n",
      "|    total_timesteps      | 4503552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011705777 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 348         |\n",
      "|    n_updates            | 37890       |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 1.5e+04     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4505000, episode_reward=16180.19 +/- 4384.33\n",
      "Episode length: 1435.00 +/- 6.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.44e+03    |\n",
      "|    mean_reward          | 1.62e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4505000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015832597 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 424         |\n",
      "|    n_updates            | 37900       |\n",
      "|    policy_gradient_loss | -0.000673   |\n",
      "|    std                  | 0.128       |\n",
      "|    value_loss           | 2.72e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.64e+03  |\n",
      "|    ep_rew_mean     | -3.35e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2200      |\n",
      "|    time_elapsed    | 9096      |\n",
      "|    total_timesteps | 4505600   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -3.33e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2201        |\n",
      "|    time_elapsed         | 9098        |\n",
      "|    total_timesteps      | 4507648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029181812 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 60.5        |\n",
      "|    n_updates            | 37910       |\n",
      "|    policy_gradient_loss | 0.00792     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 111         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2202        |\n",
      "|    time_elapsed         | 9099        |\n",
      "|    total_timesteps      | 4509696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012904645 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 249         |\n",
      "|    n_updates            | 37920       |\n",
      "|    policy_gradient_loss | -0.000442   |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 621         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4510000, episode_reward=20296.56 +/- 1812.81\n",
      "Episode length: 1550.00 +/- 7.46\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.55e+03    |\n",
      "|    mean_reward          | 2.03e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029641803 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 36.2        |\n",
      "|    n_updates            | 37930       |\n",
      "|    policy_gradient_loss | 0.0037      |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 1.5e+04     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.6e+03   |\n",
      "|    ep_rew_mean     | -3.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2203      |\n",
      "|    time_elapsed    | 9105      |\n",
      "|    total_timesteps | 4511744   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -3.54e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2204        |\n",
      "|    time_elapsed         | 9107        |\n",
      "|    total_timesteps      | 4513792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044006556 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 62.3        |\n",
      "|    n_updates            | 37940       |\n",
      "|    policy_gradient_loss | 0.00433     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 1.4e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4515000, episode_reward=21588.59 +/- 2762.51\n",
      "Episode length: 1659.40 +/- 12.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.66e+03    |\n",
      "|    mean_reward          | 2.16e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4515000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.050692298 |\n",
      "|    clip_fraction        | 0.447       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.7e+06     |\n",
      "|    n_updates            | 37950       |\n",
      "|    policy_gradient_loss | 0.0166      |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 4.39e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -3.49e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2205      |\n",
      "|    time_elapsed    | 9113      |\n",
      "|    total_timesteps | 4515840   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | -3.43e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 495          |\n",
      "|    iterations           | 2206         |\n",
      "|    time_elapsed         | 9115         |\n",
      "|    total_timesteps      | 4517888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044086818 |\n",
      "|    clip_fraction        | 0.0115       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.04         |\n",
      "|    explained_variance   | 0.943        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.89e+04     |\n",
      "|    n_updates            | 37960        |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    std                  | 0.127        |\n",
      "|    value_loss           | 8.28e+04     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.52e+03    |\n",
      "|    ep_rew_mean          | -3.45e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2207        |\n",
      "|    time_elapsed         | 9116        |\n",
      "|    total_timesteps      | 4519936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004565793 |\n",
      "|    clip_fraction        | 0.0297      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.08e+04    |\n",
      "|    n_updates            | 37970       |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 4.33e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4520000, episode_reward=18621.67 +/- 4554.76\n",
      "Episode length: 1549.20 +/- 12.30\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.55e+03     |\n",
      "|    mean_reward          | 1.86e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4520000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052693877 |\n",
      "|    clip_fraction        | 0.0348       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.04         |\n",
      "|    explained_variance   | 0.971        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.26e+03     |\n",
      "|    n_updates            | 37980        |\n",
      "|    policy_gradient_loss | -0.0027      |\n",
      "|    std                  | 0.127        |\n",
      "|    value_loss           | 7.37e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.5e+03   |\n",
      "|    ep_rew_mean     | -3.44e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2208      |\n",
      "|    time_elapsed    | 9122      |\n",
      "|    total_timesteps | 4521984   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.47e+03     |\n",
      "|    ep_rew_mean          | -3.47e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 495          |\n",
      "|    iterations           | 2209         |\n",
      "|    time_elapsed         | 9124         |\n",
      "|    total_timesteps      | 4524032      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062528593 |\n",
      "|    clip_fraction        | 0.0627       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.04         |\n",
      "|    explained_variance   | 0.977        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.97e+03     |\n",
      "|    n_updates            | 37990        |\n",
      "|    policy_gradient_loss | -0.00519     |\n",
      "|    std                  | 0.127        |\n",
      "|    value_loss           | 4.32e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4525000, episode_reward=16437.05 +/- 3772.82\n",
      "Episode length: 1532.40 +/- 13.18\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.53e+03    |\n",
      "|    mean_reward          | 1.64e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4525000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007177324 |\n",
      "|    clip_fraction        | 0.0584      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.05        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.61e+03    |\n",
      "|    n_updates            | 38000       |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 4.87e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.46e+03  |\n",
      "|    ep_rew_mean     | -3.48e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2210      |\n",
      "|    time_elapsed    | 9129      |\n",
      "|    total_timesteps | 4526080   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | -3.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2211        |\n",
      "|    time_elapsed         | 9131        |\n",
      "|    total_timesteps      | 4528128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011848981 |\n",
      "|    clip_fraction        | 0.0819      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.05        |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 398         |\n",
      "|    n_updates            | 38010       |\n",
      "|    policy_gradient_loss | -0.00183    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 3.63e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4530000, episode_reward=20601.00 +/- 4468.14\n",
      "Episode length: 1582.40 +/- 13.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.58e+03    |\n",
      "|    mean_reward          | 2.06e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4530000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008248997 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.05        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.18e+03    |\n",
      "|    n_updates            | 38020       |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 1.76e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -3.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2212      |\n",
      "|    time_elapsed    | 9137      |\n",
      "|    total_timesteps | 4530176   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -3.47e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 495         |\n",
      "|    iterations           | 2213        |\n",
      "|    time_elapsed         | 9139        |\n",
      "|    total_timesteps      | 4532224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013996001 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 503         |\n",
      "|    n_updates            | 38030       |\n",
      "|    policy_gradient_loss | -0.00229    |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 983         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.42e+03   |\n",
      "|    ep_rew_mean          | -3.46e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 2214       |\n",
      "|    time_elapsed         | 9140       |\n",
      "|    total_timesteps      | 4534272    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02461388 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.04       |\n",
      "|    explained_variance   | 0.991      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 57.3       |\n",
      "|    n_updates            | 38040      |\n",
      "|    policy_gradient_loss | 0.0111     |\n",
      "|    std                  | 0.127      |\n",
      "|    value_loss           | 604        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4535000, episode_reward=18208.19 +/- 5614.87\n",
      "Episode length: 1649.20 +/- 8.57\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.65e+03    |\n",
      "|    mean_reward          | 1.82e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4535000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014535705 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 140         |\n",
      "|    n_updates            | 38050       |\n",
      "|    policy_gradient_loss | 0.00697     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 725         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.41e+03  |\n",
      "|    ep_rew_mean     | -3.47e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2215      |\n",
      "|    time_elapsed    | 9146      |\n",
      "|    total_timesteps | 4536320   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | -3.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2216        |\n",
      "|    time_elapsed         | 9148        |\n",
      "|    total_timesteps      | 4538368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013311578 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.01e+03    |\n",
      "|    n_updates            | 38060       |\n",
      "|    policy_gradient_loss | 0.00136     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 8.82e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4540000, episode_reward=22766.75 +/- 2233.17\n",
      "Episode length: 1985.80 +/- 9.95\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.99e+03    |\n",
      "|    mean_reward          | 2.28e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.061622493 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 77          |\n",
      "|    n_updates            | 38070       |\n",
      "|    policy_gradient_loss | 0.00761     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 259         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.41e+03  |\n",
      "|    ep_rew_mean     | -3.31e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2217      |\n",
      "|    time_elapsed    | 9155      |\n",
      "|    total_timesteps | 4540416   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.4e+03     |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2218        |\n",
      "|    time_elapsed         | 9157        |\n",
      "|    total_timesteps      | 4542464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018426582 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 108         |\n",
      "|    n_updates            | 38080       |\n",
      "|    policy_gradient_loss | 0.00484     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 2.65e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39e+03    |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2219        |\n",
      "|    time_elapsed         | 9158        |\n",
      "|    total_timesteps      | 4544512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014097698 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.05        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 79.4        |\n",
      "|    n_updates            | 38090       |\n",
      "|    policy_gradient_loss | 0.00828     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 241         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4545000, episode_reward=22980.30 +/- 3792.62\n",
      "Episode length: 2122.00 +/- 9.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.12e+03    |\n",
      "|    mean_reward          | 2.3e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4545000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014415868 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 64.3        |\n",
      "|    n_updates            | 38100       |\n",
      "|    policy_gradient_loss | 0.000432    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.39e+03  |\n",
      "|    ep_rew_mean     | -3.33e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 2220      |\n",
      "|    time_elapsed    | 9165      |\n",
      "|    total_timesteps | 4546560   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.41e+03   |\n",
      "|    ep_rew_mean          | -3.31e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 2221       |\n",
      "|    time_elapsed         | 9167       |\n",
      "|    total_timesteps      | 4548608    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03322383 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.04       |\n",
      "|    explained_variance   | 0.984      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 66.4       |\n",
      "|    n_updates            | 38110      |\n",
      "|    policy_gradient_loss | -0.000951  |\n",
      "|    std                  | 0.126      |\n",
      "|    value_loss           | 5.18e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4550000, episode_reward=23870.52 +/- 3802.04\n",
      "Episode length: 2810.40 +/- 6.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.81e+03     |\n",
      "|    mean_reward          | 2.39e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4550000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068686604 |\n",
      "|    clip_fraction        | 0.192        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.04         |\n",
      "|    explained_variance   | 0.963        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.77e+03     |\n",
      "|    n_updates            | 38120        |\n",
      "|    policy_gradient_loss | 0.012        |\n",
      "|    std                  | 0.126        |\n",
      "|    value_loss           | 2.59e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.43e+03  |\n",
      "|    ep_rew_mean     | -3.29e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2222      |\n",
      "|    time_elapsed    | 9176      |\n",
      "|    total_timesteps | 4550656   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.43e+03    |\n",
      "|    ep_rew_mean          | -3.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2223        |\n",
      "|    time_elapsed         | 9178        |\n",
      "|    total_timesteps      | 4552704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007920858 |\n",
      "|    clip_fraction        | 0.0729      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.05e+03    |\n",
      "|    n_updates            | 38130       |\n",
      "|    policy_gradient_loss | -0.00809    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 3.37e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | -3.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2224        |\n",
      "|    time_elapsed         | 9179        |\n",
      "|    total_timesteps      | 4554752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020863682 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 101         |\n",
      "|    n_updates            | 38140       |\n",
      "|    policy_gradient_loss | 0.00645     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 353         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4555000, episode_reward=20996.66 +/- 5135.93\n",
      "Episode length: 2704.40 +/- 7.17\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.7e+03     |\n",
      "|    mean_reward          | 2.1e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4555000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030523613 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 38150       |\n",
      "|    policy_gradient_loss | -0.0048     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 2.7e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.44e+03  |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2225      |\n",
      "|    time_elapsed    | 9188      |\n",
      "|    total_timesteps | 4556800   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.46e+03    |\n",
      "|    ep_rew_mean          | -3.24e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2226        |\n",
      "|    time_elapsed         | 9190        |\n",
      "|    total_timesteps      | 4558848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022915414 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.1        |\n",
      "|    n_updates            | 38160       |\n",
      "|    policy_gradient_loss | 0.00719     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 126         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4560000, episode_reward=25351.45 +/- 3798.64\n",
      "Episode length: 2257.80 +/- 10.98\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.26e+03    |\n",
      "|    mean_reward          | 2.54e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032480784 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.05        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.36e+03    |\n",
      "|    n_updates            | 38170       |\n",
      "|    policy_gradient_loss | 0.00526     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 934         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.47e+03  |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2227      |\n",
      "|    time_elapsed    | 9197      |\n",
      "|    total_timesteps | 4560896   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | -3.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2228        |\n",
      "|    time_elapsed         | 9199        |\n",
      "|    total_timesteps      | 4562944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017923424 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.05        |\n",
      "|    explained_variance   | 0.981       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 23.7        |\n",
      "|    n_updates            | 38180       |\n",
      "|    policy_gradient_loss | 0.00199     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 4.01e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | -3.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2229        |\n",
      "|    time_elapsed         | 9200        |\n",
      "|    total_timesteps      | 4564992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009253214 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 38190       |\n",
      "|    policy_gradient_loss | -0.000597   |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 256         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4565000, episode_reward=17989.24 +/- 5477.93\n",
      "Episode length: 2505.20 +/- 8.91\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 2.51e+03     |\n",
      "|    mean_reward          | 1.8e+04      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4565000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039022136 |\n",
      "|    clip_fraction        | 0.033        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.04         |\n",
      "|    explained_variance   | 0.993        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 171          |\n",
      "|    n_updates            | 38200        |\n",
      "|    policy_gradient_loss | 0.000607     |\n",
      "|    std                  | 0.126        |\n",
      "|    value_loss           | 3.76e+03     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -3.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2230      |\n",
      "|    time_elapsed    | 9208      |\n",
      "|    total_timesteps | 4567040   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.48e+03     |\n",
      "|    ep_rew_mean          | -3.14e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 496          |\n",
      "|    iterations           | 2231         |\n",
      "|    time_elapsed         | 9210         |\n",
      "|    total_timesteps      | 4569088      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037405873 |\n",
      "|    clip_fraction        | 0.0362       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.04         |\n",
      "|    explained_variance   | 0.995        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 197          |\n",
      "|    n_updates            | 38210        |\n",
      "|    policy_gradient_loss | -0.00196     |\n",
      "|    std                  | 0.126        |\n",
      "|    value_loss           | 1.81e+03     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4570000, episode_reward=19235.91 +/- 2935.37\n",
      "Episode length: 2481.60 +/- 12.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.48e+03    |\n",
      "|    mean_reward          | 1.92e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037705258 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 29.9        |\n",
      "|    n_updates            | 38220       |\n",
      "|    policy_gradient_loss | 0.0101      |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 166         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.48e+03  |\n",
      "|    ep_rew_mean     | -2.88e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2232      |\n",
      "|    time_elapsed    | 9218      |\n",
      "|    total_timesteps | 4571136   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.5e+03    |\n",
      "|    ep_rew_mean          | -2.73e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 495        |\n",
      "|    iterations           | 2233       |\n",
      "|    time_elapsed         | 9220       |\n",
      "|    total_timesteps      | 4573184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04225249 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.03       |\n",
      "|    explained_variance   | 1          |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 11.7       |\n",
      "|    n_updates            | 38230      |\n",
      "|    policy_gradient_loss | 0.0027     |\n",
      "|    std                  | 0.126      |\n",
      "|    value_loss           | 77.4       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4575000, episode_reward=19129.31 +/- 4441.03\n",
      "Episode length: 2486.00 +/- 13.04\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.49e+03   |\n",
      "|    mean_reward          | 1.91e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4575000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00678764 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.03       |\n",
      "|    explained_variance   | 0.996      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 446        |\n",
      "|    n_updates            | 38240      |\n",
      "|    policy_gradient_loss | -0.000491  |\n",
      "|    std                  | 0.126      |\n",
      "|    value_loss           | 2.4e+03    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.52e+03  |\n",
      "|    ep_rew_mean     | -2.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2234      |\n",
      "|    time_elapsed    | 9228      |\n",
      "|    total_timesteps | 4575232   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.54e+03     |\n",
      "|    ep_rew_mean          | -2.7e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 495          |\n",
      "|    iterations           | 2235         |\n",
      "|    time_elapsed         | 9229         |\n",
      "|    total_timesteps      | 4577280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016643677 |\n",
      "|    clip_fraction        | 0.0199       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.03         |\n",
      "|    explained_variance   | 0.99         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 764          |\n",
      "|    n_updates            | 38250        |\n",
      "|    policy_gradient_loss | -0.00141     |\n",
      "|    std                  | 0.126        |\n",
      "|    value_loss           | 3.59e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.55e+03    |\n",
      "|    ep_rew_mean          | -2.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2236        |\n",
      "|    time_elapsed         | 9231        |\n",
      "|    total_timesteps      | 4579328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010843504 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 200         |\n",
      "|    n_updates            | 38260       |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 1.23e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4580000, episode_reward=25272.13 +/- 879.19\n",
      "Episode length: 1959.00 +/- 6.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.96e+03    |\n",
      "|    mean_reward          | 2.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028728765 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 31.1        |\n",
      "|    n_updates            | 38270       |\n",
      "|    policy_gradient_loss | 0.00647     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 120         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.56e+03  |\n",
      "|    ep_rew_mean     | -2.53e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2237      |\n",
      "|    time_elapsed    | 9238      |\n",
      "|    total_timesteps | 4581376   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.56e+03    |\n",
      "|    ep_rew_mean          | -2.53e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2238        |\n",
      "|    time_elapsed         | 9240        |\n",
      "|    total_timesteps      | 4583424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027513916 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.02        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 16.5        |\n",
      "|    n_updates            | 38280       |\n",
      "|    policy_gradient_loss | 0.0152      |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 72          |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4585000, episode_reward=24229.19 +/- 885.53\n",
      "Episode length: 1888.00 +/- 8.69\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.89e+03    |\n",
      "|    mean_reward          | 2.42e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4585000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011334188 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.02        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 30          |\n",
      "|    n_updates            | 38290       |\n",
      "|    policy_gradient_loss | -0.000326   |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 117         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.57e+03  |\n",
      "|    ep_rew_mean     | -2.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 495       |\n",
      "|    iterations      | 2239      |\n",
      "|    time_elapsed    | 9246      |\n",
      "|    total_timesteps | 4585472   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | -2.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2240        |\n",
      "|    time_elapsed         | 9248        |\n",
      "|    total_timesteps      | 4587520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012320105 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.02        |\n",
      "|    explained_variance   | 0.232       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.77e+06    |\n",
      "|    n_updates            | 38300       |\n",
      "|    policy_gradient_loss | 0.000229    |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 4.91e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.58e+03   |\n",
      "|    ep_rew_mean          | -2.07e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 2241       |\n",
      "|    time_elapsed         | 9250       |\n",
      "|    total_timesteps      | 4589568    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00126097 |\n",
      "|    clip_fraction        | 0.00581    |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.02       |\n",
      "|    explained_variance   | 0.384      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.31e+05   |\n",
      "|    n_updates            | 38310      |\n",
      "|    policy_gradient_loss | -0.00288   |\n",
      "|    std                  | 0.127      |\n",
      "|    value_loss           | 1.85e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4590000, episode_reward=20813.35 +/- 7716.23\n",
      "Episode length: 1606.20 +/- 501.18\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.61e+03     |\n",
      "|    mean_reward          | 2.08e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4590000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036606123 |\n",
      "|    clip_fraction        | 0.0146       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.02         |\n",
      "|    explained_variance   | 0.786        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.25e+04     |\n",
      "|    n_updates            | 38320        |\n",
      "|    policy_gradient_loss | -0.00598     |\n",
      "|    std                  | 0.127        |\n",
      "|    value_loss           | 1.15e+06     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.59e+03  |\n",
      "|    ep_rew_mean     | -1.93e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 2242      |\n",
      "|    time_elapsed    | 9255      |\n",
      "|    total_timesteps | 4591616   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.6e+03      |\n",
      "|    ep_rew_mean          | -1.91e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 496          |\n",
      "|    iterations           | 2243         |\n",
      "|    time_elapsed         | 9257         |\n",
      "|    total_timesteps      | 4593664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064652413 |\n",
      "|    clip_fraction        | 0.0819       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.02         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 224          |\n",
      "|    n_updates            | 38330        |\n",
      "|    policy_gradient_loss | -0.00257     |\n",
      "|    std                  | 0.127        |\n",
      "|    value_loss           | 2.2e+04      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4595000, episode_reward=22102.77 +/- 3814.10\n",
      "Episode length: 1781.20 +/- 4.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.78e+03    |\n",
      "|    mean_reward          | 2.21e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4595000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009428396 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.02        |\n",
      "|    explained_variance   | 0.982       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 176         |\n",
      "|    n_updates            | 38340       |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 3.93e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.61e+03  |\n",
      "|    ep_rew_mean     | -1.77e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 2244      |\n",
      "|    time_elapsed    | 9263      |\n",
      "|    total_timesteps | 4595712   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.61e+03    |\n",
      "|    ep_rew_mean          | -1.63e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2245        |\n",
      "|    time_elapsed         | 9265        |\n",
      "|    total_timesteps      | 4597760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008394116 |\n",
      "|    clip_fraction        | 0.0933      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 607         |\n",
      "|    n_updates            | 38350       |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 3.18e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | -1.34e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2246        |\n",
      "|    time_elapsed         | 9267        |\n",
      "|    total_timesteps      | 4599808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009304785 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 608         |\n",
      "|    n_updates            | 38360       |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 1.77e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4600000, episode_reward=21068.18 +/- 2690.22\n",
      "Episode length: 1700.80 +/- 9.24\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.7e+03    |\n",
      "|    mean_reward          | 2.11e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4600000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01425891 |\n",
      "|    clip_fraction        | 0.149      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.03       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 60.6       |\n",
      "|    n_updates            | 38370      |\n",
      "|    policy_gradient_loss | 0.000337   |\n",
      "|    std                  | 0.126      |\n",
      "|    value_loss           | 842        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -1.18e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 2247      |\n",
      "|    time_elapsed    | 9273      |\n",
      "|    total_timesteps | 4601856   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.63e+03   |\n",
      "|    ep_rew_mean          | -1.04e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 2248       |\n",
      "|    time_elapsed         | 9275       |\n",
      "|    total_timesteps      | 4603904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02385371 |\n",
      "|    clip_fraction        | 0.154      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.04       |\n",
      "|    explained_variance   | 0.998      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 70.4       |\n",
      "|    n_updates            | 38380      |\n",
      "|    policy_gradient_loss | 0.00459    |\n",
      "|    std                  | 0.126      |\n",
      "|    value_loss           | 166        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4605000, episode_reward=18721.38 +/- 8372.04\n",
      "Episode length: 1384.60 +/- 394.82\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.38e+03     |\n",
      "|    mean_reward          | 1.87e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4605000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052321786 |\n",
      "|    clip_fraction        | 0.0267       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.04         |\n",
      "|    explained_variance   | 0.381        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.92e+06     |\n",
      "|    n_updates            | 38390        |\n",
      "|    policy_gradient_loss | 0.00323      |\n",
      "|    std                  | 0.126        |\n",
      "|    value_loss           | 2.37e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.62e+03  |\n",
      "|    ep_rew_mean     | -7.74e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 2249      |\n",
      "|    time_elapsed    | 9280      |\n",
      "|    total_timesteps | 4605952   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62e+03    |\n",
      "|    ep_rew_mean          | -6.1e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2250        |\n",
      "|    time_elapsed         | 9282        |\n",
      "|    total_timesteps      | 4608000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023976142 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 110         |\n",
      "|    n_updates            | 38400       |\n",
      "|    policy_gradient_loss | 0.00644     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 1.79e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4610000, episode_reward=9782.89 +/- 11610.13\n",
      "Episode length: 2012.80 +/- 687.87\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.01e+03    |\n",
      "|    mean_reward          | 9.78e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039914563 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 39.9        |\n",
      "|    n_updates            | 38410       |\n",
      "|    policy_gradient_loss | 0.00105     |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 243         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.63e+03  |\n",
      "|    ep_rew_mean     | -4.52e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 496       |\n",
      "|    iterations      | 2251      |\n",
      "|    time_elapsed    | 9288      |\n",
      "|    total_timesteps | 4610048   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63e+03    |\n",
      "|    ep_rew_mean          | -3.11e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2252        |\n",
      "|    time_elapsed         | 9290        |\n",
      "|    total_timesteps      | 4612096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011562352 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.03        |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.85e+03    |\n",
      "|    n_updates            | 38420       |\n",
      "|    policy_gradient_loss | 0.000125    |\n",
      "|    std                  | 0.127       |\n",
      "|    value_loss           | 9.3e+03     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.63e+03   |\n",
      "|    ep_rew_mean          | 1.86e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 2253       |\n",
      "|    time_elapsed         | 9292       |\n",
      "|    total_timesteps      | 4614144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02495932 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.04       |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 51.7       |\n",
      "|    n_updates            | 38430      |\n",
      "|    policy_gradient_loss | 0.0022     |\n",
      "|    std                  | 0.127      |\n",
      "|    value_loss           | 138        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4615000, episode_reward=15444.01 +/- 8831.68\n",
      "Episode length: 1189.00 +/- 486.11\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.19e+03     |\n",
      "|    mean_reward          | 1.54e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4615000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045558102 |\n",
      "|    clip_fraction        | 0.0661       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.04         |\n",
      "|    explained_variance   | 0.596        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.74e+05     |\n",
      "|    n_updates            | 38440        |\n",
      "|    policy_gradient_loss | -0.000667    |\n",
      "|    std                  | 0.127        |\n",
      "|    value_loss           | 1.01e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.6e+03  |\n",
      "|    ep_rew_mean     | 2.79e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 496      |\n",
      "|    iterations      | 2254     |\n",
      "|    time_elapsed    | 9297     |\n",
      "|    total_timesteps | 4616192  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.59e+03   |\n",
      "|    ep_rew_mean          | 7.13e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 2255       |\n",
      "|    time_elapsed         | 9298       |\n",
      "|    total_timesteps      | 4618240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.16377853 |\n",
      "|    clip_fraction        | 0.12       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.04       |\n",
      "|    explained_variance   | 0.44       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.68e+07   |\n",
      "|    n_updates            | 38450      |\n",
      "|    policy_gradient_loss | -0.00331   |\n",
      "|    std                  | 0.127      |\n",
      "|    value_loss           | 1.83e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4620000, episode_reward=-20686.77 +/- 57530.67\n",
      "Episode length: 707.20 +/- 512.79\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 707        |\n",
      "|    mean_reward          | -2.07e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4620000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.49781847 |\n",
      "|    clip_fraction        | 0.373      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.04       |\n",
      "|    explained_variance   | 0.96       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 262        |\n",
      "|    n_updates            | 38460      |\n",
      "|    policy_gradient_loss | 0.0498     |\n",
      "|    std                  | 0.127      |\n",
      "|    value_loss           | 6.33e+03   |\n",
      "----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.59e+03 |\n",
      "|    ep_rew_mean     | 7.4e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 496      |\n",
      "|    iterations      | 2256     |\n",
      "|    time_elapsed    | 9302     |\n",
      "|    total_timesteps | 4620288  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 9.36e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 496         |\n",
      "|    iterations           | 2257        |\n",
      "|    time_elapsed         | 9304        |\n",
      "|    total_timesteps      | 4622336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022962473 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 38.2        |\n",
      "|    n_updates            | 38470       |\n",
      "|    policy_gradient_loss | 0.00637     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 113         |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.59e+03   |\n",
      "|    ep_rew_mean          | 9.37e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 496        |\n",
      "|    iterations           | 2258       |\n",
      "|    time_elapsed         | 9306       |\n",
      "|    total_timesteps      | 4624384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00566845 |\n",
      "|    clip_fraction        | 0.102      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.04       |\n",
      "|    explained_variance   | 0.971      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.43e+03   |\n",
      "|    n_updates            | 38480      |\n",
      "|    policy_gradient_loss | -0.00107   |\n",
      "|    std                  | 0.126      |\n",
      "|    value_loss           | 1.68e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4625000, episode_reward=-10294.98 +/- 59520.32\n",
      "Episode length: 1129.20 +/- 676.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.13e+03    |\n",
      "|    mean_reward          | -1.03e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4625000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005559397 |\n",
      "|    clip_fraction        | 0.0329      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 279         |\n",
      "|    n_updates            | 38490       |\n",
      "|    policy_gradient_loss | -0.00499    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 3.27e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.58e+03 |\n",
      "|    ep_rew_mean     | 9.61e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 496      |\n",
      "|    iterations      | 2259     |\n",
      "|    time_elapsed    | 9310     |\n",
      "|    total_timesteps | 4626432  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.58e+03    |\n",
      "|    ep_rew_mean          | 9.65e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 2260        |\n",
      "|    time_elapsed         | 9312        |\n",
      "|    total_timesteps      | 4628480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010388013 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.975       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 252         |\n",
      "|    n_updates            | 38500       |\n",
      "|    policy_gradient_loss | 0.00797     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 8.04e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4630000, episode_reward=9988.97 +/- 5489.31\n",
      "Episode length: 902.60 +/- 613.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 903         |\n",
      "|    mean_reward          | 9.99e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026215782 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 32.8        |\n",
      "|    n_updates            | 38510       |\n",
      "|    policy_gradient_loss | 0.00581     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 177         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.57e+03 |\n",
      "|    ep_rew_mean     | 9.7e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 497      |\n",
      "|    iterations      | 2261     |\n",
      "|    time_elapsed    | 9316     |\n",
      "|    total_timesteps | 4630528  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.55e+03   |\n",
      "|    ep_rew_mean          | 9.56e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 497        |\n",
      "|    iterations           | 2262       |\n",
      "|    time_elapsed         | 9318       |\n",
      "|    total_timesteps      | 4632576    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02662998 |\n",
      "|    clip_fraction        | 0.116      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.04       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 152        |\n",
      "|    n_updates            | 38520      |\n",
      "|    policy_gradient_loss | 0.00531    |\n",
      "|    std                  | 0.126      |\n",
      "|    value_loss           | 1.16e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.54e+03    |\n",
      "|    ep_rew_mean          | 9.53e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 2263        |\n",
      "|    time_elapsed         | 9320        |\n",
      "|    total_timesteps      | 4634624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012016199 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.92e+04    |\n",
      "|    n_updates            | 38530       |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 2.44e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4635000, episode_reward=8431.67 +/- 3093.09\n",
      "Episode length: 598.00 +/- 22.05\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 598         |\n",
      "|    mean_reward          | 8.43e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4635000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008937959 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 186         |\n",
      "|    n_updates            | 38540       |\n",
      "|    policy_gradient_loss | -0.00293    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 7.41e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.53e+03 |\n",
      "|    ep_rew_mean     | 9.38e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 497      |\n",
      "|    iterations      | 2264     |\n",
      "|    time_elapsed    | 9323     |\n",
      "|    total_timesteps | 4636672  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.5e+03   |\n",
      "|    ep_rew_mean          | 9.11e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 497       |\n",
      "|    iterations           | 2265      |\n",
      "|    time_elapsed         | 9325      |\n",
      "|    total_timesteps      | 4638720   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0179929 |\n",
      "|    clip_fraction        | 0.17      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.04      |\n",
      "|    explained_variance   | 0.997     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 147       |\n",
      "|    n_updates            | 38550     |\n",
      "|    policy_gradient_loss | 0.00445   |\n",
      "|    std                  | 0.125     |\n",
      "|    value_loss           | 409       |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4640000, episode_reward=7152.92 +/- 5182.43\n",
      "Episode length: 616.60 +/- 21.77\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 617         |\n",
      "|    mean_reward          | 7.15e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019984484 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 724         |\n",
      "|    n_updates            | 38560       |\n",
      "|    policy_gradient_loss | 0.00437     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.83e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.48e+03 |\n",
      "|    ep_rew_mean     | 8.81e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 497      |\n",
      "|    iterations      | 2266     |\n",
      "|    time_elapsed    | 9328     |\n",
      "|    total_timesteps | 4640768  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.48e+03    |\n",
      "|    ep_rew_mean          | 8.81e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 2267        |\n",
      "|    time_elapsed         | 9330        |\n",
      "|    total_timesteps      | 4642816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017119462 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 88.1        |\n",
      "|    n_updates            | 38570       |\n",
      "|    policy_gradient_loss | -0.00118    |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 7.16e+03    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.47e+03    |\n",
      "|    ep_rew_mean          | 6.19e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 2268        |\n",
      "|    time_elapsed         | 9332        |\n",
      "|    total_timesteps      | 4644864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009517338 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 493         |\n",
      "|    n_updates            | 38580       |\n",
      "|    policy_gradient_loss | 0.00439     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 1.76e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4645000, episode_reward=16126.25 +/- 5772.09\n",
      "Episode length: 1218.60 +/- 770.32\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.22e+03    |\n",
      "|    mean_reward          | 1.61e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4645000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002084268 |\n",
      "|    clip_fraction        | 0.0113      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.543       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.44e+06    |\n",
      "|    n_updates            | 38590       |\n",
      "|    policy_gradient_loss | -0.0026     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 2.29e+07    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.46e+03 |\n",
      "|    ep_rew_mean     | 6.2e+03  |\n",
      "| time/              |          |\n",
      "|    fps             | 497      |\n",
      "|    iterations      | 2269     |\n",
      "|    time_elapsed    | 9337     |\n",
      "|    total_timesteps | 4646912  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.45e+03    |\n",
      "|    ep_rew_mean          | 6.09e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 2270        |\n",
      "|    time_elapsed         | 9339        |\n",
      "|    total_timesteps      | 4648960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008705144 |\n",
      "|    clip_fraction        | 0.0612      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 500         |\n",
      "|    n_updates            | 38600       |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    std                  | 0.126       |\n",
      "|    value_loss           | 6.73e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4650000, episode_reward=10876.49 +/- 2401.61\n",
      "Episode length: 600.00 +/- 7.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 600         |\n",
      "|    mean_reward          | 1.09e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018075135 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 644         |\n",
      "|    n_updates            | 38610       |\n",
      "|    policy_gradient_loss | -0.000979   |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 9.88e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.45e+03 |\n",
      "|    ep_rew_mean     | 6.12e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 497      |\n",
      "|    iterations      | 2271     |\n",
      "|    time_elapsed    | 9342     |\n",
      "|    total_timesteps | 4651008  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.42e+03    |\n",
      "|    ep_rew_mean          | 6.01e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 497         |\n",
      "|    iterations           | 2272        |\n",
      "|    time_elapsed         | 9344        |\n",
      "|    total_timesteps      | 4653056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009428718 |\n",
      "|    clip_fraction        | 0.0685      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 342         |\n",
      "|    n_updates            | 38620       |\n",
      "|    policy_gradient_loss | -0.006      |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.93e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4655000, episode_reward=6363.63 +/- 5442.39\n",
      "Episode length: 616.80 +/- 19.71\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 617         |\n",
      "|    mean_reward          | 6.36e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4655000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010694193 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 795         |\n",
      "|    n_updates            | 38630       |\n",
      "|    policy_gradient_loss | 0.00109     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.1e+04     |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.4e+03  |\n",
      "|    ep_rew_mean     | 8.26e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 497      |\n",
      "|    iterations      | 2273     |\n",
      "|    time_elapsed    | 9347     |\n",
      "|    total_timesteps | 4655104  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.37e+03    |\n",
      "|    ep_rew_mean          | 7.71e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2274        |\n",
      "|    time_elapsed         | 9349        |\n",
      "|    total_timesteps      | 4657152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025545182 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 460         |\n",
      "|    n_updates            | 38640       |\n",
      "|    policy_gradient_loss | 0.00851     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.73e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.36e+03    |\n",
      "|    ep_rew_mean          | 6.18e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2275        |\n",
      "|    time_elapsed         | 9351        |\n",
      "|    total_timesteps      | 4659200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021289147 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13e+04    |\n",
      "|    n_updates            | 38650       |\n",
      "|    policy_gradient_loss | 0.0132      |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 2.41e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4660000, episode_reward=12732.42 +/- 5160.90\n",
      "Episode length: 760.80 +/- 332.68\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 761          |\n",
      "|    mean_reward          | 1.27e+04     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4660000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031389864 |\n",
      "|    clip_fraction        | 0.0272       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.04         |\n",
      "|    explained_variance   | 0.372        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.09e+06     |\n",
      "|    n_updates            | 38660        |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    std                  | 0.125        |\n",
      "|    value_loss           | 2.34e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.33e+03 |\n",
      "|    ep_rew_mean     | 5.96e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 498      |\n",
      "|    iterations      | 2276     |\n",
      "|    time_elapsed    | 9355     |\n",
      "|    total_timesteps | 4661248  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.3e+03    |\n",
      "|    ep_rew_mean          | 5.64e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 498        |\n",
      "|    iterations           | 2277       |\n",
      "|    time_elapsed         | 9357       |\n",
      "|    total_timesteps      | 4663296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.11671524 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.04       |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 174        |\n",
      "|    n_updates            | 38670      |\n",
      "|    policy_gradient_loss | 0.0103     |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 1.22e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4665000, episode_reward=9918.44 +/- 6500.85\n",
      "Episode length: 716.60 +/- 238.08\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 717         |\n",
      "|    mean_reward          | 9.92e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4665000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036993295 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 38680       |\n",
      "|    policy_gradient_loss | 0.0157      |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 260         |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.26e+03 |\n",
      "|    ep_rew_mean     | 3.85e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 498      |\n",
      "|    iterations      | 2278     |\n",
      "|    time_elapsed    | 9360     |\n",
      "|    total_timesteps | 4665344  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.22e+03  |\n",
      "|    ep_rew_mean          | 3.52e+03  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 498       |\n",
      "|    iterations           | 2279      |\n",
      "|    time_elapsed         | 9362      |\n",
      "|    total_timesteps      | 4667392   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0766239 |\n",
      "|    clip_fraction        | 0.267     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.04      |\n",
      "|    explained_variance   | 0.398     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.32e+07  |\n",
      "|    n_updates            | 38690     |\n",
      "|    policy_gradient_loss | 0.0124    |\n",
      "|    std                  | 0.125     |\n",
      "|    value_loss           | 2.38e+07  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.16e+03    |\n",
      "|    ep_rew_mean          | 3.05e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2280        |\n",
      "|    time_elapsed         | 9364        |\n",
      "|    total_timesteps      | 4669440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019422088 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 450         |\n",
      "|    n_updates            | 38700       |\n",
      "|    policy_gradient_loss | -0.000242   |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 4.09e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4670000, episode_reward=14110.01 +/- 3365.74\n",
      "Episode length: 819.20 +/- 285.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 819         |\n",
      "|    mean_reward          | 1.41e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032878548 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.04        |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.48e+04    |\n",
      "|    n_updates            | 38710       |\n",
      "|    policy_gradient_loss | 0.00393     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 6.58e+04    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.11e+03 |\n",
      "|    ep_rew_mean     | 2.33e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 498      |\n",
      "|    iterations      | 2281     |\n",
      "|    time_elapsed    | 9368     |\n",
      "|    total_timesteps | 4671488  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.01e+03    |\n",
      "|    ep_rew_mean          | -900        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 498         |\n",
      "|    iterations           | 2282        |\n",
      "|    time_elapsed         | 9369        |\n",
      "|    total_timesteps      | 4673536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029961342 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.05        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 153         |\n",
      "|    n_updates            | 38720       |\n",
      "|    policy_gradient_loss | 0.00957     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 3.12e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4675000, episode_reward=8662.74 +/- 6100.01\n",
      "Episode length: 726.60 +/- 216.48\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 727        |\n",
      "|    mean_reward          | 8.66e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4675000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08916727 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.05       |\n",
      "|    explained_variance   | 0.357      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.44e+07   |\n",
      "|    n_updates            | 38730      |\n",
      "|    policy_gradient_loss | 0.0261     |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 3.41e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 958       |\n",
      "|    ep_rew_mean     | -1.27e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 498       |\n",
      "|    iterations      | 2283      |\n",
      "|    time_elapsed    | 9373      |\n",
      "|    total_timesteps | 4675584   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 901       |\n",
      "|    ep_rew_mean          | -1.08e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 498       |\n",
      "|    iterations           | 2284      |\n",
      "|    time_elapsed         | 9375      |\n",
      "|    total_timesteps      | 4677632   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0116025 |\n",
      "|    clip_fraction        | 0.115     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.05      |\n",
      "|    explained_variance   | 0.934     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 489       |\n",
      "|    n_updates            | 38740     |\n",
      "|    policy_gradient_loss | -0.00147  |\n",
      "|    std                  | 0.125     |\n",
      "|    value_loss           | 2.48e+04  |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 866         |\n",
      "|    ep_rew_mean          | -1.53e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 2285        |\n",
      "|    time_elapsed         | 9377        |\n",
      "|    total_timesteps      | 4679680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009795072 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.06        |\n",
      "|    explained_variance   | 0.46        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 5.01e+04    |\n",
      "|    n_updates            | 38750       |\n",
      "|    policy_gradient_loss | 0.00807     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.64e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4680000, episode_reward=-18050.42 +/- 55734.23\n",
      "Episode length: 621.20 +/- 358.28\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 621        |\n",
      "|    mean_reward          | -1.81e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4680000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02739566 |\n",
      "|    clip_fraction        | 0.168      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.06       |\n",
      "|    explained_variance   | 0.962      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.32e+04   |\n",
      "|    n_updates            | 38760      |\n",
      "|    policy_gradient_loss | 0.00287    |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 1.86e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 833       |\n",
      "|    ep_rew_mean     | -1.96e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 2286      |\n",
      "|    time_elapsed    | 9380      |\n",
      "|    total_timesteps | 4681728   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 798        |\n",
      "|    ep_rew_mean          | -2.3e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 499        |\n",
      "|    iterations           | 2287       |\n",
      "|    time_elapsed         | 9382       |\n",
      "|    total_timesteps      | 4683776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03325811 |\n",
      "|    clip_fraction        | 0.197      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.06       |\n",
      "|    explained_variance   | 0.915      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 86.9       |\n",
      "|    n_updates            | 38770      |\n",
      "|    policy_gradient_loss | 0.00725    |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 2.47e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4685000, episode_reward=-15962.89 +/- 54676.22\n",
      "Episode length: 487.00 +/- 203.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 487         |\n",
      "|    mean_reward          | -1.6e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4685000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026378721 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.06        |\n",
      "|    explained_variance   | 0.995       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 223         |\n",
      "|    n_updates            | 38780       |\n",
      "|    policy_gradient_loss | 0.0111      |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.66e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 763       |\n",
      "|    ep_rew_mean     | -2.33e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 2288      |\n",
      "|    time_elapsed    | 9385      |\n",
      "|    total_timesteps | 4685824   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 737        |\n",
      "|    ep_rew_mean          | -2.29e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 499        |\n",
      "|    iterations           | 2289       |\n",
      "|    time_elapsed         | 9387       |\n",
      "|    total_timesteps      | 4687872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.52628005 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.07       |\n",
      "|    explained_variance   | 0.411      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 284        |\n",
      "|    n_updates            | 38790      |\n",
      "|    policy_gradient_loss | 0.0211     |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 1.74e+07   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 723        |\n",
      "|    ep_rew_mean          | -3.72e+03  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 499        |\n",
      "|    iterations           | 2290       |\n",
      "|    time_elapsed         | 9389       |\n",
      "|    total_timesteps      | 4689920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01684118 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.07       |\n",
      "|    explained_variance   | 0.772      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 273        |\n",
      "|    n_updates            | 38800      |\n",
      "|    policy_gradient_loss | 0.00122    |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 8.8e+04    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4690000, episode_reward=9576.23 +/- 2133.82\n",
      "Episode length: 604.20 +/- 19.43\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 604          |\n",
      "|    mean_reward          | 9.58e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4690000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070208623 |\n",
      "|    clip_fraction        | 0.0902       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.07         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.37e+07     |\n",
      "|    n_updates            | 38810        |\n",
      "|    policy_gradient_loss | 0.00276      |\n",
      "|    std                  | 0.125        |\n",
      "|    value_loss           | 4.53e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 699       |\n",
      "|    ep_rew_mean     | -3.92e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 2291      |\n",
      "|    time_elapsed    | 9392      |\n",
      "|    total_timesteps | 4691968   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 661         |\n",
      "|    ep_rew_mean          | -4.23e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 499         |\n",
      "|    iterations           | 2292        |\n",
      "|    time_elapsed         | 9394        |\n",
      "|    total_timesteps      | 4694016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007585954 |\n",
      "|    clip_fraction        | 0.0867      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.07        |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.37e+03    |\n",
      "|    n_updates            | 38820       |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 2.42e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4695000, episode_reward=5244.39 +/- 5074.87\n",
      "Episode length: 606.40 +/- 25.16\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 606         |\n",
      "|    mean_reward          | 5.24e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4695000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009160114 |\n",
      "|    clip_fraction        | 0.0765      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.08        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.7e+03     |\n",
      "|    n_updates            | 38830       |\n",
      "|    policy_gradient_loss | -0.00333    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 2.01e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 644       |\n",
      "|    ep_rew_mean     | -5.61e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 2293      |\n",
      "|    time_elapsed    | 9397      |\n",
      "|    total_timesteps | 4696064   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 650       |\n",
      "|    ep_rew_mean          | -5.51e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 499       |\n",
      "|    iterations           | 2294      |\n",
      "|    time_elapsed         | 9399      |\n",
      "|    total_timesteps      | 4698112   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.962684  |\n",
      "|    clip_fraction        | 0.283     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.08      |\n",
      "|    explained_variance   | 0.405     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 572       |\n",
      "|    n_updates            | 38840     |\n",
      "|    policy_gradient_loss | 0.0234    |\n",
      "|    std                  | 0.125     |\n",
      "|    value_loss           | 1.84e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4700000, episode_reward=-16211.16 +/- 51477.64\n",
      "Episode length: 486.80 +/- 208.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 487         |\n",
      "|    mean_reward          | -1.62e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006153276 |\n",
      "|    clip_fraction        | 0.0579      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.08        |\n",
      "|    explained_variance   | 0.97        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.13e+03    |\n",
      "|    n_updates            | 38850       |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 7.01e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 605       |\n",
      "|    ep_rew_mean     | -1.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 499       |\n",
      "|    iterations      | 2295      |\n",
      "|    time_elapsed    | 9402      |\n",
      "|    total_timesteps | 4700160   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 583       |\n",
      "|    ep_rew_mean          | -1.04e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 499       |\n",
      "|    iterations           | 2296      |\n",
      "|    time_elapsed         | 9404      |\n",
      "|    total_timesteps      | 4702208   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.6431892 |\n",
      "|    clip_fraction        | 0.193     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.08      |\n",
      "|    explained_variance   | 0.458     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.61e+07  |\n",
      "|    n_updates            | 38860     |\n",
      "|    policy_gradient_loss | -0.0309   |\n",
      "|    std                  | 0.125     |\n",
      "|    value_loss           | 6.37e+07  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 519         |\n",
      "|    ep_rew_mean          | -1.69e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2297        |\n",
      "|    time_elapsed         | 9406        |\n",
      "|    total_timesteps      | 4704256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002981879 |\n",
      "|    clip_fraction        | 0.0292      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.08        |\n",
      "|    explained_variance   | 0.417       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.3e+06     |\n",
      "|    n_updates            | 38870       |\n",
      "|    policy_gradient_loss | -0.00433    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 3.41e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4705000, episode_reward=-12264.08 +/- 47342.43\n",
      "Episode length: 477.00 +/- 210.15\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 477       |\n",
      "|    mean_reward          | -1.23e+04 |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4705000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.3124704 |\n",
      "|    clip_fraction        | 0.199     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.08      |\n",
      "|    explained_variance   | 0.461     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 2.62e+07  |\n",
      "|    n_updates            | 38880     |\n",
      "|    policy_gradient_loss | 0.00897   |\n",
      "|    std                  | 0.125     |\n",
      "|    value_loss           | 6.8e+07   |\n",
      "---------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 496      |\n",
      "|    ep_rew_mean     | -2.1e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 500      |\n",
      "|    iterations      | 2298     |\n",
      "|    time_elapsed    | 9409     |\n",
      "|    total_timesteps | 4706304  |\n",
      "---------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 481       |\n",
      "|    ep_rew_mean          | -2.09e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 500       |\n",
      "|    iterations           | 2299      |\n",
      "|    time_elapsed         | 9411      |\n",
      "|    total_timesteps      | 4708352   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 1.5469831 |\n",
      "|    clip_fraction        | 0.207     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.08      |\n",
      "|    explained_variance   | 0.463     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.91e+07  |\n",
      "|    n_updates            | 38890     |\n",
      "|    policy_gradient_loss | -0.0224   |\n",
      "|    std                  | 0.125     |\n",
      "|    value_loss           | 3.97e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4710000, episode_reward=9181.88 +/- 3696.17\n",
      "Episode length: 616.80 +/- 45.60\n",
      "--------------------------------------\n",
      "| eval/                   |          |\n",
      "|    mean_ep_length       | 617      |\n",
      "|    mean_reward          | 9.18e+03 |\n",
      "| time/                   |          |\n",
      "|    total_timesteps      | 4710000  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 4.469041 |\n",
      "|    clip_fraction        | 0.493    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | 4.07     |\n",
      "|    explained_variance   | 0.474    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 5.48e+06 |\n",
      "|    n_updates            | 38900    |\n",
      "|    policy_gradient_loss | 0.0208   |\n",
      "|    std                  | 0.125    |\n",
      "|    value_loss           | 1.21e+07 |\n",
      "--------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 482       |\n",
      "|    ep_rew_mean     | -2.08e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 2300      |\n",
      "|    time_elapsed    | 9414      |\n",
      "|    total_timesteps | 4710400   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 481        |\n",
      "|    ep_rew_mean          | -1.95e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 500        |\n",
      "|    iterations           | 2301       |\n",
      "|    time_elapsed         | 9416       |\n",
      "|    total_timesteps      | 4712448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00895025 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.07       |\n",
      "|    explained_variance   | 0.887      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 374        |\n",
      "|    n_updates            | 38910      |\n",
      "|    policy_gradient_loss | -0.00048   |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 4.77e+04   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 480         |\n",
      "|    ep_rew_mean          | -2.15e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2302        |\n",
      "|    time_elapsed         | 9418        |\n",
      "|    total_timesteps      | 4714496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013108226 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.06        |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.03e+05    |\n",
      "|    n_updates            | 38920       |\n",
      "|    policy_gradient_loss | 0.00506     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 4.85e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4715000, episode_reward=-22609.92 +/- 66155.02\n",
      "Episode length: 503.80 +/- 170.23\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 504          |\n",
      "|    mean_reward          | -2.26e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4715000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027681987 |\n",
      "|    clip_fraction        | 0.0256       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.06         |\n",
      "|    explained_variance   | 0.422        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.11e+06     |\n",
      "|    n_updates            | 38930        |\n",
      "|    policy_gradient_loss | -0.00393     |\n",
      "|    std                  | 0.125        |\n",
      "|    value_loss           | 3.1e+07      |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 480       |\n",
      "|    ep_rew_mean     | -2.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 2303      |\n",
      "|    time_elapsed    | 9421      |\n",
      "|    total_timesteps | 4716544   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 477         |\n",
      "|    ep_rew_mean          | -2.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2304        |\n",
      "|    time_elapsed         | 9423        |\n",
      "|    total_timesteps      | 4718592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015214959 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.07        |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 778         |\n",
      "|    n_updates            | 38940       |\n",
      "|    policy_gradient_loss | -0.00558    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.1e+05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4720000, episode_reward=9045.51 +/- 2405.60\n",
      "Episode length: 563.80 +/- 12.89\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 564          |\n",
      "|    mean_reward          | 9.05e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4720000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052509164 |\n",
      "|    clip_fraction        | 0.125        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.07         |\n",
      "|    explained_variance   | 0.365        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.54e+06     |\n",
      "|    n_updates            | 38950        |\n",
      "|    policy_gradient_loss | 0.00364      |\n",
      "|    std                  | 0.125        |\n",
      "|    value_loss           | 2.61e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 482       |\n",
      "|    ep_rew_mean     | -2.28e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 500       |\n",
      "|    iterations      | 2305      |\n",
      "|    time_elapsed    | 9426      |\n",
      "|    total_timesteps | 4720640   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 487         |\n",
      "|    ep_rew_mean          | -2.49e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 500         |\n",
      "|    iterations           | 2306        |\n",
      "|    time_elapsed         | 9428        |\n",
      "|    total_timesteps      | 4722688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012250467 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.07        |\n",
      "|    explained_variance   | 0.92        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 373         |\n",
      "|    n_updates            | 38960       |\n",
      "|    policy_gradient_loss | -0.00559    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 3.74e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 478         |\n",
      "|    ep_rew_mean          | -2.99e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2307        |\n",
      "|    time_elapsed         | 9430        |\n",
      "|    total_timesteps      | 4724736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009117088 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.07        |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.32e+07    |\n",
      "|    n_updates            | 38970       |\n",
      "|    policy_gradient_loss | 0.00126     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 6.44e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4725000, episode_reward=-63705.78 +/- 81828.19\n",
      "Episode length: 387.80 +/- 237.77\n",
      "-------------------------------------------\n",
      "| eval/                   |               |\n",
      "|    mean_ep_length       | 388           |\n",
      "|    mean_reward          | -6.37e+04     |\n",
      "| time/                   |               |\n",
      "|    total_timesteps      | 4725000       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00094000145 |\n",
      "|    clip_fraction        | 0.00156       |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 4.07          |\n",
      "|    explained_variance   | 0.383         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 3.24e+07      |\n",
      "|    n_updates            | 38980         |\n",
      "|    policy_gradient_loss | -0.00231      |\n",
      "|    std                  | 0.125         |\n",
      "|    value_loss           | 8.84e+07      |\n",
      "-------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 489       |\n",
      "|    ep_rew_mean     | -3.05e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 2308      |\n",
      "|    time_elapsed    | 9432      |\n",
      "|    total_timesteps | 4726784   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 480          |\n",
      "|    ep_rew_mean          | -3.51e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2309         |\n",
      "|    time_elapsed         | 9434         |\n",
      "|    total_timesteps      | 4728832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0027510044 |\n",
      "|    clip_fraction        | 0.0139       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.07         |\n",
      "|    explained_variance   | 0.401        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.57e+07     |\n",
      "|    n_updates            | 38990        |\n",
      "|    policy_gradient_loss | -0.00714     |\n",
      "|    std                  | 0.125        |\n",
      "|    value_loss           | 3.79e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4730000, episode_reward=-47320.12 +/- 75084.99\n",
      "Episode length: 660.60 +/- 408.77\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 661          |\n",
      "|    mean_reward          | -4.73e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4730000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026970697 |\n",
      "|    clip_fraction        | 0.00781      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.07         |\n",
      "|    explained_variance   | 0.445        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.28e+07     |\n",
      "|    n_updates            | 39000        |\n",
      "|    policy_gradient_loss | -0.00288     |\n",
      "|    std                  | 0.125        |\n",
      "|    value_loss           | 7.88e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 476       |\n",
      "|    ep_rew_mean     | -3.72e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 2310      |\n",
      "|    time_elapsed    | 9438      |\n",
      "|    total_timesteps | 4730880   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 480         |\n",
      "|    ep_rew_mean          | -4.14e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2311        |\n",
      "|    time_elapsed         | 9440        |\n",
      "|    total_timesteps      | 4732928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005375987 |\n",
      "|    clip_fraction        | 0.0171      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.07        |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.18e+06    |\n",
      "|    n_updates            | 39010       |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.08e+07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 488          |\n",
      "|    ep_rew_mean          | -4.36e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 501          |\n",
      "|    iterations           | 2312         |\n",
      "|    time_elapsed         | 9441         |\n",
      "|    total_timesteps      | 4734976      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046273605 |\n",
      "|    clip_fraction        | 0.0241       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.07         |\n",
      "|    explained_variance   | 0.418        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.45e+07     |\n",
      "|    n_updates            | 39020        |\n",
      "|    policy_gradient_loss | -0.00628     |\n",
      "|    std                  | 0.125        |\n",
      "|    value_loss           | 6.78e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4735000, episode_reward=-39156.62 +/- 88098.18\n",
      "Episode length: 505.20 +/- 126.54\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 505          |\n",
      "|    mean_reward          | -3.92e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4735000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038307034 |\n",
      "|    clip_fraction        | 0.0197       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.07         |\n",
      "|    explained_variance   | 0.368        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.23e+07     |\n",
      "|    n_updates            | 39030        |\n",
      "|    policy_gradient_loss | -0.00493     |\n",
      "|    std                  | 0.125        |\n",
      "|    value_loss           | 6.29e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 488       |\n",
      "|    ep_rew_mean     | -4.37e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 2313      |\n",
      "|    time_elapsed    | 9444      |\n",
      "|    total_timesteps | 4737024   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 498        |\n",
      "|    ep_rew_mean          | -4.39e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 501        |\n",
      "|    iterations           | 2314       |\n",
      "|    time_elapsed         | 9446       |\n",
      "|    total_timesteps      | 4739072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01266777 |\n",
      "|    clip_fraction        | 0.082      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.07       |\n",
      "|    explained_variance   | 0.786      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.67e+03   |\n",
      "|    n_updates            | 39040      |\n",
      "|    policy_gradient_loss | -0.00323   |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 4.62e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4740000, episode_reward=15778.54 +/- 10527.01\n",
      "Episode length: 1327.00 +/- 360.03\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.33e+03    |\n",
      "|    mean_reward          | 1.58e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006733964 |\n",
      "|    clip_fraction        | 0.0585      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.07        |\n",
      "|    explained_variance   | 0.415       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.27e+07    |\n",
      "|    n_updates            | 39050       |\n",
      "|    policy_gradient_loss | -0.00613    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 3.55e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 511       |\n",
      "|    ep_rew_mean     | -4.23e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 2315      |\n",
      "|    time_elapsed    | 9451      |\n",
      "|    total_timesteps | 4741120   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 526         |\n",
      "|    ep_rew_mean          | -4.21e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2316        |\n",
      "|    time_elapsed         | 9453        |\n",
      "|    total_timesteps      | 4743168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007100736 |\n",
      "|    clip_fraction        | 0.0434      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.07        |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.62e+03    |\n",
      "|    n_updates            | 39060       |\n",
      "|    policy_gradient_loss | -0.00262    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 2.69e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4745000, episode_reward=1559.54 +/- 8591.35\n",
      "Episode length: 754.80 +/- 337.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 755         |\n",
      "|    mean_reward          | 1.56e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4745000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007222666 |\n",
      "|    clip_fraction        | 0.0304      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.08        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.41e+03    |\n",
      "|    n_updates            | 39070       |\n",
      "|    policy_gradient_loss | -0.00244    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 2.41e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 535       |\n",
      "|    ep_rew_mean     | -4.21e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 2317      |\n",
      "|    time_elapsed    | 9457      |\n",
      "|    total_timesteps | 4745216   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 540         |\n",
      "|    ep_rew_mean          | -4.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2318        |\n",
      "|    time_elapsed         | 9459        |\n",
      "|    total_timesteps      | 4747264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004213554 |\n",
      "|    clip_fraction        | 0.0293      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.08        |\n",
      "|    explained_variance   | 0.659       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.75e+05    |\n",
      "|    n_updates            | 39080       |\n",
      "|    policy_gradient_loss | -0.00394    |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.66e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 547         |\n",
      "|    ep_rew_mean          | -4.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 501         |\n",
      "|    iterations           | 2319        |\n",
      "|    time_elapsed         | 9461        |\n",
      "|    total_timesteps      | 4749312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011518492 |\n",
      "|    clip_fraction        | 0.0372      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.08        |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 6.27e+06    |\n",
      "|    n_updates            | 39090       |\n",
      "|    policy_gradient_loss | 0.00897     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.69e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4750000, episode_reward=11536.23 +/- 9045.17\n",
      "Episode length: 1080.80 +/- 422.85\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.08e+03   |\n",
      "|    mean_reward          | 1.15e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4750000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01068646 |\n",
      "|    clip_fraction        | 0.0584     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.08       |\n",
      "|    explained_variance   | 0.891      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.01e+03   |\n",
      "|    n_updates            | 39100      |\n",
      "|    policy_gradient_loss | -0.00164   |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 1.65e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 557       |\n",
      "|    ep_rew_mean     | -4.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 501       |\n",
      "|    iterations      | 2320      |\n",
      "|    time_elapsed    | 9465      |\n",
      "|    total_timesteps | 4751360   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 565       |\n",
      "|    ep_rew_mean          | -4.5e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 502       |\n",
      "|    iterations           | 2321      |\n",
      "|    time_elapsed         | 9467      |\n",
      "|    total_timesteps      | 4753408   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.5072692 |\n",
      "|    clip_fraction        | 0.101     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.08      |\n",
      "|    explained_variance   | 0.507     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 1.63e+07  |\n",
      "|    n_updates            | 39110     |\n",
      "|    policy_gradient_loss | 0.00528   |\n",
      "|    std                  | 0.125     |\n",
      "|    value_loss           | 2.79e+07  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4755000, episode_reward=-86205.89 +/- 86939.15\n",
      "Episode length: 624.80 +/- 648.51\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 625        |\n",
      "|    mean_reward          | -8.62e+04  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4755000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02062218 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.08       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 226        |\n",
      "|    n_updates            | 39120      |\n",
      "|    policy_gradient_loss | 0.00526    |\n",
      "|    std                  | 0.125      |\n",
      "|    value_loss           | 2.93e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 561       |\n",
      "|    ep_rew_mean     | -4.67e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 2322      |\n",
      "|    time_elapsed    | 9470      |\n",
      "|    total_timesteps | 4755456   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 588       |\n",
      "|    ep_rew_mean          | -4.4e+04  |\n",
      "| time/                   |           |\n",
      "|    fps                  | 502       |\n",
      "|    iterations           | 2323      |\n",
      "|    time_elapsed         | 9472      |\n",
      "|    total_timesteps      | 4757504   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.3908707 |\n",
      "|    clip_fraction        | 0.165     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.09      |\n",
      "|    explained_variance   | 0.408     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 7.46e+06  |\n",
      "|    n_updates            | 39130     |\n",
      "|    policy_gradient_loss | -0.0194   |\n",
      "|    std                  | 0.125     |\n",
      "|    value_loss           | 2.57e+07  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 596         |\n",
      "|    ep_rew_mean          | -4.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 2324        |\n",
      "|    time_elapsed         | 9474        |\n",
      "|    total_timesteps      | 4759552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013687452 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.09        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 170         |\n",
      "|    n_updates            | 39140       |\n",
      "|    policy_gradient_loss | 0.00893     |\n",
      "|    std                  | 0.125       |\n",
      "|    value_loss           | 1.36e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4760000, episode_reward=20130.05 +/- 128.08\n",
      "Episode length: 1372.80 +/- 4.92\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.37e+03   |\n",
      "|    mean_reward          | 2.01e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4760000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.42243856 |\n",
      "|    clip_fraction        | 0.284      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.09       |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 198        |\n",
      "|    n_updates            | 39150      |\n",
      "|    policy_gradient_loss | 0.0166     |\n",
      "|    std                  | 0.124      |\n",
      "|    value_loss           | 3.78e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 613       |\n",
      "|    ep_rew_mean     | -4.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 2325      |\n",
      "|    time_elapsed    | 9479      |\n",
      "|    total_timesteps | 4761600   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 620        |\n",
      "|    ep_rew_mean          | -4.12e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 2326       |\n",
      "|    time_elapsed         | 9481       |\n",
      "|    total_timesteps      | 4763648    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.65462416 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.09       |\n",
      "|    explained_variance   | 0.981      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 80.4       |\n",
      "|    n_updates            | 39160      |\n",
      "|    policy_gradient_loss | 0.0155     |\n",
      "|    std                  | 0.124      |\n",
      "|    value_loss           | 2.76e+03   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4765000, episode_reward=-13439.64 +/- 66975.53\n",
      "Episode length: 1116.80 +/- 494.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.12e+03    |\n",
      "|    mean_reward          | -1.34e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4765000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015732922 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.1         |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.1        |\n",
      "|    n_updates            | 39170       |\n",
      "|    policy_gradient_loss | -1.95e-05   |\n",
      "|    std                  | 0.124       |\n",
      "|    value_loss           | 517         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 629       |\n",
      "|    ep_rew_mean     | -4.01e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 2327      |\n",
      "|    time_elapsed    | 9485      |\n",
      "|    total_timesteps | 4765696   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 650       |\n",
      "|    ep_rew_mean          | -4.06e+04 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 502       |\n",
      "|    iterations           | 2328      |\n",
      "|    time_elapsed         | 9487      |\n",
      "|    total_timesteps      | 4767744   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.4605919 |\n",
      "|    clip_fraction        | 0.3       |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.1       |\n",
      "|    explained_variance   | 0.549     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 4.01e+06  |\n",
      "|    n_updates            | 39180     |\n",
      "|    policy_gradient_loss | 0.0308    |\n",
      "|    std                  | 0.123     |\n",
      "|    value_loss           | 2.06e+07  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 663         |\n",
      "|    ep_rew_mean          | -3.94e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 2329        |\n",
      "|    time_elapsed         | 9489        |\n",
      "|    total_timesteps      | 4769792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021006487 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.11        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 252         |\n",
      "|    n_updates            | 39190       |\n",
      "|    policy_gradient_loss | 0.00195     |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 828         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4770000, episode_reward=7086.70 +/- 24064.47\n",
      "Episode length: 1399.80 +/- 133.70\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.4e+03     |\n",
      "|    mean_reward          | 7.09e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035966977 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.12        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 144         |\n",
      "|    n_updates            | 39200       |\n",
      "|    policy_gradient_loss | 0.0173      |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 403         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 684       |\n",
      "|    ep_rew_mean     | -3.82e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 2330      |\n",
      "|    time_elapsed    | 9494      |\n",
      "|    total_timesteps | 4771840   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 692         |\n",
      "|    ep_rew_mean          | -3.83e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 2331        |\n",
      "|    time_elapsed         | 9496        |\n",
      "|    total_timesteps      | 4773888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015556346 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.732       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.93e+05    |\n",
      "|    n_updates            | 39210       |\n",
      "|    policy_gradient_loss | -0.00468    |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 2.41e+05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4775000, episode_reward=-38594.16 +/- 82188.68\n",
      "Episode length: 1153.20 +/- 448.26\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.15e+03    |\n",
      "|    mean_reward          | -3.86e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4775000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017157871 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 39220       |\n",
      "|    policy_gradient_loss | 0.0142      |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 3.96e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 699       |\n",
      "|    ep_rew_mean     | -3.83e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 2332      |\n",
      "|    time_elapsed    | 9501      |\n",
      "|    total_timesteps | 4775936   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 733        |\n",
      "|    ep_rew_mean          | -3.68e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 502        |\n",
      "|    iterations           | 2333       |\n",
      "|    time_elapsed         | 9503       |\n",
      "|    total_timesteps      | 4777984    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.21505405 |\n",
      "|    clip_fraction        | 0.105      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.13       |\n",
      "|    explained_variance   | 0.639      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.85e+06   |\n",
      "|    n_updates            | 39230      |\n",
      "|    policy_gradient_loss | 0.0131     |\n",
      "|    std                  | 0.122      |\n",
      "|    value_loss           | 7.84e+06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4780000, episode_reward=14961.45 +/- 6993.72\n",
      "Episode length: 1367.20 +/- 28.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.37e+03    |\n",
      "|    mean_reward          | 1.5e+04     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4780000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024415268 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 98.2        |\n",
      "|    n_updates            | 39240       |\n",
      "|    policy_gradient_loss | 0.00519     |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 313         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 746       |\n",
      "|    ep_rew_mean     | -3.57e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 2334      |\n",
      "|    time_elapsed    | 9508      |\n",
      "|    total_timesteps | 4780032   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 772         |\n",
      "|    ep_rew_mean          | -3.36e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 2335        |\n",
      "|    time_elapsed         | 9510        |\n",
      "|    total_timesteps      | 4782080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028070834 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.12        |\n",
      "|    explained_variance   | 1           |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 37.8        |\n",
      "|    n_updates            | 39250       |\n",
      "|    policy_gradient_loss | 0.00674     |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 142         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 781         |\n",
      "|    ep_rew_mean          | -3.52e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 502         |\n",
      "|    iterations           | 2336        |\n",
      "|    time_elapsed         | 9511        |\n",
      "|    total_timesteps      | 4784128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017170332 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.12        |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 116         |\n",
      "|    n_updates            | 39260       |\n",
      "|    policy_gradient_loss | 0.00982     |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 9.99e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4785000, episode_reward=9448.52 +/- 13908.21\n",
      "Episode length: 1453.00 +/- 62.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.45e+03    |\n",
      "|    mean_reward          | 9.45e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4785000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010964971 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.12        |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.71e+07    |\n",
      "|    n_updates            | 39270       |\n",
      "|    policy_gradient_loss | 8.45e-05    |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 2.93e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 801       |\n",
      "|    ep_rew_mean     | -3.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 2337      |\n",
      "|    time_elapsed    | 9517      |\n",
      "|    total_timesteps | 4786176   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 817          |\n",
      "|    ep_rew_mean          | -3.48e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 2338         |\n",
      "|    time_elapsed         | 9519         |\n",
      "|    total_timesteps      | 4788224      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 9.086629e-05 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.12         |\n",
      "|    explained_variance   | 0.386        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.45e+06     |\n",
      "|    n_updates            | 39280        |\n",
      "|    policy_gradient_loss | -0.000665    |\n",
      "|    std                  | 0.123        |\n",
      "|    value_loss           | 3.45e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4790000, episode_reward=10350.29 +/- 18616.77\n",
      "Episode length: 1456.20 +/- 71.54\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.46e+03    |\n",
      "|    mean_reward          | 1.04e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007523241 |\n",
      "|    clip_fraction        | 0.0428      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.12        |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.55e+04    |\n",
      "|    n_updates            | 39290       |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 7.02e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 832       |\n",
      "|    ep_rew_mean     | -3.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 502       |\n",
      "|    iterations      | 2339      |\n",
      "|    time_elapsed    | 9524      |\n",
      "|    total_timesteps | 4790272   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 849          |\n",
      "|    ep_rew_mean          | -3.45e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 2340         |\n",
      "|    time_elapsed         | 9526         |\n",
      "|    total_timesteps      | 4792320      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0015445817 |\n",
      "|    clip_fraction        | 0.00762      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.12         |\n",
      "|    explained_variance   | 0.388        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.64e+06     |\n",
      "|    n_updates            | 39300        |\n",
      "|    policy_gradient_loss | -0.00481     |\n",
      "|    std                  | 0.123        |\n",
      "|    value_loss           | 1.53e+07     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 857         |\n",
      "|    ep_rew_mean          | -3.46e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 2341        |\n",
      "|    time_elapsed         | 9528        |\n",
      "|    total_timesteps      | 4794368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010745065 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.12        |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.5e+04     |\n",
      "|    n_updates            | 39310       |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 6.62e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4795000, episode_reward=10698.98 +/- 15516.70\n",
      "Episode length: 1405.40 +/- 62.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.41e+03    |\n",
      "|    mean_reward          | 1.07e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4795000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014715677 |\n",
      "|    clip_fraction        | 0.0507      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.582       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.32e+06    |\n",
      "|    n_updates            | 39320       |\n",
      "|    policy_gradient_loss | 0.00914     |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 8.47e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 876       |\n",
      "|    ep_rew_mean     | -3.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 2342      |\n",
      "|    time_elapsed    | 9533      |\n",
      "|    total_timesteps | 4796416   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 891         |\n",
      "|    ep_rew_mean          | -3.41e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 2343        |\n",
      "|    time_elapsed         | 9535        |\n",
      "|    total_timesteps      | 4798464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008713997 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 654         |\n",
      "|    n_updates            | 39330       |\n",
      "|    policy_gradient_loss | -0.000326   |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 5.28e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4800000, episode_reward=4071.49 +/- 17899.03\n",
      "Episode length: 1357.80 +/- 85.93\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.36e+03   |\n",
      "|    mean_reward          | 4.07e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4800000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06602377 |\n",
      "|    clip_fraction        | 0.195      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.13       |\n",
      "|    explained_variance   | 0.863      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 3.42e+04   |\n",
      "|    n_updates            | 39340      |\n",
      "|    policy_gradient_loss | 0.0193     |\n",
      "|    std                  | 0.123      |\n",
      "|    value_loss           | 1.89e+05   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 897       |\n",
      "|    ep_rew_mean     | -3.41e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 2344      |\n",
      "|    time_elapsed    | 9540      |\n",
      "|    total_timesteps | 4800512   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 910        |\n",
      "|    ep_rew_mean          | -3.39e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 2345       |\n",
      "|    time_elapsed         | 9541       |\n",
      "|    total_timesteps      | 4802560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02853213 |\n",
      "|    clip_fraction        | 0.242      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.12       |\n",
      "|    explained_variance   | 0.986      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 166        |\n",
      "|    n_updates            | 39350      |\n",
      "|    policy_gradient_loss | 0.00804    |\n",
      "|    std                  | 0.123      |\n",
      "|    value_loss           | 985        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 922         |\n",
      "|    ep_rew_mean          | -3.39e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 2346        |\n",
      "|    time_elapsed         | 9543        |\n",
      "|    total_timesteps      | 4804608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015278906 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.12        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 109         |\n",
      "|    n_updates            | 39360       |\n",
      "|    policy_gradient_loss | -0.00156    |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 3.43e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4805000, episode_reward=14413.54 +/- 5134.66\n",
      "Episode length: 1209.80 +/- 16.82\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.21e+03    |\n",
      "|    mean_reward          | 1.44e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4805000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043884747 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.617       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.83e+06    |\n",
      "|    n_updates            | 39370       |\n",
      "|    policy_gradient_loss | 0.00213     |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 3.1e+06     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 930       |\n",
      "|    ep_rew_mean     | -3.42e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 2347      |\n",
      "|    time_elapsed    | 9548      |\n",
      "|    total_timesteps | 4806656   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 944         |\n",
      "|    ep_rew_mean          | -3.26e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 2348        |\n",
      "|    time_elapsed         | 9550        |\n",
      "|    total_timesteps      | 4808704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022177022 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 111         |\n",
      "|    n_updates            | 39380       |\n",
      "|    policy_gradient_loss | 0.00572     |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 448         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4810000, episode_reward=11061.55 +/- 5505.03\n",
      "Episode length: 1217.40 +/- 13.09\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.22e+03    |\n",
      "|    mean_reward          | 1.11e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023462947 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.32e+04    |\n",
      "|    n_updates            | 39390       |\n",
      "|    policy_gradient_loss | 0.00306     |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 2.16e+06    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 951       |\n",
      "|    ep_rew_mean     | -3.26e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 2349      |\n",
      "|    time_elapsed    | 9555      |\n",
      "|    total_timesteps | 4810752   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 965         |\n",
      "|    ep_rew_mean          | -3.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 2350        |\n",
      "|    time_elapsed         | 9556        |\n",
      "|    total_timesteps      | 4812800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003104914 |\n",
      "|    clip_fraction        | 0.00601     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.54        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.77e+06    |\n",
      "|    n_updates            | 39400       |\n",
      "|    policy_gradient_loss | -0.0017     |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 5.38e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 979         |\n",
      "|    ep_rew_mean          | -3.3e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 503         |\n",
      "|    iterations           | 2351        |\n",
      "|    time_elapsed         | 9558        |\n",
      "|    total_timesteps      | 4814848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020922584 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.967       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 226         |\n",
      "|    n_updates            | 39410       |\n",
      "|    policy_gradient_loss | -0.00151    |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 5.27e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4815000, episode_reward=11536.04 +/- 7955.90\n",
      "Episode length: 1288.80 +/- 22.30\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.29e+03   |\n",
      "|    mean_reward          | 1.15e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4815000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06699939 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.13       |\n",
      "|    explained_variance   | 0.691      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.59e+06   |\n",
      "|    n_updates            | 39420      |\n",
      "|    policy_gradient_loss | 0.00543    |\n",
      "|    std                  | 0.122      |\n",
      "|    value_loss           | 3.56e+06   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 991       |\n",
      "|    ep_rew_mean     | -3.16e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 2352      |\n",
      "|    time_elapsed    | 9563      |\n",
      "|    total_timesteps | 4816896   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -3.16e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 503          |\n",
      "|    iterations           | 2353         |\n",
      "|    time_elapsed         | 9565         |\n",
      "|    total_timesteps      | 4818944      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067651574 |\n",
      "|    clip_fraction        | 0.0432       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.13         |\n",
      "|    explained_variance   | 0.681        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.26e+06     |\n",
      "|    n_updates            | 39430        |\n",
      "|    policy_gradient_loss | 0.00212      |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 2.54e+06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4820000, episode_reward=-27619.36 +/- 75981.17\n",
      "Episode length: 1061.40 +/- 466.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.06e+03    |\n",
      "|    mean_reward          | -2.76e+04   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028534183 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.6e+04     |\n",
      "|    n_updates            | 39440       |\n",
      "|    policy_gradient_loss | 0.0127      |\n",
      "|    std                  | 0.123       |\n",
      "|    value_loss           | 1.22e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.01e+03  |\n",
      "|    ep_rew_mean     | -3.17e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 2354      |\n",
      "|    time_elapsed    | 9569      |\n",
      "|    total_timesteps | 4820992   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.02e+03   |\n",
      "|    ep_rew_mean          | -3.32e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 503        |\n",
      "|    iterations           | 2355       |\n",
      "|    time_elapsed         | 9571       |\n",
      "|    total_timesteps      | 4823040    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07602198 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.13       |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 89.2       |\n",
      "|    n_updates            | 39450      |\n",
      "|    policy_gradient_loss | 0.0079     |\n",
      "|    std                  | 0.122      |\n",
      "|    value_loss           | 2.89e+04   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4825000, episode_reward=-131903.64 +/- 14082.49\n",
      "Episode length: 928.80 +/- 129.09\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 929        |\n",
      "|    mean_reward          | -1.32e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4825000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.19255926 |\n",
      "|    clip_fraction        | 0.699      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.14       |\n",
      "|    explained_variance   | 0.38       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.58e+07   |\n",
      "|    n_updates            | 39460      |\n",
      "|    policy_gradient_loss | 0.065      |\n",
      "|    std                  | 0.122      |\n",
      "|    value_loss           | 3.19e+07   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.03e+03  |\n",
      "|    ep_rew_mean     | -3.46e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 503       |\n",
      "|    iterations      | 2356      |\n",
      "|    time_elapsed    | 9575      |\n",
      "|    total_timesteps | 4825088   |\n",
      "----------------------------------\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 1.04e+03      |\n",
      "|    ep_rew_mean          | -3.59e+04     |\n",
      "| time/                   |               |\n",
      "|    fps                  | 503           |\n",
      "|    iterations           | 2357          |\n",
      "|    time_elapsed         | 9577          |\n",
      "|    total_timesteps      | 4827136       |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00042667656 |\n",
      "|    clip_fraction        | 9.77e-05      |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | 4.14          |\n",
      "|    explained_variance   | 0.4           |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 2.05e+07      |\n",
      "|    n_updates            | 39470         |\n",
      "|    policy_gradient_loss | -0.00107      |\n",
      "|    std                  | 0.122         |\n",
      "|    value_loss           | 5.63e+07      |\n",
      "-------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05e+03     |\n",
      "|    ep_rew_mean          | -3.72e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 2358         |\n",
      "|    time_elapsed         | 9579         |\n",
      "|    total_timesteps      | 4829184      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025499836 |\n",
      "|    clip_fraction        | 0.0189       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.14         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.74e+06     |\n",
      "|    n_updates            | 39480        |\n",
      "|    policy_gradient_loss | -0.00592     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 5.57e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4830000, episode_reward=-149361.84 +/- 5801.27\n",
      "Episode length: 1066.60 +/- 18.24\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.07e+03     |\n",
      "|    mean_reward          | -1.49e+05    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4830000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037881143 |\n",
      "|    clip_fraction        | 0.0357       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.14         |\n",
      "|    explained_variance   | 0.441        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.68e+07     |\n",
      "|    n_updates            | 39490        |\n",
      "|    policy_gradient_loss | -0.00615     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 6.04e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -3.73e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 2359      |\n",
      "|    time_elapsed    | 9583      |\n",
      "|    total_timesteps | 4831232   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.07e+03     |\n",
      "|    ep_rew_mean          | -4.03e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 2360         |\n",
      "|    time_elapsed         | 9585         |\n",
      "|    total_timesteps      | 4833280      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053060353 |\n",
      "|    clip_fraction        | 0.0208       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.14         |\n",
      "|    explained_variance   | 0.443        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.28e+07     |\n",
      "|    n_updates            | 39500        |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 6.04e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4835000, episode_reward=-47710.64 +/- 73853.45\n",
      "Episode length: 1316.60 +/- 207.35\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.32e+03     |\n",
      "|    mean_reward          | -4.77e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4835000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034256799 |\n",
      "|    clip_fraction        | 0.0234       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.14         |\n",
      "|    explained_variance   | 0.41         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.59e+07     |\n",
      "|    n_updates            | 39510        |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 6e+07        |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -4.13e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 2361      |\n",
      "|    time_elapsed    | 9590      |\n",
      "|    total_timesteps | 4835328   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.09e+03     |\n",
      "|    ep_rew_mean          | -4.09e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 2362         |\n",
      "|    time_elapsed         | 9592         |\n",
      "|    total_timesteps      | 4837376      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056837695 |\n",
      "|    clip_fraction        | 0.053        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.14         |\n",
      "|    explained_variance   | 0.442        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.14e+07     |\n",
      "|    n_updates            | 39520        |\n",
      "|    policy_gradient_loss | -0.00224     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 5.44e+07     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | -3.96e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 2363        |\n",
      "|    time_elapsed         | 9594        |\n",
      "|    total_timesteps      | 4839424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002496249 |\n",
      "|    clip_fraction        | 0.00952     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.14        |\n",
      "|    explained_variance   | 0.464       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.64e+06    |\n",
      "|    n_updates            | 39530       |\n",
      "|    policy_gradient_loss | -0.00353    |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 2.87e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4840000, episode_reward=-32552.69 +/- 24221.13\n",
      "Episode length: 1956.20 +/- 19.59\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.96e+03     |\n",
      "|    mean_reward          | -3.26e+04    |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035636772 |\n",
      "|    clip_fraction        | 0.0172       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.14         |\n",
      "|    explained_variance   | 0.96         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.54e+03     |\n",
      "|    n_updates            | 39540        |\n",
      "|    policy_gradient_loss | -0.00375     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 6.89e+04     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.12e+03  |\n",
      "|    ep_rew_mean     | -3.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 2364      |\n",
      "|    time_elapsed    | 9600      |\n",
      "|    total_timesteps | 4841472   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.13e+03     |\n",
      "|    ep_rew_mean          | -3.6e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 2365         |\n",
      "|    time_elapsed         | 9602         |\n",
      "|    total_timesteps      | 4843520      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032458487 |\n",
      "|    clip_fraction        | 0.0155       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.14         |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.69e+04     |\n",
      "|    n_updates            | 39550        |\n",
      "|    policy_gradient_loss | -0.00245     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 8.99e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4845000, episode_reward=15289.98 +/- 3908.51\n",
      "Episode length: 1491.40 +/- 11.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.49e+03    |\n",
      "|    mean_reward          | 1.53e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4845000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009556197 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.13        |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.34e+03    |\n",
      "|    n_updates            | 39560       |\n",
      "|    policy_gradient_loss | -0.00362    |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 2.61e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.15e+03  |\n",
      "|    ep_rew_mean     | -3.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 2366      |\n",
      "|    time_elapsed    | 9608      |\n",
      "|    total_timesteps | 4845568   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.15e+03     |\n",
      "|    ep_rew_mean          | -3.57e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 504          |\n",
      "|    iterations           | 2367         |\n",
      "|    time_elapsed         | 9610         |\n",
      "|    total_timesteps      | 4847616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077497037 |\n",
      "|    clip_fraction        | 0.0458       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.13         |\n",
      "|    explained_variance   | 0.966        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.84e+03     |\n",
      "|    n_updates            | 39570        |\n",
      "|    policy_gradient_loss | -0.00562     |\n",
      "|    std                  | 0.122        |\n",
      "|    value_loss           | 1.82e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.16e+03   |\n",
      "|    ep_rew_mean          | -3.16e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 2368       |\n",
      "|    time_elapsed         | 9611       |\n",
      "|    total_timesteps      | 4849664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00983428 |\n",
      "|    clip_fraction        | 0.0878     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.14       |\n",
      "|    explained_variance   | 0.965      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.73e+03   |\n",
      "|    n_updates            | 39580      |\n",
      "|    policy_gradient_loss | -0.00274   |\n",
      "|    std                  | 0.122      |\n",
      "|    value_loss           | 2.7e+04    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4850000, episode_reward=13393.86 +/- 4938.10\n",
      "Episode length: 1293.40 +/- 7.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.29e+03    |\n",
      "|    mean_reward          | 1.34e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015610496 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.14        |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.17e+04    |\n",
      "|    n_updates            | 39590       |\n",
      "|    policy_gradient_loss | -0.00185    |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 7.27e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.17e+03  |\n",
      "|    ep_rew_mean     | -2.98e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 2369      |\n",
      "|    time_elapsed    | 9616      |\n",
      "|    total_timesteps | 4851712   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.18e+03    |\n",
      "|    ep_rew_mean          | -2.97e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 2370        |\n",
      "|    time_elapsed         | 9618        |\n",
      "|    total_timesteps      | 4853760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003564247 |\n",
      "|    clip_fraction        | 0.0382      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.14        |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.2e+07     |\n",
      "|    n_updates            | 39600       |\n",
      "|    policy_gradient_loss | -0.000447   |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 3.13e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4855000, episode_reward=13587.18 +/- 7231.43\n",
      "Episode length: 1248.20 +/- 21.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.25e+03    |\n",
      "|    mean_reward          | 1.36e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4855000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015284364 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.14        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 733         |\n",
      "|    n_updates            | 39610       |\n",
      "|    policy_gradient_loss | 0.0112      |\n",
      "|    std                  | 0.122       |\n",
      "|    value_loss           | 4.08e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.19e+03  |\n",
      "|    ep_rew_mean     | -2.95e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 2371      |\n",
      "|    time_elapsed    | 9623      |\n",
      "|    total_timesteps | 4855808   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.21e+03   |\n",
      "|    ep_rew_mean          | -2.94e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 2372       |\n",
      "|    time_elapsed         | 9625       |\n",
      "|    total_timesteps      | 4857856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08325699 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.15       |\n",
      "|    explained_variance   | 0.987      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 268        |\n",
      "|    n_updates            | 39620      |\n",
      "|    policy_gradient_loss | 0.0136     |\n",
      "|    std                  | 0.122      |\n",
      "|    value_loss           | 1.44e+03   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.21e+03   |\n",
      "|    ep_rew_mean          | -2.95e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 2373       |\n",
      "|    time_elapsed         | 9627       |\n",
      "|    total_timesteps      | 4859904    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03590737 |\n",
      "|    clip_fraction        | 0.325      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.15       |\n",
      "|    explained_variance   | 0.869      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.24e+05   |\n",
      "|    n_updates            | 39630      |\n",
      "|    policy_gradient_loss | 0.0208     |\n",
      "|    std                  | 0.122      |\n",
      "|    value_loss           | 1.83e+05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4860000, episode_reward=13151.81 +/- 4247.72\n",
      "Episode length: 1230.60 +/- 4.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.23e+03    |\n",
      "|    mean_reward          | 1.32e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022105843 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.16        |\n",
      "|    explained_variance   | 0.994       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 59.2        |\n",
      "|    n_updates            | 39640       |\n",
      "|    policy_gradient_loss | 0.00866     |\n",
      "|    std                  | 0.121       |\n",
      "|    value_loss           | 502         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.21e+03  |\n",
      "|    ep_rew_mean     | -2.78e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 2374      |\n",
      "|    time_elapsed    | 9632      |\n",
      "|    total_timesteps | 4861952   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.21e+03    |\n",
      "|    ep_rew_mean          | -2.79e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 504         |\n",
      "|    iterations           | 2375        |\n",
      "|    time_elapsed         | 9633        |\n",
      "|    total_timesteps      | 4864000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017674092 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.16        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 95.4        |\n",
      "|    n_updates            | 39650       |\n",
      "|    policy_gradient_loss | 0.0176      |\n",
      "|    std                  | 0.121       |\n",
      "|    value_loss           | 4.01e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4865000, episode_reward=14165.47 +/- 2920.56\n",
      "Episode length: 1232.80 +/- 7.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.23e+03    |\n",
      "|    mean_reward          | 1.42e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4865000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017259147 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.16        |\n",
      "|    explained_variance   | 0.974       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 45.6        |\n",
      "|    n_updates            | 39660       |\n",
      "|    policy_gradient_loss | 0.00914     |\n",
      "|    std                  | 0.121       |\n",
      "|    value_loss           | 6.32e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.21e+03 |\n",
      "|    ep_rew_mean     | -2.8e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 504      |\n",
      "|    iterations      | 2376     |\n",
      "|    time_elapsed    | 9638     |\n",
      "|    total_timesteps | 4866048  |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.23e+03   |\n",
      "|    ep_rew_mean          | -2.6e+04   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 504        |\n",
      "|    iterations           | 2377       |\n",
      "|    time_elapsed         | 9640       |\n",
      "|    total_timesteps      | 4868096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02001363 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.16       |\n",
      "|    explained_variance   | 0.997      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 33.8       |\n",
      "|    n_updates            | 39670      |\n",
      "|    policy_gradient_loss | 0.00904    |\n",
      "|    std                  | 0.12       |\n",
      "|    value_loss           | 238        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4870000, episode_reward=15245.20 +/- 1603.77\n",
      "Episode length: 1184.80 +/- 5.38\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1.18e+03  |\n",
      "|    mean_reward          | 1.52e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4870000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0313547 |\n",
      "|    clip_fraction        | 0.266     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.18      |\n",
      "|    explained_variance   | 0.966     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 157       |\n",
      "|    n_updates            | 39680     |\n",
      "|    policy_gradient_loss | 0.00838   |\n",
      "|    std                  | 0.12      |\n",
      "|    value_loss           | 7.03e+03  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.23e+03  |\n",
      "|    ep_rew_mean     | -2.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 504       |\n",
      "|    iterations      | 2378      |\n",
      "|    time_elapsed    | 9645      |\n",
      "|    total_timesteps | 4870144   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.23e+03    |\n",
      "|    ep_rew_mean          | -2.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 2379        |\n",
      "|    time_elapsed         | 9647        |\n",
      "|    total_timesteps      | 4872192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018550094 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.18        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56.3        |\n",
      "|    n_updates            | 39690       |\n",
      "|    policy_gradient_loss | 0.00665     |\n",
      "|    std                  | 0.12        |\n",
      "|    value_loss           | 254         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.24e+03    |\n",
      "|    ep_rew_mean          | -2.32e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 2380        |\n",
      "|    time_elapsed         | 9648        |\n",
      "|    total_timesteps      | 4874240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019016087 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.18        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.1        |\n",
      "|    n_updates            | 39700       |\n",
      "|    policy_gradient_loss | 0.00983     |\n",
      "|    std                  | 0.12        |\n",
      "|    value_loss           | 137         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4875000, episode_reward=15116.51 +/- 2471.79\n",
      "Episode length: 1067.20 +/- 256.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.07e+03    |\n",
      "|    mean_reward          | 1.51e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4875000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017572576 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.19        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 56          |\n",
      "|    n_updates            | 39710       |\n",
      "|    policy_gradient_loss | -0.00351    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.24e+03  |\n",
      "|    ep_rew_mean     | -2.32e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 2381      |\n",
      "|    time_elapsed    | 9653      |\n",
      "|    total_timesteps | 4876288   |\n",
      "----------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.23e+03   |\n",
      "|    ep_rew_mean          | -2.33e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 2382       |\n",
      "|    time_elapsed         | 9655       |\n",
      "|    total_timesteps      | 4878336    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02582789 |\n",
      "|    clip_fraction        | 0.217      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.2        |\n",
      "|    explained_variance   | 0.999      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 90         |\n",
      "|    n_updates            | 39720      |\n",
      "|    policy_gradient_loss | -0.000864  |\n",
      "|    std                  | 0.119      |\n",
      "|    value_loss           | 342        |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4880000, episode_reward=14923.36 +/- 3778.58\n",
      "Episode length: 1254.40 +/- 594.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.25e+03    |\n",
      "|    mean_reward          | 1.49e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4880000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018294811 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.2         |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 63.9        |\n",
      "|    n_updates            | 39730       |\n",
      "|    policy_gradient_loss | 0.00112     |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 244         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.24e+03  |\n",
      "|    ep_rew_mean     | -2.51e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 2383      |\n",
      "|    time_elapsed    | 9660      |\n",
      "|    total_timesteps | 4880384   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.21e+03     |\n",
      "|    ep_rew_mean          | -2.73e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 505          |\n",
      "|    iterations           | 2384         |\n",
      "|    time_elapsed         | 9661         |\n",
      "|    total_timesteps      | 4882432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047878353 |\n",
      "|    clip_fraction        | 0.0545       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.2          |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.84e+07     |\n",
      "|    n_updates            | 39740        |\n",
      "|    policy_gradient_loss | -0.00104     |\n",
      "|    std                  | 0.119        |\n",
      "|    value_loss           | 5.17e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 1.2e+03    |\n",
      "|    ep_rew_mean          | -2.76e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 505        |\n",
      "|    iterations           | 2385       |\n",
      "|    time_elapsed         | 9663       |\n",
      "|    total_timesteps      | 4884480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07448881 |\n",
      "|    clip_fraction        | 0.0752     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.2        |\n",
      "|    explained_variance   | 0.374      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 1.36e+07   |\n",
      "|    n_updates            | 39750      |\n",
      "|    policy_gradient_loss | -0.00938   |\n",
      "|    std                  | 0.119      |\n",
      "|    value_loss           | 2.96e+07   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=4885000, episode_reward=1234.01 +/- 3943.99\n",
      "Episode length: 581.20 +/- 42.09\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 581        |\n",
      "|    mean_reward          | 1.23e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4885000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.28642362 |\n",
      "|    clip_fraction        | 0.152      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.2        |\n",
      "|    explained_variance   | 0.913      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 769        |\n",
      "|    n_updates            | 39760      |\n",
      "|    policy_gradient_loss | 0.00188    |\n",
      "|    std                  | 0.119      |\n",
      "|    value_loss           | 3.99e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.2e+03   |\n",
      "|    ep_rew_mean     | -2.56e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 2386      |\n",
      "|    time_elapsed    | 9666      |\n",
      "|    total_timesteps | 4886528   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -2.58e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 2387        |\n",
      "|    time_elapsed         | 9668        |\n",
      "|    total_timesteps      | 4888576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016328113 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.2         |\n",
      "|    explained_variance   | 0.99        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 275         |\n",
      "|    n_updates            | 39770       |\n",
      "|    policy_gradient_loss | -0.00195    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 1.37e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4890000, episode_reward=10157.41 +/- 137.48\n",
      "Episode length: 537.80 +/- 4.21\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 538        |\n",
      "|    mean_reward          | 1.02e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4890000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15067264 |\n",
      "|    clip_fraction        | 0.172      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.21       |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 476        |\n",
      "|    n_updates            | 39780      |\n",
      "|    policy_gradient_loss | 0.00488    |\n",
      "|    std                  | 0.119      |\n",
      "|    value_loss           | 2.82e+04   |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.18e+03  |\n",
      "|    ep_rew_mean     | -2.59e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 2388      |\n",
      "|    time_elapsed    | 9671      |\n",
      "|    total_timesteps | 4890624   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.19e+03    |\n",
      "|    ep_rew_mean          | -2.57e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 2389        |\n",
      "|    time_elapsed         | 9673        |\n",
      "|    total_timesteps      | 4892672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025283525 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.23        |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.63e+03    |\n",
      "|    n_updates            | 39790       |\n",
      "|    policy_gradient_loss | 0.00318     |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 2.76e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.17e+03    |\n",
      "|    ep_rew_mean          | -2.51e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 505         |\n",
      "|    iterations           | 2390        |\n",
      "|    time_elapsed         | 9675        |\n",
      "|    total_timesteps      | 4894720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006474808 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.23        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.91e+03    |\n",
      "|    n_updates            | 39800       |\n",
      "|    policy_gradient_loss | 0.00298     |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 6.96e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4895000, episode_reward=10045.23 +/- 4613.49\n",
      "Episode length: 813.60 +/- 513.14\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 814         |\n",
      "|    mean_reward          | 1e+04       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4895000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024401706 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.22        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 308         |\n",
      "|    n_updates            | 39810       |\n",
      "|    policy_gradient_loss | -0.00284    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 2.2e+03     |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.16e+03  |\n",
      "|    ep_rew_mean     | -2.54e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 505       |\n",
      "|    iterations      | 2391      |\n",
      "|    time_elapsed    | 9679      |\n",
      "|    total_timesteps | 4896768   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.16e+03     |\n",
      "|    ep_rew_mean          | -2.37e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 2392         |\n",
      "|    time_elapsed         | 9681         |\n",
      "|    total_timesteps      | 4898816      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030776989 |\n",
      "|    clip_fraction        | 0.0136       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.21         |\n",
      "|    explained_variance   | 0.913        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.17e+03     |\n",
      "|    n_updates            | 39820        |\n",
      "|    policy_gradient_loss | -0.00173     |\n",
      "|    std                  | 0.119        |\n",
      "|    value_loss           | 5.82e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4900000, episode_reward=4840.63 +/- 4700.45\n",
      "Episode length: 572.60 +/- 26.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 573         |\n",
      "|    mean_reward          | 4.84e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008200201 |\n",
      "|    clip_fraction        | 0.0328      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.21        |\n",
      "|    explained_variance   | 0.961       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.27e+03    |\n",
      "|    n_updates            | 39830       |\n",
      "|    policy_gradient_loss | -0.00208    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 2.04e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.15e+03  |\n",
      "|    ep_rew_mean     | -2.24e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 2393      |\n",
      "|    time_elapsed    | 9684      |\n",
      "|    total_timesteps | 4900864   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.13e+03    |\n",
      "|    ep_rew_mean          | -2.22e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 2394        |\n",
      "|    time_elapsed         | 9686        |\n",
      "|    total_timesteps      | 4902912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014788359 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.22        |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 622         |\n",
      "|    n_updates            | 39840       |\n",
      "|    policy_gradient_loss | 0.000829    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 6.79e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.12e+03    |\n",
      "|    ep_rew_mean          | -2.11e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 2395        |\n",
      "|    time_elapsed         | 9688        |\n",
      "|    total_timesteps      | 4904960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033545792 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.22        |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.33e+03    |\n",
      "|    n_updates            | 39850       |\n",
      "|    policy_gradient_loss | 0.00228     |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 1.61e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4905000, episode_reward=-145274.92 +/- 82479.55\n",
      "Episode length: 632.60 +/- 48.93\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 633         |\n",
      "|    mean_reward          | -1.45e+05   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4905000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006934937 |\n",
      "|    clip_fraction        | 0.0655      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.22        |\n",
      "|    explained_variance   | 0.979       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+03    |\n",
      "|    n_updates            | 39860       |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 6.86e+03    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.09e+03  |\n",
      "|    ep_rew_mean     | -2.07e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 2396      |\n",
      "|    time_elapsed    | 9691      |\n",
      "|    total_timesteps | 4907008   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.07e+03    |\n",
      "|    ep_rew_mean          | -2.29e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 2397        |\n",
      "|    time_elapsed         | 9693        |\n",
      "|    total_timesteps      | 4909056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004673361 |\n",
      "|    clip_fraction        | 0.0267      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.22        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.33e+06    |\n",
      "|    n_updates            | 39870       |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 2.35e+06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4910000, episode_reward=6910.53 +/- 7821.65\n",
      "Episode length: 1318.40 +/- 612.05\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.32e+03     |\n",
      "|    mean_reward          | 6.91e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4910000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0005107173 |\n",
      "|    clip_fraction        | 0.000977     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.22         |\n",
      "|    explained_variance   | 0.411        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.06e+06     |\n",
      "|    n_updates            | 39880        |\n",
      "|    policy_gradient_loss | -0.00126     |\n",
      "|    std                  | 0.119        |\n",
      "|    value_loss           | 2.81e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.04e+03  |\n",
      "|    ep_rew_mean     | -2.58e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 2398      |\n",
      "|    time_elapsed    | 9698      |\n",
      "|    total_timesteps | 4911104   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.03e+03     |\n",
      "|    ep_rew_mean          | -2.77e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 2399         |\n",
      "|    time_elapsed         | 9700         |\n",
      "|    total_timesteps      | 4913152      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010662418 |\n",
      "|    clip_fraction        | 0.00952      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.22         |\n",
      "|    explained_variance   | 0.46         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.46e+07     |\n",
      "|    n_updates            | 39890        |\n",
      "|    policy_gradient_loss | -0.00298     |\n",
      "|    std                  | 0.119        |\n",
      "|    value_loss           | 3.68e+07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4915000, episode_reward=3877.50 +/- 8650.23\n",
      "Episode length: 1072.00 +/- 613.02\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1.07e+03     |\n",
      "|    mean_reward          | 3.88e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4915000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0004812521 |\n",
      "|    clip_fraction        | 0.000684     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.22         |\n",
      "|    explained_variance   | 0.356        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.35e+07     |\n",
      "|    n_updates            | 39900        |\n",
      "|    policy_gradient_loss | -0.00131     |\n",
      "|    std                  | 0.119        |\n",
      "|    value_loss           | 3.22e+07     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.03e+03  |\n",
      "|    ep_rew_mean     | -2.74e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 2400      |\n",
      "|    time_elapsed    | 9704      |\n",
      "|    total_timesteps | 4915200   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.01e+03     |\n",
      "|    ep_rew_mean          | -2.74e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 2401         |\n",
      "|    time_elapsed         | 9706         |\n",
      "|    total_timesteps      | 4917248      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029289247 |\n",
      "|    clip_fraction        | 0.00669      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.22         |\n",
      "|    explained_variance   | 0.642        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.14e+05     |\n",
      "|    n_updates            | 39910        |\n",
      "|    policy_gradient_loss | -0.00665     |\n",
      "|    std                  | 0.119        |\n",
      "|    value_loss           | 3.84e+06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 993         |\n",
      "|    ep_rew_mean          | -2.74e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 2402        |\n",
      "|    time_elapsed         | 9708        |\n",
      "|    total_timesteps      | 4919296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002691152 |\n",
      "|    clip_fraction        | 0.0109      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.22        |\n",
      "|    explained_variance   | 0.564       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.69e+06    |\n",
      "|    n_updates            | 39920       |\n",
      "|    policy_gradient_loss | -0.00566    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 1.21e+07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4920000, episode_reward=7968.85 +/- 2671.68\n",
      "Episode length: 551.20 +/- 30.39\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 551         |\n",
      "|    mean_reward          | 7.97e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005463219 |\n",
      "|    clip_fraction        | 0.0264      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.22        |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.57e+04    |\n",
      "|    n_updates            | 39930       |\n",
      "|    policy_gradient_loss | -0.00593    |\n",
      "|    std                  | 0.119       |\n",
      "|    value_loss           | 1.16e+05    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 985       |\n",
      "|    ep_rew_mean     | -2.64e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 2403      |\n",
      "|    time_elapsed    | 9711      |\n",
      "|    total_timesteps | 4921344   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 968          |\n",
      "|    ep_rew_mean          | -2.02e+04    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 506          |\n",
      "|    iterations           | 2404         |\n",
      "|    time_elapsed         | 9713         |\n",
      "|    total_timesteps      | 4923392      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0041697975 |\n",
      "|    clip_fraction        | 0.0285       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.22         |\n",
      "|    explained_variance   | 0.687        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.72e+05     |\n",
      "|    n_updates            | 39940        |\n",
      "|    policy_gradient_loss | -0.00464     |\n",
      "|    std                  | 0.118        |\n",
      "|    value_loss           | 4.77e+06     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4925000, episode_reward=11813.71 +/- 6222.73\n",
      "Episode length: 1345.00 +/- 656.91\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.34e+03    |\n",
      "|    mean_reward          | 1.18e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4925000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013559257 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.22        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.87e+03    |\n",
      "|    n_updates            | 39950       |\n",
      "|    policy_gradient_loss | -0.000585   |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 1.46e+04    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 953       |\n",
      "|    ep_rew_mean     | -1.55e+04 |\n",
      "| time/              |           |\n",
      "|    fps             | 506       |\n",
      "|    iterations      | 2405      |\n",
      "|    time_elapsed    | 9718      |\n",
      "|    total_timesteps | 4925440   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 949         |\n",
      "|    ep_rew_mean          | -1.09e+04   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 506         |\n",
      "|    iterations           | 2406        |\n",
      "|    time_elapsed         | 9720        |\n",
      "|    total_timesteps      | 4927488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.056798603 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.23        |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 713         |\n",
      "|    n_updates            | 39960       |\n",
      "|    policy_gradient_loss | 0.01        |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 1.6e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 948         |\n",
      "|    ep_rew_mean          | -7.88e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2407        |\n",
      "|    time_elapsed         | 9722        |\n",
      "|    total_timesteps      | 4929536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012626564 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.23        |\n",
      "|    explained_variance   | 0.969       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 446         |\n",
      "|    n_updates            | 39970       |\n",
      "|    policy_gradient_loss | 0.00188     |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 7.02e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4930000, episode_reward=5466.46 +/- 4740.80\n",
      "Episode length: 535.60 +/- 15.15\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 536          |\n",
      "|    mean_reward          | 5.47e+03     |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 4930000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065343585 |\n",
      "|    clip_fraction        | 0.0944       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.24         |\n",
      "|    explained_variance   | 0.916        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 640          |\n",
      "|    n_updates            | 39980        |\n",
      "|    policy_gradient_loss | -0.00533     |\n",
      "|    std                  | 0.118        |\n",
      "|    value_loss           | 3.29e+04     |\n",
      "------------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 942       |\n",
      "|    ep_rew_mean     | -6.41e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2408      |\n",
      "|    time_elapsed    | 9725      |\n",
      "|    total_timesteps | 4931584   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 937         |\n",
      "|    ep_rew_mean          | -6.38e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2409        |\n",
      "|    time_elapsed         | 9727        |\n",
      "|    total_timesteps      | 4933632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017777003 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.24        |\n",
      "|    explained_variance   | 0.988       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.42e+03    |\n",
      "|    n_updates            | 39990       |\n",
      "|    policy_gradient_loss | 0.00118     |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 2.23e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4935000, episode_reward=8951.21 +/- 6679.15\n",
      "Episode length: 1021.80 +/- 247.52\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.02e+03    |\n",
      "|    mean_reward          | 8.95e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4935000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011874396 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.25        |\n",
      "|    explained_variance   | 0.983       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 97.3        |\n",
      "|    n_updates            | 40000       |\n",
      "|    policy_gradient_loss | -0.00349    |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 2.99e+03    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 926       |\n",
      "|    ep_rew_mean     | -6.39e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2410      |\n",
      "|    time_elapsed    | 9731      |\n",
      "|    total_timesteps | 4935680   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 919         |\n",
      "|    ep_rew_mean          | -6.36e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2411        |\n",
      "|    time_elapsed         | 9733        |\n",
      "|    total_timesteps      | 4937728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042427413 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.24        |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 303         |\n",
      "|    n_updates            | 40010       |\n",
      "|    policy_gradient_loss | 0.00124     |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 2.01e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 917         |\n",
      "|    ep_rew_mean          | -6.34e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2412        |\n",
      "|    time_elapsed         | 9735        |\n",
      "|    total_timesteps      | 4939776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014802145 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.25        |\n",
      "|    explained_variance   | 0.997       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 127         |\n",
      "|    n_updates            | 40020       |\n",
      "|    policy_gradient_loss | 0.00244     |\n",
      "|    std                  | 0.118       |\n",
      "|    value_loss           | 519         |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4940000, episode_reward=12142.58 +/- 6856.95\n",
      "Episode length: 1070.40 +/- 265.73\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.07e+03   |\n",
      "|    mean_reward          | 1.21e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4940000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01939163 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.26       |\n",
      "|    explained_variance   | 0.974      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 909        |\n",
      "|    n_updates            | 40030      |\n",
      "|    policy_gradient_loss | 0.00975    |\n",
      "|    std                  | 0.118      |\n",
      "|    value_loss           | 6.1e+03    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 916       |\n",
      "|    ep_rew_mean     | -6.46e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2413      |\n",
      "|    time_elapsed    | 9739      |\n",
      "|    total_timesteps | 4941824   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 916         |\n",
      "|    ep_rew_mean          | -4.7e+03    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2414        |\n",
      "|    time_elapsed         | 9741        |\n",
      "|    total_timesteps      | 4943872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027243152 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.26        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 68.7        |\n",
      "|    n_updates            | 40040       |\n",
      "|    policy_gradient_loss | 0.00317     |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 257         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4945000, episode_reward=7852.81 +/- 8332.90\n",
      "Episode length: 818.80 +/- 346.97\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 819         |\n",
      "|    mean_reward          | 7.85e+03    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4945000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026881706 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.27        |\n",
      "|    explained_variance   | 0.998       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 34.2        |\n",
      "|    n_updates            | 40050       |\n",
      "|    policy_gradient_loss | 0.0096      |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 194         |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 914       |\n",
      "|    ep_rew_mean     | -4.74e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2415      |\n",
      "|    time_elapsed    | 9745      |\n",
      "|    total_timesteps | 4945920   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 909         |\n",
      "|    ep_rew_mean          | -4.83e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2416        |\n",
      "|    time_elapsed         | 9747        |\n",
      "|    total_timesteps      | 4947968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015781358 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.28        |\n",
      "|    explained_variance   | 0.992       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 124         |\n",
      "|    n_updates            | 40060       |\n",
      "|    policy_gradient_loss | 0.00352     |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 1.1e+03     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4950000, episode_reward=13107.39 +/- 5022.70\n",
      "Episode length: 1834.00 +/- 17.30\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.83e+03   |\n",
      "|    mean_reward          | 1.31e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4950000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.43961748 |\n",
      "|    clip_fraction        | 0.364      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.27       |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 128        |\n",
      "|    n_updates            | 40070      |\n",
      "|    policy_gradient_loss | 0.0815     |\n",
      "|    std                  | 0.117      |\n",
      "|    value_loss           | 1.52e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 914       |\n",
      "|    ep_rew_mean     | -4.64e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2417      |\n",
      "|    time_elapsed    | 9753      |\n",
      "|    total_timesteps | 4950016   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 917          |\n",
      "|    ep_rew_mean          | -4.46e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 2418         |\n",
      "|    time_elapsed         | 9755         |\n",
      "|    total_timesteps      | 4952064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036328794 |\n",
      "|    clip_fraction        | 0.0667       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.27         |\n",
      "|    explained_variance   | 0.957        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 218          |\n",
      "|    n_updates            | 40080        |\n",
      "|    policy_gradient_loss | 0.00213      |\n",
      "|    std                  | 0.117        |\n",
      "|    value_loss           | 4.43e+03     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 924         |\n",
      "|    ep_rew_mean          | -4.37e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2419        |\n",
      "|    time_elapsed         | 9757        |\n",
      "|    total_timesteps      | 4954112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013706404 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.28        |\n",
      "|    explained_variance   | 0.999       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 71          |\n",
      "|    n_updates            | 40090       |\n",
      "|    policy_gradient_loss | 0.00698     |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 212         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4955000, episode_reward=13391.68 +/- 9280.13\n",
      "Episode length: 1627.60 +/- 538.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.63e+03    |\n",
      "|    mean_reward          | 1.34e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4955000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004399355 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.29        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 394         |\n",
      "|    n_updates            | 40100       |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 1.51e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 930       |\n",
      "|    ep_rew_mean     | -4.38e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2420      |\n",
      "|    time_elapsed    | 9762      |\n",
      "|    total_timesteps | 4956160   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 937         |\n",
      "|    ep_rew_mean          | -5.34e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2421        |\n",
      "|    time_elapsed         | 9764        |\n",
      "|    total_timesteps      | 4958208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008885636 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.29        |\n",
      "|    explained_variance   | 0.996       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 128         |\n",
      "|    n_updates            | 40110       |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 689         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4960000, episode_reward=13803.70 +/- 4356.55\n",
      "Episode length: 1952.00 +/- 10.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.95e+03    |\n",
      "|    mean_reward          | 1.38e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005894064 |\n",
      "|    clip_fraction        | 0.04        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.29        |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.94e+07    |\n",
      "|    n_updates            | 40120       |\n",
      "|    policy_gradient_loss | -0.00328    |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 1.57e+07    |\n",
      "-----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 936       |\n",
      "|    ep_rew_mean     | -5.99e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2422      |\n",
      "|    time_elapsed    | 9771      |\n",
      "|    total_timesteps | 4960256   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 943         |\n",
      "|    ep_rew_mean          | -6.96e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2423        |\n",
      "|    time_elapsed         | 9772        |\n",
      "|    total_timesteps      | 4962304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006131526 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.29        |\n",
      "|    explained_variance   | 0.598       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.23e+05    |\n",
      "|    n_updates            | 40130       |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 5.38e+06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 950         |\n",
      "|    ep_rew_mean          | -7.14e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2424        |\n",
      "|    time_elapsed         | 9774        |\n",
      "|    total_timesteps      | 4964352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013501802 |\n",
      "|    clip_fraction        | 0.0313      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.29        |\n",
      "|    explained_variance   | 0.503       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.66e+06    |\n",
      "|    n_updates            | 40140       |\n",
      "|    policy_gradient_loss | 0.000917    |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 1.4e+07     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4965000, episode_reward=-4177.73 +/- 577.02\n",
      "Episode length: 2388.60 +/- 4.63\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 2.39e+03    |\n",
      "|    mean_reward          | -4.18e+03   |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4965000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010378013 |\n",
      "|    clip_fraction        | 0.0661      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.29        |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.15e+04    |\n",
      "|    n_updates            | 40150       |\n",
      "|    policy_gradient_loss | -0.00647    |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 1.09e+06    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 959      |\n",
      "|    ep_rew_mean     | -7.1e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 2425     |\n",
      "|    time_elapsed    | 9782     |\n",
      "|    total_timesteps | 4966400  |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 953          |\n",
      "|    ep_rew_mean          | -7.28e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 2426         |\n",
      "|    time_elapsed         | 9784         |\n",
      "|    total_timesteps      | 4968448      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0036025438 |\n",
      "|    clip_fraction        | 0.00693      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.29         |\n",
      "|    explained_variance   | 0.87         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.3e+03      |\n",
      "|    n_updates            | 40160        |\n",
      "|    policy_gradient_loss | -0.00168     |\n",
      "|    std                  | 0.117        |\n",
      "|    value_loss           | 1.07e+05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4970000, episode_reward=-163811.13 +/- 5306.98\n",
      "Episode length: 2687.20 +/- 4.07\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.69e+03   |\n",
      "|    mean_reward          | -1.64e+05  |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4970000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01088387 |\n",
      "|    clip_fraction        | 0.0871     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.29       |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 676        |\n",
      "|    n_updates            | 40170      |\n",
      "|    policy_gradient_loss | 0.000516   |\n",
      "|    std                  | 0.117      |\n",
      "|    value_loss           | 1.02e+04   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 958       |\n",
      "|    ep_rew_mean     | -7.59e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2427      |\n",
      "|    time_elapsed    | 9792      |\n",
      "|    total_timesteps | 4970496   |\n",
      "----------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 972          |\n",
      "|    ep_rew_mean          | -7.97e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 2428         |\n",
      "|    time_elapsed         | 9794         |\n",
      "|    total_timesteps      | 4972544      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039078025 |\n",
      "|    clip_fraction        | 0.0266       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.29         |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.69e+03     |\n",
      "|    n_updates            | 40180        |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    std                  | 0.117        |\n",
      "|    value_loss           | 2.05e+05     |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 974          |\n",
      "|    ep_rew_mean          | -8.03e+03    |\n",
      "| time/                   |              |\n",
      "|    fps                  | 507          |\n",
      "|    iterations           | 2429         |\n",
      "|    time_elapsed         | 9796         |\n",
      "|    total_timesteps      | 4974592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0023530275 |\n",
      "|    clip_fraction        | 0.0324       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | 4.29         |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.88e+03     |\n",
      "|    n_updates            | 40190        |\n",
      "|    policy_gradient_loss | -0.00081     |\n",
      "|    std                  | 0.117        |\n",
      "|    value_loss           | 5.28e+04     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=4975000, episode_reward=9280.98 +/- 3421.94\n",
      "Episode length: 2183.80 +/- 7.70\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.18e+03   |\n",
      "|    mean_reward          | 9.28e+03   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4975000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.15568791 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.29       |\n",
      "|    explained_variance   | 0.973      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 141        |\n",
      "|    n_updates            | 40200      |\n",
      "|    policy_gradient_loss | 0.00676    |\n",
      "|    std                  | 0.117      |\n",
      "|    value_loss           | 3.03e+03   |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 985       |\n",
      "|    ep_rew_mean     | -8.04e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2430      |\n",
      "|    time_elapsed    | 9803      |\n",
      "|    total_timesteps | 4976640   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 988         |\n",
      "|    ep_rew_mean          | -4.57e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2431        |\n",
      "|    time_elapsed         | 9805        |\n",
      "|    total_timesteps      | 4978688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012000216 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.29        |\n",
      "|    explained_variance   | 0.989       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 516         |\n",
      "|    n_updates            | 40210       |\n",
      "|    policy_gradient_loss | 0.00641     |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 2.35e+03    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4980000, episode_reward=18440.26 +/- 4455.21\n",
      "Episode length: 2180.00 +/- 10.56\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.18e+03   |\n",
      "|    mean_reward          | 1.84e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4980000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01931142 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.29       |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 342        |\n",
      "|    n_updates            | 40220      |\n",
      "|    policy_gradient_loss | -0.000154  |\n",
      "|    std                  | 0.117      |\n",
      "|    value_loss           | 3.9e+04    |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1e+03     |\n",
      "|    ep_rew_mean     | -4.47e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2432      |\n",
      "|    time_elapsed    | 9812      |\n",
      "|    total_timesteps | 4980736   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.02e+03    |\n",
      "|    ep_rew_mean          | -4.28e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2433        |\n",
      "|    time_elapsed         | 9813        |\n",
      "|    total_timesteps      | 4982784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025959676 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.29        |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 83.7        |\n",
      "|    n_updates            | 40230       |\n",
      "|    policy_gradient_loss | 0.00257     |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 2.18e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.04e+03    |\n",
      "|    ep_rew_mean          | -2.39e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2434        |\n",
      "|    time_elapsed         | 9815        |\n",
      "|    total_timesteps      | 4984832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020228516 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.29        |\n",
      "|    explained_variance   | 0.993       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 154         |\n",
      "|    n_updates            | 40240       |\n",
      "|    policy_gradient_loss | 0.00989     |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 678         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=4985000, episode_reward=13681.49 +/- 2420.33\n",
      "Episode length: 2284.00 +/- 4.29\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 2.28e+03   |\n",
      "|    mean_reward          | 1.37e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 4985000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04061217 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.29       |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 820        |\n",
      "|    n_updates            | 40250      |\n",
      "|    policy_gradient_loss | 0.00643    |\n",
      "|    std                  | 0.117      |\n",
      "|    value_loss           | 4e+03      |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.04e+03  |\n",
      "|    ep_rew_mean     | -2.39e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2435      |\n",
      "|    time_elapsed    | 9822      |\n",
      "|    total_timesteps | 4986880   |\n",
      "----------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.06e+03    |\n",
      "|    ep_rew_mean          | -3.98e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2436        |\n",
      "|    time_elapsed         | 9824        |\n",
      "|    total_timesteps      | 4988928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007139803 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.29        |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.94e+03    |\n",
      "|    n_updates            | 40260       |\n",
      "|    policy_gradient_loss | 0.00256     |\n",
      "|    std                  | 0.117       |\n",
      "|    value_loss           | 2.61e+04    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=4990000, episode_reward=14362.16 +/- 4677.24\n",
      "Episode length: 2283.80 +/- 15.35\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 2.28e+03  |\n",
      "|    mean_reward          | 1.44e+04  |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 4990000   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 2.0520449 |\n",
      "|    clip_fraction        | 0.252     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.3       |\n",
      "|    explained_variance   | 0.802     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 3.44e+06  |\n",
      "|    n_updates            | 40270     |\n",
      "|    policy_gradient_loss | -0.025    |\n",
      "|    std                  | 0.116     |\n",
      "|    value_loss           | 6.36e+06  |\n",
      "---------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.07e+03  |\n",
      "|    ep_rew_mean     | -3.91e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2437      |\n",
      "|    time_elapsed    | 9832      |\n",
      "|    total_timesteps | 4990976   |\n",
      "----------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 1.09e+03  |\n",
      "|    ep_rew_mean          | -3.91e+03 |\n",
      "| time/                   |           |\n",
      "|    fps                  | 507       |\n",
      "|    iterations           | 2438      |\n",
      "|    time_elapsed         | 9833      |\n",
      "|    total_timesteps      | 4993024   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0154256 |\n",
      "|    clip_fraction        | 0.12      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | 4.31      |\n",
      "|    explained_variance   | 0.939     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 328       |\n",
      "|    n_updates            | 40280     |\n",
      "|    policy_gradient_loss | -0.00129  |\n",
      "|    std                  | 0.116     |\n",
      "|    value_loss           | 2.37e+04  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=4995000, episode_reward=14730.59 +/- 7172.30\n",
      "Episode length: 1946.80 +/- 18.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1.95e+03    |\n",
      "|    mean_reward          | 1.47e+04    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 4995000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028770505 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.31        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 107         |\n",
      "|    n_updates            | 40290       |\n",
      "|    policy_gradient_loss | 0.0205      |\n",
      "|    std                  | 0.116       |\n",
      "|    value_loss           | 1.61e+03    |\n",
      "-----------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.1e+03  |\n",
      "|    ep_rew_mean     | -3.7e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 507      |\n",
      "|    iterations      | 2439     |\n",
      "|    time_elapsed    | 9840     |\n",
      "|    total_timesteps | 4995072  |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1e+03     |\n",
      "|    ep_rew_mean          | -3.77e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2440        |\n",
      "|    time_elapsed         | 9842        |\n",
      "|    total_timesteps      | 4997120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021477018 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.32        |\n",
      "|    explained_variance   | 0.991       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 150         |\n",
      "|    n_updates            | 40300       |\n",
      "|    policy_gradient_loss | 0.0102      |\n",
      "|    std                  | 0.116       |\n",
      "|    value_loss           | 842         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.11e+03    |\n",
      "|    ep_rew_mean          | -3.59e+03   |\n",
      "| time/                   |             |\n",
      "|    fps                  | 507         |\n",
      "|    iterations           | 2441        |\n",
      "|    time_elapsed         | 9844        |\n",
      "|    total_timesteps      | 4999168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030663934 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | 4.32        |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 264         |\n",
      "|    n_updates            | 40310       |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    std                  | 0.116       |\n",
      "|    value_loss           | 1.98e+04    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5000000, episode_reward=10748.31 +/- 11972.54\n",
      "Episode length: 1203.80 +/- 543.47\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1.2e+03    |\n",
      "|    mean_reward          | 1.07e+04   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 5000000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12098316 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | 4.32       |\n",
      "|    explained_variance   | 0.992      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 68.8       |\n",
      "|    n_updates            | 40320      |\n",
      "|    policy_gradient_loss | 0.0101     |\n",
      "|    std                  | 0.116      |\n",
      "|    value_loss           | 212        |\n",
      "----------------------------------------\n",
      "----------------------------------\n",
      "| rollout/           |           |\n",
      "|    ep_len_mean     | 1.11e+03  |\n",
      "|    ep_rew_mean     | -3.68e+03 |\n",
      "| time/              |           |\n",
      "|    fps             | 507       |\n",
      "|    iterations      | 2442      |\n",
      "|    time_elapsed    | 9848      |\n",
      "|    total_timesteps | 5001216   |\n",
      "----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7f672ecbba20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps = 5_000_000, callback = eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path + '/ppo_jl_ramp_jump_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(\"/home/bmsit/Ascento/jointed_limited/Training/model_for_demo.zip\", env = env)\n",
    "\n",
    "# #JL_10 -> STAYS AT SET POINT BUT KEEPS ON SPININING VERY VERY FAST\n",
    "# #JL_10_Best -> spins a bit slowly\n",
    "\n",
    "# # JL_11 -> MOVES AROUND, ALSO BENDS 1 LEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes = 30, render = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n",
      "0.0027205056169279235\n",
      "0.061892679672144145\n",
      "-0.0014618395349485572\n",
      "-0.022755850020547894\n",
      "-0.11074096444044024\n",
      "-0.24960497530298664\n",
      "-0.21071528063906653\n",
      "-0.28185414357145544\n",
      "-0.2715465513174858\n",
      "-0.36116301233516757\n",
      "-0.42051702656247036\n",
      "-0.55781435285248\n",
      "-0.5848806589245609\n",
      "-0.6348008657746133\n",
      "-0.6931292715177931\n",
      "-0.5901485975080423\n",
      "-0.5671310217927847\n",
      "-0.49648345758627993\n",
      "-0.45726456003652644\n",
      "-0.4407296893921376\n",
      "-0.27839652305171925\n",
      "-0.21953372053937414\n",
      "-0.34144772002729445\n",
      "-0.4093563820686873\n",
      "-0.4086652454696522\n",
      "-0.35118252083838264\n",
      "-0.2937321569441572\n",
      "-0.2396395671938507\n",
      "-0.451646916246073\n",
      "-0.6305277233585526\n",
      "-0.7518943482464934\n",
      "-0.8457809667428555\n",
      "-0.9259356949854596\n",
      "-0.997720253250344\n",
      "-1.0652839608134106\n",
      "-1.152763716094218\n",
      "-1.1516769033400722\n",
      "-1.1701818361400511\n",
      "-1.1692317836009702\n",
      "-1.1705263045936312\n",
      "-1.0515125983120819\n",
      "-0.9824797474376862\n",
      "-1.0189941234987403\n",
      "-0.9579473999414176\n",
      "-0.8437486657312673\n",
      "-0.8459905647859978\n",
      "-0.8285350752165163\n",
      "-0.890782735872552\n",
      "-0.8297898400877983\n",
      "-0.7696073004100701\n",
      "-0.7815652764697699\n",
      "-0.7891204729169534\n",
      "-0.7270809022572053\n",
      "-0.7572003876901434\n",
      "-0.7686810642726204\n",
      "-0.7573134040543595\n",
      "-0.7849561270755078\n",
      "-0.7717718279999001\n",
      "-0.729048892136137\n",
      "-0.6648557775093622\n",
      "-0.5750751849927521\n",
      "-0.5246242890374683\n",
      "-0.5296613551957338\n",
      "-0.5078539174528632\n",
      "-0.4505839483154863\n",
      "-0.43042131973368286\n",
      "-0.35611509621495513\n",
      "-0.3473615139937817\n",
      "-0.36614378525055435\n",
      "-0.32855767590889007\n",
      "-0.3230604633319369\n",
      "-0.2811408125839081\n",
      "-0.24027194620530676\n",
      "-0.23164140380578171\n",
      "-0.0036977442011509095\n",
      "-0.06124661286746219\n",
      "-0.006773679643021471\n",
      "0.144852371487913\n",
      "0.019315120962262747\n",
      "0.06734676540283997\n",
      "0.06611304901730629\n",
      "-0.039878781480496756\n",
      "0.023778705668334225\n",
      "0.025266328425717067\n",
      "-0.08587548586055048\n",
      "-0.04583799405832116\n",
      "-0.04789706344475475\n",
      "-0.06532777002723765\n",
      "-0.12723678355222892\n",
      "-0.09039423741515673\n",
      "-0.15058161416166535\n",
      "-0.05609398539494885\n",
      "-0.1673742238321574\n",
      "-0.09495998990166188\n",
      "-0.17596176644912076\n",
      "-0.23007353517086193\n",
      "-0.08429388692709844\n",
      "-0.23213764383269941\n",
      "-0.10634396656861445\n",
      "-0.14899035402799718\n",
      "-0.12586230610351634\n",
      "-0.14524118677675782\n",
      "-0.1113462930777025\n",
      "-0.14219352969013807\n",
      "-0.129646433080627\n",
      "-0.07893525839254051\n",
      "-0.056007510434838106\n",
      "-0.09811561728519358\n",
      "-0.19160709788346753\n",
      "-0.0992164469227466\n",
      "-0.15454610698378607\n",
      "-0.1755939211954357\n",
      "-0.1804587476864522\n",
      "-0.200774899941648\n",
      "-0.13657977035859425\n",
      "-0.16809981499350257\n",
      "-0.13296395269617384\n",
      "-0.1089338809481403\n",
      "-0.04083543968758281\n",
      "-0.16290805348526954\n",
      "-0.1374764656887321\n",
      "-0.17709387803965385\n",
      "-0.25746737701912575\n",
      "-0.13127681873985453\n",
      "-0.1543934635658351\n",
      "-0.1452468001273255\n",
      "-0.04947519803756888\n",
      "-0.08679690081144048\n",
      "-0.10543989725670065\n",
      "-0.16324800129978725\n",
      "-0.2507188648113363\n",
      "-0.2101157993160955\n",
      "-0.20333932550460176\n",
      "-0.30669035892392377\n",
      "-0.2526848689824558\n",
      "-0.16947354634322526\n",
      "-0.16390017124270992\n",
      "-0.2251655878579947\n",
      "-0.25034907160605774\n",
      "-0.1499804754061405\n",
      "-0.21567871306869368\n",
      "-0.18149898951591614\n",
      "-0.16585239614320132\n",
      "-0.15571710332148544\n",
      "-0.18828314864245607\n",
      "-0.24580386843626723\n",
      "-0.2066913110455624\n",
      "-0.27552876247304536\n",
      "-0.22631558155109427\n",
      "-0.2103699604894523\n",
      "-0.2742484900125766\n",
      "-0.30679037301858114\n",
      "-0.3980926485845444\n",
      "-0.32689821714516665\n",
      "-0.20696403115696685\n",
      "-0.40607701730271484\n",
      "-0.20547738498534207\n",
      "-0.287981538950282\n",
      "-0.3142706383048619\n",
      "-0.3101277686540607\n",
      "-0.2901505610146561\n",
      "-0.33222024489026775\n",
      "-0.3270330161734498\n",
      "-0.3131313662655047\n",
      "-0.4230943380860004\n",
      "-0.30063265678843243\n",
      "-0.3793005774913475\n",
      "-0.3373777094110357\n",
      "-0.3003398476181758\n",
      "-0.4971662399891183\n",
      "-0.3742731440545597\n",
      "-0.35520045943086065\n",
      "-0.42187548841544054\n",
      "-0.4737728285542891\n",
      "-0.4650870417165935\n",
      "-0.4648679423686748\n",
      "-0.4637657780612669\n",
      "-0.4599961199987921\n",
      "-0.3237543896776526\n",
      "-0.39311870272563565\n",
      "-0.325323882031741\n",
      "-0.4827159335864652\n",
      "-0.341402394944714\n",
      "-0.3479165134657972\n",
      "-0.4312342956324767\n",
      "-0.44847047477052276\n",
      "-0.45327699790340614\n",
      "-0.3961187703150456\n",
      "-0.4281327909035973\n",
      "-0.5068972938402718\n",
      "-0.4052504384677291\n",
      "-0.46271220249905\n",
      "-0.5941105779599317\n",
      "-0.6573419630556582\n",
      "-0.5011156627636298\n",
      "-0.5591983949776352\n",
      "-0.4306230507842372\n",
      "-0.5850200109191427\n",
      "-0.4965831927796727\n",
      "-0.47298779699015625\n",
      "-0.49876497909119505\n",
      "-0.4424428716614032\n",
      "-0.46759209551290726\n",
      "-0.3873348953999364\n",
      "-0.42241020704315846\n",
      "-0.5054977647423684\n",
      "-0.4577706572440258\n",
      "-0.4200900024067\n",
      "-0.37701032125028255\n",
      "-0.44057610205728576\n",
      "-0.36920495333957803\n",
      "-0.42763104567665644\n",
      "-0.4296776986839911\n",
      "-0.5220836941655531\n",
      "-0.44112046760392376\n",
      "-0.36611911572798694\n",
      "-0.3865524024529626\n",
      "-0.4757737919406038\n",
      "-0.4541658984849605\n",
      "-0.5116730333998619\n",
      "-0.5740120234263686\n",
      "-0.5287094995324852\n",
      "-0.52447514053173\n",
      "-0.5482897013415692\n",
      "-0.44301748843637573\n",
      "-0.5294706507371457\n",
      "-0.4847885485876205\n",
      "-0.45598889740597265\n",
      "-0.4384584268962027\n",
      "-0.5351321908320267\n",
      "-0.5904611343465713\n",
      "-0.6436853990682714\n",
      "-0.722668839628366\n",
      "-0.6942709562183579\n",
      "-0.6991136711211976\n",
      "-0.5552991061509173\n",
      "-0.5026760269551774\n",
      "-0.5647343333154116\n",
      "-0.6331794116355677\n",
      "-0.4963980627024735\n",
      "-0.5770171959402081\n",
      "-0.6446719007341765\n",
      "-0.6511437489745463\n",
      "-0.5113566007841357\n",
      "-0.5921660693405703\n",
      "-0.5960318079568155\n",
      "-0.6209739727990303\n",
      "-0.5860669103089667\n",
      "-0.6261856377940453\n",
      "-0.6386850995776466\n",
      "-0.6182925261697336\n",
      "-0.5918670393695623\n",
      "-0.5924370384254143\n",
      "-0.646063277524984\n",
      "-0.595649119436362\n",
      "-0.5862464204278419\n",
      "-0.6954644184702345\n",
      "-0.684314154921146\n",
      "-0.689580716329323\n",
      "-0.6565624964735192\n",
      "-0.6716639999446645\n",
      "-0.5914282862851296\n",
      "-0.6341601030087729\n",
      "-0.7321329528493639\n",
      "-0.6902243450018729\n",
      "-0.7987534405534518\n",
      "-0.7712545682292488\n",
      "-0.7859827998924998\n",
      "-0.7627431521969157\n",
      "-0.6781738509855599\n",
      "-0.8375301170136927\n",
      "-0.7176834205725534\n",
      "-0.6808707588765055\n",
      "-0.7262439210599636\n",
      "-0.7279582792391579\n",
      "-0.7167025969502803\n",
      "-0.685353034112936\n",
      "-0.7472972040432708\n",
      "-0.7018482413319463\n",
      "-0.6827220961731496\n",
      "-0.7026969799939399\n",
      "-0.7623783116425066\n",
      "-0.7418953726365813\n",
      "-0.664447659523767\n",
      "-0.6850434071249908\n",
      "-0.7235632734896619\n",
      "-0.6912640384775421\n",
      "-0.7387616143965918\n",
      "-0.7023788874768925\n",
      "-0.7850755612287345\n",
      "-0.6365909643913619\n",
      "-0.727092086412373\n",
      "-0.7395997502963271\n",
      "-0.8070160290952416\n",
      "-0.729461506378421\n",
      "-0.8352572639901455\n",
      "-0.756179250913589\n",
      "-0.7608018358293901\n",
      "-0.8417167192116326\n",
      "-0.8358442484091586\n",
      "-0.7676930717158098\n",
      "-0.7767112681746273\n",
      "-0.7327383055997503\n",
      "-0.6695544738844768\n",
      "-0.7319627233779413\n",
      "-0.7232649145216241\n",
      "-0.7685263290062628\n",
      "-0.8041847575041626\n",
      "-0.7025232833008482\n",
      "-0.7376403299973926\n",
      "-0.8273032593543311\n",
      "-0.7498662150091179\n",
      "-0.6670969573862503\n",
      "-0.7875687635324105\n",
      "-0.773488969421316\n",
      "-0.8029484007343004\n",
      "-0.8325423384031961\n",
      "-0.8318187076987761\n",
      "-0.8635771899843445\n",
      "-0.7915987455362888\n",
      "-0.7373488879838747\n",
      "-0.8227766923294247\n",
      "-0.8026565203731691\n",
      "-0.731371791042583\n",
      "-0.6997862284514963\n",
      "-0.6832114383224467\n",
      "-0.7380222135554936\n",
      "-0.680530161079494\n",
      "-0.7240081819687559\n",
      "-0.7964778866741398\n",
      "-0.7384578944067857\n",
      "-0.6422793898232985\n",
      "-0.7879495784287953\n",
      "-0.7959333348554127\n",
      "-0.7695092143325921\n",
      "-0.8191386026136288\n",
      "-0.7525356565599801\n",
      "-0.8799806203055192\n",
      "-0.8380398173023824\n",
      "-0.801881928619794\n",
      "-0.8513109316631547\n",
      "-0.7305423906359888\n",
      "-0.8207226874464415\n",
      "-0.843581453683389\n",
      "-0.8731522409143632\n",
      "-0.8320851394752427\n",
      "-0.8407375565973094\n",
      "-0.8781589655629283\n",
      "-0.8106683803989033\n",
      "-0.7819806435825161\n",
      "-0.7323872776214169\n",
      "-0.7711795472485159\n",
      "-0.7977080720868704\n",
      "-0.7940909441578505\n",
      "-0.8359781672839044\n",
      "-0.8847428074007587\n",
      "-0.7632529717024353\n",
      "-0.8316762949807321\n",
      "-0.8530190369970784\n",
      "-0.8100446245182981\n",
      "-0.8555167771741988\n",
      "-0.9165960680837997\n",
      "-0.8750910750760948\n",
      "-0.9466791944275783\n",
      "-0.9236887612519123\n",
      "-0.9498258341496137\n",
      "-0.9272616869847958\n",
      "-0.9692864297076547\n",
      "-0.8843546684997172\n",
      "-0.8237448085453601\n",
      "-0.8866724385586747\n",
      "-0.8525906968750682\n",
      "-0.8966838928535494\n",
      "-0.8538484574026897\n",
      "-0.8716064583504908\n",
      "-0.8831668517873644\n",
      "-0.9868462063270635\n",
      "-0.8257308716477196\n",
      "-0.908291842718119\n",
      "-0.8330347443605399\n",
      "-0.9342443240892326\n",
      "-0.8265937933148503\n",
      "-0.7526801016262888\n",
      "-0.8469815594878176\n",
      "-0.8485703145780457\n",
      "-0.8100302169213893\n",
      "-0.8679847762892708\n",
      "-0.8743243058635167\n",
      "-0.7999115408483525\n",
      "-0.8793202790861074\n",
      "-0.9004412642210304\n",
      "-0.9455663704494188\n",
      "-0.8921939540144271\n",
      "-0.9527771581397437\n",
      "-0.8567519771865911\n",
      "-0.9087602627863054\n",
      "-0.8504274668285132\n",
      "-0.811920396756593\n",
      "-0.8648891130002185\n",
      "-0.8398989685277983\n",
      "-0.778285233362449\n",
      "-0.9052866130416588\n",
      "-0.8858596403362731\n",
      "-0.8841839645866367\n",
      "-0.8861000296435937\n",
      "-0.8308302932840572\n",
      "-0.834691125835359\n",
      "-0.8885121880097576\n",
      "-0.908362446354687\n",
      "-0.8577582314122567\n",
      "-0.8695382173648694\n",
      "-0.8930834535004132\n",
      "-0.7626910676758718\n",
      "-0.8286691076572891\n",
      "-0.8024592282090262\n",
      "-0.9483382576624911\n",
      "-0.8707030991303495\n",
      "-0.9005564683199659\n",
      "-0.8338262229888521\n",
      "-0.7437398223934577\n",
      "-0.8626489496975821\n",
      "-0.924418045924547\n",
      "-0.9460069209363486\n",
      "-0.9530706502907033\n",
      "-0.8896667781487625\n",
      "-0.957423734048572\n",
      "-0.845948643788755\n",
      "-0.8854783374712671\n",
      "-0.8684151348659583\n",
      "-0.98870728622312\n",
      "-0.9359042559116374\n",
      "-0.9472870133099793\n",
      "-0.92207035858151\n",
      "-0.8576238613475736\n",
      "-0.8616388475488213\n",
      "-1.0300404765372775\n",
      "-0.9847589439675619\n",
      "-0.8483338081412068\n",
      "-0.7927837951343516\n",
      "-0.8414320760955818\n",
      "-0.9248061622248321\n",
      "-0.9063703971921426\n",
      "-0.7807602208649835\n",
      "-0.9403656878033265\n",
      "-0.8848720842866087\n",
      "-0.8476409841030454\n",
      "-0.8703154501072934\n",
      "-0.9015945106817529\n",
      "-0.9383072137439984\n",
      "-0.9882243121696987\n",
      "-0.9492445379540474\n",
      "-0.9066872214669499\n",
      "-0.8139848833484876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8517727944887897\n",
      "-0.8970680826424156\n",
      "-0.78949749130292\n",
      "-0.7740223557714624\n",
      "-0.7988369360621074\n",
      "-0.745621857529253\n",
      "-0.8915357223694081\n",
      "-0.7816553791818867\n",
      "-0.9460512364362217\n",
      "-0.9422459620060387\n",
      "-0.8761900208122415\n",
      "-0.9715782499173045\n",
      "-0.9324131643459141\n",
      "-0.9262413688115186\n",
      "-0.846099907090248\n",
      "-0.802269743378447\n",
      "-0.8806776779351058\n",
      "-0.944805762635891\n",
      "-0.8897535394327969\n",
      "-1.033794063488422\n",
      "-0.9251417217291011\n",
      "-0.8269750289197734\n",
      "-0.7269334983659936\n",
      "-0.7897761637214537\n",
      "-0.8771983839075159\n",
      "-0.8998269351555993\n",
      "-0.8988728346252172\n",
      "-0.82371155954393\n",
      "-0.808174602245399\n",
      "-0.8117420225362569\n",
      "-0.793711303487018\n",
      "-0.9438399545501578\n",
      "-0.9444649536722989\n",
      "-0.8569724989241067\n",
      "-0.9187538345214501\n",
      "-0.843965355212476\n",
      "-0.78336271263151\n",
      "-0.9421772196773102\n",
      "-0.894631581385184\n",
      "-0.9469903861530529\n",
      "-0.9074772953858634\n",
      "-0.8167629247882995\n",
      "-0.8608148154133732\n",
      "-0.8587021070281172\n",
      "-1.0096181710190806\n",
      "-0.8571598028250997\n",
      "-0.8502468865604522\n",
      "-0.8899621485578408\n",
      "-0.8622110061373376\n",
      "-0.9854713178098895\n",
      "-0.876396538204377\n",
      "-0.8568346137595172\n",
      "-0.9334403040349746\n",
      "-0.8690707506497931\n",
      "-0.9755383342522372\n",
      "-0.8607456161796903\n",
      "-0.7887627545872855\n",
      "-0.8791327982397618\n",
      "-0.8521923674699456\n",
      "-0.8442914344210335\n",
      "-0.9041929519634997\n",
      "-0.84843698290714\n",
      "-0.8608220466357546\n",
      "-0.7607541173161242\n",
      "-0.8837879677111435\n",
      "-0.854969592394328\n",
      "-0.8354521529575297\n",
      "-0.8156830796252331\n",
      "-0.7768967110491096\n",
      "-0.8659709029888638\n",
      "-0.8181766199168253\n",
      "-0.7995630294477112\n",
      "-0.8208774670736763\n",
      "-0.8227197227163319\n",
      "-0.8663434259009505\n",
      "-0.8359854577326762\n",
      "-0.811669179282778\n",
      "-0.9339903651205529\n",
      "-0.9137375737445657\n",
      "-0.8903690563009001\n",
      "-0.848938127384905\n",
      "-0.7617812134183852\n",
      "-0.8192643152339989\n",
      "-0.8325169334041689\n",
      "-0.8251097808753096\n",
      "-0.7511649731086527\n",
      "-0.8012135528220123\n",
      "-0.8580325761817635\n",
      "-0.928547890223973\n",
      "-0.8273201747792444\n",
      "-0.8720457328389456\n",
      "-0.8833638236151083\n",
      "-0.8682141145504942\n",
      "-0.7952162089460578\n",
      "-0.9073346901823114\n",
      "-0.7943950220103678\n",
      "-0.7067160908467682\n",
      "-0.7477776772453144\n",
      "-0.7613272878799905\n",
      "-0.7959687093787754\n",
      "-0.8565570406640095\n",
      "-0.8103409735906452\n",
      "-0.7718372898789218\n",
      "-0.6752414168584314\n",
      "-0.7824104151100366\n",
      "-0.8492876381250324\n",
      "-0.7295089876143016\n",
      "-0.8014510037780318\n",
      "-0.7032314191474016\n",
      "-0.715437288436885\n",
      "-0.7137996586614822\n",
      "-0.7190336884655636\n",
      "-0.718149838108078\n",
      "-0.8461695039368368\n",
      "-0.8782246931637449\n",
      "-0.8512366175583613\n",
      "-0.867154325671308\n",
      "-0.723125274883605\n",
      "-0.8263843728174156\n",
      "-0.7800551545165295\n",
      "-0.8379306984770316\n",
      "-0.7499378504915518\n",
      "-0.8769934984998592\n",
      "-0.8677936768619213\n",
      "-0.8108159309663399\n",
      "-0.8453803469759995\n",
      "-0.8384945212772957\n",
      "-0.8787000467854931\n",
      "-0.8684044772383498\n",
      "-0.7812540529007366\n",
      "-0.7767600015696821\n",
      "-0.7857596473555648\n",
      "-0.837472087390798\n",
      "-0.761626799165491\n",
      "-0.8097815238281445\n",
      "-0.8137470289128087\n",
      "-0.80685160154179\n",
      "-0.687886837864746\n",
      "-0.8265783532766577\n",
      "-0.805637789196756\n",
      "-0.7286469086849594\n",
      "-0.7156164672530843\n",
      "-0.771023221455895\n",
      "-0.7384175916729983\n",
      "-0.7692515032502849\n",
      "-0.7092589379052918\n",
      "-0.6995807164090836\n",
      "-0.7170129633200509\n",
      "-0.7604187944958849\n",
      "-0.8367446911170323\n",
      "-0.725950368815462\n",
      "-0.74883485259297\n",
      "-0.7585183545905703\n",
      "-0.6988469883970473\n",
      "-0.7388168766882189\n",
      "-0.7865106714384997\n",
      "-0.8891263694842121\n",
      "-0.7900476904278585\n",
      "-0.8354593899070095\n",
      "-0.7362048097227155\n",
      "-0.8601557518891618\n",
      "-0.7960179689147481\n",
      "-0.7880179864916999\n",
      "-0.7474300064878432\n",
      "-0.7654217228996963\n",
      "-0.729807420139314\n",
      "-0.8318214375145581\n",
      "-0.8471533498250476\n",
      "-0.7465138951226781\n",
      "-0.8155175593653253\n",
      "-0.7422391834964679\n",
      "-0.7300783762562181\n",
      "-0.7434502426193478\n",
      "-0.6784252376076748\n",
      "-0.7690715328931763\n",
      "-0.7356282287624895\n",
      "-0.7040270002738168\n",
      "-0.7415698900316339\n",
      "-0.7144935048253961\n",
      "-0.7758730398388947\n",
      "-0.7231366047231435\n",
      "-0.7258513653717421\n",
      "-0.7335784776850424\n",
      "-0.6929676435618898\n",
      "-0.7635513828953919\n",
      "-0.7405513162410198\n",
      "-0.7048489554352656\n",
      "-0.7235632672449379\n",
      "-0.6295059963518048\n",
      "-0.6907868688729202\n",
      "-0.7794838347250272\n",
      "-0.749889176692105\n",
      "-0.6789753668850337\n",
      "-0.6157069891825577\n",
      "-0.5925366127186992\n",
      "-0.6131629872115438\n",
      "-0.6170029072095693\n",
      "-0.665333500256629\n",
      "-0.6408484082560593\n",
      "-0.7888650361393102\n",
      "-0.6968936396779315\n",
      "-0.6895485264539442\n",
      "-0.6555272706296454\n",
      "-0.5966351041852871\n",
      "-0.6324223270634795\n",
      "-0.7094254339397211\n",
      "-0.6273413992875881\n",
      "-0.6368189271036648\n",
      "-0.5671434780071803\n",
      "-0.623500100056865\n",
      "-0.6816866070140466\n",
      "-0.6800842103202639\n",
      "-0.6774550036279812\n",
      "-0.6813148590038136\n",
      "-0.615227381725362\n",
      "-0.8023593250911853\n",
      "-0.7194792869967804\n",
      "-0.7052717717387691\n",
      "-0.7387845378299966\n",
      "-0.6186248698648026\n",
      "-0.7437892033709614\n",
      "-0.6956821832666058\n",
      "-0.6338309779163299\n",
      "-0.6844529849137717\n",
      "-0.7008020693710865\n",
      "-0.6633339813407112\n",
      "-0.7619739155399334\n",
      "-0.8688297930549278\n",
      "-0.8822781004875336\n",
      "-0.8164404932056196\n",
      "-0.6840739311756981\n",
      "-0.6522962645427971\n",
      "-0.668641210434679\n",
      "-0.638241937268112\n",
      "-0.5742166345603169\n",
      "-0.6685737669355585\n",
      "-0.6756998209423212\n",
      "-0.6132773160439138\n",
      "-0.6784491686995633\n",
      "-0.6849908452786456\n",
      "-0.6760483554383736\n",
      "-0.7504867964586075\n",
      "-0.5631523330412813\n",
      "-0.560360601183404\n",
      "-0.5902046720364514\n",
      "-0.6578391940797371\n",
      "-0.667838944753332\n",
      "-0.6694612233616458\n",
      "-0.7420520637554288\n",
      "-0.7266034745322416\n",
      "-0.6323716927811031\n",
      "-0.6633330028703154\n",
      "-0.7073416749842351\n",
      "-0.6716425731981037\n",
      "-0.6574863128140225\n",
      "-0.681048566090485\n",
      "-0.5866264819581779\n",
      "-0.6821020672890542\n",
      "-0.6689204486260977\n",
      "-0.7143070389863219\n",
      "-0.6871606776554592\n",
      "-0.7493392620736972\n",
      "-0.7429563413671456\n",
      "-0.7010253712229604\n",
      "-0.6302763414909605\n",
      "-0.673537765596415\n",
      "-0.6539605273848085\n",
      "-0.6870811198450262\n",
      "-0.5698046819161474\n",
      "-0.7076401720676593\n",
      "-0.6579111243718856\n",
      "-0.8210316456998112\n",
      "-0.7831591568919181\n",
      "-0.7744829773319327\n",
      "-0.8341811528279464\n",
      "-0.7483922502984235\n",
      "-0.6957249960273982\n",
      "-0.586186870982573\n",
      "-0.5799623043048019\n",
      "-0.62574825895145\n",
      "-0.5205478593162081\n",
      "-0.5328939942889378\n",
      "-0.6663793445263261\n",
      "-0.676056028561658\n",
      "-0.6742964829594469\n",
      "-0.811148372881553\n",
      "-0.7277276951536656\n",
      "-0.7402801714217646\n",
      "-0.6730428945057622\n",
      "-0.7604562832107962\n",
      "-0.6382631209173985\n",
      "-0.6603966197247517\n",
      "-0.6359589215784057\n",
      "-0.600123604502018\n",
      "-0.7312452106590919\n",
      "-0.7020977581053423\n",
      "-0.6857665711377608\n",
      "-0.6885221892435519\n",
      "-0.666834231385643\n",
      "-0.6367108247578467\n",
      "-0.6741026507376704\n",
      "-0.6850909349883174\n",
      "-0.6005847687503488\n",
      "-0.5534445603486883\n",
      "-0.5966259538042752\n",
      "-0.5950508633451214\n",
      "-0.6752573721153764\n",
      "-0.6519620623108083\n",
      "-0.6947426099515202\n",
      "-0.6421918234230687\n",
      "-0.6412921062350605\n",
      "-0.5183137425205355\n",
      "-0.5845062960313842\n",
      "-0.7204404986057857\n",
      "-0.6334657421243565\n",
      "-0.6595299215249582\n",
      "-0.6962619708488814\n",
      "-0.6317864595755238\n",
      "-0.5813269092236575\n",
      "-0.6222160227636712\n",
      "-0.6494825435032467\n",
      "-0.665009112573346\n",
      "-0.7133254797186638\n",
      "-0.686357998450193\n",
      "-0.7231273286727748\n",
      "-0.6511965722034339\n",
      "-0.6066631833174598\n",
      "-0.631275949245451\n",
      "-0.6397022209341787\n",
      "-0.6411718041280642\n",
      "-0.7282354993164366\n",
      "-0.6570119534783538\n",
      "-0.6597996408109079\n",
      "-0.6439760457405703\n",
      "-0.7107235372172324\n",
      "-0.7248855133076926\n",
      "-0.717087356254414\n",
      "-0.6733326649970841\n",
      "-0.6069141351416888\n",
      "-0.6966453568292754\n",
      "-0.6626281625790507\n",
      "-0.6572209803624027\n",
      "-0.5964290862876076\n",
      "-0.6714551865475749\n",
      "-0.6893381016502109\n",
      "-0.7383955481619408\n",
      "-0.6134977642151028\n",
      "-0.6635280484241025\n",
      "-0.6573617414497477\n",
      "-0.5828302162129424\n",
      "-0.5693292968717705\n",
      "-0.5327699228872673\n",
      "-0.6072140383932843\n",
      "-0.5660634791143083\n",
      "-0.5557057241054867\n",
      "-0.5618456163440804\n",
      "-0.5331336314908668\n",
      "-0.5551187932794329\n",
      "-0.5446817758296847\n",
      "-0.5378044775498232\n",
      "-0.6505280370077158\n",
      "-0.5614777050553781\n",
      "-0.5309753681852875\n",
      "-0.5588436613325893\n",
      "-0.6089234430713222\n",
      "-0.621350293853523\n",
      "-0.6454505677831402\n",
      "-0.5245962784194007\n",
      "-0.639054045001038\n",
      "-0.6658733303666768\n",
      "-0.6067415944778174\n",
      "-0.5921887807764271\n",
      "-0.583339743097668\n",
      "-0.5078903771458622\n",
      "-0.5639012996361163\n",
      "-0.6796778926790893\n",
      "-0.6554248489940022\n",
      "-0.6446814882022242\n",
      "-0.771774414073369\n",
      "-0.6988922986382935\n",
      "-0.7303268342799248\n",
      "-0.7599855793727756\n",
      "-0.5742446746288812\n",
      "-0.5546047306288503\n",
      "-0.5969561431062311\n",
      "-0.6181913868874925\n",
      "-0.5766460823703721\n",
      "-0.6907896279174104\n",
      "-0.5870898025224828\n",
      "-0.6973743701102558\n",
      "-0.6598530555476224\n",
      "-0.5798437146695741\n",
      "-0.5351334810287123\n",
      "-0.5361671893284816\n",
      "-0.6587938091138972\n",
      "-0.6569529868977043\n",
      "-0.6442219291923512\n",
      "-0.6504417037672183\n",
      "-0.6377543920203317\n",
      "-0.6167895696227927\n",
      "-0.7107900033334835\n",
      "-0.6116876992502837\n",
      "-0.6407303609202926\n",
      "-0.7265576878098554\n",
      "-0.7412660025576742\n",
      "-0.7265541758323546\n",
      "-0.6478835582270368\n",
      "-0.6635761408660228\n",
      "-0.5361526149109247\n",
      "-0.6420071096578038\n",
      "-0.7001665575696933\n",
      "-0.5549904104049282\n",
      "-0.5744854310375316\n",
      "-0.6047244778885604\n",
      "-0.6061645809093665\n",
      "-0.638110234884487\n",
      "-0.6568834571329115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5650255787798306\n",
      "-0.5965424210147884\n",
      "-0.5559788060764116\n",
      "-0.6059470992672842\n",
      "-0.44296914856262876\n",
      "-0.5591341496065234\n",
      "-0.5817341330307261\n",
      "-0.5644162182767666\n",
      "-0.6245107692910288\n",
      "-0.703388120936\n",
      "-0.6828289796952707\n",
      "-0.6279687105815768\n",
      "-0.6688330972918638\n",
      "-0.4449050742336348\n",
      "-0.44102711219606416\n",
      "-0.5323173986274448\n",
      "-0.5728303019711053\n",
      "-0.5990342291455598\n",
      "-0.5467367731696766\n",
      "-0.6933430392980982\n",
      "-0.6685447623462463\n",
      "-0.6399478845092771\n",
      "-0.5113359199490071\n",
      "-0.5427604632795863\n",
      "-0.5789265600616279\n",
      "-0.6353114413058145\n",
      "-0.6329795376211489\n",
      "-0.7276870145736648\n",
      "-0.6683046962829855\n",
      "-0.6199846970655735\n",
      "-0.6226837322498756\n",
      "-0.5866592017009749\n",
      "-0.6031845038156306\n",
      "-0.5259811172000537\n",
      "-0.5172695782154211\n",
      "-0.5778388863056528\n",
      "-0.6639090834796144\n",
      "-0.6501756020127828\n",
      "-0.5889523789062547\n",
      "-0.6957653784930782\n",
      "-0.5915798608350139\n",
      "-0.6149562859960536\n",
      "-0.612332525916979\n",
      "-0.591273558103675\n",
      "-0.6885101290444988\n",
      "-0.7029360352119317\n",
      "-0.5929635720638863\n",
      "-0.5467635845077096\n",
      "-0.57575882437048\n",
      "-0.5533966504021809\n",
      "-0.6023171321821291\n",
      "-0.4840764374123293\n",
      "-0.6236500511003295\n",
      "-0.6670987427423682\n",
      "-0.5132559962815377\n",
      "-0.6039716620358635\n",
      "-0.6379493932284312\n",
      "-0.5748890312673063\n",
      "-0.6755690123624404\n",
      "-0.5549674064919194\n",
      "-0.591432728387898\n",
      "-0.6369456990035249\n",
      "-0.6195980642918549\n",
      "-0.7006675114354485\n",
      "-0.6625271967314703\n",
      "-0.7938429987840551\n",
      "-0.7384608817317381\n",
      "-0.7395160703457868\n",
      "-0.5933422340342169\n",
      "-0.6025639951012511\n",
      "-0.6423639580354046\n",
      "-0.6581177992475382\n",
      "-0.6566072142838905\n",
      "-0.627767330005276\n",
      "-0.5994431182765873\n",
      "-0.7207667985126561\n",
      "-0.6397904749112553\n",
      "-0.6895429413753413\n",
      "-0.5852810381677501\n",
      "-0.600808007069023\n",
      "-0.7193104479768127\n",
      "-0.6521881241404797\n",
      "-0.7022172251040106\n",
      "-0.7298279182302054\n",
      "-0.6887313109309515\n",
      "-0.7521779947463973\n",
      "-0.660936235655251\n",
      "-0.8178207321682341\n",
      "-0.7455248796320788\n",
      "-0.6156525672312086\n",
      "-0.710082358240288\n",
      "-0.6621477485122759\n",
      "-0.6672167188548067\n",
      "-0.6630900325917071\n",
      "-0.6197263579208672\n",
      "-0.6081648781774885\n",
      "-0.5354618932829592\n",
      "-0.7237039743011187\n",
      "-0.5800251900548161\n",
      "-0.6655997910984173\n",
      "-0.6952700118448231\n",
      "-0.7220626128512087\n",
      "-0.6338788438212901\n",
      "-0.5288626628786612\n",
      "-0.5932574168280416\n",
      "-0.5777521499060906\n",
      "-0.6228984472925856\n",
      "-0.6591442249420171\n",
      "-0.6712625795915123\n",
      "-0.7135408849478465\n",
      "-0.6524413803664885\n",
      "-0.7226851514353402\n",
      "-0.6879606576704418\n",
      "-0.6400429661295439\n",
      "-0.7416215196536531\n",
      "-0.6553344791433948\n",
      "-0.6926554132121899\n",
      "-0.5958459399409309\n",
      "-0.5586883630484746\n",
      "-0.6892376155049676\n",
      "-0.6870879804452134\n",
      "-0.6537046827034451\n",
      "-0.7181538693050712\n",
      "-0.7150551012426393\n",
      "-0.7458352065548173\n",
      "-0.8078000564084473\n",
      "-0.7884686167817467\n",
      "-0.7757826947831422\n",
      "-0.702127282698711\n",
      "-0.7070823545314354\n",
      "-0.7854093405665881\n",
      "-0.7851997396180992\n",
      "-0.7211264652844922\n",
      "-0.7827952241086491\n",
      "-0.7332191561180913\n",
      "-0.706164635114361\n",
      "-0.7828305425094056\n",
      "-0.7808506264711579\n",
      "-0.7551124052742075\n",
      "-0.7100951951337464\n",
      "-0.8135863703305303\n",
      "-0.7661550387565995\n",
      "-0.7847664036811951\n",
      "-0.7853536183536574\n",
      "-0.7397283804816341\n",
      "-0.753743483697551\n",
      "-0.7224763120152966\n",
      "-0.6988841795204233\n",
      "-0.8297469930184787\n",
      "-0.7710642327816241\n",
      "-0.7072500824045738\n",
      "-0.5715832346730357\n",
      "-0.7330538647407288\n",
      "-0.7256985588915241\n",
      "-0.8633256575165311\n",
      "-0.7742218112654478\n",
      "-0.6699654996038302\n",
      "-0.6729034799656742\n",
      "-0.7111182632152525\n",
      "-0.8052864429586527\n",
      "-0.7827439487001382\n",
      "-0.7117881317639156\n",
      "-0.753524315450032\n",
      "-0.6914265789651235\n",
      "-0.8561866036556028\n",
      "-0.6723270202164439\n",
      "-0.7359724454801997\n",
      "-0.7188023784008039\n",
      "-0.7857411674016782\n",
      "-0.6958260466074149\n",
      "-0.7550818735321289\n",
      "-0.7397823902084071\n",
      "-0.6899704641097211\n",
      "-0.7132395139258689\n",
      "-0.7468981033720306\n",
      "-0.7175407422655021\n",
      "-0.7820048588548822\n",
      "-0.7239645713498363\n",
      "-0.7311061912750253\n",
      "-0.7020601175759984\n",
      "-0.7400095770981775\n",
      "-0.7061080473440994\n",
      "-0.6467565381052653\n",
      "-0.7605653290122756\n",
      "-0.8076169403374641\n",
      "-0.6548481299610676\n",
      "-0.746113898892812\n",
      "-0.771844991197029\n",
      "-0.730374446062862\n",
      "-0.6486051812133823\n",
      "-0.7151376030182024\n",
      "-0.7226862844412058\n",
      "-0.8208508545045122\n",
      "-0.7121275461992165\n",
      "-0.581099456715866\n",
      "-0.6869279329968623\n",
      "-0.7618702519478471\n",
      "-0.7761671869808445\n",
      "-0.8361660522150974\n",
      "-0.8466143131072399\n",
      "-0.7695437479845701\n",
      "-0.801349202366424\n",
      "-0.8228251215228801\n",
      "-0.8152301449107563\n",
      "-0.8830956147623137\n",
      "-0.8556329920842214\n",
      "-0.8147470979817822\n",
      "-0.7023167480412419\n",
      "-0.7543981512271977\n",
      "-0.6676527767357243\n",
      "-0.7841744028302797\n",
      "-0.8595818091105117\n",
      "-0.8484251425658209\n",
      "-0.8045747851524324\n",
      "-0.8244006792373857\n",
      "-0.7059805846446\n",
      "-0.6382912309412622\n",
      "-0.8378860261805589\n",
      "-0.6578094047251164\n",
      "-0.7389485891598162\n",
      "-0.8023351164277226\n",
      "-0.7004924354475557\n",
      "-0.6965427844428581\n",
      "-0.7630325168009787\n",
      "-0.642399184795824\n",
      "-0.7323348323098672\n",
      "-0.6751536784656259\n",
      "-0.6923428774768345\n",
      "-0.7212714272735338\n",
      "-0.8445104045149223\n",
      "-0.8845848242172566\n",
      "-0.8279351849120614\n",
      "-0.8951934827737639\n",
      "-0.7900570812248348\n",
      "-0.8652600724044675\n",
      "-0.7374288599958491\n",
      "-0.8310697324555119\n",
      "-0.8366998991040168\n",
      "-0.8149232941647844\n",
      "-0.7523859159341711\n",
      "-0.7112934324542519\n",
      "-0.8032670971386273\n",
      "-0.7303462872666631\n",
      "-0.7718072788810156\n",
      "-0.6101356845686438\n",
      "-0.6606875426259298\n",
      "-0.7606459347349308\n",
      "-0.7963187838474888\n",
      "-0.7132992015247633\n",
      "-0.7720662487446811\n",
      "-0.7481480635408768\n",
      "-0.8070617802554961\n",
      "-0.7548170014876392\n",
      "-0.833105873309654\n",
      "-0.7761814021592137\n",
      "-0.819742926277777\n",
      "-0.7742205862603188\n",
      "-0.7379390001527577\n",
      "-0.8509049337602332\n",
      "-0.7731673535308169\n",
      "-0.7666859432630376\n",
      "-0.7889418289134416\n",
      "-0.7704309673462569\n",
      "-0.8890316715914206\n",
      "-0.8915681565704596\n",
      "-0.7345036135041638\n",
      "-0.7542100368011296\n",
      "-0.8905960709855826\n",
      "-0.8231555157847108\n",
      "-0.7335702748646814\n",
      "-0.7316761054491927\n",
      "-0.7681308849885888\n",
      "-0.8316353564632621\n",
      "-0.8153966151249489\n",
      "-0.8795123238112396\n",
      "-0.8527076011248844\n",
      "-0.7092050179881796\n",
      "-0.7420875240566659\n",
      "-0.7720449340255068\n",
      "-0.7568035080639961\n",
      "-0.7383815493287955\n",
      "-0.712898417455876\n",
      "-0.7548160057736486\n",
      "-0.7674002948599402\n",
      "-0.7679481742535108\n",
      "-0.827735619004027\n",
      "-0.9637556320097559\n",
      "-0.9930812906695776\n",
      "-0.8285555161855792\n",
      "-0.8841333294991216\n",
      "-0.8391921005089975\n",
      "-0.8579606902094548\n",
      "-0.8433649016201952\n",
      "-0.8305645492765233\n",
      "-0.8109823102945634\n",
      "-0.7435259620787772\n",
      "-0.7795591775783809\n",
      "-0.8449142663414858\n",
      "-0.9037092857048288\n",
      "-0.7625708414721816\n",
      "-0.7336216298401937\n",
      "-0.8837679269770642\n",
      "-0.8502117346796506\n",
      "-0.860560300251898\n",
      "-0.8072747237473736\n",
      "-0.8620904268247387\n",
      "-0.9343333480488315\n",
      "-0.9192560779652499\n",
      "-0.9051193328253794\n",
      "-0.7990408427627553\n",
      "-0.7782248168029163\n",
      "-0.7130771351198091\n",
      "-0.8037386549005874\n",
      "-0.7527998106705872\n",
      "-0.78222734276634\n",
      "-0.8480758996466314\n",
      "-0.8824762894345755\n",
      "-0.9033843028644993\n",
      "-0.8537603194679467\n",
      "-0.8563444233547639\n",
      "-0.8639195188030513\n",
      "-0.819525316832896\n",
      "-0.9166435664452922\n",
      "-0.7681930461755961\n",
      "-0.8137168633539433\n",
      "-0.7550245022749308\n",
      "-0.8032573395058781\n",
      "-0.740953245473447\n",
      "-0.7439680820933776\n",
      "-0.7527880001340039\n",
      "-0.7359268340793566\n",
      "-0.631546800463149\n",
      "-0.7534295415977397\n",
      "-0.7961664484353088\n",
      "-0.7623008664973352\n",
      "-0.854658158617605\n",
      "-0.8673703073830161\n",
      "-0.8047455173242872\n",
      "-0.8914278550783031\n",
      "-0.8681110544428001\n",
      "-0.7353918396572364\n",
      "-0.7938116146045939\n",
      "-0.76032816090263\n",
      "-0.7235333606059126\n",
      "-0.7933500003287458\n",
      "-0.7427563971317194\n",
      "-0.8093690650367494\n",
      "-0.8689687226496167\n",
      "-0.8270953399196892\n",
      "-0.6961256476233939\n",
      "-0.8211409075505085\n",
      "-0.8951123978546619\n",
      "-0.9350267989625706\n",
      "-0.8677015325490411\n",
      "-0.8719073726190469\n",
      "-0.8665094266670068\n",
      "-0.9708040418328322\n",
      "-0.7875491456901675\n",
      "-0.7883837880677769\n",
      "-0.8106858343773773\n",
      "-0.8442112010388207\n",
      "-0.8109874761419085\n",
      "-0.9078807189524453\n",
      "-0.8868661602771158\n",
      "-0.7850397896367957\n",
      "-0.8187338585110262\n",
      "-0.8064355197553009\n",
      "-0.8059383988637678\n",
      "-0.9168013306731455\n",
      "-0.8831778200118509\n",
      "-0.899380756106524\n",
      "-0.8259729294887266\n",
      "-0.7576572261280871\n",
      "-0.8553994355507137\n",
      "-0.8287356811392766\n",
      "-0.8130500228367306\n",
      "-0.8977062858398072\n",
      "-0.8638185992084461\n",
      "-0.9876993377168685\n",
      "-0.878204024506818\n",
      "-0.8723231479040529\n",
      "-0.9020477220394184\n",
      "-1.021320166800852\n",
      "-0.95166646604043\n",
      "-0.9493750875923772\n",
      "-0.9619238017116725\n",
      "-0.7975970484694379\n",
      "-0.9138280888847174\n",
      "-0.9371533593800304\n",
      "-0.7433669178388859\n",
      "-0.8822972950250961\n",
      "-0.8442782083317536\n",
      "-0.9143687193592305\n",
      "-0.9330767516410314\n",
      "-0.9036456658979574\n",
      "-0.8392288772092537\n",
      "-0.8833907102662515\n",
      "-0.792385305691137\n",
      "-0.9040874503982862\n",
      "-0.81320447799037\n",
      "-0.8777394543750826\n",
      "-0.9126464185939196\n",
      "-0.8044115724737706\n",
      "-0.8254208788794872\n",
      "-0.907141620697027\n",
      "-0.8133078147045195\n",
      "-0.8469547936149581\n",
      "-0.920472602128474\n",
      "-0.8523771241406214\n",
      "-0.8961446970194714\n",
      "-0.8777927351128609\n",
      "-0.971484264252141\n",
      "-0.880030404317377\n",
      "-0.9196497423817114\n",
      "-0.8519095453331902\n",
      "-0.7063069608241955\n",
      "-0.7983863611291937\n",
      "-0.8590211545001458\n",
      "-0.8618901366543747\n",
      "-0.7688840473962947\n",
      "-0.8303353168633734\n",
      "-0.83021213320512\n",
      "-0.8715378773681306\n",
      "-0.8110404944434397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8833822881640757\n",
      "-0.9619534360515931\n",
      "-0.8007809822687828\n",
      "-0.9567906816059328\n",
      "-0.8502546608482028\n",
      "-0.8517041505730918\n",
      "-0.9226262202015315\n",
      "-0.8660460308089898\n",
      "-0.9137413779038754\n",
      "-0.9074624369228758\n",
      "-0.8519274936605469\n",
      "-0.9242577492910715\n",
      "-0.8953105200339379\n",
      "-0.964143871308736\n",
      "-0.9430687225582903\n",
      "-0.8821609732798872\n",
      "-0.9123878436576891\n",
      "-0.7970205861890108\n",
      "-0.8500604094442787\n",
      "-0.8628373063533952\n",
      "-0.9131653358686713\n",
      "-0.87242620663181\n",
      "-0.9686499196935356\n",
      "-1.0018432640704564\n",
      "-0.9462867396346887\n",
      "-0.954220673489354\n",
      "-1.070779756458065\n",
      "-0.9969559581369375\n",
      "-0.9875034246932133\n",
      "-0.9387677489277718\n",
      "-0.8992709437865144\n",
      "-0.9643979965796292\n",
      "-0.8619481403050896\n",
      "-0.7983238854542053\n",
      "-0.8640457783379343\n",
      "-0.9815753666237805\n",
      "-1.0051634636589237\n",
      "-0.934504316195568\n",
      "-0.9933247007774655\n",
      "-0.9705340012697499\n",
      "-0.9159461744613021\n",
      "-1.0215444898440718\n",
      "-0.934026757121388\n",
      "-0.9513262704778234\n",
      "-0.9303603402081217\n",
      "-0.9794321029733134\n",
      "-0.8820596683636465\n",
      "-0.93923587281611\n",
      "-0.8208010887346772\n",
      "-0.9136320978903171\n",
      "-0.9061187791331996\n",
      "-0.8278376020393454\n",
      "-0.8627675547879335\n",
      "-0.8964514357385518\n",
      "-0.9950873642339563\n",
      "-0.8122670541492814\n",
      "-0.851050968029588\n",
      "-0.889231236677695\n",
      "-0.7831389210861194\n",
      "-0.8392554652721582\n",
      "-0.8080596943679741\n",
      "-0.9040479217799345\n",
      "-0.8287316784805416\n",
      "-0.9127761849678648\n",
      "-0.9204210023169708\n",
      "-0.8485038269525107\n",
      "-0.8883415274613223\n",
      "-0.93168320397521\n",
      "-1.006161691047902\n",
      "-0.9771971306150838\n",
      "-0.9839795060712906\n",
      "-0.8928967010918707\n",
      "-1.0360548995953116\n",
      "-1.0751276425428309\n",
      "-0.9377602664932084\n",
      "-0.9925051641324707\n",
      "-0.9707469449675877\n",
      "-0.9186241314560782\n",
      "-1.007845746385223\n",
      "-1.0490529751413518\n",
      "-0.9088880801759593\n",
      "-0.9871408742724215\n",
      "-0.9823247868813182\n",
      "-1.0926498774913338\n",
      "-0.9911586179496021\n",
      "-1.0743294184006176\n",
      "-0.9423090526157811\n",
      "-1.0130232577797762\n",
      "-1.0188514597728877\n",
      "-1.0003777332336798\n",
      "-1.0274766772103727\n",
      "-1.048680735670398\n",
      "-0.932737054098965\n",
      "-0.8927745918327742\n",
      "-0.9268550971611219\n",
      "-0.9323751512602393\n",
      "-0.9469680122438681\n",
      "-0.9392912306301789\n",
      "-0.9832875935030422\n",
      "-0.963684576666658\n",
      "-0.9776218903421271\n",
      "-0.9246466161538033\n",
      "-0.9853260395321558\n",
      "-0.9447199426236694\n",
      "-1.062100931571859\n",
      "-0.9961326571901354\n",
      "-0.8985846592568613\n",
      "-0.9089699700239751\n",
      "-0.842743691409503\n",
      "-1.0442126645839034\n",
      "-0.999551159427588\n",
      "-0.9731635598129829\n",
      "-0.8822784080512007\n",
      "-0.9606974879765822\n",
      "-0.9568163856466189\n",
      "-1.065242336519382\n",
      "-1.0726578176873272\n",
      "-0.9571098782413227\n",
      "-0.9767400781771542\n",
      "-1.0206066284049813\n",
      "-1.0111249513748737\n",
      "-1.0271362916516518\n",
      "-0.9997422922743511\n",
      "-1.0576678411584624\n",
      "-1.0022557760800097\n",
      "-1.0208810461667268\n",
      "-0.9507343087766498\n",
      "-0.9735285100043399\n",
      "-0.9151922108799526\n",
      "-0.9241057916836882\n",
      "-0.9129566497690416\n",
      "-0.9281079387249905\n",
      "-0.7677194457164317\n",
      "-0.8672271318598684\n",
      "-0.9293356586797885\n",
      "-1.0491440604706377\n",
      "-0.9569748770193796\n",
      "-0.9502881707004398\n",
      "-0.9871863797138988\n",
      "-0.9530990443853671\n",
      "-1.017921197091915\n",
      "-1.0937152397479604\n",
      "-1.0484384527761899\n",
      "-0.9747121028864647\n",
      "-0.9424485405327063\n",
      "-0.9860057604253196\n",
      "-1.0202775321304707\n",
      "-1.0028368252895716\n",
      "-0.9788521147352254\n",
      "-0.9587943424912566\n",
      "-0.9688694311033091\n",
      "-0.8583976802786212\n",
      "-0.9208011367903377\n",
      "-0.8563079211073057\n",
      "-0.8644491914260045\n",
      "-0.9829826150656462\n",
      "-0.8823145591317316\n",
      "-0.9930150755468369\n",
      "-0.8972411413206545\n",
      "-0.9217734766989727\n",
      "-0.9068383085321159\n",
      "-0.9611712176318187\n",
      "-1.028981477486394\n",
      "-1.0010817936223286\n",
      "-0.9880138326924411\n",
      "-0.951628143191239\n",
      "-1.018141221044364\n",
      "-0.9568032317180574\n",
      "-0.9606768389165501\n",
      "-0.9451672489848362\n",
      "-0.9729388736187803\n",
      "-0.999459889059309\n",
      "-0.9693384287882623\n",
      "-0.9806707424887157\n",
      "-1.0182671122876086\n",
      "-0.918734731283394\n",
      "-0.9828907760993686\n",
      "-0.8462105229874352\n",
      "-0.9960520386901214\n",
      "-1.001138210534129\n",
      "-0.9475374602671423\n",
      "-0.9559574600692807\n",
      "-1.1169954619486313\n",
      "-0.9699408476977311\n",
      "-1.0015921981092364\n",
      "-0.9952933159031412\n",
      "-1.0951625353605317\n",
      "-1.0126380330696065\n",
      "-1.0220029743948482\n",
      "-0.9219326032854753\n",
      "-1.045418094826337\n",
      "-1.027641781209697\n",
      "-1.0439374938396502\n",
      "-1.0363422745227462\n",
      "-1.1787356300441192\n",
      "-1.0558934476976707\n",
      "-1.1221272151459645\n",
      "-1.0493385709162264\n",
      "-0.9521733483490257\n",
      "-0.8182473031334367\n",
      "-0.9719461881338491\n",
      "-0.8356760189898872\n",
      "-0.9016992507965765\n",
      "-0.9549215508439659\n",
      "-0.8821057928216285\n",
      "-1.0383658014377959\n",
      "-1.0318568651961657\n",
      "-1.0367920150686618\n",
      "-1.0662888591251853\n",
      "-1.1004892030220321\n",
      "-1.0283540383970613\n",
      "-1.071952305035604\n",
      "-1.2510098220513486\n",
      "-1.0428666069224493\n",
      "-1.0024533592574647\n",
      "-1.0319039698099135\n",
      "-1.047008241669404\n",
      "-1.0495982342081112\n",
      "-1.0248388335404728\n",
      "-0.9692106496060592\n",
      "-0.9109557391857243\n",
      "-1.010894794268591\n",
      "-0.9739327703885965\n",
      "-1.0698277493658797\n",
      "-0.9674628059783202\n",
      "-0.9484666492400644\n",
      "-0.9665596212799404\n",
      "-0.870814845933338\n",
      "-0.9874059033607331\n",
      "-0.9914442768633731\n",
      "-1.0557399060894443\n",
      "-0.9715709772730157\n",
      "-0.981280413103126\n",
      "-0.8009659026094748\n",
      "-0.9734200606464137\n",
      "-0.9355123819784477\n",
      "-0.9357773622794877\n",
      "-0.8910209949716495\n",
      "-0.9498380143721288\n",
      "-0.9678066207579202\n",
      "-0.9957944023181756\n",
      "-1.0101134166758519\n",
      "-0.9910857761637616\n",
      "-1.0331342474677492\n",
      "-0.9761404581812052\n",
      "-0.8811040877994651\n",
      "-1.0239094590975284\n",
      "-0.9852684056945695\n",
      "-0.9257283261631455\n",
      "-0.9749318955855983\n",
      "-0.9621319051143611\n",
      "-1.0201626048076042\n",
      "-0.9708900297139489\n",
      "-0.9603172002651152\n",
      "-1.1187632050578447\n",
      "-0.9913285291567754\n",
      "-1.0863425506490545\n",
      "-1.118644810230308\n",
      "-1.0621764934131193\n",
      "-0.9156971629510966\n",
      "-0.9829247386477313\n",
      "-1.0063909582036346\n",
      "-1.0984754684827795\n",
      "-1.0180674359427833\n",
      "-1.018311965357491\n",
      "-1.0236262561356781\n",
      "-0.9867063345495227\n",
      "-0.9995827063401461\n",
      "-1.0158907236840828\n",
      "-1.023481160448421\n",
      "-1.1070476483845935\n",
      "-1.0707194034785534\n",
      "-1.1063171774668459\n",
      "-1.067138681570439\n",
      "-1.079840863621477\n",
      "-1.11000279922113\n",
      "-1.124169880041168\n",
      "-1.0906511859963997\n",
      "-0.9205076256907199\n",
      "-0.961060206389789\n",
      "-0.9616180330356805\n",
      "-1.024429321172704\n",
      "-1.0348318148071096\n",
      "-1.1510691496383376\n",
      "-0.9863792746145749\n",
      "-0.9812547600931695\n",
      "-1.0651824350036958\n",
      "-0.9387657828795564\n",
      "-1.0531940819276906\n",
      "-1.0151535877192839\n",
      "-1.078611469912743\n",
      "-0.9137546003567608\n",
      "-1.033060365858447\n",
      "-0.9743346310612434\n",
      "-1.0429018464658975\n",
      "-0.9773284684237894\n",
      "-1.0493851333851911\n",
      "-1.0696601869084148\n",
      "-1.0708997700114886\n",
      "-1.0294759692594873\n",
      "-1.1097203105524136\n",
      "-1.0400489898609087\n",
      "-0.956587362517322\n",
      "-1.0072424081019506\n",
      "-0.9871818200032889\n",
      "-1.005412058574269\n",
      "-0.9747277586407722\n",
      "-0.9463918935722735\n",
      "-0.9633996345130103\n",
      "-0.788581827067908\n",
      "-0.9101526883358408\n",
      "-0.975811249402597\n",
      "-0.9384949321493914\n",
      "-1.0115160245413872\n",
      "-0.9241311199180295\n",
      "-0.8330784360564794\n",
      "-0.9543229114970179\n",
      "-0.9233014748305907\n",
      "-0.959118247933822\n",
      "-0.9726865320004205\n",
      "-0.8973430905298465\n",
      "-0.9897797776062577\n",
      "-0.9413905447458932\n",
      "-1.0413612407717636\n",
      "-0.934017112747586\n",
      "-1.0050320307405458\n",
      "-0.9168839510466122\n",
      "-0.9773162668351782\n",
      "-0.9161754053433699\n",
      "-1.0602646379255998\n",
      "-0.9521249939817498\n",
      "-0.9924398083450034\n",
      "-1.076259413425095\n",
      "-0.9630655059762838\n",
      "-0.9577688359092755\n",
      "-0.8866281900389082\n",
      "-0.881974904950407\n",
      "-0.8722697637853963\n",
      "-0.8120052305197565\n",
      "-0.8141557128807433\n",
      "-0.9403373931358255\n",
      "-1.0384268865488293\n",
      "-0.9799321378570356\n",
      "-0.9623426431610543\n",
      "-0.9709688849448476\n",
      "-1.005952327899495\n",
      "-0.9631102700126378\n",
      "-0.8274507245989787\n",
      "-0.9002638935997228\n",
      "-0.7914963575642019\n",
      "-0.8773504586025133\n",
      "-1.0367955818198016\n",
      "-0.8550529403909042\n",
      "-1.003544534616501\n",
      "-1.0051891025291564\n",
      "-0.9255808398579317\n",
      "-1.0315588297510487\n",
      "-0.9280968041961873\n",
      "-0.9967491088003373\n",
      "-1.0164298064122443\n",
      "-1.0263241822810778\n",
      "-0.9800345804909634\n",
      "-0.9675094084259459\n",
      "-0.9185405458244534\n",
      "-1.0408543146903733\n",
      "-0.9762544962770452\n",
      "-0.9049725191307959\n",
      "-0.9645755022179003\n",
      "-0.9400653131725889\n",
      "-0.8035438906734751\n",
      "-0.9488451477416067\n",
      "-0.8985489686295913\n",
      "-1.0050638564779566\n",
      "-0.9154592371113923\n",
      "-0.9514872801300803\n",
      "-0.885667796122187\n",
      "-0.8672987326995284\n",
      "-0.9534496685605337\n",
      "-0.8783386470855544\n",
      "-0.9160322790751916\n",
      "-0.9842863377834825\n",
      "-1.0436197144786925\n",
      "-0.9806184114476537\n",
      "-0.9334345544753059\n",
      "-0.9085748974431009\n",
      "-0.8939521733054007\n",
      "-0.8982716271393415\n",
      "-0.949940207323801\n",
      "-0.8831298499493284\n",
      "-0.9065244874096223\n",
      "-0.9583950631630997\n",
      "-0.9197454828319548\n",
      "-0.9841642438529388\n",
      "-0.9693041349901753\n",
      "-0.9141688222660349\n",
      "-0.8535490757967569\n",
      "-0.8652543821910691\n",
      "-0.9049211385444146\n",
      "-0.9987944613217975\n",
      "-0.9574690068766588\n",
      "-0.9186271021601486\n",
      "-0.9321175187239163\n",
      "-0.8838703851923068\n",
      "-0.8921105744464219\n",
      "-0.9461091237296266\n",
      "-0.9132305363767295\n",
      "-0.8258914391262345\n",
      "-0.8317397236939433\n",
      "-0.9005407290546109\n",
      "-0.8894869174638229\n",
      "-0.8112512034948511\n",
      "-0.8803408283211551\n",
      "-0.9233349924770669\n",
      "-0.885678932850227\n",
      "-0.8339204360967432\n",
      "-0.9825096754538494\n",
      "-0.8673573826307514\n",
      "-0.792293061570349\n",
      "-0.8278113242671913\n",
      "-0.8773395909087823\n",
      "-0.8169146310408083\n",
      "-0.8009370960838647\n",
      "-0.887191552545302\n",
      "-0.8779296303325967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9617488767680474\n",
      "-0.8452881744093983\n",
      "-0.7882942870309021\n",
      "-0.9124635767101245\n",
      "-0.8605947511341558\n",
      "-0.8454166748896726\n",
      "-0.8438355515386907\n",
      "-0.73503316120502\n",
      "-0.8462663850986736\n",
      "-0.9175697599660594\n",
      "-0.8389409639582632\n",
      "-0.7753873071716039\n",
      "-0.776012327554341\n",
      "-0.8129554414510074\n",
      "-0.8398075258649027\n",
      "-0.8411633214311007\n",
      "-0.8803757653180073\n",
      "-0.8127923784148295\n",
      "-0.8652323530397783\n",
      "-0.872255670388727\n",
      "-0.8433666842658577\n",
      "-0.9039897602670119\n",
      "-0.9024099721824944\n",
      "-0.9626948491537936\n",
      "-0.940153488325057\n",
      "-0.8011571374532508\n",
      "-0.8325134779448439\n",
      "-0.910637923051675\n",
      "-0.8937111091457091\n",
      "-0.9267221768927165\n",
      "-1.0031606833363056\n",
      "-1.0275320768930656\n",
      "-0.9132081275782074\n",
      "-0.935739460737415\n",
      "-0.8884492247185877\n",
      "-0.8431163061468276\n",
      "-0.8739909804595072\n",
      "-0.8020319824152072\n",
      "-0.7261833541239494\n",
      "-0.9565640684779873\n",
      "-0.9251859751064719\n",
      "-0.9423522578417965\n",
      "-0.8876038264907237\n",
      "-0.837571387346399\n",
      "-0.8873668625392879\n",
      "-0.8759831098229843\n",
      "-0.8957913997827333\n",
      "-0.9256780814318288\n",
      "-0.9575193235858426\n",
      "-0.9192712182917542\n",
      "-0.9408075171454214\n",
      "-0.8349246941755025\n",
      "-0.8805145176610703\n",
      "-0.8666982869019648\n",
      "-0.801944217120799\n",
      "-0.8121445224576498\n",
      "-0.7397248663550744\n",
      "-0.7632876734451916\n",
      "-0.8148206819124963\n",
      "-0.924648727754508\n",
      "-0.7783514359507098\n",
      "-0.8617049321572798\n",
      "-0.8507877634377375\n",
      "-0.8212481018154228\n",
      "-0.7842240507982569\n",
      "-0.8521519794464065\n",
      "-0.8457050423038825\n",
      "-0.8666074444096089\n",
      "-0.8993431583784559\n",
      "-0.8795194251101245\n",
      "-0.8810288589045517\n",
      "-0.8089211793500284\n",
      "-0.7130203989220262\n",
      "-0.8333803504510698\n",
      "-0.8163204496705562\n",
      "-0.7529571388597367\n",
      "-0.8925649590716267\n",
      "-0.801127205472287\n",
      "-0.8722943114846136\n",
      "-0.8776671519970772\n",
      "-0.8024364275137433\n",
      "-0.750098744654006\n",
      "-0.7744991414779889\n",
      "-0.7334623173447574\n",
      "-0.815084040178137\n",
      "-0.7896331189926045\n",
      "-0.8248349379747838\n",
      "-0.9261708712984079\n",
      "-0.8577545383015974\n",
      "-0.8264835596367656\n",
      "-0.8282095672074733\n",
      "-0.8235211563051501\n",
      "-0.8994714428662227\n",
      "-0.784893967892274\n",
      "-0.8894819126416035\n",
      "-0.9226710069735398\n",
      "-0.9145376297338662\n",
      "-0.8508361257779216\n",
      "-0.8125721281113814\n",
      "-0.8202528111009588\n",
      "-0.9139293285013492\n",
      "-0.8175134464627526\n",
      "-0.906568898744534\n",
      "-0.8323539578025803\n",
      "-0.765257372720607\n",
      "-0.918900227229193\n",
      "-0.8628632883979122\n",
      "-0.8261987568076966\n",
      "-0.9008804062069115\n",
      "-0.8849333648685073\n",
      "-0.8646960754448914\n",
      "-0.9275717854127268\n",
      "-0.937665090185561\n",
      "-0.8910940494055216\n",
      "-0.7982785290684551\n",
      "-0.7367576724258079\n",
      "-0.694083898420189\n",
      "-0.7822854059154092\n",
      "-0.8274184886941054\n",
      "-0.8907634492358916\n",
      "-0.8735014979792968\n",
      "-0.8694855285474802\n",
      "-0.8363112918119215\n",
      "-0.8771143692113941\n",
      "-0.8322793436386285\n",
      "-0.8629201243681004\n",
      "-0.8114548463881914\n",
      "-0.8505820070500641\n",
      "-0.8132216151894496\n",
      "-0.8736256616671256\n",
      "-0.8648641093736312\n",
      "-0.7324153677914824\n",
      "-0.8586547927531117\n",
      "-0.8613966654460631\n",
      "-0.8899872770886956\n",
      "-0.8665544093881858\n",
      "-0.8656866134154817\n",
      "-0.8631707629335127\n",
      "-0.8806554294895489\n",
      "-0.8193785276222266\n",
      "-0.9149703215341769\n",
      "-0.9192957724869409\n",
      "-0.8724137777502711\n",
      "-0.8245063594490197\n",
      "-0.8482215715590573\n",
      "-0.9979586465574579\n",
      "-0.9491587570798925\n",
      "-0.9070567400315748\n",
      "-0.8332416161075084\n",
      "-0.9517080727366805\n",
      "-0.8983901913556989\n",
      "-0.9034407732741788\n",
      "-0.692191984275677\n",
      "-0.8116113105437303\n",
      "-0.7634775053833087\n",
      "-0.9755728679067684\n",
      "-0.9340481158506233\n",
      "-0.8708619305485242\n",
      "-0.9196919454721842\n",
      "-0.9325405233300816\n",
      "-1.0174250944971461\n",
      "-0.8932230997188417\n",
      "-0.9513335617049835\n",
      "-0.8711535181929625\n",
      "-0.8482844207871935\n",
      "-0.8508231664525219\n",
      "-0.8506584610675488\n",
      "-0.9252262092053469\n",
      "-0.8765298967396247\n",
      "-0.8583995022373369\n",
      "-0.9411632800136045\n",
      "-0.826100734522923\n",
      "-0.8775882781827546\n",
      "-0.9159810573471412\n",
      "-0.8034153314035565\n",
      "-0.8442788150509558\n",
      "-0.9142873323467215\n",
      "-0.9032958385934425\n",
      "-0.8463876451842007\n",
      "-0.8865359213817944\n",
      "-0.7907601806875373\n",
      "-0.8236861604412565\n",
      "-0.8427654139114321\n",
      "-0.9539275950283603\n",
      "-0.8378270712508604\n",
      "-0.8359714757437772\n",
      "-0.9353439396739861\n",
      "-0.919469407089486\n",
      "-0.9391258412356416\n",
      "-0.9196733068246562\n",
      "-0.9139787844329121\n",
      "-0.9281276661696466\n",
      "-0.905468956725667\n",
      "-0.914258933228225\n",
      "-0.9102747011257525\n",
      "-0.8895613095491715\n",
      "-0.8431423060722174\n",
      "-0.9332732603659837\n",
      "-0.8595674325161358\n",
      "-0.8367439642510741\n",
      "-0.8151158422533055\n",
      "-0.7692951212015983\n",
      "-0.8901207116140161\n",
      "-0.8307661278734729\n",
      "-0.949585558813666\n",
      "-0.7215390280899954\n",
      "-0.8150023942304955\n",
      "-0.9423024946254352\n",
      "-0.8781405663667271\n",
      "-0.8622445069447258\n",
      "-0.857757373127872\n",
      "-0.8765012283224705\n",
      "-0.9284491080530466\n",
      "-0.8651291600152292\n",
      "-0.9696381914791613\n",
      "-0.832818925467008\n",
      "-0.8324936297541986\n",
      "-0.8963898160121777\n",
      "-0.8505502845758383\n",
      "-0.9526164912152958\n",
      "-0.9258725984544407\n",
      "-0.9670027558856129\n",
      "-0.8733860277069062\n",
      "-0.8508115257181568\n",
      "-0.8252903477842265\n",
      "-0.8847895449432589\n",
      "-0.8405850629882099\n",
      "-0.8150725894398915\n",
      "-0.9248740072462069\n",
      "-0.8610218146928584\n",
      "-0.9516458667808668\n",
      "-0.9871572019854875\n",
      "-0.9460342851187378\n",
      "-0.9158379057841357\n",
      "-0.9038507155930531\n",
      "-0.8722119418449495\n",
      "-0.860664227070392\n",
      "-0.8666221339535382\n",
      "-1.011615611212921\n",
      "-0.9835434855099502\n",
      "-0.9047144907162994\n",
      "-0.9420817176365561\n",
      "-0.8559523584994336\n",
      "-0.8265059108838405\n",
      "-0.9500062148756324\n",
      "-0.8948650194087333\n",
      "-0.9851903745426169\n",
      "-0.884111755149098\n",
      "-0.8988300138343602\n",
      "-0.9280117488025855\n",
      "-0.9632662295483075\n",
      "-0.9490848769566496\n",
      "-0.9444432006922276\n",
      "-0.9736559559206583\n",
      "-0.9435283382853135\n",
      "-0.8968212215134171\n",
      "-0.9551137858088865\n",
      "-0.9287764872798366\n",
      "-0.8993225786731405\n",
      "-0.916124364871544\n",
      "-1.000451323318905\n",
      "-0.8936915264293079\n",
      "-0.8580661267930515\n",
      "-0.9915695491276636\n",
      "-1.0403766573894613\n",
      "-0.8617216426484923\n",
      "-0.8991162851670688\n",
      "-0.8620156828839782\n",
      "-0.9624792965147958\n",
      "-0.9653189754658936\n",
      "-0.9052692161490873\n",
      "-0.8795574294949772\n",
      "-0.7889982584528672\n",
      "-0.8873925979963176\n",
      "-0.8751661861617381\n",
      "-0.8736088862950084\n",
      "-0.8979971223120952\n",
      "-0.8459905861057753\n",
      "-0.9032455057462587\n",
      "-0.8229046177689083\n",
      "-0.880343128370777\n",
      "-0.8487676891870696\n",
      "-0.7700079747612503\n",
      "-0.8020507536273417\n",
      "-0.7212724961483223\n",
      "-0.7902686281029442\n",
      "-0.7886494650450092\n",
      "-0.8105971226551218\n",
      "-0.88966670586062\n",
      "-0.7876700534537465\n",
      "-0.9530620107378254\n",
      "-0.8624730191170175\n",
      "-0.8078144631782372\n",
      "-0.7815252111219094\n",
      "-0.9365003238577847\n",
      "-0.7793973082652227\n",
      "-0.8139961725389235\n",
      "-0.9201311533091946\n",
      "-0.7384071945915647\n",
      "-0.8448483797368448\n",
      "-0.8744972869599648\n",
      "-0.8569835556359137\n",
      "-0.8790301184032197\n",
      "-0.8213509762526411\n",
      "-0.8233809328910122\n",
      "-0.8044736677386398\n",
      "-0.8612131074529359\n",
      "-0.7932681266876883\n",
      "-0.8521841741768038\n",
      "-0.7427936345278858\n",
      "-0.9236731585633554\n",
      "-0.7985947964498761\n",
      "-0.7940389628242418\n",
      "-0.7998381150275519\n",
      "-0.6909019897443076\n",
      "-0.7784296303120983\n",
      "-0.8183628920820943\n",
      "-0.8753592889893601\n",
      "-0.7751959442354783\n",
      "-0.791589139789595\n",
      "-0.8830643473561022\n",
      "-0.7568685633421887\n",
      "-0.920545551601859\n",
      "-0.7979850842505594\n",
      "-0.8120873299325114\n",
      "-0.7239106916310599\n",
      "-0.7949235641390338\n",
      "-0.7950173617076334\n",
      "-0.8991527864556773\n",
      "-0.8354508328257173\n",
      "-0.8376410835840749\n",
      "-0.7648422281862468\n",
      "-0.8886786550957257\n",
      "-0.8068508676597121\n",
      "-0.8620304299995717\n",
      "-0.8239472654130152\n",
      "-0.914024893483588\n",
      "-0.9006112575813143\n",
      "-0.8548139603792896\n",
      "-0.8282741689303411\n",
      "-0.8722871685815027\n",
      "-0.8051433733449458\n",
      "-0.8843570810571192\n",
      "-0.8884818488701163\n",
      "-0.8351495745918343\n",
      "-0.8848472636135424\n",
      "-0.8968177165903197\n",
      "-0.9105264101257438\n",
      "-0.9002543449903166\n",
      "-0.9172542221023675\n",
      "-0.8672875234682397\n",
      "-0.948844319316477\n",
      "-0.9611253142702121\n",
      "-1.004671682062289\n",
      "-0.9085427130167647\n",
      "-0.9573512433453323\n",
      "-0.9426788999459003\n",
      "-0.895902924861417\n",
      "-0.9055603551465992\n",
      "-0.9101743877524899\n",
      "-0.9899241664840122\n",
      "-0.944094907185599\n",
      "-0.9182872174835559\n",
      "-0.8191818671034611\n",
      "-0.9241021314511342\n",
      "-0.9038457403100393\n",
      "-1.0029179631828113\n",
      "-0.9121087670576074\n",
      "-0.9088582765540356\n",
      "-0.8561292014401587\n",
      "-0.9427481325272975\n",
      "-1.035416011958881\n",
      "-0.8560748374912466\n",
      "-0.8035663164196916\n",
      "-0.9195100395813174\n",
      "-1.0292437992431553\n",
      "-1.0393880827642756\n",
      "-0.9931671506674631\n",
      "-1.0087428819493012\n",
      "-0.973925869461781\n",
      "-0.9294875341046795\n",
      "-0.886362755757213\n",
      "-0.9543162739041982\n",
      "-1.0141850508327483\n",
      "-0.9637451207840666\n",
      "-0.8977038094622948\n",
      "-0.9015527529935893\n",
      "-0.9466610713181032\n",
      "-0.8701728737280706\n",
      "-0.9127202727997912\n",
      "-1.0300084141163244\n",
      "-0.9730295416808559\n",
      "-1.0757068981176605\n",
      "-1.0477702803545887\n",
      "-0.988726026789599\n",
      "-0.9696250107220435\n",
      "-1.085604485106142\n",
      "-1.0213600309593276\n",
      "-1.0483234706455666\n",
      "-1.0479745227162895\n",
      "-1.0177467907182736\n",
      "-0.9899920679566433\n",
      "-0.9786343283244779\n",
      "-0.9517397977621586\n",
      "-1.0072709344913229\n",
      "-0.9652747891578489\n",
      "-0.9989441062802666\n",
      "-1.0768041122000398\n",
      "-1.0012578735390507\n",
      "-1.0211789510929177\n",
      "-0.957745760270509\n",
      "-0.9647649137851693\n",
      "-0.8348493965656058\n",
      "-0.814627438845764\n",
      "-0.8957683877367616\n",
      "-0.9370768334327533\n",
      "-1.0017892347224582\n",
      "-1.0464997901673938\n",
      "-0.9791427316067872\n",
      "-1.0354270332046989\n",
      "-1.0013026239374068\n",
      "-0.9439401905238232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0427858633608584\n",
      "-1.0200600232975643\n",
      "-1.1415606130413565\n",
      "-1.0663201901280255\n",
      "-0.9639200586566441\n",
      "-1.0595434557633487\n",
      "-0.9309791180861303\n",
      "-1.0541259404365917\n",
      "-1.0107719287936816\n",
      "-1.0091864500576369\n",
      "-1.0170592031960388\n",
      "-0.9932386824672116\n",
      "-1.0274240661026772\n",
      "-1.0343556506837757\n",
      "-1.1456129516993703\n",
      "-1.170815708065946\n",
      "-1.1128162367607621\n",
      "-0.9394844691973095\n",
      "-1.0050584900811215\n",
      "-0.9686306797900862\n",
      "-0.8980725902447777\n",
      "-0.8678192565273967\n",
      "-0.8966272360407492\n",
      "-0.9036657744897385\n",
      "-1.0408431622080936\n",
      "-1.0388763110937644\n",
      "-1.0173618747325157\n",
      "-0.9457052648893736\n",
      "-1.0871429541017457\n",
      "-0.9023531216798745\n",
      "-0.9202547053777972\n",
      "-1.0371868033130995\n",
      "-1.1438488924874168\n",
      "-1.0539614325263706\n",
      "-0.9910562581891379\n",
      "-1.0550131171795367\n",
      "-1.0343193217166784\n",
      "-1.100382885470019\n",
      "-1.1089173476948304\n",
      "-1.0479672975063632\n",
      "-1.0497661447742037\n",
      "-0.9148187698437499\n",
      "-0.9426646905502878\n",
      "-0.8822202545494322\n",
      "-0.8677907095261306\n",
      "-0.9402495185002832\n",
      "-0.9475706139176042\n",
      "-0.9479858395377209\n",
      "-1.060542595303366\n",
      "-0.9682018813530489\n",
      "-0.889308873962092\n",
      "-1.0211205223872337\n",
      "-0.9515265357804502\n",
      "-1.005745729987324\n",
      "-1.0135838028974977\n",
      "-0.9677995711784767\n",
      "-1.081858078150757\n",
      "-1.0099311170841452\n",
      "-1.0971664459992991\n",
      "-1.077947273956874\n",
      "-1.07101490010024\n",
      "-0.9948224736089225\n",
      "-1.1294697947307093\n",
      "-1.0410687655681135\n",
      "-0.9871054418547834\n",
      "-1.0159736487250546\n",
      "-0.9208966409227537\n",
      "-0.9972868357443663\n",
      "-1.0080844392714756\n",
      "-0.9750701533580712\n",
      "-0.9565601125426424\n",
      "-0.9191976066685931\n",
      "-1.0158571922927382\n",
      "-0.9818529240393657\n",
      "-1.0255537350601946\n",
      "-1.0323330985662797\n",
      "-0.9721676046645858\n",
      "-0.893177419795771\n",
      "-0.954762592768762\n",
      "-0.9556539914219941\n",
      "-1.0524654056195415\n",
      "-0.874294332591676\n",
      "-0.9640794482029572\n",
      "-1.069880625828265\n",
      "-0.8971244884318608\n",
      "-0.9263737057152174\n",
      "-0.9989310595652315\n",
      "-1.0556236177557425\n",
      "-0.8947749526042232\n",
      "-0.885294203995009\n",
      "-0.9668591977914897\n",
      "-0.9893401030644714\n",
      "-1.0114601320840457\n",
      "-0.9363036770459182\n",
      "-0.9269333328777288\n",
      "-0.8730262587540362\n",
      "-0.9142937215805251\n",
      "-0.934842708014137\n",
      "-0.9779356839868713\n",
      "-0.9539281902378438\n",
      "-0.9775230613127633\n",
      "-0.8924219638397367\n",
      "-0.9548476363876629\n",
      "-0.936628353236233\n",
      "-0.8409819194527285\n",
      "-0.8975967596168808\n",
      "-0.8495948936012818\n",
      "-0.8297709154271626\n",
      "-0.8721395243000836\n",
      "-0.9226637938266944\n",
      "-1.0025246599240043\n",
      "-0.8529058919421966\n",
      "-0.8911769344048903\n",
      "-0.9202210695098616\n",
      "-0.9071612743771458\n",
      "-0.8843660359149554\n",
      "-0.9883170305016272\n",
      "-0.8299805365956829\n",
      "-0.9011975927039964\n",
      "-0.8323317760453519\n",
      "-0.8630200011031429\n",
      "-0.9103045656634647\n",
      "-0.895934628021777\n",
      "-0.8510874057825636\n",
      "-0.9245476063796453\n",
      "-0.8427238037374323\n",
      "-0.9855991572838748\n",
      "-0.907070009150551\n",
      "-0.809912662513744\n",
      "-0.8388228313412014\n",
      "-0.8750090231696958\n",
      "-0.7937636408855622\n",
      "-0.7887058349513917\n",
      "-0.9296616712743173\n",
      "-0.8658780960130766\n",
      "-0.8741030567537508\n",
      "-0.9293421226184799\n",
      "-1.0016314423468011\n",
      "-0.9261522111912733\n",
      "-0.7942525583944923\n",
      "-0.8098081820369153\n",
      "-0.7575687549629401\n",
      "-0.8382107478927339\n",
      "-0.7680967852559749\n",
      "-0.8109944356006855\n",
      "-0.7811347811716715\n",
      "-0.7483194512834904\n",
      "-0.7736008409250362\n",
      "-0.7333033340320908\n",
      "-0.7882641828272189\n",
      "-0.7682832222386143\n",
      "-0.8453838153537498\n",
      "-0.8328715645648002\n",
      "-0.9223909254619561\n",
      "-0.8032711660518036\n",
      "-0.8401545619073434\n",
      "-0.8778571829298264\n",
      "-0.741661017746723\n",
      "-0.8784169172131304\n",
      "-0.8140305247009548\n",
      "-0.8480883051833426\n",
      "-0.8539537319162123\n",
      "-0.8533396627431485\n",
      "-0.7339849454179886\n",
      "-0.8670175461344172\n",
      "-0.8149121918467703\n",
      "-0.6621618385201319\n",
      "-0.6467818111785933\n",
      "-0.6552693586783468\n",
      "-0.7374484731532602\n",
      "-0.7124971226845609\n",
      "-0.8306907730612877\n",
      "-0.8892881944431955\n",
      "-0.775806374989825\n",
      "-0.7794286350245702\n",
      "-0.8043410211914318\n",
      "-0.7199564660255783\n",
      "-0.7264776921856092\n",
      "-0.7703256187650072\n",
      "-0.769190332736798\n",
      "-0.7397808186950615\n",
      "-0.8381194802634337\n",
      "-0.7770395524907482\n",
      "-0.7034548287543125\n",
      "-0.7666822632986283\n",
      "-0.8170663197822629\n",
      "-0.7088375196509658\n",
      "-0.7883907640336362\n",
      "-0.8748165640994658\n",
      "-0.660892476422004\n",
      "-0.7758743734605016\n",
      "-0.7171408873994323\n",
      "-0.900334907534013\n",
      "-0.7530407344926658\n",
      "-0.8013563844019256\n",
      "-0.6452714833672718\n",
      "-0.6888669665182167\n",
      "-0.8105098676303665\n",
      "-0.7803628671290336\n",
      "-0.7674445615222641\n",
      "-0.7080422164931398\n",
      "-0.6941322508720335\n",
      "-0.7332835703062812\n",
      "-0.7331365389589298\n",
      "-0.8989188664897451\n",
      "-0.7561132157591398\n",
      "-0.7894079557356645\n",
      "-0.7898502936121974\n",
      "-0.8435350651010841\n",
      "-0.9091319427995621\n",
      "-0.869933773785351\n",
      "-0.8278649936811909\n",
      "-0.7836052802899582\n",
      "-0.7520262924474379\n",
      "-0.7288154731478576\n",
      "-0.7935911730415495\n",
      "-0.8208876170699776\n",
      "-0.8132905363748394\n",
      "-0.7681151289719503\n",
      "-0.7318786248482406\n",
      "-0.8062912396501953\n",
      "-0.7473629644758294\n",
      "-0.776824430706029\n",
      "-0.7426258004499042\n",
      "-0.747238154543397\n",
      "-0.7518746491100864\n",
      "-0.7618138382955877\n",
      "-0.7630843107877615\n",
      "-0.7798998169185323\n",
      "-0.7924290204205511\n",
      "-0.7583800634390943\n",
      "-0.7972777064857278\n",
      "-0.7392640579503152\n",
      "-0.830187572275856\n",
      "-0.8075204031799904\n",
      "-0.7358477514384781\n",
      "-0.7084891542218641\n",
      "-0.8035942797877899\n",
      "-0.6818226377655051\n",
      "-0.6921034095728533\n",
      "-0.7627068896010463\n",
      "-0.7607040166052167\n",
      "-0.6571133482499519\n",
      "-0.6865710388637196\n",
      "-0.6803912025947915\n",
      "-0.6672378627709381\n",
      "-0.6842073545831475\n",
      "-0.7670341659421595\n",
      "-0.8625652500160501\n",
      "-0.7072917696418337\n",
      "-0.6617082632560479\n",
      "-0.7383053350630868\n",
      "-0.659360914477788\n",
      "-0.7091981978687933\n",
      "-0.7605960812337872\n",
      "-0.8794635846924572\n",
      "-0.765152363150534\n",
      "-0.8601962273280832\n",
      "-0.7120626281297314\n",
      "-0.7013380941859981\n",
      "-0.7620879738742732\n",
      "-0.7761973481309713\n",
      "-0.7922026468597418\n",
      "-0.746789273431752\n",
      "-0.8344778134971759\n",
      "-0.6812797152168131\n",
      "-0.7092471157288869\n",
      "-0.6938427012340317\n",
      "-0.727800703494864\n",
      "-0.7357942531294407\n",
      "-0.6588373537571124\n",
      "-0.6798594503147996\n",
      "-0.6330148325799073\n",
      "-0.7003441846270473\n",
      "-0.7505937611422089\n",
      "-0.8826879236014685\n",
      "-0.7803397330227442\n",
      "-0.7860255209824564\n",
      "-0.7420681488364318\n",
      "-0.7026765507410154\n",
      "-0.7987456090915789\n",
      "-0.8134010001401641\n",
      "-0.7050216835289914\n",
      "-0.7629643357661711\n",
      "-0.657859544596057\n",
      "-0.7409894756221618\n",
      "-0.7603692892948072\n",
      "-0.6245824092406919\n",
      "-0.6912875101817051\n",
      "-0.6445830889744031\n",
      "-0.5827043185434506\n",
      "-0.7089929387910247\n",
      "-0.7031824189772814\n",
      "-0.6529941762384882\n",
      "-0.7241110905647634\n",
      "-0.6487534110456272\n",
      "-0.6805500421338714\n",
      "-0.6171281922563817\n",
      "-0.5429264276145224\n",
      "-0.5859237142033376\n",
      "-0.5862748473662472\n",
      "-0.6212024388859296\n",
      "-0.7050935272018992\n",
      "-0.7316957048468553\n",
      "-0.6860188434658911\n",
      "-0.6130102698516802\n",
      "-0.6901726658766831\n",
      "-0.6375564338048569\n",
      "-0.6553333499099773\n",
      "-0.6746321120000913\n",
      "-0.7481127687120006\n",
      "-0.6665869645177294\n",
      "-0.7448258326179485\n",
      "-0.6972405792422925\n",
      "-0.705682159655246\n",
      "-0.633573896726275\n",
      "-0.7176983656377618\n",
      "-0.731962314776957\n",
      "-0.8047332700704909\n",
      "-0.7973961661193241\n",
      "-0.6380885939009288\n",
      "-0.7220357479183696\n",
      "-0.674161014334107\n",
      "-0.6362834921577278\n",
      "-0.6989874870559981\n",
      "-0.658314949364839\n",
      "-0.6237056991134118\n",
      "-0.6428461761990665\n",
      "-0.7160022992588203\n",
      "-0.6808752864272805\n",
      "-0.7214326847935336\n",
      "-0.6431272395929353\n",
      "-0.7721399034199568\n",
      "-0.7632301911087256\n",
      "-0.7595401246301899\n",
      "-0.7726329860604327\n",
      "-0.7994547523800967\n",
      "-0.7061918669763718\n",
      "-0.6449078596911978\n",
      "-0.7741356355756706\n",
      "-0.7620425416824375\n",
      "-0.7085784445366836\n",
      "-0.697828487269068\n",
      "-0.7166888014871127\n",
      "-0.8439797225348369\n",
      "-0.8121677935033765\n",
      "-0.6704382688216927\n",
      "-0.729833566147673\n",
      "-0.6800116014161312\n",
      "-0.7494949004043805\n",
      "-0.6350708512778966\n",
      "-0.7702642637450157\n",
      "-0.7393471866340005\n",
      "-0.8082581622831537\n",
      "-0.6933107932119816\n",
      "-0.7800203731751048\n",
      "-0.7153470762508172\n",
      "-0.7374228017464449\n",
      "-0.5702431987883874\n",
      "-0.6522433789864177\n",
      "-0.6567657101159544\n",
      "-0.6952470412184879\n",
      "-0.5073023027371871\n",
      "-0.565173377320021\n",
      "-0.611194583291628\n",
      "-0.5468880177492923\n",
      "-0.5426968917623115\n",
      "-0.49436175269243293\n",
      "-0.6889701394351234\n",
      "-0.737181440020794\n",
      "-0.6438064000342211\n",
      "-0.7134798904841133\n",
      "-0.6589875859638746\n",
      "-0.7024251760944701\n",
      "-0.6816920588476937\n",
      "-0.7138969515536047\n",
      "-0.6632352047076311\n",
      "-0.6431366356489548\n",
      "-0.7541243496270432\n",
      "-0.63479118396974\n",
      "-0.7027087131557398\n",
      "-0.8141075968651429\n",
      "-0.628772654365982\n",
      "-0.6699968632013893\n",
      "-0.606578259444283\n",
      "-0.6881661092798517\n",
      "-0.657896009482434\n",
      "-0.6712161719407326\n",
      "-0.6205135797730139\n",
      "-0.6080421755757164\n",
      "-0.6660439858646863\n",
      "-0.7167433766745062\n",
      "-0.7749450484319214\n",
      "-0.7712795309903736\n",
      "-0.8137781199834103\n",
      "-0.6579508922201991\n",
      "-0.7781351020669329\n",
      "-0.6958707877190693\n",
      "-0.7754446781867422\n",
      "-0.740276979933082\n",
      "-0.7423846540855664\n",
      "-0.7520318343127446\n",
      "-0.7496492333745611\n",
      "-0.7284486453332487\n",
      "-0.6925725147010954\n",
      "-0.7340041038723986\n",
      "-0.7340091739314398\n",
      "-0.6032645142413171\n",
      "-0.7599582244287999\n",
      "-0.696531657181705\n",
      "-0.66787380413116\n",
      "-0.5927782822876871\n",
      "-0.7219383272494728\n",
      "-0.7664026355474066\n",
      "-0.7971763750550219\n",
      "-0.7439660048878394\n",
      "-0.659950064990006\n",
      "-0.7424989509215808\n",
      "-0.6577528816837004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6078467356052207\n",
      "-0.743486615738384\n",
      "-0.7650355464881433\n",
      "-0.7319931192062563\n",
      "-0.7937784421372419\n",
      "-0.6443946998214416\n",
      "-0.7244040604003972\n",
      "-0.6628800674606671\n",
      "-0.6111535261142245\n",
      "-0.6378445357201571\n",
      "-0.6292740880406638\n",
      "-0.6541253121013865\n",
      "-0.6795885832565303\n",
      "-0.623563729424498\n",
      "-0.6886951418543708\n",
      "-0.6686866420526107\n",
      "-0.63216178562406\n",
      "-0.5910366574315765\n",
      "-0.6812923751024625\n",
      "-0.6367179677155262\n",
      "-0.529068461951655\n",
      "-0.5513490196455259\n",
      "-0.5397609904696693\n",
      "-0.4909574387543254\n",
      "-0.49560481138378165\n",
      "-0.5263626238640029\n",
      "-0.529431160407202\n",
      "-0.6031035045788291\n",
      "-0.5598483053210689\n",
      "-0.5976375450819126\n",
      "-0.6413159029862282\n",
      "-0.6946900686183495\n",
      "-0.5600587745109912\n",
      "-0.6032004163473167\n",
      "-0.6105884370493275\n",
      "-0.543002118854283\n",
      "-0.5466846574629255\n",
      "-0.6463557294763422\n",
      "-0.7193063840075522\n",
      "-0.5641336437704682\n",
      "-0.5650717577745273\n",
      "-0.7055122917509712\n",
      "-0.5890301211683683\n",
      "-0.5700058040493857\n",
      "-0.6817603822943235\n",
      "-0.7416793454559303\n",
      "-0.7147902584848791\n",
      "-0.6856746396542482\n",
      "-0.6757555493148028\n",
      "-0.6265558951273245\n",
      "-0.6497568484238717\n",
      "-0.5831819202405112\n",
      "-0.6651742743024186\n",
      "-0.7318823887041498\n",
      "-0.6382635315524492\n",
      "-0.7352045236420776\n",
      "-0.7224893216013806\n",
      "-0.7175340879145742\n",
      "-0.5822009401299825\n",
      "-0.6711415613967091\n",
      "-0.7289635655656747\n",
      "-0.7061918565967199\n",
      "-0.8091122486508739\n",
      "-0.693920355013709\n",
      "-0.7332893238572288\n",
      "-0.6827878390840341\n",
      "-0.7164938243863368\n",
      "-0.7373041294419653\n",
      "-0.6597344374793495\n",
      "-0.8130123338412943\n",
      "-0.7488058281484846\n",
      "-0.7524301420096383\n",
      "-0.7593413959841685\n",
      "-0.674450585718628\n",
      "-0.7932862717041105\n",
      "-0.6305556687464741\n",
      "-0.6268302505342705\n",
      "-0.7208016097338011\n",
      "-0.7436486409513342\n",
      "-0.8106001476462441\n",
      "-0.7398751575007413\n",
      "-0.7441150553379765\n",
      "-0.6933672134962091\n",
      "-0.7427861742554103\n",
      "-0.7101212254976469\n",
      "-0.676069209047603\n",
      "-0.5807023202672134\n",
      "-0.7260283944032302\n",
      "-0.7083863360689605\n",
      "-0.8290163422847237\n",
      "-0.7494618896124885\n",
      "-0.7121843117930874\n",
      "-0.7984898193959347\n",
      "-0.7542201309030594\n",
      "-0.7732505304024188\n",
      "-0.7253635885590528\n",
      "-0.7027020176614815\n",
      "-0.5623278995403604\n",
      "-0.6539379464180143\n",
      "-0.6510224626214635\n",
      "-0.6816515775925563\n",
      "-0.7566523888896931\n",
      "-0.7140567482141797\n",
      "-0.8152533004881064\n",
      "-0.6357344279757566\n",
      "-0.6982329879180723\n",
      "-0.7050741496170039\n",
      "-0.6783941242746584\n",
      "-0.6638740521080093\n",
      "-0.7594522959504371\n",
      "-0.697847038202805\n",
      "-0.7929904888656357\n",
      "-0.8721246338755746\n",
      "-0.7343372806779342\n",
      "-0.8135413946754531\n",
      "-0.6965888982795604\n",
      "-0.7371621457280157\n",
      "-0.6858298123734179\n",
      "-0.6851015231532139\n",
      "-0.631508937490035\n",
      "-0.6441640070636315\n",
      "-0.7414204725032019\n",
      "-0.7560288460892649\n",
      "-0.6379017482951626\n",
      "-0.7435719022970486\n",
      "-0.5905441432800363\n",
      "-0.6637057694790921\n",
      "-0.7139667979636497\n",
      "-0.7032005363028783\n",
      "-0.6550261965241019\n",
      "-0.7573255932195568\n",
      "-0.6986761770138643\n",
      "-0.6665111338019588\n",
      "-0.5728621645340137\n",
      "-0.5427054722612851\n",
      "-0.6732704169361866\n",
      "-0.6071919388874408\n",
      "-0.638858110313933\n",
      "-0.6991773601346846\n",
      "-0.8078551844515982\n",
      "-0.8423041892623135\n",
      "-0.8112224509810563\n",
      "-0.7727451006365144\n",
      "-0.8126013354593586\n",
      "-0.8299269048923074\n",
      "-0.7866481521944143\n",
      "-0.7869170247777902\n",
      "-0.6426669051372387\n",
      "-0.7359912241644345\n",
      "-0.8153831895039905\n",
      "-0.8300612922777132\n",
      "-0.7054867608553259\n",
      "-0.7937016445921058\n",
      "-0.6978508707701682\n",
      "-0.7611657183029797\n",
      "-0.7455668844944167\n",
      "-0.7096194906855146\n",
      "-0.6401903353186374\n",
      "-0.6933784915833604\n",
      "-0.7909241001347485\n",
      "-0.7648483345633513\n",
      "-0.6969152452297425\n",
      "-0.6876588745220208\n",
      "-0.8806106261117379\n",
      "-0.8336461340884065\n",
      "-0.7631924574124087\n",
      "-0.8591657387252155\n",
      "-0.806445077010458\n",
      "-0.7605803432343335\n",
      "-0.8364431563323372\n",
      "-0.7822087656753416\n",
      "-0.8397355343493635\n",
      "-0.8640903788298816\n",
      "-0.833736605873515\n",
      "-0.8793338866922977\n",
      "-0.7901350942566346\n",
      "-0.8406680469450605\n",
      "-0.8110531113521013\n",
      "-0.9381494306675465\n",
      "-0.7483035685485093\n",
      "-0.7359447714449543\n",
      "-0.8874154807461663\n",
      "-0.8713242244975655\n",
      "-0.8474016283918694\n",
      "-0.7667636774753908\n",
      "-0.8385485771252078\n",
      "-0.8853805938512125\n",
      "-0.9134729473038822\n",
      "-1.0082837275763152\n",
      "-0.9821714928608214\n",
      "-0.9488779700345876\n",
      "-0.9169977278002563\n",
      "-1.0118253696820976\n",
      "-0.954453459788836\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "env = Ascento()\n",
    "env.reset_model()\n",
    "m1 = []\n",
    "m2 = []\n",
    "m3 = []\n",
    "\n",
    "m4 = []\n",
    "\n",
    "for i_episode in range(15):\n",
    "    observation = env.reset()\n",
    "    done = None\n",
    "    while not done:\n",
    "        env.render()\n",
    "        print(env.vx)\n",
    "        action, _ = model.predict(env._get_obs())\n",
    "        m1.append(action[0])\n",
    "        m2.append(action[1])\n",
    "        m3.append(action[2])\n",
    "        m4.append(action[3])\n",
    "#         action[2] = 1\n",
    "#         action[3] = 1\n",
    "\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(m1)\n",
    "plt.plot(m2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
